[
    {
        "id": "paper_1",
        "filename": "B2024_HarukiShimizu.pdf",
        "title": "B2024_HarukiShimizu",
        "fulltext": "青山学院大学理工学部\n情報テクノロジー学科\n２０２４年度卒業研究論文\n視線を用いたFPSゲームにおける\nスキル分析\n２０２５年１月２８日提出\n指導教員ロペズ・ギヨーム教授\n提出者学生番号　氏名\n１５８２１０３９清水遥希\n青山学院大学 理工学部 情報テクノロジー学科 \n2024（令和6）年度卒業論文要旨 \n- 1 - \n \n視線を用いたFPS ゲームにおけるスキル分析 \n \n清水 遥希（15821039） \nロペズ研究室 \n \n１． はじめに \n近年のオンラインゲーム市場調査によれば，市場全\n体の規模はスマートフォンやPC 向けタイトルの拡大\nにより急成長を遂げている[1]．その中で，FPS（First \nPerson Shooter）ゲームは，「競争」という要素を強調\nした部類として多くのプレイヤーに支持されている\n[2]．FPS ゲームでは，標的への照準を合わせる動作を\n指す「AIM」というスキルが特に重要視されており，\nこのスキルの向上が勝敗を左右する要因となるが，\nAIM スキルの上達には多くの課題が存在する． \n本研究では，視線固定速度と操作速度の2 つの指標\nを用いてAIM スキルを定量的に評価し，プレイヤー\nの熟練度に応じた新たなスキル評価の枠組みを提案す\nることを目的としている． \n２．関連研究 \n既存研究では，視線追跡装置や動作データを用いて\ne スポーツプレイヤーのスキルや反応時間を評価する\n試みが行われている．Koposov らは視線追跡装置を用\nいた反応速度の評価を，Smerdov らはスマートチェア\nによる行動データ分析を実施し，それぞれプロとアマ\nチュアのスキル差を示した[3][4]． \nしかし，これらの研究ではFPS ゲーム特有のスキル\nであるAIM の定量的評価が十分ではなく，プレイヤ\nーへの具体的なフィードバックが不足している．本研\n究では，視線固定速度と操作速度を指標とし，AIM ス\nキルの客観的評価とスキル向上を支援するデータの提\n供を目指す． \n３．FPS スキル分析手法 \n本研究では，FPS のスキルを分析するための新たな\nシステムを開発した（図１を参照）．Pupil Core[5]とい\nう眼鏡型視線追跡装置を用いて，以下の２つの指標か\nらスキルを評価する． \n① \n視線固定時間：ターゲットが出現してから，視\n線がターゲットに固定されるまでの時間． \n② \n破壊時間：ターゲットが出現してから，ターゲ\nットを破壊するまでの操作時間．ターゲット破\n壊の判定は画像認識を用いて行う． \n \n図1 システムの概要図 \n４． FPS 訓練環境によるスキル計測 \n実験ではAimLabs というAim トレーニングアプリ\nを使用し，本実験のためにシナリオを2 種類作成した\n[6]．実験には19 名（成人男性18 名，成人女性1 名）\nの被験者が参加し，FPS ゲームValorant でのランク\n分布に基づき，初心者，中級者，上級者の3 つのグル\nープに分類した[7]． \n被験者には5 分間のウォームアップ，視線追跡装置\nのキャリブレーションの後に，2 種類のシナリオをそ\nれぞれ2 回ずつプレイしてもらった．実験は1 日で，\nシナリオは1，2 の順番で行った． \n① \nシナリオ１：瞬時にAIM を合わせるフリック\nAIM というAIM スキルだけが求められるよ\nうに設計した． \n② \nシナリオ２：フリックAIM に加えてゲーム知\n識が与える影響を検証するためにValorant に\n登場するステージとターゲットを再現した． \n実験終了後，実験環境やターゲットの設定に関する\nフィードバックを得るためのアンケートを実施した． \n \n \n５．結果 \n図2，図3 はシステムを使用して計測を行ったシナ\nリオ1 における視線が固定されるまでの時間とターゲ\nットが破壊されるまでの時間の分布を表す箱ひげ図で\nある．これらの結果に分析を行ったところ，それぞれ\n上級者と初心者，中級者と初心者の間に有意な差が認\nめられた．また，どちらの時間も熟練度が上がるほど\n短くなる傾向が見られた．時間とは別に命中率は熟練\n度によってほとんど差がなく，有意差もなかった． \n表1，表2 はそれぞれのシナリオにおける熟練度別\nの平均結果である．シナリオ2 においてはターゲット\nの小さい頭部分を狙ってしまうという上級者の\nValorant プレイヤーの特性が表れたため，中級者の方\nが上級者より時間が短く，上級者だけ命中率が低くな\nった． \nまた，録画データの解析により，視線移動の効率性\nが熟練度に応じて異なることが明らかになった． \n \n図2．シナリオ1 における視線が固定されるまでの時\n間の比較(**:p<0.01) \n \n図3．シナリオ1 におけるターゲットが破壊されるま\nでの時間の比較(**:p<0.01) \n表1:シナリオ1 における熟練度別の平均結果 \n \n表2:シナリオ2 における熟練度別の平均結果\n \n６．まとめ \n実験・分析結果から本研究で提案した2 つの指標は，\nAIM スキルの評価に有用であることが判明した．しか\nし，独自のアンケートより，シナリオと環境をFPS プ\nレイヤーにとって自然になるように再構築する必要が\n示唆された． \n今後の展望として，モニター距離や姿勢といった他\nの要素との関連性を検討することで，より効果的なフ\nィードバックを提供できる可能性がある． \n参考文献 \n[1] \nデロイトトーマツ：拡大を続けるゲーム市場の動\n向(2024)． \nhttps://faportal.deloitte.jp/times/articles/00093\n7.html．(最終参照日:2024/7/3) \n[2] \nFOUNDRY, Q.:7 Things We Learned About \nPrimary Gaming Motivations From Over \n250,000 Gamers (2016/12/15). \nhttps://quanticfoundry.com/2016/12/15/ \nprimary-motivations/. (最終参照日:2025/1/13) \n[3] \nKoposov, D., Semenova, M., Somov, A., Lange, \nA., Stepanov, A. and Burnaev, E.: Anal- ysis of \nthe Reaction Time of eSports Players through \nthe Gaze Tracking and Person- ality Trait, 2020 \nIEEE 29th International Symposium on \nIndustrial Electronics (ISIE), IEEE, pp. 1560-\n1565  \n[4] \nSmerdov, A., Burnaev, E. and Somov, A.: \neSports Pro-Players Behavior During the \nGame Events: Statistical Analysis of Data \nObtained Using the Smart Chair, arXiv \npreprint arXiv: 1908.06402 (2019). \n[5] \nCore - Pupil Capture -, Pupil Labs Docs, \nhttps://docs.pupil-labs.com/ \ncore/software/pupil-capture/ \n（最終参照\n日:2025/01/19). \n[6] \nHomepage - Aimlabs,  \nhttps://aimlabs.com/. (最終参照日:2025/1/19). \n[7] \nVALORANT, \nhttps://playvalorant.com/ja-jp/. ( 最終参照日: \n2025/1/19). \n熟練度\n固視時間(秒) 破壊時間(秒) 命中率(%)\n上級者\n0.171\n0.604\n83.22\n中級者\n0.201\n0.644\n84.40\n初心者\n0.368\n0.852\n85.97\n熟練度\n破壊時間(秒)\n命中率(%)\n上級者\n0.846\n48.71\n中級者\n0.770\n64.13\n初心者\n1.028\n64.64\n目次\n第1 章\n序章\n1\n1.1\n研究背景. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n1\n1.1.1\ne-sports 業界の現状. . . . . . . . . . . . . . . . . . . . . . . . . . .\n1\n1.1.2\nFPS ゲームにおけるAIM スキル. . . . . . . . . . . . . . . . . . . .\n3\n1.2\n研究目的. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n5\n1.3\n本論文の構成. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n5\n第2 章\n関連研究\n6\n2.1\nアイトラッカーを使用した研究. . . . . . . . . . . . . . . . . . . . . . . .\n6\n2.2\nプレイヤーのスキル分類に関する研究\n. . . . . . . . . . . . . . . . . . . .\n7\n2.3\n視野と反応時間に関する研究\n. . . . . . . . . . . . . . . . . . . . . . . . .\n8\n2.4\n画像認識を用いたゲームに関する研究\n. . . . . . . . . . . . . . . . . . . .\n8\n2.5\n先行研究のまとめ. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n8\n第3 章\n開発したシステムについて\n10\n3.1\nシステムの概要. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n10\n3.2\nアイトラッカーを使用した固視測定. . . . . . . . . . . . . . . . . . . . . .\n12\n3.2.1\n固視. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n12\n3.2.2\nPupil Core . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n12\n3.3\n画像認識を使用したターゲット破壊時間測定. . . . . . . . . . . . . . . . .\n15\n3.3.1\n作成したAIM トレーニングシナリオ. . . . . . . . . . . . . . . . .\n15\n3.3.2\n画像認識\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n18\n第4 章\n実験\n20\n4.1\n実験概要. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n20\n4.2\n実験手順. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n21\n4.3\n実験環境. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n23\n4.4\n分散分析. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n24\n4.5\n実験後アンケート. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n24\ni\n第5 章\n実験結果および考察\n26\n5.1\n実験結果. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n26\n5.1.1\nシナリオ1 の結果と考察. . . . . . . . . . . . . . . . . . . . . . . .\n26\n5.1.2\nシナリオ2 の結果. . . . . . . . . . . . . . . . . . . . . . . . . . . .\n29\n5.2\n録画データから読み取れた考察. . . . . . . . . . . . . . . . . . . . . . . .\n32\n5.3\nアンケート結果. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n32\n第6 章\n結論\n35\n6.1\nまとめ. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n35\n6.2\n今後の展望\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n35\n参考文献\n37\n付録A 　FPS に関する意識調査\n39\n付録B\n　実験のフィードバックアンケート\n41\nii\n第1章\n序章\n本章では，社会的な背景をもとに研究の位置付けを明確にする．第1.1 節では本研究に\nおける背景，第1.2 節では研究目的と目標，第1.3 節では本論文の構成について述べる．\n1.1\n研究背景\n1.1.1\ne-sports 業界の現状\n近年，FPS（First Person Shooter）ゲームという一人称視点のシューティングゲームを含\nむオンライン対戦ゲームの市場規模は増加し続けている．以下に調査等を参照しながら現\n状を説明する．\nオンライン対戦ゲームを含むゲーム業界全体の市場規模が拡大し続けているが，その成\n長の要因としてマルチプラットフォーム化やe スポーツ業界の成長があげられる[1]．\n2012 年には家庭用ハードや買い切りのパッケージ版ソフトが市場の半分を占めていた\nが，10 年後にはオンラインプラットフォームの急成長により1/6 ほどになってしまってい\nることが図1-1 から分かる．また，オンラインプラットフォームの中でも，家庭用ゲーム\n機ソフトの占める割合は小さく，スマートフォンやPC 向けソフトの占める割合が大きい\nことが示唆されている．その要因としてスマートフォンの台頭とともに増加していったダ\nウンロード無料のアプリケーションの課金システムの増加などが考えられる．未だ買い\n切りのe-sports 向けゲームも多数存在するが，ここ数年でリリースされたゲームはこの課\n金に重きをおいたゲームが増えてきているため，e-sports 向けゲームの市場規模・プレイ\nヤー数は今後も成長していくと考えられる．\n1\n図1-1: 国内のゲーム市場の推移（[2] より引用）\nまた，図1-2 に示したように国内のe スポーツ市場規模は成長しており，オンライン対\n戦ゲームの中でも「競争」という部分にフォーカスしたゲームの人気が高まっている．こ\nの影響はFPS にも表れている．2022 年にはPUBG MOBILE JAPAN LEAGUE SEASON2\nという日本のFPS ゲームの大会では史上最高額となる賞金総額3 億円の大会が開催され\nた[3]．2023 年にはVALORANT CHAMPIONS TOUR MASTERS TOKYO というVCT 史\n上初の世界大会も開催された[4]．また，e-sports と聞くとプロゲーマーをイメージしがち\nだが，市場の拡大の要因にはインフルエンサーの大会やアマチュアプレイヤーのコミュニ\nティの拡大など身近な要素も含まれている．\n2\n図1-2: 日本のe スポーツ市場規模2023 年以降は予測（[5] より引用）\n1.1.2\nFPS ゲームにおけるAIM スキル\n世界中の25 万人以上のゲーマーを対象として，ゲームに対するモチベーションに関し\nた調査がある．図1-3 のグラフを見ると，若いゲーマーにとってCompetition（競争）が\n最も重要なモチベーションであることがわかる．この調査結果として，自分自身のスキル\nを磨きライバルと切磋琢磨していくプレイスタイルが好まれているということが分かっ\nた[6]．\nFPS ゲームではよく「AIM」という単語が使われる．FPS ゲームにおけるAIM とは標\n的を認識し，マウス操作を行い標的を撃ち抜く一連の動作であり，このAIM の能力が対\n戦相手よりも速く，正確であれば有利に戦うことができる[7]．そのため，勝つためには\n相手より速く敵を見つけ，反応し，照準を合わせることが求められる．プロの試合では反\n応速度，操作精度が極まったAIM がいくつも飛び出す．また，FPS ゲームでは戦術やコ\nミュニケーションなど他の要素を無視し，AIM の強さのみで1 対多数の状況をひっくり返\nしてしまった状況では「破壊」という表現がよく用いられる．この表現は普段のゲームプ\nレイをはじめ，大会の実況解説などでも使われており，FPS プレイヤーにとって馴染みの\nあるワードである．図1-3 のグラフでは2 番目にDestruction（破壊）の項目が高く，FPS\nゲームは若いゲーマーのニーズに当てはまったゲームといえる．\n3\n図1-3: 13 歳から25 歳のゲーマーの主なモチベーション（[6] より引用）\n本研究を開始するにあたって、13 人のFPS プレイヤーにAIM に関する意識調査を行っ\nた．使用したアンケートフォームを付録A に示す．1 つは「FPS ゲームで強くなるために\n一番必要なスキル」についてのアンケートだ．それぞれ多様な考え方が存在したが，半数\n以上のプレイヤーがAIM スキルが一番必要だと回答した．2 つ目は「AIM スキルの停滞\n経験」についてだ．多くのプレイヤーがAIM スキルが重要と答えたにも関わらず，ほと\nんどのプレイヤーが停滞したことがあると回答した．経験があると答えたプレイヤーの中\nにはAIM スキルを上げるための方法に迷ったと答えたプレイヤーも数名存在した．AIM\nスキルは重要度に対して上達するためのハードルが高いというのが現状である．\n図1-4: 強くなるために必要なスキル\n図1-5: AIM スキルの停滞経験\n4\n1.2\n研究目的\n拡大を続けるオンラインゲームの中でも若者のニーズを満たし，人気を獲得している\nFPS ゲームは今後も多くのプレイヤーに親しまれていくだろう．しかし，FPS というジャ\nンルの中で重要であるAIM スキルは向上させることが難しい．一部のプロプレイヤーに\nなれば専門のコーチがつくこともあるが，それ以外のプレイヤーは個人の感覚に頼り，手\n探りで上達する方法を見つけなくてはならない．本研究では，AIM スキルの上達方法を\n定量的な指標を用いてプレイヤーへフィードバックを行うことを最終的な目的としてい\nる．この目的を達成するためにはプレイヤーのスキルの良し悪しを評価する方法を確立\nする必要がある．そのため今回の研究では，AIM における視線が固定される速度と操作\n速度の数値データを獲得し，プレイヤーのレベル別に分析することでAIM スキルの新た\nな評価指標として確立することを目標としている．姿勢や腕の動作，モニターとの距離，\nデバイスの種類などAIM には様々な要素が存在する．AIM スキルを向上させるにはこれ\nらの要素をそれぞれ改善していく必要があるが，姿勢やデバイスを変えてもその良し悪し\nが判断できなければ意味がない．本研究で収集する二つの速度が分かれば，AIM を合わ\nせるまでの合計時間が求められるため，今後姿勢やデバイスの改善の評価に用いることが\n期待できる．\n1.3\n本論文の構成\n第1 章では，本論文の研究背景，研究目的，及び本論文の構成について述べた．第2 章\nでは，関連研究について説明する．第3 章ではシステムの概要について述べる．第4 章で\nは，第3 章で述べた提案システムの評価実験について述べる．第5 章では，第6 章で実施\nした評価実験の結果とその考察について述べる．最後に第??章では，本論文のまとめと今\n後の展望について述べる．\n5\n第2章\n関連研究\n2.1\nアイトラッカーを使用した研究\nKoposov らは，プロおよびアマチュアのe スポーツプレイヤーの反応時間をアイトラッ\nカーを用いて評価し，反応時間と性格特性との関連性を調査した[8]．具体的には，反応\n時間をサッカード潜時，サッカードと固視の間の時間，照準と射撃の時間の3 つに分けて\n分析した．35 名の参加者（7 名のプロプレイヤーと28 名の初心者およびアマチュア）を\n対象に実施された．結果として，プロプレイヤーは全ターゲットタイプにおいて反応が速\nく，特に赤いターゲットに対する反応が速いことが示された．対照的に，アマチュアプレ\nイヤーは中央のターゲットに対して速く反応した．この研究は，e スポーツにおける反応\n時間と性格特性との関連性について初めての包括的な分析を提供し，e スポーツのトレー\nニング方法やパフォーマンス分析の改善に寄与することが期待される．この研究で使用さ\nれたテストシナリオのスクリーンショットを図2-1 に示す．\n図2-1: テストシナリオのスクリーンショット（[8] より引用）\n6\n出山らは，瞳孔径を用いた精神疲労の評価方法を検討した[9]．この研究では，視線計測\n装置を使用して瞳孔径をリアルタイムで測定し，作業負荷と精神疲労の相関を分析した．\n結果として，精神疲労が進行するにつれて瞳孔径の平均値，最小値，積分値が減少し，疲\n労感VAS スコアと有意な相関を持つことが示された．この研究は，視覚的生体情報を利\n用して精神疲労を検出し，適切な休憩タイミングを提示する新たなシステム設計の可能性\nを示している．この研究の概要図を図2-2 に示す．\n図2-2: システムの概要図（[9] より引用）\n2.2\nプレイヤーのスキル分類に関する研究\nSmerdov らは，e-Sports プロ選手のゲーム中の行動をスマートチェアで収集したデータを\n用いて分析し，プレイヤーのスキルを評価する新しい方法を提案した[10]．実験はCS:GO\nのリテイクシナリオで実施され，プロ選手とアマチュア選手のデータが収集された．こ\nれらのデータをもとに，機械学習モデルを訓練し，最も精度の高いモデルは77%の精度\nと0.88 のROC AUC スコアを達成した．分析により，プロ選手とアマチュア選手の動作\nパターンの違いが特定され，特に重要な特徴量として殺傷や死亡後の動作，チェアの背も\nたれに寄りかかる時間の割合，加速度計とジャイロスコープの標準偏差が明らかになっ\nた．この研究は，eSports 選手の物理的な行動データを利用してパフォーマンスを評価す\nる新しい視点を提供し，ゲーム中の行動からスキルを客観的に評価するための基盤を構築\nした．\n7\n2.3\n視野と反応時間に関する研究\nboch らは，サルのエクスプレスサッケード（非常に短い反応時間の眼球運動）に関す\nる研究を行った[11]．彼らは，サルが小さな光点を注視し，その光点が消えた後に周辺の\nターゲットにサッケードするよう訓練した．光点のオフセットがターゲットのオンセッ\nトよりも140ms 以上早い場合，サルは70-80ms 以内に視線を変えることができた．エク\nスプレスサッケードの反応時間は，ターゲットの輝度やサイズに依存し，閾値近くのター\nゲットでは約120ms から，閾値を2.5 ログ単位上回る範囲で約50ms 短縮される．最小反\n応時間とそのターゲットサイズは，ターゲットの網膜偏心度の関数である．これらの結果\nは，エクスプレスサッケードの短い反応時間が主に網膜要因によって決定されることを示\n唆している．\n浅見らは，視野反応計を用いて中心視反応と周辺視反応の比較検討を行った[12]．彼ら\nは，視野反応計を用いて，中心視と周辺視の反応時間を測定し，その違いを分析した．実\n験では，被験者が中心視と周辺視の両方で光刺激に反応する時間を測定し，反応時間の違\nいを比較した．その結果，中心視反応は周辺視反応よりも速いことが示された．また，反\n応時間の違いは視標の角度や距離によっても影響を受けることが明らかになった．この研\n究は，視覚反応のメカニズムを理解する上で重要な知見を提供している．\n2.4\n画像認識を用いたゲームに関する研究\n高橋らは，テトリスを題材にしたルールベースのデバッグAI を試作し，プレイ動画か\nらバグを自動検出する手法を提案した[13]．この研究では，テンプレートマッチングによ\nる画像認識を用い，「ラインが揃ったのに消えない」バグをルールベースで判別するアル\nゴリズムを開発した．評価実験では，ブロック1 個ずつのテンプレート画像を用いる手法\nが，直感的なブロック全体のテンプレート画像を用いる手法よりも高精度であることが確\n認された．一方で，静止画単位での分析に起因する誤検知の問題や未知のバグへの対応が\n課題として挙げられた．この研究は，デバッグAI の可能性を示すとともに，汎用的なシ\nステムの構築に向けた一歩を提供している．\n2.5\n先行研究のまとめ\n既存研究では，アイトラッカーや画像認識を用いてe スポーツプレイヤーのスキルや反\n応時間を評価する試みが行われている．例えば，Koposov らの研究では，プロとアマチュ\nアのプレイヤーを対象にアイトラッカーを用いて反応時間と性格特性の関連を調査し，プ\nロ選手の反応速度が優れていることを示した．また，Smerdov らはスマートチェアを用い\n8\nた動作データの収集により，プレイヤーの行動パターンを機械学習で分析し，プロとアマ\nチュアのスキル差を明確にした．\n一方で，これらの研究にはいくつかの課題がある．第一に，アイトラッカーや動作デー\nタに依存しているため，FPS ゲーム特有のスキルであるAIM に関する定量的な評価が十\n分に行われていない点である．第二に，プレイヤー個々の熟練度に応じた具体的なフィー\nドバックが不足しており，得られたデータをプレイヤーのスキル向上に活用するための枠\n組みが不完全である．\n本研究ではこれらの課題を克服するため，視線固定速度と操作速度という2 つの新たな\n指標を用いてAIM スキルを評価する手法を提案する．この手法により，FPS ゲームにお\nける熟練度の客観的な評価が可能となり，さらにはプレイヤーのスキル向上を支援するた\nめの具体的なデータを提供できることを目指す．\n9\n第3章\n開発したシステムについて\n本研究で使用するシステムは，アイトラッカーと画像認識を使用することでターゲット\nに対して固視が発生するまでの時間と破壊するまでの時間を測定し，被験者のエイムスキ\nルを定量的に分析する．\n本章では，3.1 節で，システムの概要について説明をし，3.2 節で，アイトラッカーを使\n用した固視の測定について述べる．3.3 節では，画像認識を使用した破壊時間の測定方法\nを述べる．\n3.1\nシステムの概要\n本研究はFPS プレイヤーのAIM スキルを「視線のAIM」と「マウスのAIM」の二つに\n分け，この2 種類の能力がプレイヤーの実力にどのように関係しているか分析することを\n目的としている．初心者から上級者までのプレイヤーの二種類の数値データを収集し，集\nめたデータを分析，比較することでFPS プレイヤーにとって重要なスキルを数値的に求\nめることが可能である．システムの全体像を図3-1 に示す．\n図3-1: システムの全体像\n10\nプレイヤーにはAimlabs というアプリをプレイしてもらう．このアプリは，自由度の高\nいステージやシナリオ作成が可能である．そのため，今回の研究目標に合わせたシナリ\nオを二つ作成した．今回はフリックAIM というある一点に向かって瞬間的に照準を合わ\nせるAIM スキルに焦点を当て，分析を行った[14]．求められるAIM スキルは同じだが，\n2 つのシナリオはそれぞれ期待されるデータの特徴が異なる．作成したシナリオの内容に\nついては第3.3.1 節で説明する．\n実験に参加したFPS プレイヤーは全員Valorant という5 対5 のタクティカルFPS ゲー\nムをプレイしていたため，ゲーム知識はValorant のものを使用する[15]．Valorant ではそ\nれぞれのチームが攻撃・防御側に別れ，ステージ中の「サイト」という決められた範囲に\n向かってそれぞれ攻撃・守備を行う．今回のシナリオでは「アセント」というValorant が\nリリースされた当初から存在する一番基本的で有名なステージを再現し，攻撃側の視点で\nアセントのA サイトを攻めるという設定で行った．\nアセントＡサイトの画像を図3-2 に示す．ゲームのよくある流れとして，守備側はサイ\nトを守るために攻め側が侵入する際に遮蔽物から飛び出して迎撃するというものがある．\n遮蔽物の位置は変わらないため，Valorant をプレイしていると守備チームが飛び出してく\nる位置を予測または，記憶することができるようになる．その知識の差による認知速度の\n差を計測することでゲーム知識の有無による影響を調べることができる．\n図3-2: アセントA サイトの様子\n認知速度においてはアイトラッカーを使用することでターゲットが出現してからプレイ\nヤーの視線が固定されるまでの時間を測定した．また，マウスを自在に扱う能力におい\nてはターゲットが出現してから破壊されるまでの時間を画像認識を使用することで測定\nした．\n11\n3.2\nアイトラッカーを使用した固視測定\nプレイヤーの認知能力はアイトラッカーを使用してターゲットが出現してから，固視と\nいう視線の固定が起こるまでの時間を測定することで評価する．本研究で使用するアイト\nラッカーはPupil Labs 社のPupil Core [16] である．\n3.2.1\n固視\n固視（ﬁxation）とは，眼球運動系や視覚系でよく用いられる述語であり，視線を特定の\n目標に固定することを指す言葉である[17]．本研究では視線のAIM の指標として用いる．\n固視が発生しているときは視線の動きや瞳孔の位置も大きく動くことはないが，マイクロ\nサッケードという小さな像の動きが起こる．瞳孔の安定やマイクロサッケードを検出する\nことで固視の判定ができる．\n??\n3.2.2\nPupil Core\nPupil 社のPupil Core を図3-3 に示す．グラス型のデバイスであり，右目上部に外の景色\nを写すワールドカメラ，右目下部に右目を写すアイカメラが装着されており，それぞれ目\nの前の視界と右眼球を写す．それぞれのカメラはジョイントやレールで位置や角度を調整\nすることが可能であり，ワールドカメラはモニターが中心に写る角度に，アイカメラは眼\n球が収まるように調節した．テンプルの先からコードが伸びており，USB Type-C でパソ\nコンと接続して使用する．デバイスの使用方法等は過去の同研究室の卒業論文を参考とし\nた[9]．\n12\n図3-3: Pupil Core\nまた，同社から配信されているPupil Capture，Pupil Player というアプリケーションソフ\nトを録画，実験結果の確認のために使用した[18]．アプリケーションのスクリーンショッ\nト画像を図3-4，図3-5 に示す．Pupil Capture の画面には外カメラの画像が映し出される．\nアイカメラウィンドウでは眼球が認識されているかを確認する．アイカメラでは瞳孔と眼\n球が認識される．赤い点と円で瞳孔が表示され，青い円で瞼に隠れている部分まで補正し\nて眼球の輪郭が表示される．また，アイカメラで瞳孔の向きが認識されることでワールド\nカメラの画面にアイトラッカーの利用者が見ている場所が表示される．見ている部分は赤\nくなり，その周りに黄色の円が出れば視線が固定されていることを示している．\n13\n図3-4: Pupil Capture のスクリーンショット\n図3-5: アイカメラウィンドウのスクリーンショット\n本研究では主に画面左のC とR ボタンを使用する．C は「Calibration（キャリブレーショ\nン）」，R は「Recording（録画）」を表している．キャリブレーションではワールドカメラ\nとアイカメラの相関を行う．キャリブレーションを実行すると画面に5 つの的が表示され\nる．キャリブレーション中の画面を図3-6 に示す．5 つの的は順番に出現する．中心から\n始まり4 隅を巡り視線を誘導する．視線に動きを出すことでデータを収集し，視線の予測\n14\nを安定させる．録画は実行するとデータの収集を開始する．録画データをはじめ，視線の\n座標やタイムスタンプなど様々なデータを収集することができる．\n図3-6: キャリブレーション画面\n3.3\n画像認識を使用したターゲット破壊時間測定\n3.3.1\n作成したAIM トレーニングシナリオ\nAIM トレーニングアプリとしてAimlabs を使用した[19]．Aimlabs は，FPS などの競技\nゲームジャンルでプレイヤーがスキルを向上させるために開発されたエイムトレーニン\nグプラットフォームである．特定のゲームに合わせたトレーニングシナリオや最適なマウ\nス感度を見つける機能などAIM に関係する様々なサポートをしている．\nAimlabs の大きな特徴としていくつかのゲームに存在するステージのテンプレートデー\nタが用意されていることがあげられる．今回の研究で扱ったValorant のアセントもテンプ\nレートとして用意されているため，Aimlabs を実験用のアプリケーションとして採用した．\nトレーニングの実行後，スコアや命中精度などのフィードバックは表示されるが，ター\nゲットを破壊した詳細なタイムラインを含む本研究に必要なデータは提供されていない．\nAPI 等も利用できないため，不足しているデータは補足する必要があった．\nここで，作成した2 つのシナリオについて説明する．まず，1 つ目のシナリオについてエ\nディターやプレイ画面の画像を交えて解説する．1 つ目のシナリオのエディター画面を図\n3-7 に示す．1 つ目のシナリオはスパイダーショットと呼ばれる，中央の固定されたター\nゲットとその周りのランダムな場所に出現するターゲットを交互に射撃するものである．\n15\n中心が決まっており，その周囲に蜘蛛の巣上にターゲットが出現する様子からスパイダー\nショットと呼ばれている．図3-7 における白い壁のような部分でランダムなターゲットが\n出現する．また，この壁の中心の青い球が固定されたターゲットの出現位置である．\n図3-7: 1 つ目のシナリオのエディター画面\nこのシナリオの実行画面を図3-8，図3-9 に示す．ターゲットの形は球状に，中心のター\nゲットは青色，周囲のランダムに出現するターゲットは赤色に設定した．中心の固定され\nたターゲットは視線，カーソルの誘導の役割を果たしている．赤色のターゲットを破壊す\nる度に一度中心にリセットし，また次のランダムに出現するターゲットに反応しやすい仕\n組みとなっている．\n図3-8: 青色のターゲット\n図3-9: 赤色のターゲット\n次に，2 つ目のシナリオであるアセントを再現したシナリオについて説明する．Aimlabs\nで作成したアセントとValorant の実際のアセントの比較を図3-10，図3-11 に示す．元々\nのテンプレートもシンプルな色味をしていたが，画像認識での誤認識を防ぐために色味の\n16\nある物体の配置を抑え，光度を高く設定した．\n図3-10: Aimlabs で作成したアセントシナリオ\n図3-11: 実際のアセント\n基本的なシステムは1 つ目のシナリオと同じだが，赤いターゲットの出現位置をランダ\nムではなく遮蔽物の裏に設定した．出現場所は7 か所設置し，防御チームが潜む頻度が高\nい頻度の場所を選んだ．出現の順番もあらかじめ設定済であり，なるべく視点が振れるよ\nうな順番とした．また，Valorant をプレイしているプレイヤーは球状のものより人型の方\nが反応しやすいと考え，出現する赤色のターゲットを球状から人型に変更した．実際の\nゲームのプレイヤーの動きに似せるために，出現したターゲットはプレイヤーから見て\n90 度の角度で左右横向きに動き続ける．アセントシナリオにおけるターゲットの出現位\n置を図3-12 に示す．\n図3-12: ターゲットの出現位置（エディター画面より）\n17\n3.3.2\n画像認識\nマウスのAIM 速度を取得するためにPython を使用してAimlabs 画面の画像認識を行っ\nた．作成したコードでは赤と青どちらとものターゲットの認識を行い，画面上にターゲッ\nトが出現している間は常にタイムスタンプを残し続け，csv 形式のファイルとして保存さ\nれる．ここでのタイムスタンプはアイトラッカーからのデータとの同期を考え，UNIX 時\n間を採用した．フリックAIM の速度を比較するためには赤色のターゲットが出現してか\nら破壊されるまでの時間を計算する必要がある．シナリオは1 つのターゲットが破壊され\nた瞬間に次のターゲットが出現するように設定した．つまり，赤いターゲットが破壊され\nるタイムスタンプと青いターゲットが出現するタイムスタンプは同じであるため，次に出\n現する青いターゲットの出現時間から赤いターゲットの出現時間を引くことで破壊する\nまでにかかった時間を求めることができる．\nまた，認識を行っている際の録画データも保存される．この録画ではターゲットが認識\nされている間はマスクで囲われるため，誤認識がないかを確認することができる．画像認\n識の実行結果を2 つのシナリオにつき2 枚ずつ図3-13～図3-16 に示す．\n図3-13: シナリオ1 の画像認識実行結果1\n図3-14: シナリオ1 の画像認識実行結果2\n18\n図3-15: シナリオ2 の画像認識実行結果1\n図3-16: シナリオ2 の画像認識実行結果2\n19\n第4章\n実験\n本章では評価実験について述べる．\n4.1\n実験概要\n被験者は成人男性18 名，成人女性1 名の計19 名（年齢層は19 歳から23 歳）に協力し\nてもらった．実験時間は5 分間のアップを含めて約15 分であった．実験終了後はFPS に\n対する経験や実験環境に関するフィードバックを収集するためにアンケートを記入して\nもらった．実験中の様子を図4-1 に示す．\n図4-1: 実験の様子\nまた，本実験に参加する被験者のランクの分布と熟練度の分類を以下の表4-1 に，図4-2\nにValorant におけるランクの種類と順番を示す．\n20\n表4-1: 被験者のランクの分布と熟練度の分類\nID\nランク\n熟練度\n1\nアセンダント2\n上級者\n2\nアセンダント1\n上級者\n3\nアセンダント1\n上級者\n4\nダイヤ1\n上級者\n5\nダイヤ1\n上級者\n6\nプラチナ2\n中級者\n7\nプラチナ1\n中級者\n8\nプラチナ1\n中級者\n9\nゴールド2\n中級者\n10\nゴールド1\n中級者\n11\nゴールド1\n中級者\n12\nシルバー1\n中級者\n13\nシルバー1\n中級者\n14\nランクなし\n初心者\n15\nランクなし\n初心者\n16\nランクなし\n初心者\n17\nランクなし\n初心者\n18\nランクなし\n初心者\n19\nランクなし\n初心者\n図4-2: ランクの種類と順番（[15] より引用）\n4.2\n実験手順\n本実験では，被験者の最大限のAIM スキルのデータを収集するための手順を踏んだ．\nまず，マウスの操作や画面に素早く反応できるようにマウスパッドやキーボード，モニ\nター，椅子の位置や高さなどを自分好みに調整してもらった．また，普段からFPS ゲー\n21\nムをプレイしているプレイヤーは自分の設定どおりにマウスのDPI（Dots Per Inc）とゲー\nム内感度を調節してもらった．次に，アイトラッカーを装着してもらい，カメラの位置調\n整を行いキャリブレーションを実行した．この時Pupil Capture 上で視線を追えているこ\nとを必ず確認した．その後，マウスの操作感やAimlabs に慣れるために3.3.1 節で説明し\nたシナリオ1 を使用して5 分間のウォームアップを行ってもらった．5 分間でシナリオ1\nが3 回か4 回プレイできるのだが，ほとんどのプレイヤーがこの回数をプレイするとスコ\nアが安定したため，5 分間と定めた．\nここまでを準備とし，次の手順からは計測に移る．作成した2 つのシナリオをそれぞれ\n2 回ずつプレイしてもらった．シナリオ1 は45 秒間経過，シナリオ2 は設置したターゲッ\nト42 個すべてを破壊する（約30 秒）ことで終了する．シナリオに取り組んでいる最中は\n休む暇なくAIM に集中することとなる．Valorant では相手と撃ち合う時間がそれほど長\nくないため，実験時間を長くしてしまうと被験者の集中力を阻害してしまうと考え，45 秒\nに設定した．また，シナリオ2 に関しては出現する順番を覚えることができないように計\n測前に説明のみ行い，練習はなしとした．実験の手順を示すフロー図を図4-3 に示す．\n図4-3: 実験の手順を示すフロー図\n22\n4.3\n実験環境\n本節では実験で使用した環境について述べる．被験者全員が高いパフォーマンスを発揮\nできるように汎用性が高く，性能が良い環境を構築した．\nマウスはlogicool 社のPRO X SUPERLIGHT 2 を使用した[20]．このマウスは右利き，\n左利きどちらのプレイヤーでも使用できるように左右対称に設計され，軽量かつセンサー\nの性能も高い．このデバイスを使用しているValorant のプロも多数いるため，採用した．\nマウスパッドはARTISAN 社のNINJA FX ライデンXsoft を使用した[21]．使いやすい柔\nらかい素材かつマウス感度が低いプレイヤーでもマウスを広く振れるように大きめのXL\nサイズとした．それぞれの画像を図4-4，4-5 に示す．\n図4-4: PRO X SUPERLIGHT 2（[20] より引用）\n図4-5: NINJA FX ライデンXsoft（[21] より引\n用）\nモニターはHP 社のOMEN X 27 を使用した[22]．画像を図4-6 に示す．高さ調節が可\n能であり，反応速度とリフレッシュレートも高性能であるため，採用した．また，机は幅\n180cm，奥行き60cm，高さ70cm のものを使用した．\n23\n図4-6: OMEN X 27\n4.4\n分散分析\n計測したデータに対して分散分析を行う．分散分析は，複数のグループ間で平均値の差\nが統計的に有意かどうかを検証するための統計手法であり，1925 年にR.A. Fisher によっ\nて提唱され，彼の著書「Statistical Methods for Research Workers」で詳細に説明されてい\nる[23]．分散分析は，総変動を「グループ間の変動」と「グループ内の変動」に分解し，\nこれらの変動の比率を計算することで，グループ間の差が大きいかどうかを判断する．1\n元配置は，1 つの独立変数に対して従属変数の平均値の差を検証するために使用され，具\n体的には，帰無仮説と対立仮説の設定，分散の分解，F 値の計算，p 値の算出という手順\nを踏む．\n本研究では，被験者を初心者，中級者，初心者に分類し，それぞれの反応時間や破壊時\n間を比較場合に使用され，p 値が0.05 未満であれば，グループ間に有意な差があると結論\n付ける．\n4.5\n実験後アンケート\n本実験では被験者のスキル調査に加え，実験環境・システムに関するフィードバックを\n収集するために独自のアンケート調査を行った．質問項目は以下の通りで，5 段階評価で\n24\n回答してもらう．\n• ランダムターゲットの大きさは適切であったか\n• アセントのターゲットの出現は自然であったか\n• 赤と青のターゲットは見づらいと思ったか\n• 実験時間は適切であったか\n• ウォームアップの時間は適切であったか\n• アイトラッカーは邪魔であったか\n• 普段通りにプレイできたか\n• 環境に関する改善点（自由記述）\n質問項目を付録B に示す．\n25\n第5章\n実験結果および考察\n5.1\n実験結果\n5.1.1\nシナリオ1 の結果と考察\nシナリオ1 の計測結果を図5-1 に示す．計測したデータは固視が発生するまでの時間，\nターゲットの破壊時間，命中率の3 つである．\n表5-1: シナリオ1 の計測結果\nID\n固視が発生する時間（秒）\n破壊時間（秒）\n命中率（%）\n1\n0.166\n0.606\n70.26\n2\n0.149\n0.605\n89.67\n3\n0.165\n0.653\n84.44\n4\n0.232\n0.575\n78.7\n5\n0.140\n0.580\n93.01\n6\n0.262\n0.650\n79\n7\n0.219\n0.591\n85.26\n8\n0.181\n0.575\n80.1\n9\n0.149\n0.692\n83.52\n10\n0.151\n0.629\n90.4\n11\n測定ミス\n0.638\n82.42\n12\n0.187\n0.618\n88.82\n13\n0.260\n0.760\n85.71\n14\n0.271\n0.815\n81.51\n15\n0.291\n0.800\n86.11\n16\n0.657\n1.036\n73.23\n17\n0.287\n0.709\n86.75\n18\n0.321\n0.844\n92.8\n19\n0.382\n0.909\n95.41\n上記の計測結果について分析を行う．\nシナリオ1 の固視が発生するまでの時間についての分布図を図5-1 に，それぞれの熟\n練度別の平均時間の表を表5-2 示す．1 名アイトラッカーの測定ミスでデータが得られな\nかった．\n26\n図5-1: シナリオ1 における固視が発生するまでの時間の分布図\n表5-2: シナリオ1 における固視が発生するまでの熟練度ごとの平均時間\n熟練度\n平均時間（秒）\n上級者\n0.171\n中級者\n0.201\n初心者\n0.368\nこの結果に関して分散分析を行ったところ，p 値は0.00465 となり，グループ間に有意\nな差が認められた．また，それぞれのグループの平均時間を比較すると熟練度が上がるほ\nど時間が短くなっている傾向がみられた．しかし，上級者のID:4 の被験者は2 番目にス\nコアが高かったにも関わらず，中級者の平均よりもかなり遅い結果を残した．このことか\nら，かならずしも固視が発生するまでの時間の速さがFPS の熟練度に繋がるわけではな\nいと考えられる．\nまた，破壊時間においても同様に分布図を図5-2 に，それぞれの熟練度別の平均時間の\n表を表5-3 示す．\n27\n図5-2: シナリオ1 におけるターゲットを破壊するまでの時間の分布図\n表5-3: シナリオ1 におけるターゲットを破壊するまでの熟練度ごとの平均時間\n熟練度\n平均時間（秒）\n上級者\n0.604\n中級者\n0.644\n初心者\n0.841\nこの結果に関しても分散分析を行ったところ，p 値は0.0000648 となり，グループ間に\n有意な差が認められた．また，それぞれのグループの平均時間を比較すると熟練度が上が\nるほど時間が短くなっている傾向がみられた．\nシナリオ1 における命中率の分布図を図5-3 に，熟練度ごとの平均命中率を図5-4 に\n示す．\n28\n図5-3: シナリオ1 における命中率の分布図\n表5-4: シナリオ1 における熟練度ごとの平均命中率\n熟練度\n命中率（%）\n上級者\n83.22\n中級者\n84.40\n初心者\n85.97\nシナリオ1 では命中率の分布，平均ともにどの熟練度でも同じ特徴がみられた．p 値も\n0.802 を示し，グループ間に有意な差は見られなかった．\n5.1.2\nシナリオ2 の結果\nシナリオ2 の計測結果を表5-5 に示す．計測したデータはターゲットの破壊時間，命中\n率の2 つである．\n上記の計測結果について分析を行う．シナリオ2 のターゲットが破壊されるまでの時間\nについての分布図を図5-4 に，それぞれの熟練度別の平均時間の表を表5-6 に示す．\n29\n表5-5: シナリオ2 の計測結果\nID\n破壊時間（秒）\n命中率（%）\n1\n0.669\n60.87\n2\n0.843\n40.98\n3\n1.040\n51.22\n4\n0.734\n37.33\n5\n0.945\n53.16\n6\n0.700\n56\n7\n0.749\n71.19\n8\n0.843\n46.67\n9\n0.739\n54.19\n10\n0.689\n75.68\n11\n0.772\n77.78\n12\n0.735\n62.69\n13\n0.931\n68.85\n14\n0.851\n67.74\n15\n0.975\n71.79\n16\n1.193\n40.98\n17\n0.287\n65.12\n18\n0.969\n67.2\n19\n1.247\n75\n図5-4: シナリオ2 におけるターゲットを破壊するまでの時間の分布図\nこの結果に関して分散分析を行ったところ，p 値は0.00572 となり，グループ間に有意\nな差が認められた．しかし，シナリオ1 とは異なり，時間が最も短いグループは中級者と\n30\n表5-6: 固視が発生するまでの平均時間\n熟練度\n平均時間（秒）\n上級者\n0.846\n中級者\n0.770\n初心者\n1.028\nなった．このような結果となった要因は熟練度ごとにValorant プレイヤーとしての特徴が\n表れたためと考えられる．Valorant にはターゲットの頭を射撃するとダメージの倍率が上\nがり，素早く敵を倒すことができるという仕様が存在する．上級者グループに属するプレ\nイヤーは普段から頭を狙ってAIM を合わせる癖がついている．今回のシナリオではター\nゲットのどこに命中させても一撃で倒せる設定にしているので頭を狙うとそれだけ的が\n小さくなるので他の被験者と比べて不利になってしまっていた．ID：2，3，5 の3 人のプ\nレイヤーが頭を狙ってしまっていたため，平均時間が長くなってしまっていた．\nシナリオ1 における命中率の分布図を図5-5 に，熟練度ごとの平均命中率を図5-7 に\n示す．\n図5-5: シナリオ2 における命中率の分布図\n表5-7: シナリオ2 における熟練度ごとの平均命中率\n熟練度\n命中率（%）\n上級者\n48.71\n中級者\n64.13\n初心者\n64.64\n31\n命中率においても破壊時間と同様の特徴が表れている．上級者のみ命中率が下がってい\nる．これは破壊時間と同様に数名が小さい的を狙ってしまっていることが原因である．\n5.2\n録画データから読み取れた考察\nアイトラッカーの録画データを確認したところ，熟練度によって視線の動きの特徴に大\nきな差があった．上級者は出現したターゲットの中心を一度の視線の動きで捉えること\nができていた．そのため，多くの場合1 つのターゲットに対して発生する固視の回数は1\n回であった．逆に初心者は出現したターゲットの中心を一度の視線移動では捉えられてい\nなかった．1 回目の視線移動ではターゲットを飛び越してしまうか距離が足りず中途半端\nな位置で止まるなど，ぼんやりと視界に捉えていた．その後，2 回目，3 回目の視線移動\nでターゲットの中心に視線を向けていた．中級者はこの上級者と初心者の間の特徴を示し\nていた．1 回の視線移動でターゲットを捉えられることもあれば，出現したターゲットが\n遠い場合は2 回視線移動するなど1 つのターゲットに対する固視の回数は初心者と上級者\nの間の回数であった．\n5.3\nアンケート結果\n独自のアンケートをもとに，被験者に回答してもらった結果を示す．まず，シナリオに\n関する被験者の評価について整理する．ランダムターゲットの大きさは適切だったかとい\nう質問に対しての結果を図5-6 に示す．この質問では，13 名が「ちょうど良い」，4 名が\n「やや大きかった」，2 名が「やや小さかった」と回答した．ターゲットの大きさはそのま\nまシナリオの難易度に繋がる．大きさに大きな不満を持ったプレイヤーがいなかったた\nめ，幅広い熟練度のプレイヤーに適応した難易度設定をすることができた．\nアセントのターゲットの出現は自然だったかという質問に対しての結果を図5-7 に示す．\nこの質問では，3 名が「自然だった」，4 名が「やや自然だった」，4 名が「どちらでもな\nい」，2 名が「やや自然だった」と回答した．この質問はValorant におけるアセントを知っ\nているプレイヤー13 人にのみ設けた．自然と感じたプレイヤーが約半数のみだったため，\nターゲットの出現の仕方をもっと工夫する必要がある．\n赤と青のターゲットは見づらいと思ったかという質問に対しての結果を図5-8 に示す．\nこの質問では，13 名が「見やすい」，2 名が「やや見やすい」，3 名が「どちらでもない」，\n1 名が「やや見づらい」と回答した．画像認識，視線誘導という目的のためにターゲット\nの色を分けたが，被験者に悪影響はほとんど与えなかった．\n32\n図5-6:「ランダムターゲットの大きさは適切だっ\nたか」に対する回答結果\n図5-7:「アセントのターゲットの出現は自然だっ\nたか」に対する回答結果\n図5-8: 「赤と青のターゲットは見づらいと思っ\nたか」に対する回答結果\n図5-9: 「実験時間は適切だったか」に対する回\n答結果\n実験時間は適切だったかという質問に対しての結果を図5-9 に示す．この質問では，16\n名が「ちょうど良い」，1 名が「やや長かった」，2 名が「やや短かった」と回答した．本\n実験では，被験者の集中力を最大限に保つ実験時間の設定を行った．「ちょうど良い」と\nいう回答がほとんどだったため，この目的は達成できた．\nウォームアップの時間は適切だったかという質問に対しての結果を図5-10 に示す．こ\nの質問では，18 名が「ちょうど良い」，1 名が「やや長かった」と回答した．ウォームアッ\nプの時間も被験者の集中力と調子を保つための時間設定にしたため，この目標を達成でき\nたことがこの結果から確認できた．\nアイトラッカーは邪魔だったかという質問に対しての結果を図5-11 に示す．この質問\nでは，10 名が「気にならなかった」，5 名が「やや気にならなかった」，1 名が「どちらで\nもない」，2 名が「やや邪魔だった」，1 名が「邪魔だった」と回答した．数名が「邪魔だっ\nた」と答えたものの，ほとんどのプレイヤーは「気にならない」と答えたため，アイト\n33\nラッカーを使用した計測は有効であると考えられる．\n図5-10:「ウォームアップの時間は適切だったか」\nに対する回答結果\n図5-11: 「アイトラッカーは邪魔だったか」に対\nする回答結果\n図5-12: 「普段通りにプレイできたか」に対する回答結果\n普段通りにプレイできたかという質問に対しての結果を図5-9 に示す．この質問では，\n5 名が「普段通りにできた」，3 名が「やや普段通りにできた」，2 名が「どちらでもない」，\n1 名が「やや普段通りにできなかった」，2 名が「普段通りにできなかった」と回答した．\nこの質問は，普段からFPS をプレイしている13 名にのみ設けた．普段通りにプレイでき\nたプレイヤーが多かったものの，数名は環境の違いから実験のパフォーマンスが下がって\nしまっていた．以下に被験者から上がった環境に関する改善点を示す．\n• デスクの高さが異なった\n• アイトラッカーが眼鏡と被っていた\n• 普段座椅子でプレイしているため，机だとやりづらかった\n34\n第6章\n結論\n6.1\nまとめ\n本研究では，AIM スキルの上達方法を定量的な指標を用いてプレイヤーへフィードバッ\nクを行うことを最終的な目的として，視線が固定される速度と操作速度の数値データを獲\n得し，プレイヤーのレベル別に分析を行った．\n実験結果から，視線とマウスを用いたAIM の速度は熟練度が上がると速くなり，それぞ\nれの熟練度の間には有意差があることが確認された．このことから2 つの速度をFPS プ\nレイヤーのAIM スキルの評価指標として使用できることが分かった．\nまた，これら以外にも，命中率，視線の動かし方などにも熟練度によって特徴が見られ\nたため，速度以外の指標もAIM スキルの評価方法として利用することが期待できる．\n6.2\n今後の展望\n今後，本研究の目的達成のために姿勢や腕の動作，モニターとの距離など別の要素と組\nみ合わせてプレイヤーへフィードバックを行うところまでアップデートすることが必要\nである．今回の実験ではプレイヤーごとに機材の位置を調整してもらったが，モニターの\n距離と高さに最も個性が表れていたため，この要素のフィードバックを行うとプレイヤー\nのためになると考えられる．具体的な方法として，アイトラッカーのワールドカメラから\n画像処理で距離を測ることなどが考えられる．\nまた，実験環境の改善が求められる．アイトラッカーの視線情報は眼鏡を使用している\n被験者など人によっては安定しなかったため，アイカメラを増設し両目の情報を入手でき\nるようにする，邪魔にならない位置に場所を移動するなどの改善が必要である．普段座椅\n子でプレイしている被験者もいたため，よりパーソナライズされた環境を提供することも\n必要である．\nシナリオの見直しも必要である．今回の実験ではターゲットの動きの再現の限界が存在\nし，100%自然な表現はできなかった．今後の実験目標によって最適なシナリオは異なる\nが，被験者がより力を発揮しやすいシナリオを作成したい．\n35\n謝辞\n本研究を進めるうえで，親身に相談に乗って下さった青山学院大学理工学部情報テクノ\nロジー学科ロペズ・ギヨーム教授に深く感謝をいたします．また，研究環境の補助をして\nくださった大熊氏，論文の添削を通してアドバイスをくださった宮澤先輩をはじめとする\nロペズ研究室の院生の方々，同期の方々に深く感謝いたします．また，実験に協力してい\nただいた被験者の方々にも感謝いたします．\n2025 年1 月28 日\n清水遥希\n36\n参考文献\n[1] デロイトトーマツ：拡大を続けるゲーム市場の動向(2024). https://faportal.\ndeloitte.jp/times/articles/000937.html.\n[2] 株式会社角川アスキー総合研究所：ファミ通ゲーム白書2022 (2022).\n[3] KRAFTON: PUBG MOBILE JAPAN LEAGUE SEASON2 開催！(2022/2/28). https:\n//pubgmobile.jp/pmjl_season2/.\n[4] Esports,\nV.:\nMASTERS\nTOKYO:\nEVERYTHING\nYOU\nNEED\nTO\nKNOW\n(2023/5/31).\nhttps://valorantesports.com/ja-JP/news/\nmasters-tokyo-everything-you-need-to-know.\n[5] 株式会社角川アスキー総合研究所：日本e スポーツ白書2023，一般社団法人日本e\nスポーツ連合(2023).\n[6] FOUNDRY, Q.: 7 Things We Learned About Primary Gaming Motivations From Over\n250,000 Gamers (2016/12/15). https://quanticfoundry.com/2016/12/15/\nprimary-motivations/.\n[7] ゲーマーゲーマー‘sPOST：【保存版】e スポーツ用語『エイム（Aim）』とはどんな\n意味？｜早わかり(2024/2/15). https://gamer2.jp/post/aim/.\n[8] Koposov, D., Semenova, M., Somov, A., Lange, A., Stepanov, A. and Burnaev, E.: Anal-\nysis of the Reaction Time of eSports Players through the Gaze Tracking and Person-\nality Trait, 2020 IEEE 29th International Symposium on Industrial Electronics (ISIE),\nIEEE, pp. 1560–1565 (online), https://doi.org/10.1109/ISIE45063.2020.\n9152422 (2020).\n[9] 出山果歩：瞳孔径に精神疲労が及ぼす影響に関する研究(2020).\n[10] Smerdov, A., Burnaev, E. and Somov, A.: eSports Pro-Players Behavior During the Game\nEvents: Statistical Analysis of Data Obtained Using the Smart Chair, arXiv preprint\narXiv:1908.06402 (2019).\n37\n[11] Boch, R., Fischer, B. and Ramsperger, E.: Express-Saccades of the Monkey: Reaction\nTimes Versus Intensity, Size, Duration, and Eccentricity of Their Targets, Experimental\nBrain Research, Vol. 55, pp. 223–231 (1984).\n[12] 高明浅見，多久満大崎，繁石島：視野反応計を用いた中心視反応と周辺視反応の比\n較検討，筑波大学体育科学系紀要，Vol. 7, pp. 149–162 (1984).\n[13] 橋秀太朗，服部峻，高原まどか：テトリスのためのルールベースなゲーム画面認識\nによるデバッグAI の試作，日本デジタルゲーム学会2022 年夏季研究発表大会予稿\n集，日本デジタルゲーム学会，pp. 45–48 (2022).\n[14] : 【保存版】e スポーツ用語『フリックエイム』とはどんな意味？┃ゲーマーゲー\nマー’s POST，https://gamer2.jp/post/flick-aim/. (参照日2025/01/19).\n[15] : VALORANT, https://playvalorant.com/ja-jp/. (参照日2025/01/19).\n[16] Labs, P.: Pupil Core. https://pupil-labs.com/products/core.\n[17] 田中啓治(独立行政法人理化学研究所脳科学総合研究センター)：固視(2019/2/18).\nhttps://bsd.neuroinf.jp/wiki/\n[18] : Core - Pupil Capture - Pupil Labs Docs, https://docs.pupil-labs.com/\ncore/software/pupil-capture/. (参照日2025/01/19).\n[19] : Homepage - Aimlabs, https://aimlabs.com/. (参照日2025/1/19).\n[20] :\nPRO\nX\n2\nSuperlight\nWireless\nGaming\nMouse,\nhttps://\ngaming.logicool.co.jp/ja-jp/products/gaming-mice/\npro-x2-superlight-wireless-mouse.html. (参照日2025/1/19).\n[21] : ARTISAN FX RAIDEN, https://www.artisan-jp.com/fx-raiden.html.\n(参照日2025/1/19).\n[22] :\nOMEN\nX\n27\nDisplay,\nhttps://www.omen.com/gb/en/displays/\nomen-x-27.html. 参照日2025/1/19.\n[23] Fisher, R.: Statistical Methods for Research Workers, Biological monographs and manu-\nals, Oliver and Boyd (1925).\n38\n付録A\n　FPSに関する意識調査\n39\n1。\n1 つだけマークしてください。\nAIM、撃ち合いの強さ\n立ち回り、頭の良さ\nコミュニケーション、仲間との連携\n相手の行動を読む、勝負勘\n2。\n1 つだけマークしてください。\nある\nない\nこのコンテンツは Google が作成または承認したものではありません。\nAIMに関する意識調査\n* 必須の質問です\nFPSで強くなるために1番必要なスキルはなんだと思いますか*\n今まで「エイムスキルの停滞」や「エイムスキルを上げる方法で迷った」と\nいう経験はありますか？\n*\n フォーム\n2025/01/26 22:00\nAIMに関する意識調査\nhttps://docs.google.com/forms/d/1giHo9hSF-159otl-6uYiRCH8AfNExGtoqaF_3yDFqJs/edit\n1/1\n付録B\n　実験のフィードバックアンケート\n41\n1。\n1 つだけマークしてください。\n小さかった\n1\n2\n3\n4\n5\n大きかった\n2。\n1 つだけマークしてください。\n不自然だった\n1\n2\n3\n4\n5\n自然だった\n3。\n1 つだけマークしてください。\n見ずらい\n1\n2\n3\n4\n5\n見やすい\n4。\n1 つだけマークしてください。\n短かった\n1\n2\n3\n4\n5\n長かった\n実験後アンケート\n* 必須の質問です\nランダムターゲットの大きさは適切でしたか*\nアセントのターゲットの出現は自然でしたか*\n赤と青のターゲットは見ずらいと思いましたか*\n実験時間は適切でしたか*\n2025/01/26 21:32\n実験後アンケート\nhttps://docs.google.com/forms/d/1kQsM44UGxUA9YS1semtWqFxwc2pqKqp4bI5a_RDvzLk/edit\n1/3\n5。\n1 つだけマークしてください。\n短かった\n1\n2\n3\n4\n5\n長かった\n6。\n1 つだけマークしてください。\n邪魔だった\n1\n2\n3\n4\n5\n気にならなかった\n7。\n1 つだけマークしてください。\n普段通りにできなかった\n1\n2\n3\n4\n5\n普段通りにできた\n8。\nこのコンテンツは Google が作成または承認したものではありません。\nウォームアップの時間は適切でしたか*\nアイトラッカーは邪魔でしたか*\n普段通りにプレイできましたか*\n実験環境(モニターやマウスなど)は適切でしたか。改善点があれば記述してく\nださい。\n*\n フォーム\n2025/01/26 21:32\n実験後アンケート\nhttps://docs.google.com/forms/d/1kQsM44UGxUA9YS1semtWqFxwc2pqKqp4bI5a_RDvzLk/edit\n2/3\n",
        "chunks": [
            "B2024_HarukiShimizu. B2024_HarukiShimizu. B2024_HarukiShimizu",
            "青山学院大学理工学部\n情報テクノロジー学科\n２０２４年度卒業研究論文\n視線を用いたFPSゲームにおける\nスキル分析\n２０２５年１月２８日提出\n指導教員ロペズ・ギヨーム教授\n提出者学生番号　氏名\n１５８２１０３９清水遥希\n青山学院大学 理工学部 情報テクノロジー学科 \n2024（令和6）年度卒業論文要旨 \n- 1 - \n \n視線を用いたFPS ゲームにおけるスキル分析 \n \n清水 遥希（15821039） \nロペズ研究室 \n \n１． はじめに \n近年のオンラインゲーム市場調査によれば，市場全\n体の規模はスマートフォンやPC 向けタイトルの拡大\nにより急成長を遂げている[1]．その中で，FPS（First \nPerson Shooter）ゲームは，「競争」という要素を強調\nした部類として多くのプレイヤーに支持されている\n[2]．FPS ゲームでは，標的への照準を合わせる動作を\n指す「AIM」というスキルが特に重要視されており，\nこのスキルの向上が勝敗を左右する要因となるが，\nAIM スキルの上達には多くの課題が存在する． \n本研究では，視線固定速度と操作速度の2 つの指標\nを用いてAIM ",
            "上達には多くの課題が存在する． \n本研究では，視線固定速度と操作速度の2 つの指標\nを用いてAIM スキルを定量的に評価し，プレイヤー\nの熟練度に応じた新たなスキル評価の枠組みを提案す\nることを目的としている． \n２．関連研究 \n既存研究では，視線追跡装置や動作データを用いて\ne スポーツプレイヤーのスキルや反応時間を評価する\n試みが行われている．Koposov らは視線追跡装置を用\nいた反応速度の評価を，Smerdov らはスマートチェア\nによる行動データ分析を実施し，それぞれプロとアマ\nチュアのスキル差を示した[3][4]． \nしかし，これらの研究ではFPS ゲーム特有のスキル\nであるAIM の定量的評価が十分ではなく，プレイヤ\nーへの具体的なフィードバックが不足している．本研\n究では，視線固定速度と操作速度を指標とし，AIM ス\nキルの客観的評価とスキル向上を支援するデータの提\n供を目指す． \n３．FPS スキル分析手法 \n本研究では，FPS のスキルを分析するための新たな\nシステムを開発した（図１を参照）．Pupil Core[5]とい\nう眼鏡型視線追跡装置を用いて，以下の２つ",
            "ムを開発した（図１を参照）．Pupil Core[5]とい\nう眼鏡型視線追跡装置を用いて，以下の２つの指標か\nらスキルを評価する． \n① \n視線固定時間：ターゲットが出現してから，視\n線がターゲットに固定されるまでの時間． \n② \n破壊時間：ターゲットが出現してから，ターゲ\nットを破壊するまでの操作時間．ターゲット破\n壊の判定は画像認識を用いて行う． \n \n図1 システムの概要図 \n４． FPS 訓練環境によるスキル計測 \n実験ではAimLabs というAim トレーニングアプリ\nを使用し，本実験のためにシナリオを2 種類作成した\n[6]．実験には19 名（成人男性18 名，成人女性1 名）\nの被験者が参加し，FPS ゲームValorant でのランク\n分布に基づき，初心者，中級者，上級者の3 つのグル\nープに分類した[7]． \n被験者には5 分間のウォームアップ，視線追跡装置\nのキャリブレーションの後に，2 種類のシナリオをそ\nれぞれ2 回ずつプレイしてもらった．実験は1 日で，\nシナリオは1，2 の順番で行った． \n① \nシナリオ１：瞬時にAIM を合わせるフリック\nAIM という",
            "リオは1，2 の順番で行った． \n① \nシナリオ１：瞬時にAIM を合わせるフリック\nAIM というAIM スキルだけが求められるよ\nうに設計した． \n② \nシナリオ２：フリックAIM に加えてゲーム知\n識が与える影響を検証するためにValorant に\n登場するステージとターゲットを再現した． \n実験終了後，実験環境やターゲットの設定に関する\nフィードバックを得るためのアンケートを実施した． \n \n \n５．結果 \n図2，図3 はシステムを使用して計測を行ったシナ\nリオ1 における視線が固定されるまでの時間とターゲ\nットが破壊されるまでの時間の分布を表す箱ひげ図で\nある．これらの結果に分析を行ったところ，それぞれ\n上級者と初心者，中級者と初心者の間に有意な差が認\nめられた．また，どちらの時間も熟練度が上がるほど\n短くなる傾向が見られた．時間とは別に命中率は熟練\n度によってほとんど差がなく，有意差もなかった． \n表1，表2 はそれぞれのシナリオにおける熟練度別\nの平均結果である．シナリオ2 においてはターゲット\nの小さい頭部分を狙ってしまうという上級者の\nValorant プレイヤーの特",
            " においてはターゲット\nの小さい頭部分を狙ってしまうという上級者の\nValorant プレイヤーの特性が表れたため，中級者の方\nが上級者より時間が短く，上級者だけ命中率が低くな\nった． \nまた，録画データの解析により，視線移動の効率性\nが熟練度に応じて異なることが明らかになった． \n \n図2．シナリオ1 における視線が固定されるまでの時\n間の比較(**:p<0.01) \n \n図3．シナリオ1 におけるターゲットが破壊されるま\nでの時間の比較(**:p<0.01) \n表1:シナリオ1 における熟練度別の平均結果 \n \n表2:シナリオ2 における熟練度別の平均結果\n \n６．まとめ \n実験・分析結果から本研究で提案した2 つの指標は，\nAIM スキルの評価に有用であることが判明した．しか\nし，独自のアンケートより，シナリオと環境をFPS プ\nレイヤーにとって自然になるように再構築する必要が\n示唆された． \n今後の展望として，モニター距離や姿勢といった他\nの要素との関連性を検討することで，より効果的なフ\nィードバックを提供できる可能性がある． \n参考文献 \n[1] \nデロイトトーマツ：拡大を続",
            "果的なフ\nィードバックを提供できる可能性がある． \n参考文献 \n[1] \nデロイトトーマツ：拡大を続けるゲーム市場の動\n向(2024)． \nhttps://faportal.deloitte.jp/times/articles/00093\n7.html．(最終参照日:2024/7/3) \n[2] \nFOUNDRY, Q.:7 Things We Learned About \nPrimary Gaming Motivations From Over \n250,000 Gamers (2016/12/15). \nhttps://quanticfoundry.com/2016/12/15/ \nprimary-motivations/. (最終参照日:2025/1/13) \n[3] \nKoposov, D., Semenova, M., Somov, A., Lange, \nA., Stepanov, A. and Burnaev, E.: Anal- ysis of \nthe Reaction Time of eSports Players through \nthe Gaze Trackin",
            " Time of eSports Players through \nthe Gaze Tracking and Person- ality Trait, 2020 \nIEEE 29th International Symposium on \nIndustrial Electronics (ISIE), IEEE, pp. 1560-\n1565  \n[4] \nSmerdov, A., Burnaev, E. and Somov, A.: \neSports Pro-Players Behavior During the \nGame Events: Statistical Analysis of Data \nObtained Using the Smart Chair, arXiv \npreprint arXiv: 1908.06402 (2019). \n[5] \nCore - Pupil Capture -, Pupil Labs Docs, \nhttps://docs.pupil-labs.com/ \ncore/software/pupil-capture/ \n（最終参照\n日:2025/",
            ".com/ \ncore/software/pupil-capture/ \n（最終参照\n日:2025/01/19). \n[6] \nHomepage - Aimlabs,  \nhttps://aimlabs.com/. (最終参照日:2025/1/19). \n[7] \nVALORANT, \nhttps://playvalorant.com/ja-jp/. ( 最終参照日: \n2025/1/19). \n熟練度\n固視時間(秒) 破壊時間(秒) 命中率(%)\n上級者\n0.171\n0.604\n83.22\n中級者\n0.201\n0.644\n84.40\n初心者\n0.368\n0.852\n85.97\n熟練度\n破壊時間(秒)\n命中率(%)\n上級者\n0.846\n48.71\n中級者\n0.770\n64.13\n初心者\n1.028\n64.64\n目次\n第1 章\n序章\n1\n1.1\n研究背景. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n1\n1.1.1\ne-sports 業界の現状. . . . . . . . . . . .",
            " . .\n1\n1.1.1\ne-sports 業界の現状. . . . . . . . . . . . . . . . . . . . . . . . . . .\n1\n1.1.2\nFPS ゲームにおけるAIM スキル. . . . . . . . . . . . . . . . . . . .\n3\n1.2\n研究目的. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n5\n1.3\n本論文の構成. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n5\n第2 章\n関連研究\n6\n2.1\nアイトラッカーを使用した研究. . . . . . . . . . . . . . . . . . . . . . . .\n6\n2.2\nプレイヤーのスキル分類に関する研究\n. . . . . . . . . . . . . . . . . . . .\n7\n2.3\n視野と反応時間に関する研究\n. . . . . . . . . . . . .",
            " . .\n7\n2.3\n視野と反応時間に関する研究\n. . . . . . . . . . . . . . . . . . . . . . . . .\n8\n2.4\n画像認識を用いたゲームに関する研究\n. . . . . . . . . . . . . . . . . . . .\n8\n2.5\n先行研究のまとめ. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n8\n第3 章\n開発したシステムについて\n10\n3.1\nシステムの概要. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n10\n3.2\nアイトラッカーを使用した固視測定. . . . . . . . . . . . . . . . . . . . . .\n12\n3.2.1\n固視. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n12\n3.2.2\nPupil Core . . . . . . . .",
            " . . . . . . .\n12\n3.2.2\nPupil Core . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n12\n3.3\n画像認識を使用したターゲット破壊時間測定. . . . . . . . . . . . . . . . .\n15\n3.3.1\n作成したAIM トレーニングシナリオ. . . . . . . . . . . . . . . . .\n15\n3.3.2\n画像認識\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n18\n第4 章\n実験\n20\n4.1\n実験概要. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n20\n4.2\n実験手順. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n21\n4.3\n実験環境. . . . .",
            ". . . . . . . . . . . . . . .\n21\n4.3\n実験環境. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n23\n4.4\n分散分析. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n24\n4.5\n実験後アンケート. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n24\ni\n第5 章\n実験結果および考察\n26\n5.1\n実験結果. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n26\n5.1.1\nシナリオ1 の結果と考察. . . . . . . . . . . . . . . . . . . . . . . .\n26\n5.1.2\nシナリオ2 の結果. . . . . . . . . . . . . . .",
            " .\n26\n5.1.2\nシナリオ2 の結果. . . . . . . . . . . . . . . . . . . . . . . . . . . .\n29\n5.2\n録画データから読み取れた考察. . . . . . . . . . . . . . . . . . . . . . . .\n32\n5.3\nアンケート結果. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n32\n第6 章\n結論\n35\n6.1\nまとめ. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n35\n6.2\n今後の展望\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n35\n参考文献\n37\n付録A 　FPS に関する意識調査\n39\n付録B\n　実験のフィードバックアンケート\n41\nii\n第1章\n序章\n本章では，社会的な背景をもとに研究の位置付けを明確にする",
            "バックアンケート\n41\nii\n第1章\n序章\n本章では，社会的な背景をもとに研究の位置付けを明確にする．第1.1 節では本研究に\nおける背景，第1.2 節では研究目的と目標，第1.3 節では本論文の構成について述べる．\n1.1\n研究背景\n1.1.1\ne-sports 業界の現状\n近年，FPS（First Person Shooter）ゲームという一人称視点のシューティングゲームを含\nむオンライン対戦ゲームの市場規模は増加し続けている．以下に調査等を参照しながら現\n状を説明する．\nオンライン対戦ゲームを含むゲーム業界全体の市場規模が拡大し続けているが，その成\n長の要因としてマルチプラットフォーム化やe スポーツ業界の成長があげられる[1]．\n2012 年には家庭用ハードや買い切りのパッケージ版ソフトが市場の半分を占めていた\nが，10 年後にはオンラインプラットフォームの急成長により1/6 ほどになってしまってい\nることが図1-1 から分かる．また，オンラインプラットフォームの中でも，家庭用ゲーム\n機ソフトの占める割合は小さく，スマートフォンやPC 向けソフトの占める割合が大きい\nことが示唆",
            "ーム\n機ソフトの占める割合は小さく，スマートフォンやPC 向けソフトの占める割合が大きい\nことが示唆されている．その要因としてスマートフォンの台頭とともに増加していったダ\nウンロード無料のアプリケーションの課金システムの増加などが考えられる．未だ買い\n切りのe-sports 向けゲームも多数存在するが，ここ数年でリリースされたゲームはこの課\n金に重きをおいたゲームが増えてきているため，e-sports 向けゲームの市場規模・プレイ\nヤー数は今後も成長していくと考えられる．\n1\n図1-1: 国内のゲーム市場の推移（[2] より引用）\nまた，図1-2 に示したように国内のe スポーツ市場規模は成長しており，オンライン対\n戦ゲームの中でも「競争」という部分にフォーカスしたゲームの人気が高まっている．こ\nの影響はFPS にも表れている．2022 年にはPUBG MOBILE JAPAN LEAGUE SEASON2\nという日本のFPS ゲームの大会では史上最高額となる賞金総額3 億円の大会が開催され\nた[3]．2023 年にはVALORANT CHAMPIONS TOUR MASTERS TO",
            "され\nた[3]．2023 年にはVALORANT CHAMPIONS TOUR MASTERS TOKYO というVCT 史\n上初の世界大会も開催された[4]．また，e-sports と聞くとプロゲーマーをイメージしがち\nだが，市場の拡大の要因にはインフルエンサーの大会やアマチュアプレイヤーのコミュニ\nティの拡大など身近な要素も含まれている．\n2\n図1-2: 日本のe スポーツ市場規模2023 年以降は予測（[5] より引用）\n1.1.2\nFPS ゲームにおけるAIM スキル\n世界中の25 万人以上のゲーマーを対象として，ゲームに対するモチベーションに関し\nた調査がある．図1-3 のグラフを見ると，若いゲーマーにとってCompetition（競争）が\n最も重要なモチベーションであることがわかる．この調査結果として，自分自身のスキル\nを磨きライバルと切磋琢磨していくプレイスタイルが好まれているということが分かっ\nた[6]．\nFPS ゲームではよく「AIM」という単語が使われる．FPS ゲームにおけるAIM とは標\n的を認識し，マウス操作を行い標的を撃ち抜く一連の動作であり，このAIM の",
            "ムにおけるAIM とは標\n的を認識し，マウス操作を行い標的を撃ち抜く一連の動作であり，このAIM の能力が対\n戦相手よりも速く，正確であれば有利に戦うことができる[7]．そのため，勝つためには\n相手より速く敵を見つけ，反応し，照準を合わせることが求められる．プロの試合では反\n応速度，操作精度が極まったAIM がいくつも飛び出す．また，FPS ゲームでは戦術やコ\nミュニケーションなど他の要素を無視し，AIM の強さのみで1 対多数の状況をひっくり返\nしてしまった状況では「破壊」という表現がよく用いられる．この表現は普段のゲームプ\nレイをはじめ，大会の実況解説などでも使われており，FPS プレイヤーにとって馴染みの\nあるワードである．図1-3 のグラフでは2 番目にDestruction（破壊）の項目が高く，FPS\nゲームは若いゲーマーのニーズに当てはまったゲームといえる．\n3\n図1-3: 13 歳から25 歳のゲーマーの主なモチベーション（[6] より引用）\n本研究を開始するにあたって、13 人のFPS プレイヤーにAIM に関する意識調査を行っ\nた．使用したアンケートフォームを付録A ",
            "3 人のFPS プレイヤーにAIM に関する意識調査を行っ\nた．使用したアンケートフォームを付録A に示す．1 つは「FPS ゲームで強くなるために\n一番必要なスキル」についてのアンケートだ．それぞれ多様な考え方が存在したが，半数\n以上のプレイヤーがAIM スキルが一番必要だと回答した．2 つ目は「AIM スキルの停滞\n経験」についてだ．多くのプレイヤーがAIM スキルが重要と答えたにも関わらず，ほと\nんどのプレイヤーが停滞したことがあると回答した．経験があると答えたプレイヤーの中\nにはAIM スキルを上げるための方法に迷ったと答えたプレイヤーも数名存在した．AIM\nスキルは重要度に対して上達するためのハードルが高いというのが現状である．\n図1-4: 強くなるために必要なスキル\n図1-5: AIM スキルの停滞経験\n4\n1.2\n研究目的\n拡大を続けるオンラインゲームの中でも若者のニーズを満たし，人気を獲得している\nFPS ゲームは今後も多くのプレイヤーに親しまれていくだろう．しかし，FPS というジャ\nンルの中で重要であるAIM スキルは向上させることが難しい．一部のプロプレイヤーに\n",
            "S というジャ\nンルの中で重要であるAIM スキルは向上させることが難しい．一部のプロプレイヤーに\nなれば専門のコーチがつくこともあるが，それ以外のプレイヤーは個人の感覚に頼り，手\n探りで上達する方法を見つけなくてはならない．本研究では，AIM スキルの上達方法を\n定量的な指標を用いてプレイヤーへフィードバックを行うことを最終的な目的としてい\nる．この目的を達成するためにはプレイヤーのスキルの良し悪しを評価する方法を確立\nする必要がある．そのため今回の研究では，AIM における視線が固定される速度と操作\n速度の数値データを獲得し，プレイヤーのレベル別に分析することでAIM スキルの新た\nな評価指標として確立することを目標としている．姿勢や腕の動作，モニターとの距離，\nデバイスの種類などAIM には様々な要素が存在する．AIM スキルを向上させるにはこれ\nらの要素をそれぞれ改善していく必要があるが，姿勢やデバイスを変えてもその良し悪し\nが判断できなければ意味がない．本研究で収集する二つの速度が分かれば，AIM を合わ\nせるまでの合計時間が求められるため，今後姿勢やデバイスの改善の評価に用",
            "度が分かれば，AIM を合わ\nせるまでの合計時間が求められるため，今後姿勢やデバイスの改善の評価に用いることが\n期待できる．\n1.3\n本論文の構成\n第1 章では，本論文の研究背景，研究目的，及び本論文の構成について述べた．第2 章\nでは，関連研究について説明する．第3 章ではシステムの概要について述べる．第4 章で\nは，第3 章で述べた提案システムの評価実験について述べる．第5 章では，第6 章で実施\nした評価実験の結果とその考察について述べる．最後に第??章では，本論文のまとめと今\n後の展望について述べる．\n5\n第2章\n関連研究\n2.1\nアイトラッカーを使用した研究\nKoposov らは，プロおよびアマチュアのe スポーツプレイヤーの反応時間をアイトラッ\nカーを用いて評価し，反応時間と性格特性との関連性を調査した[8]．具体的には，反応\n時間をサッカード潜時，サッカードと固視の間の時間，照準と射撃の時間の3 つに分けて\n分析した．35 名の参加者（7 名のプロプレイヤーと28 名の初心者およびアマチュア）を\n対象に実施された．結果として，プロプレイヤーは全ターゲットタイプにおいて反応",
            "者およびアマチュア）を\n対象に実施された．結果として，プロプレイヤーは全ターゲットタイプにおいて反応が速\nく，特に赤いターゲットに対する反応が速いことが示された．対照的に，アマチュアプレ\nイヤーは中央のターゲットに対して速く反応した．この研究は，e スポーツにおける反応\n時間と性格特性との関連性について初めての包括的な分析を提供し，e スポーツのトレー\nニング方法やパフォーマンス分析の改善に寄与することが期待される．この研究で使用さ\nれたテストシナリオのスクリーンショットを図2-1 に示す．\n図2-1: テストシナリオのスクリーンショット（[8] より引用）\n6\n出山らは，瞳孔径を用いた精神疲労の評価方法を検討した[9]．この研究では，視線計測\n装置を使用して瞳孔径をリアルタイムで測定し，作業負荷と精神疲労の相関を分析した．\n結果として，精神疲労が進行するにつれて瞳孔径の平均値，最小値，積分値が減少し，疲\n労感VAS スコアと有意な相関を持つことが示された．この研究は，視覚的生体情報を利\n用して精神疲労を検出し，適切な休憩タイミングを提示する新たなシステム設計の可能性\nを示している．こ",
            "\n用して精神疲労を検出し，適切な休憩タイミングを提示する新たなシステム設計の可能性\nを示している．この研究の概要図を図2-2 に示す．\n図2-2: システムの概要図（[9] より引用）\n2.2\nプレイヤーのスキル分類に関する研究\nSmerdov らは，e-Sports プロ選手のゲーム中の行動をスマートチェアで収集したデータを\n用いて分析し，プレイヤーのスキルを評価する新しい方法を提案した[10]．実験はCS:GO\nのリテイクシナリオで実施され，プロ選手とアマチュア選手のデータが収集された．こ\nれらのデータをもとに，機械学習モデルを訓練し，最も精度の高いモデルは77%の精度\nと0.88 のROC AUC スコアを達成した．分析により，プロ選手とアマチュア選手の動作\nパターンの違いが特定され，特に重要な特徴量として殺傷や死亡後の動作，チェアの背も\nたれに寄りかかる時間の割合，加速度計とジャイロスコープの標準偏差が明らかになっ\nた．この研究は，eSports 選手の物理的な行動データを利用してパフォーマンスを評価す\nる新しい視点を提供し，ゲーム中の行動からスキルを客観的に評価するための基盤",
            "てパフォーマンスを評価す\nる新しい視点を提供し，ゲーム中の行動からスキルを客観的に評価するための基盤を構築\nした．\n7\n2.3\n視野と反応時間に関する研究\nboch らは，サルのエクスプレスサッケード（非常に短い反応時間の眼球運動）に関す\nる研究を行った[11]．彼らは，サルが小さな光点を注視し，その光点が消えた後に周辺の\nターゲットにサッケードするよう訓練した．光点のオフセットがターゲットのオンセッ\nトよりも140ms 以上早い場合，サルは70-80ms 以内に視線を変えることができた．エク\nスプレスサッケードの反応時間は，ターゲットの輝度やサイズに依存し，閾値近くのター\nゲットでは約120ms から，閾値を2.5 ログ単位上回る範囲で約50ms 短縮される．最小反\n応時間とそのターゲットサイズは，ターゲットの網膜偏心度の関数である．これらの結果\nは，エクスプレスサッケードの短い反応時間が主に網膜要因によって決定されることを示\n唆している．\n浅見らは，視野反応計を用いて中心視反応と周辺視反応の比較検討を行った[12]．彼ら\nは，視野反応計を用いて，中心視と周辺視の反応時間を測定し，そ",
            "視反応の比較検討を行った[12]．彼ら\nは，視野反応計を用いて，中心視と周辺視の反応時間を測定し，その違いを分析した．実\n験では，被験者が中心視と周辺視の両方で光刺激に反応する時間を測定し，反応時間の違\nいを比較した．その結果，中心視反応は周辺視反応よりも速いことが示された．また，反\n応時間の違いは視標の角度や距離によっても影響を受けることが明らかになった．この研\n究は，視覚反応のメカニズムを理解する上で重要な知見を提供している．\n2.4\n画像認識を用いたゲームに関する研究\n高橋らは，テトリスを題材にしたルールベースのデバッグAI を試作し，プレイ動画か\nらバグを自動検出する手法を提案した[13]．この研究では，テンプレートマッチングによ\nる画像認識を用い，「ラインが揃ったのに消えない」バグをルールベースで判別するアル\nゴリズムを開発した．評価実験では，ブロック1 個ずつのテンプレート画像を用いる手法\nが，直感的なブロック全体のテンプレート画像を用いる手法よりも高精度であることが確\n認された．一方で，静止画単位での分析に起因する誤検知の問題や未知のバグへの対応が\n課題として挙げられた．",
            "れた．一方で，静止画単位での分析に起因する誤検知の問題や未知のバグへの対応が\n課題として挙げられた．この研究は，デバッグAI の可能性を示すとともに，汎用的なシ\nステムの構築に向けた一歩を提供している．\n2.5\n先行研究のまとめ\n既存研究では，アイトラッカーや画像認識を用いてe スポーツプレイヤーのスキルや反\n応時間を評価する試みが行われている．例えば，Koposov らの研究では，プロとアマチュ\nアのプレイヤーを対象にアイトラッカーを用いて反応時間と性格特性の関連を調査し，プ\nロ選手の反応速度が優れていることを示した．また，Smerdov らはスマートチェアを用い\n8\nた動作データの収集により，プレイヤーの行動パターンを機械学習で分析し，プロとアマ\nチュアのスキル差を明確にした．\n一方で，これらの研究にはいくつかの課題がある．第一に，アイトラッカーや動作デー\nタに依存しているため，FPS ゲーム特有のスキルであるAIM に関する定量的な評価が十\n分に行われていない点である．第二に，プレイヤー個々の熟練度に応じた具体的なフィー\nドバックが不足しており，得られたデータをプレイヤーのスキル",
            "イヤー個々の熟練度に応じた具体的なフィー\nドバックが不足しており，得られたデータをプレイヤーのスキル向上に活用するための枠\n組みが不完全である．\n本研究ではこれらの課題を克服するため，視線固定速度と操作速度という2 つの新たな\n指標を用いてAIM スキルを評価する手法を提案する．この手法により，FPS ゲームにお\nける熟練度の客観的な評価が可能となり，さらにはプレイヤーのスキル向上を支援するた\nめの具体的なデータを提供できることを目指す．\n9\n第3章\n開発したシステムについて\n本研究で使用するシステムは，アイトラッカーと画像認識を使用することでターゲット\nに対して固視が発生するまでの時間と破壊するまでの時間を測定し，被験者のエイムスキ\nルを定量的に分析する．\n本章では，3.1 節で，システムの概要について説明をし，3.2 節で，アイトラッカーを使\n用した固視の測定について述べる．3.3 節では，画像認識を使用した破壊時間の測定方法\nを述べる．\n3.1\nシステムの概要\n本研究はFPS プレイヤーのAIM スキルを「視線のAIM」と「マウスのAIM」の二つに\n分け，この2 種類の能力がプレ",
            "イヤーのAIM スキルを「視線のAIM」と「マウスのAIM」の二つに\n分け，この2 種類の能力がプレイヤーの実力にどのように関係しているか分析することを\n目的としている．初心者から上級者までのプレイヤーの二種類の数値データを収集し，集\nめたデータを分析，比較することでFPS プレイヤーにとって重要なスキルを数値的に求\nめることが可能である．システムの全体像を図3-1 に示す．\n図3-1: システムの全体像\n10\nプレイヤーにはAimlabs というアプリをプレイしてもらう．このアプリは，自由度の高\nいステージやシナリオ作成が可能である．そのため，今回の研究目標に合わせたシナリ\nオを二つ作成した．今回はフリックAIM というある一点に向かって瞬間的に照準を合わ\nせるAIM スキルに焦点を当て，分析を行った[14]．求められるAIM スキルは同じだが，\n2 つのシナリオはそれぞれ期待されるデータの特徴が異なる．作成したシナリオの内容に\nついては第3.3.1 節で説明する．\n実験に参加したFPS プレイヤーは全員Valorant という5 対5 のタクティカルFPS ゲー\nムをプレイしていた",
            "S プレイヤーは全員Valorant という5 対5 のタクティカルFPS ゲー\nムをプレイしていたため，ゲーム知識はValorant のものを使用する[15]．Valorant ではそ\nれぞれのチームが攻撃・防御側に別れ，ステージ中の「サイト」という決められた範囲に\n向かってそれぞれ攻撃・守備を行う．今回のシナリオでは「アセント」というValorant が\nリリースされた当初から存在する一番基本的で有名なステージを再現し，攻撃側の視点で\nアセントのA サイトを攻めるという設定で行った．\nアセントＡサイトの画像を図3-2 に示す．ゲームのよくある流れとして，守備側はサイ\nトを守るために攻め側が侵入する際に遮蔽物から飛び出して迎撃するというものがある．\n遮蔽物の位置は変わらないため，Valorant をプレイしていると守備チームが飛び出してく\nる位置を予測または，記憶することができるようになる．その知識の差による認知速度の\n差を計測することでゲーム知識の有無による影響を調べることができる．\n図3-2: アセントA サイトの様子\n認知速度においてはアイトラッカーを使用することでターゲットが",
            "\n図3-2: アセントA サイトの様子\n認知速度においてはアイトラッカーを使用することでターゲットが出現してからプレイ\nヤーの視線が固定されるまでの時間を測定した．また，マウスを自在に扱う能力におい\nてはターゲットが出現してから破壊されるまでの時間を画像認識を使用することで測定\nした．\n11\n3.2\nアイトラッカーを使用した固視測定\nプレイヤーの認知能力はアイトラッカーを使用してターゲットが出現してから，固視と\nいう視線の固定が起こるまでの時間を測定することで評価する．本研究で使用するアイト\nラッカーはPupil Labs 社のPupil Core [16] である．\n3.2.1\n固視\n固視（ﬁxation）とは，眼球運動系や視覚系でよく用いられる述語であり，視線を特定の\n目標に固定することを指す言葉である[17]．本研究では視線のAIM の指標として用いる．\n固視が発生しているときは視線の動きや瞳孔の位置も大きく動くことはないが，マイクロ\nサッケードという小さな像の動きが起こる．瞳孔の安定やマイクロサッケードを検出する\nことで固視の判定ができる．\n??\n3.2.2\nPupil Cor",
            "安定やマイクロサッケードを検出する\nことで固視の判定ができる．\n??\n3.2.2\nPupil Core\nPupil 社のPupil Core を図3-3 に示す．グラス型のデバイスであり，右目上部に外の景色\nを写すワールドカメラ，右目下部に右目を写すアイカメラが装着されており，それぞれ目\nの前の視界と右眼球を写す．それぞれのカメラはジョイントやレールで位置や角度を調整\nすることが可能であり，ワールドカメラはモニターが中心に写る角度に，アイカメラは眼\n球が収まるように調節した．テンプルの先からコードが伸びており，USB Type-C でパソ\nコンと接続して使用する．デバイスの使用方法等は過去の同研究室の卒業論文を参考とし\nた[9]．\n12\n図3-3: Pupil Core\nまた，同社から配信されているPupil Capture，Pupil Player というアプリケーションソフ\nトを録画，実験結果の確認のために使用した[18]．アプリケーションのスクリーンショッ\nト画像を図3-4，図3-5 に示す．Pupil Capture の画面には外カメラの画像が映し出される．\nアイカメラウィンド",
            "5 に示す．Pupil Capture の画面には外カメラの画像が映し出される．\nアイカメラウィンドウでは眼球が認識されているかを確認する．アイカメラでは瞳孔と眼\n球が認識される．赤い点と円で瞳孔が表示され，青い円で瞼に隠れている部分まで補正し\nて眼球の輪郭が表示される．また，アイカメラで瞳孔の向きが認識されることでワールド\nカメラの画面にアイトラッカーの利用者が見ている場所が表示される．見ている部分は赤\nくなり，その周りに黄色の円が出れば視線が固定されていることを示している．\n13\n図3-4: Pupil Capture のスクリーンショット\n図3-5: アイカメラウィンドウのスクリーンショット\n本研究では主に画面左のC とR ボタンを使用する．C は「Calibration（キャリブレーショ\nン）」，R は「Recording（録画）」を表している．キャリブレーションではワールドカメラ\nとアイカメラの相関を行う．キャリブレーションを実行すると画面に5 つの的が表示され\nる．キャリブレーション中の画面を図3-6 に示す．5 つの的は順番に出現する．中心から\n始まり4 隅を巡り視線を誘",
            "ーション中の画面を図3-6 に示す．5 つの的は順番に出現する．中心から\n始まり4 隅を巡り視線を誘導する．視線に動きを出すことでデータを収集し，視線の予測\n14\nを安定させる．録画は実行するとデータの収集を開始する．録画データをはじめ，視線の\n座標やタイムスタンプなど様々なデータを収集することができる．\n図3-6: キャリブレーション画面\n3.3\n画像認識を使用したターゲット破壊時間測定\n3.3.1\n作成したAIM トレーニングシナリオ\nAIM トレーニングアプリとしてAimlabs を使用した[19]．Aimlabs は，FPS などの競技\nゲームジャンルでプレイヤーがスキルを向上させるために開発されたエイムトレーニン\nグプラットフォームである．特定のゲームに合わせたトレーニングシナリオや最適なマウ\nス感度を見つける機能などAIM に関係する様々なサポートをしている．\nAimlabs の大きな特徴としていくつかのゲームに存在するステージのテンプレートデー\nタが用意されていることがあげられる．今回の研究で扱ったValorant のアセントもテンプ\nレートとして用意されているため，Ai",
            "られる．今回の研究で扱ったValorant のアセントもテンプ\nレートとして用意されているため，Aimlabs を実験用のアプリケーションとして採用した．\nトレーニングの実行後，スコアや命中精度などのフィードバックは表示されるが，ター\nゲットを破壊した詳細なタイムラインを含む本研究に必要なデータは提供されていない．\nAPI 等も利用できないため，不足しているデータは補足する必要があった．\nここで，作成した2 つのシナリオについて説明する．まず，1 つ目のシナリオについてエ\nディターやプレイ画面の画像を交えて解説する．1 つ目のシナリオのエディター画面を図\n3-7 に示す．1 つ目のシナリオはスパイダーショットと呼ばれる，中央の固定されたター\nゲットとその周りのランダムな場所に出現するターゲットを交互に射撃するものである．\n15\n中心が決まっており，その周囲に蜘蛛の巣上にターゲットが出現する様子からスパイダー\nショットと呼ばれている．図3-7 における白い壁のような部分でランダムなターゲットが\n出現する．また，この壁の中心の青い球が固定されたターゲットの出現位置である．\n図3-7: 1 ",
            "トが\n出現する．また，この壁の中心の青い球が固定されたターゲットの出現位置である．\n図3-7: 1 つ目のシナリオのエディター画面\nこのシナリオの実行画面を図3-8，図3-9 に示す．ターゲットの形は球状に，中心のター\nゲットは青色，周囲のランダムに出現するターゲットは赤色に設定した．中心の固定され\nたターゲットは視線，カーソルの誘導の役割を果たしている．赤色のターゲットを破壊す\nる度に一度中心にリセットし，また次のランダムに出現するターゲットに反応しやすい仕\n組みとなっている．\n図3-8: 青色のターゲット\n図3-9: 赤色のターゲット\n次に，2 つ目のシナリオであるアセントを再現したシナリオについて説明する．Aimlabs\nで作成したアセントとValorant の実際のアセントの比較を図3-10，図3-11 に示す．元々\nのテンプレートもシンプルな色味をしていたが，画像認識での誤認識を防ぐために色味の\n16\nある物体の配置を抑え，光度を高く設定した．\n図3-10: Aimlabs で作成したアセントシナリオ\n図3-11: 実際のアセント\n基本的なシステムは1 つ目のシナリオと同じだ",
            "作成したアセントシナリオ\n図3-11: 実際のアセント\n基本的なシステムは1 つ目のシナリオと同じだが，赤いターゲットの出現位置をランダ\nムではなく遮蔽物の裏に設定した．出現場所は7 か所設置し，防御チームが潜む頻度が高\nい頻度の場所を選んだ．出現の順番もあらかじめ設定済であり，なるべく視点が振れるよ\nうな順番とした．また，Valorant をプレイしているプレイヤーは球状のものより人型の方\nが反応しやすいと考え，出現する赤色のターゲットを球状から人型に変更した．実際の\nゲームのプレイヤーの動きに似せるために，出現したターゲットはプレイヤーから見て\n90 度の角度で左右横向きに動き続ける．アセントシナリオにおけるターゲットの出現位\n置を図3-12 に示す．\n図3-12: ターゲットの出現位置（エディター画面より）\n17\n3.3.2\n画像認識\nマウスのAIM 速度を取得するためにPython を使用してAimlabs 画面の画像認識を行っ\nた．作成したコードでは赤と青どちらとものターゲットの認識を行い，画面上にターゲッ\nトが出現している間は常にタイムスタンプを残し続け，csv 形式のファ",
            "の認識を行い，画面上にターゲッ\nトが出現している間は常にタイムスタンプを残し続け，csv 形式のファイルとして保存さ\nれる．ここでのタイムスタンプはアイトラッカーからのデータとの同期を考え，UNIX 時\n間を採用した．フリックAIM の速度を比較するためには赤色のターゲットが出現してか\nら破壊されるまでの時間を計算する必要がある．シナリオは1 つのターゲットが破壊され\nた瞬間に次のターゲットが出現するように設定した．つまり，赤いターゲットが破壊され\nるタイムスタンプと青いターゲットが出現するタイムスタンプは同じであるため，次に出\n現する青いターゲットの出現時間から赤いターゲットの出現時間を引くことで破壊する\nまでにかかった時間を求めることができる．\nまた，認識を行っている際の録画データも保存される．この録画ではターゲットが認識\nされている間はマスクで囲われるため，誤認識がないかを確認することができる．画像認\n識の実行結果を2 つのシナリオにつき2 枚ずつ図3-13～図3-16 に示す．\n図3-13: シナリオ1 の画像認識実行結果1\n図3-14: シナリオ1 の画像認識実行結果2\n18",
            "図3-13: シナリオ1 の画像認識実行結果1\n図3-14: シナリオ1 の画像認識実行結果2\n18\n図3-15: シナリオ2 の画像認識実行結果1\n図3-16: シナリオ2 の画像認識実行結果2\n19\n第4章\n実験\n本章では評価実験について述べる．\n4.1\n実験概要\n被験者は成人男性18 名，成人女性1 名の計19 名（年齢層は19 歳から23 歳）に協力し\nてもらった．実験時間は5 分間のアップを含めて約15 分であった．実験終了後はFPS に\n対する経験や実験環境に関するフィードバックを収集するためにアンケートを記入して\nもらった．実験中の様子を図4-1 に示す．\n図4-1: 実験の様子\nまた，本実験に参加する被験者のランクの分布と熟練度の分類を以下の表4-1 に，図4-2\nにValorant におけるランクの種類と順番を示す．\n20\n表4-1: 被験者のランクの分布と熟練度の分類\nID\nランク\n熟練度\n1\nアセンダント2\n上級者\n2\nアセンダント1\n上級者\n3\nアセンダント1\n上級者\n4\nダイヤ1\n上級者\n5\nダイヤ1\n上級者\n6\nプラチナ2\n中級者\n7\nプラチナ1\n中級者\n8",
            "級者\n4\nダイヤ1\n上級者\n5\nダイヤ1\n上級者\n6\nプラチナ2\n中級者\n7\nプラチナ1\n中級者\n8\nプラチナ1\n中級者\n9\nゴールド2\n中級者\n10\nゴールド1\n中級者\n11\nゴールド1\n中級者\n12\nシルバー1\n中級者\n13\nシルバー1\n中級者\n14\nランクなし\n初心者\n15\nランクなし\n初心者\n16\nランクなし\n初心者\n17\nランクなし\n初心者\n18\nランクなし\n初心者\n19\nランクなし\n初心者\n図4-2: ランクの種類と順番（[15] より引用）\n4.2\n実験手順\n本実験では，被験者の最大限のAIM スキルのデータを収集するための手順を踏んだ．\nまず，マウスの操作や画面に素早く反応できるようにマウスパッドやキーボード，モニ\nター，椅子の位置や高さなどを自分好みに調整してもらった．また，普段からFPS ゲー\n21\nムをプレイしているプレイヤーは自分の設定どおりにマウスのDPI（Dots Per Inc）とゲー\nム内感度を調節してもらった．次に，アイトラッカーを装着してもらい，カメラの位置調\n整を行いキャリブレーションを実行した．この時Pupil Capture 上で視線を追えてい",
            "の位置調\n整を行いキャリブレーションを実行した．この時Pupil Capture 上で視線を追えているこ\nとを必ず確認した．その後，マウスの操作感やAimlabs に慣れるために3.3.1 節で説明し\nたシナリオ1 を使用して5 分間のウォームアップを行ってもらった．5 分間でシナリオ1\nが3 回か4 回プレイできるのだが，ほとんどのプレイヤーがこの回数をプレイするとスコ\nアが安定したため，5 分間と定めた．\nここまでを準備とし，次の手順からは計測に移る．作成した2 つのシナリオをそれぞれ\n2 回ずつプレイしてもらった．シナリオ1 は45 秒間経過，シナリオ2 は設置したターゲッ\nト42 個すべてを破壊する（約30 秒）ことで終了する．シナリオに取り組んでいる最中は\n休む暇なくAIM に集中することとなる．Valorant では相手と撃ち合う時間がそれほど長\nくないため，実験時間を長くしてしまうと被験者の集中力を阻害してしまうと考え，45 秒\nに設定した．また，シナリオ2 に関しては出現する順番を覚えることができないように計\n測前に説明のみ行い，練習はなしとした．実験の手順を示すフロー",
            "する順番を覚えることができないように計\n測前に説明のみ行い，練習はなしとした．実験の手順を示すフロー図を図4-3 に示す．\n図4-3: 実験の手順を示すフロー図\n22\n4.3\n実験環境\n本節では実験で使用した環境について述べる．被験者全員が高いパフォーマンスを発揮\nできるように汎用性が高く，性能が良い環境を構築した．\nマウスはlogicool 社のPRO X SUPERLIGHT 2 を使用した[20]．このマウスは右利き，\n左利きどちらのプレイヤーでも使用できるように左右対称に設計され，軽量かつセンサー\nの性能も高い．このデバイスを使用しているValorant のプロも多数いるため，採用した．\nマウスパッドはARTISAN 社のNINJA FX ライデンXsoft を使用した[21]．使いやすい柔\nらかい素材かつマウス感度が低いプレイヤーでもマウスを広く振れるように大きめのXL\nサイズとした．それぞれの画像を図4-4，4-5 に示す．\n図4-4: PRO X SUPERLIGHT 2（[20] より引用）\n図4-5: NINJA FX ライデンXsoft（[21] より引\n用）\nモニ",
            "[20] より引用）\n図4-5: NINJA FX ライデンXsoft（[21] より引\n用）\nモニターはHP 社のOMEN X 27 を使用した[22]．画像を図4-6 に示す．高さ調節が可\n能であり，反応速度とリフレッシュレートも高性能であるため，採用した．また，机は幅\n180cm，奥行き60cm，高さ70cm のものを使用した．\n23\n図4-6: OMEN X 27\n4.4\n分散分析\n計測したデータに対して分散分析を行う．分散分析は，複数のグループ間で平均値の差\nが統計的に有意かどうかを検証するための統計手法であり，1925 年にR.A. Fisher によっ\nて提唱され，彼の著書「Statistical Methods for Research Workers」で詳細に説明されてい\nる[23]．分散分析は，総変動を「グループ間の変動」と「グループ内の変動」に分解し，\nこれらの変動の比率を計算することで，グループ間の差が大きいかどうかを判断する．1\n元配置は，1 つの独立変数に対して従属変数の平均値の差を検証するために使用され，具\n体的には，帰無仮説と対立仮説の設定，分散の分解，",
            "て従属変数の平均値の差を検証するために使用され，具\n体的には，帰無仮説と対立仮説の設定，分散の分解，F 値の計算，p 値の算出という手順\nを踏む．\n本研究では，被験者を初心者，中級者，初心者に分類し，それぞれの反応時間や破壊時\n間を比較場合に使用され，p 値が0.05 未満であれば，グループ間に有意な差があると結論\n付ける．\n4.5\n実験後アンケート\n本実験では被験者のスキル調査に加え，実験環境・システムに関するフィードバックを\n収集するために独自のアンケート調査を行った．質問項目は以下の通りで，5 段階評価で\n24\n回答してもらう．\n• ランダムターゲットの大きさは適切であったか\n• アセントのターゲットの出現は自然であったか\n• 赤と青のターゲットは見づらいと思ったか\n• 実験時間は適切であったか\n• ウォームアップの時間は適切であったか\n• アイトラッカーは邪魔であったか\n• 普段通りにプレイできたか\n• 環境に関する改善点（自由記述）\n質問項目を付録B に示す．\n25\n第5章\n実験結果および考察\n5.1\n実験結果\n5.1.1\nシナリオ1 の結果と考察\nシナリオ1 の計測結果を図",
            "験結果および考察\n5.1\n実験結果\n5.1.1\nシナリオ1 の結果と考察\nシナリオ1 の計測結果を図5-1 に示す．計測したデータは固視が発生するまでの時間，\nターゲットの破壊時間，命中率の3 つである．\n表5-1: シナリオ1 の計測結果\nID\n固視が発生する時間（秒）\n破壊時間（秒）\n命中率（%）\n1\n0.166\n0.606\n70.26\n2\n0.149\n0.605\n89.67\n3\n0.165\n0.653\n84.44\n4\n0.232\n0.575\n78.7\n5\n0.140\n0.580\n93.01\n6\n0.262\n0.650\n79\n7\n0.219\n0.591\n85.26\n8\n0.181\n0.575\n80.1\n9\n0.149\n0.692\n83.52\n10\n0.151\n0.629\n90.4\n11\n測定ミス\n0.638\n82.42\n12\n0.187\n0.618\n88.82\n13\n0.260\n0.760\n85.71\n14\n0.271\n0.815\n81.51\n15\n0.291\n0.800\n86.11\n16\n0.657\n1.036\n73.23\n17\n0.287\n0.709\n86.75\n18\n0.32",
            "\n16\n0.657\n1.036\n73.23\n17\n0.287\n0.709\n86.75\n18\n0.321\n0.844\n92.8\n19\n0.382\n0.909\n95.41\n上記の計測結果について分析を行う．\nシナリオ1 の固視が発生するまでの時間についての分布図を図5-1 に，それぞれの熟\n練度別の平均時間の表を表5-2 示す．1 名アイトラッカーの測定ミスでデータが得られな\nかった．\n26\n図5-1: シナリオ1 における固視が発生するまでの時間の分布図\n表5-2: シナリオ1 における固視が発生するまでの熟練度ごとの平均時間\n熟練度\n平均時間（秒）\n上級者\n0.171\n中級者\n0.201\n初心者\n0.368\nこの結果に関して分散分析を行ったところ，p 値は0.00465 となり，グループ間に有意\nな差が認められた．また，それぞれのグループの平均時間を比較すると熟練度が上がるほ\nど時間が短くなっている傾向がみられた．しかし，上級者のID:4 の被験者は2 番目にス\nコアが高かったにも関わらず，中級者の平均よりもかなり遅い結果を残した．このことか\nら，かならずしも固視が発生するまでの時間の",
            "ず，中級者の平均よりもかなり遅い結果を残した．このことか\nら，かならずしも固視が発生するまでの時間の速さがFPS の熟練度に繋がるわけではな\nいと考えられる．\nまた，破壊時間においても同様に分布図を図5-2 に，それぞれの熟練度別の平均時間の\n表を表5-3 示す．\n27\n図5-2: シナリオ1 におけるターゲットを破壊するまでの時間の分布図\n表5-3: シナリオ1 におけるターゲットを破壊するまでの熟練度ごとの平均時間\n熟練度\n平均時間（秒）\n上級者\n0.604\n中級者\n0.644\n初心者\n0.841\nこの結果に関しても分散分析を行ったところ，p 値は0.0000648 となり，グループ間に\n有意な差が認められた．また，それぞれのグループの平均時間を比較すると熟練度が上が\nるほど時間が短くなっている傾向がみられた．\nシナリオ1 における命中率の分布図を図5-3 に，熟練度ごとの平均命中率を図5-4 に\n示す．\n28\n図5-3: シナリオ1 における命中率の分布図\n表5-4: シナリオ1 における熟練度ごとの平均命中率\n熟練度\n命中率（%）\n上級者\n83.22\n中級者\n84.40\n初心者",
            "における熟練度ごとの平均命中率\n熟練度\n命中率（%）\n上級者\n83.22\n中級者\n84.40\n初心者\n85.97\nシナリオ1 では命中率の分布，平均ともにどの熟練度でも同じ特徴がみられた．p 値も\n0.802 を示し，グループ間に有意な差は見られなかった．\n5.1.2\nシナリオ2 の結果\nシナリオ2 の計測結果を表5-5 に示す．計測したデータはターゲットの破壊時間，命中\n率の2 つである．\n上記の計測結果について分析を行う．シナリオ2 のターゲットが破壊されるまでの時間\nについての分布図を図5-4 に，それぞれの熟練度別の平均時間の表を表5-6 に示す．\n29\n表5-5: シナリオ2 の計測結果\nID\n破壊時間（秒）\n命中率（%）\n1\n0.669\n60.87\n2\n0.843\n40.98\n3\n1.040\n51.22\n4\n0.734\n37.33\n5\n0.945\n53.16\n6\n0.700\n56\n7\n0.749\n71.19\n8\n0.843\n46.67\n9\n0.739\n54.19\n10\n0.689\n75.68\n11\n0.772\n77.78\n12\n0.735\n62.69\n13\n0.931\n68",
            "89\n75.68\n11\n0.772\n77.78\n12\n0.735\n62.69\n13\n0.931\n68.85\n14\n0.851\n67.74\n15\n0.975\n71.79\n16\n1.193\n40.98\n17\n0.287\n65.12\n18\n0.969\n67.2\n19\n1.247\n75\n図5-4: シナリオ2 におけるターゲットを破壊するまでの時間の分布図\nこの結果に関して分散分析を行ったところ，p 値は0.00572 となり，グループ間に有意\nな差が認められた．しかし，シナリオ1 とは異なり，時間が最も短いグループは中級者と\n30\n表5-6: 固視が発生するまでの平均時間\n熟練度\n平均時間（秒）\n上級者\n0.846\n中級者\n0.770\n初心者\n1.028\nなった．このような結果となった要因は熟練度ごとにValorant プレイヤーとしての特徴が\n表れたためと考えられる．Valorant にはターゲットの頭を射撃するとダメージの倍率が上\nがり，素早く敵を倒すことができるという仕様が存在する．上級者グループに属するプレ\nイヤーは普段から頭を狙ってAIM を合わせる癖がついている．今回のシナリオで",
            "者グループに属するプレ\nイヤーは普段から頭を狙ってAIM を合わせる癖がついている．今回のシナリオではター\nゲットのどこに命中させても一撃で倒せる設定にしているので頭を狙うとそれだけ的が\n小さくなるので他の被験者と比べて不利になってしまっていた．ID：2，3，5 の3 人のプ\nレイヤーが頭を狙ってしまっていたため，平均時間が長くなってしまっていた．\nシナリオ1 における命中率の分布図を図5-5 に，熟練度ごとの平均命中率を図5-7 に\n示す．\n図5-5: シナリオ2 における命中率の分布図\n表5-7: シナリオ2 における熟練度ごとの平均命中率\n熟練度\n命中率（%）\n上級者\n48.71\n中級者\n64.13\n初心者\n64.64\n31\n命中率においても破壊時間と同様の特徴が表れている．上級者のみ命中率が下がってい\nる．これは破壊時間と同様に数名が小さい的を狙ってしまっていることが原因である．\n5.2\n録画データから読み取れた考察\nアイトラッカーの録画データを確認したところ，熟練度によって視線の動きの特徴に大\nきな差があった．上級者は出現したターゲットの中心を一度の視線の動きで捉えること\nが",
            "の動きの特徴に大\nきな差があった．上級者は出現したターゲットの中心を一度の視線の動きで捉えること\nができていた．そのため，多くの場合1 つのターゲットに対して発生する固視の回数は1\n回であった．逆に初心者は出現したターゲットの中心を一度の視線移動では捉えられてい\nなかった．1 回目の視線移動ではターゲットを飛び越してしまうか距離が足りず中途半端\nな位置で止まるなど，ぼんやりと視界に捉えていた．その後，2 回目，3 回目の視線移動\nでターゲットの中心に視線を向けていた．中級者はこの上級者と初心者の間の特徴を示し\nていた．1 回の視線移動でターゲットを捉えられることもあれば，出現したターゲットが\n遠い場合は2 回視線移動するなど1 つのターゲットに対する固視の回数は初心者と上級者\nの間の回数であった．\n5.3\nアンケート結果\n独自のアンケートをもとに，被験者に回答してもらった結果を示す．まず，シナリオに\n関する被験者の評価について整理する．ランダムターゲットの大きさは適切だったかとい\nう質問に対しての結果を図5-6 に示す．この質問では，13 名が「ちょうど良い」，4 名が\n「やや大きかっ",
            "に対しての結果を図5-6 に示す．この質問では，13 名が「ちょうど良い」，4 名が\n「やや大きかった」，2 名が「やや小さかった」と回答した．ターゲットの大きさはそのま\nまシナリオの難易度に繋がる．大きさに大きな不満を持ったプレイヤーがいなかったた\nめ，幅広い熟練度のプレイヤーに適応した難易度設定をすることができた．\nアセントのターゲットの出現は自然だったかという質問に対しての結果を図5-7 に示す．\nこの質問では，3 名が「自然だった」，4 名が「やや自然だった」，4 名が「どちらでもな\nい」，2 名が「やや自然だった」と回答した．この質問はValorant におけるアセントを知っ\nているプレイヤー13 人にのみ設けた．自然と感じたプレイヤーが約半数のみだったため，\nターゲットの出現の仕方をもっと工夫する必要がある．\n赤と青のターゲットは見づらいと思ったかという質問に対しての結果を図5-8 に示す．\nこの質問では，13 名が「見やすい」，2 名が「やや見やすい」，3 名が「どちらでもない」，\n1 名が「やや見づらい」と回答した．画像認識，視線誘導という目的のためにターゲット\nの色を",
            "ない」，\n1 名が「やや見づらい」と回答した．画像認識，視線誘導という目的のためにターゲット\nの色を分けたが，被験者に悪影響はほとんど与えなかった．\n32\n図5-6:「ランダムターゲットの大きさは適切だっ\nたか」に対する回答結果\n図5-7:「アセントのターゲットの出現は自然だっ\nたか」に対する回答結果\n図5-8: 「赤と青のターゲットは見づらいと思っ\nたか」に対する回答結果\n図5-9: 「実験時間は適切だったか」に対する回\n答結果\n実験時間は適切だったかという質問に対しての結果を図5-9 に示す．この質問では，16\n名が「ちょうど良い」，1 名が「やや長かった」，2 名が「やや短かった」と回答した．本\n実験では，被験者の集中力を最大限に保つ実験時間の設定を行った．「ちょうど良い」と\nいう回答がほとんどだったため，この目的は達成できた．\nウォームアップの時間は適切だったかという質問に対しての結果を図5-10 に示す．こ\nの質問では，18 名が「ちょうど良い」，1 名が「やや長かった」と回答した．ウォームアッ\nプの時間も被験者の集中力と調子を保つための時間設定にしたため，この目標を達成でき",
            "した．ウォームアッ\nプの時間も被験者の集中力と調子を保つための時間設定にしたため，この目標を達成でき\nたことがこの結果から確認できた．\nアイトラッカーは邪魔だったかという質問に対しての結果を図5-11 に示す．この質問\nでは，10 名が「気にならなかった」，5 名が「やや気にならなかった」，1 名が「どちらで\nもない」，2 名が「やや邪魔だった」，1 名が「邪魔だった」と回答した．数名が「邪魔だっ\nた」と答えたものの，ほとんどのプレイヤーは「気にならない」と答えたため，アイト\n33\nラッカーを使用した計測は有効であると考えられる．\n図5-10:「ウォームアップの時間は適切だったか」\nに対する回答結果\n図5-11: 「アイトラッカーは邪魔だったか」に対\nする回答結果\n図5-12: 「普段通りにプレイできたか」に対する回答結果\n普段通りにプレイできたかという質問に対しての結果を図5-9 に示す．この質問では，\n5 名が「普段通りにできた」，3 名が「やや普段通りにできた」，2 名が「どちらでもない」，\n1 名が「やや普段通りにできなかった」，2 名が「普段通りにできなかった」と回答した．\n",
            "もない」，\n1 名が「やや普段通りにできなかった」，2 名が「普段通りにできなかった」と回答した．\nこの質問は，普段からFPS をプレイしている13 名にのみ設けた．普段通りにプレイでき\nたプレイヤーが多かったものの，数名は環境の違いから実験のパフォーマンスが下がって\nしまっていた．以下に被験者から上がった環境に関する改善点を示す．\n• デスクの高さが異なった\n• アイトラッカーが眼鏡と被っていた\n• 普段座椅子でプレイしているため，机だとやりづらかった\n34\n第6章\n結論\n6.1\nまとめ\n本研究では，AIM スキルの上達方法を定量的な指標を用いてプレイヤーへフィードバッ\nクを行うことを最終的な目的として，視線が固定される速度と操作速度の数値データを獲\n得し，プレイヤーのレベル別に分析を行った．\n実験結果から，視線とマウスを用いたAIM の速度は熟練度が上がると速くなり，それぞ\nれの熟練度の間には有意差があることが確認された．このことから2 つの速度をFPS プ\nレイヤーのAIM スキルの評価指標として使用できることが分かった．\nまた，これら以外にも，命中率，視線の動かし方などにも熟練",
            "の評価指標として使用できることが分かった．\nまた，これら以外にも，命中率，視線の動かし方などにも熟練度によって特徴が見られ\nたため，速度以外の指標もAIM スキルの評価方法として利用することが期待できる．\n6.2\n今後の展望\n今後，本研究の目的達成のために姿勢や腕の動作，モニターとの距離など別の要素と組\nみ合わせてプレイヤーへフィードバックを行うところまでアップデートすることが必要\nである．今回の実験ではプレイヤーごとに機材の位置を調整してもらったが，モニターの\n距離と高さに最も個性が表れていたため，この要素のフィードバックを行うとプレイヤー\nのためになると考えられる．具体的な方法として，アイトラッカーのワールドカメラから\n画像処理で距離を測ることなどが考えられる．\nまた，実験環境の改善が求められる．アイトラッカーの視線情報は眼鏡を使用している\n被験者など人によっては安定しなかったため，アイカメラを増設し両目の情報を入手でき\nるようにする，邪魔にならない位置に場所を移動するなどの改善が必要である．普段座椅\n子でプレイしている被験者もいたため，よりパーソナライズされた環境を提供することも",
            "要である．普段座椅\n子でプレイしている被験者もいたため，よりパーソナライズされた環境を提供することも\n必要である．\nシナリオの見直しも必要である．今回の実験ではターゲットの動きの再現の限界が存在\nし，100%自然な表現はできなかった．今後の実験目標によって最適なシナリオは異なる\nが，被験者がより力を発揮しやすいシナリオを作成したい．\n35\n謝辞\n本研究を進めるうえで，親身に相談に乗って下さった青山学院大学理工学部情報テクノ\nロジー学科ロペズ・ギヨーム教授に深く感謝をいたします．また，研究環境の補助をして\nくださった大熊氏，論文の添削を通してアドバイスをくださった宮澤先輩をはじめとする\nロペズ研究室の院生の方々，同期の方々に深く感謝いたします．また，実験に協力してい\nただいた被験者の方々にも感謝いたします．\n2025 年1 月28 日\n清水遥希\n36\n参考文献\n[1] デロイトトーマツ：拡大を続けるゲーム市場の動向(2024). https://faportal.\ndeloitte.jp/times/articles/000937.html.\n[2] 株式会社角川アスキー総合研究所：ファ",
            "times/articles/000937.html.\n[2] 株式会社角川アスキー総合研究所：ファミ通ゲーム白書2022 (2022).\n[3] KRAFTON: PUBG MOBILE JAPAN LEAGUE SEASON2 開催！(2022/2/28). https:\n//pubgmobile.jp/pmjl_season2/.\n[4] Esports,\nV.:\nMASTERS\nTOKYO:\nEVERYTHING\nYOU\nNEED\nTO\nKNOW\n(2023/5/31).\nhttps://valorantesports.com/ja-JP/news/\nmasters-tokyo-everything-you-need-to-know.\n[5] 株式会社角川アスキー総合研究所：日本e スポーツ白書2023，一般社団法人日本e\nスポーツ連合(2023).\n[6] FOUNDRY, Q.: 7 Things We Learned About Primary Gaming Motivations From Over\n250,000 Gamers (2016/12/15). https:",
            "ions From Over\n250,000 Gamers (2016/12/15). https://quanticfoundry.com/2016/12/15/\nprimary-motivations/.\n[7] ゲーマーゲーマー‘sPOST：【保存版】e スポーツ用語『エイム（Aim）』とはどんな\n意味？｜早わかり(2024/2/15). https://gamer2.jp/post/aim/.\n[8] Koposov, D., Semenova, M., Somov, A., Lange, A., Stepanov, A. and Burnaev, E.: Anal-\nysis of the Reaction Time of eSports Players through the Gaze Tracking and Person-\nality Trait, 2020 IEEE 29th International Symposium on Industrial Electronics (ISIE),\nIEEE, pp. 1560–1565 (online), https://d",
            "cs (ISIE),\nIEEE, pp. 1560–1565 (online), https://doi.org/10.1109/ISIE45063.2020.\n9152422 (2020).\n[9] 出山果歩：瞳孔径に精神疲労が及ぼす影響に関する研究(2020).\n[10] Smerdov, A., Burnaev, E. and Somov, A.: eSports Pro-Players Behavior During the Game\nEvents: Statistical Analysis of Data Obtained Using the Smart Chair, arXiv preprint\narXiv:1908.06402 (2019).\n37\n[11] Boch, R., Fischer, B. and Ramsperger, E.: Express-Saccades of the Monkey: Reaction\nTimes Versus Intensity, Size, Duration, and Eccentricity of Their Targets, E",
            "ze, Duration, and Eccentricity of Their Targets, Experimental\nBrain Research, Vol. 55, pp. 223–231 (1984).\n[12] 高明浅見，多久満大崎，繁石島：視野反応計を用いた中心視反応と周辺視反応の比\n較検討，筑波大学体育科学系紀要，Vol. 7, pp. 149–162 (1984).\n[13] 橋秀太朗，服部峻，高原まどか：テトリスのためのルールベースなゲーム画面認識\nによるデバッグAI の試作，日本デジタルゲーム学会2022 年夏季研究発表大会予稿\n集，日本デジタルゲーム学会，pp. 45–48 (2022).\n[14] : 【保存版】e スポーツ用語『フリックエイム』とはどんな意味？┃ゲーマーゲー\nマー’s POST，https://gamer2.jp/post/flick-aim/. (参照日2025/01/19).\n[15] : VALORANT, https://playvalorant.com/ja-jp/. (参照日2025/01/19).\n[16] Labs, P.: ",
            "orant.com/ja-jp/. (参照日2025/01/19).\n[16] Labs, P.: Pupil Core. https://pupil-labs.com/products/core.\n[17] 田中啓治(独立行政法人理化学研究所脳科学総合研究センター)：固視(2019/2/18).\nhttps://bsd.neuroinf.jp/wiki/\n[18] : Core - Pupil Capture - Pupil Labs Docs, https://docs.pupil-labs.com/\ncore/software/pupil-capture/. (参照日2025/01/19).\n[19] : Homepage - Aimlabs, https://aimlabs.com/. (参照日2025/1/19).\n[20] :\nPRO\nX\n2\nSuperlight\nWireless\nGaming\nMouse,\nhttps://\ngaming.logicool.co.jp/ja-jp/products/gaming-mice/\npro-x2-superlight-wirele",
            "-jp/products/gaming-mice/\npro-x2-superlight-wireless-mouse.html. (参照日2025/1/19).\n[21] : ARTISAN FX RAIDEN, https://www.artisan-jp.com/fx-raiden.html.\n(参照日2025/1/19).\n[22] :\nOMEN\nX\n27\nDisplay,\nhttps://www.omen.com/gb/en/displays/\nomen-x-27.html. 参照日2025/1/19.\n[23] Fisher, R.: Statistical Methods for Research Workers, Biological monographs and manu-\nals, Oliver and Boyd (1925).\n38\n付録A\n　FPSに関する意識調査\n39\n1。\n1 つだけマークしてください。\nAIM、撃ち合いの強さ\n立ち回り、頭の良さ\nコミュニケーション、仲間との連携\n相手の行動を読む、勝負勘\n2。\n1 つだけマークしてください。\nある\nない\nこの",
            "ョン、仲間との連携\n相手の行動を読む、勝負勘\n2。\n1 つだけマークしてください。\nある\nない\nこのコンテンツは Google が作成または承認したものではありません。\nAIMに関する意識調査\n* 必須の質問です\nFPSで強くなるために1番必要なスキルはなんだと思いますか*\n今まで「エイムスキルの停滞」や「エイムスキルを上げる方法で迷った」と\nいう経験はありますか？\n*\n フォーム\n2025/01/26 22:00\nAIMに関する意識調査\nhttps://docs.google.com/forms/d/1giHo9hSF-159otl-6uYiRCH8AfNExGtoqaF_3yDFqJs/edit\n1/1\n付録B\n　実験のフィードバックアンケート\n41\n1。\n1 つだけマークしてください。\n小さかった\n1\n2\n3\n4\n5\n大きかった\n2。\n1 つだけマークしてください。\n不自然だった\n1\n2\n3\n4\n5\n自然だった\n3。\n1 つだけマークしてください。\n見ずらい\n1\n2\n3\n4\n5\n見やすい\n4。\n1 つだけマークしてください。\n短かった\n1\n2\n3\n4\n5\n長かった\n実験後アンケー",
            "やすい\n4。\n1 つだけマークしてください。\n短かった\n1\n2\n3\n4\n5\n長かった\n実験後アンケート\n* 必須の質問です\nランダムターゲットの大きさは適切でしたか*\nアセントのターゲットの出現は自然でしたか*\n赤と青のターゲットは見ずらいと思いましたか*\n実験時間は適切でしたか*\n2025/01/26 21:32\n実験後アンケート\nhttps://docs.google.com/forms/d/1kQsM44UGxUA9YS1semtWqFxwc2pqKqp4bI5a_RDvzLk/edit\n1/3\n5。\n1 つだけマークしてください。\n短かった\n1\n2\n3\n4\n5\n長かった\n6。\n1 つだけマークしてください。\n邪魔だった\n1\n2\n3\n4\n5\n気にならなかった\n7。\n1 つだけマークしてください。\n普段通りにできなかった\n1\n2\n3\n4\n5\n普段通りにできた\n8。\nこのコンテンツは Google が作成または承認したものではありません。\nウォームアップの時間は適切でしたか*\nアイトラッカーは邪魔でしたか*\n普段通りにプレイできましたか*\n実験環境(モニターやマウスなど)は適切でした",
            "ッカーは邪魔でしたか*\n普段通りにプレイできましたか*\n実験環境(モニターやマウスなど)は適切でしたか。改善点があれば記述してく\nださい。\n*\n フォーム\n2025/01/26 21:32\n実験後アンケート\nhttps://docs.google.com/forms/d/1kQsM44UGxUA9YS1semtWqFxwc2pqKqp4bI5a_RDvzLk/edit\n2/3\n"
        ]
    },
    {
        "id": "paper_2",
        "filename": "B2024_HarutoNiimura.pdf",
        "title": "B2024_HarutoNiimura",
        "fulltext": "青山学院大学理工学部\n情報テクノロジー学科\n２０２４年度卒業研究論文\n動画視聴における瞬目促進\nフィードバック手法の検証\n２０２５年１月２８日提出\n指導教員ロペズ・ギヨーム　教授\n提出者学生番号　氏名\n１５８２１０６８新村温人\n青山学院大学 理工学部 情報テクノロジー学科 \n2024（令和6）年度卒業論文要旨 \n- 1 - \n \n動画視聴における \n瞬目促進フィードバック手法の検証 \n \n新村 温人（15821068） \nロペズ研究室 \n \n１．はじめに \n近年，動画配信市場は急速に拡大しており，その市\n場規模は2019年から2024年の4 年間で96%増加し，\n長時間視聴が恒常化している[1]．一方，デジタルデバ\nイスの使用中には瞬目（瞬き）の頻度が大幅に低下し，\nこれがドライアイや眼精疲労を引き起こす要因となり，\n社会的な課題となっている[2]． \n本研究は，眼精疲労やドライアイの対策として，動\n画視聴中の瞬目促進を目的としている．瞬目をリアル\nタイムで検出し，視覚，聴覚，触覚を活用した4 種類\nのフィードバックによって瞬目を促進するシステムを\n提案し，その効果を比較する． \n２．関連研究 \n東覚らは，ドライアイ軽減のため，瞬目回数を検知\nしリマインドを提示するシステムを提案した[3]．瞬目\nが10 秒間に2 回以下になる条件でリマインドを行う\n方法が最も効果的であり，瞬目の安定化に寄与するこ\nとが示された．一方で，リマインド方法が邪魔と感じ\nやすいという意見があり，他の感覚モダリティ（聴覚\nや触覚など）を用いた比較や評価は行われていない． \n前川らは，瞬目の模倣と印象形成への影響を調査し\nた[4]．その結果，瞬目が同期する画像は非同期の画像\nより好感度が高く評価されることを確認した． \n３．瞬目促進システムの概要 \n本研究では，動画視聴中の瞬目を促進するため，瞬\n目検出とフィードバック提示機能を備えた瞬目促進シ\nステムを開発した．瞬目検出機能，フィードバック提\n示機能と，データ記録機能の3 つで構成される． \n瞬目検出には，MediaPipe ライブラリを使用し，ノ\nートPC の内蔵カメラによる顔のランドマーク検出を\n通じて目の開閉状態を判定する[5]．具体的には，EAR\n（Eye Aspect Ratio）を用い，上下まぶた間の距離が\n一定以下の場合に瞬目と判定する[6]． \nフィードバック提示機能では，視覚2 つ（フラッシ\nュと，アニメーションGIF），聴覚1 つ（短音通知），\n触覚1 つ（スマートウォッチの振動）の4 種類を実装\nした．通常の平均瞬目回数である10 秒間で瞬目回数\nが3 回を基準に設定し，3 回以下になった際にフィー\nドバックを提示する[2]． \nデータ記録機能では，分析のために10 秒ごとの瞬\n目回数とフィードバックの有無を記録する．ユーザは\n動画視聴中，自然な形で瞬目を促進するフィードバッ\nクを受けることで，眼精疲労やドライアイの軽減が期\n待される． \n４．瞬目促進システムの効果検証方法 \nまず，EAR の閾値設定条件を最適化するため，5 名\nを対象として予備実験を実施した．結果，EAR が0.17\nの付近で実際の瞬目回数と検出された瞬目回数が最も\n近似することが確認された． \n \n図1．連続フレーム数 2 における閾値ごとの瞬目検\n出精度 \n一方で，個人差が大きく，各被験者に適した閾値を\n設定する必要があることが分かった．これを踏まえ，\n本実験では被験者ごとに事前調整の時間を設け，適切\nな閾値を設定して実験を進めた． \nそして，4 種類のフィードバックに加えて，フィー\n \n \nドバックなしの5 条件で比較を行うため，30 分間の動\n画視聴中に各条件を6 分ごとにランダムに切り替えた．\n被験者10 名を対象に瞬目回数や視聴体験への影響を\n評価し，アンケートによる各フィードバックの印象や\n視聴体験への影響を調査した． \n５．フィードバック条件の有効性検証結果 \n瞬目促進システムの5 つの条件における瞬目回数の\n結果を図１に示す．10 秒間における瞬目の平均回数は\nフィードバックなしと比べて各フィードバックで増加\nした．また，フラッシュを除く3 つのフィードバック\n方法では基準値である「10 秒間に3 回」を上回った． \nまたTukey の多重比較検定[7]を用いて条件間の差\nを分析した結果を表1 に示す．フィードバックなしの\n条件に比べて，音の条件（p=0.03）および，スマート\nウォッチの条件（p=0.01）で瞬目回数が有意に増加し\nたことが確認された．一方，GIF，フラッシュ，音，ス\nマートウォッチの間では統計的に有意な差は認められ\nなかった（p>0.05）． \n次に被験者ごとの有意差を同様に検証した結果，10\n名中8 名で条件間に有意差が確認され，音とスマート\nウォッチの条件で瞬目回数が増加した．一方，被験者\n1 と8 では有意差が見られず，個人差が顕著であるこ\nとがわかった． \nアンケートでは，各フィードバックが視聴体験に影\n響を与えるとの意見がある一方で，GIF や認識されな\nいケースも確認された．また，事前説明により瞬目を\n意識した可能性があり，今後は自然な瞬目促進効果を\n評価する実験方法が必要である．これらの結果は，認\n識度と視聴体験への影響を最適化したフィードバック\n設計が必要であることを示唆している． \n \n図2．10 秒間の平均瞬目回数（* : p < 0.05） \n表1．Tukey の多重比較検定による各フィードバッ\nク間の有意差 \n \n６．まとめ \n本研究では，動画視聴中の瞬目促進を目的とした4\n種類のフィードバックシステムを提案し，その効果を\n検証した．結果，音とスマートウォッチのフィードバ\nックが瞬目回数を有意に増加させた．一方でフィード\nバックが認識されない場合があり，設計の改善が必要\nとされた．また，個人差や被験者が瞬目を意識した可\n能性が示唆され，自然な条件下での評価が課題である． \n今後は，モバイルデバイスでの適応型アルゴリズム\nの開発や，瞬目促進による視覚疲労やドライアイ軽減\nの長期的効果の検証を通じて，実用性の向上を目指す． \n参考文献 \n[1] \n総務省: 令和6 年版情報通信白書データ集 \n(2022)\n． \nhttps://www.soumu.go.jp/johotsusintokei/white\npaper/ja/r06/html/datashu.html#f00263．（最終\n閲覧日：2025/1/26） \n[2] \nウェルビーイングクリニック駒沢公園: デジタ\nル時代における眼精疲労（Digital EyeStrain， \nDES）https://wbck.tokyo/archives/1353． （最\n終閲覧日：2025/1/26） \n[3] \n東覚瑠菜， 神場知成: ドライアイ軽減のための\nまばたきリマインド機能の開発と評価， インタ\nラクション2024 論文集， 論文ID: 1P-82， pp. \n556-561 (Feb. 2024).  \n[4] \nMaekawa， T. and Inui， T.: 瞬目の模倣が他者\nの印象に与える影響，認知心理学研究，Vol. 16， \nNo. 2， pp. 15–24 (2019)． \n[5] \nGoogle AI for Developers: MediaPipe ソリュー\nシ\nョ\nン\nガ\nイ\nド\nhttps://ai.google.dev/edge/mediapipe/solutions/\nguide?hl=ja. （最終閲覧日：2025/1/26） \n[6] \nSoukupova， T.， & Cech， J.: Eye blink \ndetection using facial landmarks ， 21st \ncomputer vision winter workshop， Rimske \nToplice， Slovenia， Vol. 2， pp. 1-6 (2016)． \n[7] \nTukey，J. W.: Comparing individual means in \nthe analysis of variance，Biometrics，Vol.5，\nNo.2，pp.99-114 (1949)． \n比較条件（Group1）\n比較条件（Group２）\np値\n有意差\nnone\nflash\n0.9290\nFALSE\nnone\nGIF\n0.0662\nFALSE\nnone\nsound\n0.0301\nTRUE\nnone\nwatch\n0.0113\nTRUE\nflash\nGIF\n0.3622\nFALSE\nflash\nsound\n0.2189\nFALSE\nflash\nwatch\n0.1113\nFALSE\nGIF\nsound\n0.9986\nFALSE\nGIF\nwatch\n0.9756\nFALSE\nsound\nwatch\n0.9979\nFALSE\n目次\n第1 章\n序章\n1\n1.1\n研究背景. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n1\n1.1.1\n動画配信市場規模の増加. . . . . . . . . . . . . . . . . . . . . . . .\n1\n1.1.2\nVDT 作業における健康問題. . . . . . . . . . . . . . . . . . . . . .\n2\n1.1.3\n涙と瞬目の役割. . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n2\n1.1.4\nVDT 作業と瞬目の関係. . . . . . . . . . . . . . . . . . . . . . . . .\n3\n1.1.5\nドライアイ患者の割合と瞬目の関係\n. . . . . . . . . . . . . . . . .\n3\n1.2\n研究目的と目標. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n3\n1.3\n本論文の構成. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n4\n第2 章\n関連研究\n5\n2.1\n瞬目に関する研究. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n5\n2.1.1\n瞬目促進のフィードバック提示. . . . . . . . . . . . . . . . . . . .\n5\n2.1.2\n瞬目検出に関する研究. . . . . . . . . . . . . . . . . . . . . . . . .\n6\n2.1.3\n感覚刺激と瞬目行動の関係に関する論文. . . . . . . . . . . . . . .\n6\n2.2\n目の健康に関する論文. . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n8\n2.2.1\nデジタルデバイスによる目の影響. . . . . . . . . . . . . . . . . . .\n8\n2.3\n注意喚起に関する論文. . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n8\n2.4\n先行研究のまとめ. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n9\n第3 章\n開発システムについて\n10\n3.1\n瞬目促進システムの概要及び提案手法\n. . . . . . . . . . . . . . . . . . . .\n10\n3.2\n瞬目促進システムのハードウェアの構成. . . . . . . . . . . . . . . . . . .\n10\n3.3\n瞬目促進システムのソフトウェアの構成. . . . . . . . . . . . . . . . . . .\n12\n3.3.1\n瞬目検出機能. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n12\n3.3.2\nフィードバック提示機能. . . . . . . . . . . . . . . . . . . . . . . .\n14\n3.3.3\nデータ記録機能. . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n16\n3.4\nシステムの利用方法\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n16\ni\n第4 章\n瞬目促進システムの効果検証実験\n17\n4.1\n実験目的. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n17\n4.2\n実験概要. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n17\n4.2.1\n瞬目検出条件の最適化実験の概要. . . . . . . . . . . . . . . . . . .\n17\n4.2.2\nフィードバック条件の有効性検証実験の概要. . . . . . . . . . . . .\n18\n4.3\n実験手順. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n18\n4.3.1\n瞬目検出条件の最適化実験\n. . . . . . . . . . . . . . . . . . . . . .\n18\n4.3.2\nフィードバック条件の有効性検証実験\n. . . . . . . . . . . . . . . .\n19\n4.4\nデータ分析方法. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n21\n4.5\nアンケートでの評価方法. . . . . . . . . . . . . . . . . . . . . . . . . . . .\n21\n第5 章\n実験結果及び考察\n23\n5.1\n瞬目検出条件の最適化実験の結果. . . . . . . . . . . . . . . . . . . . . . .\n23\n5.2\nフィードバック条件の有効性検証実験の結果. . . . . . . . . . . . . . . . .\n28\n5.3\nアンケート結果. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n32\n5.4\n考察. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n32\n第6 章\n結論\n34\n6.1\nまとめ. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n34\n6.2\n今後の展望\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n34\n参考文献\n37\nii\n第1章\n序章\n本章では，社会的な背景をもとに研究の位置付けを明確にする．1.1 節では，研究背景\nとしてコンテンツ視聴における現状と課題について述べる．1.2 節では，背景に挙げた課\n題を踏まえた本研究の目的を定義する．1.3 節では，本論文の構成について述べる．\n1.1\n研究背景\n1.1.1\n動画配信市場規模の増加\n近年，日本で動画配信市場が増加傾向にある．総務省が実施した，消費者が動画配信\nサービス事業者に支払った金額の合計に関する調査の報告によると，2019 年は2,959 億\n円であったのに対し，2023 年は5,704 億円と４年間で96.2 ％の増加を示している[1]．ま\nた，2028 年における予測値は7,371 億円となり，今後も市場規模は拡大していくことが予\n想されている．これにより，動画視聴体験の質向上や健康的な視聴態度の促進が重要な課\n題となっている．\n図1-1: 日本の動画配信市場規模の推移（[1] より引用）\n1\n1.1.2\nVDT 作業における健康問題\nVDT（Visual Display Terminal）作業に伴う健康問題は社会的に注目を集めている．厚\n生労働省の調査では，VDT 作業を行う労働者のうち68.6 ％が身体的疲労を感じており，\nその中でも，図1-2 に示すように「目の疲れ・痛み」を最も多く挙げている（90.8 ％）[2]．\nまた，第一三共ヘルスケア株式会社の調査によれば，図1-3 に示すように，テレワーク中\nの男女において，眼精疲労を訴える割合は女性22.0 ％，男性15.7 ％であることが示され\nた[3]．これらの結果から，VDT 作業による瞬目頻度の減少が健康に悪影響を及ぼしてい\nることが示唆されている．\n図1-2: VDT 作業における身体的疲労に関する調査データの抜粋（[2] より引用）\n図1-3: テレワークにおける不調内容の男女比較（[3] より引用）\n1.1.3\n涙と瞬目の役割\n涙は多くの役割を持っている．坪田によると，涙は目の表面が必要としているビタミン\n類およびタンパク質などの供給，目の表面の酸化および炎症から目を守る働き，外からの\n侵入物および古くなった細胞のを運び去る役割など多くの役割を持っている[4]．そして，\n瞬目は涙を目の表面を均一に運ぶ役割があり，瞬目を行わないと目の表面が乾燥し，涙が\n作られても上手く分配することが可能でなくなるため，意識的に瞬目を行う必要がある．\n近年人々の涙は減少傾向にあり，その分瞬目の重要度はますます高まっている．\n2\n1.1.4\nVDT 作業と瞬目の関係\nデジタルデバイスの普及は人々の健康に影響を与えている．ウェルビーイングクリニッ\nク駒沢公園は，DES と呼ばれるデジタルデバイスの長時間使用が引き起こす眼精疲労が\n新たな健康問題として注目されていることを示した[5]．DES の原因として，通常は1 分\n間に平均18-22 回である瞬目が，デジタルデバイスの使用中には1 分間に5-7 回まで減少\nしてしまうことで，目の表面に形成された涙液膜が破れるまでの時間が短縮されることが\n挙げられる．結果としてドライアイ症状の発生が懸念されることが述べられている．\n1.1.5\nドライアイ患者の割合と瞬目の関係\nドライアイは，目を守るために必要な涙の量が不足したり，涙の質のバランスが崩れる\nことで，涙が目全体に均等に行きわたらなくなる病気である．ドライアイ研究会による\nと，高齢化およびエアコンの使用，パソコンおよびスマートフォンの長時間使用，さらに\nはコンタクトレンズの装用者の増加に伴い，ドライアイの患者数は増加しており，その数\nは約2,200 万人にのぼると述べている．[6]．ドライアイは主に涙の量が減少する「量的な\n異常」と，涙の性質および涙を保持する能力が変化する「質的な異常」の2 つに分類する\nことが可能であり，特に「質的な異常」の中には，「ＢＵＴ短縮型ドライアイ」と呼ばれ\nる症状が強いタイプがある．ＢＵＴ短縮型ドライアイは涙の分泌はされるが目の表面で涙\nの膜が安定せず，5 秒以内に涙が乾いてしまうのが特徴であり，VDT 作業の多いオフィス\nワーカーおよびコンタクトレンズ装用者に多く見られる傾向があるとされている．\n1.2\n研究目的と目標\n1.1 節で述べたように，近年，動画配信市場の拡大とともに，動画視聴に伴う健康問題\nの改善が求められている．特に，眼精疲労およびドライアイは，VDT 作業中の瞬目減少\nが一因として挙げられ，重要な課題とされている．本研究では，動画視聴中における瞬目\n促進による健康問題の改善することを目的とする。\n動画視聴中の瞬目回数を検出し，その回数が基準値を下回った場合に適切なフィード\nバックを与えることで，瞬目を促進し，健康的な視聴態度を促すシステムの提案と開発を\n目的とする．具体的には，瞬目を検出するアルゴリズムを用いて瞬目の減少をリアルタイ\nムで判断し，基準値未満の場合に画面にフラッシュの表示，GIF 表示，音声再生，または\nスマートウォッチの振動といった4 種類のフィードバックを提供する．さらに，それぞれ\nのフィードバックの有効性を比較・評価する実験を実施し，最適なフィードバック手法を\n探ることを目指す．\n3\n1.3\n本論文の構成\n第1 章では，本論文の研究背景，研究目的，及び本論文の構成について述べた．第2 章\nでは，関連研究について説明する．\n4\n第2章\n関連研究\n本章では，関連研究について述べる．2.1 節では瞬目に関する研究，2.2 節では目の健\n康に関する研究，2.3 節では注意喚起に関する研究について述べる．\n2.1\n瞬目に関する研究\n2.1.1\n瞬目促進のフィードバック提示\n東覚らは，長時間のパソコン作業によるドライアイ軽減を目的とし，瞬目回数を検知し\nて適切なタイミングでリマインドを行うシステムを提案した[7]．図2-1 は，本研究で提\n案されているフィードバック方法である．内蔵カメラとMediaPipe ライブラリを活用し，\n上下まぶた間の距離を基に瞬目を検出する．比較実験では，「10 秒間に瞬目回数が2 回以\n下の場合にリマインド」の条件が最も効果的で，瞬目回数の増加や不完全な瞬目の減少が\n確認された．長時間使用実験でも瞬目の安定化が示され，被験者からの評価も高かった．\n一方で，リマインド方法が邪魔と感じやすいという意見があり，他の感覚モダリティ(聴\n覚や触覚など) を用いた比較や評価は実施されなかった. また，瞬目の質改善にはさらなる\n検証が必要であることが示唆された．\n図2-1: 提案されているフィードバック方法（[7] より引用）\n大石らは，VDT 作業による瞬目減少を防ぎ，ドライアイを軽減するための瞬目促進シ\nステムを提案した[8]．システムは瞬目検出，促進，制御機能から構成され，瞬目減少時\nに画面を白く曇らせることで注意を促すように開発された．従来のポップアップ警告では\n効果が限定的であったが，提案された手法は視覚的変化でユーザーの注意を引きやすいと\n5\n考えられた．今後は実証実験を通じて有用性を検証し，適応性の向上が目標として掲げら\nれた．\n伊藤らは，スマートグラス（SG），LCD，紙媒体によるVDT 作業の眼精疲労度を比較\nした[9]．77 名の被験者を対象に，瞬目回数，フリッカー値，高周波成分（HFC）などを\n測定．SG 群は疲労が少なく，紙群は最も強い疲労を示した．SG は視線移動を減らし負\n担軽減に寄与したが，ドライアイ傾向の被験者も存在した．結果は，医療現場でのSG 利\n用時に配慮が必要であることが示唆された．\n2.1.2\n瞬目検出に関する研究\nTereza らは，顔のランドマーク検出を活用した瞬目検出アルゴリズムを提案した[10]．\nランドマーク検出器を用いて眼の特徴点を抽出し，眼の開閉状態を表す指標である「眼裂\n縦横比（EAR）」を計算し，EAR の変動パターンを用いて，瞬目をSupport Vector Machine\n（SVM）およびHidden Markov Model（HMM）を通じて分類・検出した．これらの方法は，\n精度が高く，リアルタイムで動作可能であり，データセット（ZJU，Eyeblink8，Silesian）\nでの評価でも既存手法と比較して良好な結果を示した．瞬目頻度および持続時間といった\n特性を活用し，運転中の眠気検知および注意力監視などの応用が期待された．\n2.1.3\n感覚刺激と瞬目行動の関係に関する論文\n前川らは，瞬目の模倣が無意識に行われる現象と，それが印象形成に与える影響を調査\nした[11]．実験では，ランダムに瞬目する画像が提示されると，参加者も無意識に画像の\n瞬目と同期して瞬目を行うことが確認された．また，参加者の瞬目に同期する画像は，非\n同期の画像よりも好感度が高く評価された．結果として，視覚的に提示された瞬目が観察\n者の瞬目行動を誘発し，模倣行動が他者への好意的印象を促進する可能性が示唆された．\n山田らは，驚愕性瞬目反射に先行刺激が与える影響を調査した[12]．微弱な先行刺激\n（S1）が強い音刺激（S2）に先行する場合，刺激間隔（ISI）によって反射が抑制または促\n進されることが確認された．特に，ISI が短い場合は反射量が抑制され，長い場合は促進\n効果が見られた．山田らの研究は，視覚および聴覚の刺激が瞬目反射に与える影響を明ら\nかにし，感覚刺激が反応制御に寄与する可能性を示唆した．\n山田らは，驚愕性瞬目反射を用いた「驚愕プローブパラダイム」の手法で感情を定量的\nに評価する研究を行った[13]．急峻な音刺激によって誘発される瞬目反射が，感情状態\n（快・不快）によって促進または抑制される特性を利用している．視覚および嗅覚などの\n感覚刺激を通じ，特定の感情を惹起した際の反射量を測定し，感情状態を客観的に評価す\nる方法論を提案した．また，薬物および遺伝子型，性差が感情処理に与える影響も検討さ\n6\nれた．結果として，驚愕性瞬目反射は他覚的な感情評価の有効な指標となり得ることが示\n唆された．山田らの研究は，感情の評価と健康科学の応用可能性を広げる一助となる知見\nを提供した．\nRushworth は，瞬目反射がさまざまな刺激（視覚，聴覚，触覚）に応じて引き起こされ\nるメカニズムを調査し，瞬目反射が神経系の病変の診断および評価に役立つ可能性が示さ\nれた[14]．実験では，グラベラ（眉間）へのタップ，強い音，明るい光フラッシュが刺激\nとして使用され，これらがどのように異なる神経経路を活性化するかを解析した．特に，\n明るい光フラッシュは瞬目反射を誘発する有効な刺激であり，その反射の遅延および強度\nが神経系の健康状態を示唆することが分かった．さらに，これらの反射が単なる保護反応\nではなく，感覚入力を統合する複雑なプロセスに関与している可能性も提案された．\n7\n2.2\n目の健康に関する論文\n2.2.1\nデジタルデバイスによる目の影響\nBin らは，デジタルアイストレイン（DES）と呼ばれる，デジタルデバイスを使用すること\nによって引き起こされる眼の不快感および視覚的な問題の普及とその影響を探った[15]．\n大学生を対象に，彼らのデバイス使用時間および頻度，経験する症状の種類を調査した．\n結果として，67 ％の参加者が1～5 種類の症状を報告し，最も一般的な症状は目の乾燥お\nよび痛み，頭部および首のこりであった．また，デバイス使用時間が長いほど症状が悪化\nする傾向が見られた．研究は，デジタル環境が眼の健康に与える影響を強調し，適切な対\n策および予防策の重要性が示唆された．\nKaur らは，デジタルデバイスの使用が増加する中，DES の症状およびリスク要因，影\n響を受ける人口について詳しく分析した[16]．主な症状には目の乾燥，かゆみ，頭痛，光\nに対する過敏性などがあり，特に学生および若年層に多く見られる．調査結果では，デジ\nタルデバイスの使用時間が長いほど，これらの症状の発生率が高くなることが示された．\nまた，適切な休憩および目のケアが重要であることも強調されていて，全体としてデジタ\nル環境における視覚的健康の重要性と，予防策の必要性を提示した．\nIrina らは，デジタルデバイスの使用に伴う「コンピュータビジョン症候群（CVS）」を\n取り上げた[17]．CVS は長時間の画面使用による視覚的・筋骨格的な症状および行動変\n化を指し，主な症状として視力低下，目の疲れ，頭痛，首および肩の痛み，注意力の低下\nが挙げられていた．研究は，CVS の主な要因として，デバイスの不適切な使用，照明条\n件，長時間の作業，乾燥した環境などを指摘した．特に女性および子ども，スマートフォ\nンの過剰使用者にリスクが高いことが示された．また症状の予防には，20 分ごとに作業\nを中断し，20 秒間，6 メートル（20 フィート）以上離れた場所を見る「20-20-20 ルール」\nおよび目を閉じて2 秒間静止し，その後，まぶたを強く閉じる動作を繰り返す点滅運動な\nどが有効だと提示した．\n2.3\n注意喚起に関する論文\nWickens らは，多重資源理論（Multiple Resource Theory）に基づき，タスク間の干渉を\n予測するモデルを提案した[18]．多重資源理論では，タスクが共有する認知資源（感覚モ\nダリティ，処理段階，符号化の種類など）の特性により，干渉の程度が変化することが示\nされた．特に，異なる感覚モダリティ（例：視覚と聴覚）を使用するタスクは，同じモダ\nリティを共有するタスクよりも干渉が少ないとされていた．著者は，音が他の感覚刺激を\n補完し，注意喚起およびタスク切り替えを促進する役割を果たす点を強調し，高負荷環境\n8\nでの実用性を示した．理論とモデルは，操縦士および運転者が複数のタスクを効率的に処\n理する設計への応用可能性があると結論づけた．\n岡村らは，視覚，聴覚，触覚の3 つの感覚刺激が同時に提示された場合の情報統合の特\n性を調査した[19]．結果として，視覚刺激が最も重要であり，触覚は視覚および聴覚に次\nぐ役割を果たすことが示された．また，触覚刺激は他の感覚と相互作用しながら情報統合\nを補完し，注意喚起に寄与する可能性があることを示した．岡村らの研究は，感覚モダリ\nティ間の重要度を明らかにした．\nXu らは，視線移動に基づく触覚フィードバック（eyerofeedback）が注意喚起に与える\n効果を調査した[20]．触覚刺激により，被験者は自身の視線挙動と注意状態を自覚しおよ\nびすくなり，特に注意維持が難しい長時間タスクでパフォーマンスが向上した．Xu らの\n研究は，触覚刺激が他の感覚モダリティを補完し，注意喚起を促進する手段として有効で\nあることを示した．\n2.4\n先行研究のまとめ\nこれまでの研究では，感覚刺激を利用した瞬目促進および注意喚起の効果が多く示され\nており，それぞれの感覚モダリティが瞬目行動および視覚健康に与える影響が明らかにさ\nれてきた．しかし，異なる感覚モダリティを比較検討する研究は限られており，それぞれ\nの手法の有効性を包括的に評価する必要がある．本研究では，視覚，聴覚，触覚を活用し\nたフィードバック手法を通じて，瞬目促進における最適な刺激方法を明らかにすることを\n目指す．本研究により，瞬目不足が引き起こす眼精疲労およびドライアイの軽減に寄与\nし，日常生活に適用可能なシステム設計への新たな知見を提供することを目指している．\n9\n第3章\n開発システムについて\n本章では，本論文が開発および提案する，動画視聴中の瞬目促進システムについて述\nべる．\n3.1\n瞬目促進システムの概要及び提案手法\n本システムは，Python を用いて開発された瞬目検出アプリケーションをベースに構築さ\nれている．動画視聴中に瞬目が減少することによるドライアイのリスクを低減し，視覚の\n健康を維持することを目的として開発された．特に，瞬目の頻度低下による目の乾燥を防\nぎ，ユーザの快適な動画視聴体験を支援することを目指している．\n3.2\n瞬目促進システムのハードウェアの構成\n本研究で使用するノートPC は，図3-1 に示している，NEC 社が開発した「LAVIE Direct\nPM」である[21]．第11 世代のIntel Core i7-1165G7 プロセッサ（基本クロック周波数: 2.80\nGHz）を搭載し，16GB のメモリと512GB のSSD ストレージを備えたノートパソコンで\nある．13.3 インチのフルHD ディスプレイを搭載し，約1.2kg の軽量設計で持ち運びが容\n易である．LAVIE Direct PM は実験システムの動作環境として使用され，Python ベースの\n瞬目検出アプリケーションを実行し，内蔵カメラを用いて被験者の瞬目をリアルタイムで\n計測する役割を果たす．\n10\n図3-1: NEC 社が開発した「LAVIE Direct PM」（[21] より引用）\n本研究で使用するスマートウォッチは，図3-2に示している，Google社が開発した「Google\nPixel Watch」である[22]．GPS および心拍計に加えて，3 軸加速度計，3 軸角速度計，3 軸\n磁力計などの多くのセンサを搭載したスマートウォッチである．瞬目検出条件の最適化実\n験ではフィードバックの一つであるスマートウォッチの振動とGIF の表示を行うために\n用いる．\n図3-2: Google 社が開発した「Google Pixel Watch」（[22] より引用）\n11\n3.3\n瞬目促進システムのソフトウェアの構成\nシステムは，以下の３つの主要機能から構成されている．\n1. 瞬目検出機能\n2. フィードバック提示機能\n3. データ記録機能\n各機能は相互に連携し，瞬目の検出およびフィードバック提示をリアルタイムで行うよ\nうに設計されている．図3-3 にシステム全体のフロー図を示す．\n図3-3: システム全体のフロー図\n3.3.1\n瞬目検出機能\n瞬目検出機能にはPython のライブラリであるMediaPipe Solutions を使用している．Me-\ndiaPipe Solutions は，アプリケーションに人工知能（AI）および機械学習（ML）の技術\nを迅速に適用するためのライブラリとツールのスイートである[23]．本ソリューション\nはすぐに利用可能で，ニーズに応じたカスタマイズが可能である．MediaPipe Solutions は\nMediaPipe オープンソースプロジェクトの一部であり，提供されるソリューションコード\nをさらにカスタマイズすることで，アプリケーションの特定の要件に対応することが可能\nである．複数の開発プラットフォームに対応しており，幅広い用途で活用することが可能\nである．オブジェクト検出，画像・テキスト・短音の分類，画像生成など様々な機能があ\n12\nるが，本研究では顔のランドマーク検出機能を使用し，目の形状から眼の開閉状態を検出\nする．\n瞬目の検出手法として，EAR （Eye Aspect Ratio）を用いる．EAR は目の開閉状態を評\n価するための単一スカラー量であり，目のランドマーク（特徴点）を基に計算される[10]．\n目が開いている間，EAR の値はほぼ一定であり，目が閉じるにつれて値が0 に近づく．本\n指標は，個人差および頭部の姿勢の影響を受けにくく，画像のスケーリングおよび顔の平\n面回転に対して完全に不変です．また，両目は同期して瞬目を行うため，両目のEAR を\n平均して計算します．EAR は以下の式で定義される．\nEAR = ∥p2 −p6∥+ ∥p3 −p5∥\n2 · ∥p1 −p4∥\np1, p4\n目の左右の端点（水平方向の幅を表す）\np2, p6\n目の上下の端点（垂直方向の高さを表す）\np3, p5\n目の垂直方向中央の上下の点（補助的な高さを表す）\nEAR の計算結果例を図3-4 に示す．また，システムにおけるEAR およびEAR の連続フ\nレーム数という2 つの閾値は，瞬目検出条件の最適化実験を基に設定する．\n図3-4: EAR の計算結果例\n13\n3.3.2\nフィードバック提示機能\n瞬目検出条件の最適化実験では，以下の4 種類のフィードバックを実装している．\n1. フラッシュ\n2. アニメーションGIF 表示\n3. 短音通知\n4. スマートウォッチの振動・GIF 表示\n視覚的刺激として，フラッシュとアニメーションGIF の表示を採用した．Rushworth\n（1962）は，視覚刺激を用いた瞬目反射の研究で，強い光フラッシュが反射的な瞬目を誘\n発する有効な刺激であることを示した[14]．本研究では，この知見を基に，瞬目促進を目\n的としたフィードバックとして（図3-5）のような「フラッシュを模倣した白い画面の一\n瞬表示」を採用した．白い画面の表示は，フラッシュと同様に瞬間的な明暗変化を生じさ\nせるため，視覚的注意を瞬時に引きつけ，瞬目を誘発する可能性がある．このような視覚\n刺激の利用は，瞬目促進システムにおける効果的なフィードバックとして機能することが\n期待される．また，アニメーションGIF の表示は，図3-6 のように画面上部に目が瞬目す\nるアニメーションを表示する．視覚的に提示された瞬目が観察者によって無意識に模倣さ\nれる現象が示されているため[11]，GIF の動きに合わせた模倣行動を通じて自然な瞬目を\n誘発することを目指している．\n図3-5: フラッシュの実装例\n図3-6: アニメーションGIF 表示の実装例\n短音通知は，聴覚的刺激として「ピピッ」と表現される短い音を使用し，瞬目への意識\nを高める役割を果たす．聴覚的刺激は，他の感覚刺激を補完し，注意喚起およびタスクの\n切り替えを促進する効果があるとされており[18]，短い「ピピッ」と表現される音は，瞬\n目不足を自然に意識させ，行動を促進する効果が期待される．また，音刺激は聴覚を通じ\n14\nて瞬間的に注意を喚起し，反射的な瞬目を誘発する要因であることが示されている[12]．\nこれにより，短音通知は負担を抑えつつ，瞬目促進を効果的に実現する手法として有用で\nあると考えられる．\n触覚的刺激としては，スマートウォッチの振動を採用した．触覚は，視覚および聴覚に\n集中している状況でも有効な代替手段として機能し，負担を抑えながら注意を喚起をする\nことが可能である点で有用性がある[20]．また，Google Pixel Watch の振動機能と画面表\n示を組み合わせ，視覚・触覚の両面から瞬目を意識させるよう設計した（図3-7）．アニ\nメーションGIF の表示は，他の視覚刺激と同様に模倣行動を誘発し，自然な瞬目を促進す\nる狙いがある．\n図3-7: スマートウォッチの振動・GIF 表示の実装性\nこれらのフィードバック手法を用いた実験を通じて，異なる感覚刺激が瞬目促進にどの\nような効果をもたらすかを比較検討し，それぞれの有効性を明らかにすることを目指して\nいる．\nフィードバックのタイミングは，先行研究[7] を基に選定した．先行研究では，瞬目促\n進に効果的な4 つの方法が比較され，以下の結果が得られている：\n1. リマインドなし（ベースライン）：瞬目回数が少なく，短い瞬目が多い傾向であった．\n2. 一定（40 秒に1 回）：瞬目回数は増加するが，短い瞬目が増える場合もある．\n3. 瞬目の回数が10 秒あたい2 回以下になった時：瞬目回数が最も増加し，短い瞬目も\n減少する効果が最も高かった．\n4. 質の悪い瞬目が40 秒あたり2 割を超えた時：効果が限定的で，被験者が使いづらい\nと感じる場合があった．\n15\n1.1.4 節で述べたように，通常は1 分間に平均18-22 回である瞬目が，デジタルデバイス\nの使用中には1 分間に5-7 回まで減少してしまう[5]．したがって，本研究では，先行研\n究と同様10 秒ごとにフィードバックを提示するが，基準の設定を通常の平均瞬目回数で\nある「10 秒で3 回以下」とし，基準を満たす場合に提示をするように開発をした．\n3.3.3\nデータ記録機能\nデータ記録機能では，経過時間，瞬目の頻度，フィードバックの有無を10 秒単位で記\n録する．各フィードバックの効果を後述する実験で評価が可能であるように設計されて\nいる．\n3.4\nシステムの利用方法\n本システムの利用方法は以下の通りである．\n1. パソコンでPython アプリケーションを起動する\n2. スマートウォッチを装着し，スマートウォッチアプリを起動する\n3. 動画視聴直前にアプリのウィンドウで「s」を入力し，瞬目の計測を開始する\n4. 計測中はフィードバックが自動で提示されるため，ユーザは動画視聴を続ける\n5. 30 分の実験終了後，「f」を入力して記録データを保存する\n16\n第4章\n瞬目促進システムの効果検証実験\n本章では，瞬目促進システムを用いた評価実験について述べる．評価実験における被験\n者は実験説明を受け，実験に対する同意書による同意をもって，実験に参加する．\n4.1\n実験目的\n本システムは動画視聴中の瞬目回数を増加させることを目的としているため，実験では\n瞬目促進効果やシステムの利便性を評価する．また，実験の流れや評価指標についても詳\n述する．\nフィードバック条件の有効性検証実験の目的は，4 種類の異なるフィードバック手法が，\n瞬目促進に及ぼす効果を比較検討することである．特に，瞬目回数の増加およびユーザ体\n験（視聴体験への影響や不快感の有無）に焦点を当て，それぞれのフィードバック手法の\n有効性を評価する．また，被験者の瞬目行動に対する感覚刺激の適応性や，長時間使用に\nおける実用性を検証することで，瞬目不足が引き起こすドライアイや眼精疲労の軽減に貢\n献する新たなシステム設計の可能性を探る．\n4.2\n実験概要\n瞬目検出条件の最適化実験は，瞬目検出条件の最適化実験とフィードバック条件の有効\n性検証実験の2 段階で構成されている．\n• 瞬目検出条件の最適化実験では，EAR の閾値と連続フレーム数を基準に，瞬目検出\nの最適な条件を調査する\n• フィードバック条件の有効性検証実験では，フィードバックの有無や種類による瞬\n目促進効果を評価する\n4.2.1\n瞬目検出条件の最適化実験の概要\n瞬目検出条件の最適化実験では，瞬目検出の閾値（EAR）の適切な範囲を調査すること\nを目的とし，各被験者に対してEAR の閾値と検出結果の関係を確認した．使用するシス\nテムは，本システムから機能を限定し，アプリの起動時間とEAR の値のみを保存するよ\n17\nうに改良したものを使用する．EAR の値被験者は男女5 名とし，各自が10 分間の動画視\n聴を行い，その間のEAR の変動データを記録した．EAR の閾値は0.00 から0.30 までを\n0.01 刻みで設定し，MATLAB を用いて各閾値ごとの瞬目検出回数を算出する．また，視\n聴中の動画を撮影し，実際の瞬目回数を目視で計測する．得られた実際の瞬目回数と各閾\n値で検出された瞬目回数を比較し，最も実際の回数に近いEAR の閾値を確認することで，\n最適なEAR 閾値を特定する．被験者は成人男性3 名，成人女性2 の計5 名（年齢層は21\n歳から23 歳）に協力してもらった．実験環境の均一性を保つため，被験者にはすべて実験\n者が用意したノートPC を使用させ，視聴する動画はNetFlix から各自で選択させる形式\nとした．被験者は男女10 名で，各自が同様の条件下で実験を行う．また，フィードバッ\nク提示順序による影響を排除するため，提示順序は被験者ごとに異なるように設定する．\n4.2.2\nフィードバック条件の有効性検証実験の概要\nフィードバック条件の有効性検証実験では，異なるフィードバック条件下での瞬目促進\n効果を調査することを目的とし，被験者に動画視聴を行わせながら各種フィードバックの\n影響を確認した．被験者は成人男性8 名，成人女性2 の計10 名（年齢層は21 歳から53\n歳），全員が同じ条件下で実験を実施した．フィードバックは画面のフラッシュ，画面に\nアニメーションGIF の表示，音声による通知，スマートウォッチでの振動とアニメーショ\nンGIF の表示の4 つにフィードバックなしを加えた5 種類である．動画視聴時間は30 分\n間とし，6 分ごとにフィードバックを切り替える設定とした．フィードバックの提示順序\nによる影響を排除するため，提示順序は被験者ごとに異なるようにランダム化した．ま\nた，被験者は動画視聴中に一切の操作を必要とせず，フィードバックの切り替えはすべて\n自動で行われるよう設計した．視聴する動画および視聴環境は瞬目検出条件の最適化実験\nと同様に，被験者自身がNetFlix から選択する形式とし，実験者が用意したノートPC を\n使用させた．\n4.3\n実験手順\n4.3.1\n瞬目検出条件の最適化実験\n瞬目検出条件の最適化実験では，システムによる瞬目検出精度を評価する．実験は以下\nの手順で行う．\n1. 被験者の動画撮影を開始する．\n2. PC でアプリを起動する．\n3. 動画を10 分間視聴する．\n18\n4. データを保存する．\n以下に実験手順のフロー図を図4-1 示す．\n図4-1: 瞬目検出条件の最適化実験の手順を示すフロー図\n4.3.2\nフィードバック条件の有効性検証実験\nフィードバック条件の有効性検証実験は次のような手順で実施する．\n1. PC で動画選択後，アプリを起動する．\n2. 被験者のスマートウォッチを装着してもらい，スマートウォッチのフィードバック\nアプリを起動する．\n3. 被験者にアプリのウィンドウで「s」を入力してもらい，計測を開始する．\n4. 被験者に動画を全画面で30 分視聴する．\n5. 30 分経過後，アプリのウィンドウで「f」を入力してもらい，データを保存する．\n6. アンケートの記入を行う．\n以下に実験手順のフロー図を図4-2 に示す．\n19\n図4-2: フィードバック条件の有効性検証実験の手順を示すフロー図\nフィードバック条件の有効性検証実験では，被験者には瞬目が少なくなった時にフィー\nドバックがある旨の説明のみを行うが，直接的にフィードバックに反応するよう指示はし\nない．瞬目検出条件の最適化実験の目的については説明を省略し，被験者自身が行動変容\nを促し，瞬目が増えるかどうかを検証する．実験の様子を以下の図4-3 に示す．\n図4-3: フィードバック条件の有効性検証実験の様子\n20\n4.4\nデータ分析方法\n本研究では，各フィードバック条件における瞬目回数の違いを統計的に検証するため\nに，分散分析（ANOVA）および事後検定としてTukey の多重比較検定を用いた．\n分散分析（Analysis of Variance，ANOVA）は，複数の群間で観測されたデータの平均\n値に有意差が存在するかを評価するための手法である[24]．この手法は，群内分散と群間\n分散を比較することにより，各条件間の差異が統計的に意味のあるものであるかを検証す\nるために用いられる．本研究では，瞬目回数の分散分析を実施し，フィードバック条件間\nで有意な差が存在するかどうかを検証した．\nさらに，有意差が確認された場合には，Tukey の多重比較検定を実施し，どの条件間で\n有意な差が存在するかを特定した．Tukey の多重比較検定は，ANOVA によって条件間に\n有意差が認められた際に，条件ごとの平均値をペアで比較するための手法である[25]．こ\nの手法は，全体の有意水準（FWER）を保ちながら，すべての条件間の差異を評価するこ\nとを可能にする．本研究では，各条件における瞬目回数の違いを詳細に分析するために，\nこの手法を適用した．\nこれらの手法を用いることで，瞬目促進システムの各フィードバック条件が瞬目回数に\n与える影響を明確化し，条件間の差異を定量的に評価した．\n4.5\nアンケートでの評価方法\nアンケートに基づいて各フィードバックが瞬目を促すのに有効であったか，また動画視\n聴体験を損なわなかったかどうかを尋ねることで，システムの有効性とユーザ体験への影\n響を総合的に評価する．瞬目検出条件の最適化実験で使用したアンケートの内容を以下の\n表4-1 に示す．\n21\n表4-1: 評価実験のアンケート項目\nquestion\nQ1\n実験中にメガネまたはコンタクトを着用していましたか？\nQ2\nドライアイの治療を受けたことがありますか？\nQ3\n普段動画を視聴している際に、瞬きが少ないと感じることはありますか？\nQ4\nフィードバックとして認識できたものを選択してください。\nQ5\n画面がフラッシュのように光るフィードバックについて、\n動画視聴の妨げになる・動画に集中できないと感じましたか？\nQ6\n画面がフラッシュのように光るフィードバックについて、\n瞬きをしようと思う・瞬きをしてしまうと感じましたか？\nQ7\n画面に目が瞬きをするGIF が表示されるフィードバックについて、\n動画視聴の妨げになる・動画に集中できないと感じましたか？\nQ8\n画面に目が瞬きをするGIF が表示されるフィードバックについて、\n瞬きをしようと思う・瞬きをしてしまうと感じましたか？\nQ9\n音が流れるフィードバックについて、動画視聴の妨げになる・\n動画に集中できないと感じましたか？\nQ10\n音が流れるフィードバックについて、瞬きをしようと思う・\n瞬きをしてしまうと感じましたか？\nQ11\nスマートウォッチが振動してGIF が表示されるフィードバックについて、\n動画視聴の妨げになる・動画に集中できないと感じましたか？\nQ12\nスマートウォッチが振動してGIF が表示されるフィードバックについて、\n瞬きをしようと思う・瞬きをしてしまうと感じましたか？\nQ13\n実験で一番印象に残ったフィードバックがあれば教えてください。\n（自由記述）\n22\n第5章\n実験結果及び考察\n5.1\n瞬目検出条件の最適化実験の結果\n瞬目検出条件の最適化実験の結果を以下に示す．闘値設定の違いにより，瞬目検出結果\nは大きく変化することが明らかになった．連続フレーム数を2 とした場合の被験者1 の結\n果を図5-1 に示す．\n図5-1: 連続フレーム数2 における閾値ごとの瞬目検出精度\n被験者1 の結果としては，EAR が0.15 のとき実際の値に一番近く瞬目を検出できるこ\nとが分かった．また，0.15 前後を閾値に設定した場合には比較的安定して瞬目を検出でき\nていることが確認できる．\n1 フレーム，2 フレーム，3 フレームそれぞれの結果を図5-1，図5-2，図5-3 に示す．そ\nれぞれ実際の総瞬目回数と一番近い値に色を付けている．\n23\n表5-1: 連続フレーム数1 における実測瞬目回数とEAR 閾値別検出回数の比較\n閾値（EAR）\n被験者1\n被験者2\n被験者3\n被験者4\n被験者5\n0.05\n43\n0\n0\n4\n67\n0.06\n69\n0\n1\n16\n125\n0.07\n80\n0\n3\n56\n175\n0.08\n86\n0\n5\n148\n209\n0.09\n87\n1\n6\n231\n230\n0.10\n88\n1\n14\n321\n239\n0.11\n87\n7\n23\n353\n252\n0.12\n87\n16\n36\n373\n256\n0.13\n87\n28\n44\n388\n267\n0.14\n90\n38\n48\n392\n268\n0.15\n89\n48\n56\n390\n275\n0.16\n90\n67\n66\n400\n290\n0.17\n91\n77\n100\n401\n291\n0.18\n92\n91\n161\n406\n289\n0.19\n95\n113\n338\n428\n286\n0.20\n93\n121\n566\n504\n303\n0.21\n90\n153\n541\n612\n324\n0.22\n92\n168\n306\n737\n328\n0.23\n96\n289\n236\n895\n329\n0.24\n108\n431\n239\n659\n317\n0.25\n117\n585\n241\n535\n342\n実際の総瞬目回数\n83\n66\n144\n387\n239\n24\n表5-2: 連続フレーム数2 における実測瞬目回数とEAR 閾値別検出回数の比較\n閾値（EAR）\n被験者1\n被験者2\n被験者3\n被験者4\n被験者5\n0.05\n18\n0\n0\n1\n29\n0.06\n33\n0\n0\n3\n66\n0.07\n50\n0\n2\n23\n108\n0.08\n67\n0\n4\n75\n127\n0.09\n72\n0\n4\n155\n147\n0.10\n76\n0\n6\n235\n171\n0.11\n77\n5\n10\n303\n185\n0.12\n79\n11\n19\n341\n198\n0.13\n79\n17\n27\n360\n211\n0.14\n80\n26\n31\n375\n220\n0.15\n82\n33\n37\n383\n235\n0.16\n85\n40\n44\n387\n247\n0.17\n86\n59\n60\n386\n257\n0.18\n86\n65\n86\n391\n264\n0.19\n91\n79\n160\n395\n262\n0.20\n92\n85\n298\n422\n271\n0.21\n89\n100\n364\n468\n280\n0.22\n89\n120\n254\n523\n282\n0.23\n89\n161\n200\n557\n290\n0.24\n94\n251\n214\n435\n291\n0.25\n107\n314\n220\n354\n288\n実際の総瞬目回数\n83\n66\n144\n387\n239\n25\n表5-3: 連続フレーム数3 における実測瞬目回数とEAR 閾値別検出回数の比較\n閾値（EAR）\n被験者1\n被験者2\n被験者3\n被験者4\n被験者5\n0.05\n4\n0\n0\n0\n6\n0.06\n8\n0\n0\n1\n26\n0.07\n11\n0\n0\n7\n37\n0.08\n22\n0\n1\n23\n53\n0.09\n30\n0\n2\n72\n63\n0.10\n38\n0\n2\n133\n78\n0.11\n46\n1\n4\n191\n89\n0.12\n47\n3\n6\n256\n107\n0.13\n54\n10\n10\n292\n115\n0.14\n61\n18\n14\n320\n135\n0.15\n63\n26\n16\n341\n152\n0.16\n69\n29\n21\n356\n163\n0.17\n71\n37\n32\n372\n176\n0.18\n73\n51\n48\n376\n192\n0.19\n77\n59\n88\n383\n207\n0.20\n82\n71\n197\n405\n217\n0.21\n84\n76\n276\n429\n235\n0.22\n85\n101\n208\n463\n248\n0.23\n86\n115\n169\n471\n262\n0.24\n91\n174\n183\n379\n272\n0.25\n101\n229\n197\n288\n275\n実際の総瞬目回数\n83\n66\n144\n387\n239\n各フレーム条件における検出結果を分析したところ，特定のEAR 値（例：0.13～0.17）\nで高い精度が得られることが分かった．1 フレーム条件では，被験者によって最適なEAR\n閾値にばらつきがあり，全体的に安定性に欠けると考えられる．一方，2 フレーム条件で\nはEAR 値0.17 付近が多くの被験者で最適値となり，全体的にバランスの取れた結果を示\nした．このため，実験条件として適用する上で有効であると考えられる．\n3 フレーム条件では，EAR 値0.20 付近で比較的安定した検出が可能であるものの，被\n験者ごとの検出精度にばらつきが見られた．特に，被験者3 では最も近い値でも50 近く\nの誤検出が生じており，全体的に過検出が多い傾向にあることが確認された．瞬目が過検\n出されると，フィードバックの効果検証が正確に行えない可能性があるため，今回の実験\nにおいて3 フレーム条件は適していないと判断される．\n26\n2 フレーム条件は全体的に最も安定した結果を示し，実験条件として適用しやすいと考\nえられる．一方，被験者によって最適なEAR の値にばらつきがあり，被験者ごとの個別\n調整によってさらに精度を高める可能性が示唆された．このため，瞬目検出条件の最適化\n実験では事前に1 分程度を用いて，個別に最適なEAR 閾値を設定する時間を設けること\nとする．\n図5-2 に，EAR が0.05 から0.25 における連続フレーム数2 の条件で得られた精度比較\nを示す．このグラフは，被験者ごとのEAR 閾値における検出精度の分布を視覚的に示し\nており，2 フレーム条件が他の条件と比較して最もバランスの取れた結果を示しているこ\nとを確認できる．\n図5-2: 連続フレーム数2 における閾値ごとの瞬目検出精度\n27\n5.2\nフィードバック条件の有効性検証実験の結果\nフィードバック条件の有効性検証実験の結果を以下に示す．10 人の被験者ごとに各フ\nィードバックにおける10 秒間の瞬目回数の平均を算出し，さらに各被験者の平均から全\n体の平均を算出した．結果を以下の図5-3 に示す．各条件の平均値を比較するために，誤\n差バーとして標準誤差を付加した．これにより，平均値の信頼性を視覚的に示すことが可\n能となった．平均回数を比較すると，フィードバックなしよりも各フィードバックの方\nが瞬目回数は多いことがわかった．また，GIF 表示，短音通知，スマートウォッチによる\nフィードバックの3 条件については，通常時の瞬目回数である「10 秒間に3 回」という基\n準回数を上回る結果となった．\n図5-3: 各フィードバックにおける10 秒の平均瞬目回数\n* : p ＜0.05\n6 分間における10 秒間の瞬目平均回数について，条件間の有意差を検討するために分\n散分析（ANOVA）を実施した．統計解析にはPython（scipy およびstatsmodels ライブラ\nリ）を使用した．分散分析（ANOVA）の結果，フィードバック条件間で統計的に有意な\n差が認められた（F（4, 45）=4.05, p=0.0028）．\nANOVA で有意差が認められたため，どの条件間で差があるのかを明確にするために，\nTukey の多重比較検定を実施した．結果として，以下の条件間で有意な差が認められた．\n• フィードバックなし（none）と音声フィードバック（sound）条件（平均差=0.54, p=0.030）\n• フィードバックなし（none）と視覚フィードバック（watch）条件（平均差=0.60, p=0.011）\n28\n一方，その他の条件間では有意差は認められなかった．Tukey の多重比較検定の結果をま\nとめて表5-4 に示す．\n表5-4: Tukey の多重比較検定による各フィードバック間の有意差\n比較条件（Group1）比較条件（Group ２）平均差\np 値\n信頼区間（Lower, Upper）有意差\nnone\nﬂash\n0.1500\n0.9290\n（-0.3584, 0.6584）\nFALSE\nnone\nGIF\n0.4889\n0.0662\n（-0.0196, 0.9973）\nFALSE\nnone\nsound\n0.5417\n0.0301\n（0.0332, 1.0501）\nTRUE\nnone\nwatch\n0.6000\n0.0113\n（0.0916, 1.1084）\nTRUE\nﬂash\nGIF\n0.3389\n0.3622\n（-0.1696, 0.8473）\nFALSE\nﬂash\nsound\n0.3917\n0.2189\n（-0.1168, 0.9001）\nFALSE\nﬂash\nwatch\n0.4500\n0.1113\n（-0.0584, 0.9584）\nFALSE\nGIF\nsound\n0.0528\n0.9986\n（-0.4557, 0.5612）\nFALSE\nGIF\nwatch\n0.1111\n0.9756\n（-0.3973, 0.6196）\nFALSE\nsound\nwatch\n0.0583\n0.9979\n（-0.4501, 0.5668）\nFALSE\n次に，被験者ごとにフィードバック条件が瞬目回数に与える影響を検討するために，各\n被験者に対して先ほどと同様に分散分析（AVONA）およびTukey の多重比較検定を行っ\nた．その結果，10 名中7 名の被験者において統計的に有意な差が認められた（p ＜0.05）．\n表5-5 に，各被験者の結果を示す．\n29\n表5-5: Tukey の多重比較検定による被験者間の有意差\n被験者\nF 値\np 値\n有意差\n1\n1.60\n0.1773\nFALSE\n2\n3.48\n0.0091\nTRUE\n3\n4.76\n0.0011\nTRUE\n4\n10.03\n＜0.0001\nTRUE\n5\n15.69\n＜0.0001\nTRUE\n6\n2.96\n0.0213\nTRUE\n7\n3.78\n0.0056\nTRUE\n8\n0.55\n0.6981\nFALSE\n9\n2.49\n0.0448\nTRUE\n10\n8.41\n＜0.0001\nTRUE\n被験者2，3，4，5，6，7，10 では，フィードバック条件による瞬目回数の有意な違いが\n認められた（それぞれのp 値は0.05 未満）．特に，被験者4 と被験者5 においては，F 値\nがそれぞれ10.03 および15.69 と非常に高く，フィードバック条件間の違いが顕著である\nことが示唆された．一方，被験者1，8，9 では有意差が認められず（p ＞0.05），フィー\nドバック条件が瞬目回数に与える影響は小さいか，明確ではないことが示唆された．\nさらに，有意差が認められた被験者について，どの条件間で有意な差があるかを特定す\nるためにTukey の多重比較検定を実施した．有意差が認められた条件間を抽出したもの\nを表??に示す．\n被験者2 では，フィードバックなし（none）と音声フィードバック（sound）条件間で有\n意な差が認められた（p=0.0046）．被験者3 では，フラッシュフィードバック（ﬂash）と音\n声フィードバック（sound），および音声フィードバック（sound）と視覚フィードバック\n30\n表5-6: Tukey の多重比較検定による有意差が認められた条件間の比較結果\n被験者\n条件1\n条件2\n平均差\np 値\n有意差\n2\nnone\nsound\n-1.00\n0.0046\nTRUE\n3\nﬂash\nsound\n1.47\n0.0034\nTRUE\n3\nsound\nwatch\n-1.39\n0.0069\nTRUE\n4\nGIF\nsound\n-0.78\n0.0070\nTRUE\n4\nnone\nsound\n-1.36\n＜0.001\nTRUE\n4\nﬂash\nsound\n-1.03\n＜0.001\nTRUE\n4\nsound\nwatch\n1.00\n＜0.001\nTRUE\n5\nnone\nGIF\n-2.72\n＜0.001\nTRUE\n5\nnone\nsound\n-3.11\n＜0.001\nTRUE\n5\nnone\nwatch\n-2.39\n＜0.001\nTRUE\n5\nﬂash\nGIF\n-2.39\n＜0.001\nTRUE\n5\nﬂash\nsound\n-2.78\n＜0.001\nTRUE\n5\nﬂash\nwatch\n-2.06\n＜0.001\nTRUE\n6\nnone\nGIF\n1.63\n0.0109\nTRUE\n7\nﬂash\nwatch\n-1.50\n0.0403\nTRUE\n7\nsound\nwatch\n-1.53\n0.0348\nTRUE\n10\nnone\nGIF\n-2.14\n＜0.001\nTRUE\n10\nnone\nsound\n-1.78\n＜0.001\nTRUE\n10\nnone\nwatch\n-1.69\n＜0.001\nTRUE\n31\n（watch）の間で有意な差が確認された（p=0.0034, p=0.0069）．被験者4 では，GIF フィー\nドバック（GIF）と音声フィードバック（sound），およびフィードバックなし（none）と音\n声フィードバック（sound）で有意な差が認められた（p=0.007, p ＜0.001）．被験者5 で\nは，GIF フィードバック（GIF）とフィードバックなし（none），フラッシュフィードバッ\nク（ﬂash）と音声フィードバック（sound）など複数の条件間で有意な差が確認された（p\n＜0.001）．これらの結果から，フィードバック条件が瞬目回数に与える影響は被験者間で\n異なるものの，多くの場合で特定の条件間において有意な差が生じることが示された．\n5.3\nアンケート結果\n本研究では，瞬目促進システムのフィードバックが動画視聴体験および瞬目行動に与え\nる影響を評価するため，被験者10 名を対象にアンケート調査を実施した．その結果，以\n下の知見が得られた．\n被験者の30 ％がメガネまたはコンタクトを着用し，10 ％がドライアイ治療経験を有し\nていた．また，70 ％が普段動画視聴中に瞬目が少ないと感じると回答した．これにより，\n被験者の中に瞬目不足やドライアイに関心を持つ人が一定数いることが示された．\nフィードバックの認識度では，スマートウォッチの振動が全被験者に認識され，GIF は\n80 ％，音とフラッシュは60 ％の認識度にとどまった．特に優位差が確認された音のフィー\nドバックは認識されないと効果がないため，改善の必要性が示された．\n視聴体験への影響では，フラッシュが「妨げになる」と回答した人が57 ％と最多で，\nGIF は33 ％，スマートウォッチは40 ％，音は50 ％が「妨げになる」と回答した．この\n結果，GIF が最も動画視聴体験への影響が少ないと感じられていることがわかった．\n瞬目促進効果については，GIF が最も高く66.7 ％が「促される」と回答し，フラッシュ\nと音が50 ％，スマートウォッチは40 ％にとどまった．また，「フラッシュは字幕が読み\nにくくなる」といった課題が指摘された一方，GIF は「目立つが不快ではない」と評価さ\nれ，スマートウォッチは視聴体験への影響が少ないとの意見が多かった．\n5.4\n考察\n本研究では，動画視聴中の瞬目を促進するためのフィードバックシステムを提案し，そ\nの効果を評価した．データ分析およびアンケート調査の結果を踏まえ，以下の考察が得ら\nれた．\nまず，瞬目促進効果について，データ分析では音声フィードバックとスマートウォッチ\nによる触覚フィードバックが瞬目回数を有意に増加させることが確認された．一方で，視\n覚的フィードバック（GIF およびフラッシュ）については有意な差が認められなかったが，\n32\nGIF が瞬目促進において一定の効果を示した．これらの結果は，視覚的フィードバックが\n瞬目促進に寄与する可能性を示す一方で，音声や触覚のフィードバックがより強い瞬目促\n進効果を持つことを示唆している．\nアンケート結果では，スマートウォッチの振動は全ての被験者に認識され，視聴体験へ\nの影響がGIF に次いで少ないとの評価を受けた．一方で，音のフィードバックは認識率\nが60 ％と低く，視聴体験において50 ％が「妨げになる」と回答したことから，認識率の\n向上および視聴体験への配慮が必要であることが示唆された．また，視覚的フィードバッ\nクについては，フラッシュが「動画視聴の妨げになる」と回答した被験者が57 ％と最も\n多かったが，GIF については「目立つが不快ではない」との意見が多く，視聴体験を損ね\nない設計の可能性を示している．\nさらに，アンケート自由記述からは，視覚的フィードバックが瞬目を促す効果を持つ一\n方で，「フラッシュの光が動画の字幕を読みにくくする」といった負の影響も指摘された．\nこれに対し，GIF は視覚的に目立つが不快感が少なく，動画視聴体験を損ねにくい特性を\n有していることが確認された．また，被験者の自由記述から，フィードバックの強さやタ\nイミングが視聴体験に大きく影響を与える可能性が示唆された．\n最後に，瞬目促進効果の個人差については，被験者間で有意差の有無やフィードバック\n認識度にばらつきが見られたことから，個別調整が効果的であることが明らかとなった．\n例えば，事前にEAR 閾値やフィードバックの種類を調整することで，より効果的な瞬目\n促進が可能になると考えられる．\nこれらの考察を踏まえ，今後の課題として，（1）フィードバックの認識度を向上させる\n工夫，（2）視聴体験を損ねない設計のさらなる改善，（3）個別最適化による瞬目促進効果\nの強化が挙げられる．本研究は，瞬目促進システムの可能性を示す一方で，改善の余地が\nあることも明確にした．\n33\n第6章\n結論\n6.1\nまとめ\n本研究では，動画視聴中における瞬目不足による健康問題の軽減を目的として，視覚，\n聴覚，触覚を活用した4 種類のフィードバックを提示する瞬目促進システムを提案し，そ\nの効果を評価した．瞬目検出にはEAR（Eye Aspect Ratio）を用い，個別に閾値を調整す\nることで，各被験者に適した瞬目検出が可能であることを確認した．\n実験の結果，音声およびスマートウォッチの振動が瞬目回数を有意に増加させ，視聴体\n験を大きく損ねない効果的なフィードバックであることが示された．一方，視覚的フィー\nドバック（フラッシュおよびGIF）については瞬目促進効果が認められたものの，一部\nで視聴体験を妨げると評価され，特にフラッシュに関しては改善の余地があることが分\nかった．\nまた，アンケート調査では，GIF が視覚的に目立つが不快感は少ないという肯定的な意\n見が多く得られた一方，音やフラッシュの認識率が低い場合もあることが確認された．さ\nらに，瞬目促進効果やフィードバック認識度には個人差が大きいことが示され，個別調整\nの重要性が示唆された．\n以上の結果から，本研究は瞬目促進システムの有効性と課題を明らかにし，瞬目不足の\n軽減に向けた重要な知見を提供した．\n6.2\n今後の展望\n本研究の成果を踏まえ，以下の課題と今後の展望を示す．\nフィードバックの改良\nフィードバックの認識率を向上させ，視聴体験を損ねない設計が求められる．特に，\nフラッシュによる視覚的負担を軽減するための工夫や，音声フィードバックの認識\n率向上に向けた改善が必要である．\n個別調整の強化\n被験者ごとの瞬目促進効果やフィードバック認識度には個人差が大きいため，事前\nに適切な閾値やフィードバックの種類を調整するシステムの自動化が期待される．\n34\n自然な条件下での評価\n本研究では事前説明が瞬目意識に影響を与えた可能性があるため，より自然な状況\nで瞬目促進効果を評価できる実験設計が求められる．これにより，システムの実際\nの使用シーンにおける有効性をより正確に検証できる．\n長期的な影響の評価\n今回の実験は短期間で実施されましたが，長期的な使用が瞬目促進や眼精疲労軽減\nに与える影響を評価することが必要である．これにより，システムの持続的な効果\nを確認できる．\nモバイルデバイスへの対応\nスマートフォンやタブレットなどのモバイルデバイスに対応することで，利用シー\nンが広がると考えられる．特に，ソファでくつろぐようなだらけた姿勢でも瞬目検\n知を可能にすることで，より幅広い動画視聴環境への適応が期待される．また，ス\nマートフォンで動画を視聴する人が多い現状において，これらのデバイスへの対応\nが重要である．\n本研究は瞬目促進システムの可能性を示すとともに，さらなる改善のための方向性を示\nした．これらの課題に取り組むことで，より快適で健康的な動画視聴体験の提供に貢献で\nきると考えられる．\n35\n謝辞\n本研究を進めるうえで，丁寧なご指導を頂きました青山学院大学理工学部情報テクノロ\nジー学科ロペズ・ギヨーム教授に深く感謝をいたします．研究目標を達成するだけでな\nく，高い意欲を継続して研究に取り組むことができたのは，先生の温かく丁寧なご指導の\nおかげです．また，研究環境の補助をしてくださった大熊氏，システム開発にご意見をく\nださった高山先輩をはじめとするロペズ研究室の皆様，同期の方々，評価実験にご協力い\nただいた皆様に心よりお礼申し上げます．\n2025 年1 月27 日\n新村温人\n36\n参考文献\n[1] 総務省：令和6年版情報通信白書データ集(2022). https://www.soumu.go.jp/\njohotsusintokei/whitepaper/ja/r06/html/datashu.html#f00263.\n[2] 厚生労働省：平成２０年技術革新と労働に関する実態調査結果の概況(2008).\nhttps://www.mhlw.go.jp/toukei/itiran/roudou/saigai/anzen/\n08/02.html.\n[3] 第一三共ヘルスケア株式会社：テレワークによる体の不調「テレワーク不調」\nに関する調査(2022).\nhttps://www.soumu.go.jp/johotsusintokei/\nwhitepaper/ja/r06/html/datashu.html#f00263.\n[4] 坪田一男：涙のチカラ涙は7 マイクロリットルの海, 株式会社技術評論社(2008). (参\n照日2025/1/17).\n[5] ウェルビーイングクリニック駒沢公園：デジタル時代における眼精疲労（Digital Eye\nStrain, DES）(2025). https://wbck.tokyo/archives/1353.\n[6] ドライアイ研究会：ドライアイとは. https://dryeye.ne.jp/for-general/\ndryeye-summary/.\n[7] 東覚瑠菜, 神場知成：ドライアイ軽減のためのまばたきリマインド機能の開発と評価,\n情報処理学会インタラクション2024 論文集,pp. 556–561 (2024).\n[8] 大石太郎,戸田健,高橋謙介,劉欣欣：VDT 画面を曇らせることによるVDT 利用者瞬き\n促進システムの試作と評価, 電気学会研究会資料. PI= The papers of Technical Meeting\non” Perception Information”, IEE Japan,/知覚情報研究会[編],Vol. 2014, No. 56-80・\n82-93, 電気学会,pp. 21–23 (2014).\n[9] 伊藤奈々, 武田朴, 笠井亮佑, 上條史記, 加納敬, 島峰徹也, 荻野稔, 日向奈惠, 篠原一彦,\n田仲浩平：VDT 作業における眼精疲労度の比較―スマートグラスとLCD および印\n刷物の比較―, 医療機器学, Vol. 90, No. 5, pp. 405–413 (2020).\n37\n[10] Soukupov´a, T.: Eye-Blink Detection Using Facial Landmarks, Master’s thesis, Czech\nTechnical University in Prague, Faculty of Electrical Engineering (2016). Available at\nftp://cmp.felk.cvut.cz/pub/cmp/articles/cech/Soukupova-TR-2016-05.pdf.\n[11] Maekawa, T. and Inui, T.: 瞬目の模倣が他者の印象に与える影響, 認知心理学研究,\nVol. 16, No. 2, pp. 15–24 (2019).\n[12] 山田冨美雄, 宮田洋：ヒトの驚愕性瞬目反射におよぼす先行刺激効果, 心理学研究,\nVol. 49, No. 6, pp. 349–356 (1979).\n[13] 山田冨美雄：驚愕プローブパラダイムによる感情研究, 日本生理人類学会誌, Vol. 28,\nNo. 3, pp. 45–56 (2023).\n[14] Rushworth, G.: Observations on blink reﬂexes, Journal of neurology, neurosurgery, and\npsychiatry, Vol. 25, No. 2, p. 93 (1962).\n[15] Bin Maneea, M. W., Alamawi, H. O., Almuqbil, A., Abukhlaled, J. K., Alsuwailem, G.,\nAlabdulminaim, J., Aladawi, A. M. M. and Alshangiti, A. Y.: Digital Eye Straining: Ex-\nploring Its Prevalence, Associated Factors, and Effects on the Quality of Life, Cureus,\nVol. 16, No. 5, p. e59442 (online), https://doi.org/10.7759/cureus.59442\n(2024).\n[16] Kaur, K., Gurnani, B., Nayak, S., Deori, N., Kaur, S., Jethani, J., Singh, D., Agarkar,\nS., Hussaindeen, J. R., Sukhija, J. and Mishra, D.: Digital Eye Strain- A Comprehensive\nReview, Ophthalmology and Therapy, Vol. 11, No. 3, pp. 1655–1680 (online), https:\n//doi.org/10.1007/s40123-022-00466-5 (2022).\n[17] Pavel, I. A., Bogdanici, C. M., Donica, V. C., Anton, N., Savu, B., Chiriac, C. P., Pavel,\nC. D. and Salavastru, S. C.: Computer Vision Syndrome: An Ophthalmic Pathology of\nthe Modern Era, Medicina, Vol. 59, No. 2, p. 412 (online), https://doi.org/10.\n3390/medicina59020412 (2023).\n[18] Wickens, C. D.: Multiple resources and performance prediction, Theoretical issues in\nergonomics science, Vol. 3, No. 2, pp. 159–177 (2002).\n[19] 岡村友俊：感覚統合における視・聴・触覚の重要度, 日本感性工学会論文誌, Vol. 11,\nNo. 3, pp. 503–507 (2012).\n[20] Xu, S. and Zhang, X.: Oculomotor trajectory mapping on body as an effective intervention\nto enhance attention, arXiv preprint, Vol. 2307.15172v2 (online), https://arxiv.\norg/abs/2307.15172 (2023).\n38\n[21] NECLAVIE 公式サイト：仕様LAVIE Direct PM(X)［Pro Mobile］- 13.3 型モバイ\nルパソコン. https://lenovo-nec.jp/navigate/products/pc/193q/10/\nlavie/pmx/spec/index.html.\n[22] au: Google Pixel Watch. https://www.au.com/mobile/product/plus-one/\npixelwatch/.\n[23] for Developers, G. A.: MediaPipe ソリューションガイド(2025).\nhttps://ai.\ngoogle.dev/edge/mediapipe/solutions/guide?hl=ja.\n[24] Fisher, R.: Statistical Methods for Research Workers, Biological monographs and manu-\nals, Oliver and Boyd (1925).\n[25] Tukey, J. W.: Comparing individual means in the analysis of variance, Biometrics, pp.\n99–114 (1949).\n39\n質疑応答\n戸辺義人情報テクノロジー学科教授\nQ\n本当に面白い動画ならGIF に気づかないかもしれないと思うのですが，どのように\n考えていますか？\nA\n実際に動画に集中してGIF に気付いていない被験者もいましたが，実験結果として\nはGIF の認識率は80 ％であり，他のフィードバックと比較すると高い認識率でし\nた．今回GIF の表示は画面の上部であるため，今後は認識率を上げるような表示方\n法を検討しています．\n戸辺義人情報テクノロジー学科教授\nQ\nどのようなルールでフィードバックを生成していますか？\nA\n本研究では，10 秒ごとにフィードバックを提示するかの判定を行い，「10 秒間で瞬\n目回数が3 回以下」という条件を満たした場合にフィードバックを提示しています．\n伊藤雄一情報テクノロジー学科教授\nQ\n実験前の指示の際、瞬目を刺激することを説明しましたか？\nA\n今回の実験では，事前説明として「瞬目の回数が少ないときに何らかのフィードバッ\nクがあります．」との旨を伝えています。デバイスの使用中は瞬目が少なくなるため，\n瞬目を意識して行うことが健康的な動画視聴態度に繋がります．したがって，瞬目\nを多少意識してしまうことは問題ないと判断し，事前説明を加えました．\n40\n伊藤雄一情報テクノロジー学科助教授\nQ\nまずどんなフィードバック刺激が瞬目を起こすという基礎実験した方が良いのでは\nないですか？\nA\n本研究では瞬目を多少意識してしまうことは問題ないと判断したため，基礎実験は\n行わずに事前説明を加えて実験を行いました．今後はフィードバック刺激が直接瞬\n目に影響するかを考慮したフィードバック手法の開発も検討しています．\n41\n",
        "chunks": [
            "B2024_HarutoNiimura. B2024_HarutoNiimura. B2024_HarutoNiimura",
            "青山学院大学理工学部\n情報テクノロジー学科\n２０２４年度卒業研究論文\n動画視聴における瞬目促進\nフィードバック手法の検証\n２０２５年１月２８日提出\n指導教員ロペズ・ギヨーム　教授\n提出者学生番号　氏名\n１５８２１０６８新村温人\n青山学院大学 理工学部 情報テクノロジー学科 \n2024（令和6）年度卒業論文要旨 \n- 1 - \n \n動画視聴における \n瞬目促進フィードバック手法の検証 \n \n新村 温人（15821068） \nロペズ研究室 \n \n１．はじめに \n近年，動画配信市場は急速に拡大しており，その市\n場規模は2019年から2024年の4 年間で96%増加し，\n長時間視聴が恒常化している[1]．一方，デジタルデバ\nイスの使用中には瞬目（瞬き）の頻度が大幅に低下し，\nこれがドライアイや眼精疲労を引き起こす要因となり，\n社会的な課題となっている[2]． \n本研究は，眼精疲労やドライアイの対策として，動\n画視聴中の瞬目促進を目的としている．瞬目をリアル\nタイムで検出し，視覚，聴覚，触覚を活用した4 種類\nのフィードバックによって瞬目を促進するシステムを\n提案し，その効果を比較する． \n２．",
            "した4 種類\nのフィードバックによって瞬目を促進するシステムを\n提案し，その効果を比較する． \n２．関連研究 \n東覚らは，ドライアイ軽減のため，瞬目回数を検知\nしリマインドを提示するシステムを提案した[3]．瞬目\nが10 秒間に2 回以下になる条件でリマインドを行う\n方法が最も効果的であり，瞬目の安定化に寄与するこ\nとが示された．一方で，リマインド方法が邪魔と感じ\nやすいという意見があり，他の感覚モダリティ（聴覚\nや触覚など）を用いた比較や評価は行われていない． \n前川らは，瞬目の模倣と印象形成への影響を調査し\nた[4]．その結果，瞬目が同期する画像は非同期の画像\nより好感度が高く評価されることを確認した． \n３．瞬目促進システムの概要 \n本研究では，動画視聴中の瞬目を促進するため，瞬\n目検出とフィードバック提示機能を備えた瞬目促進シ\nステムを開発した．瞬目検出機能，フィードバック提\n示機能と，データ記録機能の3 つで構成される． \n瞬目検出には，MediaPipe ライブラリを使用し，ノ\nートPC の内蔵カメラによる顔のランドマーク検出を\n通じて目の開閉状態を判定する[5]．具体的に",
            "ノ\nートPC の内蔵カメラによる顔のランドマーク検出を\n通じて目の開閉状態を判定する[5]．具体的には，EAR\n（Eye Aspect Ratio）を用い，上下まぶた間の距離が\n一定以下の場合に瞬目と判定する[6]． \nフィードバック提示機能では，視覚2 つ（フラッシ\nュと，アニメーションGIF），聴覚1 つ（短音通知），\n触覚1 つ（スマートウォッチの振動）の4 種類を実装\nした．通常の平均瞬目回数である10 秒間で瞬目回数\nが3 回を基準に設定し，3 回以下になった際にフィー\nドバックを提示する[2]． \nデータ記録機能では，分析のために10 秒ごとの瞬\n目回数とフィードバックの有無を記録する．ユーザは\n動画視聴中，自然な形で瞬目を促進するフィードバッ\nクを受けることで，眼精疲労やドライアイの軽減が期\n待される． \n４．瞬目促進システムの効果検証方法 \nまず，EAR の閾値設定条件を最適化するため，5 名\nを対象として予備実験を実施した．結果，EAR が0.17\nの付近で実際の瞬目回数と検出された瞬目回数が最も\n近似することが確認された． \n \n図1．連続フレーム数 2 における閾",
            "数と検出された瞬目回数が最も\n近似することが確認された． \n \n図1．連続フレーム数 2 における閾値ごとの瞬目検\n出精度 \n一方で，個人差が大きく，各被験者に適した閾値を\n設定する必要があることが分かった．これを踏まえ，\n本実験では被験者ごとに事前調整の時間を設け，適切\nな閾値を設定して実験を進めた． \nそして，4 種類のフィードバックに加えて，フィー\n \n \nドバックなしの5 条件で比較を行うため，30 分間の動\n画視聴中に各条件を6 分ごとにランダムに切り替えた．\n被験者10 名を対象に瞬目回数や視聴体験への影響を\n評価し，アンケートによる各フィードバックの印象や\n視聴体験への影響を調査した． \n５．フィードバック条件の有効性検証結果 \n瞬目促進システムの5 つの条件における瞬目回数の\n結果を図１に示す．10 秒間における瞬目の平均回数は\nフィードバックなしと比べて各フィードバックで増加\nした．また，フラッシュを除く3 つのフィードバック\n方法では基準値である「10 秒間に3 回」を上回った． \nまたTukey の多重比較検定[7]を用いて条件間の差\nを分析した結果を表1 に示す",
            "を上回った． \nまたTukey の多重比較検定[7]を用いて条件間の差\nを分析した結果を表1 に示す．フィードバックなしの\n条件に比べて，音の条件（p=0.03）および，スマート\nウォッチの条件（p=0.01）で瞬目回数が有意に増加し\nたことが確認された．一方，GIF，フラッシュ，音，ス\nマートウォッチの間では統計的に有意な差は認められ\nなかった（p>0.05）． \n次に被験者ごとの有意差を同様に検証した結果，10\n名中8 名で条件間に有意差が確認され，音とスマート\nウォッチの条件で瞬目回数が増加した．一方，被験者\n1 と8 では有意差が見られず，個人差が顕著であるこ\nとがわかった． \nアンケートでは，各フィードバックが視聴体験に影\n響を与えるとの意見がある一方で，GIF や認識されな\nいケースも確認された．また，事前説明により瞬目を\n意識した可能性があり，今後は自然な瞬目促進効果を\n評価する実験方法が必要である．これらの結果は，認\n識度と視聴体験への影響を最適化したフィードバック\n設計が必要であることを示唆している． \n \n図2．10 秒間の平均瞬目回数（* : p < 0.05） ",
            "が必要であることを示唆している． \n \n図2．10 秒間の平均瞬目回数（* : p < 0.05） \n表1．Tukey の多重比較検定による各フィードバッ\nク間の有意差 \n \n６．まとめ \n本研究では，動画視聴中の瞬目促進を目的とした4\n種類のフィードバックシステムを提案し，その効果を\n検証した．結果，音とスマートウォッチのフィードバ\nックが瞬目回数を有意に増加させた．一方でフィード\nバックが認識されない場合があり，設計の改善が必要\nとされた．また，個人差や被験者が瞬目を意識した可\n能性が示唆され，自然な条件下での評価が課題である． \n今後は，モバイルデバイスでの適応型アルゴリズム\nの開発や，瞬目促進による視覚疲労やドライアイ軽減\nの長期的効果の検証を通じて，実用性の向上を目指す． \n参考文献 \n[1] \n総務省: 令和6 年版情報通信白書データ集 \n(2022)\n． \nhttps://www.soumu.go.jp/johotsusintokei/white\npaper/ja/r06/html/datashu.html#f00263．（最終\n閲覧日：2025/1/26） \n[2] \n",
            "html/datashu.html#f00263．（最終\n閲覧日：2025/1/26） \n[2] \nウェルビーイングクリニック駒沢公園: デジタ\nル時代における眼精疲労（Digital EyeStrain， \nDES）https://wbck.tokyo/archives/1353． （最\n終閲覧日：2025/1/26） \n[3] \n東覚瑠菜， 神場知成: ドライアイ軽減のための\nまばたきリマインド機能の開発と評価， インタ\nラクション2024 論文集， 論文ID: 1P-82， pp. \n556-561 (Feb. 2024).  \n[4] \nMaekawa， T. and Inui， T.: 瞬目の模倣が他者\nの印象に与える影響，認知心理学研究，Vol. 16， \nNo. 2， pp. 15–24 (2019)． \n[5] \nGoogle AI for Developers: MediaPipe ソリュー\nシ\nョ\nン\nガ\nイ\nド\nhttps://ai.google.dev/edge/mediapipe/solutions/\nguide?hl=ja. （最終閲覧日：2025/1/26",
            "mediapipe/solutions/\nguide?hl=ja. （最終閲覧日：2025/1/26） \n[6] \nSoukupova， T.， & Cech， J.: Eye blink \ndetection using facial landmarks ， 21st \ncomputer vision winter workshop， Rimske \nToplice， Slovenia， Vol. 2， pp. 1-6 (2016)． \n[7] \nTukey，J. W.: Comparing individual means in \nthe analysis of variance，Biometrics，Vol.5，\nNo.2，pp.99-114 (1949)． \n比較条件（Group1）\n比較条件（Group２）\np値\n有意差\nnone\nflash\n0.9290\nFALSE\nnone\nGIF\n0.0662\nFALSE\nnone\nsound\n0.0301\nTRUE\nnone\nwatch\n0.0113\nTRUE\nflash\nGIF\n0.3622\nFALSE\nflash\nsound\n0.",
            "\n0.0113\nTRUE\nflash\nGIF\n0.3622\nFALSE\nflash\nsound\n0.2189\nFALSE\nflash\nwatch\n0.1113\nFALSE\nGIF\nsound\n0.9986\nFALSE\nGIF\nwatch\n0.9756\nFALSE\nsound\nwatch\n0.9979\nFALSE\n目次\n第1 章\n序章\n1\n1.1\n研究背景. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n1\n1.1.1\n動画配信市場規模の増加. . . . . . . . . . . . . . . . . . . . . . . .\n1\n1.1.2\nVDT 作業における健康問題. . . . . . . . . . . . . . . . . . . . . .\n2\n1.1.3\n涙と瞬目の役割. . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n2\n1.1.4\nVDT 作業と瞬目の関係. . . . . . . . . . . ",
            ". . . .\n2\n1.1.4\nVDT 作業と瞬目の関係. . . . . . . . . . . . . . . . . . . . . . . . .\n3\n1.1.5\nドライアイ患者の割合と瞬目の関係\n. . . . . . . . . . . . . . . . .\n3\n1.2\n研究目的と目標. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n3\n1.3\n本論文の構成. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n4\n第2 章\n関連研究\n5\n2.1\n瞬目に関する研究. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n5\n2.1.1\n瞬目促進のフィードバック提示. . . . . . . . . . . . . . . . . . . .\n5\n2.1.2\n瞬目検出に関する研究. . . . . . . . . . . . . . . . . ",
            "2.1.2\n瞬目検出に関する研究. . . . . . . . . . . . . . . . . . . . . . . . .\n6\n2.1.3\n感覚刺激と瞬目行動の関係に関する論文. . . . . . . . . . . . . . .\n6\n2.2\n目の健康に関する論文. . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n8\n2.2.1\nデジタルデバイスによる目の影響. . . . . . . . . . . . . . . . . . .\n8\n2.3\n注意喚起に関する論文. . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n8\n2.4\n先行研究のまとめ. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n9\n第3 章\n開発システムについて\n10\n3.1\n瞬目促進システムの概要及び提案手法\n. . . . . . . . . . . . . . . . . . . .\n10\n3.2\n瞬",
            "法\n. . . . . . . . . . . . . . . . . . . .\n10\n3.2\n瞬目促進システムのハードウェアの構成. . . . . . . . . . . . . . . . . . .\n10\n3.3\n瞬目促進システムのソフトウェアの構成. . . . . . . . . . . . . . . . . . .\n12\n3.3.1\n瞬目検出機能. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n12\n3.3.2\nフィードバック提示機能. . . . . . . . . . . . . . . . . . . . . . . .\n14\n3.3.3\nデータ記録機能. . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n16\n3.4\nシステムの利用方法\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n16\ni\n第4 章\n瞬目促進システムの効果検証実験\n17\n4.1\n実験目的.",
            ". . . . . .\n16\ni\n第4 章\n瞬目促進システムの効果検証実験\n17\n4.1\n実験目的. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n17\n4.2\n実験概要. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n17\n4.2.1\n瞬目検出条件の最適化実験の概要. . . . . . . . . . . . . . . . . . .\n17\n4.2.2\nフィードバック条件の有効性検証実験の概要. . . . . . . . . . . . .\n18\n4.3\n実験手順. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n18\n4.3.1\n瞬目検出条件の最適化実験\n. . . . . . . . . . . . . . . . . . . . . .\n18\n4.3.2\nフィードバック条件の有効性検証",
            ". . . . . . . . . . . . .\n18\n4.3.2\nフィードバック条件の有効性検証実験\n. . . . . . . . . . . . . . . .\n19\n4.4\nデータ分析方法. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n21\n4.5\nアンケートでの評価方法. . . . . . . . . . . . . . . . . . . . . . . . . . . .\n21\n第5 章\n実験結果及び考察\n23\n5.1\n瞬目検出条件の最適化実験の結果. . . . . . . . . . . . . . . . . . . . . . .\n23\n5.2\nフィードバック条件の有効性検証実験の結果. . . . . . . . . . . . . . . . .\n28\n5.3\nアンケート結果. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n32\n5.4\n考察. . . . . . . . . . . . . ",
            " . . . . . . .\n32\n5.4\n考察. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n32\n第6 章\n結論\n34\n6.1\nまとめ. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n34\n6.2\n今後の展望\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n34\n参考文献\n37\nii\n第1章\n序章\n本章では，社会的な背景をもとに研究の位置付けを明確にする．1.1 節では，研究背景\nとしてコンテンツ視聴における現状と課題について述べる．1.2 節では，背景に挙げた課\n題を踏まえた本研究の目的を定義する．1.3 節では，本論文の構成について述べる．\n1.1\n研究背景\n1.1.1\n動画配信市場規模の増加\n近年，日本で動画配信市場が増加傾向にある．総務省が実施した，消費者が動画配信\nサービス事",
            "規模の増加\n近年，日本で動画配信市場が増加傾向にある．総務省が実施した，消費者が動画配信\nサービス事業者に支払った金額の合計に関する調査の報告によると，2019 年は2,959 億\n円であったのに対し，2023 年は5,704 億円と４年間で96.2 ％の増加を示している[1]．ま\nた，2028 年における予測値は7,371 億円となり，今後も市場規模は拡大していくことが予\n想されている．これにより，動画視聴体験の質向上や健康的な視聴態度の促進が重要な課\n題となっている．\n図1-1: 日本の動画配信市場規模の推移（[1] より引用）\n1\n1.1.2\nVDT 作業における健康問題\nVDT（Visual Display Terminal）作業に伴う健康問題は社会的に注目を集めている．厚\n生労働省の調査では，VDT 作業を行う労働者のうち68.6 ％が身体的疲労を感じており，\nその中でも，図1-2 に示すように「目の疲れ・痛み」を最も多く挙げている（90.8 ％）[2]．\nまた，第一三共ヘルスケア株式会社の調査によれば，図1-3 に示すように，テレワーク中\nの男女において，眼精疲労を訴える割",
            "ケア株式会社の調査によれば，図1-3 に示すように，テレワーク中\nの男女において，眼精疲労を訴える割合は女性22.0 ％，男性15.7 ％であることが示され\nた[3]．これらの結果から，VDT 作業による瞬目頻度の減少が健康に悪影響を及ぼしてい\nることが示唆されている．\n図1-2: VDT 作業における身体的疲労に関する調査データの抜粋（[2] より引用）\n図1-3: テレワークにおける不調内容の男女比較（[3] より引用）\n1.1.3\n涙と瞬目の役割\n涙は多くの役割を持っている．坪田によると，涙は目の表面が必要としているビタミン\n類およびタンパク質などの供給，目の表面の酸化および炎症から目を守る働き，外からの\n侵入物および古くなった細胞のを運び去る役割など多くの役割を持っている[4]．そして，\n瞬目は涙を目の表面を均一に運ぶ役割があり，瞬目を行わないと目の表面が乾燥し，涙が\n作られても上手く分配することが可能でなくなるため，意識的に瞬目を行う必要がある．\n近年人々の涙は減少傾向にあり，その分瞬目の重要度はますます高まっている．\n2\n1.1.4\nVDT 作業と瞬目の関係\nデジタルデバイ",
            "その分瞬目の重要度はますます高まっている．\n2\n1.1.4\nVDT 作業と瞬目の関係\nデジタルデバイスの普及は人々の健康に影響を与えている．ウェルビーイングクリニッ\nク駒沢公園は，DES と呼ばれるデジタルデバイスの長時間使用が引き起こす眼精疲労が\n新たな健康問題として注目されていることを示した[5]．DES の原因として，通常は1 分\n間に平均18-22 回である瞬目が，デジタルデバイスの使用中には1 分間に5-7 回まで減少\nしてしまうことで，目の表面に形成された涙液膜が破れるまでの時間が短縮されることが\n挙げられる．結果としてドライアイ症状の発生が懸念されることが述べられている．\n1.1.5\nドライアイ患者の割合と瞬目の関係\nドライアイは，目を守るために必要な涙の量が不足したり，涙の質のバランスが崩れる\nことで，涙が目全体に均等に行きわたらなくなる病気である．ドライアイ研究会による\nと，高齢化およびエアコンの使用，パソコンおよびスマートフォンの長時間使用，さらに\nはコンタクトレンズの装用者の増加に伴い，ドライアイの患者数は増加しており，その数\nは約2,200 万人にのぼると述べて",
            "の装用者の増加に伴い，ドライアイの患者数は増加しており，その数\nは約2,200 万人にのぼると述べている．[6]．ドライアイは主に涙の量が減少する「量的な\n異常」と，涙の性質および涙を保持する能力が変化する「質的な異常」の2 つに分類する\nことが可能であり，特に「質的な異常」の中には，「ＢＵＴ短縮型ドライアイ」と呼ばれ\nる症状が強いタイプがある．ＢＵＴ短縮型ドライアイは涙の分泌はされるが目の表面で涙\nの膜が安定せず，5 秒以内に涙が乾いてしまうのが特徴であり，VDT 作業の多いオフィス\nワーカーおよびコンタクトレンズ装用者に多く見られる傾向があるとされている．\n1.2\n研究目的と目標\n1.1 節で述べたように，近年，動画配信市場の拡大とともに，動画視聴に伴う健康問題\nの改善が求められている．特に，眼精疲労およびドライアイは，VDT 作業中の瞬目減少\nが一因として挙げられ，重要な課題とされている．本研究では，動画視聴中における瞬目\n促進による健康問題の改善することを目的とする。\n動画視聴中の瞬目回数を検出し，その回数が基準値を下回った場合に適切なフィード\nバックを与えることで，瞬目を促進",
            "の瞬目回数を検出し，その回数が基準値を下回った場合に適切なフィード\nバックを与えることで，瞬目を促進し，健康的な視聴態度を促すシステムの提案と開発を\n目的とする．具体的には，瞬目を検出するアルゴリズムを用いて瞬目の減少をリアルタイ\nムで判断し，基準値未満の場合に画面にフラッシュの表示，GIF 表示，音声再生，または\nスマートウォッチの振動といった4 種類のフィードバックを提供する．さらに，それぞれ\nのフィードバックの有効性を比較・評価する実験を実施し，最適なフィードバック手法を\n探ることを目指す．\n3\n1.3\n本論文の構成\n第1 章では，本論文の研究背景，研究目的，及び本論文の構成について述べた．第2 章\nでは，関連研究について説明する．\n4\n第2章\n関連研究\n本章では，関連研究について述べる．2.1 節では瞬目に関する研究，2.2 節では目の健\n康に関する研究，2.3 節では注意喚起に関する研究について述べる．\n2.1\n瞬目に関する研究\n2.1.1\n瞬目促進のフィードバック提示\n東覚らは，長時間のパソコン作業によるドライアイ軽減を目的とし，瞬目回数を検知し\nて適切なタイミングでリマイ",
            "は，長時間のパソコン作業によるドライアイ軽減を目的とし，瞬目回数を検知し\nて適切なタイミングでリマインドを行うシステムを提案した[7]．図2-1 は，本研究で提\n案されているフィードバック方法である．内蔵カメラとMediaPipe ライブラリを活用し，\n上下まぶた間の距離を基に瞬目を検出する．比較実験では，「10 秒間に瞬目回数が2 回以\n下の場合にリマインド」の条件が最も効果的で，瞬目回数の増加や不完全な瞬目の減少が\n確認された．長時間使用実験でも瞬目の安定化が示され，被験者からの評価も高かった．\n一方で，リマインド方法が邪魔と感じやすいという意見があり，他の感覚モダリティ(聴\n覚や触覚など) を用いた比較や評価は実施されなかった. また，瞬目の質改善にはさらなる\n検証が必要であることが示唆された．\n図2-1: 提案されているフィードバック方法（[7] より引用）\n大石らは，VDT 作業による瞬目減少を防ぎ，ドライアイを軽減するための瞬目促進シ\nステムを提案した[8]．システムは瞬目検出，促進，制御機能から構成され，瞬目減少時\nに画面を白く曇らせることで注意を促すように開発された．従",
            "出，促進，制御機能から構成され，瞬目減少時\nに画面を白く曇らせることで注意を促すように開発された．従来のポップアップ警告では\n効果が限定的であったが，提案された手法は視覚的変化でユーザーの注意を引きやすいと\n5\n考えられた．今後は実証実験を通じて有用性を検証し，適応性の向上が目標として掲げら\nれた．\n伊藤らは，スマートグラス（SG），LCD，紙媒体によるVDT 作業の眼精疲労度を比較\nした[9]．77 名の被験者を対象に，瞬目回数，フリッカー値，高周波成分（HFC）などを\n測定．SG 群は疲労が少なく，紙群は最も強い疲労を示した．SG は視線移動を減らし負\n担軽減に寄与したが，ドライアイ傾向の被験者も存在した．結果は，医療現場でのSG 利\n用時に配慮が必要であることが示唆された．\n2.1.2\n瞬目検出に関する研究\nTereza らは，顔のランドマーク検出を活用した瞬目検出アルゴリズムを提案した[10]．\nランドマーク検出器を用いて眼の特徴点を抽出し，眼の開閉状態を表す指標である「眼裂\n縦横比（EAR）」を計算し，EAR の変動パターンを用いて，瞬目をSupport Vector Mac",
            "横比（EAR）」を計算し，EAR の変動パターンを用いて，瞬目をSupport Vector Machine\n（SVM）およびHidden Markov Model（HMM）を通じて分類・検出した．これらの方法は，\n精度が高く，リアルタイムで動作可能であり，データセット（ZJU，Eyeblink8，Silesian）\nでの評価でも既存手法と比較して良好な結果を示した．瞬目頻度および持続時間といった\n特性を活用し，運転中の眠気検知および注意力監視などの応用が期待された．\n2.1.3\n感覚刺激と瞬目行動の関係に関する論文\n前川らは，瞬目の模倣が無意識に行われる現象と，それが印象形成に与える影響を調査\nした[11]．実験では，ランダムに瞬目する画像が提示されると，参加者も無意識に画像の\n瞬目と同期して瞬目を行うことが確認された．また，参加者の瞬目に同期する画像は，非\n同期の画像よりも好感度が高く評価された．結果として，視覚的に提示された瞬目が観察\n者の瞬目行動を誘発し，模倣行動が他者への好意的印象を促進する可能性が示唆された．\n山田らは，驚愕性瞬目反射に先行刺激が与える影響を調査した[12]",
            "印象を促進する可能性が示唆された．\n山田らは，驚愕性瞬目反射に先行刺激が与える影響を調査した[12]．微弱な先行刺激\n（S1）が強い音刺激（S2）に先行する場合，刺激間隔（ISI）によって反射が抑制または促\n進されることが確認された．特に，ISI が短い場合は反射量が抑制され，長い場合は促進\n効果が見られた．山田らの研究は，視覚および聴覚の刺激が瞬目反射に与える影響を明ら\nかにし，感覚刺激が反応制御に寄与する可能性を示唆した．\n山田らは，驚愕性瞬目反射を用いた「驚愕プローブパラダイム」の手法で感情を定量的\nに評価する研究を行った[13]．急峻な音刺激によって誘発される瞬目反射が，感情状態\n（快・不快）によって促進または抑制される特性を利用している．視覚および嗅覚などの\n感覚刺激を通じ，特定の感情を惹起した際の反射量を測定し，感情状態を客観的に評価す\nる方法論を提案した．また，薬物および遺伝子型，性差が感情処理に与える影響も検討さ\n6\nれた．結果として，驚愕性瞬目反射は他覚的な感情評価の有効な指標となり得ることが示\n唆された．山田らの研究は，感情の評価と健康科学の応用可能性を広げる一助と",
            "効な指標となり得ることが示\n唆された．山田らの研究は，感情の評価と健康科学の応用可能性を広げる一助となる知見\nを提供した．\nRushworth は，瞬目反射がさまざまな刺激（視覚，聴覚，触覚）に応じて引き起こされ\nるメカニズムを調査し，瞬目反射が神経系の病変の診断および評価に役立つ可能性が示さ\nれた[14]．実験では，グラベラ（眉間）へのタップ，強い音，明るい光フラッシュが刺激\nとして使用され，これらがどのように異なる神経経路を活性化するかを解析した．特に，\n明るい光フラッシュは瞬目反射を誘発する有効な刺激であり，その反射の遅延および強度\nが神経系の健康状態を示唆することが分かった．さらに，これらの反射が単なる保護反応\nではなく，感覚入力を統合する複雑なプロセスに関与している可能性も提案された．\n7\n2.2\n目の健康に関する論文\n2.2.1\nデジタルデバイスによる目の影響\nBin らは，デジタルアイストレイン（DES）と呼ばれる，デジタルデバイスを使用すること\nによって引き起こされる眼の不快感および視覚的な問題の普及とその影響を探った[15]．\n大学生を対象に，彼らのデバイス使用時間お",
            "不快感および視覚的な問題の普及とその影響を探った[15]．\n大学生を対象に，彼らのデバイス使用時間および頻度，経験する症状の種類を調査した．\n結果として，67 ％の参加者が1～5 種類の症状を報告し，最も一般的な症状は目の乾燥お\nよび痛み，頭部および首のこりであった．また，デバイス使用時間が長いほど症状が悪化\nする傾向が見られた．研究は，デジタル環境が眼の健康に与える影響を強調し，適切な対\n策および予防策の重要性が示唆された．\nKaur らは，デジタルデバイスの使用が増加する中，DES の症状およびリスク要因，影\n響を受ける人口について詳しく分析した[16]．主な症状には目の乾燥，かゆみ，頭痛，光\nに対する過敏性などがあり，特に学生および若年層に多く見られる．調査結果では，デジ\nタルデバイスの使用時間が長いほど，これらの症状の発生率が高くなることが示された．\nまた，適切な休憩および目のケアが重要であることも強調されていて，全体としてデジタ\nル環境における視覚的健康の重要性と，予防策の必要性を提示した．\nIrina らは，デジタルデバイスの使用に伴う「コンピュータビジョン症候群（CVS）",
            "性を提示した．\nIrina らは，デジタルデバイスの使用に伴う「コンピュータビジョン症候群（CVS）」を\n取り上げた[17]．CVS は長時間の画面使用による視覚的・筋骨格的な症状および行動変\n化を指し，主な症状として視力低下，目の疲れ，頭痛，首および肩の痛み，注意力の低下\nが挙げられていた．研究は，CVS の主な要因として，デバイスの不適切な使用，照明条\n件，長時間の作業，乾燥した環境などを指摘した．特に女性および子ども，スマートフォ\nンの過剰使用者にリスクが高いことが示された．また症状の予防には，20 分ごとに作業\nを中断し，20 秒間，6 メートル（20 フィート）以上離れた場所を見る「20-20-20 ルール」\nおよび目を閉じて2 秒間静止し，その後，まぶたを強く閉じる動作を繰り返す点滅運動な\nどが有効だと提示した．\n2.3\n注意喚起に関する論文\nWickens らは，多重資源理論（Multiple Resource Theory）に基づき，タスク間の干渉を\n予測するモデルを提案した[18]．多重資源理論では，タスクが共有する認知資源（感覚モ\nダリティ，処理段階，符号化の種類な",
            "した[18]．多重資源理論では，タスクが共有する認知資源（感覚モ\nダリティ，処理段階，符号化の種類など）の特性により，干渉の程度が変化することが示\nされた．特に，異なる感覚モダリティ（例：視覚と聴覚）を使用するタスクは，同じモダ\nリティを共有するタスクよりも干渉が少ないとされていた．著者は，音が他の感覚刺激を\n補完し，注意喚起およびタスク切り替えを促進する役割を果たす点を強調し，高負荷環境\n8\nでの実用性を示した．理論とモデルは，操縦士および運転者が複数のタスクを効率的に処\n理する設計への応用可能性があると結論づけた．\n岡村らは，視覚，聴覚，触覚の3 つの感覚刺激が同時に提示された場合の情報統合の特\n性を調査した[19]．結果として，視覚刺激が最も重要であり，触覚は視覚および聴覚に次\nぐ役割を果たすことが示された．また，触覚刺激は他の感覚と相互作用しながら情報統合\nを補完し，注意喚起に寄与する可能性があることを示した．岡村らの研究は，感覚モダリ\nティ間の重要度を明らかにした．\nXu らは，視線移動に基づく触覚フィードバック（eyerofeedback）が注意喚起に与える\n効果を調査した",
            "，視線移動に基づく触覚フィードバック（eyerofeedback）が注意喚起に与える\n効果を調査した[20]．触覚刺激により，被験者は自身の視線挙動と注意状態を自覚しおよ\nびすくなり，特に注意維持が難しい長時間タスクでパフォーマンスが向上した．Xu らの\n研究は，触覚刺激が他の感覚モダリティを補完し，注意喚起を促進する手段として有効で\nあることを示した．\n2.4\n先行研究のまとめ\nこれまでの研究では，感覚刺激を利用した瞬目促進および注意喚起の効果が多く示され\nており，それぞれの感覚モダリティが瞬目行動および視覚健康に与える影響が明らかにさ\nれてきた．しかし，異なる感覚モダリティを比較検討する研究は限られており，それぞれ\nの手法の有効性を包括的に評価する必要がある．本研究では，視覚，聴覚，触覚を活用し\nたフィードバック手法を通じて，瞬目促進における最適な刺激方法を明らかにすることを\n目指す．本研究により，瞬目不足が引き起こす眼精疲労およびドライアイの軽減に寄与\nし，日常生活に適用可能なシステム設計への新たな知見を提供することを目指している．\n9\n第3章\n開発システムについて\n本章では，本",
            "テム設計への新たな知見を提供することを目指している．\n9\n第3章\n開発システムについて\n本章では，本論文が開発および提案する，動画視聴中の瞬目促進システムについて述\nべる．\n3.1\n瞬目促進システムの概要及び提案手法\n本システムは，Python を用いて開発された瞬目検出アプリケーションをベースに構築さ\nれている．動画視聴中に瞬目が減少することによるドライアイのリスクを低減し，視覚の\n健康を維持することを目的として開発された．特に，瞬目の頻度低下による目の乾燥を防\nぎ，ユーザの快適な動画視聴体験を支援することを目指している．\n3.2\n瞬目促進システムのハードウェアの構成\n本研究で使用するノートPC は，図3-1 に示している，NEC 社が開発した「LAVIE Direct\nPM」である[21]．第11 世代のIntel Core i7-1165G7 プロセッサ（基本クロック周波数: 2.80\nGHz）を搭載し，16GB のメモリと512GB のSSD ストレージを備えたノートパソコンで\nある．13.3 インチのフルHD ディスプレイを搭載し，約1.2kg の軽量設計で持ち運びが容\n易で",
            "ある．13.3 インチのフルHD ディスプレイを搭載し，約1.2kg の軽量設計で持ち運びが容\n易である．LAVIE Direct PM は実験システムの動作環境として使用され，Python ベースの\n瞬目検出アプリケーションを実行し，内蔵カメラを用いて被験者の瞬目をリアルタイムで\n計測する役割を果たす．\n10\n図3-1: NEC 社が開発した「LAVIE Direct PM」（[21] より引用）\n本研究で使用するスマートウォッチは，図3-2に示している，Google社が開発した「Google\nPixel Watch」である[22]．GPS および心拍計に加えて，3 軸加速度計，3 軸角速度計，3 軸\n磁力計などの多くのセンサを搭載したスマートウォッチである．瞬目検出条件の最適化実\n験ではフィードバックの一つであるスマートウォッチの振動とGIF の表示を行うために\n用いる．\n図3-2: Google 社が開発した「Google Pixel Watch」（[22] より引用）\n11\n3.3\n瞬目促進システムのソフトウェアの構成\nシステムは，以下の３つの主要機能から構成されている．\n1.",
            "3\n瞬目促進システムのソフトウェアの構成\nシステムは，以下の３つの主要機能から構成されている．\n1. 瞬目検出機能\n2. フィードバック提示機能\n3. データ記録機能\n各機能は相互に連携し，瞬目の検出およびフィードバック提示をリアルタイムで行うよ\nうに設計されている．図3-3 にシステム全体のフロー図を示す．\n図3-3: システム全体のフロー図\n3.3.1\n瞬目検出機能\n瞬目検出機能にはPython のライブラリであるMediaPipe Solutions を使用している．Me-\ndiaPipe Solutions は，アプリケーションに人工知能（AI）および機械学習（ML）の技術\nを迅速に適用するためのライブラリとツールのスイートである[23]．本ソリューション\nはすぐに利用可能で，ニーズに応じたカスタマイズが可能である．MediaPipe Solutions は\nMediaPipe オープンソースプロジェクトの一部であり，提供されるソリューションコード\nをさらにカスタマイズすることで，アプリケーションの特定の要件に対応することが可能\nである．複数の開発プラットフォームに対応しており",
            "，アプリケーションの特定の要件に対応することが可能\nである．複数の開発プラットフォームに対応しており，幅広い用途で活用することが可能\nである．オブジェクト検出，画像・テキスト・短音の分類，画像生成など様々な機能があ\n12\nるが，本研究では顔のランドマーク検出機能を使用し，目の形状から眼の開閉状態を検出\nする．\n瞬目の検出手法として，EAR （Eye Aspect Ratio）を用いる．EAR は目の開閉状態を評\n価するための単一スカラー量であり，目のランドマーク（特徴点）を基に計算される[10]．\n目が開いている間，EAR の値はほぼ一定であり，目が閉じるにつれて値が0 に近づく．本\n指標は，個人差および頭部の姿勢の影響を受けにくく，画像のスケーリングおよび顔の平\n面回転に対して完全に不変です．また，両目は同期して瞬目を行うため，両目のEAR を\n平均して計算します．EAR は以下の式で定義される．\nEAR = ∥p2 −p6∥+ ∥p3 −p5∥\n2 · ∥p1 −p4∥\np1, p4\n目の左右の端点（水平方向の幅を表す）\np2, p6\n目の上下の端点（垂直方向の高さを表す）\np3,",
            "\n目の左右の端点（水平方向の幅を表す）\np2, p6\n目の上下の端点（垂直方向の高さを表す）\np3, p5\n目の垂直方向中央の上下の点（補助的な高さを表す）\nEAR の計算結果例を図3-4 に示す．また，システムにおけるEAR およびEAR の連続フ\nレーム数という2 つの閾値は，瞬目検出条件の最適化実験を基に設定する．\n図3-4: EAR の計算結果例\n13\n3.3.2\nフィードバック提示機能\n瞬目検出条件の最適化実験では，以下の4 種類のフィードバックを実装している．\n1. フラッシュ\n2. アニメーションGIF 表示\n3. 短音通知\n4. スマートウォッチの振動・GIF 表示\n視覚的刺激として，フラッシュとアニメーションGIF の表示を採用した．Rushworth\n（1962）は，視覚刺激を用いた瞬目反射の研究で，強い光フラッシュが反射的な瞬目を誘\n発する有効な刺激であることを示した[14]．本研究では，この知見を基に，瞬目促進を目\n的としたフィードバックとして（図3-5）のような「フラッシュを模倣した白い画面の一\n瞬表示」を採用した．白い画面の表示は，フラッシュと同様に瞬間的な",
            "「フラッシュを模倣した白い画面の一\n瞬表示」を採用した．白い画面の表示は，フラッシュと同様に瞬間的な明暗変化を生じさ\nせるため，視覚的注意を瞬時に引きつけ，瞬目を誘発する可能性がある．このような視覚\n刺激の利用は，瞬目促進システムにおける効果的なフィードバックとして機能することが\n期待される．また，アニメーションGIF の表示は，図3-6 のように画面上部に目が瞬目す\nるアニメーションを表示する．視覚的に提示された瞬目が観察者によって無意識に模倣さ\nれる現象が示されているため[11]，GIF の動きに合わせた模倣行動を通じて自然な瞬目を\n誘発することを目指している．\n図3-5: フラッシュの実装例\n図3-6: アニメーションGIF 表示の実装例\n短音通知は，聴覚的刺激として「ピピッ」と表現される短い音を使用し，瞬目への意識\nを高める役割を果たす．聴覚的刺激は，他の感覚刺激を補完し，注意喚起およびタスクの\n切り替えを促進する効果があるとされており[18]，短い「ピピッ」と表現される音は，瞬\n目不足を自然に意識させ，行動を促進する効果が期待される．また，音刺激は聴覚を通じ\n14\nて瞬間的に",
            "\n目不足を自然に意識させ，行動を促進する効果が期待される．また，音刺激は聴覚を通じ\n14\nて瞬間的に注意を喚起し，反射的な瞬目を誘発する要因であることが示されている[12]．\nこれにより，短音通知は負担を抑えつつ，瞬目促進を効果的に実現する手法として有用で\nあると考えられる．\n触覚的刺激としては，スマートウォッチの振動を採用した．触覚は，視覚および聴覚に\n集中している状況でも有効な代替手段として機能し，負担を抑えながら注意を喚起をする\nことが可能である点で有用性がある[20]．また，Google Pixel Watch の振動機能と画面表\n示を組み合わせ，視覚・触覚の両面から瞬目を意識させるよう設計した（図3-7）．アニ\nメーションGIF の表示は，他の視覚刺激と同様に模倣行動を誘発し，自然な瞬目を促進す\nる狙いがある．\n図3-7: スマートウォッチの振動・GIF 表示の実装性\nこれらのフィードバック手法を用いた実験を通じて，異なる感覚刺激が瞬目促進にどの\nような効果をもたらすかを比較検討し，それぞれの有効性を明らかにすることを目指して\nいる．\nフィードバックのタイミングは，先行研究[",
            "討し，それぞれの有効性を明らかにすることを目指して\nいる．\nフィードバックのタイミングは，先行研究[7] を基に選定した．先行研究では，瞬目促\n進に効果的な4 つの方法が比較され，以下の結果が得られている：\n1. リマインドなし（ベースライン）：瞬目回数が少なく，短い瞬目が多い傾向であった．\n2. 一定（40 秒に1 回）：瞬目回数は増加するが，短い瞬目が増える場合もある．\n3. 瞬目の回数が10 秒あたい2 回以下になった時：瞬目回数が最も増加し，短い瞬目も\n減少する効果が最も高かった．\n4. 質の悪い瞬目が40 秒あたり2 割を超えた時：効果が限定的で，被験者が使いづらい\nと感じる場合があった．\n15\n1.1.4 節で述べたように，通常は1 分間に平均18-22 回である瞬目が，デジタルデバイス\nの使用中には1 分間に5-7 回まで減少してしまう[5]．したがって，本研究では，先行研\n究と同様10 秒ごとにフィードバックを提示するが，基準の設定を通常の平均瞬目回数で\nある「10 秒で3 回以下」とし，基準を満たす場合に提示をするように開発をした．\n3.3.3\nデータ記録機能\nデータ",
            "3 回以下」とし，基準を満たす場合に提示をするように開発をした．\n3.3.3\nデータ記録機能\nデータ記録機能では，経過時間，瞬目の頻度，フィードバックの有無を10 秒単位で記\n録する．各フィードバックの効果を後述する実験で評価が可能であるように設計されて\nいる．\n3.4\nシステムの利用方法\n本システムの利用方法は以下の通りである．\n1. パソコンでPython アプリケーションを起動する\n2. スマートウォッチを装着し，スマートウォッチアプリを起動する\n3. 動画視聴直前にアプリのウィンドウで「s」を入力し，瞬目の計測を開始する\n4. 計測中はフィードバックが自動で提示されるため，ユーザは動画視聴を続ける\n5. 30 分の実験終了後，「f」を入力して記録データを保存する\n16\n第4章\n瞬目促進システムの効果検証実験\n本章では，瞬目促進システムを用いた評価実験について述べる．評価実験における被験\n者は実験説明を受け，実験に対する同意書による同意をもって，実験に参加する．\n4.1\n実験目的\n本システムは動画視聴中の瞬目回数を増加させることを目的としているため，実験では\n瞬目促進効果やシステ",
            "本システムは動画視聴中の瞬目回数を増加させることを目的としているため，実験では\n瞬目促進効果やシステムの利便性を評価する．また，実験の流れや評価指標についても詳\n述する．\nフィードバック条件の有効性検証実験の目的は，4 種類の異なるフィードバック手法が，\n瞬目促進に及ぼす効果を比較検討することである．特に，瞬目回数の増加およびユーザ体\n験（視聴体験への影響や不快感の有無）に焦点を当て，それぞれのフィードバック手法の\n有効性を評価する．また，被験者の瞬目行動に対する感覚刺激の適応性や，長時間使用に\nおける実用性を検証することで，瞬目不足が引き起こすドライアイや眼精疲労の軽減に貢\n献する新たなシステム設計の可能性を探る．\n4.2\n実験概要\n瞬目検出条件の最適化実験は，瞬目検出条件の最適化実験とフィードバック条件の有効\n性検証実験の2 段階で構成されている．\n• 瞬目検出条件の最適化実験では，EAR の閾値と連続フレーム数を基準に，瞬目検出\nの最適な条件を調査する\n• フィードバック条件の有効性検証実験では，フィードバックの有無や種類による瞬\n目促進効果を評価する\n4.2.1\n瞬目検出条件の",
            "性検証実験では，フィードバックの有無や種類による瞬\n目促進効果を評価する\n4.2.1\n瞬目検出条件の最適化実験の概要\n瞬目検出条件の最適化実験では，瞬目検出の閾値（EAR）の適切な範囲を調査すること\nを目的とし，各被験者に対してEAR の閾値と検出結果の関係を確認した．使用するシス\nテムは，本システムから機能を限定し，アプリの起動時間とEAR の値のみを保存するよ\n17\nうに改良したものを使用する．EAR の値被験者は男女5 名とし，各自が10 分間の動画視\n聴を行い，その間のEAR の変動データを記録した．EAR の閾値は0.00 から0.30 までを\n0.01 刻みで設定し，MATLAB を用いて各閾値ごとの瞬目検出回数を算出する．また，視\n聴中の動画を撮影し，実際の瞬目回数を目視で計測する．得られた実際の瞬目回数と各閾\n値で検出された瞬目回数を比較し，最も実際の回数に近いEAR の閾値を確認することで，\n最適なEAR 閾値を特定する．被験者は成人男性3 名，成人女性2 の計5 名（年齢層は21\n歳から23 歳）に協力してもらった．実験環境の均一性を保つため，被験者にはすべて実験\n",
            "年齢層は21\n歳から23 歳）に協力してもらった．実験環境の均一性を保つため，被験者にはすべて実験\n者が用意したノートPC を使用させ，視聴する動画はNetFlix から各自で選択させる形式\nとした．被験者は男女10 名で，各自が同様の条件下で実験を行う．また，フィードバッ\nク提示順序による影響を排除するため，提示順序は被験者ごとに異なるように設定する．\n4.2.2\nフィードバック条件の有効性検証実験の概要\nフィードバック条件の有効性検証実験では，異なるフィードバック条件下での瞬目促進\n効果を調査することを目的とし，被験者に動画視聴を行わせながら各種フィードバックの\n影響を確認した．被験者は成人男性8 名，成人女性2 の計10 名（年齢層は21 歳から53\n歳），全員が同じ条件下で実験を実施した．フィードバックは画面のフラッシュ，画面に\nアニメーションGIF の表示，音声による通知，スマートウォッチでの振動とアニメーショ\nンGIF の表示の4 つにフィードバックなしを加えた5 種類である．動画視聴時間は30 分\n間とし，6 分ごとにフィードバックを切り替える設定とした．フィードバックの",
            "．動画視聴時間は30 分\n間とし，6 分ごとにフィードバックを切り替える設定とした．フィードバックの提示順序\nによる影響を排除するため，提示順序は被験者ごとに異なるようにランダム化した．ま\nた，被験者は動画視聴中に一切の操作を必要とせず，フィードバックの切り替えはすべて\n自動で行われるよう設計した．視聴する動画および視聴環境は瞬目検出条件の最適化実験\nと同様に，被験者自身がNetFlix から選択する形式とし，実験者が用意したノートPC を\n使用させた．\n4.3\n実験手順\n4.3.1\n瞬目検出条件の最適化実験\n瞬目検出条件の最適化実験では，システムによる瞬目検出精度を評価する．実験は以下\nの手順で行う．\n1. 被験者の動画撮影を開始する．\n2. PC でアプリを起動する．\n3. 動画を10 分間視聴する．\n18\n4. データを保存する．\n以下に実験手順のフロー図を図4-1 示す．\n図4-1: 瞬目検出条件の最適化実験の手順を示すフロー図\n4.3.2\nフィードバック条件の有効性検証実験\nフィードバック条件の有効性検証実験は次のような手順で実施する．\n1. PC で動画選択後，アプリを起動",
            "ィードバック条件の有効性検証実験は次のような手順で実施する．\n1. PC で動画選択後，アプリを起動する．\n2. 被験者のスマートウォッチを装着してもらい，スマートウォッチのフィードバック\nアプリを起動する．\n3. 被験者にアプリのウィンドウで「s」を入力してもらい，計測を開始する．\n4. 被験者に動画を全画面で30 分視聴する．\n5. 30 分経過後，アプリのウィンドウで「f」を入力してもらい，データを保存する．\n6. アンケートの記入を行う．\n以下に実験手順のフロー図を図4-2 に示す．\n19\n図4-2: フィードバック条件の有効性検証実験の手順を示すフロー図\nフィードバック条件の有効性検証実験では，被験者には瞬目が少なくなった時にフィー\nドバックがある旨の説明のみを行うが，直接的にフィードバックに反応するよう指示はし\nない．瞬目検出条件の最適化実験の目的については説明を省略し，被験者自身が行動変容\nを促し，瞬目が増えるかどうかを検証する．実験の様子を以下の図4-3 に示す．\n図4-3: フィードバック条件の有効性検証実験の様子\n20\n4.4\nデータ分析方法\n本研究では，各フィード",
            "3: フィードバック条件の有効性検証実験の様子\n20\n4.4\nデータ分析方法\n本研究では，各フィードバック条件における瞬目回数の違いを統計的に検証するため\nに，分散分析（ANOVA）および事後検定としてTukey の多重比較検定を用いた．\n分散分析（Analysis of Variance，ANOVA）は，複数の群間で観測されたデータの平均\n値に有意差が存在するかを評価するための手法である[24]．この手法は，群内分散と群間\n分散を比較することにより，各条件間の差異が統計的に意味のあるものであるかを検証す\nるために用いられる．本研究では，瞬目回数の分散分析を実施し，フィードバック条件間\nで有意な差が存在するかどうかを検証した．\nさらに，有意差が確認された場合には，Tukey の多重比較検定を実施し，どの条件間で\n有意な差が存在するかを特定した．Tukey の多重比較検定は，ANOVA によって条件間に\n有意差が認められた際に，条件ごとの平均値をペアで比較するための手法である[25]．こ\nの手法は，全体の有意水準（FWER）を保ちながら，すべての条件間の差異を評価するこ\nとを可能にする．",
            "の手法は，全体の有意水準（FWER）を保ちながら，すべての条件間の差異を評価するこ\nとを可能にする．本研究では，各条件における瞬目回数の違いを詳細に分析するために，\nこの手法を適用した．\nこれらの手法を用いることで，瞬目促進システムの各フィードバック条件が瞬目回数に\n与える影響を明確化し，条件間の差異を定量的に評価した．\n4.5\nアンケートでの評価方法\nアンケートに基づいて各フィードバックが瞬目を促すのに有効であったか，また動画視\n聴体験を損なわなかったかどうかを尋ねることで，システムの有効性とユーザ体験への影\n響を総合的に評価する．瞬目検出条件の最適化実験で使用したアンケートの内容を以下の\n表4-1 に示す．\n21\n表4-1: 評価実験のアンケート項目\nquestion\nQ1\n実験中にメガネまたはコンタクトを着用していましたか？\nQ2\nドライアイの治療を受けたことがありますか？\nQ3\n普段動画を視聴している際に、瞬きが少ないと感じることはありますか？\nQ4\nフィードバックとして認識できたものを選択してください。\nQ5\n画面がフラッシュのように光るフィードバックについて、\n動画視聴の妨",
            "たものを選択してください。\nQ5\n画面がフラッシュのように光るフィードバックについて、\n動画視聴の妨げになる・動画に集中できないと感じましたか？\nQ6\n画面がフラッシュのように光るフィードバックについて、\n瞬きをしようと思う・瞬きをしてしまうと感じましたか？\nQ7\n画面に目が瞬きをするGIF が表示されるフィードバックについて、\n動画視聴の妨げになる・動画に集中できないと感じましたか？\nQ8\n画面に目が瞬きをするGIF が表示されるフィードバックについて、\n瞬きをしようと思う・瞬きをしてしまうと感じましたか？\nQ9\n音が流れるフィードバックについて、動画視聴の妨げになる・\n動画に集中できないと感じましたか？\nQ10\n音が流れるフィードバックについて、瞬きをしようと思う・\n瞬きをしてしまうと感じましたか？\nQ11\nスマートウォッチが振動してGIF が表示されるフィードバックについて、\n動画視聴の妨げになる・動画に集中できないと感じましたか？\nQ12\nスマートウォッチが振動してGIF が表示されるフィードバックについて、\n瞬きをしようと思う・瞬きをしてしまうと感じましたか？\nQ13\n実験で",
            "されるフィードバックについて、\n瞬きをしようと思う・瞬きをしてしまうと感じましたか？\nQ13\n実験で一番印象に残ったフィードバックがあれば教えてください。\n（自由記述）\n22\n第5章\n実験結果及び考察\n5.1\n瞬目検出条件の最適化実験の結果\n瞬目検出条件の最適化実験の結果を以下に示す．闘値設定の違いにより，瞬目検出結果\nは大きく変化することが明らかになった．連続フレーム数を2 とした場合の被験者1 の結\n果を図5-1 に示す．\n図5-1: 連続フレーム数2 における閾値ごとの瞬目検出精度\n被験者1 の結果としては，EAR が0.15 のとき実際の値に一番近く瞬目を検出できるこ\nとが分かった．また，0.15 前後を閾値に設定した場合には比較的安定して瞬目を検出でき\nていることが確認できる．\n1 フレーム，2 フレーム，3 フレームそれぞれの結果を図5-1，図5-2，図5-3 に示す．そ\nれぞれ実際の総瞬目回数と一番近い値に色を付けている．\n23\n表5-1: 連続フレーム数1 における実測瞬目回数とEAR 閾値別検出回数の比較\n閾値（EAR）\n被験者1\n被験者2\n被験者3\n被験者4\n被験者",
            "目回数とEAR 閾値別検出回数の比較\n閾値（EAR）\n被験者1\n被験者2\n被験者3\n被験者4\n被験者5\n0.05\n43\n0\n0\n4\n67\n0.06\n69\n0\n1\n16\n125\n0.07\n80\n0\n3\n56\n175\n0.08\n86\n0\n5\n148\n209\n0.09\n87\n1\n6\n231\n230\n0.10\n88\n1\n14\n321\n239\n0.11\n87\n7\n23\n353\n252\n0.12\n87\n16\n36\n373\n256\n0.13\n87\n28\n44\n388\n267\n0.14\n90\n38\n48\n392\n268\n0.15\n89\n48\n56\n390\n275\n0.16\n90\n67\n66\n400\n290\n0.17\n91\n77\n100\n401\n291\n0.18\n92\n91\n161\n406\n289\n0.19\n95\n113\n338\n428\n286\n0.20\n93\n121\n566\n504\n303\n0.21\n90\n153\n541\n612\n324\n0.22\n92\n168\n306\n737\n328\n0.23\n96\n289\n236\n895\n329\n0.24\n108\n431\n239\n659\n317\n0.25\n117\n5",
            "89\n236\n895\n329\n0.24\n108\n431\n239\n659\n317\n0.25\n117\n585\n241\n535\n342\n実際の総瞬目回数\n83\n66\n144\n387\n239\n24\n表5-2: 連続フレーム数2 における実測瞬目回数とEAR 閾値別検出回数の比較\n閾値（EAR）\n被験者1\n被験者2\n被験者3\n被験者4\n被験者5\n0.05\n18\n0\n0\n1\n29\n0.06\n33\n0\n0\n3\n66\n0.07\n50\n0\n2\n23\n108\n0.08\n67\n0\n4\n75\n127\n0.09\n72\n0\n4\n155\n147\n0.10\n76\n0\n6\n235\n171\n0.11\n77\n5\n10\n303\n185\n0.12\n79\n11\n19\n341\n198\n0.13\n79\n17\n27\n360\n211\n0.14\n80\n26\n31\n375\n220\n0.15\n82\n33\n37\n383\n235\n0.16\n85\n40\n44\n387\n247\n0.17\n86\n59\n60\n386\n257\n0.18\n86\n65\n86\n391\n264\n0.19\n91\n79\n160\n395\n262\n0.20\n92\n85\n298\n422\n27",
            "1\n264\n0.19\n91\n79\n160\n395\n262\n0.20\n92\n85\n298\n422\n271\n0.21\n89\n100\n364\n468\n280\n0.22\n89\n120\n254\n523\n282\n0.23\n89\n161\n200\n557\n290\n0.24\n94\n251\n214\n435\n291\n0.25\n107\n314\n220\n354\n288\n実際の総瞬目回数\n83\n66\n144\n387\n239\n25\n表5-3: 連続フレーム数3 における実測瞬目回数とEAR 閾値別検出回数の比較\n閾値（EAR）\n被験者1\n被験者2\n被験者3\n被験者4\n被験者5\n0.05\n4\n0\n0\n0\n6\n0.06\n8\n0\n0\n1\n26\n0.07\n11\n0\n0\n7\n37\n0.08\n22\n0\n1\n23\n53\n0.09\n30\n0\n2\n72\n63\n0.10\n38\n0\n2\n133\n78\n0.11\n46\n1\n4\n191\n89\n0.12\n47\n3\n6\n256\n107\n0.13\n54\n10\n10\n292\n115\n0.14\n61\n18\n14\n320\n135\n0.15\n63\n26\n16\n341\n152\n0.16\n69\n29\n21\n3",
            "8\n14\n320\n135\n0.15\n63\n26\n16\n341\n152\n0.16\n69\n29\n21\n356\n163\n0.17\n71\n37\n32\n372\n176\n0.18\n73\n51\n48\n376\n192\n0.19\n77\n59\n88\n383\n207\n0.20\n82\n71\n197\n405\n217\n0.21\n84\n76\n276\n429\n235\n0.22\n85\n101\n208\n463\n248\n0.23\n86\n115\n169\n471\n262\n0.24\n91\n174\n183\n379\n272\n0.25\n101\n229\n197\n288\n275\n実際の総瞬目回数\n83\n66\n144\n387\n239\n各フレーム条件における検出結果を分析したところ，特定のEAR 値（例：0.13～0.17）\nで高い精度が得られることが分かった．1 フレーム条件では，被験者によって最適なEAR\n閾値にばらつきがあり，全体的に安定性に欠けると考えられる．一方，2 フレーム条件で\nはEAR 値0.17 付近が多くの被験者で最適値となり，全体的にバランスの取れた結果を示\nした．このため，実験条件として適用する上で有効であると考えられ",
            "り，全体的にバランスの取れた結果を示\nした．このため，実験条件として適用する上で有効であると考えられる．\n3 フレーム条件では，EAR 値0.20 付近で比較的安定した検出が可能であるものの，被\n験者ごとの検出精度にばらつきが見られた．特に，被験者3 では最も近い値でも50 近く\nの誤検出が生じており，全体的に過検出が多い傾向にあることが確認された．瞬目が過検\n出されると，フィードバックの効果検証が正確に行えない可能性があるため，今回の実験\nにおいて3 フレーム条件は適していないと判断される．\n26\n2 フレーム条件は全体的に最も安定した結果を示し，実験条件として適用しやすいと考\nえられる．一方，被験者によって最適なEAR の値にばらつきがあり，被験者ごとの個別\n調整によってさらに精度を高める可能性が示唆された．このため，瞬目検出条件の最適化\n実験では事前に1 分程度を用いて，個別に最適なEAR 閾値を設定する時間を設けること\nとする．\n図5-2 に，EAR が0.05 から0.25 における連続フレーム数2 の条件で得られた精度比較\nを示す．このグラフは，被験者ごとのEAR 閾値にお",
            "おける連続フレーム数2 の条件で得られた精度比較\nを示す．このグラフは，被験者ごとのEAR 閾値における検出精度の分布を視覚的に示し\nており，2 フレーム条件が他の条件と比較して最もバランスの取れた結果を示しているこ\nとを確認できる．\n図5-2: 連続フレーム数2 における閾値ごとの瞬目検出精度\n27\n5.2\nフィードバック条件の有効性検証実験の結果\nフィードバック条件の有効性検証実験の結果を以下に示す．10 人の被験者ごとに各フ\nィードバックにおける10 秒間の瞬目回数の平均を算出し，さらに各被験者の平均から全\n体の平均を算出した．結果を以下の図5-3 に示す．各条件の平均値を比較するために，誤\n差バーとして標準誤差を付加した．これにより，平均値の信頼性を視覚的に示すことが可\n能となった．平均回数を比較すると，フィードバックなしよりも各フィードバックの方\nが瞬目回数は多いことがわかった．また，GIF 表示，短音通知，スマートウォッチによる\nフィードバックの3 条件については，通常時の瞬目回数である「10 秒間に3 回」という基\n準回数を上回る結果となった．\n図5-3: 各フィードバッ",
            "目回数である「10 秒間に3 回」という基\n準回数を上回る結果となった．\n図5-3: 各フィードバックにおける10 秒の平均瞬目回数\n* : p ＜0.05\n6 分間における10 秒間の瞬目平均回数について，条件間の有意差を検討するために分\n散分析（ANOVA）を実施した．統計解析にはPython（scipy およびstatsmodels ライブラ\nリ）を使用した．分散分析（ANOVA）の結果，フィードバック条件間で統計的に有意な\n差が認められた（F（4, 45）=4.05, p=0.0028）．\nANOVA で有意差が認められたため，どの条件間で差があるのかを明確にするために，\nTukey の多重比較検定を実施した．結果として，以下の条件間で有意な差が認められた．\n• フィードバックなし（none）と音声フィードバック（sound）条件（平均差=0.54, p=0.030）\n• フィードバックなし（none）と視覚フィードバック（watch）条件（平均差=0.60, p=0.011）\n28\n一方，その他の条件間では有意差は認められなかった．Tukey の多重比較検定の結果をま\nとめて",
            "28\n一方，その他の条件間では有意差は認められなかった．Tukey の多重比較検定の結果をま\nとめて表5-4 に示す．\n表5-4: Tukey の多重比較検定による各フィードバック間の有意差\n比較条件（Group1）比較条件（Group ２）平均差\np 値\n信頼区間（Lower, Upper）有意差\nnone\nﬂash\n0.1500\n0.9290\n（-0.3584, 0.6584）\nFALSE\nnone\nGIF\n0.4889\n0.0662\n（-0.0196, 0.9973）\nFALSE\nnone\nsound\n0.5417\n0.0301\n（0.0332, 1.0501）\nTRUE\nnone\nwatch\n0.6000\n0.0113\n（0.0916, 1.1084）\nTRUE\nﬂash\nGIF\n0.3389\n0.3622\n（-0.1696, 0.8473）\nFALSE\nﬂash\nsound\n0.3917\n0.2189\n（-0.1168, 0.9001）\nFALSE\nﬂash\nwatch\n0.4500\n0.1113\n（-0.0584, 0.9584）\nFALSE\nGIF\nsound\n0.052",
            "500\n0.1113\n（-0.0584, 0.9584）\nFALSE\nGIF\nsound\n0.0528\n0.9986\n（-0.4557, 0.5612）\nFALSE\nGIF\nwatch\n0.1111\n0.9756\n（-0.3973, 0.6196）\nFALSE\nsound\nwatch\n0.0583\n0.9979\n（-0.4501, 0.5668）\nFALSE\n次に，被験者ごとにフィードバック条件が瞬目回数に与える影響を検討するために，各\n被験者に対して先ほどと同様に分散分析（AVONA）およびTukey の多重比較検定を行っ\nた．その結果，10 名中7 名の被験者において統計的に有意な差が認められた（p ＜0.05）．\n表5-5 に，各被験者の結果を示す．\n29\n表5-5: Tukey の多重比較検定による被験者間の有意差\n被験者\nF 値\np 値\n有意差\n1\n1.60\n0.1773\nFALSE\n2\n3.48\n0.0091\nTRUE\n3\n4.76\n0.0011\nTRUE\n4\n10.03\n＜0.0001\nTRUE\n5\n15.69\n＜0.0001\nTRUE\n6\n2.96\n0.0213\nTRU",
            "0.0001\nTRUE\n5\n15.69\n＜0.0001\nTRUE\n6\n2.96\n0.0213\nTRUE\n7\n3.78\n0.0056\nTRUE\n8\n0.55\n0.6981\nFALSE\n9\n2.49\n0.0448\nTRUE\n10\n8.41\n＜0.0001\nTRUE\n被験者2，3，4，5，6，7，10 では，フィードバック条件による瞬目回数の有意な違いが\n認められた（それぞれのp 値は0.05 未満）．特に，被験者4 と被験者5 においては，F 値\nがそれぞれ10.03 および15.69 と非常に高く，フィードバック条件間の違いが顕著である\nことが示唆された．一方，被験者1，8，9 では有意差が認められず（p ＞0.05），フィー\nドバック条件が瞬目回数に与える影響は小さいか，明確ではないことが示唆された．\nさらに，有意差が認められた被験者について，どの条件間で有意な差があるかを特定す\nるためにTukey の多重比較検定を実施した．有意差が認められた条件間を抽出したもの\nを表??に示す．\n被験者2 では，フィードバックなし（none）と音声フィードバック（sound）条件間で有\n意な差が認め",
            "者2 では，フィードバックなし（none）と音声フィードバック（sound）条件間で有\n意な差が認められた（p=0.0046）．被験者3 では，フラッシュフィードバック（ﬂash）と音\n声フィードバック（sound），および音声フィードバック（sound）と視覚フィードバック\n30\n表5-6: Tukey の多重比較検定による有意差が認められた条件間の比較結果\n被験者\n条件1\n条件2\n平均差\np 値\n有意差\n2\nnone\nsound\n-1.00\n0.0046\nTRUE\n3\nﬂash\nsound\n1.47\n0.0034\nTRUE\n3\nsound\nwatch\n-1.39\n0.0069\nTRUE\n4\nGIF\nsound\n-0.78\n0.0070\nTRUE\n4\nnone\nsound\n-1.36\n＜0.001\nTRUE\n4\nﬂash\nsound\n-1.03\n＜0.001\nTRUE\n4\nsound\nwatch\n1.00\n＜0.001\nTRUE\n5\nnone\nGIF\n-2.72\n＜0.001\nTRUE\n5\nnone\nsound\n-3.11\n＜0.001\nTRUE\n5\nnone\nwatch\n-2.39",
            "\n5\nnone\nsound\n-3.11\n＜0.001\nTRUE\n5\nnone\nwatch\n-2.39\n＜0.001\nTRUE\n5\nﬂash\nGIF\n-2.39\n＜0.001\nTRUE\n5\nﬂash\nsound\n-2.78\n＜0.001\nTRUE\n5\nﬂash\nwatch\n-2.06\n＜0.001\nTRUE\n6\nnone\nGIF\n1.63\n0.0109\nTRUE\n7\nﬂash\nwatch\n-1.50\n0.0403\nTRUE\n7\nsound\nwatch\n-1.53\n0.0348\nTRUE\n10\nnone\nGIF\n-2.14\n＜0.001\nTRUE\n10\nnone\nsound\n-1.78\n＜0.001\nTRUE\n10\nnone\nwatch\n-1.69\n＜0.001\nTRUE\n31\n（watch）の間で有意な差が確認された（p=0.0034, p=0.0069）．被験者4 では，GIF フィー\nドバック（GIF）と音声フィードバック（sound），およびフィードバックなし（none）と音\n声フィードバック（sound）で有意な差が認められた（p=0.007, p ＜0.001）．被験者5 で\n",
            "ードバック（sound）で有意な差が認められた（p=0.007, p ＜0.001）．被験者5 で\nは，GIF フィードバック（GIF）とフィードバックなし（none），フラッシュフィードバッ\nク（ﬂash）と音声フィードバック（sound）など複数の条件間で有意な差が確認された（p\n＜0.001）．これらの結果から，フィードバック条件が瞬目回数に与える影響は被験者間で\n異なるものの，多くの場合で特定の条件間において有意な差が生じることが示された．\n5.3\nアンケート結果\n本研究では，瞬目促進システムのフィードバックが動画視聴体験および瞬目行動に与え\nる影響を評価するため，被験者10 名を対象にアンケート調査を実施した．その結果，以\n下の知見が得られた．\n被験者の30 ％がメガネまたはコンタクトを着用し，10 ％がドライアイ治療経験を有し\nていた．また，70 ％が普段動画視聴中に瞬目が少ないと感じると回答した．これにより，\n被験者の中に瞬目不足やドライアイに関心を持つ人が一定数いることが示された．\nフィードバックの認識度では，スマートウォッチの振動が全被験者に認識され，GIF は\n80",
            "示された．\nフィードバックの認識度では，スマートウォッチの振動が全被験者に認識され，GIF は\n80 ％，音とフラッシュは60 ％の認識度にとどまった．特に優位差が確認された音のフィー\nドバックは認識されないと効果がないため，改善の必要性が示された．\n視聴体験への影響では，フラッシュが「妨げになる」と回答した人が57 ％と最多で，\nGIF は33 ％，スマートウォッチは40 ％，音は50 ％が「妨げになる」と回答した．この\n結果，GIF が最も動画視聴体験への影響が少ないと感じられていることがわかった．\n瞬目促進効果については，GIF が最も高く66.7 ％が「促される」と回答し，フラッシュ\nと音が50 ％，スマートウォッチは40 ％にとどまった．また，「フラッシュは字幕が読み\nにくくなる」といった課題が指摘された一方，GIF は「目立つが不快ではない」と評価さ\nれ，スマートウォッチは視聴体験への影響が少ないとの意見が多かった．\n5.4\n考察\n本研究では，動画視聴中の瞬目を促進するためのフィードバックシステムを提案し，そ\nの効果を評価した．データ分析およびアンケート調査の結果を踏まえ，",
            "フィードバックシステムを提案し，そ\nの効果を評価した．データ分析およびアンケート調査の結果を踏まえ，以下の考察が得ら\nれた．\nまず，瞬目促進効果について，データ分析では音声フィードバックとスマートウォッチ\nによる触覚フィードバックが瞬目回数を有意に増加させることが確認された．一方で，視\n覚的フィードバック（GIF およびフラッシュ）については有意な差が認められなかったが，\n32\nGIF が瞬目促進において一定の効果を示した．これらの結果は，視覚的フィードバックが\n瞬目促進に寄与する可能性を示す一方で，音声や触覚のフィードバックがより強い瞬目促\n進効果を持つことを示唆している．\nアンケート結果では，スマートウォッチの振動は全ての被験者に認識され，視聴体験へ\nの影響がGIF に次いで少ないとの評価を受けた．一方で，音のフィードバックは認識率\nが60 ％と低く，視聴体験において50 ％が「妨げになる」と回答したことから，認識率の\n向上および視聴体験への配慮が必要であることが示唆された．また，視覚的フィードバッ\nクについては，フラッシュが「動画視聴の妨げになる」と回答した被験者が57 ％と最も",
            "覚的フィードバッ\nクについては，フラッシュが「動画視聴の妨げになる」と回答した被験者が57 ％と最も\n多かったが，GIF については「目立つが不快ではない」との意見が多く，視聴体験を損ね\nない設計の可能性を示している．\nさらに，アンケート自由記述からは，視覚的フィードバックが瞬目を促す効果を持つ一\n方で，「フラッシュの光が動画の字幕を読みにくくする」といった負の影響も指摘された．\nこれに対し，GIF は視覚的に目立つが不快感が少なく，動画視聴体験を損ねにくい特性を\n有していることが確認された．また，被験者の自由記述から，フィードバックの強さやタ\nイミングが視聴体験に大きく影響を与える可能性が示唆された．\n最後に，瞬目促進効果の個人差については，被験者間で有意差の有無やフィードバック\n認識度にばらつきが見られたことから，個別調整が効果的であることが明らかとなった．\n例えば，事前にEAR 閾値やフィードバックの種類を調整することで，より効果的な瞬目\n促進が可能になると考えられる．\nこれらの考察を踏まえ，今後の課題として，（1）フィードバックの認識度を向上させる\n工夫，（2）視聴体験を損ねな",
            "察を踏まえ，今後の課題として，（1）フィードバックの認識度を向上させる\n工夫，（2）視聴体験を損ねない設計のさらなる改善，（3）個別最適化による瞬目促進効果\nの強化が挙げられる．本研究は，瞬目促進システムの可能性を示す一方で，改善の余地が\nあることも明確にした．\n33\n第6章\n結論\n6.1\nまとめ\n本研究では，動画視聴中における瞬目不足による健康問題の軽減を目的として，視覚，\n聴覚，触覚を活用した4 種類のフィードバックを提示する瞬目促進システムを提案し，そ\nの効果を評価した．瞬目検出にはEAR（Eye Aspect Ratio）を用い，個別に閾値を調整す\nることで，各被験者に適した瞬目検出が可能であることを確認した．\n実験の結果，音声およびスマートウォッチの振動が瞬目回数を有意に増加させ，視聴体\n験を大きく損ねない効果的なフィードバックであることが示された．一方，視覚的フィー\nドバック（フラッシュおよびGIF）については瞬目促進効果が認められたものの，一部\nで視聴体験を妨げると評価され，特にフラッシュに関しては改善の余地があることが分\nかった．\nまた，アンケート調査では，GIF が視",
            "，特にフラッシュに関しては改善の余地があることが分\nかった．\nまた，アンケート調査では，GIF が視覚的に目立つが不快感は少ないという肯定的な意\n見が多く得られた一方，音やフラッシュの認識率が低い場合もあることが確認された．さ\nらに，瞬目促進効果やフィードバック認識度には個人差が大きいことが示され，個別調整\nの重要性が示唆された．\n以上の結果から，本研究は瞬目促進システムの有効性と課題を明らかにし，瞬目不足の\n軽減に向けた重要な知見を提供した．\n6.2\n今後の展望\n本研究の成果を踏まえ，以下の課題と今後の展望を示す．\nフィードバックの改良\nフィードバックの認識率を向上させ，視聴体験を損ねない設計が求められる．特に，\nフラッシュによる視覚的負担を軽減するための工夫や，音声フィードバックの認識\n率向上に向けた改善が必要である．\n個別調整の強化\n被験者ごとの瞬目促進効果やフィードバック認識度には個人差が大きいため，事前\nに適切な閾値やフィードバックの種類を調整するシステムの自動化が期待される．\n34\n自然な条件下での評価\n本研究では事前説明が瞬目意識に影響を与えた可能性があるため，より自然な",
            "\n34\n自然な条件下での評価\n本研究では事前説明が瞬目意識に影響を与えた可能性があるため，より自然な状況\nで瞬目促進効果を評価できる実験設計が求められる．これにより，システムの実際\nの使用シーンにおける有効性をより正確に検証できる．\n長期的な影響の評価\n今回の実験は短期間で実施されましたが，長期的な使用が瞬目促進や眼精疲労軽減\nに与える影響を評価することが必要である．これにより，システムの持続的な効果\nを確認できる．\nモバイルデバイスへの対応\nスマートフォンやタブレットなどのモバイルデバイスに対応することで，利用シー\nンが広がると考えられる．特に，ソファでくつろぐようなだらけた姿勢でも瞬目検\n知を可能にすることで，より幅広い動画視聴環境への適応が期待される．また，ス\nマートフォンで動画を視聴する人が多い現状において，これらのデバイスへの対応\nが重要である．\n本研究は瞬目促進システムの可能性を示すとともに，さらなる改善のための方向性を示\nした．これらの課題に取り組むことで，より快適で健康的な動画視聴体験の提供に貢献で\nきると考えられる．\n35\n謝辞\n本研究を進めるうえで，丁寧なご指導を頂",
            "な動画視聴体験の提供に貢献で\nきると考えられる．\n35\n謝辞\n本研究を進めるうえで，丁寧なご指導を頂きました青山学院大学理工学部情報テクノロ\nジー学科ロペズ・ギヨーム教授に深く感謝をいたします．研究目標を達成するだけでな\nく，高い意欲を継続して研究に取り組むことができたのは，先生の温かく丁寧なご指導の\nおかげです．また，研究環境の補助をしてくださった大熊氏，システム開発にご意見をく\nださった高山先輩をはじめとするロペズ研究室の皆様，同期の方々，評価実験にご協力い\nただいた皆様に心よりお礼申し上げます．\n2025 年1 月27 日\n新村温人\n36\n参考文献\n[1] 総務省：令和6年版情報通信白書データ集(2022). https://www.soumu.go.jp/\njohotsusintokei/whitepaper/ja/r06/html/datashu.html#f00263.\n[2] 厚生労働省：平成２０年技術革新と労働に関する実態調査結果の概況(2008).\nhttps://www.mhlw.go.jp/toukei/itiran/roudou/saigai/anzen/\n08",
            "w.mhlw.go.jp/toukei/itiran/roudou/saigai/anzen/\n08/02.html.\n[3] 第一三共ヘルスケア株式会社：テレワークによる体の不調「テレワーク不調」\nに関する調査(2022).\nhttps://www.soumu.go.jp/johotsusintokei/\nwhitepaper/ja/r06/html/datashu.html#f00263.\n[4] 坪田一男：涙のチカラ涙は7 マイクロリットルの海, 株式会社技術評論社(2008). (参\n照日2025/1/17).\n[5] ウェルビーイングクリニック駒沢公園：デジタル時代における眼精疲労（Digital Eye\nStrain, DES）(2025). https://wbck.tokyo/archives/1353.\n[6] ドライアイ研究会：ドライアイとは. https://dryeye.ne.jp/for-general/\ndryeye-summary/.\n[7] 東覚瑠菜, 神場知成：ドライアイ軽減のためのまばたきリマインド機能の開発と評価,\n情報処理学会インタラクション20",
            "場知成：ドライアイ軽減のためのまばたきリマインド機能の開発と評価,\n情報処理学会インタラクション2024 論文集,pp. 556–561 (2024).\n[8] 大石太郎,戸田健,高橋謙介,劉欣欣：VDT 画面を曇らせることによるVDT 利用者瞬き\n促進システムの試作と評価, 電気学会研究会資料. PI= The papers of Technical Meeting\non” Perception Information”, IEE Japan,/知覚情報研究会[編],Vol. 2014, No. 56-80・\n82-93, 電気学会,pp. 21–23 (2014).\n[9] 伊藤奈々, 武田朴, 笠井亮佑, 上條史記, 加納敬, 島峰徹也, 荻野稔, 日向奈惠, 篠原一彦,\n田仲浩平：VDT 作業における眼精疲労度の比較―スマートグラスとLCD および印\n刷物の比較―, 医療機器学, Vol. 90, No. 5, pp. 405–413 (2020).\n37\n[10] Soukupov´a, T.: Eye-Blink Detection Using Facial Landmar",
            "ov´a, T.: Eye-Blink Detection Using Facial Landmarks, Master’s thesis, Czech\nTechnical University in Prague, Faculty of Electrical Engineering (2016). Available at\nftp://cmp.felk.cvut.cz/pub/cmp/articles/cech/Soukupova-TR-2016-05.pdf.\n[11] Maekawa, T. and Inui, T.: 瞬目の模倣が他者の印象に与える影響, 認知心理学研究,\nVol. 16, No. 2, pp. 15–24 (2019).\n[12] 山田冨美雄, 宮田洋：ヒトの驚愕性瞬目反射におよぼす先行刺激効果, 心理学研究,\nVol. 49, No. 6, pp. 349–356 (1979).\n[13] 山田冨美雄：驚愕プローブパラダイムによる感情研究, 日本生理人類学会誌, Vol. 28,\nNo. 3, pp. 45–56 (2023).\n[14] Rushworth",
            ", Vol. 28,\nNo. 3, pp. 45–56 (2023).\n[14] Rushworth, G.: Observations on blink reﬂexes, Journal of neurology, neurosurgery, and\npsychiatry, Vol. 25, No. 2, p. 93 (1962).\n[15] Bin Maneea, M. W., Alamawi, H. O., Almuqbil, A., Abukhlaled, J. K., Alsuwailem, G.,\nAlabdulminaim, J., Aladawi, A. M. M. and Alshangiti, A. Y.: Digital Eye Straining: Ex-\nploring Its Prevalence, Associated Factors, and Effects on the Quality of Life, Cureus,\nVol. 16, No. 5, p. e59442 (online), https://doi.org/10.7759/cureus.",
            ". e59442 (online), https://doi.org/10.7759/cureus.59442\n(2024).\n[16] Kaur, K., Gurnani, B., Nayak, S., Deori, N., Kaur, S., Jethani, J., Singh, D., Agarkar,\nS., Hussaindeen, J. R., Sukhija, J. and Mishra, D.: Digital Eye Strain- A Comprehensive\nReview, Ophthalmology and Therapy, Vol. 11, No. 3, pp. 1655–1680 (online), https:\n//doi.org/10.1007/s40123-022-00466-5 (2022).\n[17] Pavel, I. A., Bogdanici, C. M., Donica, V. C., Anton, N., Savu, B., Chiriac, C. P., Pavel,\nC. D. and Salavastru, S. C.: Com",
            "ac, C. P., Pavel,\nC. D. and Salavastru, S. C.: Computer Vision Syndrome: An Ophthalmic Pathology of\nthe Modern Era, Medicina, Vol. 59, No. 2, p. 412 (online), https://doi.org/10.\n3390/medicina59020412 (2023).\n[18] Wickens, C. D.: Multiple resources and performance prediction, Theoretical issues in\nergonomics science, Vol. 3, No. 2, pp. 159–177 (2002).\n[19] 岡村友俊：感覚統合における視・聴・触覚の重要度, 日本感性工学会論文誌, Vol. 11,\nNo. 3, pp. 503–507 (2012).\n[20] Xu, S. and Zhang, X.: Oculomotor trajectory mapping on body as ",
            "ang, X.: Oculomotor trajectory mapping on body as an effective intervention\nto enhance attention, arXiv preprint, Vol. 2307.15172v2 (online), https://arxiv.\norg/abs/2307.15172 (2023).\n38\n[21] NECLAVIE 公式サイト：仕様LAVIE Direct PM(X)［Pro Mobile］- 13.3 型モバイ\nルパソコン. https://lenovo-nec.jp/navigate/products/pc/193q/10/\nlavie/pmx/spec/index.html.\n[22] au: Google Pixel Watch. https://www.au.com/mobile/product/plus-one/\npixelwatch/.\n[23] for Developers, G. A.: MediaPipe ソリューションガイド(2025).\nhttps://ai.\ngoogle.de",
            " MediaPipe ソリューションガイド(2025).\nhttps://ai.\ngoogle.dev/edge/mediapipe/solutions/guide?hl=ja.\n[24] Fisher, R.: Statistical Methods for Research Workers, Biological monographs and manu-\nals, Oliver and Boyd (1925).\n[25] Tukey, J. W.: Comparing individual means in the analysis of variance, Biometrics, pp.\n99–114 (1949).\n39\n質疑応答\n戸辺義人情報テクノロジー学科教授\nQ\n本当に面白い動画ならGIF に気づかないかもしれないと思うのですが，どのように\n考えていますか？\nA\n実際に動画に集中してGIF に気付いていない被験者もいましたが，実験結果として\nはGIF の認識率は80 ％であり，他のフィードバックと比較すると高い認識率でし\nた．今回GIF の表示は画面の上部であるため，今後",
            "り，他のフィードバックと比較すると高い認識率でし\nた．今回GIF の表示は画面の上部であるため，今後は認識率を上げるような表示方\n法を検討しています．\n戸辺義人情報テクノロジー学科教授\nQ\nどのようなルールでフィードバックを生成していますか？\nA\n本研究では，10 秒ごとにフィードバックを提示するかの判定を行い，「10 秒間で瞬\n目回数が3 回以下」という条件を満たした場合にフィードバックを提示しています．\n伊藤雄一情報テクノロジー学科教授\nQ\n実験前の指示の際、瞬目を刺激することを説明しましたか？\nA\n今回の実験では，事前説明として「瞬目の回数が少ないときに何らかのフィードバッ\nクがあります．」との旨を伝えています。デバイスの使用中は瞬目が少なくなるため，\n瞬目を意識して行うことが健康的な動画視聴態度に繋がります．したがって，瞬目\nを多少意識してしまうことは問題ないと判断し，事前説明を加えました．\n40\n伊藤雄一情報テクノロジー学科助教授\nQ\nまずどんなフィードバック刺激が瞬目を起こすという基礎実験した方が良いのでは\nないですか？\nA\n本研究では瞬目を多少意識してしまうことは問題ない",
            "という基礎実験した方が良いのでは\nないですか？\nA\n本研究では瞬目を多少意識してしまうことは問題ないと判断したため，基礎実験は\n行わずに事前説明を加えて実験を行いました．今後はフィードバック刺激が直接瞬\n目に影響するかを考慮したフィードバック手法の開発も検討しています．\n41\n"
        ]
    },
    {
        "id": "paper_3",
        "filename": "B2024_KaitoMiyazaki.pdf",
        "title": "B2024_KaitoMiyazaki",
        "fulltext": "青山学院大学理工学部\n情報テクノロジー学科\n２０２４年度卒業研究論文\n仮想現実を用いたAIアバタとの英\n会話コミュニケーション\n２０２５年１月２８日提出\n指導教員ロペズ・ギヨーム教授\n提出者学生番号　氏名\n１５８２００８３宮崎海斗\n青山学院大学 理工学部 情報テクノロジー学科 \n2024（令和6 年度）卒業論文要旨 \n1 \n \n仮想現実を用いたAI アバタとの英会話コミュニケーシ\nョン \n \n宮崎 海斗（15820083） \nロペズ研究室 \n \n１．はじめに \n図1 のアンケート結果が示すように日本人の多くが\n英語で話すことに対して不安を抱えていることが調査\nから明らかになっている[1]． \nその原因として，語彙力や発音への自信の不足，流\n暢に話せないことへの不安が挙げられている．従来の\n英語学習ツールでは，リアルな対話環境を再現するこ\nとが難しく，実際のコミュニケーションに必要なスキ\nルを効果的に習得することが困難であった． \n \n図1 英語を話すことが苦手な理由（[1]より引用） \nこれらの課題を解決するために，本研究では仮想現\n実（VR）技術と人工知能（AI）技術を活用した英語学\n習システムを提案する． \n２．関連研究 \n 川崎らは，宮崎大学の学生らを対象にVR が作り出\nす空間に入って英会話を楽しむ学習活動への参加を募\nった．参加者はヘッドセットを用い，異なる場面設定\nで英会話を行い，最終回には討論を体験した．VR 空\n間でのロールプレイにより，英会話を楽しむ参加者が\n多く，語彙増強や復習の必要性が認識されるなど，英\n語学習への主体的な意識の変化が見られた [2]． \n植田らは非言語情報に着目し，身体動作を組み合わ\nせた3 つの条件で，英会話練習を想定し非言語コミュ\nニケーションの実験を行った[3]．結果，VR 空間のア\nバタとの会話においても，現実でのコミュニケーショ\nンと同様，ユーザとアバタの両者において非言語情報\nが現実の会話を再現する上で重要であること，アバタ\nに人間らしさを与えることを示した． \n これまでの研究から仮想現実を利用した英会話学習\nの一定の有効性が示されている一方，ヘッドマウント\nディスプレイ（HMD）を着用した実際の人間同士の対\n話や，あらかじめ設定された台本に基づいて行われる\nコンピュータとの対話が中心であった．以上のことか\nら，本研究ではAI アバタとの会話を通じて参加者が\n自由に発言し，その発言に基づいて会話が自然に展開\nされることで，対人での英会話における緊張感や不安\n感を軽減し，英会話のモチベーションを向上させるこ\nとを目指す． \n３．開発した英会話システムの概要 \n図2 に開発した英会話システムの構成要素と使用方\n法を示す．学習者はシステム利用状況や会話進行度を\n確認するデバイスとしてHMD（Meta Quest 3）を装\n着する．被験者の地点・視点移動，発言内容の録音，\n環境設定などの操作は，HMD 付属のコントローラに\nて行えるようにしている． \n \n図2 開発した英会話システムの仕様概要 \n \n2 \n本システムは音声認識，自然言語処理，音声合成の\n各プロセスが統合された構造となっており，リアルタ\nイムでの双方向コミュニケーションを実現している．\n以下の機能で設計・実装することで，学習者は自然な\n会話体験が得られる． \n1 HMD のマイク入力から学習者の発話データを \nマイク入力として取得 \n2 Convai[4]の音声認識機能（STT：Speech to Text） \nにより発話内容をテキスト化 \n3 OpenAI[5]のAPI を用いて発話テキストデータ \nに対応する回答文を生成 \n4 Convai の音声合成機能（TTS：Text to Speech） \nを用いて，回答文を音声データに変換 \n5 AI アバタが回答文音声データを発話 \n４．開発システムの効果検証 \n本システムの効果を以下の3 つの方法で検証した． \n・発話能力：スピーキングテストPROGOS \n・会話理解力：会話内容への習熟度を測るクイズ \n・英会話に対する印象アンケート  \n 10 名の参加者（20 代男性・女性）のスピーキング\n能力の基準値は，事前に PROGOS を受験することで\n取得する．その後，HMD を装着し，仮想空間内で1 人\n目のAI アバタと12 分間の英会話セッションを行う．\nこのセッションでは，自由にAI アバタとの対話を進\nめるとともに，制限時間内に関連するクイズの回答を\n記入する．同様の作業を2 人目のAI アバタとも行っ\nた後，アンケートに回答する．最後に，再度PROGOS\nを受験してもらうことで，スピーキング能力の変化を\n測定する． \nPROGOS によるスピーキング能力のスコア変化を\n図3 に示す．平均スコアが0.6 ポイント上昇し，一定\nのスピーキング能力の向上が示された．ただし，これ\nはシステムによる効果だけでなく，試験への慣れの影\n響も考慮する必要がある． \nVR 空間内の会話内容に関するクイズの全問正解率\nおよび自由記述欄の回答から，被験者がシステム内で\nの英会話を通じて提示された情報を的確に把握し，対\n話内容を発展させていたことが示唆された． \n \n図3 スピーキング能力のスコア変化 \n６．まとめ \n本研究は英会話学習における心理的障壁を軽減し，\nモチベーションを向上させるためのVR とAI 技術の\n組み合わせがもたらす可能性を示した点で新規性があ\nる．特に，AI アバタを用いることで対人での緊張感を\n和らげ，自由度の高い会話を楽しむ学習環境を提供で\nきたことは，従来の台本型会話システムにはない特徴\nである．また，実験結果において，スピーキング能力\nの向上や学習意欲の高まりが示された点は，本システ\nムの有効性を裏付けている． \n一方，いくつかの課題も明らかになった．例えば，\nPROGOS のスコア向上がシステムの効果に直接起因\nするのか，試験への慣れが影響したのかを区別するこ\nとは困難であった．また，短期間での実験であったた\nめ，継続的な使用における効果や課題については十分\nに検証できていない．今後はそれらの点を明確にして\nいく必要がある． \n参考文献 \n[1] 国際ビジネスコミュニケーション協会：「英語の\nスピーキングに関する実態と意識」調査，\nhttps://www.iibc-global.org/index.html. \n[2] 川崎典子：「VR 英会話プログラム」パイロットス\nタディの実践報告，宮崎大学工学部紀要， \nVol.51,pp.147–152(2022). \n[3] 植田智裕，田辺弘子，小宮山摂ほか：視線とジェ\nスチャにより会話進行が変化するVR 英会話システム，\n研究報告ヒューマンコンピュータインタラクション\n(HCI)，Vol. 2021,No. 6, pp. 1–8 (2021). \n[4] Convai．”Convai API． \nhttps://docs.convai.com/api-docs/.（2025/1/24 参照） \n[5] OpenAI．”OpenAI API” \nhttps://www.openai.com/api/. （2025/1/24 参照） \n目次\n第1 章\n序章\n1\n1.1\n研究背景. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n1\n1.1.1\n複合現実技術. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n1\n1.1.2\n英会話の重要性. . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n2\n1.1.3\n英会話に対する不安\n. . . . . . . . . . . . . . . . . . . . . . . . . .\n3\n1.2\n研究目的. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n4\n第2 章\n関連研究・技術\n6\n2.1\nオンライン英会話の教育的検証. . . . . . . . . . . . . . . . . . . . . . . .\n6\n2.2\n教育・言語支援システムとしてのAR・VR の有用性. . . . . . . . . . . . .\n8\n2.3\nバーチャル空間を用いた英会話システム. . . . . . . . . . . . . . . . . . .\n10\n2.3.1\nVR 英会話プログラム\n. . . . . . . . . . . . . . . . . . . . . . . . .\n10\n2.3.2\n非言語情報を取り入れたVR 英会話教育. . . . . . . . . . . . . . .\n11\n2.4\nまとめ. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n12\n第3 章\nバーチャル・リアリティを用いたAI アバタとの英会話コミュニケーション\nシステム\n13\n3.1\nシステム概要. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n13\n3.2\n空間投影手法とバーチャル空間内における表現手法. . . . . . . . . . . . .\n14\n3.2.1\n空間投影手法. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n14\n3.2.2\nバーチャル空間内における表現手法\n. . . . . . . . . . . . . . . . .\n15\n3.3\nAI アバタの作成\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n16\n3.4\nシステム設計およびスクリプト生成手法. . . . . . . . . . . . . . . . . . .\n17\n3.4.1\nシステム設計. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n17\n3.4.2\nアバターの会話スクリプト生成手法\n. . . . . . . . . . . . . . . . .\n18\n3.5\nまとめ. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n19\n第4 章\nスピーキング力および英会話に対するモチベーションへの影響の評価実験\n20\n4.1\n実験目的. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n20\n4.2\n実験環境. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n20\ni\n4.3\n評価指標. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n21\n4.3.1\nPROGOS for English speaking\n. . . . . . . . . . . . . . . . . . . . .\n21\n4.3.2\nAI アバタとの会話に関するクイズ\n. . . . . . . . . . . . . . . . . .\n22\n4.3.3\nアンケート. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n23\n4.4\n実験方法. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n24\n第5 章\n実験結果と考察\n26\n5.1\nPROGOS の結果と考察. . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n26\n5.2\nアンケートの結果と考察. . . . . . . . . . . . . . . . . . . . . . . . . . . .\n28\n5.3\nクイズの結果と考察\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n30\n5.4\nまとめ. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n30\n第6 章\n結論と今後の展望\n32\n6.1\n結論. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n32\n6.2\n今後の展望\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n33\n謝辞\n34\n参考文献\n35\n質疑応答\n38\nii\n第1章\n序章\n本章では，本研究における研究背景，目的および本論文の構成について述べる．\n1.1\n研究背景\n1.1.1\n複合現実技術\n近年，バーチャル・リアリティや拡張現実が話題になっている．これらの映像技術は\n年々発展しており2020 年にはVR 市場規模は約18 億ドルと，全メディアセグメントで\nも最も高い数字となっている[1]．図1-1 に2025 年までのコンテンツ予測成長率を示す．\nVR はトップで年平均成長率は30.3%，市場規模は69 億ドルと見積もられおり，研究分野\nだけでなく一般消費者向けのゲームコンテンツにおいても注目されている．\n拡張現実（AR），バーチャル・リアリティ（VR），複合現実（MR）から成るxR（Cross\nReality）と呼ばれる基本的な概念は頭にかぶる形のディスプレイ（ヘッドマウントディス\nプレイ:HMD）にバーチャルなオブジェクトであるホログラムを映すものである．特に複\n合現実は，シースルー型のディスプレイを用いて現実世界を深度センサや赤外線カメラで\n解析することにより，ホログラムを実際の物体と重畳して表現することが可能である．こ\nれにより，従来では2D としての情報提示しかできなかったが，現実世界の環境変化に応\nじたフィードバックが可能となる．\n1\n図1-1: 2020-2025 年におけるコンテンツごとの予測成長率（[1] より引用）\n1.1.2\n英会話の重要性\nグローバル化が進む中，英語での効果的なコミュニケーション能力は，多くの分野で欠\nかせないスキルとなっている．特に，国際ビジネス，学術交流，観光業，さらには医療や\nIT 分野においても，英語は共通言語としての役割を果たしており，日常業務や国際的な\nプロジェクトの遂行において重要性が増している．このような背景から，世界中で英語を\n学ぶ人々の数は急増しており，新しい学習方法や技術を活用した教育プログラムへの関心\nも高まっている．\n従来の英語学習法である教科書学習や教室での授業は，文法や読解力の向上には効果的\nである一方で，実際の会話で必要とされるスピーキングやリスニングスキルを十分に伸ば\nすには限界がある．たとえば，学校教育では限られた時間の中で大人数の生徒を対象に指\n導するため，一人一人が会話練習を行う機会が少ない．また，教室での対話練習は，母語\n話者とのやり取りに比べて現実的な緊張感や即時性に欠けるため，実践的なコミュニケー\nション能力の習得には至らない場合が多い．\n近年，人工音声技術の進歩やクラウドサービスの普及により，音声認識や対話制御と\nいった技術を容易に利用できるようになり，それを活用した英語学習アプリの開発[2] や，\nロボットを用いた対話システムの研究[3] が進められている．しかし，これらのシステム\nでは，学習相手がイラストやロボットで表現されている場合が多く，実際の人間との会話\nに近い臨場感や緊張感を体験することは難しい．また，会話の中で質問が投げかけられた\n2\n際も，相手が実在の人物ではないため，学習者が長時間考え込むことがあり，自然な会話\nの流れが途切れてしまう場合がある．これにより，実際の会話に近い学習環境を提供する\nには限界があると言える．このような背景のもと，テクノロジーを活用した言語学習の革\n新が求められている[4]．\n1.1.3\n英会話に対する不安\n日本人の多くが英語で話すことに対して不安を抱えていることが調査から明らかになっ\nている[5]．「英語で話すことが得意ですか」に対し，「得意」または「どちらかといえば\n得意」と回答した人は47.8%だった一方で，「苦手」または「どちらかといえば苦手」と\n回答した人は52.2%と過半数を占めた．つまり，英語で話すことが苦手であると感じてい\nる人の割合は，得意であると感じている人を上回っている状況が浮き彫りになった．\n図1-2: 英語を話すことに対する自信（[5] より引用）\nさらに，「苦手」または「どちらかといえば苦手」と回答した52.2%の回答者に対して\nその理由を尋ねたところ，最も多かったのは「語彙力に自信がないから（60.9%）」であ\nり，次いで「流暢に話せないから（60.5%）」，「発音に自信がないから（53.6%）」という\n結果が得られた．これらの結果から，日本人が英語で話すことに対して感じる不安は，言\n語そのものの知識不足および技術的な側面に起因していることが伺える．\n3\n図1-3: 英語を話すことが苦手な理由（[5] より引用）\n特に，「語彙力に自信がない」との回答が多かったことは，学校教育や自主学習の中で\nの単語学習の重要性が高い一方で，実際に会話でその語彙を適切に使用する経験が不足し\nている可能性を示唆している．また，「流暢に話せない」と感じる人が多いことは，日常\n的な英語でのアウトプット機会が少ないことや，実践的な会話練習の不足が要因として挙\nげられる．さらに，「発音に自信がない」という回答は，日本の英語教育がリスニングや\n発音指導に十分な時間を割いていない現状や，学習者自身が正しい発音を確認する機会の\n不足を反映していると考えられる．\nこれらのデータから推測されるのは，日本人の英語学習において，理論的な学習に加え\nて，実践的かつ効果的なアウトプットの機会を増やすことが重要であるという点である．\n語彙力や流暢さ，発音といった要素は，一朝一夕で克服可能であるものではなく，日常的\nな実践の中で徐々に自信を育む必要がある．したがって，英語を話す環境をシミュレー\nションする技術や，実際の会話に近い練習機会を提供する教育手法の開発が，日本人の英\n語スキル向上に向けた鍵となると考えられる．\n1.2\n研究目的\n1.1 節で述べたように，日本人が英語を話す際に感じる不安や課題として，語彙力や発\n音への自信不足，流暢に話すことへの不安が挙げられる．また，従来の英語学習ツールで\n4\nは，リアルな対話環境を再現することが難しく，実際のコミュニケーションで必要なスキ\nルを効果的に習得することが困難であった．これらの課題を解決するため，本研究では，\nバーチャル・リアリティ技術を活用した英語学習システムを提案する．バーチャル・リア\nリティ技術を活用し，ヘッドマウントディスプレイを通じて学習者をバーチャル空間に誘\n導することで，リアルな対話環境を再現する．本環境では，AI アバタが学習者の対話相\n手となり，現実に近いシナリオを展開する．\n従来の英語学習ツールでは，実際の会話に必要な「臨場感」や「相手との即時的な応答」\nの要素が不足していた．また，語彙力や発音への不安，流暢さの欠如が原因で多くの学習\n者が英語で話すことに消極的であるという課題があった．本研究では，AI アバタがリア\nルな非言語的表現や応答を行うことで，これらの課題を克服し，学習者に自然でストレス\nの少ない対話体験を提供することを目指す．\n具体的には，本システムは以下の点を目標とする．\n1. スピーキング力の向上の向上: バーチャル空間のリアリティとAI アバタの自然な挙\n動を通じて，学習者のスピーキング力の向上を目指す．\n2. 学習者の英会話に対する自信の向上: AI アバタとの対話環境において，学習者が積\n極的に発話練習が可能である場を提供し，英会話に対する自信を培う．\n本研究の成果は，学習者が英語に対する自信を持ち，実生活での英語コミュニケーション\nに積極的に取り組むための新しい学習アプローチを提案するものである．\n5\n第2章\n関連研究・技術\n本章では，本研究に関連する先行研究および，バーチャル・リアリティを利用した技術，\nVR を用いた言語教育システムについて述べる．\n2.1\nオンライン英会話の教育的検証\n大和田はオンライン英会話プログラムの教育的効果を，質問紙調査とスピーキングテ\nストによって検証した[6]．2015 年6 月から7 月に実施された「英会話サプリ」では，学\n部生37 名（全員女子）が参加した．受講生の週平均レッスン回数を分析すると，週1 回\n未満が16 名で最多，次いで週6 回以上7 回未満が7 名だった．理想的な週3 回以上の受\n講者は17 名（45.9%）であり，学習意欲の高さが多くの受講回数に繋がっていることが\n示唆された．プログラム終了後のアンケート（回答率48.6%）では，「英語を話すことへ\nの抵抗が減った」（M=4.79，SD=.61）が最も高評価だったが，「英語を話す力が伸びた」\n（M=3.95，SD=1.19）や「文法力が伸びた」（M=3.26，SD=1.07）は表2-1 のように相対的\nに低い評価だった．これには短期間であることや受講回数の差が影響している可能性があ\nる．自由記述では，「先生が親しみやすい」といった肯定的意見のほか，「指導力のばらつ\nき」や「キャンセル制約」などの課題も指摘された．受講生のスピーキング力はVersant\nSpeaking Test によって図2-1 のように評価された．このテストは音声認識と自動採点で総\n合点（20～80 点）とCEFR レベルを算出し，A1 からC2 までの6 段階で言語能力を評価\nする．受講前後の比較では，A，C，E の3 名にスコアとレベルの上昇が見られた．特に\nA は，4 か月間で10 点向上し，CEFR で1 レベル上昇した．一方，B はスコアが下がり，\nD は変化がなかった．\n6\n表2-1: 英会話サプリに対するアンケート結果（[6] より引用）\n質問内容\n平均値（M）\n標準偏差（SD）\nレッスンの内容には満足した\n4.32\n1.13\n先生の教え方には満足した\n4.21\n1.32\n英語を話す力が伸びた\n3.95\n1.19\n英語を聞く力が伸びた\n4.05\n1.15\n英語の語彙（単語の数）が増えた\n4.37\n0.74\n英語の文法の力が伸びた\n3.26\n1.07\n英語の発音がよくなった\n3.84\n1.18\n英語学習の意欲が増えた\n4.63\n0.67\n英語を話すことの抵抗感が減った\n4.79\n0.61\n今回は楽しく英語を学ぶことができた\n4.42\n1.09\n機会があればオンライン英会話を続けてみたい\n4.42\n1.23\n図2-1: Versant Speaking Test 結果（[6] より引用）\n先行研究によると，短期留学（4～5 週間）で平均3.45 点，長期留学（1 年間）で約6.9\n点の上昇が期待される中，A の10 点の伸びは特筆すべき結果であった[7]．A は4 か月間\nで139 回（約57.9 時間）受講しており，集中的な学習が成果を上げたと考えられる．以\n上の結果から，英会話サプリは短期間で英語への抵抗を減らす効果がある一方で，スピー\nキング力や文法力の向上にはさらなる時間と努力が必要であることが示された．\n7\n2.2\n教育・言語支援システムとしてのAR・VR の有用性\n近年，AR/VR は教育分野でも活用されている．例えば，Google 社は学習を目的にVR\n体験を提供する「Expeditions」を開発し，NASA は星座や天体を視覚化する「SkyView」\nを発表した．さらに，AR/VR コンテンツ作成技術（ARToolkit，Vuforia など）も進化を続\nけている．山元は，AR/VR を活用した教育・学習支援システムの有用性を紹介し，特に\n産業分野，とりわけ自動車におけるAR 技術の応用に触れながら，教育への貢献と課題に\nついて解説した[8]．ここでAR はAugmented Reality の略称で，日本語では「拡張現実」\nを意味する．現実世界での体験にデジタル情報を重ね合わせ，新たな価値を生み出すXR\n（Cross Reality）と呼ばれる先端技術のひとつである．主にスマートフォンやスマートグ\nラスを通し，目で見ている光景にCG 映像などが合成され，あたかも実際に存在するよう\nに見える技術を指す．\n一方VR はVirtual Reality の略称である．VR ヘッドセットを装着することで視覚的に\n現実世界を遮断し，デジタル上に再現されたバーチャル空間をまるでその場にいるように\n体感できる技術である．VR はバーチャル空間を現実のように体験できる点が最大の特徴\nで，現実世界での体験をベースにしたAR とは明確に異なる．最近ではインターネット上\nに作られたバーチャル世界「メタバース」に没入するための手段として，VR は大いに関\n心を集めている．図2-2 にAR とVR のイメージを示す.\n図2-2: AR とVR （[9] より引用）\n次に教育・学習支援システムにおける有用性について，本稿ではVR に関するもののみ\n取り上げる．Non-immersive VR の例として，高校生対象の科学実験シミュレーションが\n可能なシステムが提案されており，このシステムではディスプレイにVR 実験空間を提\n示し，Wii Remote を使って操作する．また，Second Life 環境では建築の安全教育をロー\nルプレイングできるシステムもある．Semi-immersive VR では，巨大ディスプレイとキ\nネクトによるジェスチャーを用いて，バーチャル空間で外国語の学習をするシステムや，\n8\nHMD と力覚センサを使って重力のシミュレーションを行うシステムが提案されている．\nFully-immersive VRは多くが、人物の正面・側面・床面の3つの面をスクリーンで囲み、没入\n感の高いバーチャル体験ができるシステムであるCAVE ベースであり，例えばPDD-NOS\nの児童が安全に横断歩道を渡る訓練を行うシステムや，前庭障害の症状を緩和するため\nにバーチャル空間内で食料品店を歩き回るシステムが提案されている．さらに，HMD を\n使って建築空間のデザインを学習するシステムや，モーションキャプチャーを利用してア\nフリカのDjembe ハンドドラム演奏を練習するシステムもある．\nVR の意義は，バーチャル環境とのインタラクションを通じて現実では実現困難な学習\nを可能にすることである．例えば，外出が難しい学習者がリハビリを受ける際に，恐怖や\n危険を排除したバーチャル空間で学習できる．また，3D の建築物を現実環境に重ねるこ\nとが難しい学習においても有用だ．しかし，バーチャル環境でなければ不可能な学習もあ\nり，例えば重力の体験やドラム演奏の練習などは，必ずしもVR 環境が必要ではない場合\nもある．Non-immersive VR は没入感がないため，VR としての意義が薄く，教育利用にお\nいてバーチャル環境とVR を混同しているケースも指摘されている．\n9\n2.3\nバーチャル空間を用いた英会話システム\n2.3.1\nVR 英会話プログラム\nコロナ禍でオンライン英会話が一般化する中，工学部学生には魅力的な学習方法となら\nず，対話の緊張感ややる気低下が課題となった．そこで川崎らは，宮崎大学の学生らを対\n象に図2-3 に示すようなVR が作り出す空間に入って英会話を楽しむ学習活動への参加を\n募った[10]．デジタルツールや工学技術への関心が高い学生には，VR 技術を用いた英会\n話が有効と考えられ，VR 空間でのゲーム感覚のロールプレイを取り入れたプログラムが\n実施された．参加者はヘッドセットを用い，異なる場面設定で英会話を行い，最終回には\n討論を体験した．VR 空間でのロールプレイにより，英会話を楽しむ参加者が多く，語彙\n増強や復習の必要性が認識されるなど，英語学習への主体的な意識の変化が見られた．こ\nの結果を踏まえ，早期に英語自律学習方法を指導する仕組みの導入が効果的であると示唆\nされた．\n図2-3: 参加募集を呼びかけるポスター（[10] より引用）\n10\n2.3.2\n非言語情報を取り入れたVR 英会話教育\nVR 空間の臨場感を活かした英会話学習システムが登場している中で，鈴木らはVR 空\n間のアバタとの音声対話を利用した英会話を，アバタの有無で比較し，アバタの存在が好\n意的に評価されることを示した[11]．さらに植田らは非言語情報に着目し，身体動作を\n組み合わせた3 つの条件で，英会話練習を想定し非言語コミュニケーションの実験を行っ\nた[12]．タスク達成時間，ユーザの視線対象とそれを見た間を測定し，3 種類のアンケー\nトと合わせて，VR 空間内でのアバタとの会話においても，現実の会話と同様に，ユーザ\nが用いる非言語情報が重要といえるかどうか，またそのユーザビリティを調査した．結\n果，VR 空間のアバタとの会話においても，現実でのコミュニケーションと同様，ユーザ\nとアバタの両者において非言語情報が現実の会話を再現する上で重要であること，アバタ\nに人間らしさを与えることを示した．\n図2-4: システムの全体構成図（[12] より引用）\n11\n2.4\nまとめ\nオンライン英会話プログラム「英会話サプリ」の調査では，短期間で英語を話すことへ\nの抵抗が減少する効果が確認された一方，スピーキング力や文法力の向上には時間と努力\nが必要であることが示された．特に受講回数が多い学生は顕著な成果を上げており，学習\n意欲の高さが結果に影響していると考えられる．指導力のばらつきやシステム上の制約な\nどの課題も明らかになった．\nまた，AR/VR 技術は教育支援において現実では困難な学習を可能にする点で有用性が\n高く，外国語学習やリハビリ訓練，建築デザインの学習など多岐にわたる応用事例があ\nる．しかし，VR でなければ実現できない学習内容は限定的であり，非没入型VR の効果\nやVR とバーチャル環境の混同といった課題も指摘されている．\n2.3.2 の研究では評価指標としてアンケートを採用していた．アンケートを通じて学習\n者の満足度や没入感の向上が確認されている一方, 具体的な学習成果を定量的に評価する\n研究は十分に行われていない．VR を活用した英会話コミュニケーションに焦点を当てた\n研究もいくつか存在しているが（2.3），これらは主にHMD を着用した実際の人間同士の\n対話や，あらかじめ設定された台本に基づいて行われるコンピュータとの対話が中心で\nあった．\n以上のことから，本研究ではAI アバタとの会話を通じて参加者が自由に発言し，その\n発言に基づいて会話が自然に展開されることで，対人での英会話における緊張感や不安感\nを軽減し，英会話のモチベーションを向上させることを目的とする．このため，従来の台\n本に沿った会話や，対話相手に依存することなく，実際の会話に近いダイナミックでフレ\nキシブルなコミュニケーションを体験できる可能性がある．加えて，AI アバタの性格や\n空間設定が学習者に親しみやすさを与えるようにデザインし，学習者により安心して会話\nに挑戦できる環境を提供することで，学習者の英会話コミュニケーション能力の向上に寄\n与することを目指す．\n12\n第3章\nバーチャル・リアリティを用いたAIアバ\nタとの英会話コミュニケーションシステム\n3.1\nシステム概要\n本節では本研究で提案するバーチャル・リアリティにおいて，AI アバタと英会話コミュ\nニケーションするシステムについて説明する．これはヘッドマウントディスプレイを用\nいたバーチャル・リアリティ技術により，現実を模した空間でAI を組み込んだアバタと\n自由に英会話コミュニケーションを行うことで，英会話への意欲の維持・向上を目的とし\nたシステムである．図3-1 に提案システムの全体図を示す．英会話を行う人はシステム利\n用状況や会話進行度を確認するデバイスとしてヘッドマウントディスプレイを装着する．\n被験者の地点・視点移動，発言内容の録音，環境設定を行うボタンを割り振った付属機器\nをコントローラとして扱う．コントローラを用いてAI アバタの近くに移動し，録音ボタ\nンを長押しすることで自身の発言の録音が開始される．録音ボタンを放すと発言した内容\nがAPI を用いてChat GPT に転送され，応答を受け取ることでAI アバタとの会話が可能\nにとなる．API の仕組みについては詳しい説明を後述する．\n図3-1: 提案システムの全体図\n13\n3.2\n空間投影手法とバーチャル空間内における表現手法\n本節では空間投影手法である作成されたバーチャル空間内でのバーチャル・リアリティ\nによる表現手法について述べる．\n3.2.1\n空間投影手法\n本研究ではヘッドマウントディスプレイとしてMeta 社のMeta Quest 3 [13] を用いる．\n図3-2 にMeta Quest 3 の外見を示す．Meta Quest 3 は，Meta 社が開発したスタンドアロン\n型のVR/MR ヘッドセットである．2023 年10 月に発売された当デバイスは，Snapdragon\nXR2 Gen 2 プロセッサによる高い処理能力と片目あたり2064 × 2，208 ピクセルの高解像\n度ディスプレイを備え，前作であるMeta Quest 2 の2 倍以上の性能向上を実現している．\nまた，パンケーキレンズの採用による40%の薄型化や，RGB カラーカメラによる高品質\nなカラーパススルー機能によって現実世界とバーチャル世界を融合させた自然なMR 体\n験が可能となっている．さらに精度の高いハンドトラッキング機能によってコントロー\nラーなしで手の動きを正確に認識し，自然な操作感を提供することで，ゲームからビジネ\nス，教育，日常生活に至るまで幅広い用途で活用が期待されている．\n図3-2: Meta Quest 3（Meta 社）\n14\n3.2.2\nバーチャル空間内における表現手法\n本システムの開発にはUnity Technologies 社が提供するUnity [14] を用いた．Unity は無\n料で利用可能なゲームエンジンであり，作成したプロジェクトはAndroid やPC，HMD な\nど様々な環境にビルド可能である．また，様々なユーザーが作成したアセットがアセット\nストアから利用可能となっており，短期間での開発が可能である．本システムはHMD 上\nで動作するため，HMD 上のあらゆる情報を扱えるようにする拡張パッケージ（OculusXR）\nを導入した．\n本研究では作成されたバーチャル空間上での会話が行われるが，より現実的な空間での\nコミュニケーションが対面でのコミュニケーションに近づくと考えられる．そこでバー\nチャル空間の作成としてUnity のAsset であるApartment Kit [15] を利用した．Apartment\nKit は，Brick Project Studio が提供する無料のUnity アセットであり，建築やインテリア\nの制作を効率化するモジュール式の建築キットである．このアセットには200 種類以上\nの豊富な3D プレハブが収録されており，リビングルーム，キッチン，寝室，浴室といっ\nた様々な空間をデザインを可能にするため，本研究のバーチャル空間の作成に適すと考え\nた．図3-3 に作成したバーチャル空間を示す．\n図3-3: 作成したバーチャル空間\n後述するAI アバタは外国人を想定した外見や性格の付与を行ったため，一般的な海外\nの家のリビングルームを模して作成した．壁や床，家具等それぞれに物理演算を施すこと\nで被験者やAI アバタのすり抜けを防止した．\n15\n3.3\nAI アバタの作成\n本節ではAI アバタの作成方法とその使用について述べる．本システムの開発にはUnity\nアセット上のNPC AI エンジンであるConvai [16] を利用した．Convai とは，開発者やク\nリエイター向けのプラットフォームであり，バーチャル環境や現実世界で多モーダルな\n認識能力を持つキャラクターを直感的に設計できるツールを提供している．Convai では，\nキャラクターの動作，言語能力，知識，感情状態などを詳細にカスタマイズでき，ゲーム\n内での動的な反応やリアルなインタラクションを実現可能である．また，髪型，体型，衣\n服，アクセサリーなどを選択して3D キャラクターをゼロから作成し，その外見を個性に\n合わせてカスタマイズすることができる．\n本研究においてAI アバタは非常に重要な役割を担う．特に被験者がAI アバタと会話す\nる際，現実的な環境を作り出すためには，外見や会話内容が自然なものであることが求め\nられる．そのため，本来ゲームのNPC 作成の際に利用される当システムが適していると\n考えた．図3-4 に作成したAI アバタを示す．\n図3-4: 作成したAI アバタ（Gonzalez（左）とJessy（右））\n作成したAI アバタはGonzales とJessy の計2 体である．それぞれに設定したキャラク\nター背景を表3-1 に示す．会話の中で発言内容が二転三転しないために，キャラクター背\n景は詳細に記述したが，ここでは特に重要な項目だけを示す．\n表3-1 に示した内容は初対面の外国人と会話をする際，取り扱われやすい話題を示して\nいる[17]．それぞれ年齢，出身地，出身地で人気なもの，好きなスポーツ，そのスポーツ\nでのポジションである．後述するシステムの評価実験では，これらの情報を利用しシステ\nムの習熟度を測る．\n16\n表3-1: 作成したAI アバタのキャラクター背景\n名前\n年齢\n出身地\n地元で人気なもの\n好きなスポーツ\nポジション\nGonzales\n20 歳\nブラジル\nカーニバル\nサッカー\nミッドフィルダー\nJessy\n21 歳\nアメリカ合衆国\nグランドキャニオン\nバスケットボール\nポイントガード\n3.4\nシステム設計およびスクリプト生成手法\n本節では通信手法およびシステム設計について述べる．\n3.4.1\nシステム設計\n本稿ではシステム設計について述べる．図3-5 にシステム設計のシーケンス図を示す．\nまず，学習者の発話データをマイク入力として取得し，この音声データは音声認識システム\n（Convai STT）によりテキスト化される．次に，テキスト化された発話データはOpenAI [18]\nを用いて回答文が生成される．この回答文は音声合成システム（Convai TTS）を用いて\n音声データに変換される．そして，生成された音声データがAI アバタの発話として再生\nされることで，学習者はバーチャル・リアリティ内で自然な会話を体験することが可能で\nある．本システムは音声認識，自然言語処理，音声合成の各プロセスが統合された構造と\nなっており，リアルタイムでの双方向コミュニケーションを実現している．\n図3-5: システム設計のシーケンス図\n17\nここで，Meta Quest 3 のコントローラへのボタン割り振りを図3-6 に示す．学習者は左\nコントローラのスティックを利用して自身の位置を変更し，AI アバタに近づく．この時，\n右コントローラのスティックを利用して視点変更が可能である．AI アバタに近づくと会\n話内容が表示されるバーが出現し，その状態でA ボタンを押すことで話しかけることが\n可能である．\n図3-6: コントローラへのボタン割り振り\n3.4.2\nアバターの会話スクリプト生成手法\n本システムにおいて，AIアバタとの会話を実現するためにConvaiのSpeech to Text（STT），\nText to Speech（TTS）機能とOpenAI を利用した．スクリプト生成手法を図3-7 に示す．\nUnity 上で入力された学習者の音声データをAPI を用いてConvai に送信し，Convai のSTT\n機能利用して文字列に変換する．変換された文字列をOpenAI のAPI を用いてChat GPT\nに送信する．その文字列に対する回答をChat GPT が生成し，Convai に送り返す．Convai\nのTTS 機能利用して文字列に変換し，Unity 上のAI アバタから音声データを再生する．\n18\n図3-7: AI アバタのスクリプト生成手法\n3.5\nまとめ\n本研究では，バーチャル・リアリティ環境においてAI アバタとの英会話を可能にする\nシステムを提案した．このシステムは，ヘッドマウントディスプレイMeta Quest 3 を用\nい，現実世界に近い空間でAI アバタと自然な英会話を行うことを目的としている．学習\n者はコントローラを使用して位置や視点を調整し，AI アバタに近づいて発話を録音する\nことで，リアルタイムな対話を体験できる．発話内容はConvai のSTT 機能でテキスト化\nされ，OpenAI のAPI を介してChatGPT による応答が生成される．その後，Convai のTTS\n機能を通じて音声化され，AI アバタから再生されることで自然な会話が実現される．\nバーチャル空間の作成にはUnity のApartment Kit アセットを用い，海外の一般的なリ\nビングルームを模した空間を構築した．また，Convai を利用して外国人を想定したAI ア\nバタを作成し，学習者が会話内容に集中できるようリアルで詳細なキャラクター背景を設\n定した．\n本システムは，音声認識，自然言語処理，音声合成の各技術を統合することで，リアル\nタイムかつ双方向のコミュニケーションを実現している．これにより，学習者は英会話を\n通じて言語スキルを向上させるだけでなく，英語を話すことへの心理的なハードルを下げ\nる効果も期待される．\n19\n第4章\nスピーキング力および英会話に対するモチ\nベーションへの影響の評価実験\n4.1\n実験目的\n本実験の目的は，バーチャル空間上でAI アバターと英会話コミュニケーションを行う\nシステムが，学習者の英語スピーキング力の向上および英会話に対するモチベーションの\n変化に与える影響を評価することである．本システムを利用した学習環境が，従来の学習\n手法に比べて英語スピーキング能力の改善にどの程度寄与するのかを明らかにするとと\nもに，学習者の英会話への抵抗感を軽減し，意欲を向上させる効果があるかを検証するこ\nとを目指す．\n4.2\n実験環境\n男性8 名，女性2 名の計10 名の大学生を対象に，ヘッドマウントディスプレイを装着し，\n本システムを利用してAI アバタと英会話コミュニケーションを行ってもらった．図4-1\nに実験に利用した部屋を示す．被験者はこの部屋で，着席した状態で実験を行う．バー\nチャル空間上での移動はコントローラ制御にて行うため，部屋の広さや構造の条件は必要\nないが，外音の少ない環境で実験を行った．\n図4-1: 実験環境の部屋の様子\n20\n4.3\n評価指標\n本節では本実験での評価指標について説明する．\n4.3.1\nPROGOS for English speaking\n本研究では，英語スピーキング能力の変化を評価するためにPROGOS を指標として用\nいた．PROGOS は，実践的なビジネスシーンを基に英語スピーキング能力を測定するオ\nンラインテストで，幅広い仕事に必要なスピーキング力を評価可能である．受験形式は\nオープンクエスチョン形式で，受験時間は約20 分と短時間で実施できるのが特徴である．\nまた，測定結果は最短2～3 分で返却されるため，受験者がすぐに自分の英語力を把握で\nきる仕組みとなっている[19]．\nPROGOS の評価は，国際的に使われている言語運用能力の基準であるCEFR（Common\nEuropean Framework of Reference for Languages）[20] に準拠している．CEFR は，言語運\n用能力をA1 からC2 までの6 段階で評価し，世界中の学校教育，学術研究，企業などで\n広く活用されており，国際標準となっている．この指標によって，英語力を「基礎段階の\n言語使用者（A1～A2）」「自立した言語使用者（B1～B2）」「熟達した言語使用者（C1～\nC2）」というレベルで評価する．図4-2 に各試験団体のデータによるCEFR との対照表を\n示す．本研究では，このCEFR 基準に基づくスコアを使ってスピーキング能力の変化を客\n観的に示した．\n図4-2: 各試験団体のデータによるCEFR との対照表( [20] より引用)\nPROGOS のテストは，以下の5 つのセクションで構成されている．1 つ目はインタビュー\n21\n形式での自由回答，2 つ目は英文の音読，3 つ目はプレゼンテーション形式でのスピーチ，\n4 つ目はグラフや図を使ったプレゼンテーション，5 つ目はロールプレイである．この多\n様な構成によって，受験者の総合的なスピーキング能力を測定することができる．たとえ\nば，インタビュー形式では自然なコミュニケーション能力を，音読では発音や流暢さを，\nプレゼンテーションでは論理的思考と表現力を評価する．また，グラフや図の活用やロー\nルプレイを通じて，実践的なビジネスシーンで求められる能力も測定可能である．図4-2\nに指標別の評価項目を示す．\n図4-3: PROGOS における指標別評価項目\n本研究では，バーチャル空間上でAI アバターを使った英会話システムの利用前後で\nPROGOS を実施し，スピーキング能力の変化を分析した．これにより，システムが英語\nスピーキング力の向上に与える影響の定量的な評価を行った．\n4.3.2\nAI アバタとの会話に関するクイズ\nシステムを適切に利用できているかを測るために，図4-4 に示すクイズを設けた．この\nクイズはAI アバタの年齢，出身地，出身地で人気なもの，好きなスポーツ，そのスポー\nツでのポジションを尋ねており，会話内容から回答を導くものとなっている．問題自体\nは，最低限の英会話を行うことができれば回答できる難易度となっている．また，設問は\n22\n3.3 節で示したように初対面の外国人と会話をする際，取り扱われやすい話題を示してお\nり，AI アバタと会話する際のシナリオとしての役割も兼ねている．最後の自由に感想を\n記載する設問は，被験者が自然なコミュニケーションを行うことで得た情報を記すために\n設けた．\n図4-4: クイズの内容\n4.3.3\nアンケート\n本実験後，VR の操作に対する感想や英会話に対するモチベーションの変化を調査する\nためにアンケートを設けた．「強く同意する」，「同意する」，「どちらともいえない」，「同意\nしない」，「強く同意しない」の5 段階で評価する．以下にアンケートの設問内容を示す．\n1. VR の操作は難しかったですか？\n23\n2. クイズにより円滑に会話が進みましたか？\n3. AI アバタと自然に会話することができましたか？\n4. 対人で話す際と同じような感覚を得れましたか？\n5. 英会話コミュニケーションへのモチベーションが向上しましたか？\n6. 英語を話すことに対して前向きな気持ちが強まりましたか？\n7. 英語を話すことに対して自信がついたと感じますか？\n8. このシステムをまた利用したいとおもいましたか？\n4.4\n実験方法\n以下に実験の流れを示す．\n1. スピーキングテストを実施\n2. (HMD を装着し)，1 体目のAI アバタと12 分間の英会話開始\n3. 英会話後，クイズに回答\n4. (HMD を装着し)，2 体目のAI アバタと12 分間の英会話開始\n5. 英会話後，クイズに回答\n6. スピーキングテストを実施\n7. アンケートに回答\n各実験参加者は，実験の開始時に英語スピーキング能力の基礎データを取得するため，\nはじめにPROGOS を受験し，システム利用前のスピーキング力を測定する．この初期評\n価により，参加者のスピーキング能力の基準値が得られる．その後，ヘッドマウントディ\nスプレイを装着し，バーチャル空間内でAI アバタ（Gonzales）と12 分間の英会話セッショ\nンを行う．このセッションでは，自由にAI アバタとの対話を進めるとともに，制限時間\n内に関連するクイズに回答を記入する．ここで，当クイズは実験前に被験者に説明されて\nおり，設問内容に沿って会話が展開されることが期待される．\nさらに，1 週間後，参加者は再びヘッドマウントディスプレイを装着し，別のAI アバタ\n（Jessy）と同様に12 分間の英会話セッションを行う．この2 回目のセッションでも，AI\n24\nアバタとの会話を進めながら，制限時間内にクイズに回答を記入する．1 回目と2 回目の\nセッションで異なるAI アバタを使用することで，参加者が異なる話者との対話にどのよ\nうに適応するかを検証できるよう設計されている．\n最終的に，2 回目の英会話セッション終了後，参加者にはアンケートに回答してもらい，\nシステムの使用感や英会話に対するモチベーションの変化などを調査する．加えて，再度\nPROGOS を受験することで，システム利用前後でのスピーキング能力の変化を測定する．\n尚，取得したPROGOS のデータはT 検定を行い有意差の有無を判定した．T 検定とは条\n件の異なる2 つの群において、それぞれの群の平均値の間の差が統計的に有意なものであ\nるか判定する手法である．これら一連のプロセスにより，バーチャル空間内での英会話体\n験が英語スピーキング能力に及ぼす影響を総合的に評価する．\nここで図4-5 にVR 上で会話をしている様子を示す.\n図4-5: VR 上での会話の様子\n25\n第5章\n実験結果と考察\n5.1\nPROGOS の結果と考察\n本節では，オンラインテストPROGOS を用いて測定したスピーキング力の評価結果お\nよび考察を述べる．あらかじめ結果を分かりやすくするため，PROGOS の評価書式を表\n5-1 のように変換した．PROGOS ではPre-A1 からC1 までの評価が得られるが，本実験で\nはB2 以上のスコアは得られなかったためB2 までの変換を行った．\n表5-1: PROGOS のスコア変換\nレベル\nPre-A1\nA1\nA1High\nA2\nA2High\nB1\nB1High\nB2\nスコア\n1\n2\n3\n4\n5\n6\n7\n8\n表5-2 に各被験者（A からJ）のPROGOS のスコアを，図5-1 に各被験者のスコア変化\nを示す．なお，各被験者の横にあるバーのうち，下側が1 回目の試験結果で上側が2 回目\nの試験結果である．1 回目と2 回目の結果をスコアに換算し，全体の平均値を算出したと\nころ，平均で0.6 ポイントの上昇が見られた．個別の結果を見ると，被験者A，E，H，I\nの4 名が1 ポイント以上のスコア上昇を示し，特に被験者I はA2 からB1 に上昇するなど\n顕著な変化が観察された．一方で，被験者B，G，J の3 名はスコアに変化がなく，被験\n者F は1 ポイントのスコア減少が見られた．\n表5-2: 各被験者のPROGOS のスコア\nA\nB\nC\nD\nE\nF\nG\nH\nI\nJ\n平均値\n1 回目\n3\n6\n5\n4\n1\n5\n4\n3\n4\n5\n4\n2 回目\n4\n6\n6\n5\n2\n4\n5\n3\n6\n5\n4.6\n26\n図5-1: 各被験者のPROGOS のスコア変化\n表5-3 に示すようにT 検定の結果，PROGOS の結果には有意な差があることが明らかに\nなった．結果として，平均スコアが0.6 ポイント上昇したが，この要因については慎重に\n考える必要がある．一つの可能性として，本研究で開発した仮想空間上でのAI アバタと\nの英会話システムがスピーキング能力の向上に寄与した可能性が挙げられる．システム\n内では，クイズ形式やアバタとの対話を通じて英語をアウトプットする機会を提供してお\nり，これが被験者のスピーキング力にポジティブな影響を与えた可能性がある．\n表5-3: PROGOS の結果におけるスコア比較\nパターン\n平均値\np 値\n有意差\n1 回目\n4\n2 回目\n4.6\np ＜0.05\nあり\n一方で，スコア上昇が試験そのものへの慣れによるものの可能性も否定できない．PRO-\nGOS は形式化された問題を含むため，1 回目の受験を通じて試験形式や回答の流れに慣れ\nたことが2 回目のスコア向上に繋がった可能性がある．特に，被験者B，G，J のスコア\nが変化しなかったことや，被験者F のスコアが減少したことからも，全員が均一に効果を\n得られるわけではない点が示唆される．\n27\n今回の実験では，各被験者がAI アバタとの対話を行ったのは合計24 分間（12 分間× 2\n回）という短時間だった．そのため，スコア上昇の程度は限定的であり，英語力全体の向\n上を示すには不足している可能性がある．長期間の利用を通じた効果測定が行われれば，\nより顕著な変化が観察されるかもしれない．\n今後は，システム利用後のスコア上昇が試験への慣れによるものか，あるいはシステム\n自体の効果によるものかをより明確にするために，対照群を設定した実験を実施する必要\nがある．加えて，システム利用期間や利用頻度がスコアに与える影響についても詳細に検\n討していくことが求められる．\n5.2\nアンケートの結果と考察\n本節ではアンケートの結果とその考察を述べる．アンケートの各項目は「強く同意しな\nい」を1，「強く同意する」を5 としてスコアリングした．また，スコアリングした値を\n用いて各モードの各項目の平均スコアを算出した．表5-4 に評価実験のアンケート結果を\n示す．アンケートの各項目について考察を行う．\n表5-4: アンケート結果\n設問\n平均スコア\nVR の操作は難しかったですか？\n1.7\nクイズにより円滑に会話が進みましたか？\n4.3\nAI アバタと自然に会話することができましたか？\n4.2\n対人で話す際と同じような感覚を得れましたか？\n4.2\n英会話コミュニケーションへのモチベーションが向上しましたか？\n4.6\n英語を話すことに対して前向きな気持ちが強まりましたか？\n4.7\n英語を話すことに対して自信がついたと感じますか？\n4.2\nこのシステムをまた利用したいとおもいましたか？\n4.6\nQ1．VR の操作は難しかったですか？\n本設問の平均スコアは1.7 であった．これは，多くの被験者がVR 操作を難しく感じ\nなかったことを示している．この結果は，本研究で用いたシステムのユーザにとっ\nて扱いやすい設計が寄与していると考えられる．直感的な操作が可能であることで，\n被験者が英会話自体に集中できたことが示唆される．\nQ2．クイズにより円滑に会話が進みましたか？\n本設問の平均スコアは4.3 であった．この高いスコアは，クイズ形式が被験者の英会\n話をスムーズに促進する要因となったことを示唆している．クイズが適切なトピッ\n28\nクを提供し，AI アバタとの会話が一貫性を持つものとなった可能性がある．また，\nクイズ形式による構造化が，参加者の負担を軽減し会話を円滑にしたと考えられる．\nQ3．AI アバタと自然に会話することができましたか？\n本設問の平均スコアは4.2 であった．この結果は，AI アバタが自然な対話体験を提\n供できたことを示している．特に，被験者がAI との会話に違和感を覚えることな\nく，親しみを持って会話できた可能性が考えられる．今後，さらにAI の表現力や応\n答精度を高めることで，よりリアルな会話体験が提供できると期待される．\nQ4．対人で話す際と同じような感覚を得れましたか？\n本設問の平均スコアは4.2 であった．このスコアは，VR とAI 技術を組み合わせた\n英会話システムが，対人での英会話と近い感覚を被験者に提供できたことを示して\nいる．対人での会話に近い体験を実現できたことは，本システムの没入感や自然さ\nが高く評価された結果といえる．\nQ5．英会話コミュニケーションへのモチベーションが向上しましたか？\n本設問の平均スコアは4.6 であった．これは，本システムが被験者の英会話学習へ\nの意欲を高める効果を持っていることを示唆している．被験者が英会話を楽しみな\nがら学習できたことが，モチベーション向上につながったと考えられる．\nQ6．英語を話すことに対して前向きな気持ちが強まりましたか？\n本設問の平均スコアは4.7 であった．この結果は，本システムが英会話に対するポジ\nティブな感情を強化する役割を果たしたことを示している．被験者がAI アバタとの\n対話を通じて，英語に対する抵抗感を軽減し，より積極的な姿勢を持つようになっ\nたことが示唆される．\nQ7．英語を話すことに対して自信がついたと感じますか？\n本設問の平均スコアは4.2 であった．このスコアは，本システムが英語を話す自信\nを一定程度向上させたことを示している．実践的なシミュレーション環境が，被験\n者の自己効力感を高める一助となったと考えられる．\nQ8．このシステムをまた利用したいとおもいましたか？\n本設問の平均スコアは4.6 であった．この結果は，被験者が本システムを高く評価\nし，再利用への意欲を示していることを反映している．その要因として，システム\nの使いやすさ，学習効果，および楽しい体験が寄与していると考えられる．\n29\n5.3\nクイズの結果と考察\n本実験では，仮想空間上の英会話システムを利用した後，参加者にクイズを実施した．\nクイズは図4-4 の通り6 問で構成され，英会話を通じて得た情報に基づく回答が求められ\nた．その結果，被験者全員が全問正解を達成した．また，クイズの最後に設けた自由記述\n欄では，被験者の多くが好きなスポーツチームやその他の趣味について記載しており，AI\nアバタとの会話内容をさらに発展させた回答が見られた．\n全問正解という結果と5.2 のQ2 から，被験者がシステムを通じて提示された情報を正\n確に把握できたことが示された．このことは，仮想空間上でのAI アバタとの対話が，英\n会話コミュニケーションのスムーズな運用を可能にしたことを示唆している．また，自由\n記述欄に記載された内容から，被験者がシステム内での対話を活発に行い，クイズの範囲\nを超えた個人的な興味や関心に基づく会話を発展させていたと考えられる．\nクイズ自体は難易度が高く設定されていなかったため，全問正解という結果は予想可能\nであったものの，対話内容を忠実に理解し再現する能力がシステム利用を通じて発揮され\nた点は注目に値する．この結果は，AI アバタを用いた英会話システムが，単なる受け身\nの情報取得ではなく，対話を通じた積極的な情報交換を促進する有用な手段である可能性\nを示している．\n一方で，クイズの結果だけではスピーキング能力向上の因果関係を直接示すには限界が\nある．したがって，英会話システムの有効性をより具体的に検証するためには，被験者へ\nのインタビューや追加の観察データを収集することが今後の課題として挙げられる．\n5.4\nまとめ\n本章ではシステムを用いた評価実験の結果とその考察について述べた．PROGOS の結\n果では，平均スコアが0.6 ポイント上昇し，一定のスピーキング能力の向上が示された．\nただし，これはシステムによる効果だけでなく，試験への慣れの影響も考慮する必要があ\nる．また，クイズの全問正解率および自由記述欄の回答から，被験者がシステム内での英\n会話を通じて提示された情報を的確に把握し，対話内容を発展させていたことが示唆さ\nれた．\nさらに，アンケート結果では，被験者がシステムの操作性を高く評価し（「VR の操作は\n難しかったか」のスコア1.7），AI アバタとの会話を通じて英会話へのモチベーションや\n前向きな気持ちの向上（平均スコア4.6 以上）が確認された．特に，「英語を話すことに対\nして前向きな気持ちが強まった」との項目で最も高い平均スコア4.7 が得られたことは，\nシステムの心理的効果を裏付ける重要な結果といえる．\nこれらの結果から，AI アバタを用いた英会話システムは，英語スピーキング能力の向\n30\n上やコミュニケーションへの積極性を促進する可能性が示された．ただし，効果の詳細な\n要因を明らかにするためには，さらなる調査や長期的な利用を視野に入れた研究が必要で\nある．\n31\n第6章\n結論と今後の展望\n6.1\n結論\n本研究では，仮想空間上でAI アバタを活用した英会話システムを開発し，その有用性\nを評価するためにPROGOS，クイズ，およびアンケートを用いた検証を行った．\n1 章では，英会話の重要性，そして英会話学習における心理的障壁や対人コミュニケー\nションの難しさを解消するために，バーチャル・リアリティ技術の活用が注目されている\n背景を述べた．\n2 章では，従来のVR を利用した英語教育研究の多くが台本に基づいた対話や人間同士\nの対話を中心としており，自由度の高い会話を支援するシステムが不足している現状を示\nした．\n3 章では，本研究で開発したシステムの詳細を説明した．このシステムはMeta Quest 3\nを利用し，Unity とConvai を活用して自然な英会話体験を提供するものである．ユーザー\nはAI アバタとの自由な対話を通じて，英語を話すスキルや自信を向上させることを目指\nした．また，AI アバタの性格や空間設定が学習者に親しみやすさを与えるよう設計され\nている．\n4 章では，実験概要を示し，参加者に仮想空間内でAI アバタと会話を行わせた後，PRO-\nGOS，クイズ，アンケートを通じてその効果を検証した．\n5 章では，結果として，PROGOS では平均スコアが0.6 ポイント上昇し，有意な差が認\nめられたことで一定のスピーキング能力の向上が示された．クイズでは被験者全員が全問\n正解し，対話を通じて提供された情報を正確に把握していたことが確認された．さらに，\nアンケートでは，システム操作の簡便性や英会話へのモチベーション向上が高く評価さ\nれ，特に「英語を話すことに対して前向きな気持ちが強まった」という項目で最も高い平\n均スコア4.7 を得た．\n総括として，本研究は英会話学習における心理的障壁を軽減し，モチベーションを向上\nさせるためのVR 技術の可能性を示した点で新規性がある．特に，AI アバタを用いるこ\nとで対人での緊張感を和らげながら，自由度の高い会話を楽しむ学習環境を提供できたこ\nとは，従来の台本型会話システムにはない特徴である．また，実験結果において，スピー\nキング能力の向上や学習意欲の高まりが示された点は，本システムの有効性を裏付けてい\nる．一方で，いくつかの課題も明らかになった．例えば，PROGOS のスコア向上がシス\n32\nテムの効果に直接起因するのか，試験への慣れが影響したのかを区別することは困難で\nあった．また，短期間での実験であったため，継続的な使用における効果や課題について\nは十分に検証できていない．\n6.2\n今後の展望\n今後の展望として，以下の点が挙げられる．第一に，本システムの長期的な利用による\n効果を調査し，継続的な英会話能力の向上や心理的変化を明らかにすることが重要であ\nる．第二に，より多様な背景や英語レベルを持つ被験者を対象にした実験を行い，システ\nムの普遍的な有効性を検証する必要がある．第三に，クイズや対話内容をより高度化し，\n学習者のレベルに応じた適応的なシナリオを導入することで，さらなる学習効果が期待さ\nれる．\n本研究を通じて，仮想空間上でのAI アバタを用いた英会話システムが，従来の英語学\n習方法を補完し，新しい学習体験を提供する可能性が示された．今後の研究や改良を通じ\nて，本システムがより多くの学習者にとって有用なツールとなることを期待する．\n33\n謝辞\n本研究の機会を与えて下さり，研究面について大変ご丁寧なご指導を賜りました，青山\n学院大学理工学部情報テクノロジー学科Guillaume LOPEZ 教授に深く感謝申し上げます．\nそして，システム開発をサポートしていただいた阿部悠貴先輩，研究会などを通して助言\nをいただいたLOPEZ 研究室の皆様並びに実験に協力していただいた皆様，金銭面でも精\n神面でも支えていただいた家族に深く感謝いたします．\n2025 年1 月24 日\n宮崎　海斗\n34\n参考文献\n[1] Ballhaus, W. and Chow, W.: Power shifts: Altering the dynamics of the E&M industry,\nhttps://www.pwc.com/gx/en/entertainment-media/outlook-2021/\nperspectives-2021-2025.pdf. (Accessed on 1/14/2025).\n[2] SpeakBUDDY:\nAI\n英会話アプリスピークバディ—音声認識機\n能搭載の英語学習でスピーキング、リスニング力が上達！，\nttps://www.speakbuddy.me/. (Accessed on 1/14/2025).\n[3] 秋本桃子，阿部秀尚，生田祐子，森田武史，山口高平ほか：教師業務ルール分析に\n基づく対話型ロボットを用いた発音練習の実装と評価，情報教育シンポジウム論文\n集，Vol. 2018, No. 26, pp. 185–188 (2018).\n[4] 齊藤真生，櫻井淳，川合康央：頭部搭載型ディスプレイを用いたスペイン語学習シス\nテムの提案，IEICE Conferences Archives, The Institute of Electronics, Information and\nCommunication Engineers (2021).\n[5] 一般財団法人国際ビジネスコミュニケーション協\n会\n：「英語のスピーキングに関する実態と意識」調査\n，\nhttps://www.iibc-global.org/index.html.\n[6] 大和田和治：東京音楽大学におけるオンライン英会話プログラムの導入とその教育\n的効果の検証，研究紀要，Vol. 39, pp. 53–66 (2016).\n[7] 清水裕子，桐村亮，野澤健：経済学部英語圏短期留学プログラムにおけるスピーキン\nグ・テストの実施とその結果報告，立命館高等教育研究，Vol. 14, pp. 91–102 (2014).\n[8] 山元翔：AR/VR の教育・学習支援システムへの利用と課題，教育システム情報学会\n誌，Vol. 36, No. 2, pp. 49–56 (2019).\n[9] goetsch.media:\nhttps://www.goetsch.media/augmented-reality.\n(Accessed\non\n1/14/2025).\n35\n[10] 川崎典子：「VR 英会話プログラム」パイロットスタディの実践報告，宮崎大学工\n学部紀要，Vol. 51, pp. 147–152 (2022).\n[11] 鈴木直人，廣井富，藤原祐磨ほか：英会話学習システムにおけるCG キャラクタの効\n果と学習者の発話タイミング制御のための付加表現に関する検討，日本音響学会研\n究発表会講演論文集，Vol. 2014 秋期(2014).\n[12] 植田智裕，田辺弘子，小宮山摂ほか：視線とジェスチャにより会話進行が変化するVR\n英会話システム，研究報告ヒューマンコンピュータインタラクション(HCI)，Vol. 2021,\nNo. 6, pp. 1–8 (2021).\n[13] Meta\n社\n：Meta\nQuest\n3,\nhttps://www.meta.com/jp/quest/quest-3/. (Accessed on 1/14/2025).\n[14] Unitytechnology\n社\n：Unity,\nhttps://unity.com/ja. (Accessed on 1/14/2025).\n[15] BrickProjectStudio:\nApartmentKit,\nhttps://assetstore.unity.com/packages/3d/environments/\napartment-kit-124055. (Accessed on 1/14/2025).\n[16] P.Mukherjee:\nConvaiasset,\nhttps://assetstore.unity.com/packages/tools/behavior-ai/\nnpc-ai-engine-dialog-actions-voice-and-lipsync-convai-235621.\n(Accessed on 1/14/2025).\n[17] DMM\n英\n会\n話：も\nう\n会\n話\nネ\nタ\nに\n困\nら\nな\nい\n！初\nめ\nて\n会った外国人とすぐに打ち解ける英語フレーズ，\nhttps://eikaiwa.dmm.com/blog/learning-english/expressions/\nfirst-conversation/. (Accessed on 1/14/2025).\n[18] OpenAI\n社\n：OpenAI,\nhttps://openai.com/ja-JP/chatgpt/overview/.\n(Accessed\non\n1/14/2025).\n[19] 株\n式\n会\n社\nプ\nロ\nゴ\nス\n：PROGOS,\nhttps://progos.ai/. (Accessed on 1/14/2025).\n[20] 文部科学省：各試験団体のデータによる\nCEFR\nとの対照表，\nhttps://www.mext.go.jp/b_menu/shingi/chousa/shotou/117/\n36\nshiryo/__icsFiles/afieldfile/2016/05/24/1368985_15_1.pdf/.\n(Accessed on 1/14/2025).\n37\n質疑応答\n伊藤　雄一　情報テクノロジー学科　教授\nQ\nVR になったこそ何がよくなりましたか．\nA\nVR を活用したことで，英語学習における没入感の向上と心理的ハードルの軽減の2\n点で効果が見られました．従来の英語学習ツールでは，対話のリアリティが不足し，\n画面越しの学習では実際の会話に必要な臨場感や緊張感を再現することが困難でし\nた．しかし，VR を用いることで，学習者は仮想空間内で実際にその場にいるかのよ\nうな体験をしながら英会話を行うことができました．また，VR 環境では学習者が\n対人の緊張を感じにくいため，発話に対する心理的な障壁が軽減され，より積極的\nに英語を話せるようになりました．本研究では，PROGOS やアンケートを通じて，\nVR 環境での英会話が学習者のスピーキング力やモチベーションの向上に寄与する\n可能性を示しました．\n戸辺　義人　情報テクノロジー学科　教授\nQ\n研究としての要素はどこにありますか．\nA\n本研究の学術的な貢献として，1 つ目にVR 環境でのAI アバタとの自由対話による\n英会話学習の検証が挙げられます．従来のVR を用いた英語学習の多くは，台本に\n沿った会話や事前に決められたシナリオに基づいたものが主流であり，学習者が自\n由に発話し，それに応じた自然な応答が得られるシステムの研究は少ないです．本\n研究では，AI アバタと自由に対話できる環境を構築し，その効果を実験的に検証し\nました．2 つ目に英会話学習における心理的ハードルの軽減効果の分析が挙げられ\nます．日本人が英語を話す際に感じる不安（発音や流暢さへの自信のなさ）が，VR\nを活用することで軽減されるかを，アンケート結果をもとに分析しました．その結\n果，「英語を話すことに対する前向きな気持ちが強まった」という項目で高評価を得\nるなど，VR の活用が心理的な障壁を下げる可能性が示唆されました．\n38\n戸辺　義人　情報テクノロジー学科　教授\nQ\nVR は仮想現実ではなく、仮想空間をいいます．\nA\n近年，「仮想」という言葉の意味が曖昧になりつつあり，特に技術分野では「バーチャ\nル」という表現が用いられることが増えています．例えば，メタバース関連の議論\nでは「仮想空間」ではなく「バーチャル空間」と表現されることが多く，VR に関連\nする技術やサービスでも「バーチャル」という表現が一般的になっています．\n本研究では，VR 技術を活用して「実際の空間を模倣する」のではなく，「ユーザー\nが没入して対話できる環境を提供する」ことを目的としているため，「仮想現実」よ\nりも「バーチャル空間」という表現が適切であると考えられます．\n39\n",
        "chunks": [
            "B2024_KaitoMiyazaki. B2024_KaitoMiyazaki. B2024_KaitoMiyazaki",
            "青山学院大学理工学部\n情報テクノロジー学科\n２０２４年度卒業研究論文\n仮想現実を用いたAIアバタとの英\n会話コミュニケーション\n２０２５年１月２８日提出\n指導教員ロペズ・ギヨーム教授\n提出者学生番号　氏名\n１５８２００８３宮崎海斗\n青山学院大学 理工学部 情報テクノロジー学科 \n2024（令和6 年度）卒業論文要旨 \n1 \n \n仮想現実を用いたAI アバタとの英会話コミュニケーシ\nョン \n \n宮崎 海斗（15820083） \nロペズ研究室 \n \n１．はじめに \n図1 のアンケート結果が示すように日本人の多くが\n英語で話すことに対して不安を抱えていることが調査\nから明らかになっている[1]． \nその原因として，語彙力や発音への自信の不足，流\n暢に話せないことへの不安が挙げられている．従来の\n英語学習ツールでは，リアルな対話環境を再現するこ\nとが難しく，実際のコミュニケーションに必要なスキ\nルを効果的に習得することが困難であった． \n \n図1 英語を話すことが苦手な理由（[1]より引用） \nこれらの課題を解決するために，本研究では仮想現\n実（VR）技術と人工知能（AI）技術を活用した英語学",
            "これらの課題を解決するために，本研究では仮想現\n実（VR）技術と人工知能（AI）技術を活用した英語学\n習システムを提案する． \n２．関連研究 \n 川崎らは，宮崎大学の学生らを対象にVR が作り出\nす空間に入って英会話を楽しむ学習活動への参加を募\nった．参加者はヘッドセットを用い，異なる場面設定\nで英会話を行い，最終回には討論を体験した．VR 空\n間でのロールプレイにより，英会話を楽しむ参加者が\n多く，語彙増強や復習の必要性が認識されるなど，英\n語学習への主体的な意識の変化が見られた [2]． \n植田らは非言語情報に着目し，身体動作を組み合わ\nせた3 つの条件で，英会話練習を想定し非言語コミュ\nニケーションの実験を行った[3]．結果，VR 空間のア\nバタとの会話においても，現実でのコミュニケーショ\nンと同様，ユーザとアバタの両者において非言語情報\nが現実の会話を再現する上で重要であること，アバタ\nに人間らしさを与えることを示した． \n これまでの研究から仮想現実を利用した英会話学習\nの一定の有効性が示されている一方，ヘッドマウント\nディスプレイ（HMD）を着用した実際の人間同士の対\n話や",
            "の有効性が示されている一方，ヘッドマウント\nディスプレイ（HMD）を着用した実際の人間同士の対\n話や，あらかじめ設定された台本に基づいて行われる\nコンピュータとの対話が中心であった．以上のことか\nら，本研究ではAI アバタとの会話を通じて参加者が\n自由に発言し，その発言に基づいて会話が自然に展開\nされることで，対人での英会話における緊張感や不安\n感を軽減し，英会話のモチベーションを向上させるこ\nとを目指す． \n３．開発した英会話システムの概要 \n図2 に開発した英会話システムの構成要素と使用方\n法を示す．学習者はシステム利用状況や会話進行度を\n確認するデバイスとしてHMD（Meta Quest 3）を装\n着する．被験者の地点・視点移動，発言内容の録音，\n環境設定などの操作は，HMD 付属のコントローラに\nて行えるようにしている． \n \n図2 開発した英会話システムの仕様概要 \n \n2 \n本システムは音声認識，自然言語処理，音声合成の\n各プロセスが統合された構造となっており，リアルタ\nイムでの双方向コミュニケーションを実現している．\n以下の機能で設計・実装することで，学習者は自然な\n会話",
            "での双方向コミュニケーションを実現している．\n以下の機能で設計・実装することで，学習者は自然な\n会話体験が得られる． \n1 HMD のマイク入力から学習者の発話データを \nマイク入力として取得 \n2 Convai[4]の音声認識機能（STT：Speech to Text） \nにより発話内容をテキスト化 \n3 OpenAI[5]のAPI を用いて発話テキストデータ \nに対応する回答文を生成 \n4 Convai の音声合成機能（TTS：Text to Speech） \nを用いて，回答文を音声データに変換 \n5 AI アバタが回答文音声データを発話 \n４．開発システムの効果検証 \n本システムの効果を以下の3 つの方法で検証した． \n・発話能力：スピーキングテストPROGOS \n・会話理解力：会話内容への習熟度を測るクイズ \n・英会話に対する印象アンケート  \n 10 名の参加者（20 代男性・女性）のスピーキング\n能力の基準値は，事前に PROGOS を受験することで\n取得する．その後，HMD を装着し，仮想空間内で1 人\n目のAI アバタと12 分間の英会話セッションを行う．\nこのセッショ",
            " を装着し，仮想空間内で1 人\n目のAI アバタと12 分間の英会話セッションを行う．\nこのセッションでは，自由にAI アバタとの対話を進\nめるとともに，制限時間内に関連するクイズの回答を\n記入する．同様の作業を2 人目のAI アバタとも行っ\nた後，アンケートに回答する．最後に，再度PROGOS\nを受験してもらうことで，スピーキング能力の変化を\n測定する． \nPROGOS によるスピーキング能力のスコア変化を\n図3 に示す．平均スコアが0.6 ポイント上昇し，一定\nのスピーキング能力の向上が示された．ただし，これ\nはシステムによる効果だけでなく，試験への慣れの影\n響も考慮する必要がある． \nVR 空間内の会話内容に関するクイズの全問正解率\nおよび自由記述欄の回答から，被験者がシステム内で\nの英会話を通じて提示された情報を的確に把握し，対\n話内容を発展させていたことが示唆された． \n \n図3 スピーキング能力のスコア変化 \n６．まとめ \n本研究は英会話学習における心理的障壁を軽減し，\nモチベーションを向上させるためのVR とAI 技術の\n組み合わせがもたらす可能性を示した点で新規性があ\n",
            "ベーションを向上させるためのVR とAI 技術の\n組み合わせがもたらす可能性を示した点で新規性があ\nる．特に，AI アバタを用いることで対人での緊張感を\n和らげ，自由度の高い会話を楽しむ学習環境を提供で\nきたことは，従来の台本型会話システムにはない特徴\nである．また，実験結果において，スピーキング能力\nの向上や学習意欲の高まりが示された点は，本システ\nムの有効性を裏付けている． \n一方，いくつかの課題も明らかになった．例えば，\nPROGOS のスコア向上がシステムの効果に直接起因\nするのか，試験への慣れが影響したのかを区別するこ\nとは困難であった．また，短期間での実験であったた\nめ，継続的な使用における効果や課題については十分\nに検証できていない．今後はそれらの点を明確にして\nいく必要がある． \n参考文献 \n[1] 国際ビジネスコミュニケーション協会：「英語の\nスピーキングに関する実態と意識」調査，\nhttps://www.iibc-global.org/index.html. \n[2] 川崎典子：「VR 英会話プログラム」パイロットス\nタディの実践報告，宮崎大学工学部紀要， \nVol",
            " 川崎典子：「VR 英会話プログラム」パイロットス\nタディの実践報告，宮崎大学工学部紀要， \nVol.51,pp.147–152(2022). \n[3] 植田智裕，田辺弘子，小宮山摂ほか：視線とジェ\nスチャにより会話進行が変化するVR 英会話システム，\n研究報告ヒューマンコンピュータインタラクション\n(HCI)，Vol. 2021,No. 6, pp. 1–8 (2021). \n[4] Convai．”Convai API． \nhttps://docs.convai.com/api-docs/.（2025/1/24 参照） \n[5] OpenAI．”OpenAI API” \nhttps://www.openai.com/api/. （2025/1/24 参照） \n目次\n第1 章\n序章\n1\n1.1\n研究背景. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n1\n1.1.1\n複合現実技術. . . . . . . . . . . . . . . . . . . . . . . . . . . .",
            " . . . . . . . . . . . . . . . . . . . . . . . . . . .\n1\n1.1.2\n英会話の重要性. . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n2\n1.1.3\n英会話に対する不安\n. . . . . . . . . . . . . . . . . . . . . . . . . .\n3\n1.2\n研究目的. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n4\n第2 章\n関連研究・技術\n6\n2.1\nオンライン英会話の教育的検証. . . . . . . . . . . . . . . . . . . . . . . .\n6\n2.2\n教育・言語支援システムとしてのAR・VR の有用性. . . . . . . . . . . . .\n8\n2.3\nバーチャル空間を用いた英会話システム. . . . . . . . . . . . . . . . . . .\n10\n2.3.1\nVR 英会話プ",
            ". . . . . . . . . . . . . . . . .\n10\n2.3.1\nVR 英会話プログラム\n. . . . . . . . . . . . . . . . . . . . . . . . .\n10\n2.3.2\n非言語情報を取り入れたVR 英会話教育. . . . . . . . . . . . . . .\n11\n2.4\nまとめ. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n12\n第3 章\nバーチャル・リアリティを用いたAI アバタとの英会話コミュニケーション\nシステム\n13\n3.1\nシステム概要. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n13\n3.2\n空間投影手法とバーチャル空間内における表現手法. . . . . . . . . . . . .\n14\n3.2.1\n空間投影手法. . . . . . . . . . . . . . . . . . . . . . . . . ",
            ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n14\n3.2.2\nバーチャル空間内における表現手法\n. . . . . . . . . . . . . . . . .\n15\n3.3\nAI アバタの作成\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n16\n3.4\nシステム設計およびスクリプト生成手法. . . . . . . . . . . . . . . . . . .\n17\n3.4.1\nシステム設計. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n17\n3.4.2\nアバターの会話スクリプト生成手法\n. . . . . . . . . . . . . . . . .\n18\n3.5\nまとめ. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n19\n第4 章\nスピーキング力",
            " . . . . . . . . . . . . . . . . .\n19\n第4 章\nスピーキング力および英会話に対するモチベーションへの影響の評価実験\n20\n4.1\n実験目的. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n20\n4.2\n実験環境. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n20\ni\n4.3\n評価指標. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n21\n4.3.1\nPROGOS for English speaking\n. . . . . . . . . . . . . . . . . . . . .\n21\n4.3.2\nAI アバタとの会話に関するクイズ\n. . . . . . . . . . . . . . . . . .\n22\n4.3.3\nアンケート. . . . . ",
            ". . . . . . . . . . . . .\n22\n4.3.3\nアンケート. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n23\n4.4\n実験方法. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n24\n第5 章\n実験結果と考察\n26\n5.1\nPROGOS の結果と考察. . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n26\n5.2\nアンケートの結果と考察. . . . . . . . . . . . . . . . . . . . . . . . . . . .\n28\n5.3\nクイズの結果と考察\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n30\n5.4\nまとめ. . . . . . . . . . . . . . . . . . . . . . . . . . . . . ",
            ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n30\n第6 章\n結論と今後の展望\n32\n6.1\n結論. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n32\n6.2\n今後の展望\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n33\n謝辞\n34\n参考文献\n35\n質疑応答\n38\nii\n第1章\n序章\n本章では，本研究における研究背景，目的および本論文の構成について述べる．\n1.1\n研究背景\n1.1.1\n複合現実技術\n近年，バーチャル・リアリティや拡張現実が話題になっている．これらの映像技術は\n年々発展しており2020 年にはVR 市場規模は約18 億ドルと，全メディアセグメントで\nも最も高い数字となっている[1]．図1-1 に2025 年までのコンテンツ予測成長率を示す．\nVR はトップで年平均成長率は30.3%",
            "図1-1 に2025 年までのコンテンツ予測成長率を示す．\nVR はトップで年平均成長率は30.3%，市場規模は69 億ドルと見積もられおり，研究分野\nだけでなく一般消費者向けのゲームコンテンツにおいても注目されている．\n拡張現実（AR），バーチャル・リアリティ（VR），複合現実（MR）から成るxR（Cross\nReality）と呼ばれる基本的な概念は頭にかぶる形のディスプレイ（ヘッドマウントディス\nプレイ:HMD）にバーチャルなオブジェクトであるホログラムを映すものである．特に複\n合現実は，シースルー型のディスプレイを用いて現実世界を深度センサや赤外線カメラで\n解析することにより，ホログラムを実際の物体と重畳して表現することが可能である．こ\nれにより，従来では2D としての情報提示しかできなかったが，現実世界の環境変化に応\nじたフィードバックが可能となる．\n1\n図1-1: 2020-2025 年におけるコンテンツごとの予測成長率（[1] より引用）\n1.1.2\n英会話の重要性\nグローバル化が進む中，英語での効果的なコミュニケーション能力は，多くの分野で欠\nかせないスキルとなっている．",
            "ル化が進む中，英語での効果的なコミュニケーション能力は，多くの分野で欠\nかせないスキルとなっている．特に，国際ビジネス，学術交流，観光業，さらには医療や\nIT 分野においても，英語は共通言語としての役割を果たしており，日常業務や国際的な\nプロジェクトの遂行において重要性が増している．このような背景から，世界中で英語を\n学ぶ人々の数は急増しており，新しい学習方法や技術を活用した教育プログラムへの関心\nも高まっている．\n従来の英語学習法である教科書学習や教室での授業は，文法や読解力の向上には効果的\nである一方で，実際の会話で必要とされるスピーキングやリスニングスキルを十分に伸ば\nすには限界がある．たとえば，学校教育では限られた時間の中で大人数の生徒を対象に指\n導するため，一人一人が会話練習を行う機会が少ない．また，教室での対話練習は，母語\n話者とのやり取りに比べて現実的な緊張感や即時性に欠けるため，実践的なコミュニケー\nション能力の習得には至らない場合が多い．\n近年，人工音声技術の進歩やクラウドサービスの普及により，音声認識や対話制御と\nいった技術を容易に利用できるようになり，それを活用し",
            "ウドサービスの普及により，音声認識や対話制御と\nいった技術を容易に利用できるようになり，それを活用した英語学習アプリの開発[2] や，\nロボットを用いた対話システムの研究[3] が進められている．しかし，これらのシステム\nでは，学習相手がイラストやロボットで表現されている場合が多く，実際の人間との会話\nに近い臨場感や緊張感を体験することは難しい．また，会話の中で質問が投げかけられた\n2\n際も，相手が実在の人物ではないため，学習者が長時間考え込むことがあり，自然な会話\nの流れが途切れてしまう場合がある．これにより，実際の会話に近い学習環境を提供する\nには限界があると言える．このような背景のもと，テクノロジーを活用した言語学習の革\n新が求められている[4]．\n1.1.3\n英会話に対する不安\n日本人の多くが英語で話すことに対して不安を抱えていることが調査から明らかになっ\nている[5]．「英語で話すことが得意ですか」に対し，「得意」または「どちらかといえば\n得意」と回答した人は47.8%だった一方で，「苦手」または「どちらかといえば苦手」と\n回答した人は52.2%と過半数を占めた．つまり，英語",
            "方で，「苦手」または「どちらかといえば苦手」と\n回答した人は52.2%と過半数を占めた．つまり，英語で話すことが苦手であると感じてい\nる人の割合は，得意であると感じている人を上回っている状況が浮き彫りになった．\n図1-2: 英語を話すことに対する自信（[5] より引用）\nさらに，「苦手」または「どちらかといえば苦手」と回答した52.2%の回答者に対して\nその理由を尋ねたところ，最も多かったのは「語彙力に自信がないから（60.9%）」であ\nり，次いで「流暢に話せないから（60.5%）」，「発音に自信がないから（53.6%）」という\n結果が得られた．これらの結果から，日本人が英語で話すことに対して感じる不安は，言\n語そのものの知識不足および技術的な側面に起因していることが伺える．\n3\n図1-3: 英語を話すことが苦手な理由（[5] より引用）\n特に，「語彙力に自信がない」との回答が多かったことは，学校教育や自主学習の中で\nの単語学習の重要性が高い一方で，実際に会話でその語彙を適切に使用する経験が不足し\nている可能性を示唆している．また，「流暢に話せない」と感じる人が多いことは，日常\n的な英",
            "験が不足し\nている可能性を示唆している．また，「流暢に話せない」と感じる人が多いことは，日常\n的な英語でのアウトプット機会が少ないことや，実践的な会話練習の不足が要因として挙\nげられる．さらに，「発音に自信がない」という回答は，日本の英語教育がリスニングや\n発音指導に十分な時間を割いていない現状や，学習者自身が正しい発音を確認する機会の\n不足を反映していると考えられる．\nこれらのデータから推測されるのは，日本人の英語学習において，理論的な学習に加え\nて，実践的かつ効果的なアウトプットの機会を増やすことが重要であるという点である．\n語彙力や流暢さ，発音といった要素は，一朝一夕で克服可能であるものではなく，日常的\nな実践の中で徐々に自信を育む必要がある．したがって，英語を話す環境をシミュレー\nションする技術や，実際の会話に近い練習機会を提供する教育手法の開発が，日本人の英\n語スキル向上に向けた鍵となると考えられる．\n1.2\n研究目的\n1.1 節で述べたように，日本人が英語を話す際に感じる不安や課題として，語彙力や発\n音への自信不足，流暢に話すことへの不安が挙げられる．また，従来の英語学習ツ",
            "や課題として，語彙力や発\n音への自信不足，流暢に話すことへの不安が挙げられる．また，従来の英語学習ツールで\n4\nは，リアルな対話環境を再現することが難しく，実際のコミュニケーションで必要なスキ\nルを効果的に習得することが困難であった．これらの課題を解決するため，本研究では，\nバーチャル・リアリティ技術を活用した英語学習システムを提案する．バーチャル・リア\nリティ技術を活用し，ヘッドマウントディスプレイを通じて学習者をバーチャル空間に誘\n導することで，リアルな対話環境を再現する．本環境では，AI アバタが学習者の対話相\n手となり，現実に近いシナリオを展開する．\n従来の英語学習ツールでは，実際の会話に必要な「臨場感」や「相手との即時的な応答」\nの要素が不足していた．また，語彙力や発音への不安，流暢さの欠如が原因で多くの学習\n者が英語で話すことに消極的であるという課題があった．本研究では，AI アバタがリア\nルな非言語的表現や応答を行うことで，これらの課題を克服し，学習者に自然でストレス\nの少ない対話体験を提供することを目指す．\n具体的には，本システムは以下の点を目標とする．\n1. スピーキ",
            "ない対話体験を提供することを目指す．\n具体的には，本システムは以下の点を目標とする．\n1. スピーキング力の向上の向上: バーチャル空間のリアリティとAI アバタの自然な挙\n動を通じて，学習者のスピーキング力の向上を目指す．\n2. 学習者の英会話に対する自信の向上: AI アバタとの対話環境において，学習者が積\n極的に発話練習が可能である場を提供し，英会話に対する自信を培う．\n本研究の成果は，学習者が英語に対する自信を持ち，実生活での英語コミュニケーション\nに積極的に取り組むための新しい学習アプローチを提案するものである．\n5\n第2章\n関連研究・技術\n本章では，本研究に関連する先行研究および，バーチャル・リアリティを利用した技術，\nVR を用いた言語教育システムについて述べる．\n2.1\nオンライン英会話の教育的検証\n大和田はオンライン英会話プログラムの教育的効果を，質問紙調査とスピーキングテ\nストによって検証した[6]．2015 年6 月から7 月に実施された「英会話サプリ」では，学\n部生37 名（全員女子）が参加した．受講生の週平均レッスン回数を分析すると，週1 回\n未満が16 名で",
            "生37 名（全員女子）が参加した．受講生の週平均レッスン回数を分析すると，週1 回\n未満が16 名で最多，次いで週6 回以上7 回未満が7 名だった．理想的な週3 回以上の受\n講者は17 名（45.9%）であり，学習意欲の高さが多くの受講回数に繋がっていることが\n示唆された．プログラム終了後のアンケート（回答率48.6%）では，「英語を話すことへ\nの抵抗が減った」（M=4.79，SD=.61）が最も高評価だったが，「英語を話す力が伸びた」\n（M=3.95，SD=1.19）や「文法力が伸びた」（M=3.26，SD=1.07）は表2-1 のように相対的\nに低い評価だった．これには短期間であることや受講回数の差が影響している可能性があ\nる．自由記述では，「先生が親しみやすい」といった肯定的意見のほか，「指導力のばらつ\nき」や「キャンセル制約」などの課題も指摘された．受講生のスピーキング力はVersant\nSpeaking Test によって図2-1 のように評価された．このテストは音声認識と自動採点で総\n合点（20～80 点）とCEFR レベルを算出し，A1 からC2 までの6 段階で言語能",
            "動採点で総\n合点（20～80 点）とCEFR レベルを算出し，A1 からC2 までの6 段階で言語能力を評価\nする．受講前後の比較では，A，C，E の3 名にスコアとレベルの上昇が見られた．特に\nA は，4 か月間で10 点向上し，CEFR で1 レベル上昇した．一方，B はスコアが下がり，\nD は変化がなかった．\n6\n表2-1: 英会話サプリに対するアンケート結果（[6] より引用）\n質問内容\n平均値（M）\n標準偏差（SD）\nレッスンの内容には満足した\n4.32\n1.13\n先生の教え方には満足した\n4.21\n1.32\n英語を話す力が伸びた\n3.95\n1.19\n英語を聞く力が伸びた\n4.05\n1.15\n英語の語彙（単語の数）が増えた\n4.37\n0.74\n英語の文法の力が伸びた\n3.26\n1.07\n英語の発音がよくなった\n3.84\n1.18\n英語学習の意欲が増えた\n4.63\n0.67\n英語を話すことの抵抗感が減った\n4.79\n0.61\n今回は楽しく英語を学ぶことができた\n4.42\n1.09\n機会があればオンライン英会話を続けてみたい\n4.42\n1.23\n図2-1: Versant Spe",
            "\n機会があればオンライン英会話を続けてみたい\n4.42\n1.23\n図2-1: Versant Speaking Test 結果（[6] より引用）\n先行研究によると，短期留学（4～5 週間）で平均3.45 点，長期留学（1 年間）で約6.9\n点の上昇が期待される中，A の10 点の伸びは特筆すべき結果であった[7]．A は4 か月間\nで139 回（約57.9 時間）受講しており，集中的な学習が成果を上げたと考えられる．以\n上の結果から，英会話サプリは短期間で英語への抵抗を減らす効果がある一方で，スピー\nキング力や文法力の向上にはさらなる時間と努力が必要であることが示された．\n7\n2.2\n教育・言語支援システムとしてのAR・VR の有用性\n近年，AR/VR は教育分野でも活用されている．例えば，Google 社は学習を目的にVR\n体験を提供する「Expeditions」を開発し，NASA は星座や天体を視覚化する「SkyView」\nを発表した．さらに，AR/VR コンテンツ作成技術（ARToolkit，Vuforia など）も進化を続\nけている．山元は，AR/VR を活用した教育・学習支",
            "oolkit，Vuforia など）も進化を続\nけている．山元は，AR/VR を活用した教育・学習支援システムの有用性を紹介し，特に\n産業分野，とりわけ自動車におけるAR 技術の応用に触れながら，教育への貢献と課題に\nついて解説した[8]．ここでAR はAugmented Reality の略称で，日本語では「拡張現実」\nを意味する．現実世界での体験にデジタル情報を重ね合わせ，新たな価値を生み出すXR\n（Cross Reality）と呼ばれる先端技術のひとつである．主にスマートフォンやスマートグ\nラスを通し，目で見ている光景にCG 映像などが合成され，あたかも実際に存在するよう\nに見える技術を指す．\n一方VR はVirtual Reality の略称である．VR ヘッドセットを装着することで視覚的に\n現実世界を遮断し，デジタル上に再現されたバーチャル空間をまるでその場にいるように\n体感できる技術である．VR はバーチャル空間を現実のように体験できる点が最大の特徴\nで，現実世界での体験をベースにしたAR とは明確に異なる．最近ではインターネット上\nに作られたバーチャル世界「メタバース」に",
            "ースにしたAR とは明確に異なる．最近ではインターネット上\nに作られたバーチャル世界「メタバース」に没入するための手段として，VR は大いに関\n心を集めている．図2-2 にAR とVR のイメージを示す.\n図2-2: AR とVR （[9] より引用）\n次に教育・学習支援システムにおける有用性について，本稿ではVR に関するもののみ\n取り上げる．Non-immersive VR の例として，高校生対象の科学実験シミュレーションが\n可能なシステムが提案されており，このシステムではディスプレイにVR 実験空間を提\n示し，Wii Remote を使って操作する．また，Second Life 環境では建築の安全教育をロー\nルプレイングできるシステムもある．Semi-immersive VR では，巨大ディスプレイとキ\nネクトによるジェスチャーを用いて，バーチャル空間で外国語の学習をするシステムや，\n8\nHMD と力覚センサを使って重力のシミュレーションを行うシステムが提案されている．\nFully-immersive VRは多くが、人物の正面・側面・床面の3つの面をスクリーンで囲み、没入\n感の高",
            "-immersive VRは多くが、人物の正面・側面・床面の3つの面をスクリーンで囲み、没入\n感の高いバーチャル体験ができるシステムであるCAVE ベースであり，例えばPDD-NOS\nの児童が安全に横断歩道を渡る訓練を行うシステムや，前庭障害の症状を緩和するため\nにバーチャル空間内で食料品店を歩き回るシステムが提案されている．さらに，HMD を\n使って建築空間のデザインを学習するシステムや，モーションキャプチャーを利用してア\nフリカのDjembe ハンドドラム演奏を練習するシステムもある．\nVR の意義は，バーチャル環境とのインタラクションを通じて現実では実現困難な学習\nを可能にすることである．例えば，外出が難しい学習者がリハビリを受ける際に，恐怖や\n危険を排除したバーチャル空間で学習できる．また，3D の建築物を現実環境に重ねるこ\nとが難しい学習においても有用だ．しかし，バーチャル環境でなければ不可能な学習もあ\nり，例えば重力の体験やドラム演奏の練習などは，必ずしもVR 環境が必要ではない場合\nもある．Non-immersive VR は没入感がないため，VR としての意義が薄く，教",
            "ない場合\nもある．Non-immersive VR は没入感がないため，VR としての意義が薄く，教育利用にお\nいてバーチャル環境とVR を混同しているケースも指摘されている．\n9\n2.3\nバーチャル空間を用いた英会話システム\n2.3.1\nVR 英会話プログラム\nコロナ禍でオンライン英会話が一般化する中，工学部学生には魅力的な学習方法となら\nず，対話の緊張感ややる気低下が課題となった．そこで川崎らは，宮崎大学の学生らを対\n象に図2-3 に示すようなVR が作り出す空間に入って英会話を楽しむ学習活動への参加を\n募った[10]．デジタルツールや工学技術への関心が高い学生には，VR 技術を用いた英会\n話が有効と考えられ，VR 空間でのゲーム感覚のロールプレイを取り入れたプログラムが\n実施された．参加者はヘッドセットを用い，異なる場面設定で英会話を行い，最終回には\n討論を体験した．VR 空間でのロールプレイにより，英会話を楽しむ参加者が多く，語彙\n増強や復習の必要性が認識されるなど，英語学習への主体的な意識の変化が見られた．こ\nの結果を踏まえ，早期に英語自律学習方法を指導する仕組みの導入が効果",
            "主体的な意識の変化が見られた．こ\nの結果を踏まえ，早期に英語自律学習方法を指導する仕組みの導入が効果的であると示唆\nされた．\n図2-3: 参加募集を呼びかけるポスター（[10] より引用）\n10\n2.3.2\n非言語情報を取り入れたVR 英会話教育\nVR 空間の臨場感を活かした英会話学習システムが登場している中で，鈴木らはVR 空\n間のアバタとの音声対話を利用した英会話を，アバタの有無で比較し，アバタの存在が好\n意的に評価されることを示した[11]．さらに植田らは非言語情報に着目し，身体動作を\n組み合わせた3 つの条件で，英会話練習を想定し非言語コミュニケーションの実験を行っ\nた[12]．タスク達成時間，ユーザの視線対象とそれを見た間を測定し，3 種類のアンケー\nトと合わせて，VR 空間内でのアバタとの会話においても，現実の会話と同様に，ユーザ\nが用いる非言語情報が重要といえるかどうか，またそのユーザビリティを調査した．結\n果，VR 空間のアバタとの会話においても，現実でのコミュニケーションと同様，ユーザ\nとアバタの両者において非言語情報が現実の会話を再現する上で重要であること，アバタ\n",
            "ンと同様，ユーザ\nとアバタの両者において非言語情報が現実の会話を再現する上で重要であること，アバタ\nに人間らしさを与えることを示した．\n図2-4: システムの全体構成図（[12] より引用）\n11\n2.4\nまとめ\nオンライン英会話プログラム「英会話サプリ」の調査では，短期間で英語を話すことへ\nの抵抗が減少する効果が確認された一方，スピーキング力や文法力の向上には時間と努力\nが必要であることが示された．特に受講回数が多い学生は顕著な成果を上げており，学習\n意欲の高さが結果に影響していると考えられる．指導力のばらつきやシステム上の制約な\nどの課題も明らかになった．\nまた，AR/VR 技術は教育支援において現実では困難な学習を可能にする点で有用性が\n高く，外国語学習やリハビリ訓練，建築デザインの学習など多岐にわたる応用事例があ\nる．しかし，VR でなければ実現できない学習内容は限定的であり，非没入型VR の効果\nやVR とバーチャル環境の混同といった課題も指摘されている．\n2.3.2 の研究では評価指標としてアンケートを採用していた．アンケートを通じて学習\n者の満足度や没入感の向上が確認され",
            "は評価指標としてアンケートを採用していた．アンケートを通じて学習\n者の満足度や没入感の向上が確認されている一方, 具体的な学習成果を定量的に評価する\n研究は十分に行われていない．VR を活用した英会話コミュニケーションに焦点を当てた\n研究もいくつか存在しているが（2.3），これらは主にHMD を着用した実際の人間同士の\n対話や，あらかじめ設定された台本に基づいて行われるコンピュータとの対話が中心で\nあった．\n以上のことから，本研究ではAI アバタとの会話を通じて参加者が自由に発言し，その\n発言に基づいて会話が自然に展開されることで，対人での英会話における緊張感や不安感\nを軽減し，英会話のモチベーションを向上させることを目的とする．このため，従来の台\n本に沿った会話や，対話相手に依存することなく，実際の会話に近いダイナミックでフレ\nキシブルなコミュニケーションを体験できる可能性がある．加えて，AI アバタの性格や\n空間設定が学習者に親しみやすさを与えるようにデザインし，学習者により安心して会話\nに挑戦できる環境を提供することで，学習者の英会話コミュニケーション能力の向上に寄\n与することを",
            "会話\nに挑戦できる環境を提供することで，学習者の英会話コミュニケーション能力の向上に寄\n与することを目指す．\n12\n第3章\nバーチャル・リアリティを用いたAIアバ\nタとの英会話コミュニケーションシステム\n3.1\nシステム概要\n本節では本研究で提案するバーチャル・リアリティにおいて，AI アバタと英会話コミュ\nニケーションするシステムについて説明する．これはヘッドマウントディスプレイを用\nいたバーチャル・リアリティ技術により，現実を模した空間でAI を組み込んだアバタと\n自由に英会話コミュニケーションを行うことで，英会話への意欲の維持・向上を目的とし\nたシステムである．図3-1 に提案システムの全体図を示す．英会話を行う人はシステム利\n用状況や会話進行度を確認するデバイスとしてヘッドマウントディスプレイを装着する．\n被験者の地点・視点移動，発言内容の録音，環境設定を行うボタンを割り振った付属機器\nをコントローラとして扱う．コントローラを用いてAI アバタの近くに移動し，録音ボタ\nンを長押しすることで自身の発言の録音が開始される．録音ボタンを放すと発言した内容\nがAPI を用いてChat ",
            "することで自身の発言の録音が開始される．録音ボタンを放すと発言した内容\nがAPI を用いてChat GPT に転送され，応答を受け取ることでAI アバタとの会話が可能\nにとなる．API の仕組みについては詳しい説明を後述する．\n図3-1: 提案システムの全体図\n13\n3.2\n空間投影手法とバーチャル空間内における表現手法\n本節では空間投影手法である作成されたバーチャル空間内でのバーチャル・リアリティ\nによる表現手法について述べる．\n3.2.1\n空間投影手法\n本研究ではヘッドマウントディスプレイとしてMeta 社のMeta Quest 3 [13] を用いる．\n図3-2 にMeta Quest 3 の外見を示す．Meta Quest 3 は，Meta 社が開発したスタンドアロン\n型のVR/MR ヘッドセットである．2023 年10 月に発売された当デバイスは，Snapdragon\nXR2 Gen 2 プロセッサによる高い処理能力と片目あたり2064 × 2，208 ピクセルの高解像\n度ディスプレイを備え，前作であるMeta Quest 2 の2 倍以上の性能向上を実現している．\nまた，パ",
            "スプレイを備え，前作であるMeta Quest 2 の2 倍以上の性能向上を実現している．\nまた，パンケーキレンズの採用による40%の薄型化や，RGB カラーカメラによる高品質\nなカラーパススルー機能によって現実世界とバーチャル世界を融合させた自然なMR 体\n験が可能となっている．さらに精度の高いハンドトラッキング機能によってコントロー\nラーなしで手の動きを正確に認識し，自然な操作感を提供することで，ゲームからビジネ\nス，教育，日常生活に至るまで幅広い用途で活用が期待されている．\n図3-2: Meta Quest 3（Meta 社）\n14\n3.2.2\nバーチャル空間内における表現手法\n本システムの開発にはUnity Technologies 社が提供するUnity [14] を用いた．Unity は無\n料で利用可能なゲームエンジンであり，作成したプロジェクトはAndroid やPC，HMD な\nど様々な環境にビルド可能である．また，様々なユーザーが作成したアセットがアセット\nストアから利用可能となっており，短期間での開発が可能である．本システムはHMD 上\nで動作するため，HMD 上の",
            "用可能となっており，短期間での開発が可能である．本システムはHMD 上\nで動作するため，HMD 上のあらゆる情報を扱えるようにする拡張パッケージ（OculusXR）\nを導入した．\n本研究では作成されたバーチャル空間上での会話が行われるが，より現実的な空間での\nコミュニケーションが対面でのコミュニケーションに近づくと考えられる．そこでバー\nチャル空間の作成としてUnity のAsset であるApartment Kit [15] を利用した．Apartment\nKit は，Brick Project Studio が提供する無料のUnity アセットであり，建築やインテリア\nの制作を効率化するモジュール式の建築キットである．このアセットには200 種類以上\nの豊富な3D プレハブが収録されており，リビングルーム，キッチン，寝室，浴室といっ\nた様々な空間をデザインを可能にするため，本研究のバーチャル空間の作成に適すと考え\nた．図3-3 に作成したバーチャル空間を示す．\n図3-3: 作成したバーチャル空間\n後述するAI アバタは外国人を想定した外見や性格の付与を行ったため，一般的な海外\nの家",
            "ーチャル空間\n後述するAI アバタは外国人を想定した外見や性格の付与を行ったため，一般的な海外\nの家のリビングルームを模して作成した．壁や床，家具等それぞれに物理演算を施すこと\nで被験者やAI アバタのすり抜けを防止した．\n15\n3.3\nAI アバタの作成\n本節ではAI アバタの作成方法とその使用について述べる．本システムの開発にはUnity\nアセット上のNPC AI エンジンであるConvai [16] を利用した．Convai とは，開発者やク\nリエイター向けのプラットフォームであり，バーチャル環境や現実世界で多モーダルな\n認識能力を持つキャラクターを直感的に設計できるツールを提供している．Convai では，\nキャラクターの動作，言語能力，知識，感情状態などを詳細にカスタマイズでき，ゲーム\n内での動的な反応やリアルなインタラクションを実現可能である．また，髪型，体型，衣\n服，アクセサリーなどを選択して3D キャラクターをゼロから作成し，その外見を個性に\n合わせてカスタマイズすることができる．\n本研究においてAI アバタは非常に重要な役割を担う．特に被験者がAI アバタと会話す\nる",
            "ができる．\n本研究においてAI アバタは非常に重要な役割を担う．特に被験者がAI アバタと会話す\nる際，現実的な環境を作り出すためには，外見や会話内容が自然なものであることが求め\nられる．そのため，本来ゲームのNPC 作成の際に利用される当システムが適していると\n考えた．図3-4 に作成したAI アバタを示す．\n図3-4: 作成したAI アバタ（Gonzalez（左）とJessy（右））\n作成したAI アバタはGonzales とJessy の計2 体である．それぞれに設定したキャラク\nター背景を表3-1 に示す．会話の中で発言内容が二転三転しないために，キャラクター背\n景は詳細に記述したが，ここでは特に重要な項目だけを示す．\n表3-1 に示した内容は初対面の外国人と会話をする際，取り扱われやすい話題を示して\nいる[17]．それぞれ年齢，出身地，出身地で人気なもの，好きなスポーツ，そのスポーツ\nでのポジションである．後述するシステムの評価実験では，これらの情報を利用しシステ\nムの習熟度を測る．\n16\n表3-1: 作成したAI アバタのキャラクター背景\n名前\n年齢\n出身地\n地元で人気なも",
            "測る．\n16\n表3-1: 作成したAI アバタのキャラクター背景\n名前\n年齢\n出身地\n地元で人気なもの\n好きなスポーツ\nポジション\nGonzales\n20 歳\nブラジル\nカーニバル\nサッカー\nミッドフィルダー\nJessy\n21 歳\nアメリカ合衆国\nグランドキャニオン\nバスケットボール\nポイントガード\n3.4\nシステム設計およびスクリプト生成手法\n本節では通信手法およびシステム設計について述べる．\n3.4.1\nシステム設計\n本稿ではシステム設計について述べる．図3-5 にシステム設計のシーケンス図を示す．\nまず，学習者の発話データをマイク入力として取得し，この音声データは音声認識システム\n（Convai STT）によりテキスト化される．次に，テキスト化された発話データはOpenAI [18]\nを用いて回答文が生成される．この回答文は音声合成システム（Convai TTS）を用いて\n音声データに変換される．そして，生成された音声データがAI アバタの発話として再生\nされることで，学習者はバーチャル・リアリティ内で自然な会話を体験することが可能で\nある．本システムは音声認識，自然言語処理，音",
            "チャル・リアリティ内で自然な会話を体験することが可能で\nある．本システムは音声認識，自然言語処理，音声合成の各プロセスが統合された構造と\nなっており，リアルタイムでの双方向コミュニケーションを実現している．\n図3-5: システム設計のシーケンス図\n17\nここで，Meta Quest 3 のコントローラへのボタン割り振りを図3-6 に示す．学習者は左\nコントローラのスティックを利用して自身の位置を変更し，AI アバタに近づく．この時，\n右コントローラのスティックを利用して視点変更が可能である．AI アバタに近づくと会\n話内容が表示されるバーが出現し，その状態でA ボタンを押すことで話しかけることが\n可能である．\n図3-6: コントローラへのボタン割り振り\n3.4.2\nアバターの会話スクリプト生成手法\n本システムにおいて，AIアバタとの会話を実現するためにConvaiのSpeech to Text（STT），\nText to Speech（TTS）機能とOpenAI を利用した．スクリプト生成手法を図3-7 に示す．\nUnity 上で入力された学習者の音声データをAPI を用いてConva",
            "成手法を図3-7 に示す．\nUnity 上で入力された学習者の音声データをAPI を用いてConvai に送信し，Convai のSTT\n機能利用して文字列に変換する．変換された文字列をOpenAI のAPI を用いてChat GPT\nに送信する．その文字列に対する回答をChat GPT が生成し，Convai に送り返す．Convai\nのTTS 機能利用して文字列に変換し，Unity 上のAI アバタから音声データを再生する．\n18\n図3-7: AI アバタのスクリプト生成手法\n3.5\nまとめ\n本研究では，バーチャル・リアリティ環境においてAI アバタとの英会話を可能にする\nシステムを提案した．このシステムは，ヘッドマウントディスプレイMeta Quest 3 を用\nい，現実世界に近い空間でAI アバタと自然な英会話を行うことを目的としている．学習\n者はコントローラを使用して位置や視点を調整し，AI アバタに近づいて発話を録音する\nことで，リアルタイムな対話を体験できる．発話内容はConvai のSTT 機能でテキスト化\nされ，OpenAI のAPI を介してChatGPT による応",
            "nvai のSTT 機能でテキスト化\nされ，OpenAI のAPI を介してChatGPT による応答が生成される．その後，Convai のTTS\n機能を通じて音声化され，AI アバタから再生されることで自然な会話が実現される．\nバーチャル空間の作成にはUnity のApartment Kit アセットを用い，海外の一般的なリ\nビングルームを模した空間を構築した．また，Convai を利用して外国人を想定したAI ア\nバタを作成し，学習者が会話内容に集中できるようリアルで詳細なキャラクター背景を設\n定した．\n本システムは，音声認識，自然言語処理，音声合成の各技術を統合することで，リアル\nタイムかつ双方向のコミュニケーションを実現している．これにより，学習者は英会話を\n通じて言語スキルを向上させるだけでなく，英語を話すことへの心理的なハードルを下げ\nる効果も期待される．\n19\n第4章\nスピーキング力および英会話に対するモチ\nベーションへの影響の評価実験\n4.1\n実験目的\n本実験の目的は，バーチャル空間上でAI アバターと英会話コミュニケーションを行う\nシステムが，学習者の英語スピーキング",
            "ーチャル空間上でAI アバターと英会話コミュニケーションを行う\nシステムが，学習者の英語スピーキング力の向上および英会話に対するモチベーションの\n変化に与える影響を評価することである．本システムを利用した学習環境が，従来の学習\n手法に比べて英語スピーキング能力の改善にどの程度寄与するのかを明らかにするとと\nもに，学習者の英会話への抵抗感を軽減し，意欲を向上させる効果があるかを検証するこ\nとを目指す．\n4.2\n実験環境\n男性8 名，女性2 名の計10 名の大学生を対象に，ヘッドマウントディスプレイを装着し，\n本システムを利用してAI アバタと英会話コミュニケーションを行ってもらった．図4-1\nに実験に利用した部屋を示す．被験者はこの部屋で，着席した状態で実験を行う．バー\nチャル空間上での移動はコントローラ制御にて行うため，部屋の広さや構造の条件は必要\nないが，外音の少ない環境で実験を行った．\n図4-1: 実験環境の部屋の様子\n20\n4.3\n評価指標\n本節では本実験での評価指標について説明する．\n4.3.1\nPROGOS for English speaking\n本研究では，英語スピーキン",
            "る．\n4.3.1\nPROGOS for English speaking\n本研究では，英語スピーキング能力の変化を評価するためにPROGOS を指標として用\nいた．PROGOS は，実践的なビジネスシーンを基に英語スピーキング能力を測定するオ\nンラインテストで，幅広い仕事に必要なスピーキング力を評価可能である．受験形式は\nオープンクエスチョン形式で，受験時間は約20 分と短時間で実施できるのが特徴である．\nまた，測定結果は最短2～3 分で返却されるため，受験者がすぐに自分の英語力を把握で\nきる仕組みとなっている[19]．\nPROGOS の評価は，国際的に使われている言語運用能力の基準であるCEFR（Common\nEuropean Framework of Reference for Languages）[20] に準拠している．CEFR は，言語運\n用能力をA1 からC2 までの6 段階で評価し，世界中の学校教育，学術研究，企業などで\n広く活用されており，国際標準となっている．この指標によって，英語力を「基礎段階の\n言語使用者（A1～A2）」「自立した言語使用者（B1～B2）」「熟達し",
            "よって，英語力を「基礎段階の\n言語使用者（A1～A2）」「自立した言語使用者（B1～B2）」「熟達した言語使用者（C1～\nC2）」というレベルで評価する．図4-2 に各試験団体のデータによるCEFR との対照表を\n示す．本研究では，このCEFR 基準に基づくスコアを使ってスピーキング能力の変化を客\n観的に示した．\n図4-2: 各試験団体のデータによるCEFR との対照表( [20] より引用)\nPROGOS のテストは，以下の5 つのセクションで構成されている．1 つ目はインタビュー\n21\n形式での自由回答，2 つ目は英文の音読，3 つ目はプレゼンテーション形式でのスピーチ，\n4 つ目はグラフや図を使ったプレゼンテーション，5 つ目はロールプレイである．この多\n様な構成によって，受験者の総合的なスピーキング能力を測定することができる．たとえ\nば，インタビュー形式では自然なコミュニケーション能力を，音読では発音や流暢さを，\nプレゼンテーションでは論理的思考と表現力を評価する．また，グラフや図の活用やロー\nルプレイを通じて，実践的なビジネスシーンで求められる能力も測定可能である．図4-2\n",
            "図の活用やロー\nルプレイを通じて，実践的なビジネスシーンで求められる能力も測定可能である．図4-2\nに指標別の評価項目を示す．\n図4-3: PROGOS における指標別評価項目\n本研究では，バーチャル空間上でAI アバターを使った英会話システムの利用前後で\nPROGOS を実施し，スピーキング能力の変化を分析した．これにより，システムが英語\nスピーキング力の向上に与える影響の定量的な評価を行った．\n4.3.2\nAI アバタとの会話に関するクイズ\nシステムを適切に利用できているかを測るために，図4-4 に示すクイズを設けた．この\nクイズはAI アバタの年齢，出身地，出身地で人気なもの，好きなスポーツ，そのスポー\nツでのポジションを尋ねており，会話内容から回答を導くものとなっている．問題自体\nは，最低限の英会話を行うことができれば回答できる難易度となっている．また，設問は\n22\n3.3 節で示したように初対面の外国人と会話をする際，取り扱われやすい話題を示してお\nり，AI アバタと会話する際のシナリオとしての役割も兼ねている．最後の自由に感想を\n記載する設問は，被験者が自然なコミュニケーシ",
            "のシナリオとしての役割も兼ねている．最後の自由に感想を\n記載する設問は，被験者が自然なコミュニケーションを行うことで得た情報を記すために\n設けた．\n図4-4: クイズの内容\n4.3.3\nアンケート\n本実験後，VR の操作に対する感想や英会話に対するモチベーションの変化を調査する\nためにアンケートを設けた．「強く同意する」，「同意する」，「どちらともいえない」，「同意\nしない」，「強く同意しない」の5 段階で評価する．以下にアンケートの設問内容を示す．\n1. VR の操作は難しかったですか？\n23\n2. クイズにより円滑に会話が進みましたか？\n3. AI アバタと自然に会話することができましたか？\n4. 対人で話す際と同じような感覚を得れましたか？\n5. 英会話コミュニケーションへのモチベーションが向上しましたか？\n6. 英語を話すことに対して前向きな気持ちが強まりましたか？\n7. 英語を話すことに対して自信がついたと感じますか？\n8. このシステムをまた利用したいとおもいましたか？\n4.4\n実験方法\n以下に実験の流れを示す．\n1. スピーキングテストを実施\n2. (HMD を装着し)，",
            "4\n実験方法\n以下に実験の流れを示す．\n1. スピーキングテストを実施\n2. (HMD を装着し)，1 体目のAI アバタと12 分間の英会話開始\n3. 英会話後，クイズに回答\n4. (HMD を装着し)，2 体目のAI アバタと12 分間の英会話開始\n5. 英会話後，クイズに回答\n6. スピーキングテストを実施\n7. アンケートに回答\n各実験参加者は，実験の開始時に英語スピーキング能力の基礎データを取得するため，\nはじめにPROGOS を受験し，システム利用前のスピーキング力を測定する．この初期評\n価により，参加者のスピーキング能力の基準値が得られる．その後，ヘッドマウントディ\nスプレイを装着し，バーチャル空間内でAI アバタ（Gonzales）と12 分間の英会話セッショ\nンを行う．このセッションでは，自由にAI アバタとの対話を進めるとともに，制限時間\n内に関連するクイズに回答を記入する．ここで，当クイズは実験前に被験者に説明されて\nおり，設問内容に沿って会話が展開されることが期待される．\nさらに，1 週間後，参加者は再びヘッドマウントディスプレイを装着し，別のAI アバタ\n（J",
            "される．\nさらに，1 週間後，参加者は再びヘッドマウントディスプレイを装着し，別のAI アバタ\n（Jessy）と同様に12 分間の英会話セッションを行う．この2 回目のセッションでも，AI\n24\nアバタとの会話を進めながら，制限時間内にクイズに回答を記入する．1 回目と2 回目の\nセッションで異なるAI アバタを使用することで，参加者が異なる話者との対話にどのよ\nうに適応するかを検証できるよう設計されている．\n最終的に，2 回目の英会話セッション終了後，参加者にはアンケートに回答してもらい，\nシステムの使用感や英会話に対するモチベーションの変化などを調査する．加えて，再度\nPROGOS を受験することで，システム利用前後でのスピーキング能力の変化を測定する．\n尚，取得したPROGOS のデータはT 検定を行い有意差の有無を判定した．T 検定とは条\n件の異なる2 つの群において、それぞれの群の平均値の間の差が統計的に有意なものであ\nるか判定する手法である．これら一連のプロセスにより，バーチャル空間内での英会話体\n験が英語スピーキング能力に及ぼす影響を総合的に評価する．\nここで図4-5 に",
            "ャル空間内での英会話体\n験が英語スピーキング能力に及ぼす影響を総合的に評価する．\nここで図4-5 にVR 上で会話をしている様子を示す.\n図4-5: VR 上での会話の様子\n25\n第5章\n実験結果と考察\n5.1\nPROGOS の結果と考察\n本節では，オンラインテストPROGOS を用いて測定したスピーキング力の評価結果お\nよび考察を述べる．あらかじめ結果を分かりやすくするため，PROGOS の評価書式を表\n5-1 のように変換した．PROGOS ではPre-A1 からC1 までの評価が得られるが，本実験で\nはB2 以上のスコアは得られなかったためB2 までの変換を行った．\n表5-1: PROGOS のスコア変換\nレベル\nPre-A1\nA1\nA1High\nA2\nA2High\nB1\nB1High\nB2\nスコア\n1\n2\n3\n4\n5\n6\n7\n8\n表5-2 に各被験者（A からJ）のPROGOS のスコアを，図5-1 に各被験者のスコア変化\nを示す．なお，各被験者の横にあるバーのうち，下側が1 回目の試験結果で上側が2 回目\nの試験結果である．1 回目と2 回目の結果をスコアに換算し，全体の平均",
            "目の試験結果で上側が2 回目\nの試験結果である．1 回目と2 回目の結果をスコアに換算し，全体の平均値を算出したと\nころ，平均で0.6 ポイントの上昇が見られた．個別の結果を見ると，被験者A，E，H，I\nの4 名が1 ポイント以上のスコア上昇を示し，特に被験者I はA2 からB1 に上昇するなど\n顕著な変化が観察された．一方で，被験者B，G，J の3 名はスコアに変化がなく，被験\n者F は1 ポイントのスコア減少が見られた．\n表5-2: 各被験者のPROGOS のスコア\nA\nB\nC\nD\nE\nF\nG\nH\nI\nJ\n平均値\n1 回目\n3\n6\n5\n4\n1\n5\n4\n3\n4\n5\n4\n2 回目\n4\n6\n6\n5\n2\n4\n5\n3\n6\n5\n4.6\n26\n図5-1: 各被験者のPROGOS のスコア変化\n表5-3 に示すようにT 検定の結果，PROGOS の結果には有意な差があることが明らかに\nなった．結果として，平均スコアが0.6 ポイント上昇したが，この要因については慎重に\n考える必要がある．一つの可能性として，本研究で開発した仮想空間上でのAI アバタと\nの英会話システムがスピーキング能力の向上に寄与",
            "として，本研究で開発した仮想空間上でのAI アバタと\nの英会話システムがスピーキング能力の向上に寄与した可能性が挙げられる．システム\n内では，クイズ形式やアバタとの対話を通じて英語をアウトプットする機会を提供してお\nり，これが被験者のスピーキング力にポジティブな影響を与えた可能性がある．\n表5-3: PROGOS の結果におけるスコア比較\nパターン\n平均値\np 値\n有意差\n1 回目\n4\n2 回目\n4.6\np ＜0.05\nあり\n一方で，スコア上昇が試験そのものへの慣れによるものの可能性も否定できない．PRO-\nGOS は形式化された問題を含むため，1 回目の受験を通じて試験形式や回答の流れに慣れ\nたことが2 回目のスコア向上に繋がった可能性がある．特に，被験者B，G，J のスコア\nが変化しなかったことや，被験者F のスコアが減少したことからも，全員が均一に効果を\n得られるわけではない点が示唆される．\n27\n今回の実験では，各被験者がAI アバタとの対話を行ったのは合計24 分間（12 分間× 2\n回）という短時間だった．そのため，スコア上昇の程度は限定的であり，英語力全体の向\n上を示すに",
            "× 2\n回）という短時間だった．そのため，スコア上昇の程度は限定的であり，英語力全体の向\n上を示すには不足している可能性がある．長期間の利用を通じた効果測定が行われれば，\nより顕著な変化が観察されるかもしれない．\n今後は，システム利用後のスコア上昇が試験への慣れによるものか，あるいはシステム\n自体の効果によるものかをより明確にするために，対照群を設定した実験を実施する必要\nがある．加えて，システム利用期間や利用頻度がスコアに与える影響についても詳細に検\n討していくことが求められる．\n5.2\nアンケートの結果と考察\n本節ではアンケートの結果とその考察を述べる．アンケートの各項目は「強く同意しな\nい」を1，「強く同意する」を5 としてスコアリングした．また，スコアリングした値を\n用いて各モードの各項目の平均スコアを算出した．表5-4 に評価実験のアンケート結果を\n示す．アンケートの各項目について考察を行う．\n表5-4: アンケート結果\n設問\n平均スコア\nVR の操作は難しかったですか？\n1.7\nクイズにより円滑に会話が進みましたか？\n4.3\nAI アバタと自然に会話することができましたか？",
            "7\nクイズにより円滑に会話が進みましたか？\n4.3\nAI アバタと自然に会話することができましたか？\n4.2\n対人で話す際と同じような感覚を得れましたか？\n4.2\n英会話コミュニケーションへのモチベーションが向上しましたか？\n4.6\n英語を話すことに対して前向きな気持ちが強まりましたか？\n4.7\n英語を話すことに対して自信がついたと感じますか？\n4.2\nこのシステムをまた利用したいとおもいましたか？\n4.6\nQ1．VR の操作は難しかったですか？\n本設問の平均スコアは1.7 であった．これは，多くの被験者がVR 操作を難しく感じ\nなかったことを示している．この結果は，本研究で用いたシステムのユーザにとっ\nて扱いやすい設計が寄与していると考えられる．直感的な操作が可能であることで，\n被験者が英会話自体に集中できたことが示唆される．\nQ2．クイズにより円滑に会話が進みましたか？\n本設問の平均スコアは4.3 であった．この高いスコアは，クイズ形式が被験者の英会\n話をスムーズに促進する要因となったことを示唆している．クイズが適切なトピッ\n28\nクを提供し，AI アバタとの会話が一貫性を持つもの",
            "たことを示唆している．クイズが適切なトピッ\n28\nクを提供し，AI アバタとの会話が一貫性を持つものとなった可能性がある．また，\nクイズ形式による構造化が，参加者の負担を軽減し会話を円滑にしたと考えられる．\nQ3．AI アバタと自然に会話することができましたか？\n本設問の平均スコアは4.2 であった．この結果は，AI アバタが自然な対話体験を提\n供できたことを示している．特に，被験者がAI との会話に違和感を覚えることな\nく，親しみを持って会話できた可能性が考えられる．今後，さらにAI の表現力や応\n答精度を高めることで，よりリアルな会話体験が提供できると期待される．\nQ4．対人で話す際と同じような感覚を得れましたか？\n本設問の平均スコアは4.2 であった．このスコアは，VR とAI 技術を組み合わせた\n英会話システムが，対人での英会話と近い感覚を被験者に提供できたことを示して\nいる．対人での会話に近い体験を実現できたことは，本システムの没入感や自然さ\nが高く評価された結果といえる．\nQ5．英会話コミュニケーションへのモチベーションが向上しましたか？\n本設問の平均スコアは4.6 であっ",
            "5．英会話コミュニケーションへのモチベーションが向上しましたか？\n本設問の平均スコアは4.6 であった．これは，本システムが被験者の英会話学習へ\nの意欲を高める効果を持っていることを示唆している．被験者が英会話を楽しみな\nがら学習できたことが，モチベーション向上につながったと考えられる．\nQ6．英語を話すことに対して前向きな気持ちが強まりましたか？\n本設問の平均スコアは4.7 であった．この結果は，本システムが英会話に対するポジ\nティブな感情を強化する役割を果たしたことを示している．被験者がAI アバタとの\n対話を通じて，英語に対する抵抗感を軽減し，より積極的な姿勢を持つようになっ\nたことが示唆される．\nQ7．英語を話すことに対して自信がついたと感じますか？\n本設問の平均スコアは4.2 であった．このスコアは，本システムが英語を話す自信\nを一定程度向上させたことを示している．実践的なシミュレーション環境が，被験\n者の自己効力感を高める一助となったと考えられる．\nQ8．このシステムをまた利用したいとおもいましたか？\n本設問の平均スコアは4.6 であった．この結果は，被験者が本システムを高",
            "用したいとおもいましたか？\n本設問の平均スコアは4.6 であった．この結果は，被験者が本システムを高く評価\nし，再利用への意欲を示していることを反映している．その要因として，システム\nの使いやすさ，学習効果，および楽しい体験が寄与していると考えられる．\n29\n5.3\nクイズの結果と考察\n本実験では，仮想空間上の英会話システムを利用した後，参加者にクイズを実施した．\nクイズは図4-4 の通り6 問で構成され，英会話を通じて得た情報に基づく回答が求められ\nた．その結果，被験者全員が全問正解を達成した．また，クイズの最後に設けた自由記述\n欄では，被験者の多くが好きなスポーツチームやその他の趣味について記載しており，AI\nアバタとの会話内容をさらに発展させた回答が見られた．\n全問正解という結果と5.2 のQ2 から，被験者がシステムを通じて提示された情報を正\n確に把握できたことが示された．このことは，仮想空間上でのAI アバタとの対話が，英\n会話コミュニケーションのスムーズな運用を可能にしたことを示唆している．また，自由\n記述欄に記載された内容から，被験者がシステム内での対話を活発に行い，クイ",
            "を示唆している．また，自由\n記述欄に記載された内容から，被験者がシステム内での対話を活発に行い，クイズの範囲\nを超えた個人的な興味や関心に基づく会話を発展させていたと考えられる．\nクイズ自体は難易度が高く設定されていなかったため，全問正解という結果は予想可能\nであったものの，対話内容を忠実に理解し再現する能力がシステム利用を通じて発揮され\nた点は注目に値する．この結果は，AI アバタを用いた英会話システムが，単なる受け身\nの情報取得ではなく，対話を通じた積極的な情報交換を促進する有用な手段である可能性\nを示している．\n一方で，クイズの結果だけではスピーキング能力向上の因果関係を直接示すには限界が\nある．したがって，英会話システムの有効性をより具体的に検証するためには，被験者へ\nのインタビューや追加の観察データを収集することが今後の課題として挙げられる．\n5.4\nまとめ\n本章ではシステムを用いた評価実験の結果とその考察について述べた．PROGOS の結\n果では，平均スコアが0.6 ポイント上昇し，一定のスピーキング能力の向上が示された．\nただし，これはシステムによる効果だけでなく，試験へ",
            "上昇し，一定のスピーキング能力の向上が示された．\nただし，これはシステムによる効果だけでなく，試験への慣れの影響も考慮する必要があ\nる．また，クイズの全問正解率および自由記述欄の回答から，被験者がシステム内での英\n会話を通じて提示された情報を的確に把握し，対話内容を発展させていたことが示唆さ\nれた．\nさらに，アンケート結果では，被験者がシステムの操作性を高く評価し（「VR の操作は\n難しかったか」のスコア1.7），AI アバタとの会話を通じて英会話へのモチベーションや\n前向きな気持ちの向上（平均スコア4.6 以上）が確認された．特に，「英語を話すことに対\nして前向きな気持ちが強まった」との項目で最も高い平均スコア4.7 が得られたことは，\nシステムの心理的効果を裏付ける重要な結果といえる．\nこれらの結果から，AI アバタを用いた英会話システムは，英語スピーキング能力の向\n30\n上やコミュニケーションへの積極性を促進する可能性が示された．ただし，効果の詳細な\n要因を明らかにするためには，さらなる調査や長期的な利用を視野に入れた研究が必要で\nある．\n31\n第6章\n結論と今後の展望\n6.1\n",
            "らなる調査や長期的な利用を視野に入れた研究が必要で\nある．\n31\n第6章\n結論と今後の展望\n6.1\n結論\n本研究では，仮想空間上でAI アバタを活用した英会話システムを開発し，その有用性\nを評価するためにPROGOS，クイズ，およびアンケートを用いた検証を行った．\n1 章では，英会話の重要性，そして英会話学習における心理的障壁や対人コミュニケー\nションの難しさを解消するために，バーチャル・リアリティ技術の活用が注目されている\n背景を述べた．\n2 章では，従来のVR を利用した英語教育研究の多くが台本に基づいた対話や人間同士\nの対話を中心としており，自由度の高い会話を支援するシステムが不足している現状を示\nした．\n3 章では，本研究で開発したシステムの詳細を説明した．このシステムはMeta Quest 3\nを利用し，Unity とConvai を活用して自然な英会話体験を提供するものである．ユーザー\nはAI アバタとの自由な対話を通じて，英語を話すスキルや自信を向上させることを目指\nした．また，AI アバタの性格や空間設定が学習者に親しみやすさを与えるよう設計され\nている．\n4 章では，",
            "また，AI アバタの性格や空間設定が学習者に親しみやすさを与えるよう設計され\nている．\n4 章では，実験概要を示し，参加者に仮想空間内でAI アバタと会話を行わせた後，PRO-\nGOS，クイズ，アンケートを通じてその効果を検証した．\n5 章では，結果として，PROGOS では平均スコアが0.6 ポイント上昇し，有意な差が認\nめられたことで一定のスピーキング能力の向上が示された．クイズでは被験者全員が全問\n正解し，対話を通じて提供された情報を正確に把握していたことが確認された．さらに，\nアンケートでは，システム操作の簡便性や英会話へのモチベーション向上が高く評価さ\nれ，特に「英語を話すことに対して前向きな気持ちが強まった」という項目で最も高い平\n均スコア4.7 を得た．\n総括として，本研究は英会話学習における心理的障壁を軽減し，モチベーションを向上\nさせるためのVR 技術の可能性を示した点で新規性がある．特に，AI アバタを用いるこ\nとで対人での緊張感を和らげながら，自由度の高い会話を楽しむ学習環境を提供できたこ\nとは，従来の台本型会話システムにはない特徴である．また，実験結果において，",
            "む学習環境を提供できたこ\nとは，従来の台本型会話システムにはない特徴である．また，実験結果において，スピー\nキング能力の向上や学習意欲の高まりが示された点は，本システムの有効性を裏付けてい\nる．一方で，いくつかの課題も明らかになった．例えば，PROGOS のスコア向上がシス\n32\nテムの効果に直接起因するのか，試験への慣れが影響したのかを区別することは困難で\nあった．また，短期間での実験であったため，継続的な使用における効果や課題について\nは十分に検証できていない．\n6.2\n今後の展望\n今後の展望として，以下の点が挙げられる．第一に，本システムの長期的な利用による\n効果を調査し，継続的な英会話能力の向上や心理的変化を明らかにすることが重要であ\nる．第二に，より多様な背景や英語レベルを持つ被験者を対象にした実験を行い，システ\nムの普遍的な有効性を検証する必要がある．第三に，クイズや対話内容をより高度化し，\n学習者のレベルに応じた適応的なシナリオを導入することで，さらなる学習効果が期待さ\nれる．\n本研究を通じて，仮想空間上でのAI アバタを用いた英会話システムが，従来の英語学\n習方法を補完",
            "る．\n本研究を通じて，仮想空間上でのAI アバタを用いた英会話システムが，従来の英語学\n習方法を補完し，新しい学習体験を提供する可能性が示された．今後の研究や改良を通じ\nて，本システムがより多くの学習者にとって有用なツールとなることを期待する．\n33\n謝辞\n本研究の機会を与えて下さり，研究面について大変ご丁寧なご指導を賜りました，青山\n学院大学理工学部情報テクノロジー学科Guillaume LOPEZ 教授に深く感謝申し上げます．\nそして，システム開発をサポートしていただいた阿部悠貴先輩，研究会などを通して助言\nをいただいたLOPEZ 研究室の皆様並びに実験に協力していただいた皆様，金銭面でも精\n神面でも支えていただいた家族に深く感謝いたします．\n2025 年1 月24 日\n宮崎　海斗\n34\n参考文献\n[1] Ballhaus, W. and Chow, W.: Power shifts: Altering the dynamics of the E&M industry,\nhttps://www.pwc.com/gx/en/entertainment-media/outlook-20",
            "//www.pwc.com/gx/en/entertainment-media/outlook-2021/\nperspectives-2021-2025.pdf. (Accessed on 1/14/2025).\n[2] SpeakBUDDY:\nAI\n英会話アプリスピークバディ—音声認識機\n能搭載の英語学習でスピーキング、リスニング力が上達！，\nttps://www.speakbuddy.me/. (Accessed on 1/14/2025).\n[3] 秋本桃子，阿部秀尚，生田祐子，森田武史，山口高平ほか：教師業務ルール分析に\n基づく対話型ロボットを用いた発音練習の実装と評価，情報教育シンポジウム論文\n集，Vol. 2018, No. 26, pp. 185–188 (2018).\n[4] 齊藤真生，櫻井淳，川合康央：頭部搭載型ディスプレイを用いたスペイン語学習シス\nテムの提案，IEICE Conferences Archives, The Institute of Electronics, Information and\nCommunication Engineers (2021)",
            "cs, Information and\nCommunication Engineers (2021).\n[5] 一般財団法人国際ビジネスコミュニケーション協\n会\n：「英語のスピーキングに関する実態と意識」調査\n，\nhttps://www.iibc-global.org/index.html.\n[6] 大和田和治：東京音楽大学におけるオンライン英会話プログラムの導入とその教育\n的効果の検証，研究紀要，Vol. 39, pp. 53–66 (2016).\n[7] 清水裕子，桐村亮，野澤健：経済学部英語圏短期留学プログラムにおけるスピーキン\nグ・テストの実施とその結果報告，立命館高等教育研究，Vol. 14, pp. 91–102 (2014).\n[8] 山元翔：AR/VR の教育・学習支援システムへの利用と課題，教育システム情報学会\n誌，Vol. 36, No. 2, pp. 49–56 (2019).\n[9] goetsch.media:\nhttps://www.goetsch.media/augmented-reality.\n(Accessed\non\n1/14/2025).\n35\n[1",
            "/augmented-reality.\n(Accessed\non\n1/14/2025).\n35\n[10] 川崎典子：「VR 英会話プログラム」パイロットスタディの実践報告，宮崎大学工\n学部紀要，Vol. 51, pp. 147–152 (2022).\n[11] 鈴木直人，廣井富，藤原祐磨ほか：英会話学習システムにおけるCG キャラクタの効\n果と学習者の発話タイミング制御のための付加表現に関する検討，日本音響学会研\n究発表会講演論文集，Vol. 2014 秋期(2014).\n[12] 植田智裕，田辺弘子，小宮山摂ほか：視線とジェスチャにより会話進行が変化するVR\n英会話システム，研究報告ヒューマンコンピュータインタラクション(HCI)，Vol. 2021,\nNo. 6, pp. 1–8 (2021).\n[13] Meta\n社\n：Meta\nQuest\n3,\nhttps://www.meta.com/jp/quest/quest-3/. (Accessed on 1/14/2025).\n[14] Unitytechnology\n社\n：Unity,\nhttps://unity.com/ja. ",
            "] Unitytechnology\n社\n：Unity,\nhttps://unity.com/ja. (Accessed on 1/14/2025).\n[15] BrickProjectStudio:\nApartmentKit,\nhttps://assetstore.unity.com/packages/3d/environments/\napartment-kit-124055. (Accessed on 1/14/2025).\n[16] P.Mukherjee:\nConvaiasset,\nhttps://assetstore.unity.com/packages/tools/behavior-ai/\nnpc-ai-engine-dialog-actions-voice-and-lipsync-convai-235621.\n(Accessed on 1/14/2025).\n[17] DMM\n英\n会\n話：も\nう\n会\n話\nネ\nタ\nに\n困\nら\nな\nい\n！初\nめ\nて\n会った外国人とすぐに打ち解ける英語フレーズ，\nhttps://eikaiwa.dmm.com/blog/learning-engl",
            "英語フレーズ，\nhttps://eikaiwa.dmm.com/blog/learning-english/expressions/\nfirst-conversation/. (Accessed on 1/14/2025).\n[18] OpenAI\n社\n：OpenAI,\nhttps://openai.com/ja-JP/chatgpt/overview/.\n(Accessed\non\n1/14/2025).\n[19] 株\n式\n会\n社\nプ\nロ\nゴ\nス\n：PROGOS,\nhttps://progos.ai/. (Accessed on 1/14/2025).\n[20] 文部科学省：各試験団体のデータによる\nCEFR\nとの対照表，\nhttps://www.mext.go.jp/b_menu/shingi/chousa/shotou/117/\n36\nshiryo/__icsFiles/afieldfile/2016/05/24/1368985_15_1.pdf/.\n(Accessed on 1/14/2025).\n37\n質疑応答\n伊藤　雄一　情報テクノロジー学科　教授\nQ\nVR になったこそ何が",
            "4/2025).\n37\n質疑応答\n伊藤　雄一　情報テクノロジー学科　教授\nQ\nVR になったこそ何がよくなりましたか．\nA\nVR を活用したことで，英語学習における没入感の向上と心理的ハードルの軽減の2\n点で効果が見られました．従来の英語学習ツールでは，対話のリアリティが不足し，\n画面越しの学習では実際の会話に必要な臨場感や緊張感を再現することが困難でし\nた．しかし，VR を用いることで，学習者は仮想空間内で実際にその場にいるかのよ\nうな体験をしながら英会話を行うことができました．また，VR 環境では学習者が\n対人の緊張を感じにくいため，発話に対する心理的な障壁が軽減され，より積極的\nに英語を話せるようになりました．本研究では，PROGOS やアンケートを通じて，\nVR 環境での英会話が学習者のスピーキング力やモチベーションの向上に寄与する\n可能性を示しました．\n戸辺　義人　情報テクノロジー学科　教授\nQ\n研究としての要素はどこにありますか．\nA\n本研究の学術的な貢献として，1 つ目にVR 環境でのAI アバタとの自由対話による\n英会話学習の検証が挙げられます．従来のVR を用いた英語",
            "R 環境でのAI アバタとの自由対話による\n英会話学習の検証が挙げられます．従来のVR を用いた英語学習の多くは，台本に\n沿った会話や事前に決められたシナリオに基づいたものが主流であり，学習者が自\n由に発話し，それに応じた自然な応答が得られるシステムの研究は少ないです．本\n研究では，AI アバタと自由に対話できる環境を構築し，その効果を実験的に検証し\nました．2 つ目に英会話学習における心理的ハードルの軽減効果の分析が挙げられ\nます．日本人が英語を話す際に感じる不安（発音や流暢さへの自信のなさ）が，VR\nを活用することで軽減されるかを，アンケート結果をもとに分析しました．その結\n果，「英語を話すことに対する前向きな気持ちが強まった」という項目で高評価を得\nるなど，VR の活用が心理的な障壁を下げる可能性が示唆されました．\n38\n戸辺　義人　情報テクノロジー学科　教授\nQ\nVR は仮想現実ではなく、仮想空間をいいます．\nA\n近年，「仮想」という言葉の意味が曖昧になりつつあり，特に技術分野では「バーチャ\nル」という表現が用いられることが増えています．例えば，メタバース関連の議論\nでは「仮想",
            "は「バーチャ\nル」という表現が用いられることが増えています．例えば，メタバース関連の議論\nでは「仮想空間」ではなく「バーチャル空間」と表現されることが多く，VR に関連\nする技術やサービスでも「バーチャル」という表現が一般的になっています．\n本研究では，VR 技術を活用して「実際の空間を模倣する」のではなく，「ユーザー\nが没入して対話できる環境を提供する」ことを目的としているため，「仮想現実」よ\nりも「バーチャル空間」という表現が適切であると考えられます．\n39\n"
        ]
    },
    {
        "id": "paper_4",
        "filename": "B2024_KoukiMatsuda_卒論.pdf",
        "title": "B2024_KoukiMatsuda_卒論",
        "fulltext": "青山学院大学理工学部\n情報テクノロジー学科\n２０２４年度卒業研究論文\n仮想現実での視線情報を用いた\n商品作動ギミックによる\n関心の変化\n２０２５年１月23 日提出\n指導教員ロペズ・ギヨーム教授\n提出者学　氏名\n１５８２１０８３松田　滉生\n青山学院大学 理工学部 情報テクノロジー学科 \n2024（令和6 年）年度卒業論文要旨 \n1 \n仮想現実での視線情報を用いた商品作動ギミックによる関心の変化 \n松田 滉生（15821083） \nロ ペ ズ 研 究 室 \n \n１．はじめに \nインターネットを利用した商品の購入が急激に増加し\nており，今や多くの消費者が日常生活の一部として受\nけ入れている．店舗で実物を確認せずにインターネッ\nトだけで商品を購入することに抵抗がない消費者も増\n加している[1]．一方，特に高額商品や大きさが重要\nな商品（家具，衣類，電化製品）においては，実物を\n見てから購入したいためネットショッピングを利用し\nない消費者もまだ多い[2]． \nそこで本研究は，仮想現実（VR）空間上で商品を\n3 次元で再現するとともに，可動なパーツに動的な動\nきをさせることで，商品への興味関心が向上するかを\n検証することを目的とする． \n２．関連研究 \n落合は視線情報に基づいた嗜好分析から商品を推薦\nする VR システムを提案している[3]．コンビニエン\nスストアを想定したワールドを作成し，カップ麺を\n33 種類用意しユーザーの興味や嗜好分析を視線情報\nとアンケート評価で行った結果，注視時間からユーザ\nーの興味や嗜好を判断することが可能だと考えられた． \n張はネットショップにおける暗示的動きを表す静止\n画が消費者行動に与える影響を研究した[4]．暗示的\n動きとは，静止画でありながら動きが感じられる視覚\n的特性を指す．暗示的動きを表す静止画は、消費者に\n購買意欲を向上させる効果を持つと示された． \n３．視線情報を用いた商品作動ギミック \n 本研究では動的な動きが分かりやすいように家電\n製品を3D モデルとして使用する．ヘッドマウントデ\nィスプレイ（HMD）を用いたVR 空間上に家電量販\n店をイメージしたワールドを作成した（図１を参照）．\nまた，Pupil Neon [5] を Meta Quest3 [6] に取り付け\n視線情報を読み取り，注目が集まっている商品のみを\nアニメーションで動くようにシステムを構築した． \n視線情報によってポインターが移動し，図２のよう\nに視覚的にどこに注目しているのかわかりやすくする\nために，ポインターから赤色でray を表示させた．ア\nニメーションの設定として，図３のように炊飯器の開\n閉動作，扇風機の首振り動作，電子レンジの扉開閉動\n作が行えるように，各3D モデルを複数要素に分けた\nうえで，動作軸を定義するなどの工夫により，動的な\n動きを直感的に理解できるようにした．\n \n図１. 家電量販店をイメージしたワールドの様子 \n \n図２. ray が飛んでいる様子 \n \n図4.それぞれのアニメーションの様子 \n青山学院大学 理工学部 情報テクノロジー学科 \n2024（令和6）年度卒業論文要旨 \n \n４．評価方法 \n3 つの異なるVR 環境を用意し，被験者10 人に電化\n製品を観察・比較してもらい，それぞれのパターンが\n興味関心に与える影響を評価した．用意した VR 環境\nは以下の 3 つのパターンになる． \n• \n静止: 3D モデルが動かない静止状態． \n• \n常時動作 3D モデルが常に動き続ける状態． \n• \n注視動作: 被験者の視線情報に基づき，注目して\nいる 3D モデルのみが動く状態． \n順序効果を排除するため，各実験参加者は 3 つのパ\nターンのVR 環境をランダムな順序で体験してもらっ\nた．被験者には事前に，3 パターンのVR 環境で電化\n製品の観察・比較を行った後にアンケートに回答して\nもらうことを伝えた．また，それぞれのパターンの具\n体的な違いには明示せず，観察を自然に行ってもらう\nように促した． \n５．評価結果 \n関連研究を参考に，各 VR 環境でのユーザーの利用\n時間をエンゲージメントの定量的な指標として定義し\nた．具体的には，各環境の体験開始から終了までの時\n間（秒）を計測し，その値を比較することでエンゲー\nジメントの違いを評価した．またアンケート評価で興\n味と使用イメージについての主観評価も行った． \n視線情報に基づき動作する「注視動作」環境が最も\n長い平均利用時間（45 秒）を示し，エンゲージメン\nトが他の 2 つの環境と比較して有意に高いことが分か\nりました（表１）．また，表２に示す興味関心に関す\nるアンケートの結果から，「注視動作」環境は「静止\n環境」と比較して非常に高い有意な差を示した（p＜\n0.01）．さらに，「常時動作」環境と比較したときも\n（p＜0.05）有意な差があることが明らかとなった． \n   表1.各パターンの平均利用時間と標準偏差 \n    \n \n \n \n表2.アンケート評価におけるスコア比較 \n \n６．まとめ \n本システムの使用により，現実世界で家電量販店に\n行く前に仮想現実上で動きのある 3D モデルを先に見\nることで興味を掻き立てて，使用するのイメージを想\n像させることができ，興味を持たせることができると\n明らかになった． \nシステムの改善点として，商品が一方向しか見れず \n360 度見ることができないこと，商品との距離があり\n近くに寄せられなかったことが挙げられる．また，扇\n風機の音や電子レンジの音などの聴覚的フィードバッ\nクも実装することで，より没入感を与えて興味をより\n掻き立てることができたのではと考えられる．以上に\nあげられる課題を解決し実装することで，本システム\nをより没入感があり興味関心に影響を与えられるシス\nテムに発展させていく． \n参考文献 \n[1] \nNRI メディアフォーラム:生活者1 万人アンケー\nト（９回目）にみる日本人の価値観・消費行動\nの\n変\n化 \nhttps://www.nri.com/content/900032338.pdf \n[2] \n総務省: インターネットの使用状況 \nhttps://www.soumu.go.jp/johotsusintokei/whit\nepaper/ja/h27/html/nc122400.html \n[3] \n落合拓朗 藤田智 益子宗星野准一： 視線情報に\n基づいた嗜好分析から商品推薦を行う VR ショ\nッピングシステム，IPSJ SIG Technical \nReport, Vol. 2019-HCI-184, No. 3 (2019) \n[4] \n張 テイテイ： ネットショップにおける暗示的動\nきを表す静止画が消費者行動に与える影響，経\n営論集 (2023). \n[5] \nPupil \nNeon\n．\nPupilLabs \n社\n \n， \nhttps://pupil-labs.com/.（2025/1/24 参照） \n[6] \nMeta \nQuest3\n．\nMeta \n社\n \n， \nhttps://www.meta.com/jp/quest/quest-3/\n（2025/1/24 参照） \n目次\n第1 章\n序章\n1\n1.1\n研究背景. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n1\n1.1.1\nオンラインショッピングの増加. . . . . . . . . . . . . . . . . . . .\n1\n1.1.2\n消費行動と視線情報の関係\n. . . . . . . . . . . . . . . . . . . . . .\n5\n1.2\n研究目的. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n5\n1.3\n本論文の構成. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n5\n第2 章\nVR と消費行動の変化に関する研究\n6\n2.1\nネットショップにおける暗示的動きを表す静止画が消費者行動に与える影\n響に関する研究. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n6\n2.2\nVR と視線情報\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n7\n2.2.1\n視線情報から商品推薦を行うVR システム. . . . . . . . . . . . . .\n7\n2.2.2\nVR 空間における視線とコミュニケーション. . . . . . . . . . . . .\n8\n2.2.3\nVR 環境における視線追跡と運転. . . . . . . . . . . . . . . . . . .\n9\n2.2.4\nアイトラッキングによる購買行動分析に関する研究. . . . . . . . .\n10\n2.3\nVR と興味関心\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n12\n2.4\n先行研究のまとめ. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n14\n第3 章\n仮想現実において，視線情報を用いた商品作動ギミック\n15\n3.1\nシステム概要. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n15\n3.2\n使用デバイス. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n16\n3.2.1\nシステムに利用したHMD . . . . . . . . . . . . . . . . . . . . . . .\n16\n3.2.2\n視線情報を計測するデバイス\n. . . . . . . . . . . . . . . . . . . . .\n17\n3.3\n動的な3D モデルの作成方法. . . . . . . . . . . . . . . . . . . . . . . . . .\n18\n3.3.1\n3D モデルの読み取り方\n. . . . . . . . . . . . . . . . . . . . . . . .\n18\n3.3.2\nアニメーションの作成方法\n. . . . . . . . . . . . . . . . . . . . . .\n19\n3.4\n通信手法及び仮想空間内における表現手法. . . . . . . . . . . . . . . . . .\n19\n3.4.1\nシステム開発に利用した開発プラットフォーム\n. . . . . . . . . . .\n20\n3.4.2\n視線情報計測. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n20\ni\n3.5\nまとめ. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n21\n第4 章\nモデルの動的な動きの有無による興味関心の評価実験\n22\n4.1\n実験目的. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n22\n4.2\n実験環境. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n22\n4.3\n実験方法. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n23\n4.4\n評価方法. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n24\n4.4.1\nエンゲージメント評価. . . . . . . . . . . . . . . . . . . . . . . . .\n24\n4.4.2\nアンケート評価. . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n24\n4.4.3\nシステムの使いやすさの評価指標. . . . . . . . . . . . . . . . . . .\n25\n第5 章\n実験結果と考察\n26\n5.1\nエンゲージメント評価考察. . . . . . . . . . . . . . . . . . . . . . . . . . .\n26\n5.2\nアンケート評価および考察. . . . . . . . . . . . . . . . . . . . . . . . . . .\n27\n5.3\nシステムの使いやすさの評価結果および考察. . . . . . . . . . . . . . . . .\n31\n5.4\nまとめ. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n31\n第6 章\n結論と今後の展望\n32\n6.1\n結論. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n32\n6.2\n今後の展望\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n32\nacknowledgments\n33\n参考文献\n34\nii\n第1章\n序章\n本章では，社会的な背景をもとに研究の位置付けを明確にする．1.1 節では，研究背景\nとしてオンラインショッピングでの購入における現状と課題について述べる．1.2 節では，\n背景に挙げた課題を踏まえた本研究の目的を定義する．1.3 節では，本論文の構成につい\nて述べる．\n1.1\n研究背景\n1.1.1\nオンラインショッピングの増加\n近年，日本ではEC サイトを利用した商品の購入が急激に増加しており，今や多くの消\n費者がインターネットを活用した買い物を日常生活の一部として受け入れている．図1-1\n統計局が実施した調査によると，ネットショッピングの利用率や支出額は年々増加傾向に\nあり，その成長は新型コロナウイルス感染症の拡大による生活様式の変化とも相まって一\n層加速している[1]．\n図1-1: ネットショッピング利用世帯の割合の推移（[1] より）\n1\n図1-2 のように，特に外出を控える生活が推奨された2020 年以降，食品や生活必需品\nの購入においてもネットショッピングを利用する人々が急増し，EC 市場の拡大に拍車を\nかけたとされている．\n図1-2: オンライン消費の増加( [2] より)\n飲食業界においては，インターネットで注文し，飲食店から食事を配達してくれる宅\n配サービスが，大都市を中心に利用が増えている．また，e コマースにおいても，プラッ\nトフォームサービス等を利用せ，自ら開設したウェブサイトを通じた販売が増加してい\nる．このように，自らが企画・生産した商品を消費者に対して直接販売するD2C（Direct\nto Consumer）の動きが加速している[2]（図1-3）．これにより，大都市の消費者が地方の\n個人や小規模店舗から商品を購入することが可能となるなど新たなつながりも生まれる．\nこのような消費行動の変化は，単なる一過性のものではなく，今後の産業構造が大きく変\n化することにつながる可能性がある．\n図1-3: D2C の概念図( [2] より)\n2023 年の統計によれば，2 人以上の世帯におけるネットショッピングの支出金額は1 か\n月平均23，021 円に達し，利用世帯当たりの支出金額は42,937 円と，統計が開始された\n2002 年以来過去最多を記録しました．この数字は，ネットショッピングが単なる補助的\n2\nな購買手段に留まらず，多くの人々の主たる購買方法として定着しつつあることを示して\nいる．また，野村総合研究所の調査には世代間の差異も見られるが，特に若年層や働き盛\nりの世代である20 代から40 代の間では，インターネットショッピングを年1 回以上利用\nする人の割合が80 ％を超えており，これらの層がEC 市場の拡大を牽引していることが\n明らかになっている．図1-4 に調査結果を示す．\n図1-4: インターネットショッピングを年1 回以上利用する人の割合の推移( [3] より)\nさらに，店舗で実物を確認せずにインターネットだけで商品を購入することに抵抗がな\nい消費者も増加している．2021 年の調査では，その割合が約50 ％に達し，従来の「商品\nを直接手に取って確認したい」という購買行動の変化を示している[3](図1-5)．\n3\n図1-5: 店舗で実物を確認せずにインターネットだけで商品を買うか( [3] より)\nこの背景には，商品の写真や動画，レビューなどのデジタルコンテンツの進化が挙げら\nれる．これにより，消費者は実物を確認しなくても商品の品質や性能をある程度把握でき\nるようになり，購買の意思決定がオンラインで完結するケースが増えている．\n一方で，ネットショッピングにはまだ課題も残されている．総務省が実施した調査によ\nると，ネットショッピングを利用しない理由として「実物を見てから購入したい」という\n回答が多く挙げられており，これがEC 市場のさらなる成長を妨げる一因となっている．\n特に高額商品やサイズが重要な商品（家具，衣類，電化製品）においては，購入前に実物\nを確認したいというニーズが根強く存在している．また，商品の写真や説明が実物と異な\nる場合，消費者の期待を裏切る結果となり，返品や交換の増加につながる可能性も指摘さ\nれている．\n以上のように，ネットショッピングの利用率や支出額は確実に増加しているが，同時に\nその利便性と実物確認の重要性という相反する要素が存在していることが分かる．これら\nの課題を解決するためには，消費者が安心して購入できる環境を整備することが必要だ．\n例えば，商品の詳細を分かりやすく伝えるための高品質な写真や動画，拡張現実（AR）や\n仮想現実（VR）を活用した視覚的な確認手段の導入が期待されている．\n以上より，ネットショッピングは利便性の向上により多くの支持を得ている一方で，実\n物を確認できないことによる購買意欲の低下という課題を抱えている．この問題を克服す\nることで，さらに多くの消費者がネットショッピングを活用し，EC 市場の発展が進むと\n考えられる．\n4\n1.1.2\n消費行動と視線情報の関係\n消費行動と視線情報の関連を分析した調査では，視線計測技術を用いた, 商業施設にお\nいて消費者の視線情報から消費者の興味を分析する研究が行われていた．近年だとメタ\nバースやXR といった分野を実験環境として利用することが多く研究されている．既存の\n研究では実験環境にPC のモニターやスクリーンが利用されており，メタバース空間を実\n験環境として選んだ場合においても同様な結果が得られることが明らかになっている[4]．\nマーケティングや消費者行動研究において重要なテーマとなっている．視線計測技術（ア\nイトラッキング）を活用することで，消費者がどのような情報に注目し，どのような意思\n決定プロセスを経て購買に至るのかを詳細に分析することが可能だ．例えば商品配置やデ\nザイン，色彩などが消費者の視線を引き付け，購買意思決定に影響を与えることが示され\nている[5]．しかし，VR 空間に3D モデルを表示しそのモデルを見ての消費行動，興味の\n変化についての研究はまだ行われていない．\n1.2\n研究目的\n1.1 節で述べたように，ネットショッピングで買う前に実物を見る必要があると考える．\nそのため，本研究では，VR 空間上で，使用イメージが分かることで興味が変化するのか\nを研究目的とする．具体的には，視線情報を元にユーザーの興味を判定し，注目した物の\n3D モデルを動かす．そこで本研究では，仮説を実証するために以下の2 つの点について\n取り組んだ．\n1. 実物のような3D モデルとアニメーションの作成．\n2. 視線情報によって3D モデルの動きを制御．\n1.3\n本論文の構成\n第1 章では，本論文の研究背景，研究目的，及び本論文の構成について述べた．第2 章\nでは，VR を融合した消費行動の変化に関する先行研究を3 つ述べた．第3 章では，シス\nテムの概要，使用デバイス，3D モデルの作成方法，通信手法について述べた．第4 章では\n本研究の実験目的，実験環境，実験方法，評価方法について述べた．第5 章ではエンゲー\nジメント評価考察，アンケート評価および考察，システムの使いやすさの評価結果および\n考察を述べた．第6 章では結論と今後の展望を述べている．\n5\n第2章\nVRと消費行動の変化に関する研究\n本章では，VR を融合した消費行動の変化に関する研究について述べる．2.2.1 節では視\n線情報に基づいた嗜好分析から商品推薦を行うVR ショッピングシステムの研究，2.2.4\n節ではアイトラッキングによる買い物客の購買行動分析の研究について述べる．2.1 では\nネットショップにおける暗示的動きを表す静止画が消費者行動に与える影響について述\nべる．\n2.1\nネットショップにおける暗示的動きを表す静止画が消費者行動に与え\nる影響に関する研究\nこの論文では，ネットショップにおける商品の提示形式が消費者の商品選択や購買意欲に\nどのような影響を与えるかを検討した[6]．その中でも特に「暗示的動き(Implied Motion)」\nを表す静止画に注目し，その効果とメカニズムを議論している．視覚刺激が消費者の注意\nや判断に及ぼす影響は広く研究されてきたが，これまでは静的な商品画像やビデオなどの\n動的提示に焦点が当てられることが多かった．本研究では，静止画が持つ暗示的な動きが\n消費者行動に与える影響を実証的に検証した点で新規性がある．「暗示的動き」とは，静\n止画でありながら動きが感じられる視覚的特性を指す．この現象は視覚システムによる\n運動の想像と再現によって生じるとされ，実際の運動と同様に脳の特定の領域を活性化さ\nせることが知られている．消費者は，運動を暗示する静止画を見ることで，商品に対する\n心的イメージ（mental imagery）を形成しやすくなる．この心的イメージは，消費者が商\n品を使用する場面や効果を鮮明に想像することを可能にし，購買意欲や商品態度に影響を\n与える．仮説を検証するためにYahoo!クラウドソーシングにて実験を行った．実験は商\n品画像の提示形式を動的なもの（図2-1）と静的なもの（図2-2）に分け200 名の20 代～\n60 代の一般消費者を対象として行った．質問として「これからネット店舗尾で使われる\n画像を見せる．画像をよく見て質問に回答してください．」として解答してもらった．\n結果として，視覚刺激の形式が消費者行動に与える影響を示す重要な知見を提供してい\nる．特に，暗示的動きを表す静止画は，消費者に運動を知覚させ，心的イメージの鮮明さ\nを高めることで，購買意欲や商品態度を向上させる効果を持つ．また，静止画はビデオや\nVR に比べて制作コストが低く，ネットショップにおける実用性が高いと考えられる．\n6\n図2-1: 暗示的動きのある商品写真( [6]\nより)\n図2-2: 静的な商品写真( [6] より)\n2.2\nVR と視線情報\n2.2.1\n視線情報から商品推薦を行うVR システム\nこの論文では，視線情報に基づいた嗜好分析から商品を推薦するVR システムを提案し\nている[7]．限定的問題解決プロセスを導入している．限定的問題解決プロセスとは，あ\nる商品群から商品を選択する場合においてユーザーが商品についてある程度の知識があ\nり，複数の選択肢から比較検討を行うことであり，限定的加算型（限定された選択肢か\nら，全体的に評価を行い選択する）という評価方法を利用している．予備調査として即\n席麺の購入においての購買意思決定について20 代の男女30 名を対象にアンケート形式\nで調査を行った結果，20 代の消費者が商品購入を決定する要素で最も重要視するものは\n“価格”と“味”を重視するということが予備調査で判明した．この予備調査をもとに味\nの特徴，価格帯，麺の種類など合計33 の商品要素を利用してユーザーの興味や嗜好分析\nを行うことにした．被験者はコントローラを利用して商品を選択すること，商品の詳細\n情報として拡大された商品パッケージと商品説明を見ることができる(図2-3)．被験者は\nその商品が気に入れば購入を決定する．購入決定後に，図2-3 のように被験者に対して\n商品推薦を行った．VR ショッピングシステム体験後に商品購入の理由や推薦商品に対す\nる満足度，実際の店舗との購買体験の差異についてアンケートで調査した．\n7\n図2-3: 被験者が商品を選択したときに見る画面と被験者に商品を推薦したときに見せる画面\n( [7] より)\n20 代前半の男性12 名を被験者として実験を行った．被験者が商品を注視した時間が\n中央値より短い群（A 群）と長い群（B 群）と二つに分けた．A 群は商品をVR 店舗内の\n商品をすべて見てから商品を買うという探索的な姿勢が見られない群と推測され，B 群は\n最初に全ての商品選択肢を把握してから自分の好みでフィルタリングを行う群だと推測\nできる．そのため，注視時間からユーザーの興味や嗜好を判断することが可能だと考えら\nれた．被験者のアンケートからわかったこととして，このシステムでは注視時間を基に\n制作しているため，商品の購入を決定する時間が短いユーザーに対しては興味や嗜好に\n合った商品を推薦することは難しいと考えられる．しかし，そのようなユーザーに対して\nも興味や嗜好に合わないまでも，見新しい商品を推薦機能としては十分に利用できるこ\nとがわかった．一方で，商品の購入までに一定の時間をかけて選ぶユーザーに対しては\nユーザーの興味や嗜好に合った商品を推薦できると考えられる．しかし，このようなユー\nザーに対しては新しい商品を推薦できないということがわかった．また，VR 店舗におい\nても，実際の店舗と同様に目に付きやすく，手の届きやすい位置にある商品に対して注視\nが集まることが分かった．このことから注視時間からユーザーの興味を推定するという仮\n定を立てる際に商品の位置を考慮する必要があるとわかった．\n2.2.2\nVR 空間における視線とコミュニケーション\nこの論文ではVR 空間においてアバターとの視線コミュニケーションが対話に与える影\n響を明らかにすることを目的とした[8]．視線は対面コミュニケーションにおいて重要な\n非言語情報であり，VR 空間でもアバターとの自然な対話を実現するためには視線の役割\nが鍵となる．小宮山らは，VR 空間内でHMD 装着者がアバターと対話する環境を構築し，\n視線を用いた場合と首の向きを視線として代用した場合で比較実験を行った．アイトラッ\nキング機能付きHMD を使用し，アバターの視線や動作を調整した対話システムを設計し\nた．実験の結果，視線追跡を用いた場合，アバターとの空間共有感やアイコンタクトの評\n価が有意に向上した．また，アバターとの対話時に視線が自然に合うことで，対話のス\n8\nムーズさや親しみやすさも高まることが示唆された．一方で，首の向きを視線として代\n用する場合は，視線の動きが制限され，対話における違和感が生じることが確認された．\nVR 空間でアバターを用いた対話をより自然にするためには，視線検出技術の導入が重要\nであると結論付けられた．\n坂本らはVR 空間におけるマンガ教材読書時の学習支援を目的とし，視線情報を用いた\n主観的難易度推定手法を提案した[9]．マンガ教材は，文字と絵が組み合わさった複雑な\nレイアウトを持つため，ページ滞在時間などのログデータだけでは学習者の理解度や難易\n度の推定が難しい．そこで本研究では，視線データを活用し，学習者の主観的な難易度を\nコマ単位で推定する手法を開発した．提案手法では，従来の視線特徴量に加えて，「視線\nヒートマップ情報」および「注視点と視線の交点の距離」というVR 空間特有の特徴量を\n抽出し，機械学習を用いて難易度を推定した．評価実験の結果，ユーザ依存モデルではラ\nンダムフォレスト（RF）を用いた推定でF 値0.705，ユーザ非依存モデルではSVM によ\nる推定でF 値0.711 を達成し，従来手法より高精度な難易度推定が可能であることを示し\nた．今後の課題として，データ収集の拡充，リアルタイム推定の精度向上，学習支援シス\nテムへの応用が挙げられた．この研究よりマンガ教材を活用したVR 学習環境の個別最適\n化への貢献が期待される．\n石川らはVR 空間内における視線の一致と表情変化がコミュニケーションの円滑さに及\nぼす影響を研究した[10]．現在のVR コミュニケーションでは，ユーザの表情をHMD 内\n蔵カメラで反映させるフェイストラッキング技術が用いられているが，表情の変化が限定\n的であり，感情表現が不自然になるという課題がある．そこで本研究では，アバター同士\nの視線が一致した際に表情変化を強調することで，ユーザの気づきを促し，親密度を向上\nさせる手法を提案した．実験では，HTCVIVE とUnity を使用し，VR 空間内に3DCG キャ\nラクターを配置した．HMD 装着者とキャラクターの視線が一致すると，キャラクターの\n表情が無表情→笑顔→より強い笑顔の3 段階で変化するように設定し，その影響を評\n価した．結果として，視線が一致すると表情の変化に対する気づきが促進され，笑顔への\n変化が快適なコミュニケーションにつながる可能性が示唆された．しかし，笑顔の強度が\n増すにつれて気づきにくくなる傾向も見られた．\n2.2.3\nVR 環境における視線追跡と運転\n侯らはVR 環境を活用し，視線追跡技術を用いた運転視線評価システムを設計し，初心\n者ドライバーの視線特性を分析し研究した[11]．運転中の視線の動きは交通安全に大き\nく影響を与える要素であり，適切な視線配分を学習することで運転技術の向上が期待され\nる．このシステムでは，HTC Vive Pro Eye を用いて運転者の視線データを収集し，360 度\n映像をVR 空間内で再生することで，実際の運転体験を再現する．被験者はVR 環境内で\n9\n運転し，その際の視線データを熟練者の視線データと比較することで，視線配分の適切さ\nを評価する．また，視線の動きの違いをスコア化し，学習の進捗を可視化する機能も搭載\nしている．実験では，運転経験の異なる3 名の被験者を対象に視線の角度差とスコアを分\n析した．その結果，運転経験がない被験者ほど熟練者との視線の差異が大きく，スコアが\n低いことが確認された．一方で，運転免許を所持する被験者は，熟練者に近い視線配分を\n示し，高いスコアを達成した．これらの結果から，VR を用いた視線訓練が初心者ドライ\nバーの視線改善に有効である可能性が示唆された．\n2.2.4\nアイトラッキングによる購買行動分析に関する研究\n現地と現地を再現したVR の売り場において，非計画購買が発生する歩行時の視聴時間\nと，影響を与えているパッケージデザイン要素の関係性を解釈することを目的とした研究\nがある．非計画購買を分析するために，視認に関連した各種の内容や時間を定義し，手法\nとしてまとめた．場面の分類として，売り場では選択→進行→比較→購買の4 段階の場面\nの分類として用いた．（図2-4）売り場を歩行し，非計画購買として商品を見つけて比較\nし，購買に至るメンタルモデルの変化を捉えられる．\n図2-4: 場面の分類( [12] より)\n次に視認時間を定義した（図2-5．視認時間の傾向から，売り場の商品の形態を存在把\n握して選択→比較する傾向の時間として，0．2 秒未満を見まわし，0．2 秒以上1 秒未満\nを確認，1 秒以上5 秒未満を中止しており内容も覚えている，5 秒以上見た場合詳細も把\n握できる状態とした．\n10\n図2-5: 視認時間の傾向( [12] より)\nパッケージの要素についても分類し，文字量特徴量と背景特徴量として抽出・数値化し，\n視認時間との相関を分析し，パッケージデザインに実験データを紐づけて活用できるよう\nにした．結果と考察について進行場面と比較場面が分類された．進行場面: 購買行動が進\n行中で，VR 環境では商品の背景特徴量に関連があり，見ているかどうかの時間（視認時\n間）が有意な関連があることが示された．比較場面: 異なる選択肢を比較する場面で，現\n地とVR の両方で文字や背景特徴量と購買行動の関連が確認され，特に背景特徴量につい\nては強い相関が見られた．結果として，見た商品は，背景特徴量が少なく，文字特徴量が\n多かった傾向があり，購買行動は進行場面から比較場面への移行を示唆し，文字特徴量が\n多い商品が多い商品が特に重視されることが示され，現地とVR の両方で，購買行動に影\n響を与える特徴量の傾向が類似していることが確認された[12]．\n中島らは百貨店におけるアイトラッキングデバイスを用いた購買行動の評価を行った\n[13]．消費者の購買行動における非計画購買（来店前に計画されていない購買）は，店舗\n滞在時間や顧客特性に大きく影響されることが既存研究で示唆されている．この論文で\nは，多層階の百貨店を対象に，アイトラッキングデバイスを用いて消費者の動線や購買行\n動を観察し，非計画購買に影響を与える要因を評価することを目的とした．実験場所とし\nて，都心に所在する大型百貨店で実験を行い，Tobii 社のアイトラッキングデバイス[14]\nを被験者に装着してもらい，自由に1 時間ショッピングを行ってもらった．参加者は自由\nにショッピングを行い，その際の視線データと店舗滞在時間が記録された．また，購買目\n的や好みの店舗，訪店歴などのアンケートデータも収集し，これらの情報をもとに非計\n画購買の発生要因を分析した．モデル評価にはLOOCV（Leave-One-Out Cross-Validation）\nを採用し[15]，データ分析には，ランダムフォレストを用いた予測モデルが採用され，非\n計画購買の発生を高い精度で予測することができた．特に，実店舗嗜好や店舗滞在時間が\n非計画購買に大きな影響を与える要因であることが明らかとなった．具体的には，図2-6\nのように店舗滞在時間が1500 秒を超えると非計画購買が増加する一方，2000 秒を超える\nと購買意欲が減少する傾向が確認された．\n11\n図2-6: 中島らの研究結果( [13] より)\n横軸：店舗滞在時間　縦軸：非計画購買への影響\nこの研究の結果から，実店舗への関心が高い消費者ほど非計画購買を行いやすいことが\n示唆される．また，アイトラッキングデバイスを活用した視線情報の収集が，購買行動の\n予測や分析において有効であることが実証された．\n2.3\nVR と興味関心\n林らはVR を活用して若者のイベント参加を促す方法について研究した[16]．若者の地\n域活性化のためのイベントへの参加率の低さに着目し，VR を活用して潜在的な興味を引\nき出し，イベント参加を促す手法を提案している．まず若者がイベントに参加しない理由\nを分析し，参加することで得られる便益を考察した．単にイベントをVR で紹介するので\nはなく，体験させることで興味を引き出せるのではと考えた．現実のイベントに参加しな\nい理由として，時間やお金，労力などのコストがかかってしまう．そこでVR を活用しど\nんなイベントなのかを体験させることで，心理的なハードルを下げることを目標とした．\nVR 空間でイベントの準備や広報を仮想的に体験してもらう．例えば，地域の祭りの準備\nをVR で手伝ったり，模擬店の運営をVR で試した．アフォーダンス理論を応用しVR 内\nでの若者行動を分析した．アフォーダンス理論とは人は環境の中にあるものによって自然\nに行動が誘発されるという考えで、椅子があれば座りたくなったり，ドアノブがあれば回\nしたくなるといったものだ．この考えを応用し，VR 空間内での若者の行動を観察するこ\nとで，何に興味があるかを分析した．VR 内で神輿を担ぐアクションを良くする場合，祭\nりの伝統文化に興味がある．模擬店の売り上げ管理に集中する場合，経営や販売に興味が\nあるのではと仮説を立てた．VR 空間での行動データをNMF 解析で数値化し，どのアク\nティブにどれくらい時間を使ったか，どれだけ集中していたかを記録し，このデータを基\n12\nにこの人はこのタイプのイベントに興味がありそうではと分析した．結果としてVR を活\n用することで若者にとって魅力的なイベントは何かを数値的観点から分析することが可\n能となり，若者の潜在的な興味を引き出し，参加を促すことが可能であることを示した．\n成田らは視線追跡型VRHMD を用いた工学実験の訓練システムを開発し，学習効果の\n向上を目指した[17]．従来の講義形式の授業では集中力を維持しにくいという課題があ\nり，VR 技術を活用することで，没入感の向上による学習効果の向上が期待される．特に，\n工学実験では安全性の確保や作業手順の正確な習得が重要であり，VR 技術との親和性が\n高い．本研究では，視線追跡型VRHMD「FOVE0」，VR 開発環境「Unity」，手の動きを\n認識する「Leap Motion」を組み合わせ，実験手順の習得を支援するシステムを構築した．\n視線情報を活用し，学習者が適切な箇所を注視しているかを判定し，必要に応じて視線誘\n導を行う．また，ゲーミフィケーションの要素を導入し，得点の可視化やフィードバッ\nクを行うことで学習意欲を高める仕組みを導入した．実験では，電動機の起動手順をVR\n環境で再現し，視線の記録と操作の正確性を評価した．その結果，学習者が特定のオブ\nジェクトを一定時間注視した際に得点が加算されるなど，視線追跡によるフィードバック\nが機能することが確認された．\n土居らはVR を活用した文化財鑑賞がどのように鑑賞者の興味関心に影響を与えるかを\n調査することを目的とした[18]．特にシネマチックVR（映画のような映像コンテンツを\nVR 空間内のシアターで鑑賞する方式）に着目し，VR 表現の違いが観賞者の注視点や興\n味に与える影響を分析した．文化財の観光資源化がすすめられているが, 伝統的な解説は\n難解で理解しづらいとされてきた．そこでデジタルアーカイブを活用することで，より\n分かりやすい鑑賞体験を提供できると考えた．実験方法として国宝「八橋蒔絵螺鈿硯箱」\n（やつはしまきえらでんすずりばこ）を題材にした3 種類のVR コンテンツを制作し，VR\n空間内のシアターで鑑賞させる．参加者にVR 映像の前後で静止画を観察させ，視線計測\nや興味度の変化を分析．アイトラッキング機能付きHMD を使用して眼球運動を計測し，\nVR 映像鑑賞中の視線運動と瞬目発生頻度，視線停留時間の変化を計測した．瞬きの発生\n頻度の変化で興味度を測り，興味度が高いとまばたきの回数が減るという理学的知見に基\nづき，VR 映像の前後での瞬目発生頻度で興味の変化を評価した．結果として，VR 映像\nを見た後，まばたきの回数が減り，視線が特定の部分に衆目する傾向が確認された．VR\n表現（特に「透視」「歩行」などのインタラクティブな演出）が文化財への興味を引き出\nすのに有効であることが示唆された．\n武田らはVR 空間におけるアバターが購買意欲に与える影響について研究した[19]．\nバーチャルショッピングにおける購買意欲に与える影響を明らかにすることを目的とし\nた．バーチャルショッピングでは，商品の3D モデルを確認できる利点があるが，店員ア\nバターの影響については十分な研究がなされていない．HMD を装着した参加者に対し，\n13\n1. テキストと音声による商品説明（テキスト条件），2. 動画による商品説明（動画条件），\n3. アバターが身振り手振りを交えて説明する条件（アバター条件）の3 種類を設定し，購\n買意欲の変化を比較した．その結果，すべての条件で購買意欲の向上が確認されたが，特\nにアバター条件での上昇率が最も高かった．また，アバター条件では商品の理解度も高ま\nり，説明に対する親しみやすさや実在感が向上した．一方で，個人の興味関心や商品の種\n類による影響も大きく，購買意欲の変化には個人差があることが示唆された．\n2.4\n先行研究のまとめ\nこれまでの研究は視線情報による購買行動の変化や消費行動の分析，見え方による購\n買意欲の変化などを調べてきた．2.2.1 節では視線情報から商品を推薦することができる\nユーザも存在するが，商品の位置によっても変化がでるため，本研究ではすべてを平行に\n置き，見やすくした中での商品選択を行うものとし，注視時間の平均時間によって推薦を\n行っていたため，本研究ではシステムの利用時間によって興味関心を評価する．2.2.4 か\nら注視時間を1 秒以上見ている場合と定義しる．2-1 から暗示的な動きのある商品写真が\n心的イメージを高め，購買意欲や商品への興味を向上させていたことから，本研究では，\n視線情報からユーザーの気になっているものだけに動的なアニメーションが動くように\nし，他のものと差別化できるシステムを提案する．\n14\n第3章\n仮想現実において，視線情報を用いた商品\n作動ギミック\n3.1\nシステム概要\n本節では本研究で提案する仮想現実において，視線情報を用いた商品作動ギミックの概\n要について述べる．動的な動きが分かりやすいように本研究では家電製品を3D モデルと\nして使用する．ヘッドマウントディスプレイを用いた仮想現実上に家電量販店をイメー\nジしたワールドを作成し，Pupil Neon [20] をMeta Quest3 [21] に取り付け視線情報を読み\n取り，注目が集まっているオブジェクトのみをアニメーションで動くようにシステムを作\n成．家電量販店に直接行くのではなく仮想現実上で動的な動きを見ることによる興味の向\n上や変化を図ることを目的としたシステムである．\n図3-1 に提案システムの全体図を示す．被験者はヘッドマウントディスプレイを装着し，\nVR 空間上で家電製品を見ることができる．視線情報によってポインターが移動し，図3-2\nのように視覚的にどこに注目しているのかわかりやすくするために，ポインターから赤色\nでray を表示させた．\n図3-1: 家電量販店をイメージしたワールドの様子\n図3-2: ray\n15\nまたアニメーションの設定として，図3-3 のように炊飯器は開閉の動作，扇風機は首を\n振る動作，電子レンジは扉の開閉が行えるようにアニメーションを作成してあり，動的な\n動きを直感的に理解できるようにした．\n図3-3: 電化製品の動的な動き\n3.2\n使用デバイス\n本節では，このシステムを構成するデバイスの説明について述べる．\n3.2.1\nシステムに利用したHMD\n本研究ではヘッドマウントディスプレイとしてMeta 社が製造するバーチャルリアリティ\nヘッドセットのMeta Quest3 を使用する[21]．図3-4 にMeta Quest3 の外見を示す．Meta\nQuest3 は単体で動作するためその他の特別な機器が不要である．左右のコントローラー\nを使い仮想現実上で操作することができる．4K 解像度+ Inﬁnite Display 基本容量512GB\nで視野110°，メモリ8GB であり，バッテリー駆動時間は連続使用で2．2 時間のため，\n本研究におけるシステムを問題なく利用できる仕様となっている．\n16\n図3-4: Meta Quest3 の外見( [21] より)\n本研究では仮想現実内に家電量販店を模した店舗を作成し，3 つの家電製品を設置する．\nリアルな没入感を体験してもらい実際に店舗にいるように体験してもらうように，家電量\n販店のように白い壁や床を配置し，ガラスのテーブルの上に3D モデルを設置した．\n3.2.2\n視線情報を計測するデバイス\n本研究では，視線情報の取得のために図3-5Pupil Labs 社が出すPupil Neon を使用し\nた[20]．Pupil Neon を利用することでVR 空間に存在する3D オブジェクトに対してユー\nザーの視線情報が計測できる．ユーザーの左右の眼下にそれぞれ小型カメラを設置して，\nユーザーの眼球運動とVR 空間にある注視点をキャリブレーションすることで，VR 空間\nにおいてユーザーの視線情報を取得することができる．\n17\n図3-5: Pupil Neon の外見( [20] より)\nユーザーの視線方向にray を飛ばすことで，ray が電化製品に衝突した時に，商品を見\nたと判定することができる．この視線情報を利用して，ユーザーがどの商品を見たのか，，\n商品を何秒間見ていたのかなどのデータを取得することができる．2-5 より1 秒以上の視\n線の停止を注目としてＶＲ上でも判定できると分かっているため，これを使い電化製品に\n注目（１秒以上）が集めった時アニメーションが動きだすように設計した．Pupil Neon と\nスマートフォンを接続し，Pupil Labs 社のNeon Companion を使い，視線がどこを向いて\nいるのかの測定と接続を行い，python で動かした．\n3.3\n動的な3D モデルの作成方法\n本節では3D モデルの読み取り方法，アニメーションの作成方法について述べる．\n3.3.1\n3D モデルの読み取り方\n3D モデルには，Unity 上のAsset を使うのではなく，現実世界にある電化製品を使うこと\nでより現実世界をイメージできるようにした．現実世界の電化製品を3D モデルに変更す\nるためにToolbox AI社が出しているスマートフォン向けアプリケーションのScaniverse-3D\nScanner [22] を使用した．使用したスマートフォンはApple 社が出しているｉＰｈｏｎｅ\n14 を使用した[23]．図3-6 のように現実世界の家電を机の上などに置き，アプリケーショ\nンを起動して全方位を読み取ることで3D モデルを作成した．\n18\n図3-6: 3D モデルの読み取り方\n3.3.2\nアニメーションの作成方法\nアニメーションの作成に非営利団体であるBlender 財団が開発しているBlender を使用\nした[24]．Scaniverse で読み込んだ3D データーはobj ファイルを，一度blender に読み込\nませアニメーションを付けglb ファイルに変更し作成を行った．開閉や首振りを行うアニ\nメーションを作成するため，ボーンは作成せず単純な開閉動作のみを設定し動的な動きを\n付けた．\n図3-7: Blender での編集画面\n3.4\n通信手法及び仮想空間内における表現手法\n本節では仮想空間の表現方法とその使用に述べる．\n19\n3.4.1\nシステム開発に利用した開発プラットフォーム\n本開発にはUnity Technologies が提供するUnity [25] を用いた．Unity は無料で利用可能\nなゲームエンジンであり，作成したプロジェクトはAndroid やPC，HMD など様々な環境\nにビルド可能である．また，様々なユーザーが作成したアセットがアセットストアから利\n用可能となっており，短期間での開発が可能である．本システムはHMD 上で動作するた\nめ，HMD 上のあらゆるセンサ情報を扱えるようにする拡張パッケージ（OpenXR）を導\n入した．図3-8 にシステム開発の様子を示す．本システムは1 人でMeta Quest を装着し椅\n子または立った状態で仮想現実内の電化製品を見る．\n図3-8: システム開発の様子\n3.4.2\n視線情報計測\n視線情報の計測を実装するため，図3-9 のようにMeta Quest3 とPupil を接続し仮想空\n間上（Unity）で視線情報を読み取りPupil Neon に情報を送り，データ化された視線情報\nから注目時間によってアニメーションを再生した．コンソールからapi をPupil Neon に送\nり，視線情報をコンソールに返してMQTT ブローカーにパブリッシュし，VR に送る．\n20\n図3-9: 視線情報計測と共有の仕組みの概要図\n3.5\nまとめ\n本章ではシステム概要，仮想現実の表現方法，視線情報の取得方法について述べた．ユー\nザーがシステムを利用するには特別なコントローラー等は必要とせず，視線の入力のみで\n行うことが可能である．また，読み取ったデータをUnity 上で管理しアニメーションを制\n御しているため環境に依存せず簡単に利用可能である．\n21\n第4章\nモデルの動的な動きの有無による興味関心\nの評価実験\n4.1\n実験目的\n本研究の目的は．本システムを利用する際のシステムの有用性や．ユーザーがどのよう\nに感じるかを検証することである．具体的には．ユーザーの興味や嗜好．体験を通じた\n感じ方がどのように変化するかを分析し．それらの変化に基づいてシステムの有効性を評\n価する．また．以下の3 つのパターンに基づいて比較を行い．各パターンがユーザー体験\nに与える影響を検証する．静止，モデルが動かない場合常時動作，モデルが常に動いてい\nる場合注視動作，視線情報によってモデルが動く場合．これらの比較を通じて．視線情報\nを活用した動的なインタラクションがユーザーの興味喚起や体験の質に与える効果を明\nらかにし．システム設計における有用性の評価を行うことを目指す．\n4.2\n実験環境\n被験者10 人に図4-1 のMeta Quest3 にPupil Labs を取り付けたヘッドマウントディスプ\nレイを装着してもらう．\n図4-1: ヘッドマウントディスプレイ\n22\n4.3\n実験方法\n本研究では．3 つの異なるVR 環境を用いて．被験者に電化製品（炊飯器．電子レンジ．\n扇風機）を観察・比較してもらい．それぞれの場合でエンゲージメントに与える影響を評\n価した．以下に実験の手順を示す．各VR 環境は以下の3 つのパターンで構成される．\n• 静止: 3D モデルが動かない静止状態．\n• 常時動作: 3D モデルが常に動き続ける状態．\n• 注視動作: 被験者の視線情報に基づき．注目している3D モデルのみが動く状態．\nこの時各実験参加者には3 つのパターンのVR 環境を体験してもらうが．順序効果を排除\nするために．体験順序をランダムに設定した．被験者には事前に，3 パターンの環境で電\n化製品の観察・比較を行った後にアンケートに回答してもらうことを伝えた．また，それ\nぞれのパターンの具体的な違いには明示せず，観察を自然に行ってもらうように促した．\n各被験者には3 つのVR 環境を順番に体験してもらい．それぞれの環境で電化製品を観察\nした．観察時間は被験者に委ね．十分に観察したと感じた時点で次の環境に移行するよ\nうにした．\n23\n4.4\n評価方法\n4.4.1\nエンゲージメント評価\n本実験では，各VR 環境でのユーザーの利用時間をエンゲージメントの定量的な指標と\nして定義した．具体的には．各環境の体験開始から終了までの時間（秒）を計測し．その\n値を比較することでエンゲージメントの違いを評価した．被験者が各VR 環境で観察を開\n始した時点でタイマーを開始し．観察を終了した時点でタイマーを停止することで．利用\n時間を記録した．各環境での利用時間は被験者が自由に決定できるようにし．無理のな\nい形で自然な観察行動が得られるよう配慮した．記録した利用時間を環境ごとに集計し．\n平均利用時間や標準偏差を算出した．また．各パターンにおけるエンゲージメントの違\nいを統計的手法を用いて比較した．定量的な評価に加えて．被験者にはアンケートを通\nじて主観的な感想や各環境に対する満足度を回答してもらった．これにより．定量的評\n価と主観的な意見の相関を分析し．視線連動型インタラクション（注視動作）の有効性を\n検証した．\n4.4.2\nアンケート評価\n本研究では．3 つの異なるVR 環境に対する被験者の主観的な評価を収集するため．ア\nンケートを実施した．アンケート評価の目的は．VR 環境の違いが被験者の興味や使用イ\nメージ形成．さらには購買意欲に与える影響を明らかにすることである．特に視線情報\nによって動く環境（注視動作）が．他の環境（動かない場合．動き続ける場合）と比較し\nて．より高い興味や購買意欲を引き出すかどうかを検証した．アンケートは以下の設問\nで構成されており．それぞれの質問に対する回答を数値化し．定量的に分析した．\n• 設問1: 興味がわいたか．\n• 設問2: 扇風機が暑さを軽減してくれると感じたか．\n• 設問3: 炊飯器でご飯を炊くイメージができたか．\n• 設問4: 電子レンジでものを温めるイメージができたか\n設問1 は，各VR 環境がどの程度ユーザーの興味を引いたかを評価する設問．被験者に\nは．VR 環境の動きや視覚的な特徴が興味を引くかどうかを直感的に回答してもらった．\n設問2～4 では，モデルの視覚的な表現が．利用場面の具体性にどのように影響を与える\nかを検証した．評価方法として設問1～4 は各設問に対して．被験者には1～10 の範囲で\n数値評価を行ってもらった．1: 全くそう思わない10: 非常にそう思うこの評価方法によ\n24\nり．各設問に対する回答を数値化し．VR 環境ごとの違いを明確に把握することが可能と\nなった．\n4.4.3\nシステムの使いやすさの評価指標\nシステムの使いやすさの評価としてSystem Usability Scale（SUS）を用いた[26]．SUS\nは10 の質問に対し5 段階で評価を行う質問票であり，ユーザビリティと学習能力を測定\nし指標化する．すべての質問の5 段階評価の結果は0 から100 の範囲でスコアリングさ\nれる，SUS におけるスコアの基準を表4-1 に示す．平均点は68 点となっており，平均点\n以上が良いシステムと言われる．SUS のアンケート回答者は各項目を5 段階で評価する．\n集計方法は奇数の質問の回答スコアから1 を引き，偶数の質問スコアを5 から引く．その\n後，すべてのスコアを合算し2．5 倍したものがSUS スコアとなる．付録に実際に使用し\nたSUS に関するアンケートフォームを掲載した．\n表4-1: SUS におけるスコアと評価の対応\nSUS score\nGrade\nAdjective Rating\n>80.3\nA\nExcellent\n68 - 80.3\nB\nGood\n68\nC\nOkay\n51 - 68\nD\nPoor\n<51\nE\nAwful\n25\n第5章\n実験結果と考察\n5.1\nエンゲージメント評価考察\n本節ではエンゲージメントの評価結果および考察を述べる．表5-1 に3 パターンそれぞ\nれの平均利用時間と標準偏差を示す．\n表5-1: 各パターンの平均利用時間と標準偏差\nパターン\n平均利用時間(秒）\n標準偏差（秒）有意差\n静止:3D モデルが動かない状態\n20.684\n9.213\nあり\n常時動作:3D モデルが常に動き続ける状態\n32.518\n15.684\nあり\n注視動作: 視線情報に基づき動作する状態\n45.018\n12.872\n—\n図5-1: 平均利用時間の有意差\n*:p<0.05，**:p<0.01\n他の項目については有意差なし\n図5-2 から，視線情報に基づき動作する注視動作が最も長い平均利用時間（45．018 秒）\nを示し，エンゲージメントが他の2 つのパターンと比較して有意に高いことが分かった．\n静止状態と注視動作がもっとも有意な差を示し，注視動作の有意性を示しました．さら\n26\nに，標準偏差の値から，各パターンにおける観察時間のばらつきを評価しました．静止お\nよび注視動作は，比較的安定したばらつきを示した一方で，常時動作は標準偏差が最も大\nきく（15．684 秒），被験者による観察時間の個人差が大きいことが示唆されました．\nこれらの結果は，視線情報を活用する動的なインタラクションがユーザの興味を持続さ\nせ，観察行動を促進する効果があることを示しています．視線情報によって動作する注視\n動作では，被験者が長時間観察を続ける傾向が見られ，インタラクションのパーソナライ\nズ効果が興味を向上させる可能性が示唆されます．\n一方，常に動き続ける常時動作では観察時間が静止より長いものの，標準偏差が大きく，\n被験者間での評価が分かれる結果となりました．これは，動き続ける状態が一部の被験者\nにとって過剰な刺激や情報過多として認識された可能性を示しています．\n常に止まっている静止状態は，他のパターンに比べてエンゲージメントが低く，ユーザ\nが積極的に関与する機会が限られていると考えられます．このことは，動的インタラク\nションがユーザの興味喚起に与える重要な役割を強調しています．\n5.2\nアンケート評価および考察\n本節ではアンケート評価の結果とその考察を述べる．本研究では，3 つの異なるVR 環\n境（「静止」，「常時動作」，「注視動作」）における被験者の主観的評価をアンケートを通じ\nて収集し，興味関心，使用イメージ形成について定量的に分析した．アンケート結果の数\n値化に基づく分析の結果，注視動作が他の2 つの環境と比較して，被験者の興味，イメー\nジ形成において最も高いスコアを示した．この章では，各設問の詳細な結果を示し，T 検\n定による有意差の検証とともに，その考察を展開する．\n設問1．興味がわいたかでは，VR 環境がどの程度ユーザの興味を引いたかを評価した．\n以下の表5-2 に示す通り，注視動作は平均スコア6．7 で，他のパターンと比較して最も\n高い評価を得た．\n表5-2: 設問1 における興味関心のスコア比較\nパターン\n平均値\np 値\n有意差\n静止\n1.9\np ＜0.01\nあり\n常時動作\n5.0\np ＜0.05\nあり\n注視動作\n6.7\n—\n—\n—\n27\n図5-2: 興味関心の有意差\n*:p<0.05，**:p<0.01\n他の項目については有意差なし\nT 検定の結果，注視動作は静止と比較して非常に高い有意な差を示した（p ＜0.01）．ま\nた，常時動作と比較したときも（ｐ＜0.05）有意な差があることが明らかとなった．興味\n関心の差として段階的に静止＜常時動作＜注視動作の順でスコアが上がり主観的なアン\nケート評価でも注視動作が有意であることが分かった．\n設問2 4 ではそれぞれ扇風機，炊飯器，電子レンジの使用イメージ形成を測定した．ま\nず扇風機について表5-3 に示す．T 検定の結果として図5-3 のように，注視動作は静止と\n比較して有意な差が検出されたが，常時動作とは有意差はないと検出された．\n表5-3: 扇風機が暑さを軽減してくれると感じたか\nパターン\n平均値\np 値\n有意差\n静止\n1.8\np ＜0.01\nあり\n常時動作\n5.4\np ＞0.05\nなし\n注視動作\n6.7\n—\n—\n—\n28\n図5-3: 扇風機の使用イメージの比較\n*:p<0.05，**:p<0.01\n他の項目については有意差なし\n次に炊飯器について表5-4 に示す．\n図5-4: 炊飯器の使用イメージの比較\n*:p<0.05，**:p<0.01\n他の項目については有意差なし\nT 検定の結果として図5-4 のように，扇風機と同じように注視動作は静止と比較して有\n意な差が検出されたが，常時動作とは有意差はないと検出された．最後に電子レンジに\n29\n表5-4: 炊飯器がご飯を炊くイメージができたかどうか\nパターン\n平均値\np 値\n有意差\n静止\n1.3\np ＜0.01\nあり\n常時動作\n5.5\np ＞0.05\nなし\n注視動作\n6.2\n—\n—\n—\nついて表5-5 に示す．\n図5-5: 電子レンジの使用イメージの比較\n*:p<0.05，**:p<0.01\n他の項目については有意差なし\nT 検定の結果として図5-5 のように，注視動作は静止と比較して有意な差が検出された\nが，常時動作とは有意差はないと検出された．この３つの表から静止では動きがないた\n表5-5: 電子レンジでものを温めるイメージができたか\nパターン\n平均値\np 値\n有意差\n静止\n1.2\np ＜0.01\nあり\n常時動作\n5.0\np ＞0.05\nなし\n注視動作\n5.7\n—\n—\n—\nめ，視覚的な刺激が不足し，製品の利用イメージが付かず想像しにくいが，常時動作と3\nでは同じように動きをみることができるため，視覚的な刺激の差がないため，有意な差が\nなかったと考えられる．\n30\n5.3\nシステムの使いやすさの評価結果および考察\n本節ではシステムの使いやすさの評価結果およびその考察を述べる．評価指標について\nは4．4．3 節で述べた．SUS 法に基づいて，10 名の被験者にアンケートに回答してもら\nい，システムの使いやすさを算出した．表5-6 におけるSUS スコアの平均値を示す．結\n果として，SUS スコアの平均値は75．75 点であり，SUS スコアの基準値である68 点を\n上回った．このことから，本システムは被験者にとって「使いやすいシステム」であると\n評価できる．\n表5-6: 本システムのSUS スコア\n指標\nSUS score\nSUS スコア\n75.75\nSUS スコア全体としては基準を上回る評価を得たが，個別の設問において低い評価が見\nられた項目も存在する．特に「このシステムを使用するには技術サポートが必要です」や\n「このシステムは不必要に複雑であると思います」という設問において，一部の被験者が\n否定的な回答をしており，これが評価のばらつきに影響を与えた考えられる．低評価の原\n因としては，システムの機能や操作が複雑に感じられたことが原因と考えられる．特に，\n視線情報を用いたインタラクションに慣れていないユーザにとっては，意図通りの操作が\n困難であった可能性がある．これらの課題を解決することで，システムの使いやすさをさ\nらに向上させることができるが，解決策として，より直感的なインタフェースの導入し即\n時にフィードバックを提供し，精度を向上させることでシステムのユーザビリティをさら\nに向上できると考えられる．\n5.4\nまとめ\n本章ではシステムを用いた評価実験結果とその考察について述べた．それぞれのパター\nンでエンゲージメントの評価とアンケート評価を行い比較を行った．常時動作，注視動作\nのような動的インタラクションがユーザの興味や使用イメージの形成において極めて効\n果的であることを示した．定量的なエンゲージメント評価では視線情報に基づいて動作す\nる注視動作がもっとも有意性がありユーザの関心を長引かせ引き出す効果があると示さ\nれた．視線情報を用いることで，ユーザ体験を個別化し，長時間のエンゲージメントを維\n持できる可能性が示唆された．\n31\n第6章\n結論と今後の展望\n6.1\n結論\n本研究ではネットショッピングで購入する前に実物を見れるようにするために、仮想現\n実上で3D モデルを表示し動的な動きがあることで興味関心が変わるかを提案した．視線\n情報を活用して，注目しているモデルのみが動くシステムを作成し，動き続ける場合，動\nかない場合の3 パターンでエンゲージメント評価とアンケート評価を行った．エンゲージ\nメント評価では注視動作での平均利用時間が静止状態の2 倍近く長く，利用者の興味を最\nも引いていたと考えられる．アンケート評価では3D モデルが静止状態と注視動作が非常\nに有意な差を示し，常時動作とも有意な差を示した．本システムの使用により，現実世界\nで家電量販店に行く前に仮想現実上で動きのある3D モデルを先に見ることで興味を掻き\n立てて，使用するのイメージを想像させることができ，興味を持たせることができると明\nらかになった．\n6.2\n今後の展望\nシステムの改善点として，商品が一方向しか見れず360 度見ることができないこと，音\nなどの視覚以外のフィードバックがないため没入感にかけてしまっていること，商品との\n距離があり近くに寄せられなかったことが挙げられる．システムを考えたとき，家電量販\n店で商品を持ち上げることはないと考えてしまい，単方向からのアニメーションのみ作成\nしてしまったが，仮想現実という環境を最大限に利用できていなかったと感じる．また，\n扇風機の音や電子レンジの音などの聴覚的フィードバックも実装することで，より没入感\nを与えて興味をより掻き立てることができたのではと考えられる．以上にあげられる課題\nを解決し実装することで，より没入感があり興味関心に影響を与えられるシステムが完成\nできると考えているため，本システムを発展させていきたい．\n32\n謝辞\n本研究の機会を与えて下さり，研究面について大変ご丁寧なご指導を賜りました，青山\n学院大学理工学部情報テクノロジー学科Guillaume LOPEZ 教授に深く感謝申し上げます．\nそして，研究会などを通して助言をいただいたLOPEZ 研究室の皆様並びに実験に協力し\nていただいた皆様に深く感謝いたします．\n2025 年1 月23 日\n松田　滉生\n33\n参考文献\n[1] 統計局：2022\n年　家計消費状況調査　結果の概況.\n://www.stat.go.jp/data/joukyou/2022ar/gaikyou/pdf/gk01.pdf.\n[2] NRI メディアフォーラム：第322 回NRI メディアフォーラム(2021).\nhttps:\n//www.nri.com/-/media/Corporate/jp/Files/PDF/knowledge/\nreport/cc/mediaforum/2021/forum322.pdf?la=ja-JP&hash=\n396365B469B39B585BCE5A74CD340308B02D63F2%EF%BC%89.\n[3] 総務省：平成27 年　インターネットショッピングの利用状況\n(2015).\nhttps://www.soumu.go.jp/johotsusintokei/whitepaper/ja/h27/\nhtml/nc122400.html.\n[4] 石橋健関西大学データサイエンス研究センター：調査実験における視線追跡機能付\nきVR の利用可能性に関する研究(2018). https://www.jstage.jst.go.jp/\narticle/jasmin/2018t06/0/2018t06_99/_pdf/-char/ja.\n[5] 里村卓也：視線計測による消費者行動の理解. /https://orsj.org/wp-content/corsj/or62-\n12/or6212775.pdf?utmsource = chatgpt.com.\n[6] 張テイテイ：ネットショップにおける暗示的動きを表す静止画が消費者行動に与える影\n響，経営論集(2023).\n[7] 落合拓朗藤田智益子宗星野准一：視線情報に基づいた嗜好分析から商品推薦を行うVR\nショッピングシステム，IPSJ SIG Technical Report, Vol. 2019-HCI-184, No. 3 (2019).\n[8] 真吾柿沼育盛川浩志小宮山：VR 空間内におけるアバタとの視線コミュニケーション，研\n究報告エンタテインメントコンピューティング（EC），Vol. 1 (2018).\n[9] 坂本賢哉白井詩沙香武村紀子Orlosky Jason 長瀧寛之上田真由美浦西友樹竹村治雄：視\n線情報に基づくVR 空間でのマンガ教材読書時の主観的難易度推定，研究報告エンタテイ\nンメントコンピューティング（EC），Vol. 3 (2021).\n[10] 岩川亘宮脇健三郎：視線の重なりと表情変化が及ぼすVR コミュニケーション円滑さへ\nの効果，（第20 回情報科学技術フォーラム，Vol. 3 (2021).\n34\n[11] 広典侯：VR 環境における視線追跡技術を用いた運転視線評価システムの設計，第86 回\n全国大会講演論文集，Vol. 1 (2024).\n[12] 本田司（（株）ジオクリエイツ）三坂昇司（公益財団法人流通経済研究所）佐藤直行（公\n立はこだて未来大学）古田久美子，東瑞穂，山本智子，本多倫子（マルハニチロ（株）中\n央研究所）：アイトラッキングによる買物客の購買行動分析―ＶＲの売場の実験ツール\nと分析手法の開発―，Supplement, Vol. 59 (2023).\n[13] 中島仁大竹恒平：百貨店におけるアイトラッキングデバイスを用いた購買行動の評価，第\n86 回全国大会講演論文集　437 - 438，Vol. 1 (2024).\n[14] : Tobii pro，Tobii 社，https://www.tobii.com/ja. (参照日2025/1/23).\n[15] Wiki:\n交差検証LOOCV，https://ja.wikipedia.org/wiki/%E4%BA%A4%E5%\nB7%AE%E6%A4%9C%E8%A8%BC. (参照日2025/1/23).\n[16] 林真滉森拓也原田史子島川博光：若者のイベント参加を促す潜在興味の顕在化のための\nVR による仕掛け，FIT2020（第19 回情報科学技術フォーラム）301 - 302，Vol. 3 (2020).\n[17] 千田和範成田陸斗：視線追跡型VRHMD を用いた工学実験用訓練システムの開発，教育\nシステム情報学会第43 回全国大会，Vol. 3 (2018).\n[18] 土居巧果，河合隆史，中村直靖，黒田敏康，内山悠一：シネマチックVR における文化財\nの表現手法が興味・関心に及ぼす影響，第23 回日本バーチャルリアリティ学会大会論文\n集，Vol. 1 (2018).\n[19] 武田凌（東京工科大学）楊尚諺（東京工科大学）盛川浩志（東京工科大学）：VR 空間\nでの店員アバターによる商品説明が購買意欲に与える影響，日本人間工学会第64 回大会，\nVol. 5 (2023).\n[20] :\nPupil Neon．PupilLabs 社\n，\nhttps://pupil-labs.com/. (Accessed on 1/8/2025).\n[21] :\nMeta Quest3．Meta 社\n，\nhttps://www.meta.com/jp/quest/quest-3/. (Accessed on 1/8/2024).\n[22] :\nScaniverse-3D Scanner．Toolbox AI 社\n，\nhttps://scaniverse.com/. (Accessed on 1/8/2024).\n[23] :\niPhone14．Apple 社\n，\nhttps://www.apple.com/jp/iphone-14/specs/.\n35\n[24] :\nBlender 財団\n，\nhttps://www.blender.jp/.\n[25] :\nUnity．Unity Technologies．，\nhttps://unity.com/ja. (Accessed on 1/8/2024).\n[26] measuringU:\n10 Things to Know About the System Usability Scale (SUS),\nhttps://measuringu.com/10-things-sus/ (2013). (Accessed on 1/11/2024).\n36\n質疑応答\n伊藤雄一　情報テクノロジー学科　教授\nQ\n平均利用時間はどういうふうに定義していますか？\nA\n平均利用時間はシステムを利用し始めた時間から被験者が終了でというまでを平均\n利用時間にしました．\n伊藤雄一　情報テクノロジー学科　教授\nQ\n動きに引っ張られて、いつ止まるかが気になるため、長くみるのでは？\nA\n注視時間を1 秒以上と定義し，アニメーションは2 秒から4 秒ほどで終わるので差\n違はほとんどないと考えています．\n伊藤雄一　情報テクノロジー学科　教授\nQ\n視線情報を活用した評価指標も検討すると良いと思います\nA\n今回，視線情報を活用した評価指標を使っていませんでした．今後の研究で反映し\nます．\n37\n戸辺　義人　情報テクノロジー学科　教授\nQ\n目的が大きすぎるのでは？\nA\n具体的すぎる目的をおいていました．今後の研究では抽象度を増して結論で達成で\nきたかどうかが分かるように反映します．\n上堀　情報テクノロジー学科　助手\nQ\n３つの群を比較しているようですが、t 検定のp 値補正していますか？\nA\nT 検定で比較を行っているのが，注視動作とその他2 つのため行っていません．\n38\n",
        "chunks": [
            "B2024_KoukiMatsuda_卒論. B2024_KoukiMatsuda_卒論. B2024_KoukiMatsuda_卒論",
            "青山学院大学理工学部\n情報テクノロジー学科\n２０２４年度卒業研究論文\n仮想現実での視線情報を用いた\n商品作動ギミックによる\n関心の変化\n２０２５年１月23 日提出\n指導教員ロペズ・ギヨーム教授\n提出者学　氏名\n１５８２１０８３松田　滉生\n青山学院大学 理工学部 情報テクノロジー学科 \n2024（令和6 年）年度卒業論文要旨 \n1 \n仮想現実での視線情報を用いた商品作動ギミックによる関心の変化 \n松田 滉生（15821083） \nロ ペ ズ 研 究 室 \n \n１．はじめに \nインターネットを利用した商品の購入が急激に増加し\nており，今や多くの消費者が日常生活の一部として受\nけ入れている．店舗で実物を確認せずにインターネッ\nトだけで商品を購入することに抵抗がない消費者も増\n加している[1]．一方，特に高額商品や大きさが重要\nな商品（家具，衣類，電化製品）においては，実物を\n見てから購入したいためネットショッピングを利用し\nない消費者もまだ多い[2]． \nそこで本研究は，仮想現実（VR）空間上で商品を\n3 次元で再現するとともに，可動なパーツに動的な動\nきをさせることで，商品への興味関心が向",
            "で商品を\n3 次元で再現するとともに，可動なパーツに動的な動\nきをさせることで，商品への興味関心が向上するかを\n検証することを目的とする． \n２．関連研究 \n落合は視線情報に基づいた嗜好分析から商品を推薦\nする VR システムを提案している[3]．コンビニエン\nスストアを想定したワールドを作成し，カップ麺を\n33 種類用意しユーザーの興味や嗜好分析を視線情報\nとアンケート評価で行った結果，注視時間からユーザ\nーの興味や嗜好を判断することが可能だと考えられた． \n張はネットショップにおける暗示的動きを表す静止\n画が消費者行動に与える影響を研究した[4]．暗示的\n動きとは，静止画でありながら動きが感じられる視覚\n的特性を指す．暗示的動きを表す静止画は、消費者に\n購買意欲を向上させる効果を持つと示された． \n３．視線情報を用いた商品作動ギミック \n 本研究では動的な動きが分かりやすいように家電\n製品を3D モデルとして使用する．ヘッドマウントデ\nィスプレイ（HMD）を用いたVR 空間上に家電量販\n店をイメージしたワールドを作成した（図１を参照）．\nまた，Pupil Neon [5] を Me",
            "販\n店をイメージしたワールドを作成した（図１を参照）．\nまた，Pupil Neon [5] を Meta Quest3 [6] に取り付け\n視線情報を読み取り，注目が集まっている商品のみを\nアニメーションで動くようにシステムを構築した． \n視線情報によってポインターが移動し，図２のよう\nに視覚的にどこに注目しているのかわかりやすくする\nために，ポインターから赤色でray を表示させた．ア\nニメーションの設定として，図３のように炊飯器の開\n閉動作，扇風機の首振り動作，電子レンジの扉開閉動\n作が行えるように，各3D モデルを複数要素に分けた\nうえで，動作軸を定義するなどの工夫により，動的な\n動きを直感的に理解できるようにした．\n \n図１. 家電量販店をイメージしたワールドの様子 \n \n図２. ray が飛んでいる様子 \n \n図4.それぞれのアニメーションの様子 \n青山学院大学 理工学部 情報テクノロジー学科 \n2024（令和6）年度卒業論文要旨 \n \n４．評価方法 \n3 つの異なるVR 環境を用意し，被験者10 人に電化\n製品を観察・比較してもらい，それぞれのパターンが\n興味関心に与える影",
            "を用意し，被験者10 人に電化\n製品を観察・比較してもらい，それぞれのパターンが\n興味関心に与える影響を評価した．用意した VR 環境\nは以下の 3 つのパターンになる． \n• \n静止: 3D モデルが動かない静止状態． \n• \n常時動作 3D モデルが常に動き続ける状態． \n• \n注視動作: 被験者の視線情報に基づき，注目して\nいる 3D モデルのみが動く状態． \n順序効果を排除するため，各実験参加者は 3 つのパ\nターンのVR 環境をランダムな順序で体験してもらっ\nた．被験者には事前に，3 パターンのVR 環境で電化\n製品の観察・比較を行った後にアンケートに回答して\nもらうことを伝えた．また，それぞれのパターンの具\n体的な違いには明示せず，観察を自然に行ってもらう\nように促した． \n５．評価結果 \n関連研究を参考に，各 VR 環境でのユーザーの利用\n時間をエンゲージメントの定量的な指標として定義し\nた．具体的には，各環境の体験開始から終了までの時\n間（秒）を計測し，その値を比較することでエンゲー\nジメントの違いを評価した．またアンケート評価で興\n味と使用イメージについての主観評価も",
            "とでエンゲー\nジメントの違いを評価した．またアンケート評価で興\n味と使用イメージについての主観評価も行った． \n視線情報に基づき動作する「注視動作」環境が最も\n長い平均利用時間（45 秒）を示し，エンゲージメン\nトが他の 2 つの環境と比較して有意に高いことが分か\nりました（表１）．また，表２に示す興味関心に関す\nるアンケートの結果から，「注視動作」環境は「静止\n環境」と比較して非常に高い有意な差を示した（p＜\n0.01）．さらに，「常時動作」環境と比較したときも\n（p＜0.05）有意な差があることが明らかとなった． \n   表1.各パターンの平均利用時間と標準偏差 \n    \n \n \n \n表2.アンケート評価におけるスコア比較 \n \n６．まとめ \n本システムの使用により，現実世界で家電量販店に\n行く前に仮想現実上で動きのある 3D モデルを先に見\nることで興味を掻き立てて，使用するのイメージを想\n像させることができ，興味を持たせることができると\n明らかになった． \nシステムの改善点として，商品が一方向しか見れず \n360 度見ることができないこと，商品との距離があり\n近くに寄せられな",
            "て，商品が一方向しか見れず \n360 度見ることができないこと，商品との距離があり\n近くに寄せられなかったことが挙げられる．また，扇\n風機の音や電子レンジの音などの聴覚的フィードバッ\nクも実装することで，より没入感を与えて興味をより\n掻き立てることができたのではと考えられる．以上に\nあげられる課題を解決し実装することで，本システム\nをより没入感があり興味関心に影響を与えられるシス\nテムに発展させていく． \n参考文献 \n[1] \nNRI メディアフォーラム:生活者1 万人アンケー\nト（９回目）にみる日本人の価値観・消費行動\nの\n変\n化 \nhttps://www.nri.com/content/900032338.pdf \n[2] \n総務省: インターネットの使用状況 \nhttps://www.soumu.go.jp/johotsusintokei/whit\nepaper/ja/h27/html/nc122400.html \n[3] \n落合拓朗 藤田智 益子宗星野准一： 視線情報に\n基づいた嗜好分析から商品推薦を行う VR ショ\nッピングシステム，IPSJ SIG Technical \nR",
            "嗜好分析から商品推薦を行う VR ショ\nッピングシステム，IPSJ SIG Technical \nReport, Vol. 2019-HCI-184, No. 3 (2019) \n[4] \n張 テイテイ： ネットショップにおける暗示的動\nきを表す静止画が消費者行動に与える影響，経\n営論集 (2023). \n[5] \nPupil \nNeon\n．\nPupilLabs \n社\n \n， \nhttps://pupil-labs.com/.（2025/1/24 参照） \n[6] \nMeta \nQuest3\n．\nMeta \n社\n \n， \nhttps://www.meta.com/jp/quest/quest-3/\n（2025/1/24 参照） \n目次\n第1 章\n序章\n1\n1.1\n研究背景. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n1\n1.1.1\nオンラインショッピングの増加. . . . . . . . . . . . . . . . . . . .\n1\n1.1.2\n消費行動と視線情報の関係\n. .",
            ". . . . . . . . . . . . .\n1\n1.1.2\n消費行動と視線情報の関係\n. . . . . . . . . . . . . . . . . . . . . .\n5\n1.2\n研究目的. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n5\n1.3\n本論文の構成. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n5\n第2 章\nVR と消費行動の変化に関する研究\n6\n2.1\nネットショップにおける暗示的動きを表す静止画が消費者行動に与える影\n響に関する研究. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n6\n2.2\nVR と視線情報\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n7\n2.2.1\n視線情報から商品推薦を行うVR シス",
            ". . . . . . . . . . . .\n7\n2.2.1\n視線情報から商品推薦を行うVR システム. . . . . . . . . . . . . .\n7\n2.2.2\nVR 空間における視線とコミュニケーション. . . . . . . . . . . . .\n8\n2.2.3\nVR 環境における視線追跡と運転. . . . . . . . . . . . . . . . . . .\n9\n2.2.4\nアイトラッキングによる購買行動分析に関する研究. . . . . . . . .\n10\n2.3\nVR と興味関心\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n12\n2.4\n先行研究のまとめ. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n14\n第3 章\n仮想現実において，視線情報を用いた商品作動ギミック\n15\n3.1\nシステム概要. . . . . . . . . . . . . . . . . . . . . . . ",
            "テム概要. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n15\n3.2\n使用デバイス. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n16\n3.2.1\nシステムに利用したHMD . . . . . . . . . . . . . . . . . . . . . . .\n16\n3.2.2\n視線情報を計測するデバイス\n. . . . . . . . . . . . . . . . . . . . .\n17\n3.3\n動的な3D モデルの作成方法. . . . . . . . . . . . . . . . . . . . . . . . . .\n18\n3.3.1\n3D モデルの読み取り方\n. . . . . . . . . . . . . . . . . . . . . . . .\n18\n3.3.2\nアニメーションの作成方法\n. . . . . . . . . . . . . . . . . . . . . .\n19\n3.",
            "\n. . . . . . . . . . . . . . . . . . . . . .\n19\n3.4\n通信手法及び仮想空間内における表現手法. . . . . . . . . . . . . . . . . .\n19\n3.4.1\nシステム開発に利用した開発プラットフォーム\n. . . . . . . . . . .\n20\n3.4.2\n視線情報計測. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n20\ni\n3.5\nまとめ. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n21\n第4 章\nモデルの動的な動きの有無による興味関心の評価実験\n22\n4.1\n実験目的. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n22\n4.2\n実験環境. . . . . . . . . . . . . . . . . . . . . . . . ",
            "環境. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n22\n4.3\n実験方法. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n23\n4.4\n評価方法. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n24\n4.4.1\nエンゲージメント評価. . . . . . . . . . . . . . . . . . . . . . . . .\n24\n4.4.2\nアンケート評価. . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n24\n4.4.3\nシステムの使いやすさの評価指標. . . . . . . . . . . . . . . . . . .\n25\n第5 章\n実験結果と考察\n26\n5.1\nエンゲージメント評価考察. . . . . . . ",
            "\n25\n第5 章\n実験結果と考察\n26\n5.1\nエンゲージメント評価考察. . . . . . . . . . . . . . . . . . . . . . . . . . .\n26\n5.2\nアンケート評価および考察. . . . . . . . . . . . . . . . . . . . . . . . . . .\n27\n5.3\nシステムの使いやすさの評価結果および考察. . . . . . . . . . . . . . . . .\n31\n5.4\nまとめ. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n31\n第6 章\n結論と今後の展望\n32\n6.1\n結論. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n32\n6.2\n今後の展望\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n32\n",
            " . . . . . . . . . . . . . . . . . . . . . . .\n32\nacknowledgments\n33\n参考文献\n34\nii\n第1章\n序章\n本章では，社会的な背景をもとに研究の位置付けを明確にする．1.1 節では，研究背景\nとしてオンラインショッピングでの購入における現状と課題について述べる．1.2 節では，\n背景に挙げた課題を踏まえた本研究の目的を定義する．1.3 節では，本論文の構成につい\nて述べる．\n1.1\n研究背景\n1.1.1\nオンラインショッピングの増加\n近年，日本ではEC サイトを利用した商品の購入が急激に増加しており，今や多くの消\n費者がインターネットを活用した買い物を日常生活の一部として受け入れている．図1-1\n統計局が実施した調査によると，ネットショッピングの利用率や支出額は年々増加傾向に\nあり，その成長は新型コロナウイルス感染症の拡大による生活様式の変化とも相まって一\n層加速している[1]．\n図1-1: ネットショッピング利用世帯の割合の推移（[1] より）\n1\n図1-2 のように，特に外出を控える生活が推奨された2020 年以降，",
            "合の推移（[1] より）\n1\n図1-2 のように，特に外出を控える生活が推奨された2020 年以降，食品や生活必需品\nの購入においてもネットショッピングを利用する人々が急増し，EC 市場の拡大に拍車を\nかけたとされている．\n図1-2: オンライン消費の増加( [2] より)\n飲食業界においては，インターネットで注文し，飲食店から食事を配達してくれる宅\n配サービスが，大都市を中心に利用が増えている．また，e コマースにおいても，プラッ\nトフォームサービス等を利用せ，自ら開設したウェブサイトを通じた販売が増加してい\nる．このように，自らが企画・生産した商品を消費者に対して直接販売するD2C（Direct\nto Consumer）の動きが加速している[2]（図1-3）．これにより，大都市の消費者が地方の\n個人や小規模店舗から商品を購入することが可能となるなど新たなつながりも生まれる．\nこのような消費行動の変化は，単なる一過性のものではなく，今後の産業構造が大きく変\n化することにつながる可能性がある．\n図1-3: D2C の概念図( [2] より)\n2023 年の統計によれば，2 人以上の世帯",
            "ある．\n図1-3: D2C の概念図( [2] より)\n2023 年の統計によれば，2 人以上の世帯におけるネットショッピングの支出金額は1 か\n月平均23，021 円に達し，利用世帯当たりの支出金額は42,937 円と，統計が開始された\n2002 年以来過去最多を記録しました．この数字は，ネットショッピングが単なる補助的\n2\nな購買手段に留まらず，多くの人々の主たる購買方法として定着しつつあることを示して\nいる．また，野村総合研究所の調査には世代間の差異も見られるが，特に若年層や働き盛\nりの世代である20 代から40 代の間では，インターネットショッピングを年1 回以上利用\nする人の割合が80 ％を超えており，これらの層がEC 市場の拡大を牽引していることが\n明らかになっている．図1-4 に調査結果を示す．\n図1-4: インターネットショッピングを年1 回以上利用する人の割合の推移( [3] より)\nさらに，店舗で実物を確認せずにインターネットだけで商品を購入することに抵抗がな\nい消費者も増加している．2021 年の調査では，その割合が約50 ％に達し，従来の「商品\nを直接手に取って",
            "者も増加している．2021 年の調査では，その割合が約50 ％に達し，従来の「商品\nを直接手に取って確認したい」という購買行動の変化を示している[3](図1-5)．\n3\n図1-5: 店舗で実物を確認せずにインターネットだけで商品を買うか( [3] より)\nこの背景には，商品の写真や動画，レビューなどのデジタルコンテンツの進化が挙げら\nれる．これにより，消費者は実物を確認しなくても商品の品質や性能をある程度把握でき\nるようになり，購買の意思決定がオンラインで完結するケースが増えている．\n一方で，ネットショッピングにはまだ課題も残されている．総務省が実施した調査によ\nると，ネットショッピングを利用しない理由として「実物を見てから購入したい」という\n回答が多く挙げられており，これがEC 市場のさらなる成長を妨げる一因となっている．\n特に高額商品やサイズが重要な商品（家具，衣類，電化製品）においては，購入前に実物\nを確認したいというニーズが根強く存在している．また，商品の写真や説明が実物と異な\nる場合，消費者の期待を裏切る結果となり，返品や交換の増加につながる可能性も指摘さ\nれている．\n以上の",
            "る場合，消費者の期待を裏切る結果となり，返品や交換の増加につながる可能性も指摘さ\nれている．\n以上のように，ネットショッピングの利用率や支出額は確実に増加しているが，同時に\nその利便性と実物確認の重要性という相反する要素が存在していることが分かる．これら\nの課題を解決するためには，消費者が安心して購入できる環境を整備することが必要だ．\n例えば，商品の詳細を分かりやすく伝えるための高品質な写真や動画，拡張現実（AR）や\n仮想現実（VR）を活用した視覚的な確認手段の導入が期待されている．\n以上より，ネットショッピングは利便性の向上により多くの支持を得ている一方で，実\n物を確認できないことによる購買意欲の低下という課題を抱えている．この問題を克服す\nることで，さらに多くの消費者がネットショッピングを活用し，EC 市場の発展が進むと\n考えられる．\n4\n1.1.2\n消費行動と視線情報の関係\n消費行動と視線情報の関連を分析した調査では，視線計測技術を用いた, 商業施設にお\nいて消費者の視線情報から消費者の興味を分析する研究が行われていた．近年だとメタ\nバースやXR といった分野を実験環境として利用",
            "費者の興味を分析する研究が行われていた．近年だとメタ\nバースやXR といった分野を実験環境として利用することが多く研究されている．既存の\n研究では実験環境にPC のモニターやスクリーンが利用されており，メタバース空間を実\n験環境として選んだ場合においても同様な結果が得られることが明らかになっている[4]．\nマーケティングや消費者行動研究において重要なテーマとなっている．視線計測技術（ア\nイトラッキング）を活用することで，消費者がどのような情報に注目し，どのような意思\n決定プロセスを経て購買に至るのかを詳細に分析することが可能だ．例えば商品配置やデ\nザイン，色彩などが消費者の視線を引き付け，購買意思決定に影響を与えることが示され\nている[5]．しかし，VR 空間に3D モデルを表示しそのモデルを見ての消費行動，興味の\n変化についての研究はまだ行われていない．\n1.2\n研究目的\n1.1 節で述べたように，ネットショッピングで買う前に実物を見る必要があると考える．\nそのため，本研究では，VR 空間上で，使用イメージが分かることで興味が変化するのか\nを研究目的とする．具体的には，視線情報を元に",
            "空間上で，使用イメージが分かることで興味が変化するのか\nを研究目的とする．具体的には，視線情報を元にユーザーの興味を判定し，注目した物の\n3D モデルを動かす．そこで本研究では，仮説を実証するために以下の2 つの点について\n取り組んだ．\n1. 実物のような3D モデルとアニメーションの作成．\n2. 視線情報によって3D モデルの動きを制御．\n1.3\n本論文の構成\n第1 章では，本論文の研究背景，研究目的，及び本論文の構成について述べた．第2 章\nでは，VR を融合した消費行動の変化に関する先行研究を3 つ述べた．第3 章では，シス\nテムの概要，使用デバイス，3D モデルの作成方法，通信手法について述べた．第4 章では\n本研究の実験目的，実験環境，実験方法，評価方法について述べた．第5 章ではエンゲー\nジメント評価考察，アンケート評価および考察，システムの使いやすさの評価結果および\n考察を述べた．第6 章では結論と今後の展望を述べている．\n5\n第2章\nVRと消費行動の変化に関する研究\n本章では，VR を融合した消費行動の変化に関する研究について述べる．2.2.1 節では視\n線情報に基づい",
            "では，VR を融合した消費行動の変化に関する研究について述べる．2.2.1 節では視\n線情報に基づいた嗜好分析から商品推薦を行うVR ショッピングシステムの研究，2.2.4\n節ではアイトラッキングによる買い物客の購買行動分析の研究について述べる．2.1 では\nネットショップにおける暗示的動きを表す静止画が消費者行動に与える影響について述\nべる．\n2.1\nネットショップにおける暗示的動きを表す静止画が消費者行動に与え\nる影響に関する研究\nこの論文では，ネットショップにおける商品の提示形式が消費者の商品選択や購買意欲に\nどのような影響を与えるかを検討した[6]．その中でも特に「暗示的動き(Implied Motion)」\nを表す静止画に注目し，その効果とメカニズムを議論している．視覚刺激が消費者の注意\nや判断に及ぼす影響は広く研究されてきたが，これまでは静的な商品画像やビデオなどの\n動的提示に焦点が当てられることが多かった．本研究では，静止画が持つ暗示的な動きが\n消費者行動に与える影響を実証的に検証した点で新規性がある．「暗示的動き」とは，静\n止画でありながら動きが感じられる視覚的特性を指",
            "的に検証した点で新規性がある．「暗示的動き」とは，静\n止画でありながら動きが感じられる視覚的特性を指す．この現象は視覚システムによる\n運動の想像と再現によって生じるとされ，実際の運動と同様に脳の特定の領域を活性化さ\nせることが知られている．消費者は，運動を暗示する静止画を見ることで，商品に対する\n心的イメージ（mental imagery）を形成しやすくなる．この心的イメージは，消費者が商\n品を使用する場面や効果を鮮明に想像することを可能にし，購買意欲や商品態度に影響を\n与える．仮説を検証するためにYahoo!クラウドソーシングにて実験を行った．実験は商\n品画像の提示形式を動的なもの（図2-1）と静的なもの（図2-2）に分け200 名の20 代～\n60 代の一般消費者を対象として行った．質問として「これからネット店舗尾で使われる\n画像を見せる．画像をよく見て質問に回答してください．」として解答してもらった．\n結果として，視覚刺激の形式が消費者行動に与える影響を示す重要な知見を提供してい\nる．特に，暗示的動きを表す静止画は，消費者に運動を知覚させ，心的イメージの鮮明さ\nを高めることで，購",
            "る．特に，暗示的動きを表す静止画は，消費者に運動を知覚させ，心的イメージの鮮明さ\nを高めることで，購買意欲や商品態度を向上させる効果を持つ．また，静止画はビデオや\nVR に比べて制作コストが低く，ネットショップにおける実用性が高いと考えられる．\n6\n図2-1: 暗示的動きのある商品写真( [6]\nより)\n図2-2: 静的な商品写真( [6] より)\n2.2\nVR と視線情報\n2.2.1\n視線情報から商品推薦を行うVR システム\nこの論文では，視線情報に基づいた嗜好分析から商品を推薦するVR システムを提案し\nている[7]．限定的問題解決プロセスを導入している．限定的問題解決プロセスとは，あ\nる商品群から商品を選択する場合においてユーザーが商品についてある程度の知識があ\nり，複数の選択肢から比較検討を行うことであり，限定的加算型（限定された選択肢か\nら，全体的に評価を行い選択する）という評価方法を利用している．予備調査として即\n席麺の購入においての購買意思決定について20 代の男女30 名を対象にアンケート形式\nで調査を行った結果，20 代の消費者が商品購入を決定する要素で最も重要視する",
            "を対象にアンケート形式\nで調査を行った結果，20 代の消費者が商品購入を決定する要素で最も重要視するものは\n“価格”と“味”を重視するということが予備調査で判明した．この予備調査をもとに味\nの特徴，価格帯，麺の種類など合計33 の商品要素を利用してユーザーの興味や嗜好分析\nを行うことにした．被験者はコントローラを利用して商品を選択すること，商品の詳細\n情報として拡大された商品パッケージと商品説明を見ることができる(図2-3)．被験者は\nその商品が気に入れば購入を決定する．購入決定後に，図2-3 のように被験者に対して\n商品推薦を行った．VR ショッピングシステム体験後に商品購入の理由や推薦商品に対す\nる満足度，実際の店舗との購買体験の差異についてアンケートで調査した．\n7\n図2-3: 被験者が商品を選択したときに見る画面と被験者に商品を推薦したときに見せる画面\n( [7] より)\n20 代前半の男性12 名を被験者として実験を行った．被験者が商品を注視した時間が\n中央値より短い群（A 群）と長い群（B 群）と二つに分けた．A 群は商品をVR 店舗内の\n商品をすべて見てから商品を買うとい",
            "）と長い群（B 群）と二つに分けた．A 群は商品をVR 店舗内の\n商品をすべて見てから商品を買うという探索的な姿勢が見られない群と推測され，B 群は\n最初に全ての商品選択肢を把握してから自分の好みでフィルタリングを行う群だと推測\nできる．そのため，注視時間からユーザーの興味や嗜好を判断することが可能だと考えら\nれた．被験者のアンケートからわかったこととして，このシステムでは注視時間を基に\n制作しているため，商品の購入を決定する時間が短いユーザーに対しては興味や嗜好に\n合った商品を推薦することは難しいと考えられる．しかし，そのようなユーザーに対して\nも興味や嗜好に合わないまでも，見新しい商品を推薦機能としては十分に利用できるこ\nとがわかった．一方で，商品の購入までに一定の時間をかけて選ぶユーザーに対しては\nユーザーの興味や嗜好に合った商品を推薦できると考えられる．しかし，このようなユー\nザーに対しては新しい商品を推薦できないということがわかった．また，VR 店舗におい\nても，実際の店舗と同様に目に付きやすく，手の届きやすい位置にある商品に対して注視\nが集まることが分かった．このことから注",
            "様に目に付きやすく，手の届きやすい位置にある商品に対して注視\nが集まることが分かった．このことから注視時間からユーザーの興味を推定するという仮\n定を立てる際に商品の位置を考慮する必要があるとわかった．\n2.2.2\nVR 空間における視線とコミュニケーション\nこの論文ではVR 空間においてアバターとの視線コミュニケーションが対話に与える影\n響を明らかにすることを目的とした[8]．視線は対面コミュニケーションにおいて重要な\n非言語情報であり，VR 空間でもアバターとの自然な対話を実現するためには視線の役割\nが鍵となる．小宮山らは，VR 空間内でHMD 装着者がアバターと対話する環境を構築し，\n視線を用いた場合と首の向きを視線として代用した場合で比較実験を行った．アイトラッ\nキング機能付きHMD を使用し，アバターの視線や動作を調整した対話システムを設計し\nた．実験の結果，視線追跡を用いた場合，アバターとの空間共有感やアイコンタクトの評\n価が有意に向上した．また，アバターとの対話時に視線が自然に合うことで，対話のス\n8\nムーズさや親しみやすさも高まることが示唆された．一方で，首の向きを視線と",
            "に合うことで，対話のス\n8\nムーズさや親しみやすさも高まることが示唆された．一方で，首の向きを視線として代\n用する場合は，視線の動きが制限され，対話における違和感が生じることが確認された．\nVR 空間でアバターを用いた対話をより自然にするためには，視線検出技術の導入が重要\nであると結論付けられた．\n坂本らはVR 空間におけるマンガ教材読書時の学習支援を目的とし，視線情報を用いた\n主観的難易度推定手法を提案した[9]．マンガ教材は，文字と絵が組み合わさった複雑な\nレイアウトを持つため，ページ滞在時間などのログデータだけでは学習者の理解度や難易\n度の推定が難しい．そこで本研究では，視線データを活用し，学習者の主観的な難易度を\nコマ単位で推定する手法を開発した．提案手法では，従来の視線特徴量に加えて，「視線\nヒートマップ情報」および「注視点と視線の交点の距離」というVR 空間特有の特徴量を\n抽出し，機械学習を用いて難易度を推定した．評価実験の結果，ユーザ依存モデルではラ\nンダムフォレスト（RF）を用いた推定でF 値0.705，ユーザ非依存モデルではSVM によ\nる推定でF 値0.711 を達",
            "）を用いた推定でF 値0.705，ユーザ非依存モデルではSVM によ\nる推定でF 値0.711 を達成し，従来手法より高精度な難易度推定が可能であることを示し\nた．今後の課題として，データ収集の拡充，リアルタイム推定の精度向上，学習支援シス\nテムへの応用が挙げられた．この研究よりマンガ教材を活用したVR 学習環境の個別最適\n化への貢献が期待される．\n石川らはVR 空間内における視線の一致と表情変化がコミュニケーションの円滑さに及\nぼす影響を研究した[10]．現在のVR コミュニケーションでは，ユーザの表情をHMD 内\n蔵カメラで反映させるフェイストラッキング技術が用いられているが，表情の変化が限定\n的であり，感情表現が不自然になるという課題がある．そこで本研究では，アバター同士\nの視線が一致した際に表情変化を強調することで，ユーザの気づきを促し，親密度を向上\nさせる手法を提案した．実験では，HTCVIVE とUnity を使用し，VR 空間内に3DCG キャ\nラクターを配置した．HMD 装着者とキャラクターの視線が一致すると，キャラクターの\n表情が無表情→笑顔→より強い笑顔の3 段階で",
            "装着者とキャラクターの視線が一致すると，キャラクターの\n表情が無表情→笑顔→より強い笑顔の3 段階で変化するように設定し，その影響を評\n価した．結果として，視線が一致すると表情の変化に対する気づきが促進され，笑顔への\n変化が快適なコミュニケーションにつながる可能性が示唆された．しかし，笑顔の強度が\n増すにつれて気づきにくくなる傾向も見られた．\n2.2.3\nVR 環境における視線追跡と運転\n侯らはVR 環境を活用し，視線追跡技術を用いた運転視線評価システムを設計し，初心\n者ドライバーの視線特性を分析し研究した[11]．運転中の視線の動きは交通安全に大き\nく影響を与える要素であり，適切な視線配分を学習することで運転技術の向上が期待され\nる．このシステムでは，HTC Vive Pro Eye を用いて運転者の視線データを収集し，360 度\n映像をVR 空間内で再生することで，実際の運転体験を再現する．被験者はVR 環境内で\n9\n運転し，その際の視線データを熟練者の視線データと比較することで，視線配分の適切さ\nを評価する．また，視線の動きの違いをスコア化し，学習の進捗を可視化する機能も搭載\nし",
            "線配分の適切さ\nを評価する．また，視線の動きの違いをスコア化し，学習の進捗を可視化する機能も搭載\nしている．実験では，運転経験の異なる3 名の被験者を対象に視線の角度差とスコアを分\n析した．その結果，運転経験がない被験者ほど熟練者との視線の差異が大きく，スコアが\n低いことが確認された．一方で，運転免許を所持する被験者は，熟練者に近い視線配分を\n示し，高いスコアを達成した．これらの結果から，VR を用いた視線訓練が初心者ドライ\nバーの視線改善に有効である可能性が示唆された．\n2.2.4\nアイトラッキングによる購買行動分析に関する研究\n現地と現地を再現したVR の売り場において，非計画購買が発生する歩行時の視聴時間\nと，影響を与えているパッケージデザイン要素の関係性を解釈することを目的とした研究\nがある．非計画購買を分析するために，視認に関連した各種の内容や時間を定義し，手法\nとしてまとめた．場面の分類として，売り場では選択→進行→比較→購買の4 段階の場面\nの分類として用いた．（図2-4）売り場を歩行し，非計画購買として商品を見つけて比較\nし，購買に至るメンタルモデルの変化を捉えられる．",
            "売り場を歩行し，非計画購買として商品を見つけて比較\nし，購買に至るメンタルモデルの変化を捉えられる．\n図2-4: 場面の分類( [12] より)\n次に視認時間を定義した（図2-5．視認時間の傾向から，売り場の商品の形態を存在把\n握して選択→比較する傾向の時間として，0．2 秒未満を見まわし，0．2 秒以上1 秒未満\nを確認，1 秒以上5 秒未満を中止しており内容も覚えている，5 秒以上見た場合詳細も把\n握できる状態とした．\n10\n図2-5: 視認時間の傾向( [12] より)\nパッケージの要素についても分類し，文字量特徴量と背景特徴量として抽出・数値化し，\n視認時間との相関を分析し，パッケージデザインに実験データを紐づけて活用できるよう\nにした．結果と考察について進行場面と比較場面が分類された．進行場面: 購買行動が進\n行中で，VR 環境では商品の背景特徴量に関連があり，見ているかどうかの時間（視認時\n間）が有意な関連があることが示された．比較場面: 異なる選択肢を比較する場面で，現\n地とVR の両方で文字や背景特徴量と購買行動の関連が確認され，特に背景特徴量につい\nては強い相関が見ら",
            "とVR の両方で文字や背景特徴量と購買行動の関連が確認され，特に背景特徴量につい\nては強い相関が見られた．結果として，見た商品は，背景特徴量が少なく，文字特徴量が\n多かった傾向があり，購買行動は進行場面から比較場面への移行を示唆し，文字特徴量が\n多い商品が多い商品が特に重視されることが示され，現地とVR の両方で，購買行動に影\n響を与える特徴量の傾向が類似していることが確認された[12]．\n中島らは百貨店におけるアイトラッキングデバイスを用いた購買行動の評価を行った\n[13]．消費者の購買行動における非計画購買（来店前に計画されていない購買）は，店舗\n滞在時間や顧客特性に大きく影響されることが既存研究で示唆されている．この論文で\nは，多層階の百貨店を対象に，アイトラッキングデバイスを用いて消費者の動線や購買行\n動を観察し，非計画購買に影響を与える要因を評価することを目的とした．実験場所とし\nて，都心に所在する大型百貨店で実験を行い，Tobii 社のアイトラッキングデバイス[14]\nを被験者に装着してもらい，自由に1 時間ショッピングを行ってもらった．参加者は自由\nにショッピングを行い，",
            "者に装着してもらい，自由に1 時間ショッピングを行ってもらった．参加者は自由\nにショッピングを行い，その際の視線データと店舗滞在時間が記録された．また，購買目\n的や好みの店舗，訪店歴などのアンケートデータも収集し，これらの情報をもとに非計\n画購買の発生要因を分析した．モデル評価にはLOOCV（Leave-One-Out Cross-Validation）\nを採用し[15]，データ分析には，ランダムフォレストを用いた予測モデルが採用され，非\n計画購買の発生を高い精度で予測することができた．特に，実店舗嗜好や店舗滞在時間が\n非計画購買に大きな影響を与える要因であることが明らかとなった．具体的には，図2-6\nのように店舗滞在時間が1500 秒を超えると非計画購買が増加する一方，2000 秒を超える\nと購買意欲が減少する傾向が確認された．\n11\n図2-6: 中島らの研究結果( [13] より)\n横軸：店舗滞在時間　縦軸：非計画購買への影響\nこの研究の結果から，実店舗への関心が高い消費者ほど非計画購買を行いやすいことが\n示唆される．また，アイトラッキングデバイスを活用した視線情報の収集が，購買行",
            "購買を行いやすいことが\n示唆される．また，アイトラッキングデバイスを活用した視線情報の収集が，購買行動の\n予測や分析において有効であることが実証された．\n2.3\nVR と興味関心\n林らはVR を活用して若者のイベント参加を促す方法について研究した[16]．若者の地\n域活性化のためのイベントへの参加率の低さに着目し，VR を活用して潜在的な興味を引\nき出し，イベント参加を促す手法を提案している．まず若者がイベントに参加しない理由\nを分析し，参加することで得られる便益を考察した．単にイベントをVR で紹介するので\nはなく，体験させることで興味を引き出せるのではと考えた．現実のイベントに参加しな\nい理由として，時間やお金，労力などのコストがかかってしまう．そこでVR を活用しど\nんなイベントなのかを体験させることで，心理的なハードルを下げることを目標とした．\nVR 空間でイベントの準備や広報を仮想的に体験してもらう．例えば，地域の祭りの準備\nをVR で手伝ったり，模擬店の運営をVR で試した．アフォーダンス理論を応用しVR 内\nでの若者行動を分析した．アフォーダンス理論とは人は環境の中にある",
            "アフォーダンス理論を応用しVR 内\nでの若者行動を分析した．アフォーダンス理論とは人は環境の中にあるものによって自然\nに行動が誘発されるという考えで、椅子があれば座りたくなったり，ドアノブがあれば回\nしたくなるといったものだ．この考えを応用し，VR 空間内での若者の行動を観察するこ\nとで，何に興味があるかを分析した．VR 内で神輿を担ぐアクションを良くする場合，祭\nりの伝統文化に興味がある．模擬店の売り上げ管理に集中する場合，経営や販売に興味が\nあるのではと仮説を立てた．VR 空間での行動データをNMF 解析で数値化し，どのアク\nティブにどれくらい時間を使ったか，どれだけ集中していたかを記録し，このデータを基\n12\nにこの人はこのタイプのイベントに興味がありそうではと分析した．結果としてVR を活\n用することで若者にとって魅力的なイベントは何かを数値的観点から分析することが可\n能となり，若者の潜在的な興味を引き出し，参加を促すことが可能であることを示した．\n成田らは視線追跡型VRHMD を用いた工学実験の訓練システムを開発し，学習効果の\n向上を目指した[17]．従来の講義形式の授業では",
            "を用いた工学実験の訓練システムを開発し，学習効果の\n向上を目指した[17]．従来の講義形式の授業では集中力を維持しにくいという課題があ\nり，VR 技術を活用することで，没入感の向上による学習効果の向上が期待される．特に，\n工学実験では安全性の確保や作業手順の正確な習得が重要であり，VR 技術との親和性が\n高い．本研究では，視線追跡型VRHMD「FOVE0」，VR 開発環境「Unity」，手の動きを\n認識する「Leap Motion」を組み合わせ，実験手順の習得を支援するシステムを構築した．\n視線情報を活用し，学習者が適切な箇所を注視しているかを判定し，必要に応じて視線誘\n導を行う．また，ゲーミフィケーションの要素を導入し，得点の可視化やフィードバッ\nクを行うことで学習意欲を高める仕組みを導入した．実験では，電動機の起動手順をVR\n環境で再現し，視線の記録と操作の正確性を評価した．その結果，学習者が特定のオブ\nジェクトを一定時間注視した際に得点が加算されるなど，視線追跡によるフィードバック\nが機能することが確認された．\n土居らはVR を活用した文化財鑑賞がどのように鑑賞者の興味関心に影響",
            "\nが機能することが確認された．\n土居らはVR を活用した文化財鑑賞がどのように鑑賞者の興味関心に影響を与えるかを\n調査することを目的とした[18]．特にシネマチックVR（映画のような映像コンテンツを\nVR 空間内のシアターで鑑賞する方式）に着目し，VR 表現の違いが観賞者の注視点や興\n味に与える影響を分析した．文化財の観光資源化がすすめられているが, 伝統的な解説は\n難解で理解しづらいとされてきた．そこでデジタルアーカイブを活用することで，より\n分かりやすい鑑賞体験を提供できると考えた．実験方法として国宝「八橋蒔絵螺鈿硯箱」\n（やつはしまきえらでんすずりばこ）を題材にした3 種類のVR コンテンツを制作し，VR\n空間内のシアターで鑑賞させる．参加者にVR 映像の前後で静止画を観察させ，視線計測\nや興味度の変化を分析．アイトラッキング機能付きHMD を使用して眼球運動を計測し，\nVR 映像鑑賞中の視線運動と瞬目発生頻度，視線停留時間の変化を計測した．瞬きの発生\n頻度の変化で興味度を測り，興味度が高いとまばたきの回数が減るという理学的知見に基\nづき，VR 映像の前後での瞬目発生頻度で興味の",
            "味度が高いとまばたきの回数が減るという理学的知見に基\nづき，VR 映像の前後での瞬目発生頻度で興味の変化を評価した．結果として，VR 映像\nを見た後，まばたきの回数が減り，視線が特定の部分に衆目する傾向が確認された．VR\n表現（特に「透視」「歩行」などのインタラクティブな演出）が文化財への興味を引き出\nすのに有効であることが示唆された．\n武田らはVR 空間におけるアバターが購買意欲に与える影響について研究した[19]．\nバーチャルショッピングにおける購買意欲に与える影響を明らかにすることを目的とし\nた．バーチャルショッピングでは，商品の3D モデルを確認できる利点があるが，店員ア\nバターの影響については十分な研究がなされていない．HMD を装着した参加者に対し，\n13\n1. テキストと音声による商品説明（テキスト条件），2. 動画による商品説明（動画条件），\n3. アバターが身振り手振りを交えて説明する条件（アバター条件）の3 種類を設定し，購\n買意欲の変化を比較した．その結果，すべての条件で購買意欲の向上が確認されたが，特\nにアバター条件での上昇率が最も高かった．また，アバター条件で",
            "条件で購買意欲の向上が確認されたが，特\nにアバター条件での上昇率が最も高かった．また，アバター条件では商品の理解度も高ま\nり，説明に対する親しみやすさや実在感が向上した．一方で，個人の興味関心や商品の種\n類による影響も大きく，購買意欲の変化には個人差があることが示唆された．\n2.4\n先行研究のまとめ\nこれまでの研究は視線情報による購買行動の変化や消費行動の分析，見え方による購\n買意欲の変化などを調べてきた．2.2.1 節では視線情報から商品を推薦することができる\nユーザも存在するが，商品の位置によっても変化がでるため，本研究ではすべてを平行に\n置き，見やすくした中での商品選択を行うものとし，注視時間の平均時間によって推薦を\n行っていたため，本研究ではシステムの利用時間によって興味関心を評価する．2.2.4 か\nら注視時間を1 秒以上見ている場合と定義しる．2-1 から暗示的な動きのある商品写真が\n心的イメージを高め，購買意欲や商品への興味を向上させていたことから，本研究では，\n視線情報からユーザーの気になっているものだけに動的なアニメーションが動くように\nし，他のものと差別化できるシス",
            "らユーザーの気になっているものだけに動的なアニメーションが動くように\nし，他のものと差別化できるシステムを提案する．\n14\n第3章\n仮想現実において，視線情報を用いた商品\n作動ギミック\n3.1\nシステム概要\n本節では本研究で提案する仮想現実において，視線情報を用いた商品作動ギミックの概\n要について述べる．動的な動きが分かりやすいように本研究では家電製品を3D モデルと\nして使用する．ヘッドマウントディスプレイを用いた仮想現実上に家電量販店をイメー\nジしたワールドを作成し，Pupil Neon [20] をMeta Quest3 [21] に取り付け視線情報を読み\n取り，注目が集まっているオブジェクトのみをアニメーションで動くようにシステムを作\n成．家電量販店に直接行くのではなく仮想現実上で動的な動きを見ることによる興味の向\n上や変化を図ることを目的としたシステムである．\n図3-1 に提案システムの全体図を示す．被験者はヘッドマウントディスプレイを装着し，\nVR 空間上で家電製品を見ることができる．視線情報によってポインターが移動し，図3-2\nのように視覚的にどこに注目しているのかわかり",
            "ができる．視線情報によってポインターが移動し，図3-2\nのように視覚的にどこに注目しているのかわかりやすくするために，ポインターから赤色\nでray を表示させた．\n図3-1: 家電量販店をイメージしたワールドの様子\n図3-2: ray\n15\nまたアニメーションの設定として，図3-3 のように炊飯器は開閉の動作，扇風機は首を\n振る動作，電子レンジは扉の開閉が行えるようにアニメーションを作成してあり，動的な\n動きを直感的に理解できるようにした．\n図3-3: 電化製品の動的な動き\n3.2\n使用デバイス\n本節では，このシステムを構成するデバイスの説明について述べる．\n3.2.1\nシステムに利用したHMD\n本研究ではヘッドマウントディスプレイとしてMeta 社が製造するバーチャルリアリティ\nヘッドセットのMeta Quest3 を使用する[21]．図3-4 にMeta Quest3 の外見を示す．Meta\nQuest3 は単体で動作するためその他の特別な機器が不要である．左右のコントローラー\nを使い仮想現実上で操作することができる．4K 解像度+ Inﬁnite Display 基本容量512G",
            "い仮想現実上で操作することができる．4K 解像度+ Inﬁnite Display 基本容量512GB\nで視野110°，メモリ8GB であり，バッテリー駆動時間は連続使用で2．2 時間のため，\n本研究におけるシステムを問題なく利用できる仕様となっている．\n16\n図3-4: Meta Quest3 の外見( [21] より)\n本研究では仮想現実内に家電量販店を模した店舗を作成し，3 つの家電製品を設置する．\nリアルな没入感を体験してもらい実際に店舗にいるように体験してもらうように，家電量\n販店のように白い壁や床を配置し，ガラスのテーブルの上に3D モデルを設置した．\n3.2.2\n視線情報を計測するデバイス\n本研究では，視線情報の取得のために図3-5Pupil Labs 社が出すPupil Neon を使用し\nた[20]．Pupil Neon を利用することでVR 空間に存在する3D オブジェクトに対してユー\nザーの視線情報が計測できる．ユーザーの左右の眼下にそれぞれ小型カメラを設置して，\nユーザーの眼球運動とVR 空間にある注視点をキャリブレーションすることで，VR 空間\nにおいてユーザ",
            "ユーザーの眼球運動とVR 空間にある注視点をキャリブレーションすることで，VR 空間\nにおいてユーザーの視線情報を取得することができる．\n17\n図3-5: Pupil Neon の外見( [20] より)\nユーザーの視線方向にray を飛ばすことで，ray が電化製品に衝突した時に，商品を見\nたと判定することができる．この視線情報を利用して，ユーザーがどの商品を見たのか，，\n商品を何秒間見ていたのかなどのデータを取得することができる．2-5 より1 秒以上の視\n線の停止を注目としてＶＲ上でも判定できると分かっているため，これを使い電化製品に\n注目（１秒以上）が集めった時アニメーションが動きだすように設計した．Pupil Neon と\nスマートフォンを接続し，Pupil Labs 社のNeon Companion を使い，視線がどこを向いて\nいるのかの測定と接続を行い，python で動かした．\n3.3\n動的な3D モデルの作成方法\n本節では3D モデルの読み取り方法，アニメーションの作成方法について述べる．\n3.3.1\n3D モデルの読み取り方\n3D モデルには，Unity 上のAss",
            "方法について述べる．\n3.3.1\n3D モデルの読み取り方\n3D モデルには，Unity 上のAsset を使うのではなく，現実世界にある電化製品を使うこと\nでより現実世界をイメージできるようにした．現実世界の電化製品を3D モデルに変更す\nるためにToolbox AI社が出しているスマートフォン向けアプリケーションのScaniverse-3D\nScanner [22] を使用した．使用したスマートフォンはApple 社が出しているｉＰｈｏｎｅ\n14 を使用した[23]．図3-6 のように現実世界の家電を机の上などに置き，アプリケーショ\nンを起動して全方位を読み取ることで3D モデルを作成した．\n18\n図3-6: 3D モデルの読み取り方\n3.3.2\nアニメーションの作成方法\nアニメーションの作成に非営利団体であるBlender 財団が開発しているBlender を使用\nした[24]．Scaniverse で読み込んだ3D データーはobj ファイルを，一度blender に読み込\nませアニメーションを付けglb ファイルに変更し作成を行った．開閉や首振りを行うアニ\nメーションを作成す",
            "アニメーションを付けglb ファイルに変更し作成を行った．開閉や首振りを行うアニ\nメーションを作成するため，ボーンは作成せず単純な開閉動作のみを設定し動的な動きを\n付けた．\n図3-7: Blender での編集画面\n3.4\n通信手法及び仮想空間内における表現手法\n本節では仮想空間の表現方法とその使用に述べる．\n19\n3.4.1\nシステム開発に利用した開発プラットフォーム\n本開発にはUnity Technologies が提供するUnity [25] を用いた．Unity は無料で利用可能\nなゲームエンジンであり，作成したプロジェクトはAndroid やPC，HMD など様々な環境\nにビルド可能である．また，様々なユーザーが作成したアセットがアセットストアから利\n用可能となっており，短期間での開発が可能である．本システムはHMD 上で動作するた\nめ，HMD 上のあらゆるセンサ情報を扱えるようにする拡張パッケージ（OpenXR）を導\n入した．図3-8 にシステム開発の様子を示す．本システムは1 人でMeta Quest を装着し椅\n子または立った状態で仮想現実内の電化製品を見る．\n図3-8",
            "1 人でMeta Quest を装着し椅\n子または立った状態で仮想現実内の電化製品を見る．\n図3-8: システム開発の様子\n3.4.2\n視線情報計測\n視線情報の計測を実装するため，図3-9 のようにMeta Quest3 とPupil を接続し仮想空\n間上（Unity）で視線情報を読み取りPupil Neon に情報を送り，データ化された視線情報\nから注目時間によってアニメーションを再生した．コンソールからapi をPupil Neon に送\nり，視線情報をコンソールに返してMQTT ブローカーにパブリッシュし，VR に送る．\n20\n図3-9: 視線情報計測と共有の仕組みの概要図\n3.5\nまとめ\n本章ではシステム概要，仮想現実の表現方法，視線情報の取得方法について述べた．ユー\nザーがシステムを利用するには特別なコントローラー等は必要とせず，視線の入力のみで\n行うことが可能である．また，読み取ったデータをUnity 上で管理しアニメーションを制\n御しているため環境に依存せず簡単に利用可能である．\n21\n第4章\nモデルの動的な動きの有無による興味関心\nの評価実験\n4.1\n実験目的\n本研究の",
            "ある．\n21\n第4章\nモデルの動的な動きの有無による興味関心\nの評価実験\n4.1\n実験目的\n本研究の目的は．本システムを利用する際のシステムの有用性や．ユーザーがどのよう\nに感じるかを検証することである．具体的には．ユーザーの興味や嗜好．体験を通じた\n感じ方がどのように変化するかを分析し．それらの変化に基づいてシステムの有効性を評\n価する．また．以下の3 つのパターンに基づいて比較を行い．各パターンがユーザー体験\nに与える影響を検証する．静止，モデルが動かない場合常時動作，モデルが常に動いてい\nる場合注視動作，視線情報によってモデルが動く場合．これらの比較を通じて．視線情報\nを活用した動的なインタラクションがユーザーの興味喚起や体験の質に与える効果を明\nらかにし．システム設計における有用性の評価を行うことを目指す．\n4.2\n実験環境\n被験者10 人に図4-1 のMeta Quest3 にPupil Labs を取り付けたヘッドマウントディスプ\nレイを装着してもらう．\n図4-1: ヘッドマウントディスプレイ\n22\n4.3\n実験方法\n本研究では．3 つの異なるVR 環境を用いて．被験者に電",
            "ウントディスプレイ\n22\n4.3\n実験方法\n本研究では．3 つの異なるVR 環境を用いて．被験者に電化製品（炊飯器．電子レンジ．\n扇風機）を観察・比較してもらい．それぞれの場合でエンゲージメントに与える影響を評\n価した．以下に実験の手順を示す．各VR 環境は以下の3 つのパターンで構成される．\n• 静止: 3D モデルが動かない静止状態．\n• 常時動作: 3D モデルが常に動き続ける状態．\n• 注視動作: 被験者の視線情報に基づき．注目している3D モデルのみが動く状態．\nこの時各実験参加者には3 つのパターンのVR 環境を体験してもらうが．順序効果を排除\nするために．体験順序をランダムに設定した．被験者には事前に，3 パターンの環境で電\n化製品の観察・比較を行った後にアンケートに回答してもらうことを伝えた．また，それ\nぞれのパターンの具体的な違いには明示せず，観察を自然に行ってもらうように促した．\n各被験者には3 つのVR 環境を順番に体験してもらい．それぞれの環境で電化製品を観察\nした．観察時間は被験者に委ね．十分に観察したと感じた時点で次の環境に移行するよ\nうにした．\n23\n4.",
            "た．観察時間は被験者に委ね．十分に観察したと感じた時点で次の環境に移行するよ\nうにした．\n23\n4.4\n評価方法\n4.4.1\nエンゲージメント評価\n本実験では，各VR 環境でのユーザーの利用時間をエンゲージメントの定量的な指標と\nして定義した．具体的には．各環境の体験開始から終了までの時間（秒）を計測し．その\n値を比較することでエンゲージメントの違いを評価した．被験者が各VR 環境で観察を開\n始した時点でタイマーを開始し．観察を終了した時点でタイマーを停止することで．利用\n時間を記録した．各環境での利用時間は被験者が自由に決定できるようにし．無理のな\nい形で自然な観察行動が得られるよう配慮した．記録した利用時間を環境ごとに集計し．\n平均利用時間や標準偏差を算出した．また．各パターンにおけるエンゲージメントの違\nいを統計的手法を用いて比較した．定量的な評価に加えて．被験者にはアンケートを通\nじて主観的な感想や各環境に対する満足度を回答してもらった．これにより．定量的評\n価と主観的な意見の相関を分析し．視線連動型インタラクション（注視動作）の有効性を\n検証した．\n4.4.2\nアンケート評価",
            "関を分析し．視線連動型インタラクション（注視動作）の有効性を\n検証した．\n4.4.2\nアンケート評価\n本研究では．3 つの異なるVR 環境に対する被験者の主観的な評価を収集するため．ア\nンケートを実施した．アンケート評価の目的は．VR 環境の違いが被験者の興味や使用イ\nメージ形成．さらには購買意欲に与える影響を明らかにすることである．特に視線情報\nによって動く環境（注視動作）が．他の環境（動かない場合．動き続ける場合）と比較し\nて．より高い興味や購買意欲を引き出すかどうかを検証した．アンケートは以下の設問\nで構成されており．それぞれの質問に対する回答を数値化し．定量的に分析した．\n• 設問1: 興味がわいたか．\n• 設問2: 扇風機が暑さを軽減してくれると感じたか．\n• 設問3: 炊飯器でご飯を炊くイメージができたか．\n• 設問4: 電子レンジでものを温めるイメージができたか\n設問1 は，各VR 環境がどの程度ユーザーの興味を引いたかを評価する設問．被験者に\nは．VR 環境の動きや視覚的な特徴が興味を引くかどうかを直感的に回答してもらった．\n設問2～4 では，モデルの視覚的な表現が．利",
            "な特徴が興味を引くかどうかを直感的に回答してもらった．\n設問2～4 では，モデルの視覚的な表現が．利用場面の具体性にどのように影響を与える\nかを検証した．評価方法として設問1～4 は各設問に対して．被験者には1～10 の範囲で\n数値評価を行ってもらった．1: 全くそう思わない10: 非常にそう思うこの評価方法によ\n24\nり．各設問に対する回答を数値化し．VR 環境ごとの違いを明確に把握することが可能と\nなった．\n4.4.3\nシステムの使いやすさの評価指標\nシステムの使いやすさの評価としてSystem Usability Scale（SUS）を用いた[26]．SUS\nは10 の質問に対し5 段階で評価を行う質問票であり，ユーザビリティと学習能力を測定\nし指標化する．すべての質問の5 段階評価の結果は0 から100 の範囲でスコアリングさ\nれる，SUS におけるスコアの基準を表4-1 に示す．平均点は68 点となっており，平均点\n以上が良いシステムと言われる．SUS のアンケート回答者は各項目を5 段階で評価する．\n集計方法は奇数の質問の回答スコアから1 を引き，偶数の質問スコアを5 から",
            "目を5 段階で評価する．\n集計方法は奇数の質問の回答スコアから1 を引き，偶数の質問スコアを5 から引く．その\n後，すべてのスコアを合算し2．5 倍したものがSUS スコアとなる．付録に実際に使用し\nたSUS に関するアンケートフォームを掲載した．\n表4-1: SUS におけるスコアと評価の対応\nSUS score\nGrade\nAdjective Rating\n>80.3\nA\nExcellent\n68 - 80.3\nB\nGood\n68\nC\nOkay\n51 - 68\nD\nPoor\n<51\nE\nAwful\n25\n第5章\n実験結果と考察\n5.1\nエンゲージメント評価考察\n本節ではエンゲージメントの評価結果および考察を述べる．表5-1 に3 パターンそれぞ\nれの平均利用時間と標準偏差を示す．\n表5-1: 各パターンの平均利用時間と標準偏差\nパターン\n平均利用時間(秒）\n標準偏差（秒）有意差\n静止:3D モデルが動かない状態\n20.684\n9.213\nあり\n常時動作:3D モデルが常に動き続ける状態\n32.518\n15.684\nあり\n注視動作: 視線情報に基づき動作する状態\n45.018\n12.",
            "態\n32.518\n15.684\nあり\n注視動作: 視線情報に基づき動作する状態\n45.018\n12.872\n—\n図5-1: 平均利用時間の有意差\n*:p<0.05，**:p<0.01\n他の項目については有意差なし\n図5-2 から，視線情報に基づき動作する注視動作が最も長い平均利用時間（45．018 秒）\nを示し，エンゲージメントが他の2 つのパターンと比較して有意に高いことが分かった．\n静止状態と注視動作がもっとも有意な差を示し，注視動作の有意性を示しました．さら\n26\nに，標準偏差の値から，各パターンにおける観察時間のばらつきを評価しました．静止お\nよび注視動作は，比較的安定したばらつきを示した一方で，常時動作は標準偏差が最も大\nきく（15．684 秒），被験者による観察時間の個人差が大きいことが示唆されました．\nこれらの結果は，視線情報を活用する動的なインタラクションがユーザの興味を持続さ\nせ，観察行動を促進する効果があることを示しています．視線情報によって動作する注視\n動作では，被験者が長時間観察を続ける傾向が見られ，インタラクションのパーソナライ\nズ効果が興味を向上させる可能性",
            "験者が長時間観察を続ける傾向が見られ，インタラクションのパーソナライ\nズ効果が興味を向上させる可能性が示唆されます．\n一方，常に動き続ける常時動作では観察時間が静止より長いものの，標準偏差が大きく，\n被験者間での評価が分かれる結果となりました．これは，動き続ける状態が一部の被験者\nにとって過剰な刺激や情報過多として認識された可能性を示しています．\n常に止まっている静止状態は，他のパターンに比べてエンゲージメントが低く，ユーザ\nが積極的に関与する機会が限られていると考えられます．このことは，動的インタラク\nションがユーザの興味喚起に与える重要な役割を強調しています．\n5.2\nアンケート評価および考察\n本節ではアンケート評価の結果とその考察を述べる．本研究では，3 つの異なるVR 環\n境（「静止」，「常時動作」，「注視動作」）における被験者の主観的評価をアンケートを通じ\nて収集し，興味関心，使用イメージ形成について定量的に分析した．アンケート結果の数\n値化に基づく分析の結果，注視動作が他の2 つの環境と比較して，被験者の興味，イメー\nジ形成において最も高いスコアを示した．この章では，各設問",
            " つの環境と比較して，被験者の興味，イメー\nジ形成において最も高いスコアを示した．この章では，各設問の詳細な結果を示し，T 検\n定による有意差の検証とともに，その考察を展開する．\n設問1．興味がわいたかでは，VR 環境がどの程度ユーザの興味を引いたかを評価した．\n以下の表5-2 に示す通り，注視動作は平均スコア6．7 で，他のパターンと比較して最も\n高い評価を得た．\n表5-2: 設問1 における興味関心のスコア比較\nパターン\n平均値\np 値\n有意差\n静止\n1.9\np ＜0.01\nあり\n常時動作\n5.0\np ＜0.05\nあり\n注視動作\n6.7\n—\n—\n—\n27\n図5-2: 興味関心の有意差\n*:p<0.05，**:p<0.01\n他の項目については有意差なし\nT 検定の結果，注視動作は静止と比較して非常に高い有意な差を示した（p ＜0.01）．ま\nた，常時動作と比較したときも（ｐ＜0.05）有意な差があることが明らかとなった．興味\n関心の差として段階的に静止＜常時動作＜注視動作の順でスコアが上がり主観的なアン\nケート評価でも注視動作が有意であることが分かった．\n設問2 4 ではそれぞれ扇風",
            "上がり主観的なアン\nケート評価でも注視動作が有意であることが分かった．\n設問2 4 ではそれぞれ扇風機，炊飯器，電子レンジの使用イメージ形成を測定した．ま\nず扇風機について表5-3 に示す．T 検定の結果として図5-3 のように，注視動作は静止と\n比較して有意な差が検出されたが，常時動作とは有意差はないと検出された．\n表5-3: 扇風機が暑さを軽減してくれると感じたか\nパターン\n平均値\np 値\n有意差\n静止\n1.8\np ＜0.01\nあり\n常時動作\n5.4\np ＞0.05\nなし\n注視動作\n6.7\n—\n—\n—\n28\n図5-3: 扇風機の使用イメージの比較\n*:p<0.05，**:p<0.01\n他の項目については有意差なし\n次に炊飯器について表5-4 に示す．\n図5-4: 炊飯器の使用イメージの比較\n*:p<0.05，**:p<0.01\n他の項目については有意差なし\nT 検定の結果として図5-4 のように，扇風機と同じように注視動作は静止と比較して有\n意な差が検出されたが，常時動作とは有意差はないと検出された．最後に電子レンジに\n29\n表5-4: 炊飯器がご飯を炊くイメージができたかどうか\n",
            "ないと検出された．最後に電子レンジに\n29\n表5-4: 炊飯器がご飯を炊くイメージができたかどうか\nパターン\n平均値\np 値\n有意差\n静止\n1.3\np ＜0.01\nあり\n常時動作\n5.5\np ＞0.05\nなし\n注視動作\n6.2\n—\n—\n—\nついて表5-5 に示す．\n図5-5: 電子レンジの使用イメージの比較\n*:p<0.05，**:p<0.01\n他の項目については有意差なし\nT 検定の結果として図5-5 のように，注視動作は静止と比較して有意な差が検出された\nが，常時動作とは有意差はないと検出された．この３つの表から静止では動きがないた\n表5-5: 電子レンジでものを温めるイメージができたか\nパターン\n平均値\np 値\n有意差\n静止\n1.2\np ＜0.01\nあり\n常時動作\n5.0\np ＞0.05\nなし\n注視動作\n5.7\n—\n—\n—\nめ，視覚的な刺激が不足し，製品の利用イメージが付かず想像しにくいが，常時動作と3\nでは同じように動きをみることができるため，視覚的な刺激の差がないため，有意な差が\nなかったと考えられる．\n30\n5.3\nシステムの使いやすさの評価結果および考察\n本節ではシステム",
            "が\nなかったと考えられる．\n30\n5.3\nシステムの使いやすさの評価結果および考察\n本節ではシステムの使いやすさの評価結果およびその考察を述べる．評価指標について\nは4．4．3 節で述べた．SUS 法に基づいて，10 名の被験者にアンケートに回答してもら\nい，システムの使いやすさを算出した．表5-6 におけるSUS スコアの平均値を示す．結\n果として，SUS スコアの平均値は75．75 点であり，SUS スコアの基準値である68 点を\n上回った．このことから，本システムは被験者にとって「使いやすいシステム」であると\n評価できる．\n表5-6: 本システムのSUS スコア\n指標\nSUS score\nSUS スコア\n75.75\nSUS スコア全体としては基準を上回る評価を得たが，個別の設問において低い評価が見\nられた項目も存在する．特に「このシステムを使用するには技術サポートが必要です」や\n「このシステムは不必要に複雑であると思います」という設問において，一部の被験者が\n否定的な回答をしており，これが評価のばらつきに影響を与えた考えられる．低評価の原\n因としては，システムの機能や操作が複雑に",
            "，これが評価のばらつきに影響を与えた考えられる．低評価の原\n因としては，システムの機能や操作が複雑に感じられたことが原因と考えられる．特に，\n視線情報を用いたインタラクションに慣れていないユーザにとっては，意図通りの操作が\n困難であった可能性がある．これらの課題を解決することで，システムの使いやすさをさ\nらに向上させることができるが，解決策として，より直感的なインタフェースの導入し即\n時にフィードバックを提供し，精度を向上させることでシステムのユーザビリティをさら\nに向上できると考えられる．\n5.4\nまとめ\n本章ではシステムを用いた評価実験結果とその考察について述べた．それぞれのパター\nンでエンゲージメントの評価とアンケート評価を行い比較を行った．常時動作，注視動作\nのような動的インタラクションがユーザの興味や使用イメージの形成において極めて効\n果的であることを示した．定量的なエンゲージメント評価では視線情報に基づいて動作す\nる注視動作がもっとも有意性がありユーザの関心を長引かせ引き出す効果があると示さ\nれた．視線情報を用いることで，ユーザ体験を個別化し，長時間のエンゲージメントを維\n",
            "効果があると示さ\nれた．視線情報を用いることで，ユーザ体験を個別化し，長時間のエンゲージメントを維\n持できる可能性が示唆された．\n31\n第6章\n結論と今後の展望\n6.1\n結論\n本研究ではネットショッピングで購入する前に実物を見れるようにするために、仮想現\n実上で3D モデルを表示し動的な動きがあることで興味関心が変わるかを提案した．視線\n情報を活用して，注目しているモデルのみが動くシステムを作成し，動き続ける場合，動\nかない場合の3 パターンでエンゲージメント評価とアンケート評価を行った．エンゲージ\nメント評価では注視動作での平均利用時間が静止状態の2 倍近く長く，利用者の興味を最\nも引いていたと考えられる．アンケート評価では3D モデルが静止状態と注視動作が非常\nに有意な差を示し，常時動作とも有意な差を示した．本システムの使用により，現実世界\nで家電量販店に行く前に仮想現実上で動きのある3D モデルを先に見ることで興味を掻き\n立てて，使用するのイメージを想像させることができ，興味を持たせることができると明\nらかになった．\n6.2\n今後の展望\nシステムの改善点として，商品が一方向しか見",
            "せることができると明\nらかになった．\n6.2\n今後の展望\nシステムの改善点として，商品が一方向しか見れず360 度見ることができないこと，音\nなどの視覚以外のフィードバックがないため没入感にかけてしまっていること，商品との\n距離があり近くに寄せられなかったことが挙げられる．システムを考えたとき，家電量販\n店で商品を持ち上げることはないと考えてしまい，単方向からのアニメーションのみ作成\nしてしまったが，仮想現実という環境を最大限に利用できていなかったと感じる．また，\n扇風機の音や電子レンジの音などの聴覚的フィードバックも実装することで，より没入感\nを与えて興味をより掻き立てることができたのではと考えられる．以上にあげられる課題\nを解決し実装することで，より没入感があり興味関心に影響を与えられるシステムが完成\nできると考えているため，本システムを発展させていきたい．\n32\n謝辞\n本研究の機会を与えて下さり，研究面について大変ご丁寧なご指導を賜りました，青山\n学院大学理工学部情報テクノロジー学科Guillaume LOPEZ 教授に深く感謝申し上げます．\nそして，研究会などを通して助言をいた",
            "科Guillaume LOPEZ 教授に深く感謝申し上げます．\nそして，研究会などを通して助言をいただいたLOPEZ 研究室の皆様並びに実験に協力し\nていただいた皆様に深く感謝いたします．\n2025 年1 月23 日\n松田　滉生\n33\n参考文献\n[1] 統計局：2022\n年　家計消費状況調査　結果の概況.\n://www.stat.go.jp/data/joukyou/2022ar/gaikyou/pdf/gk01.pdf.\n[2] NRI メディアフォーラム：第322 回NRI メディアフォーラム(2021).\nhttps:\n//www.nri.com/-/media/Corporate/jp/Files/PDF/knowledge/\nreport/cc/mediaforum/2021/forum322.pdf?la=ja-JP&hash=\n396365B469B39B585BCE5A74CD340308B02D63F2%EF%BC%89.\n[3] 総務省：平成27 年　インターネットショッピングの利用状況\n(2015).\nhttps://www.soumu.go.jp/johotsu",
            "ョッピングの利用状況\n(2015).\nhttps://www.soumu.go.jp/johotsusintokei/whitepaper/ja/h27/\nhtml/nc122400.html.\n[4] 石橋健関西大学データサイエンス研究センター：調査実験における視線追跡機能付\nきVR の利用可能性に関する研究(2018). https://www.jstage.jst.go.jp/\narticle/jasmin/2018t06/0/2018t06_99/_pdf/-char/ja.\n[5] 里村卓也：視線計測による消費者行動の理解. /https://orsj.org/wp-content/corsj/or62-\n12/or6212775.pdf?utmsource = chatgpt.com.\n[6] 張テイテイ：ネットショップにおける暗示的動きを表す静止画が消費者行動に与える影\n響，経営論集(2023).\n[7] 落合拓朗藤田智益子宗星野准一：視線情報に基づいた嗜好分析から商品推薦を行うVR\nショッピングシステム，IPSJ SIG Technical Report, Vol. 2",
            "を行うVR\nショッピングシステム，IPSJ SIG Technical Report, Vol. 2019-HCI-184, No. 3 (2019).\n[8] 真吾柿沼育盛川浩志小宮山：VR 空間内におけるアバタとの視線コミュニケーション，研\n究報告エンタテインメントコンピューティング（EC），Vol. 1 (2018).\n[9] 坂本賢哉白井詩沙香武村紀子Orlosky Jason 長瀧寛之上田真由美浦西友樹竹村治雄：視\n線情報に基づくVR 空間でのマンガ教材読書時の主観的難易度推定，研究報告エンタテイ\nンメントコンピューティング（EC），Vol. 3 (2021).\n[10] 岩川亘宮脇健三郎：視線の重なりと表情変化が及ぼすVR コミュニケーション円滑さへ\nの効果，（第20 回情報科学技術フォーラム，Vol. 3 (2021).\n34\n[11] 広典侯：VR 環境における視線追跡技術を用いた運転視線評価システムの設計，第86 回\n全国大会講演論文集，Vol. 1 (2024).\n[12] 本田司（（株）ジオクリエイツ）三坂昇司（公益財団法人流通経済研究所）佐藤直行（公\n立はこだて",
            "12] 本田司（（株）ジオクリエイツ）三坂昇司（公益財団法人流通経済研究所）佐藤直行（公\n立はこだて未来大学）古田久美子，東瑞穂，山本智子，本多倫子（マルハニチロ（株）中\n央研究所）：アイトラッキングによる買物客の購買行動分析―ＶＲの売場の実験ツール\nと分析手法の開発―，Supplement, Vol. 59 (2023).\n[13] 中島仁大竹恒平：百貨店におけるアイトラッキングデバイスを用いた購買行動の評価，第\n86 回全国大会講演論文集　437 - 438，Vol. 1 (2024).\n[14] : Tobii pro，Tobii 社，https://www.tobii.com/ja. (参照日2025/1/23).\n[15] Wiki:\n交差検証LOOCV，https://ja.wikipedia.org/wiki/%E4%BA%A4%E5%\nB7%AE%E6%A4%9C%E8%A8%BC. (参照日2025/1/23).\n[16] 林真滉森拓也原田史子島川博光：若者のイベント参加を促す潜在興味の顕在化のための\nVR による仕掛け，FIT2020（第19 回情報科学技術フォーラ",
            "加を促す潜在興味の顕在化のための\nVR による仕掛け，FIT2020（第19 回情報科学技術フォーラム）301 - 302，Vol. 3 (2020).\n[17] 千田和範成田陸斗：視線追跡型VRHMD を用いた工学実験用訓練システムの開発，教育\nシステム情報学会第43 回全国大会，Vol. 3 (2018).\n[18] 土居巧果，河合隆史，中村直靖，黒田敏康，内山悠一：シネマチックVR における文化財\nの表現手法が興味・関心に及ぼす影響，第23 回日本バーチャルリアリティ学会大会論文\n集，Vol. 1 (2018).\n[19] 武田凌（東京工科大学）楊尚諺（東京工科大学）盛川浩志（東京工科大学）：VR 空間\nでの店員アバターによる商品説明が購買意欲に与える影響，日本人間工学会第64 回大会，\nVol. 5 (2023).\n[20] :\nPupil Neon．PupilLabs 社\n，\nhttps://pupil-labs.com/. (Accessed on 1/8/2025).\n[21] :\nMeta Quest3．Meta 社\n，\nhttps://www.meta.com/jp/",
            "1] :\nMeta Quest3．Meta 社\n，\nhttps://www.meta.com/jp/quest/quest-3/. (Accessed on 1/8/2024).\n[22] :\nScaniverse-3D Scanner．Toolbox AI 社\n，\nhttps://scaniverse.com/. (Accessed on 1/8/2024).\n[23] :\niPhone14．Apple 社\n，\nhttps://www.apple.com/jp/iphone-14/specs/.\n35\n[24] :\nBlender 財団\n，\nhttps://www.blender.jp/.\n[25] :\nUnity．Unity Technologies．，\nhttps://unity.com/ja. (Accessed on 1/8/2024).\n[26] measuringU:\n10 Things to Know About the System Usability Scale (SUS),\nhttps://measuringu.com/10-things-sus/ (2013).",
            "US),\nhttps://measuringu.com/10-things-sus/ (2013). (Accessed on 1/11/2024).\n36\n質疑応答\n伊藤雄一　情報テクノロジー学科　教授\nQ\n平均利用時間はどういうふうに定義していますか？\nA\n平均利用時間はシステムを利用し始めた時間から被験者が終了でというまでを平均\n利用時間にしました．\n伊藤雄一　情報テクノロジー学科　教授\nQ\n動きに引っ張られて、いつ止まるかが気になるため、長くみるのでは？\nA\n注視時間を1 秒以上と定義し，アニメーションは2 秒から4 秒ほどで終わるので差\n違はほとんどないと考えています．\n伊藤雄一　情報テクノロジー学科　教授\nQ\n視線情報を活用した評価指標も検討すると良いと思います\nA\n今回，視線情報を活用した評価指標を使っていませんでした．今後の研究で反映し\nます．\n37\n戸辺　義人　情報テクノロジー学科　教授\nQ\n目的が大きすぎるのでは？\nA\n具体的すぎる目的をおいていました．今後の研究では抽象度を増して結論で達成で\nきたかどうかが分かるように反映します．\n上堀　情報テクノロジー学科　助手",
            "抽象度を増して結論で達成で\nきたかどうかが分かるように反映します．\n上堀　情報テクノロジー学科　助手\nQ\n３つの群を比較しているようですが、t 検定のp 値補正していますか？\nA\nT 検定で比較を行っているのが，注視動作とその他2 つのため行っていません．\n38\n"
        ]
    },
    {
        "id": "paper_5",
        "filename": "B2024_MiyoshiNakajima.pdf",
        "title": "B2024_MiyoshiNakajima",
        "fulltext": "青山学院大学理工学部\n情報テクノロジー学科\n２０２４年度卒業研究論文\n心拍変動を用いた学生の勉強に対\nする集中力向上手法の比較\n２０２５年１月２８日提出\n指導教員ロペズ・ギヨーム　教授\n提出者学生番号　氏名\n１５８２１０６６中島弥芳\n青山学院大学 理工学部 情報テクノロジー学科 \n2024（令和6）年度卒業論文要旨 \n- 1 - \n \n心拍変動を用いた学生の勉強に対する集中力向上手法の\n比較 \n \n中島 弥芳（15821066） \nロペズ研究室 \n \n1．はじめに \nコロナウイルス蔓延を境にオンライン授業を導入す\nる大学は増加した．それにより，学生の学習環境は多\n様化しており，学習の効率を高めるためには，集中力\nを向上させる方法の検討が重要となっている．実際に，\n全国大学生活協同組合連合会の調査では学習について\nの悩みを抱える大学生は約半数を占める結果になった． \nそこで，本研究では学生のデスクワークに焦点を当\nて，心拍変動指標を用いて，仮眠(Nap)，音楽(Music)，\nストレッチ(Stretch)の3 種類の休憩方法がデスクワー\nクにおける集中力回復に与える影響を比較することを\n目的とした． \n2．関連研究 \n過去の研究では，ウェアラブルデバイスを活用した\n心拍変動解析によるストレス評価や集中力向上に関す\nる手法が多く提案されている．例えば，浦野らは，心\n拍数に同期した光変化による心理状態の可視化が提案\nされた[3]．さらに，三木ら[4]は，心拍データや瞬きの\n回数といった生体情報を用いて休憩時間の過ごし方の\n違いが作業パフォーマンスに与える影響を定量的に評\n価した．彼らは，「寝る」「スマートフォンを見る」「運\n動をする」など複数の休憩方法が集中力や作業パフォ\nーマンスに与える効果を調査し，心拍変動を活用した\n新たな評価方法を提案している． \n3．休憩方法の回復効果検証実験 \n本研究はこれらの知見を基に，学生のデスクワーク\nにおける集中力回復に最適な休憩方法を特定すること\nを目指し，三木らが示した実験の改善点を参考にして\n休憩方法を選定した．10 名の大学生(男9 人，女1 人)\nを対象に，静かな実験室において，以下の手順でデー\nタを収集した． \n1. \n安静状態で心拍変動を3 分間測定する． \n2. \n20 分間の自由デスクワークをして，心拍変動\nの記録を行う． \n3. \n仮眠(10 分)，音楽(3 分)，ストレッチ(3 分)の\nいずれかの休憩を行う． \n4. \n各休憩方法の後に再び20 分間のデスクワー\nクをして，心拍変動を記録． \n休憩方法の順番による影響を排除するため，1 日1 種\n類の休憩方法をランダムに選び，3 日間にわたって実\n験を実施した．効果の比較には先行研究と同様に心拍\n変動指標のLF/HF を用いた．LF は低周波成分，HF\nは高周波成分を示し，LF/HF 値が高い場合はストレス\nや緊張状態，低い場合はリラックス状態を示す．本実\n験では，先行研究[4]を参考にしてLF/HF 値が2．0 以\n上を「集中している状態」\n「ストレス状態」と定義した． \n4．休憩方法の回復効果の評価結果 \n4-1． 心拍変動指標の評価 \n本研究では，3 種類の休憩方法(Music，Nap，Stretch)\nがLF/HF の変化量に与える影響を評価するため，休\n憩前後のLF/HF の平均値を比較した．t 検定および一\n元配置分散分析(ANOVA)を実施した結果，休憩方法間\nにおけるLF/HF 比の変化量には統計的に有意な差は\n確認されなかった．表1 に分散分析の結果，表2 にt\n検定の結果をまとめた． \n表1：分散分析の結果 \n    \n \n \n \n表2：t 検定の結果 \n \nさらに，Tukey HSD 検定による多重比較を行った\nが，すべての休憩方法の組み合わせにおいて統計的な\n有意差は見られなかった(Music vs Nap のq 値 = \n0.047， Nap vs Stretch のq 値 = 0.779， Music vs \nStretch のq 値 = 0.732)．しかし，休憩方法ごとの\nLF/HF の平均変化量は，Music が0.89（標準偏差 = \n0.45），Nap が0.88(標準偏差 = 0.47)，Stretch が\n1.02(標準偏差 = 0.30)であり，平均的な傾向として\nStretch がやや高い結果を示した．また，標準偏差に着\n目しても\nNap(0.47) ，Music(0.45) に比べて\nStretch(0.30)が最も小さく，結果のばらつきが少ない．\n表1 は多重比較検定の結果，表2 は休憩方法ごとの統\n計量をそれぞれ示す． \n表3：多重比較検定の結果(TukeyHSD) \n   \n \n \n図1：休憩方法ごとの統計量 \n4-2． アンケートによる主観的評価 \n本実験後，休憩方法の集中力向上効果や設定時間の適\n切性，リラックス効果に関するアンケートを実施した．\nその結果，「仮眠をとる」が最も効果的と評価され，全\n回答者が肯定的だった．「ストレッチをする」や「音楽\nを聴く」も高評価を得ており，特に「ストレッチをす\nる」はリラックス効果で90％が肯定的だった．一方で，\n「音楽を聴く」と「仮眠をとる」の設定時間が短いと\nの意見や，仮眠時の体勢や環境条件が集中の妨げにな\nるとの指摘があった． \n5．まとめ \n本研究では，Nap，Music，Stretch の3 つの休憩方\n法の効果を比較したが，解析結果では有意差が見られ\nなかったものの，LF/HF の平均変化量はStretch が一\n番高いことからことから，Music，Nap よりも集中力\n回復に効果的であると言える．また，標準偏差で\nStretch の数値が最小だったことから，Stretch が他の\n休憩方法よりも効果の安定性が高く個人間の影響を受\nけにくいと考えられる．有意差が見られなかったのは\n以下の要因が関係していると考えられる． \n1. \n被験者数が10 人と少なく，統計的検出力が不\n足していたこと． \n2. \nLF/HF 比が個人ごとに異なる基準値や変化量\nを持つため，個人差が効果を埋もれさせた可能\n性があること． \n3. \nLF/HF 比の感受性が高い一方で，短時間の休\n憩では十分な変化を検出しにくかったことが\n挙げられる． \nさらに，音楽や仮眠の設定時間が適切でなかったと\nの評価や，休憩中の環境要因(仮眠の体勢や室内の明る\nさなど)が休憩効果を低下させた可能性も指摘された．\n本研究の結果を踏まえ，今後は，サンプルサイズの拡\n大，休憩時間や環境要因の改善，さらには主観的評価\nに加えて他の生理指標を併用した多角的な効果検証が\n必要であると考える． \n参考文献 \n[1] \nDigital Knowledge 株式会社：オンデマンド学習に\n関するレポート． https://www.digital-knowledge．\nco．jp/wp-content/uploads/2023/11/report_ondemand．\npdf （参照日 2025/01/28） \n[2] \n全国大学生活協同組合連合会：第59 回学生．生\n活\n実\n態\n調\n査\n報\n告\nhttps://www.univcoop.or.jp/press/life/report.html \n（参照日 2025/01/28） \n[3] \n浦野健太，廣井慧，米澤拓郎，河口信夫ほか： ド\nキドキをセンシングして可視化する LED ライ\nティングデバイス，マルチメディア， 分散協調\nとモバイルシンポジウム2248 論文集， Vol. 2020， \npp.1616–1622 (2020)． \n[4] \n三木隆裕，寺田努，前田俊幸，唐澤鵬翔，安達淳，\n塚本昌彦ほか： 休憩時間の過ごし方が作業パフ\nォーマンスに及ぼす影響の調査，研究報告ユビキ\nタスコンピューティングシステム (UBI)， Vol. \n2018， No.3， pp.1–8 (2018). \n目次\n第1 章\n序章\n1\n1.1\n研究背景. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n1\n1.1.1\nコロナウイルスが授業形態に与えた影響. . . . . . . . . . . . . . .\n1\n1.1.2\nリモートワークによる集中力の低下\n. . . . . . . . . . . . . . . . .\n1\n1.1.3\n集中力向上に対する休憩の必要性. . . . . . . . . . . . . . . . . . .\n1\n1.2\n研究目的. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n2\n1.3\n本論文の構成. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n3\n第2 章\n関連研究\n4\n2.1\nウェアラブルデバイスを活用した生体データの解析と応用に関する研究. .\n4\n2.2\nストレス・集中力評価と向上に関する研究. . . . . . . . . . . . . . . . . .\n6\n2.3\nロケーションや環境対応型の情報提示システム\n. . . . . . . . . . . . . . .\n11\n2.4\n健康促進および休憩の効果. . . . . . . . . . . . . . . . . . . . . . . . . . .\n12\n2.5\n先行研究のまとめ. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n13\n第3 章\n本研究で用いる技術や用語について\n14\n3.1\n心拍間隔と心拍変動\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n14\n3.2\n自律神経系\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n14\n3.2.1\n交感神経\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n15\n3.2.2\n副交感神経. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n15\n3.3\n心拍変動解析. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n16\n3.3.1\n時間領域解析. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n16\n3.3.2\n周波数領域解析. . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n17\n3.4\n集中力の定義. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n18\n第4 章\n集中力回復のための休憩方法比較検証\n19\n4.1\n実験目的. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n19\n4.1.1\n実験概要\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n19\n4.2\n実験概要及び手順. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n19\n4.3\n集中力回復の評価に用いる指標. . . . . . . . . . . . . . . . . . . . . . . .\n21\ni\n4.3.1\n定量効果について\n. . . . . . . . . . . . . . . . . . . . . . . . . . .\n21\n4.3.2\n定性的評価について\n. . . . . . . . . . . . . . . . . . . . . . . . . .\n23\n第5 章\n比較検証実験の結果及び考察\n26\n5.1\n心拍変動指標のt 検定による評価\n. . . . . . . . . . . . . . . . . . . . . . .\n26\n5.2\n心拍変動指標の一元配置分散分析・多重比較による評価\n. . . . . . . . . .\n27\n5.3\nアンケートによる主観的評価\n. . . . . . . . . . . . . . . . . . . . . . . . .\n28\n5.3.1\n各休憩方法の効果についての評価. . . . . . . . . . . . . . . . . . .\n28\n5.3.2\n各休憩方法の設定時間についての評価\n. . . . . . . . . . . . . . . .\n29\n5.3.3\n各休憩方法のリラックス効果\n. . . . . . . . . . . . . . . . . . . . .\n29\n5.3.4\n集中を妨げる要因\n. . . . . . . . . . . . . . . . . . . . . . . . . . .\n29\n5.4\n考察. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n30\n5.5\n実験の改善点. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n31\n第6 章\n結論\n33\n6.1\nまとめ. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n33\n6.1.1\n集中度についての定量的評価\n. . . . . . . . . . . . . . . . . . . . .\n33\n6.1.2\n集中度についての定性的評価\n. . . . . . . . . . . . . . . . . . . . .\n33\n6.2\n今後の展望\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n33\n謝辞\n35\n参考文献\n38\nii\n第1章\n序章\n本章では，社会的な背景をもとに研究の位置付けを明確にする．1.1 節では，研究背景\nとしてコンテンツ視聴における現状と課題について述べる．1.2 節では，背景に挙げた課\n題を踏まえた本研究の目的を定義する．1.3 節では，本論文の構成について述べる．\n1.1\n研究背景\n1.1.1\nコロナウイルスが授業形態に与えた影響\n日本における大学(国公立大学，私立大学) では，2020 年の新型コロナウイルス感染症\nの拡大後，急速にオンデマンド授業の導入が進んだ．Digital Knowledge 株式会社の調査\nによると，2023 年11 月時点で，オンデマンド授業を日常的に取り入れている大学が過半\n数を占めている[1]．\n図1-1: （[1] より引用)\n1.1.2\nリモートワークによる集中力の低下\n全国大学生活協同組合連合会が9，873 人の大学生に2023 年11 月に実施した調査によ\nれば，約半数の大学生が学習に関する悩みを抱えていることが明らかになっている．同\n調査では，学生の生活全般について幅広く調査が行われており，授業や課題に対するモチ\nベーションの低下や，学習時間の確保の難しさ，オンライン授業の増加による集中力の低\n下が主な課題として挙げられている[2]．\n図1-2: 大学生に対する「日常生活の中で悩んでいることや気にかかっていること」の質問に対す\nる回答結果【％】（[2] より引用)\n1.1.3\n集中力向上に対する休憩の必要性\n現代の労働環境において，長時間の集中作業は生産性を低下させるだけでなく，精神的\nおよび肉体的疲労を招く原因となる．Diamond Harvard Business Review の記事によれば，\n1\n適切なタイミングでの休憩は，集中力の持続や業務効率の向上に不可欠であるとされてい\nる．以下に，そのポイントをまとめる[3]．\n• 集中力の持続には限界がある\n集中力には自然な限界があり，特に連続的な作業では注意力が低下する「集中力の\n波」が発生する．この波を意識し，適切なタイミングで休憩を取ることが，集中力を\n持続させるカギであると指摘されている．例えば，25 分作業し5 分休憩を取る「ポ\nモドーロ・テクニック」は，短期的な集中力を最大化する方法として広く実践され\nている．\n• 休憩が脳に与えるポジティブな影響\n休憩には，脳をリフレッシュさせる効果がある．短時間でも意識的に作業から離れ\nることで，脳が過剰なストレスから解放され，次の作業に向けたリカバリーが可能\nになる．また，特定の休憩方法（仮眠，軽い運動，リラクゼーションを目的とした\n音楽など）が脳の神経活動を活性化し，注意力や判断力の向上に寄与することが報\n告されている．\n• 適切な休憩が生産性を高める\n長時間働き続けることが必ずしも高い生産性をもたらさない点が強調されている．\nむしろ，定期的な休憩を挟むことで，集中力がリセットされ，より高い効率で作業\nを再開できる．休憩を取らずに作業を続ける場合，最終的にはエラーやミスの増加，\n創造性の低下が発生しやすくなる．\n• 休憩の方法とタイミングの重要性\n記事では，どのような休憩が有効かについても議論されている．特に，短時間の仮眠\nやストレッチ，音楽を聴くことなどは，集中力の回復に効果的であるとされる．ま\nた，休憩のタイミングを個々人の集中力のリズムに合わせて調整することが推奨さ\nれている．\n1.2\n研究目的\n1.1 節で述べたように，コロナウイルスの影響でリモートワークが増加することで多く\nの社会人が仕事に集中できていないという悩みを抱えている．このことから，コロナウイ\nルス以後デスクワークで集中力を保つことが難しいと感じている人が増加していると予\n想される．この問題を解決するためには，デスクワークに効果的な休憩方法を特定し，社\n会人に限らずデスクワークをするすべての人に集中力の回復を図る．そこで本研究では，\nテレワーク環境下での集中力低下に対し，複数の休憩方法の効果を比較・検証を行う．\n2\nまた，本研究では，効果的な休憩方法を選定するため，既存の知見および先行研究( [4])\nの結果を考慮した．具体的には，「音楽を聴く」，「仮眠をとる(10 分)」，「ストレッチをす\nる」の3 つを休憩方法として採用した．先行研究において「飲食をする」休憩方法は顕著\nな効果が確認されなかったため本研究では除外した．また，ManpowerGroup 株式会社に\nよるウェブサイトを基に[5]「音楽を聴く」という先行研究で扱われていない休憩手法を\n新たに追加し，「運動」に関しては負荷が軽く身体的疲労が少ない「ストレッチ」に変更\nした．さらに，先行研究[6] では仮眠時間の延長の必要性が指摘されていたため，本研究\nでは先行研究よりも長い仮眠時間を設定し，その効果を最大化することを目指した．\n1.3\n本論文の構成\n第1 章では，本論文の研究背景，研究目的，及び本論文の構成について述べた．第2 章\nでは，先行研究について述べる．第3 章では，専門用語，システム概要について述べる．\n第3 章では，専門用語，システム概要について述べる．第4 章では，実験概要について述\nべる．第5 章では，実験結果，考察について述べる．\n3\n第2章\n関連研究\n本章では，に関する研究について述べる．2.1 節ではウェアラブルデバイスを活用した\n生体データの解析と応用に関する研究，2.2 節ではストレス・集中力評価と向上に関する\n研究,2.3 節ではロケーションや環境対応型の情報提示システムに関する研究，2.4 節では\n健康促進および休憩の効果の研究について述べる．\n2.1\nウェアラブルデバイスを活用した生体データの解析と応用に関する\n研究\n閏間らは, メガネ型ウェアラブルデバイス（JINS MEME）とスマートウォッチ（Apple\nWatch）を用い, 歩行中の心拍と視線活動を測定することで, 異性への好意を判定する手法\nを提案した．被験者に街を散策してもらい, 視線活動や心拍数のデータを収集した後, まば\nたきの回数と心拍数が増加する際の映像を分析した結果, 被験者の好みの異性が映る場合\nにこれらの変化が確認され, 心拍数と視線活動が好意と一定の相関を持つ可能性が示唆さ\nれた．また, 移動平均フィルタを用いてノイズを除去したデータの分析では, まばたきの回\n数と心拍数の相関係数が0.4295 を示し, 心拍とまばたきの増加が好意を抱く状況で顕著に\nなることが明らかになった．一方で, 好意以外の要因によってデータに影響が及ぶ場合も\n確認され, さらなる検証が必要であるが, 簡易な装置による好意の自動判定システムの可能\n性が示された[4]．\n吉村らは, ウェアラブルデバイスを活用し, 観光地の評価を旅行者の内面状態から推定す\nる手法を提案した．Android Wear を用いて安静状態および歩行中の心拍数を計測し, その\n精度を筋電式心拍計（my Beat）と比較した結果, 運動の影響を除外すれば信頼性が高いこ\nとが確認された．また, 観光地での内面状態を想定し, 動画視聴中の心拍数を分析したとこ\nろ, 心拍数が高い状態を平均的に維持する特性が見られ, 運動中とは異なる変化が観測され\nた．この結果から, 心拍センサを活用した内面状態の推定が可能であることが示唆され, 観\n光地評価における個別ニーズへの対応や観光地の改善に活用できる可能性が示された[7]．\n浦野らは，ウェアラブルデバイスで計測した心拍数に基づき, 心拍信号に同期した光の\n変化を用いて心理的緊張や興奮をリアルタイムで可視化する図2-1 に示されているような\nLED デバイスを提案した．既存の心拍計測デバイスが提示情報をユーザ個人に限定する\nのに対し, 本デバイスは発光パターンを用いて心拍情報を視覚的に共有可能とすることで,\n4\n他者とのインタラクションを促進する．具体的には, 光学式心拍センサとマイコンを組み\n合わせ, ユーザの心拍数に応じた発光パターンを生成し, 心理状態を他者に伝える仕組みを\n開発した．実験では, 心拍波形を忠実に反映した発光パターンが心理状態の共有を可能に\nすることが確認され, ゲームやイベント, 医療分野での応用可能性が示唆された[8]．\n図2-1: 光学センサ，デバイス本体，LED の構成（[8] より引用）\n青木らは, 個人に適応した住空間サービスを実現するため, 心拍数を含むマルチモーダル\nデータを用いて体感温度や気分の変化を分析する手法を提案した．高齢者や学生を対象に\n行った住空間実験では, 心拍数や温湿度データ, 気分などの主観的・客観的情報を収集し,\nそれらを統合した分析ツールを用いて体感状況の変化パターンを解析した．その結果, 体\n感温度と心拍数の変化には一定の相関があり, 心拍数データが体感温度の推定や快適性向\n上に寄与する可能性が示された．これにより, 住空間の自動制御や個人化サービスの設計\nへの応用が期待される[9]．\n角田らは，心拍数と呼吸数の長期的な変動の類似性を利用し, コンテンツ視聴による気\n分変化を非侵襲的に推定する手法を提案した．従来の主観評価法や顔表情解析法におけ\nるユーザ拘束やノイズの影響を克服するため, コメディ動画視聴中の心拍・呼吸データを\n収集し, フィルタ処理により動作ノイズを除去したデータを分析した．その結果, 心拍数\nと呼吸数の同期が気分変化と密接に関連することが確認され, この手法の有効性が示され\nた．提案手法は, コンテンツ提供者による効果的な作品評価や個人の視聴体験向上に寄与\nする可能性を持つ[10]．\n図2-2: 提案手法図（[10] より引用）\n東海林らは, スマートウォッチを用いて動画鑑賞中の心拍変動を解析し, 鑑賞者の感情を\n客観的に評価する手法を提案した．従来の主観的なアンケート評価や複数のセンサを使用\nした負荷の大きい方法に代わり, 心拍変動データと機械学習モデルを組み合わせて, 鑑賞者\n5\nの感情を自動推定する実験を行った．実験部屋の全体図を図2-3 に示す．ホラー動画を対\n象とした評価では,F1 値が90 ％以上という高精度を達成し, 視聴体験を基にした動画推薦\nや評価システムへの実用化可能性が示唆された[11]．\n図2-3: 実験部屋の全体図（[11] より引用）\n野本らは, スポーツ観戦中の情動を脈拍変動（PRV）を用いて客観的に評価する手法を\n提案した．Android Wear 搭載のウェアラブルデバイスを用いて心拍データを取得し,KNN\nアルゴリズムを活用して観戦中の喜びや興奮, 平静さなどを分類するモデルを構築した．\n評価実験では, 喜びや興奮の感情を80 ％上の精度で分類できることが確認され, スポーツ\n観戦時の心理的変化をデータに基づいて理解する手法として有効性が示された．今後は,\n観戦体験の向上やイベント設計への応用が期待される[12]．\n図2-4: 実装した脈拍間隔ノイズ処理手法を説明するコメント付き脈拍変動PSD プロット（[12] よ\nり引用）\n2.2\nストレス・集中力評価と向上に関する研究\n田島らは，腕時計型ウェアラブルデバイスを活用し,98 名の母親を対象に心理的ストレ\nス反応と心拍変動や睡眠などの生理的データの関連性を分析するとともに, ストレス対処\n行動の変化を検討した．4 週間のデータ収集期間の結果, 心理的ストレス反応と生理的デー\nタの間に有意な相関が確認されたものの, 個人差が大きく共通のパターンは得られなかっ\nた．一方, ストレス対処行動においては, 調査期間後に高ストレス群でポジティブな再評価\n6\n型の対処行動が顕著に増加した．この変化は, ウェアラブルデバイスを通じたストレス認\n識とデータの可視化が自己管理意識を高めたことが要因と考えられる．これらの結果は,\n育児支援としてのストレスマネジメントツールの可能性を示唆している[13]．\n伊村らは, 医療現場における医師のストレス推定手法として, ウェアラブルセンサデバイ\nスを活用して心拍変動や睡眠データを解析する方法を提案した．7 名の医師を対象に最大\n8 週間データを収集し, 心拍数の低周波成分と高周波成分の比率や睡眠深度データを基に\n疲労やストレスを推定した．結果, 医師のストレス状態を高精度で推定可能であり, ストレ\nス軽減のための休息の必要性を判断できることが示された．本手法は, 医療現場の過酷な\n労働環境における医師の健康管理や医療事故の未然防止に寄与する可能性がある[14]．\n図2-5: リング型ウェアラブルデバイス[14] よ\nり引用）\n図2-6: 腕時計型ウェアラブルデバイス（[14]\nより引用）\n鈴木らは, 長距離運転中のドライバーが適切な休憩を取るためのストレス推定システム\nを提案した．スマートウォッチで取得した心拍変動データを高速フーリエ変換し, 低周波\n成分と高周波成分の比率を基にストレス状態を分類するモデルを構築した．9 名の被験者\nによる実験では, サポートベクタマシンを用いたストレス状態の分類精度が73 ％に達し,\n運転中のストレス評価に実用性があることが示唆された．本手法は, ドライバーの事故防\n止や安全運転支援への応用が期待される[15]．\n宮崎らは, オンライン授業における集中力持続を目的としたシステムを提案した．Node-\nRED を用いて構築されたシステムは,5 分ごとに受講者の顔写真を撮影し, 顔の有無に基づ\nいて集中力を推測する．集中力が低下した場合には, 光やアロマといった刺激を自動的に\n提供し, 注意を引き戻す仕組みを導入した．実験結果から, 本システムがオンライン授業中\nの受講者の集中力を効果的に維持し, 学習効率の向上に寄与する可能性が確認された[16]．\n7\n図2-7: システム構成図（[16] より引用）\n森川らは, スマートグラスを活用して複合現実空間に仮想の壁を表示し, 周囲の視野を制\n限することで学習や作業時の集中力を向上させる手法を提案した．これまでの研究では,\n視野や周辺情報を制御して集中を高める手法が検討されていたが, 固定された設備を必要\nとすることが多かった．本研究では, スマートグラスを使用することで携帯性を向上させ,\n自習室のような集中環境をどこでも再現可能にした．開発されたシステムでは, ユーザー\nの視界に仮想的な壁を表示し, 周囲の人や物からの気を散らす要素を排除する．実験によ\nり, ユーザーが集中して作業に取り組める環境を簡易かつ効果的に提供できることが示さ\nれ, この手法の教育や作業支援への応用可能性が示唆された[17]．\n図2-8: システム構成図（[17] より引用）\n菅野らは, 大勢の聴衆の前でのプレゼンテーション時に生じる緊張を緩和するため, 心拍\n情報のフィードバック手法を提案した．視覚, 聴覚, 触覚の3 種類の虚偽心拍情報を用い, そ\nれぞれのフィードバックが発表者に与える影響を比較検証した．具体的には, 視覚フィー\nドバックでは心拍数のグラフ表示, 聴覚では心拍音の再生, 触覚では心拍に応じた圧力デバ\nイスを用いた．実験では発表者が最も知覚しやすいのは視覚的フィードバックである一\n方, 触覚と聴覚も緊張を緩和する効果が認められた．本手法は, プレゼンテーションスキル\nの向上や緊張の制御を支援するシステム設計に有用である可能性が示された[18]．\n河端らは, 焦電センサを用いて学習中の脚部動作を非接触で計測し, 精神疲労が蓄積した\nタイミングで適切な休憩を提案するシステムを開発した．22 名の被験者を対象に, 脚部動\n8\n作の頻度と精神疲労の関係を分析し, 動作計測の正確性を評価した結果, 目視計測との一致\n率は89.2 ％に達した．さらに, 脚部動作の変化に基づき休憩を提示するシステムを提案し,\n個別に適応した休憩タイミングの提示が学習効率向上に寄与することが示唆された．本手\n法は, 集中力の維持と疲労軽減を目的とした学習支援の有効なアプローチを提供する[19]．\n濱谷らは, スマートフォン内蔵センサやウェアラブルセンサを用いて, タイピングや動画\n視聴などの行動中に取得した加速度, 心拍数, 皮膚導電率などのデータを分析し, 集中度を\n推定する手法を提案した．1 名の被験者を対象に40 分間のデータ収集を行い, 集中行動と\nセンサデータの相関を分析した結果, 集中時には特定の生理指標に特徴的な変化が見られ\nることが確認された．本手法は, 集中度の可視化とパフォーマンス向上のためのシステム\n開発に活用可能であり, 教育や職場環境での応用が期待される[20]．\n図2-9: システム図（[20] より引用）\n川崎らは, スマートウォッチを用いて勉強中の心拍数データを収集し, 集中, 眠気, 疲労と\nいった精神状態の度合いを連続的に推定するシステムを提案した．被験者2 名を対象にし\nた実験では, 心拍数の変化パターンから各状態を識別するモデルを構築し,F1 値が78 ％以\n上の精度で分類が可能であることを確認した．短期的な休憩提案と長期的なフィードバッ\nクによる学習効率向上が期待され, 教育分野での応用可能性が示された[21]．\n徳田らは，オフィス環境における不適切な割り込みを軽減し, 適切なタイミングでのコ\nミュニケーションや休憩を誘発することで行動変容を促進することを目的として, ユーザ\nの集中度を３段階で可視化するシステム(図2-10) を提案した．具体的には,JINS MEME\nというアイウェアを利用してユーザの集中度を瞬きの頻度と姿勢の安定性から正確に計\n測し, スマートIoT 照明のPhilips hue によって集中度を「フロー状態」「集中状態」「集中\nしていない状態」の3 段階で可視化するシステム(図2-11) である．従来のマウスやキー\nボード利用に基づく手法では対応が難しかった読書や思考中の状態についても, 本システ\nムは正確に計測可能であり, 生産性向上や疲労軽減への貢献が見込まれる．今後の課題と\nしては, 提案システムの実用性評価, 他デバイスとの組み合わせによる精度向上, 集中度の\n9\n提示方法の拡張が挙げられる[22]．\n図2-10: 提案システムの概要（[22] より引用）\n図2-11: フロー状態(赤)，集中状態(黄)，集中していない状態(青)（[22] より引用）\n橘らは,PC 作業中の集中力向上を目的として, 視線を作業エリアに誘導する視覚刺激の\n効果について検証を行った．視覚刺激として,「白地」「黒地」「内向き縞模様」「外向き縞模\n様」「ランダムドット」の5 種類の背景パターンを設定した(図2-12)．被験者には, これら\nの背景を表示したPC 画面上で計算問題を解答させ, その際の瞬目頻度, 音に対する反応時\n間, 正答率, 主観的集中度を測定した．なお, 実験は図2-13 に示すような環境で行われた．\n実験の結果, 内向き縞模様の視覚刺激が他の条件と比較して最も高い集中力向上効果を示\nした．具体的には, 瞬目頻度の減少, 計算問題の正答率の向上, 主観的集中度の上昇が確認\nされた．一方, 外向き縞模様やランダムドットでは集中度が低下する傾向が見られた．こ\nれらの結果から, 内向き縞模様の視覚刺激が作業エリアへの注意を促進し, 集中力を高める\n有効な手段であることが示唆された．\n10\n図2-12: 5 種類の背景パターン（[23] より引用）\n図2-13: 実験環境（[23] より引用）\n2.3\nロケーションや環境対応型の情報提示システム\n小松らは, 社会的接触の頻度を客観的に計測し, 健康状態や行動変容の促進に役立てるた\nめ, 腕時計型ウェアラブルデバイスを活用した会話時間計測手法を提案した．市販のデバ\nイスに搭載されたマイクと機械学習モデルを組み合わせ, 環境音と会話音を分類し, 信頼度\n50 ％以上の場合を会話時間として記録する「OHANASHI」アプリを開発した．実験では,\n雑音と会話の判別精度が85 ％以上であることを確認し, 被験者7 名を対象に実際の生活環\n境で2 週間計測を実施した．その結果, 時刻ごとの会話パターンが可視化され, 計測データ\nが社会的接触への意識向上に寄与する可能性が示唆された[24]．\n千葉らは, ウェアラブルデバイスを活用し, 野外ミュージアムにおける健康増進と鑑賞体\n験の向上を目的としたシステムを提案した．心拍数やカロリー消費量を測定するリストバ\nンド型デバイスとスマートフォンを連携させ, 来館者が森林ウォーキングをしながら彫刻\n11\nや植物の情報を動的に得られる仕組みを構築した．プロトタイプの開発では, 季節や時間\n帯に応じて情報を提供する機能や,SNS で感想を共有する機能も搭載した．調査結果から,\n森林セラピーや運動情報に対する高い需要が確認され, 来館者の満足度向上に寄与する可\n能性が示された[25]．\n吉田らは, スマートウォッチの消費電力削減とユーザ位置情報に基づく動的な情報提示\nを目的としたシステムを開発した．ジオフェンシング技術と音波を用いた位置推定手法\nを組み合わせ, エリアとブロック単位で位置を特定し, その場に関連する情報を自動的に提\n示する仕組みを構築した．実験では, 部屋単位で情報を提示する精度が100 ％に達し, 提示\nまでの時間は1 分以内が96 ％を占めた．また, エリア内外での切り替えにより, スマート\nウォッチのバッテリー消費を最小限に抑えられることが確認された[26]．\n2.4\n健康促進および休憩の効果\n岡部らは, 地域住民30 名を対象に腕時計型ウェアラブルデバイスを用いたセルフモニ\nタリングが歩数と睡眠時間に与える影響を検証した．1 週目は通常活動を記録するコント\nロール期間,2 週目はデバイスによるセルフモニタリング期間とし,VAS を用いて健康意識\nの変化を調査した．結果, 男性では歩数が平均7987 歩から9529 歩へと有意に増加したが,\n女性では有意差は見られなかった．また, 睡眠時間に有意な変化はなかったものの, 男女と\nもに健康意識は向上した．これにより, セルフモニタリングが男性の歩数増加や健康意識\n向上に寄与する可能性が示され, 男女間での指導方法の差異の必要性が考察された[27]．\n本多らは, 寺院での坐禅が自律神経活動に及ぼす影響を明らかにすることを目的とした．\n健常な成人11 名を対象に, 僧侶の指導下で15 分間の坐禅を実施し, 自律神経活動を測定し\nた．結果, 坐禅後に心拍数の低下やSDNN とLnTP の有意な増加が観察され, 中程度の効果\n量を示した．これにより, 坐禅が交感神経および自律神経機能を一過的に活性化する可能\n性が示唆された．本研究は坐禅が健康増進活動として有効であることを一般人に示す初め\nての実証的研究である[28]．\n後藤らは, 脚部動作時間を基に学習者の疲労を推定し, 適切な休憩タイミングを提案する\nシステムを開発した．20 名の大学生を対象に, 休憩を取り入れた実験群と連続学習を行う\n対照群に分け,90 分間の映像講義後にテストを実施した．結果, 提案システムによる休憩タ\nイミングの提示は集中力の維持と学習成果の向上に寄与した．脚部動作を非接触で計測す\nる本手法は, 学習環境を妨げずに適応可能な効果的な休憩管理手段を提供する[29]．\n荻野らは, 長時間作業の合間に運動を組み込むことで集中力と作業効率を向上させる効\n果を検証した．被験者は「休憩なし」「運動なし」「運動あり」の3 条件で校正作業を実施\nし, 生体情報と課題正答率を比較した．結果, 運動あり条件では正答率が最も高く, 運動が\n12\n集中力維持に有効であることが示された．本手法は短時間の運動を効果的に取り入れるこ\nとで, 作業パフォーマンスを向上させる可能性を示唆している[30]．\n渡部らは, 休憩時にクラシック音楽を聴取することで休憩後の作業遂行能力や主観的気\n分がどのように変化するかを検証した．35 名の大学生を対象に, クラシック音楽聴取条件\nとノイズ音聴取条件で符号課題を実施した結果, クラシック音楽条件での作業量が有意に\n多く, 集中力と活気が向上した．本研究は, 音楽が作業効率や気分の改善に与える影響を定\n量的に示すものであり, 効果的な休憩法の設計に寄与する[31]．\n三木らは, オフィスワーカーの休憩時間の過ごし方が作業パフォーマンスに及ぼす影響\nを調査し, 効果的な休憩手法を提案することを目的とした．被験者9 名に対し, 計算課題の\n実施前後で休憩時間を6 種類（「寝る」「スマートフォンを見る」「運動をする」「タバコを\n吸う」「コーヒーを飲む」「食べ物を食べる」）に分け, 心拍センサと眼電位センサを用いて\n生体情報を計測した．ストレス指標（LF/HF 値）と瞬きの回数を分析し, 休憩後の作業効\n率を評価した結果,「寝る」「運動をする」「タバコを吸う」が特にパフォーマンス向上に\n効果的であり,LF/HF 値が高い状態での作業効率が向上することが確認された．一方, 課題\nの順番による慣れや個人差がデータに影響する可能性も指摘され, さらなる検証が必要で\nある．本研究は, 休憩方法が作業効率やストレス軽減に与える影響を示し, 個人に適した休\n憩設計の基礎を提供するものである[6]．\n2.5\n先行研究のまとめ\nこれまでの研究では, デスクワークに特化した効果的な休憩方法について, 完全に結論\n付けられていない．そこで本実験では、デスクワークの作業を想定し,LF/HF(Low Fre-\nquency/High Frequency) を用いて休憩前後の集中度回復を計測し, その効果を比較・検討\nする．\n13\n第3章\n本研究で用いる技術や用語について\n本章では測定に用いる技術や用語について述べる．\n3.1\n心拍間隔と心拍変動\n心臓は，収縮と拡張を周期的に繰り返すことで生命を維持している．この活動を細胞レ\nベルで見ると，脱分極と活動電位，再分極と静止電位の繰り返しにより制御されている．\n図3-1 は正常な心電図を示している．PP 間隔は，心房の興奮が始まってから次の興奮が\n始まるまでの時間を指し，RR 間隔は，心室の収縮から次の収縮までの時間を指す．正常\nな状態では，これらの間隔は規則正しく周期的である．また，心室が1 分間に収縮する回\n数を心拍数と呼ぶ．RR 間隔を基に心室の興奮周期を求めることで，心拍数を算出するこ\nとが可能である[32]．\n図3-1: 正常心電図( [32] より引用)\n3.2\n自律神経系\n自律神経系は，身体の内臓機能や循環器，呼吸器，消化器，腺分泌などを無意識的かつ\n自動的に調節する神経系であり，主に交感神経系と副交感神経系の2 つの主要な構成要素\nから成る．これら2 つの系は，互いに拮抗的に働きながら，身体の恒常性(homeostasis) を\n維持する役割を果たす．交感神経系は，ストレスや緊急事態において活性化され，心拍数\n14\nの増加，血圧の上昇，気管支の拡張，血糖値の上昇など，身体を活動的な状態に導く「闘\n争・逃走反応(ﬁght-or-ﬂight response)」を担う．一方，副交感神経系は，心拍数の減少，消\n化管の活動促進，エネルギー貯蔵の促進など，リラックス状態や回復を促進する「休息と\n消化(rest-and-digest)」を担う．自律神経系の中枢は主に視床下部や延髄に位置し，外部環\n境や内部の代謝的要求に応じて活動を動的に調整する．また，自律神経系の機能は，心拍\n変動(heart rate variability，HRV) や皮膚電位反応(electrodermal activity，EDA) などの生\n理学的指標を通じて評価される．これにより，ストレスや精神的負荷の状態を客観的に把\n握することが可能である．自律神経系の異常は，高血圧や慢性疾患，精神疾患など多岐に\nわたる健康問題と関連し，その調節機構の理解は臨床医学や健康科学において重要な課題\nとなっている．\n3.2.1\n交感神経\n交感神経系は，自律神経系の一部であり，身体がストレスや緊急事態に直面した際に活\n性化される「闘争・逃走反応(ﬁght-or-ﬂight response)」を担う神経系である．この系は，脊\n髄の胸髄および腰髄(T1-L2) から起始する神経節前線維(preganglionic ﬁbers) と，交感神\n経幹または遠位の神経節に位置する神経節後線維(postganglionic ﬁbers) で構成される．交\n感神経系の主要な役割は，身体を活動的かつ即応的な状態にすることであり，これには心\n拍数の増加，血圧の上昇，気管支の拡張，血糖値の上昇，瞳孔の拡大などが含まれる．交\n感神経系の神経伝達は，神経節前線維から分泌されるアセチルコリン(acetylcholine) を介\nして開始され，神経節後線維からは主にノルアドレナリン(norepinephrine) が放出される．\nこのノルアドレナリンは，心臓や血管，呼吸器などの標的組織に作用し，各器官の機能を\n調節する．また，副腎髄質も交感神経系の一部とみなされ，ストレス時にはアドレナリン\n(adrenaline) とノルアドレナリンを血中に分泌する．このように交感神経系は，緊急時や\n身体的・精神的負荷がかかった状態において，エネルギー供給を増強し，適応的な応答を\n促進する役割を果たす．しかし，交感神経系の過剰な活性化は，高血圧やストレス関連疾\n患などの健康問題を引き起こす可能性があるため，その活動の調節は重要である．\n3.2.2\n副交感神経\n副交感神経系は，自律神経系の一部であり，主に身体の「休息と消化(rest-and-digest)」\nに関連する活動を調節する．副交感神経系は，中枢神経系の脳幹部(迷走神経や顔面神経，\n舌咽神経を含む) および仙髄(S2-S4) から起始する神経節前線維と，標的器官の近傍や内\n部に位置する神経節後線維で構成される．副交感神経系の主要な機能は，エネルギーの保\n存と回復に貢献することである．これには，心拍数の減少，血圧の低下，消化液分泌の促\n15\n進，腸管の蠕動運動の活性化，瞳孔の収縮などが含まれる．これらの調整により，副交感\n神経系は身体をリラックス状態に導き，回復や再生を促進する．たとえば，食事後に消化\n活動を活発化させる一方で，身体の活動性を抑制してエネルギーを節約する．副交感神経\n系の神経伝達では，神経節前線維および神経節後線維のいずれにおいても，アセチルコリ\nンが主要な神経伝達物質として機能する．アセチルコリンは，標的組織のムスカリン受容\n体(muscarinic receptors) に結合し，特定の生理機能を誘導する．副交感神経系は，交感神\n経系と協調的に働くことで，身体の恒常性を維持する役割を果たす．しかし，副交感神経\n系の異常な機能低下は，消化不良や慢性的なストレス障害などの健康問題を引き起こす可\n能性がある．\n3.3\n心拍変動解析\n前述にあるように，周期的な変動には自律神経系に関係する呼吸と同期したゆらぎ，お\nよび血圧と同期したゆらぎが反映されているため，自律神経系の活動が心拍間隔の周期的\nな変動に影響を与えているという関係性が示されている．つまり，心拍変動を解析するこ\nとによって，自律神経系の活動状態を把握することが可能である．\n3.3.1\n時間領域解析\n時間領域解析は，心拍間隔(RR 間隔) の変動を時間の観点から解析する手法であり，主\nに自律神経系の活動や心拍の規則性を評価するために用いられる．この解析では，心拍間\n隔を座標上にプロットし，その変動の大きさや傾向を観察する．具体的には，縦軸と横軸\nの単位がいずれも「時間」となり，縦軸には心拍間隔を示すミリ秒[ms]，横軸には経過時\n間を示す秒[s] を使用する．この方法では，時間軸上の変化として心拍間隔の増減を視覚\n的に捉えることができ，心拍の安定性やリズムの乱れを直感的に評価することが可能であ\nる．また，時間領域解析では，平均心拍間隔やその標準偏差，隣接する心拍間隔の差分に\n基づく統計指標(例：SDNN，RMSSD，pNN50) を算出することにより，心拍変動の特徴\nを定量的に評価する．\n特にこの手法は，心拍間隔が時間とともにどのように変化するかを明確に把握すること\nに適しており，ストレス，疾患，運動負荷などの影響を解析する際に広く応用されている．\n一方で，時間領域解析は周波数特性や周期性の詳細な解析には向いていないため，必要に\n応じて周波数領域解析や非線形解析と組み合わせることが推奨される．\n16\n3.3.2\n周波数領域解析\n周波数領域解析は，心拍間隔の変動特性を周波数の観点から解析する方法であり，自律神\n経系の活動を詳細に評価するために広く用いられる．この解析手法では，時系列データと\nして得られる心拍間隔の変動を周波数帯域ごとに分離し，各帯域のエネルギーや寄与度を\n分析する．波形の周波数成分を分離するには，フーリエ変換（FFT: Fast Fourier Transform）\nやウェルチ法などの信号処理技術を用いる．\n具体的には，心拍間隔の変動を周波数として表現し，そのパワースペクトル密度（Power\nSpectral Density，PSD）を求めることで，交感神経系および副交感神経系の活動状態を定\n量的に評価できる．\n• 高周波数帯域（HF: High Frequency，0.15～0.40 Hz）：副交感神経（迷走神経）の\n活動を反映し，呼吸と連動する心拍変動成分を示す．\n• 低周波数帯域（LF: Low Frequency，0.05～0.15 Hz）：交感神経および副交感神経\nの双方が関与する心拍変動成分を示すが，特に交感神経の影響が強いとされる．\nこれらの帯域のパワーを比較することで，交感神経と副交感神経のバランスや，交感神経\nの相対的な活動量を評価できる．特に，LF/HF 比は交感神経優位性を示す重要な指標であ\nり，ストレス，疲労，精神的緊張の評価に活用される．\n周波数領域解析は，心拍変動の周期性を明確に捉えられるため，時間領域解析では見え\nにくい情報を補完する．加えて，特定の周波数成分を取り出して解析できることから，自\n律神経系の活動状態をより精緻に理解する手法として有用である．\n図3-2: 心拍変動時系列データのパワースペクトル( [33] より引用)\n17\n3.4\n集中力の定義\n一般的に，LF/HF 値は2 以上の時，人はストレス状態にあり，LF/HF 値が2 未満の時は\nリラックス状態にある．そこで，本実験では集中している状態をストレスを感じている状\n態(リラックスしていない状態) と定義することとした[6]．\n18\n第4章\n集中力回復のための休憩方法比較検証\n本章では, 集中力を回復させるための休憩方法比較検証実験について述べる．評価実験\nにおける被験者は実験説明を受け，実験に対する同意書による同意をもって，実験に参加\nする．先行研究( [6]) では，仮眠，運動(ジョギング)，喫煙が作業パフォーマンスの向上\nに寄与することが示されている．しかし，運動に関しては負荷が過大であると結論付けら\nれていたため，本研究ではストレッチ( [34]) に置き換えた．また，仮眠に関しては，先行\n研究における5 分という短時間設定では十分な効果が得られないと考え，休憩効果を高め\nるために10 分へと延長した．仮眠の時間設定はgirafeenap のウェブサイト( [35]) を参考\nにした．さらに，喫煙は非喫煙者に適用できないため，その代替として，ManpowerGroup\n株式会社のウェブサイト( [5]) を基に，音楽を聴くという新たな休憩方法を採用した．こ\nの手法は先行研究では検討されておらず，本研究において新たな視点として取り入れた．\n4.1\n実験目的\n4.1.1\n実験概要\n実験では，集中力を回復させるために最適な休憩方法を比較するために3 つの休憩方法\nで集中力の推移を比較検証する．\n4.2\n実験概要及び手順\n本実験は，静かで空調設備も整った部屋で行い，実験中は被験者以外いない作業に集中\nしやすい環境で行った．今回の被験者は，大学生・大学院生の10 人とする．\n心拍数測定の実験手順\n実験は次の手順で実施する．\n1. 被験者に椅子に座った状態でスマートウォッチを装着してもらい，アプリ(RRI) を\n起動してもらう．\n2. アプリ上で測定開始ボタンを押してもらい，そこから3 分の安静時間をおく．\n19\n3. 安静後，被験者には自由に20 分間作業を実施してもらう．\n4. デスクワーク後，各休憩をとってもらう．\n5. 休憩後には再度20 分間の自由な作業を行ってもらう．この際，休憩前後での集中度\nの比較をするため，休憩前後では同じ分量の作業を行ってもらう．\n6. 作業終了後にアプリ上の測定終了ボタンを押してもらう．\n7. 被験者には3 回の実験後にアンケートの記入を実施してもらう．\n図4-1 は実験の手順を表した図である．休憩方法は，好きな音楽を聴く，軽いストレッ\nチをする，仮眠するのいずれかを行う．また，休憩時間は仮眠の場合のみ10 分で，他の\n2 つの休憩は3 分とする．各被験者この3 種類の休憩方法でそれぞれ実験を行う際，集中\n力への影響を考え，1 日1 種類を3 日間かけて行った．\n図4-1: 実験の手順\nまた，図4-2，図4-3 は実験中の作業中の様子であり，図4-4 は仮眠の休憩中，図4-5 は\nストレッチの休憩中，図4-6 は音楽を聴く休憩中の様子である．\n20\n図4-2: 実験風景\n図4-3: 実験風景\n図4-4: 休憩風景(仮眠)\n図4-5: 休憩風景(ストレッチ)\n図4-6: 休憩風景(音楽)\n4.3\n集中力回復の評価に用いる指標\n4.3.1\n定量効果について\nt 検定とは，ある仮説が正しいかどうかを判断するための仮説検定の手法の一つであり，\nt 分布を利用して分析を行う．t 分布は，最も一般的な分布である正規分布に基づいている\n21\nが，母集団(データ全体) に関する分散が分からない場合に使用される統計的分布である．\nこの分布は，母分散が未知であるときに，標本データを基に母集団の特性を推定する際に\n役立つ．そのため，t 分布は標本サイズが小さい場合や母集団の分布が完全には分からな\nい場合でも頻繁に使用される．t 検定の目的は，2 つのグループの平均値の違いが偶然に\nよるものか，それとも統計的に有意な違いがあるかを判断することである．この検定で\nは，まず「帰無仮説」と呼ばれる仮説を立てる．帰無仮説は，調べたい仮説とは反対の内\n容を主張するもので，例えば「2 つのグループの平均値には差がない」というものが典型\n的である．t 検定では，帰無仮説が正しいと仮定した場合のデータの発生確率(p 値) を計\n算し，このp 値を事前に設定した有意水準と比較する．もしp 値が有意水準よりも低けれ\nば，帰無仮説を否定し，「偶然では説明できない差がある」と判断する．これにより，元々\nの仮説(対立仮説) が支持されることになる．一般的にt 値とは，2 つのグループ間の平均\n値の差が統計的に意味があるかどうかを示す指標である．t 値が大きいほど，2 つの平均\n値の間に差がある可能性が高くなる．p 値は，得られたデータが「帰無仮説が正しいと仮\n定した場合」に観測される希少性を表す．p 値が小さいほど，観測された結果が偶然によ\nる可能性が低いと考えられる．有意水準は，p 値がどの程度小さいときに「統計的に有意\nである」と判断するかを示す基準である．一般的に，有意水準は0.05 に設定されること\nが多い．これは，5 ％以下の確率でしか起こらない事象を「偶然ではない」と見なすこと\nを意味する( [36])．また，分析の手順は以下のようになる．\n1. 帰無仮説を設定する．\n2. 実際のデータからt 値を計算し，そこからp 値を求める．\n3. p 値を有意水準(通常は0.05) と比較する．p 値が有意水準よりも小さい場合，帰無仮\n説を棄却する．これにより，仮説(対立仮説) が統計的に有意であると判断される．\n一元分散分析(ANOVA:Analysis of Variance) は，3 つ以上のグループ間の平均値の差を\n統計的に検証するための手法であり，単一の独立変数(因子) が従属変数に与える影響を解\n析する際に用いられる．この手法では，グループ間の分散とグループ内の分散を比較し，\n観測された差が偶然によるものではないかどうかを判断する．帰無仮説と対立仮説の下，\n分散比(F 値) を計算し，F 分布に基づく検定で有意性を評価する．一元分散分析の適用に\nは，データが独立していること，正規分布に従っていること，そしてグループ間の分散が\n等しいことが条件とされる．この手法は，複数のグループ間での比較を効率的に行える\n( [37])．\nTukey の多重比較検定(Tukey 法) は，3 つ以上のグループ間で平均値の差を比較し，どの\nグループ間に有意な差が存在するかを明らかにするための統計手法である．この手法は，\n分散分析(ANOVA) で全体的な有意差が検出された後，具体的にどのグループ間で差があ\n22\nるのかを特定する際に用いられる．Tukey 法は他の多重比較法と比べて検出力が高く，検\n定の精度が優れているとされる．ただし，適用するためには各グループの分散が等しく，\nデータが正規分布に従っていることが前提条件となる．Tukey 法は多重比較法の中でも非\n常によく用いられ，特に各グループのサンプルサイズが等しい場合に適している( [38])．\n4.3.2\n定性的評価について\n[H] 以下の図4-7，4-8，4-9，4-10 は評価実験で使用する評価アンケートである．11 個\nの質問で構成され，質問は「1. 全くそう思わない」から「5. とてもそう思う」の5 段階で\nの評価尺度を使用するもの，選択式のもの，自由記述のものを含む．\n図4-7: アンケート問1，問2\n23\n図4-8: アンケート問3，問4，問5\n図4-9: アンケート問6，問7，問8\n24\n図4-10: アンケート問9，問10，問11\n25\n第5章\n比較検証実験の結果及び考察\n5.1\n心拍変動指標のt 検定による評価\n3 種類の休憩方法(仮眠，音楽を聴く，ストレッチ) の効果を比較するために，各被験者\n(10 名) の休憩後と休憩前の作業時におけるLF/HF 値を用いて分析を行った．具体的には，\n以下の手順で解析を実施した．\n1. 変化量の計算\n各休憩方法において，被験者ごとに以下の式で変化量を算出した：\n∆LF/HF = 平均値(休憩後の作業時のLF/HF)−平均値(休憩前の作業時のLF/HF)\n2. 組み合わせごとのt 検定\n3 種類の休憩方法から2 組ずつ(仮眠・音楽，仮眠・ストレッチ，音楽・ストレッチ)\nの合計3 パターンの組み合わせについて，対応のない2 群間の平均値の差を検定す\nるため，独立標本t 検定を行った．t 検定の有意水準はα = 0.05 とした．\n表5-1，5-2，5-3 は一対の標本による平均の検定によってt 検定を行った結果の表である．\n表から分かるようにどの組み合わせにおいても有意差は見られなかった．\n表5-1: 音楽とストレッチ間のt 検定の結果\n項目\n音楽\nストレッチ\n平均\n0.887\n1.021\n分散\n0.200\n0.089\n観測数\n10\n10\nピアソン相関\n-0.519\n仮説平均との差異\n0\n自由度\n9\nt 値\n-0.650\nP 値(片側)\n0.266\nt 境界値(片側)\n1.833\n26\n表5-2: 音楽と仮眠間のt 検定の結果\n項目\n音楽\n仮眠\n平均\n0.887\n0.878\n分散\n0.200\n0.218\n観測数\n10\n10\nピアソン相関\n0.048\n仮説平均との差異\n0\n自由度\n9\nt 値\n0.043\nP 値(片側)\n0.483\nt 境界値(片側)\n1.833\n表5-3: ストレッチと仮眠間のt 検定の結果\n項目\nストレッチ\n仮眠\n平均\n1.021\n0.878\n分散\n0.089\n0.218\n観測数\n10\n10\nピアソン相関\n-0.330\n仮説平均との差異\n0\n自由度\n9\nt 値\n0.716\nP 値(片側)\n0.246\nt 境界値(片側)\n1.833\n5.2\n心拍変動指標の一元配置分散分析・多重比較による評価\n休憩方法(仮眠，音楽，ストレッチ) がLF/HF 値に与える影響を検討するため，一元配\n置分散分析(ANOVA) およびTukey の多重比較検定を用いて解析を行ったが，いずれの休\n憩方法間においても統計的有意差(p ＞0.05) は認められず，LF/HF 比の変化量(Δ LF/HF)\nの平均値は仮眠で0.88 ± 0.47，音楽で0.89 ± 0.45，ストレッチで1.02 ± 0.30 であった．\n27\n表5-4: 分散分析の結果\n指標\n値\nF 値\n0.38127\n因子の自由度(df factor)\n2\n残差の自由度(df error)\n27\n因子平方和(SS factor)\n0.12911\n残差平方和(SS error)\n4.5715\n表5-5: 多重比較検定の結果(Tukey HSD)\n比較\n平均の差\nq 値\n判定\nMusic vs Nap\n0.009\n0.047\n有意差なし\nMusic vs Stretch\n0.135\n0.732\n有意差なし\nNap vs Stretch\n0.143\n0.779\n有意差なし\n表5-6: 休憩方法ごとの統計量\n休憩方法\n平均変化量\n標準偏差\nMusic\n0.89\n0.45\nNap\n0.88\n0.47\nStretch\n1.02\n0.30\n5.3\nアンケートによる主観的評価\nアンケートによる主観的評価を行った．本実験では，休憩方法に対する集中力向上の効\n果，設定時間の適切性，リラックス効果についてアンケート調査を実施した．その結果を\n以下に示す．\n5.3.1\n各休憩方法の効果についての評価\n• 音楽を聴く: 音楽を聴いた後に集中力が向上したと感じた被験者は，「とてもそう思\nう」が20 ％，「そう思う」が70 ％であり，肯定的な回答が全体の90 ％を占めた．一\n方で，「どちらでもない」と回答した被験者は10 ％にとどまった．\n• ストレッチをする: ストレッチを行った後に集中力が向上したと感じた被験者は，「と\nてもそう思う」が20 ％，「そう思う」が60 ％で，肯定的な回答は全体の80 ％を占\n28\nめた．「どちらでもない」と「そう思わない」の回答がそれぞれ10 ％ずつ見られた．\n• 仮眠をとる: 仮眠をとった後に集中力が向上したと感じた被験者は，「とてもそう思\nう」が40 ％，「そう思う」が60 ％であり，全体で100 ％が肯定的な評価を示した．\n5.3.2\n各休憩方法の設定時間についての評価\n• 音楽を聴く: 音楽を聴く際の設定時間について適切だと感じた被験者は，「とてもそ\nう思う」が30 ％，「そう思う」が30 ％であったが，「そう思わない」と回答した被\n験者が40 ％に上り，時間設定に課題があることが示唆された．\n• ストレッチをする: ストレッチの設定時間について適切だと感じた被験者は，「とて\nもそう思う」が40 ％，「そう思う」が40 ％で，肯定的な回答が全体の80 ％を占め\nた．一方で，「そう思わない」とする回答が20 ％見られた．\n• 仮眠をとる: 仮眠の設定時間について適切だと感じた被験者は，「とてもそう思う」が\n20 ％，「そう思う」が40 ％であり，合わせて60 ％が肯定的であった．しかし，「そ\nう思わない」と回答した被験者も40 ％を占め，時間設定の改善が必要であることが\n示された．\n5.3.3\n各休憩方法のリラックス効果\n• 音楽を聴く: 音楽を聴いた際にリラックスできたと回答した被験者は，「とてもそう\n思う」が50 ％，「そう思う」が50 ％であり，全員が肯定的な評価を示した．\n• ストレッチをする: ストレッチを行った際にリラックスできたと回答した被験者は，\n「とてもそう思う」が40 ％，「そう思う」が50 ％で，肯定的な回答が全体の90 ％を\n占めた．「どちらでもない」とする回答が10 ％見られた．\n• 仮眠をとる: 仮眠をとった際にリラックスできたと回答した被験者は，「とてもそう\n思う」が50 ％，「そう思う」が40 ％で，肯定的な回答が全体の90 ％を占めた．「ど\nちらでもない」と回答した被験者が10 ％存在した．\n5.3.4\n集中を妨げる要因\n休憩中に集中を妨げる要因として，以下の項目が挙げられた．\n• 「特になし」と回答した被験者が40 ％と最も多かった．\n29\n• 一方で，「仮眠の体勢が寝づらかった」が20 ％，「明るくて仮眠が取りづらかった」\nが10 ％といった仮眠中の物理的な要因が指摘された．\n• その他，「スマートウォッチのバイブレーションが気になった」(10 ％)，「音楽の時\n間が短すぎた」(10 ％)，「休憩時間が適切でなかった」(10 ％) といった設定上の課題\nも挙げられた．\n以上のアンケート結果から主観的評価においては，「仮眠をとる」がもっとも集中力回復\nに効果的な休憩方法であり，次に「ストレッチをする」，「音楽を聴く」の順に効果的な休\n憩方法だと言える．\n5.4\n考察\n解析結果から，今回の実験で有意差が出なかった原因として，以下の要因が考えられる．\n• サンプルサイズの不足: 被験者数が10 人と少ないため，統計的検出力が不足してい\nる可能性があります．サンプルサイズを増やすことで，ばらつきを減少させ，有意\n差が検出される可能性が高まります．\n• 個人差の影響: LF/HF 比は個人ごとに基準値や変化量が異なるため，被験者間のば\nらつきが効果を埋もれさせる可能性があります．同じ被験者を繰り返し測定するデ\nザインを採用することで，この影響を軽減できます．\n• LF/HF 比の特性: LF/HF 比は感受性が高く，短時間の休憩では大きな変化が生じに\nくい場合があります．測定方法や他の補助指標の併用を検討する必要があります．\n• 休憩方法の効果に対する個人差: 各休憩方法における集中力向上の評価では，「とて\nもそう思う」と「そう思う」の回答が多数を占めた一方で，「どちらでもない」また\nは「そう思わない」とした回答が一定数存在しました．このことから，休憩方法の\n効果には被験者間で個人差が大きく，統一的な効果を示すことが困難だったと推測\nされます．\n• 休憩時間の適切性に関する評価: 休憩時間について，「音楽を聴く」「ストレッチをす\nる」「仮眠をとる」のいずれにおいても設定時間が適切でなかったとする回答が見ら\nれました．特に，「音楽を聴く」では「そう思わない」が40%，「仮眠をとる」では\n「そう思わない」が40%に上っており，休憩時間が効果を十分に発揮するのに適して\nいなかった可能性があります．\n• 休憩中の環境要因: 休憩中に集中を妨げる要因として，「仮眠の体勢が寝づらかった」\n「明るくて仮眠が取りづらかった」といった物理的要因や，「音楽の時間が短すぎた」\n30\n「休憩時間が適切でなかった」といった設定上の問題が挙げられました．これらの要\n因が，被験者における休憩効果を低下させたと考えられます．\n• リラックス効果のばらつき: リラックス効果に関する評価では，肯定的な回答が多\nかったものの，「どちらでもない」とした回答も見られました．このことは，被験者\nが感じるリラックス効果に個人差があることを示しており，それが集中力向上の主\n観的評価に影響を及ぼした可能性があります．\n5.5\n実験の改善点\n以上を踏まえ，以下の改善点が考えられる．\n• サンプルサイズの拡大: 被験者数を増加させ，統計的検出力を向上させる．例えば，\n20 人以上の被験者を対象とすることで，効果のばらつきを軽減し，有意差を検出す\nる可能性を高める．\n• 個人差を考慮したデザイン: 被験者間の個人差を軽減するため，同じ被験者に複数\nの休憩方法を繰り返し適用し，その前後でLF/HF 比を測定する「被験者内デザイン」\nを採用する．また，事前に被験者の基礎的な自律神経指標を測定し，個人差を補正\nする方法を検討する．\n• 休憩時間の再設定: 各休憩方法において，効果が最大限発揮される適切な時間設定\nを再検討する．例えば，仮眠の時間を20 分程度に延長し，音楽の聴取時間もリラッ\nクス効果を十分に引き出す長さに調整する．\n• 環境要因の統一: 仮眠時の環境を改善するため，明るさを調整可能な部屋や快適な\n仮眠姿勢を取れる椅子やリクライニングを用意する．音楽の音量や選曲を統一する\nことで，外的要因を最小限に抑える．\n• 測定指標の追加: LF/HF 比以外にも，主観的なストレスレベルや集中力の自己評価\nアンケートを併用し，多角的に休憩方法の効果を評価する．また，他の生理指標(心\n拍数，血圧，皮膚電気活動など) の測定も検討する．\n• 休憩方法のバリエーション拡大: 仮眠や音楽以外のリラックス手法(深呼吸法，瞑想\nなど) を取り入れ，それぞれの効果を比較することで，より適切な休憩方法を特定\nする．\n• リラックス効果の個別最適化: 被験者ごとに最適な休憩方法を事前に調査するプロ\nセスを導入し，個別に最適化された休憩を提供する．例えば，リラックス効果が高\nい音楽のジャンルや仮眠の時間を事前に確認する．\n31\nこれらの改善点を反映することで，実験結果の精度や信頼性が向上し，より明確な効果\nを示す結果が得られることが期待される．\n32\n第6章\n結論\n6.1\nまとめ\n本論文では，「音楽を聴く」「ストレッチをする」「仮眠をとる」の３種類の休憩方法に\nおいてどれが最も集中力回復に効果的かの検証を実施した．\n6.1.1\n集中度についての定量的評価\n被験者のLF/HF スコアを用いてt 検定，分散分析・多重比較を行った結果，統計的に有\n意な差があるとは言えなかった．本研究は，10 人と少ないサンプル数での実験だったた\nめ，被験者によってLF/HF スコアの増減の差が激しく，より多くの被験者からLF/HF ス\nコアを取ることでより精度の高い実験結果となり，有意な差が見られる可能性もあると考\nえられる．\n6.1.2\n集中度についての定性的評価\n被験者に対してアンケートを行った結果，「仮眠をとる」「ストレッチをする」「音楽を\n聴く」の順で集中度が回復したという結果になった。数値としては有意差が見られなかっ\nたが，被験者自身の感覚としては休憩方法によって集中度の回復に差が見られる結果と\nなった。\n6.2\n今後の展望\n本研究では，休憩方法が集中力向上に及ぼす効果を評価したが，有意差が見られなかっ\nた。この結果には，個人差，設定時間，環境要因，リラックス効果のばらつきが関与して\nいる可能性が示唆された。今後の展望としては，休憩方法ごとの効果を最大化するために\n最適な時間設定を再検討し，事前調査やパイロット実験を通じて適切な休憩時間を特定す\nる必要がある。また，仮眠時の体勢や光量，音楽の再生時間や音量の調整など，快適な休\n憩環境を提供するための物理的・設定上の問題の改善が求められる。さらに，休憩効果に\nは個人差が大きいことが示唆されているため，クラスター分析や多変量解析を用いたデー\nタ分析を通じて被験者の特性ごとに適した休憩方法を明らかにし，より多様なバックグラ\n33\nウンドを持つ対象者を取り入れることで汎用性や適応性を高めることも重要である。加え\nて，生理的データと主観的評価を統合的に解析することで休憩効果を客観的に評価し，そ\nの科学的裏付けを強化する必要がある。これらの改善を通じて，休憩方法と集中力向上の\n関係をより明確にし，効果的な休憩設計を実現することで，オフィス環境や業務パフォー\nマンスの向上に貢献できると期待される。\n34\n謝辞\n本稿の執筆に際し，ご指導していただいた青山学院大学理工学部情報テクノロジー学科\nロペス・ギヨーム教授，木村正子助手に深く感謝申し上げます．研究室の設備・機器や\n研究環境を整えて下さった他，研究目標を達成するためのアドバイスやアイデアを提供し\nて下さり，研究を最後まで取り組むことができました．そして，問題解決のために様々な\n視点でのご意見や励ましをいただいたロペズ研究室の先輩方，実験に参加していただきま\nした被験者の皆様に深く感謝いたします．\n35\n質疑応答\n戸辺　義人　情報テクノロジー学科　教授\nQ\n休憩前後のLF/HF 変化量を出したということは、作業が終わってすぐにLF/HF を\n計測したということですか。\nA\n実験が始まってから終了するまで心拍数を測り続け、実験後に休憩前のデータと休\n憩後のデータを抜き出し変化量を求めました。\n戸辺　義人　情報テクノロジー学科　教授\nQ\nLF/HF の値はどのような時間変化を示したか。\nA\nなだらかではなく明らかな変化が見られました。具体的には、休憩に入ったタイミ\nングで明LF/HF は低下し、また作業を再開するとLF/HF は上昇する結果でした。\n戸辺　義人　情報テクノロジー学科　教授\nQ\nLF/HF の値になだらかではなく明らかな変化が見られたということは、休憩方法に\n関わらず作業をやめればLF/HF 値は下がるという仮説も立てられますか。\nA\n本実験では、何もせずに過ごす休憩を比較していないので確実な結論は出せません\nが、その可能性もあると考えます。\n36\n伊藤雄一情報テクノロジー学科教授\nQ\nLF の周期はどれくらいで設定されていますか。\nA\n本実験は5 分で設定しました。\n伊藤雄一情報テクノロジー学科教授\nQ\n20 分間のデスクワークはどれくらいの負荷になっていますか。\nA\nより現実的な設定で行うために各被験者に自由なデスクワークを行ってもらったた\nめ作業の負荷については把握できていません。また、自由なデスクワークを行って\nもらうに当たり、前半の20 分と後半の20 分がそれぞれ同程度の負荷のものという\n条件のみを課しました。\n伊藤雄一情報テクノロジー学科教授\nQ\n仮眠、音楽、ストレッチ以外に被験者が実際に普段行っている休憩方法も比較基準\nとして行いましたか。\nA\n本実験では、仮眠、音楽、ストレッチ以外の休憩方法は行えていないので、今後の\n改善点として参考にさせていただきます。\n山下優依情報テクノロジー学科戸辺研究室助手\nQ\n被験者のコンディションが実験結果に大きく関係すると思うのですが、被験者が実\n験前に何を行っていたかのアンケートは取りましたか。\nA\nそれについてのヒアリングは行えていません。ただ、3 日間とも同じ時間帯に実験\nを行ったのでよほど1 日のルーティーンが決まっていない人でない限り、3 日間の\nコンディションに大きな差はないと考えます。\n37\n参考文献\n[1] DigitalKnowledge 株式会社：オンデマンド学習に関するレポート，https:\n//www.digital-knowledge.co.jp/wp-content/uploads/2023/11/\nreport_ondemand.pdf. (参照日2025/01/28).\n[2] 全国大学生活協同組合連合会：第59 回学生生活実態調査報告，https://www.\nunivcoop.or.jp/press/life/report.html. (参照日2025/01/28).\n[3] ダイヤモンド・オンライン：休憩の取り方で、生産性とウェルビーイングは劇的に\n向上する，https://dhbr.diamond.jp/articles/-/9732?page=2. (参照日\n2025/01/23).\n[4] 閏間莉央，小池崇文ほか：ウェアラブルデバイスによる心拍・視線移動の測定を用\nいた歩行時における異性への好意判定手法の検討，第79 回全国大会講演論文集，\nVol. 2017, No. 1, pp. 979–980 (2017).\n[5] Japan,\nM.:\n会社での休憩時間の過ごし方\n～リフレッシュ方法6 選\n～\n，https://www.manpowergroup.jp/staff/column/career/\nhow-to-spend-rest-time-in-company.html. (参照日2025/01/23).\n[6] 三木隆裕，寺田努，前田俊幸，唐澤鵬翔，安達淳，塚本昌彦ほか：休憩時間の過ごし\n方が作業パフォーマンスに及ぼす影響の調査，研究報告ユビキタスコンピューティ\nングシステム(UBI)，Vol. 2018, No. 3, pp. 1–8 (2018).\n[7] 吉村梓，打越大成，岩本健嗣，松本三千人ほか：観光地評価のための腕時計型心拍\nセンサによる内面状態推定手法，第77 回全国大会講演論文集，Vol. 2015, No. 1, pp.\n131–132 (2015).\n[8] 浦野健太，廣井慧，米澤拓郎，河口信夫ほか：ドキドキをセンシングして可視化す\nるLED ライティングデバイス，マルチメディア, 分散協調とモバイルシンポジウム\n2248 論文集，Vol. 2020, pp. 1616–1622 (2020).\n[9] 青木渉，桐山伸也ほか：心拍センシングに基づくマルチモーダル体感状況理解，第\n79 回全国大会講演論文集，Vol. 2017, No. 1, pp. 161–162 (2017).\n38\n[10] 角田啓介，江口佳那，吉田和広，渡部智樹，水野理ほか：心拍と呼吸を用いたコンテ\nンツ視聴による気分変化の推定: コメディ視聴における検討，情報処理学会論文誌コ\nンシューマ・デバイス& システム(CDS)，Vol. 7, No. 1, pp. 44–52 (2017).\n[11] 東海林綾，竹下怜花，横窪安奈ほか：心拍変動解析を用いた動画鑑賞の客観的評価，\nマルチメディア, 分散協調とモバイルシンポジウム2021 論文集，Vol. 2021, No. 1,\npp. 1149–1154 (2021).\n[12] 野本大雅，花田祥典，横窪安奈ほか：脈拍変動を用いたスポーツ観戦時における情\n動の客観的評価，マルチメディア, 分散協調とモバイルシンポジウム2105 論文集，\nVol. 2020, pp. 588–592 (2020).\n[13] 田島真沙美ほか：母親のストレスマネジメントに関する研究: 腕時計型ウェアラブル\nデバイスを用いて，紀要，Vol. 58, pp. 35–47 (2023).\n[14] 伊村一成，後藤佑介，酒井晃二，小原雄，田添潤，三浦寛司，廣田達哉，内山彰，乃\n村能成ほか：ウェアラブルセンサデバイスを用いた医師のストレス推定手法の提案，\n研究報告電子化知的財産・社会基盤(EIP)，Vol. 2021, No. 5, pp. 1–8 (2021).\n[15] 鈴木伊織，佐藤文明ほか：ウェアラブル端末により検知した心拍変動に基づくスト\nレス推定，研究報告コンピュータセキュリティ(CSEC)，Vol. 2020, No. 30, pp. 1–7\n(2020).\n[16] 宮崎裕哉，杉村博ほか：オンライン受講者向け集中力持続支援システム，第84 回全\n国大会講演論文集，Vol. 2022, No. 1, pp. 269–270 (2022).\n[17] 森川聖也，吉野孝ほか：スマートグラスを用いた視界の制限による集中力向上手法\nの提案，第85 回全国大会講演論文集，Vol. 2023, No. 1, pp. 197–198 (2023).\n[18] 菅野真功，小林稔ほか：プレゼンテーション時における心拍フィードバックによる緊\n張緩和手法の検討，研究報告デジタルコンテンツクリエーション(DCC)，Vol. 2019,\nNo. 45, pp. 1–6 (2019).\n[19] 河端留奈，相川大吾，江木啓訓ほか：脚部動作計測に基づいて学習活動の休憩を提\n案する手法，第82 回全国大会講演論文集，Vol. 2020, No. 1, pp. 55–56 (2020).\n[20] 濱谷尚志，内山彰，東野輝夫ほか：種々のセンサを併用した集中度センシング法の\n検討，研究報告高度交通システムとスマートコミュニティ(ITS)，Vol. 2015, No. 10,\npp. 1–6 (2015).\n39\n[21] 川崎勇佑，横窪安奈ほか：勉強中における心拍数を用いた精神状態度合の推定，マ\nルチメディア, 分散協調とモバイルシンポジウム2021 論文集，Vol. 2021, No. 1, pp.\n936–942 (2021).\n[22] 徳田博行，高橋雄太，音田恭宏，金谷勇輝，荒川豊，安本慶一ほか：アイウェアによ\nる集中力センシングに基づいた行動変容システムの設計，2017 年度情報処理学会関\n西支部支部大会講演論文集，Vol. 2017 (2017).\n[23] 橘卓見，岡部浩之，佐藤未知，福嶋政期，梶本浩之：PC 作業時の集中力向上のため\nの作業用壁紙，Interaction (2012).\n[24] 小松勇輝，下条和暉，西山勇毅，瀬崎薫ほか：腕時計型ウェアラブルデバイスを用い\nた会話時間計測手法の構築に向けて，第84 回全国大会講演論文集，Vol. 2022, No. 1,\npp. 219–220 (2022).\n[25] 千葉桂也，阿部昭博，市川尚，富澤浩樹，工藤彰ほか：ウェアラブルデバイスを活用\nした健康増進型野外ミュージアム鑑賞支援システムの提案，第79 回全国大会講演論\n文集，Vol. 2017, No. 1, pp. 807–808 (2017).\n[26] 吉田崇洋，井口信和，野田潤ほか：ユーザロケーションに応じた腕時計型ウェアラ\nブルデバイスによる動的な情報提示システムの開発，第78 回全国大会講演論文集，\nVol. 2016, No. 1, pp. 409–410 (2016).\n[27] 岡部真子，佐々木新介：腕時計型ウェアラブルデバイスでのセルフモニタリングが\n地域住民の歩数と睡眠時間にもたらす効果，ヒューマンケア研究学会誌，Vol. 13,\nNo. 1, pp. 1–7 (2022).\n[28] 本多祥子，太田洋一：一般人による寺院での坐禅が自律神経機能に与える影響，健\n康レクリエーション研究= Japanese journal of health recreation，Vol. 17, pp. 23–31\n(2022).\n[29] 後藤和彦，相川大吾，江木啓訓ほか：脚部動作計測に基づく学習効果向上のための休\n憩提案システム，第83 回全国大会講演論文集，Vol. 2021, No. 1, pp. 129–130 (2021).\n[30] 荻野隼：休憩時の運動が生体情報と集中力に及ぼす影響，日本知能情報ファジィ学\n会ファジィシステムシンポジウム講演論文集第36 回ファジィシステムシンポジ\nウム，日本知能情報ファジィ学会，pp. 35–36 (2020).\n[31] 渡部貴史，小林未来：休憩時の音楽聴取が作業遂行に及ぼす影響，新潟医療福祉学\n会誌，Vol. 20, No. 1, pp. 39–39 (2020).\n40\n[32] 看護roo：心電図波形の名称と意味～幅と高さ｜心電図とはなんだろう，https:\n//www.kango-roo.com/learning/1708/ (2015). (参照日2022/1/7).\n[33] ストレスと自律神経の科学：ストレス指標のHF，LF とは？，http://hclab.\nsakura.ne.jp/stress_novice_LFHF.html. (参照日2022/6/22).\n[34] Work, H.: 集中力を高める休憩の取り方：生産性を上げるためのポイント，https:\n//note.com/hiromoneywork/n/n1202c250d8e0. (参照日2025/01/23).\n[35] G-NAP: 仮眠の効果～15～20 分程度の仮眠で疲労回復効果～，https://g-nap.\ncom/post-987/. (参照日2025/01/23).\n[36] Surveroid: t 検定とは～データ分析手法の基本～，https://surveroid.jp/\nmr-journal/data_analysis_method/5Xiot. (参照日2025/01/23).\n[37] JMP:\n一元分散分析（ANOVA）とは，https://www.jmp.com/ja_jp/\nstatistics-knowledge-portal/one-way-anova.html.\n(参照日\n2025/01/23).\n[38] Radi-Toko: 3 群以上パラメトリックデータをTukey 法で多重比較する，https://\nradi-toko.com/statistic-tukey/. (参照日2025/01/23).\n41\n",
        "chunks": [
            "B2024_MiyoshiNakajima. B2024_MiyoshiNakajima. B2024_MiyoshiNakajima",
            "青山学院大学理工学部\n情報テクノロジー学科\n２０２４年度卒業研究論文\n心拍変動を用いた学生の勉強に対\nする集中力向上手法の比較\n２０２５年１月２８日提出\n指導教員ロペズ・ギヨーム　教授\n提出者学生番号　氏名\n１５８２１０６６中島弥芳\n青山学院大学 理工学部 情報テクノロジー学科 \n2024（令和6）年度卒業論文要旨 \n- 1 - \n \n心拍変動を用いた学生の勉強に対する集中力向上手法の\n比較 \n \n中島 弥芳（15821066） \nロペズ研究室 \n \n1．はじめに \nコロナウイルス蔓延を境にオンライン授業を導入す\nる大学は増加した．それにより，学生の学習環境は多\n様化しており，学習の効率を高めるためには，集中力\nを向上させる方法の検討が重要となっている．実際に，\n全国大学生活協同組合連合会の調査では学習について\nの悩みを抱える大学生は約半数を占める結果になった． \nそこで，本研究では学生のデスクワークに焦点を当\nて，心拍変動指標を用いて，仮眠(Nap)，音楽(Music)，\nストレッチ(Stretch)の3 種類の休憩方法がデスクワー\nクにおける集中力回復に与える影響を比較することを\n",
            "Stretch)の3 種類の休憩方法がデスクワー\nクにおける集中力回復に与える影響を比較することを\n目的とした． \n2．関連研究 \n過去の研究では，ウェアラブルデバイスを活用した\n心拍変動解析によるストレス評価や集中力向上に関す\nる手法が多く提案されている．例えば，浦野らは，心\n拍数に同期した光変化による心理状態の可視化が提案\nされた[3]．さらに，三木ら[4]は，心拍データや瞬きの\n回数といった生体情報を用いて休憩時間の過ごし方の\n違いが作業パフォーマンスに与える影響を定量的に評\n価した．彼らは，「寝る」「スマートフォンを見る」「運\n動をする」など複数の休憩方法が集中力や作業パフォ\nーマンスに与える効果を調査し，心拍変動を活用した\n新たな評価方法を提案している． \n3．休憩方法の回復効果検証実験 \n本研究はこれらの知見を基に，学生のデスクワーク\nにおける集中力回復に最適な休憩方法を特定すること\nを目指し，三木らが示した実験の改善点を参考にして\n休憩方法を選定した．10 名の大学生(男9 人，女1 人)\nを対象に，静かな実験室において，以下の手順でデー\nタを収集した． \n1. \n安静状",
            " 人，女1 人)\nを対象に，静かな実験室において，以下の手順でデー\nタを収集した． \n1. \n安静状態で心拍変動を3 分間測定する． \n2. \n20 分間の自由デスクワークをして，心拍変動\nの記録を行う． \n3. \n仮眠(10 分)，音楽(3 分)，ストレッチ(3 分)の\nいずれかの休憩を行う． \n4. \n各休憩方法の後に再び20 分間のデスクワー\nクをして，心拍変動を記録． \n休憩方法の順番による影響を排除するため，1 日1 種\n類の休憩方法をランダムに選び，3 日間にわたって実\n験を実施した．効果の比較には先行研究と同様に心拍\n変動指標のLF/HF を用いた．LF は低周波成分，HF\nは高周波成分を示し，LF/HF 値が高い場合はストレス\nや緊張状態，低い場合はリラックス状態を示す．本実\n験では，先行研究[4]を参考にしてLF/HF 値が2．0 以\n上を「集中している状態」\n「ストレス状態」と定義した． \n4．休憩方法の回復効果の評価結果 \n4-1． 心拍変動指標の評価 \n本研究では，3 種類の休憩方法(Music，Nap，Stretch)\nがLF/HF の変化量に与える影響を評価",
            "，3 種類の休憩方法(Music，Nap，Stretch)\nがLF/HF の変化量に与える影響を評価するため，休\n憩前後のLF/HF の平均値を比較した．t 検定および一\n元配置分散分析(ANOVA)を実施した結果，休憩方法間\nにおけるLF/HF 比の変化量には統計的に有意な差は\n確認されなかった．表1 に分散分析の結果，表2 にt\n検定の結果をまとめた． \n表1：分散分析の結果 \n    \n \n \n \n表2：t 検定の結果 \n \nさらに，Tukey HSD 検定による多重比較を行った\nが，すべての休憩方法の組み合わせにおいて統計的な\n有意差は見られなかった(Music vs Nap のq 値 = \n0.047， Nap vs Stretch のq 値 = 0.779， Music vs \nStretch のq 値 = 0.732)．しかし，休憩方法ごとの\nLF/HF の平均変化量は，Music が0.89（標準偏差 = \n0.45），Nap が0.88(標準偏差 = 0.47)，Stretch が\n1.02(標準偏差 = 0.30)であり，平均的な傾向として\nStretch がやや高",
            "etch が\n1.02(標準偏差 = 0.30)であり，平均的な傾向として\nStretch がやや高い結果を示した．また，標準偏差に着\n目しても\nNap(0.47) ，Music(0.45) に比べて\nStretch(0.30)が最も小さく，結果のばらつきが少ない．\n表1 は多重比較検定の結果，表2 は休憩方法ごとの統\n計量をそれぞれ示す． \n表3：多重比較検定の結果(TukeyHSD) \n   \n \n \n図1：休憩方法ごとの統計量 \n4-2． アンケートによる主観的評価 \n本実験後，休憩方法の集中力向上効果や設定時間の適\n切性，リラックス効果に関するアンケートを実施した．\nその結果，「仮眠をとる」が最も効果的と評価され，全\n回答者が肯定的だった．「ストレッチをする」や「音楽\nを聴く」も高評価を得ており，特に「ストレッチをす\nる」はリラックス効果で90％が肯定的だった．一方で，\n「音楽を聴く」と「仮眠をとる」の設定時間が短いと\nの意見や，仮眠時の体勢や環境条件が集中の妨げにな\nるとの指摘があった． \n5．まとめ \n本研究では，Nap，Music，Stretch の3 つの休憩方\n法の効",
            "があった． \n5．まとめ \n本研究では，Nap，Music，Stretch の3 つの休憩方\n法の効果を比較したが，解析結果では有意差が見られ\nなかったものの，LF/HF の平均変化量はStretch が一\n番高いことからことから，Music，Nap よりも集中力\n回復に効果的であると言える．また，標準偏差で\nStretch の数値が最小だったことから，Stretch が他の\n休憩方法よりも効果の安定性が高く個人間の影響を受\nけにくいと考えられる．有意差が見られなかったのは\n以下の要因が関係していると考えられる． \n1. \n被験者数が10 人と少なく，統計的検出力が不\n足していたこと． \n2. \nLF/HF 比が個人ごとに異なる基準値や変化量\nを持つため，個人差が効果を埋もれさせた可能\n性があること． \n3. \nLF/HF 比の感受性が高い一方で，短時間の休\n憩では十分な変化を検出しにくかったことが\n挙げられる． \nさらに，音楽や仮眠の設定時間が適切でなかったと\nの評価や，休憩中の環境要因(仮眠の体勢や室内の明る\nさなど)が休憩効果を低下させた可能性も指摘された．\n本研究の結果を踏まえ",
            "因(仮眠の体勢や室内の明る\nさなど)が休憩効果を低下させた可能性も指摘された．\n本研究の結果を踏まえ，今後は，サンプルサイズの拡\n大，休憩時間や環境要因の改善，さらには主観的評価\nに加えて他の生理指標を併用した多角的な効果検証が\n必要であると考える． \n参考文献 \n[1] \nDigital Knowledge 株式会社：オンデマンド学習に\n関するレポート． https://www.digital-knowledge．\nco．jp/wp-content/uploads/2023/11/report_ondemand．\npdf （参照日 2025/01/28） \n[2] \n全国大学生活協同組合連合会：第59 回学生．生\n活\n実\n態\n調\n査\n報\n告\nhttps://www.univcoop.or.jp/press/life/report.html \n（参照日 2025/01/28） \n[3] \n浦野健太，廣井慧，米澤拓郎，河口信夫ほか： ド\nキドキをセンシングして可視化する LED ライ\nティングデバイス，マルチメディア， 分散協調\nとモバイルシンポジウム2248 論文集， Vol. 202",
            "ングデバイス，マルチメディア， 分散協調\nとモバイルシンポジウム2248 論文集， Vol. 2020， \npp.1616–1622 (2020)． \n[4] \n三木隆裕，寺田努，前田俊幸，唐澤鵬翔，安達淳，\n塚本昌彦ほか： 休憩時間の過ごし方が作業パフ\nォーマンスに及ぼす影響の調査，研究報告ユビキ\nタスコンピューティングシステム (UBI)， Vol. \n2018， No.3， pp.1–8 (2018). \n目次\n第1 章\n序章\n1\n1.1\n研究背景. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n1\n1.1.1\nコロナウイルスが授業形態に与えた影響. . . . . . . . . . . . . . .\n1\n1.1.2\nリモートワークによる集中力の低下\n. . . . . . . . . . . . . . . . .\n1\n1.1.3\n集中力向上に対する休憩の必要性. . . . . . . . . . . . . . . . . . .\n1\n1.2\n研究目的. . . . . .",
            " . . . . . . . . . . . . . .\n1\n1.2\n研究目的. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n2\n1.3\n本論文の構成. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n3\n第2 章\n関連研究\n4\n2.1\nウェアラブルデバイスを活用した生体データの解析と応用に関する研究. .\n4\n2.2\nストレス・集中力評価と向上に関する研究. . . . . . . . . . . . . . . . . .\n6\n2.3\nロケーションや環境対応型の情報提示システム\n. . . . . . . . . . . . . . .\n11\n2.4\n健康促進および休憩の効果. . . . . . . . . . . . . . . . . . . . . . . . . . .\n12\n2.5\n先行研究のまとめ. . . . . . . . . . . . . . . . . . . . . . . ",
            "のまとめ. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n13\n第3 章\n本研究で用いる技術や用語について\n14\n3.1\n心拍間隔と心拍変動\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n14\n3.2\n自律神経系\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n14\n3.2.1\n交感神経\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n15\n3.2.2\n副交感神経. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n15\n3.3\n心拍変動解析. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n16\n3.3.1\n時間領",
            ". . . . . . . . . . . . . . . . . . .\n16\n3.3.1\n時間領域解析. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n16\n3.3.2\n周波数領域解析. . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n17\n3.4\n集中力の定義. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n18\n第4 章\n集中力回復のための休憩方法比較検証\n19\n4.1\n実験目的. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n19\n4.1.1\n実験概要\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n19\n4.2\n実験概要及び手順. . . . . . . . . . . . . . ",
            " . . .\n19\n4.2\n実験概要及び手順. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n19\n4.3\n集中力回復の評価に用いる指標. . . . . . . . . . . . . . . . . . . . . . . .\n21\ni\n4.3.1\n定量効果について\n. . . . . . . . . . . . . . . . . . . . . . . . . . .\n21\n4.3.2\n定性的評価について\n. . . . . . . . . . . . . . . . . . . . . . . . . .\n23\n第5 章\n比較検証実験の結果及び考察\n26\n5.1\n心拍変動指標のt 検定による評価\n. . . . . . . . . . . . . . . . . . . . . . .\n26\n5.2\n心拍変動指標の一元配置分散分析・多重比較による評価\n. . . . . . . . . .\n27\n5.3\nアンケートによる主観的評価\n. . . . . . . . . . . . . . . . . ",
            "3\nアンケートによる主観的評価\n. . . . . . . . . . . . . . . . . . . . . . . . .\n28\n5.3.1\n各休憩方法の効果についての評価. . . . . . . . . . . . . . . . . . .\n28\n5.3.2\n各休憩方法の設定時間についての評価\n. . . . . . . . . . . . . . . .\n29\n5.3.3\n各休憩方法のリラックス効果\n. . . . . . . . . . . . . . . . . . . . .\n29\n5.3.4\n集中を妨げる要因\n. . . . . . . . . . . . . . . . . . . . . . . . . . .\n29\n5.4\n考察. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n30\n5.5\n実験の改善点. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n31\n第6 章\n",
            ". . . . . . . . . . . . . . . . . . . . .\n31\n第6 章\n結論\n33\n6.1\nまとめ. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n33\n6.1.1\n集中度についての定量的評価\n. . . . . . . . . . . . . . . . . . . . .\n33\n6.1.2\n集中度についての定性的評価\n. . . . . . . . . . . . . . . . . . . . .\n33\n6.2\n今後の展望\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n33\n謝辞\n35\n参考文献\n38\nii\n第1章\n序章\n本章では，社会的な背景をもとに研究の位置付けを明確にする．1.1 節では，研究背景\nとしてコンテンツ視聴における現状と課題について述べる．1.2 節では，背景に挙げた課\n題を踏まえた本研究の目的を定義する．1.3 節では，本論文の構成について",
            "2 節では，背景に挙げた課\n題を踏まえた本研究の目的を定義する．1.3 節では，本論文の構成について述べる．\n1.1\n研究背景\n1.1.1\nコロナウイルスが授業形態に与えた影響\n日本における大学(国公立大学，私立大学) では，2020 年の新型コロナウイルス感染症\nの拡大後，急速にオンデマンド授業の導入が進んだ．Digital Knowledge 株式会社の調査\nによると，2023 年11 月時点で，オンデマンド授業を日常的に取り入れている大学が過半\n数を占めている[1]．\n図1-1: （[1] より引用)\n1.1.2\nリモートワークによる集中力の低下\n全国大学生活協同組合連合会が9，873 人の大学生に2023 年11 月に実施した調査によ\nれば，約半数の大学生が学習に関する悩みを抱えていることが明らかになっている．同\n調査では，学生の生活全般について幅広く調査が行われており，授業や課題に対するモチ\nベーションの低下や，学習時間の確保の難しさ，オンライン授業の増加による集中力の低\n下が主な課題として挙げられている[2]．\n図1-2: 大学生に対する「日常生活の中で悩んでいることや気に",
            "主な課題として挙げられている[2]．\n図1-2: 大学生に対する「日常生活の中で悩んでいることや気にかかっていること」の質問に対す\nる回答結果【％】（[2] より引用)\n1.1.3\n集中力向上に対する休憩の必要性\n現代の労働環境において，長時間の集中作業は生産性を低下させるだけでなく，精神的\nおよび肉体的疲労を招く原因となる．Diamond Harvard Business Review の記事によれば，\n1\n適切なタイミングでの休憩は，集中力の持続や業務効率の向上に不可欠であるとされてい\nる．以下に，そのポイントをまとめる[3]．\n• 集中力の持続には限界がある\n集中力には自然な限界があり，特に連続的な作業では注意力が低下する「集中力の\n波」が発生する．この波を意識し，適切なタイミングで休憩を取ることが，集中力を\n持続させるカギであると指摘されている．例えば，25 分作業し5 分休憩を取る「ポ\nモドーロ・テクニック」は，短期的な集中力を最大化する方法として広く実践され\nている．\n• 休憩が脳に与えるポジティブな影響\n休憩には，脳をリフレッシュさせる効果がある．短時間でも意識的に作業か",
            "憩が脳に与えるポジティブな影響\n休憩には，脳をリフレッシュさせる効果がある．短時間でも意識的に作業から離れ\nることで，脳が過剰なストレスから解放され，次の作業に向けたリカバリーが可能\nになる．また，特定の休憩方法（仮眠，軽い運動，リラクゼーションを目的とした\n音楽など）が脳の神経活動を活性化し，注意力や判断力の向上に寄与することが報\n告されている．\n• 適切な休憩が生産性を高める\n長時間働き続けることが必ずしも高い生産性をもたらさない点が強調されている．\nむしろ，定期的な休憩を挟むことで，集中力がリセットされ，より高い効率で作業\nを再開できる．休憩を取らずに作業を続ける場合，最終的にはエラーやミスの増加，\n創造性の低下が発生しやすくなる．\n• 休憩の方法とタイミングの重要性\n記事では，どのような休憩が有効かについても議論されている．特に，短時間の仮眠\nやストレッチ，音楽を聴くことなどは，集中力の回復に効果的であるとされる．ま\nた，休憩のタイミングを個々人の集中力のリズムに合わせて調整することが推奨さ\nれている．\n1.2\n研究目的\n1.1 節で述べたように，コロナウイルスの影響でリモート",
            "ことが推奨さ\nれている．\n1.2\n研究目的\n1.1 節で述べたように，コロナウイルスの影響でリモートワークが増加することで多く\nの社会人が仕事に集中できていないという悩みを抱えている．このことから，コロナウイ\nルス以後デスクワークで集中力を保つことが難しいと感じている人が増加していると予\n想される．この問題を解決するためには，デスクワークに効果的な休憩方法を特定し，社\n会人に限らずデスクワークをするすべての人に集中力の回復を図る．そこで本研究では，\nテレワーク環境下での集中力低下に対し，複数の休憩方法の効果を比較・検証を行う．\n2\nまた，本研究では，効果的な休憩方法を選定するため，既存の知見および先行研究( [4])\nの結果を考慮した．具体的には，「音楽を聴く」，「仮眠をとる(10 分)」，「ストレッチをす\nる」の3 つを休憩方法として採用した．先行研究において「飲食をする」休憩方法は顕著\nな効果が確認されなかったため本研究では除外した．また，ManpowerGroup 株式会社に\nよるウェブサイトを基に[5]「音楽を聴く」という先行研究で扱われていない休憩手法を\n新たに追加し，「運動",
            "ウェブサイトを基に[5]「音楽を聴く」という先行研究で扱われていない休憩手法を\n新たに追加し，「運動」に関しては負荷が軽く身体的疲労が少ない「ストレッチ」に変更\nした．さらに，先行研究[6] では仮眠時間の延長の必要性が指摘されていたため，本研究\nでは先行研究よりも長い仮眠時間を設定し，その効果を最大化することを目指した．\n1.3\n本論文の構成\n第1 章では，本論文の研究背景，研究目的，及び本論文の構成について述べた．第2 章\nでは，先行研究について述べる．第3 章では，専門用語，システム概要について述べる．\n第3 章では，専門用語，システム概要について述べる．第4 章では，実験概要について述\nべる．第5 章では，実験結果，考察について述べる．\n3\n第2章\n関連研究\n本章では，に関する研究について述べる．2.1 節ではウェアラブルデバイスを活用した\n生体データの解析と応用に関する研究，2.2 節ではストレス・集中力評価と向上に関する\n研究,2.3 節ではロケーションや環境対応型の情報提示システムに関する研究，2.4 節では\n健康促進および休憩の効果の研究について述べる．\n2.1\nウェア",
            "システムに関する研究，2.4 節では\n健康促進および休憩の効果の研究について述べる．\n2.1\nウェアラブルデバイスを活用した生体データの解析と応用に関する\n研究\n閏間らは, メガネ型ウェアラブルデバイス（JINS MEME）とスマートウォッチ（Apple\nWatch）を用い, 歩行中の心拍と視線活動を測定することで, 異性への好意を判定する手法\nを提案した．被験者に街を散策してもらい, 視線活動や心拍数のデータを収集した後, まば\nたきの回数と心拍数が増加する際の映像を分析した結果, 被験者の好みの異性が映る場合\nにこれらの変化が確認され, 心拍数と視線活動が好意と一定の相関を持つ可能性が示唆さ\nれた．また, 移動平均フィルタを用いてノイズを除去したデータの分析では, まばたきの回\n数と心拍数の相関係数が0.4295 を示し, 心拍とまばたきの増加が好意を抱く状況で顕著に\nなることが明らかになった．一方で, 好意以外の要因によってデータに影響が及ぶ場合も\n確認され, さらなる検証が必要であるが, 簡易な装置による好意の自動判定システムの可能\n性が示された[4]．\n吉村らは, ウェアラブ",
            "あるが, 簡易な装置による好意の自動判定システムの可能\n性が示された[4]．\n吉村らは, ウェアラブルデバイスを活用し, 観光地の評価を旅行者の内面状態から推定す\nる手法を提案した．Android Wear を用いて安静状態および歩行中の心拍数を計測し, その\n精度を筋電式心拍計（my Beat）と比較した結果, 運動の影響を除外すれば信頼性が高いこ\nとが確認された．また, 観光地での内面状態を想定し, 動画視聴中の心拍数を分析したとこ\nろ, 心拍数が高い状態を平均的に維持する特性が見られ, 運動中とは異なる変化が観測され\nた．この結果から, 心拍センサを活用した内面状態の推定が可能であることが示唆され, 観\n光地評価における個別ニーズへの対応や観光地の改善に活用できる可能性が示された[7]．\n浦野らは，ウェアラブルデバイスで計測した心拍数に基づき, 心拍信号に同期した光の\n変化を用いて心理的緊張や興奮をリアルタイムで可視化する図2-1 に示されているような\nLED デバイスを提案した．既存の心拍計測デバイスが提示情報をユーザ個人に限定する\nのに対し, 本デバイスは発光パターンを用いて",
            "既存の心拍計測デバイスが提示情報をユーザ個人に限定する\nのに対し, 本デバイスは発光パターンを用いて心拍情報を視覚的に共有可能とすることで,\n4\n他者とのインタラクションを促進する．具体的には, 光学式心拍センサとマイコンを組み\n合わせ, ユーザの心拍数に応じた発光パターンを生成し, 心理状態を他者に伝える仕組みを\n開発した．実験では, 心拍波形を忠実に反映した発光パターンが心理状態の共有を可能に\nすることが確認され, ゲームやイベント, 医療分野での応用可能性が示唆された[8]．\n図2-1: 光学センサ，デバイス本体，LED の構成（[8] より引用）\n青木らは, 個人に適応した住空間サービスを実現するため, 心拍数を含むマルチモーダル\nデータを用いて体感温度や気分の変化を分析する手法を提案した．高齢者や学生を対象に\n行った住空間実験では, 心拍数や温湿度データ, 気分などの主観的・客観的情報を収集し,\nそれらを統合した分析ツールを用いて体感状況の変化パターンを解析した．その結果, 体\n感温度と心拍数の変化には一定の相関があり, 心拍数データが体感温度の推定や快適性向\n上に寄与する可",
            "\n感温度と心拍数の変化には一定の相関があり, 心拍数データが体感温度の推定や快適性向\n上に寄与する可能性が示された．これにより, 住空間の自動制御や個人化サービスの設計\nへの応用が期待される[9]．\n角田らは，心拍数と呼吸数の長期的な変動の類似性を利用し, コンテンツ視聴による気\n分変化を非侵襲的に推定する手法を提案した．従来の主観評価法や顔表情解析法におけ\nるユーザ拘束やノイズの影響を克服するため, コメディ動画視聴中の心拍・呼吸データを\n収集し, フィルタ処理により動作ノイズを除去したデータを分析した．その結果, 心拍数\nと呼吸数の同期が気分変化と密接に関連することが確認され, この手法の有効性が示され\nた．提案手法は, コンテンツ提供者による効果的な作品評価や個人の視聴体験向上に寄与\nする可能性を持つ[10]．\n図2-2: 提案手法図（[10] より引用）\n東海林らは, スマートウォッチを用いて動画鑑賞中の心拍変動を解析し, 鑑賞者の感情を\n客観的に評価する手法を提案した．従来の主観的なアンケート評価や複数のセンサを使用\nした負荷の大きい方法に代わり, 心拍変動データと機械学習モ",
            "観的なアンケート評価や複数のセンサを使用\nした負荷の大きい方法に代わり, 心拍変動データと機械学習モデルを組み合わせて, 鑑賞者\n5\nの感情を自動推定する実験を行った．実験部屋の全体図を図2-3 に示す．ホラー動画を対\n象とした評価では,F1 値が90 ％以上という高精度を達成し, 視聴体験を基にした動画推薦\nや評価システムへの実用化可能性が示唆された[11]．\n図2-3: 実験部屋の全体図（[11] より引用）\n野本らは, スポーツ観戦中の情動を脈拍変動（PRV）を用いて客観的に評価する手法を\n提案した．Android Wear 搭載のウェアラブルデバイスを用いて心拍データを取得し,KNN\nアルゴリズムを活用して観戦中の喜びや興奮, 平静さなどを分類するモデルを構築した．\n評価実験では, 喜びや興奮の感情を80 ％上の精度で分類できることが確認され, スポーツ\n観戦時の心理的変化をデータに基づいて理解する手法として有効性が示された．今後は,\n観戦体験の向上やイベント設計への応用が期待される[12]．\n図2-4: 実装した脈拍間隔ノイズ処理手法を説明するコメント付き脈拍変動PSD プロ",
            "れる[12]．\n図2-4: 実装した脈拍間隔ノイズ処理手法を説明するコメント付き脈拍変動PSD プロット（[12] よ\nり引用）\n2.2\nストレス・集中力評価と向上に関する研究\n田島らは，腕時計型ウェアラブルデバイスを活用し,98 名の母親を対象に心理的ストレ\nス反応と心拍変動や睡眠などの生理的データの関連性を分析するとともに, ストレス対処\n行動の変化を検討した．4 週間のデータ収集期間の結果, 心理的ストレス反応と生理的デー\nタの間に有意な相関が確認されたものの, 個人差が大きく共通のパターンは得られなかっ\nた．一方, ストレス対処行動においては, 調査期間後に高ストレス群でポジティブな再評価\n6\n型の対処行動が顕著に増加した．この変化は, ウェアラブルデバイスを通じたストレス認\n識とデータの可視化が自己管理意識を高めたことが要因と考えられる．これらの結果は,\n育児支援としてのストレスマネジメントツールの可能性を示唆している[13]．\n伊村らは, 医療現場における医師のストレス推定手法として, ウェアラブルセンサデバイ\nスを活用して心拍変動や睡眠データを解析する方法を提案した．7 ",
            "法として, ウェアラブルセンサデバイ\nスを活用して心拍変動や睡眠データを解析する方法を提案した．7 名の医師を対象に最大\n8 週間データを収集し, 心拍数の低周波成分と高周波成分の比率や睡眠深度データを基に\n疲労やストレスを推定した．結果, 医師のストレス状態を高精度で推定可能であり, ストレ\nス軽減のための休息の必要性を判断できることが示された．本手法は, 医療現場の過酷な\n労働環境における医師の健康管理や医療事故の未然防止に寄与する可能性がある[14]．\n図2-5: リング型ウェアラブルデバイス[14] よ\nり引用）\n図2-6: 腕時計型ウェアラブルデバイス（[14]\nより引用）\n鈴木らは, 長距離運転中のドライバーが適切な休憩を取るためのストレス推定システム\nを提案した．スマートウォッチで取得した心拍変動データを高速フーリエ変換し, 低周波\n成分と高周波成分の比率を基にストレス状態を分類するモデルを構築した．9 名の被験者\nによる実験では, サポートベクタマシンを用いたストレス状態の分類精度が73 ％に達し,\n運転中のストレス評価に実用性があることが示唆された．本手法は, ドライ",
            "の分類精度が73 ％に達し,\n運転中のストレス評価に実用性があることが示唆された．本手法は, ドライバーの事故防\n止や安全運転支援への応用が期待される[15]．\n宮崎らは, オンライン授業における集中力持続を目的としたシステムを提案した．Node-\nRED を用いて構築されたシステムは,5 分ごとに受講者の顔写真を撮影し, 顔の有無に基づ\nいて集中力を推測する．集中力が低下した場合には, 光やアロマといった刺激を自動的に\n提供し, 注意を引き戻す仕組みを導入した．実験結果から, 本システムがオンライン授業中\nの受講者の集中力を効果的に維持し, 学習効率の向上に寄与する可能性が確認された[16]．\n7\n図2-7: システム構成図（[16] より引用）\n森川らは, スマートグラスを活用して複合現実空間に仮想の壁を表示し, 周囲の視野を制\n限することで学習や作業時の集中力を向上させる手法を提案した．これまでの研究では,\n視野や周辺情報を制御して集中を高める手法が検討されていたが, 固定された設備を必要\nとすることが多かった．本研究では, スマートグラスを使用することで携帯性を向上させ,\n自習",
            "備を必要\nとすることが多かった．本研究では, スマートグラスを使用することで携帯性を向上させ,\n自習室のような集中環境をどこでも再現可能にした．開発されたシステムでは, ユーザー\nの視界に仮想的な壁を表示し, 周囲の人や物からの気を散らす要素を排除する．実験によ\nり, ユーザーが集中して作業に取り組める環境を簡易かつ効果的に提供できることが示さ\nれ, この手法の教育や作業支援への応用可能性が示唆された[17]．\n図2-8: システム構成図（[17] より引用）\n菅野らは, 大勢の聴衆の前でのプレゼンテーション時に生じる緊張を緩和するため, 心拍\n情報のフィードバック手法を提案した．視覚, 聴覚, 触覚の3 種類の虚偽心拍情報を用い, そ\nれぞれのフィードバックが発表者に与える影響を比較検証した．具体的には, 視覚フィー\nドバックでは心拍数のグラフ表示, 聴覚では心拍音の再生, 触覚では心拍に応じた圧力デバ\nイスを用いた．実験では発表者が最も知覚しやすいのは視覚的フィードバックである一\n方, 触覚と聴覚も緊張を緩和する効果が認められた．本手法は, プレゼンテーションスキル\nの向上や緊張の",
            ", 触覚と聴覚も緊張を緩和する効果が認められた．本手法は, プレゼンテーションスキル\nの向上や緊張の制御を支援するシステム設計に有用である可能性が示された[18]．\n河端らは, 焦電センサを用いて学習中の脚部動作を非接触で計測し, 精神疲労が蓄積した\nタイミングで適切な休憩を提案するシステムを開発した．22 名の被験者を対象に, 脚部動\n8\n作の頻度と精神疲労の関係を分析し, 動作計測の正確性を評価した結果, 目視計測との一致\n率は89.2 ％に達した．さらに, 脚部動作の変化に基づき休憩を提示するシステムを提案し,\n個別に適応した休憩タイミングの提示が学習効率向上に寄与することが示唆された．本手\n法は, 集中力の維持と疲労軽減を目的とした学習支援の有効なアプローチを提供する[19]．\n濱谷らは, スマートフォン内蔵センサやウェアラブルセンサを用いて, タイピングや動画\n視聴などの行動中に取得した加速度, 心拍数, 皮膚導電率などのデータを分析し, 集中度を\n推定する手法を提案した．1 名の被験者を対象に40 分間のデータ収集を行い, 集中行動と\nセンサデータの相関を分析した結果, 集",
            "名の被験者を対象に40 分間のデータ収集を行い, 集中行動と\nセンサデータの相関を分析した結果, 集中時には特定の生理指標に特徴的な変化が見られ\nることが確認された．本手法は, 集中度の可視化とパフォーマンス向上のためのシステム\n開発に活用可能であり, 教育や職場環境での応用が期待される[20]．\n図2-9: システム図（[20] より引用）\n川崎らは, スマートウォッチを用いて勉強中の心拍数データを収集し, 集中, 眠気, 疲労と\nいった精神状態の度合いを連続的に推定するシステムを提案した．被験者2 名を対象にし\nた実験では, 心拍数の変化パターンから各状態を識別するモデルを構築し,F1 値が78 ％以\n上の精度で分類が可能であることを確認した．短期的な休憩提案と長期的なフィードバッ\nクによる学習効率向上が期待され, 教育分野での応用可能性が示された[21]．\n徳田らは，オフィス環境における不適切な割り込みを軽減し, 適切なタイミングでのコ\nミュニケーションや休憩を誘発することで行動変容を促進することを目的として, ユーザ\nの集中度を３段階で可視化するシステム(図2-10) を提案し",
            "容を促進することを目的として, ユーザ\nの集中度を３段階で可視化するシステム(図2-10) を提案した．具体的には,JINS MEME\nというアイウェアを利用してユーザの集中度を瞬きの頻度と姿勢の安定性から正確に計\n測し, スマートIoT 照明のPhilips hue によって集中度を「フロー状態」「集中状態」「集中\nしていない状態」の3 段階で可視化するシステム(図2-11) である．従来のマウスやキー\nボード利用に基づく手法では対応が難しかった読書や思考中の状態についても, 本システ\nムは正確に計測可能であり, 生産性向上や疲労軽減への貢献が見込まれる．今後の課題と\nしては, 提案システムの実用性評価, 他デバイスとの組み合わせによる精度向上, 集中度の\n9\n提示方法の拡張が挙げられる[22]．\n図2-10: 提案システムの概要（[22] より引用）\n図2-11: フロー状態(赤)，集中状態(黄)，集中していない状態(青)（[22] より引用）\n橘らは,PC 作業中の集中力向上を目的として, 視線を作業エリアに誘導する視覚刺激の\n効果について検証を行った．視覚刺激として,「白地」「",
            "として, 視線を作業エリアに誘導する視覚刺激の\n効果について検証を行った．視覚刺激として,「白地」「黒地」「内向き縞模様」「外向き縞模\n様」「ランダムドット」の5 種類の背景パターンを設定した(図2-12)．被験者には, これら\nの背景を表示したPC 画面上で計算問題を解答させ, その際の瞬目頻度, 音に対する反応時\n間, 正答率, 主観的集中度を測定した．なお, 実験は図2-13 に示すような環境で行われた．\n実験の結果, 内向き縞模様の視覚刺激が他の条件と比較して最も高い集中力向上効果を示\nした．具体的には, 瞬目頻度の減少, 計算問題の正答率の向上, 主観的集中度の上昇が確認\nされた．一方, 外向き縞模様やランダムドットでは集中度が低下する傾向が見られた．こ\nれらの結果から, 内向き縞模様の視覚刺激が作業エリアへの注意を促進し, 集中力を高める\n有効な手段であることが示唆された．\n10\n図2-12: 5 種類の背景パターン（[23] より引用）\n図2-13: 実験環境（[23] より引用）\n2.3\nロケーションや環境対応型の情報提示システム\n小松らは, 社会的接触の頻度を客観的に",
            "り引用）\n2.3\nロケーションや環境対応型の情報提示システム\n小松らは, 社会的接触の頻度を客観的に計測し, 健康状態や行動変容の促進に役立てるた\nめ, 腕時計型ウェアラブルデバイスを活用した会話時間計測手法を提案した．市販のデバ\nイスに搭載されたマイクと機械学習モデルを組み合わせ, 環境音と会話音を分類し, 信頼度\n50 ％以上の場合を会話時間として記録する「OHANASHI」アプリを開発した．実験では,\n雑音と会話の判別精度が85 ％以上であることを確認し, 被験者7 名を対象に実際の生活環\n境で2 週間計測を実施した．その結果, 時刻ごとの会話パターンが可視化され, 計測データ\nが社会的接触への意識向上に寄与する可能性が示唆された[24]．\n千葉らは, ウェアラブルデバイスを活用し, 野外ミュージアムにおける健康増進と鑑賞体\n験の向上を目的としたシステムを提案した．心拍数やカロリー消費量を測定するリストバ\nンド型デバイスとスマートフォンを連携させ, 来館者が森林ウォーキングをしながら彫刻\n11\nや植物の情報を動的に得られる仕組みを構築した．プロトタイプの開発では, 季節や時間\n帯",
            "ら彫刻\n11\nや植物の情報を動的に得られる仕組みを構築した．プロトタイプの開発では, 季節や時間\n帯に応じて情報を提供する機能や,SNS で感想を共有する機能も搭載した．調査結果から,\n森林セラピーや運動情報に対する高い需要が確認され, 来館者の満足度向上に寄与する可\n能性が示された[25]．\n吉田らは, スマートウォッチの消費電力削減とユーザ位置情報に基づく動的な情報提示\nを目的としたシステムを開発した．ジオフェンシング技術と音波を用いた位置推定手法\nを組み合わせ, エリアとブロック単位で位置を特定し, その場に関連する情報を自動的に提\n示する仕組みを構築した．実験では, 部屋単位で情報を提示する精度が100 ％に達し, 提示\nまでの時間は1 分以内が96 ％を占めた．また, エリア内外での切り替えにより, スマート\nウォッチのバッテリー消費を最小限に抑えられることが確認された[26]．\n2.4\n健康促進および休憩の効果\n岡部らは, 地域住民30 名を対象に腕時計型ウェアラブルデバイスを用いたセルフモニ\nタリングが歩数と睡眠時間に与える影響を検証した．1 週目は通常活動を記録するコン",
            "を用いたセルフモニ\nタリングが歩数と睡眠時間に与える影響を検証した．1 週目は通常活動を記録するコント\nロール期間,2 週目はデバイスによるセルフモニタリング期間とし,VAS を用いて健康意識\nの変化を調査した．結果, 男性では歩数が平均7987 歩から9529 歩へと有意に増加したが,\n女性では有意差は見られなかった．また, 睡眠時間に有意な変化はなかったものの, 男女と\nもに健康意識は向上した．これにより, セルフモニタリングが男性の歩数増加や健康意識\n向上に寄与する可能性が示され, 男女間での指導方法の差異の必要性が考察された[27]．\n本多らは, 寺院での坐禅が自律神経活動に及ぼす影響を明らかにすることを目的とした．\n健常な成人11 名を対象に, 僧侶の指導下で15 分間の坐禅を実施し, 自律神経活動を測定し\nた．結果, 坐禅後に心拍数の低下やSDNN とLnTP の有意な増加が観察され, 中程度の効果\n量を示した．これにより, 坐禅が交感神経および自律神経機能を一過的に活性化する可能\n性が示唆された．本研究は坐禅が健康増進活動として有効であることを一般人に示す初め\nての実証的",
            "る可能\n性が示唆された．本研究は坐禅が健康増進活動として有効であることを一般人に示す初め\nての実証的研究である[28]．\n後藤らは, 脚部動作時間を基に学習者の疲労を推定し, 適切な休憩タイミングを提案する\nシステムを開発した．20 名の大学生を対象に, 休憩を取り入れた実験群と連続学習を行う\n対照群に分け,90 分間の映像講義後にテストを実施した．結果, 提案システムによる休憩タ\nイミングの提示は集中力の維持と学習成果の向上に寄与した．脚部動作を非接触で計測す\nる本手法は, 学習環境を妨げずに適応可能な効果的な休憩管理手段を提供する[29]．\n荻野らは, 長時間作業の合間に運動を組み込むことで集中力と作業効率を向上させる効\n果を検証した．被験者は「休憩なし」「運動なし」「運動あり」の3 条件で校正作業を実施\nし, 生体情報と課題正答率を比較した．結果, 運動あり条件では正答率が最も高く, 運動が\n12\n集中力維持に有効であることが示された．本手法は短時間の運動を効果的に取り入れるこ\nとで, 作業パフォーマンスを向上させる可能性を示唆している[30]．\n渡部らは, 休憩時にクラシック音",
            "で, 作業パフォーマンスを向上させる可能性を示唆している[30]．\n渡部らは, 休憩時にクラシック音楽を聴取することで休憩後の作業遂行能力や主観的気\n分がどのように変化するかを検証した．35 名の大学生を対象に, クラシック音楽聴取条件\nとノイズ音聴取条件で符号課題を実施した結果, クラシック音楽条件での作業量が有意に\n多く, 集中力と活気が向上した．本研究は, 音楽が作業効率や気分の改善に与える影響を定\n量的に示すものであり, 効果的な休憩法の設計に寄与する[31]．\n三木らは, オフィスワーカーの休憩時間の過ごし方が作業パフォーマンスに及ぼす影響\nを調査し, 効果的な休憩手法を提案することを目的とした．被験者9 名に対し, 計算課題の\n実施前後で休憩時間を6 種類（「寝る」「スマートフォンを見る」「運動をする」「タバコを\n吸う」「コーヒーを飲む」「食べ物を食べる」）に分け, 心拍センサと眼電位センサを用いて\n生体情報を計測した．ストレス指標（LF/HF 値）と瞬きの回数を分析し, 休憩後の作業効\n率を評価した結果,「寝る」「運動をする」「タバコを吸う」が特にパフォーマンス向上に\n効",
            "憩後の作業効\n率を評価した結果,「寝る」「運動をする」「タバコを吸う」が特にパフォーマンス向上に\n効果的であり,LF/HF 値が高い状態での作業効率が向上することが確認された．一方, 課題\nの順番による慣れや個人差がデータに影響する可能性も指摘され, さらなる検証が必要で\nある．本研究は, 休憩方法が作業効率やストレス軽減に与える影響を示し, 個人に適した休\n憩設計の基礎を提供するものである[6]．\n2.5\n先行研究のまとめ\nこれまでの研究では, デスクワークに特化した効果的な休憩方法について, 完全に結論\n付けられていない．そこで本実験では、デスクワークの作業を想定し,LF/HF(Low Fre-\nquency/High Frequency) を用いて休憩前後の集中度回復を計測し, その効果を比較・検討\nする．\n13\n第3章\n本研究で用いる技術や用語について\n本章では測定に用いる技術や用語について述べる．\n3.1\n心拍間隔と心拍変動\n心臓は，収縮と拡張を周期的に繰り返すことで生命を維持している．この活動を細胞レ\nベルで見ると，脱分極と活動電位，再分極と静止電位の繰り返しにより制御され",
            "している．この活動を細胞レ\nベルで見ると，脱分極と活動電位，再分極と静止電位の繰り返しにより制御されている．\n図3-1 は正常な心電図を示している．PP 間隔は，心房の興奮が始まってから次の興奮が\n始まるまでの時間を指し，RR 間隔は，心室の収縮から次の収縮までの時間を指す．正常\nな状態では，これらの間隔は規則正しく周期的である．また，心室が1 分間に収縮する回\n数を心拍数と呼ぶ．RR 間隔を基に心室の興奮周期を求めることで，心拍数を算出するこ\nとが可能である[32]．\n図3-1: 正常心電図( [32] より引用)\n3.2\n自律神経系\n自律神経系は，身体の内臓機能や循環器，呼吸器，消化器，腺分泌などを無意識的かつ\n自動的に調節する神経系であり，主に交感神経系と副交感神経系の2 つの主要な構成要素\nから成る．これら2 つの系は，互いに拮抗的に働きながら，身体の恒常性(homeostasis) を\n維持する役割を果たす．交感神経系は，ストレスや緊急事態において活性化され，心拍数\n14\nの増加，血圧の上昇，気管支の拡張，血糖値の上昇など，身体を活動的な状態に導く「闘\n争・逃走反応(ﬁght",
            "加，血圧の上昇，気管支の拡張，血糖値の上昇など，身体を活動的な状態に導く「闘\n争・逃走反応(ﬁght-or-ﬂight response)」を担う．一方，副交感神経系は，心拍数の減少，消\n化管の活動促進，エネルギー貯蔵の促進など，リラックス状態や回復を促進する「休息と\n消化(rest-and-digest)」を担う．自律神経系の中枢は主に視床下部や延髄に位置し，外部環\n境や内部の代謝的要求に応じて活動を動的に調整する．また，自律神経系の機能は，心拍\n変動(heart rate variability，HRV) や皮膚電位反応(electrodermal activity，EDA) などの生\n理学的指標を通じて評価される．これにより，ストレスや精神的負荷の状態を客観的に把\n握することが可能である．自律神経系の異常は，高血圧や慢性疾患，精神疾患など多岐に\nわたる健康問題と関連し，その調節機構の理解は臨床医学や健康科学において重要な課題\nとなっている．\n3.2.1\n交感神経\n交感神経系は，自律神経系の一部であり，身体がストレスや緊急事態に直面した際に活\n性化される「闘争・逃走反応(ﬁght-",
            "神経系の一部であり，身体がストレスや緊急事態に直面した際に活\n性化される「闘争・逃走反応(ﬁght-or-ﬂight response)」を担う神経系である．この系は，脊\n髄の胸髄および腰髄(T1-L2) から起始する神経節前線維(preganglionic ﬁbers) と，交感神\n経幹または遠位の神経節に位置する神経節後線維(postganglionic ﬁbers) で構成される．交\n感神経系の主要な役割は，身体を活動的かつ即応的な状態にすることであり，これには心\n拍数の増加，血圧の上昇，気管支の拡張，血糖値の上昇，瞳孔の拡大などが含まれる．交\n感神経系の神経伝達は，神経節前線維から分泌されるアセチルコリン(acetylcholine) を介\nして開始され，神経節後線維からは主にノルアドレナリン(norepinephrine) が放出される．\nこのノルアドレナリンは，心臓や血管，呼吸器などの標的組織に作用し，各器官の機能を\n調節する．また，副腎髄質も交感神経系の一部とみなされ，ストレス時にはアドレナリン\n(adrenaline) とノルアドレナリンを血中に分泌する．このように交感",
            "レス時にはアドレナリン\n(adrenaline) とノルアドレナリンを血中に分泌する．このように交感神経系は，緊急時や\n身体的・精神的負荷がかかった状態において，エネルギー供給を増強し，適応的な応答を\n促進する役割を果たす．しかし，交感神経系の過剰な活性化は，高血圧やストレス関連疾\n患などの健康問題を引き起こす可能性があるため，その活動の調節は重要である．\n3.2.2\n副交感神経\n副交感神経系は，自律神経系の一部であり，主に身体の「休息と消化(rest-and-digest)」\nに関連する活動を調節する．副交感神経系は，中枢神経系の脳幹部(迷走神経や顔面神経，\n舌咽神経を含む) および仙髄(S2-S4) から起始する神経節前線維と，標的器官の近傍や内\n部に位置する神経節後線維で構成される．副交感神経系の主要な機能は，エネルギーの保\n存と回復に貢献することである．これには，心拍数の減少，血圧の低下，消化液分泌の促\n15\n進，腸管の蠕動運動の活性化，瞳孔の収縮などが含まれる．これらの調整により，副交感\n神経系は身体をリラックス状態に導き，回復や再生を促進する．たとえば，食事後に消化\n活動を",
            "り，副交感\n神経系は身体をリラックス状態に導き，回復や再生を促進する．たとえば，食事後に消化\n活動を活発化させる一方で，身体の活動性を抑制してエネルギーを節約する．副交感神経\n系の神経伝達では，神経節前線維および神経節後線維のいずれにおいても，アセチルコリ\nンが主要な神経伝達物質として機能する．アセチルコリンは，標的組織のムスカリン受容\n体(muscarinic receptors) に結合し，特定の生理機能を誘導する．副交感神経系は，交感神\n経系と協調的に働くことで，身体の恒常性を維持する役割を果たす．しかし，副交感神経\n系の異常な機能低下は，消化不良や慢性的なストレス障害などの健康問題を引き起こす可\n能性がある．\n3.3\n心拍変動解析\n前述にあるように，周期的な変動には自律神経系に関係する呼吸と同期したゆらぎ，お\nよび血圧と同期したゆらぎが反映されているため，自律神経系の活動が心拍間隔の周期的\nな変動に影響を与えているという関係性が示されている．つまり，心拍変動を解析するこ\nとによって，自律神経系の活動状態を把握することが可能である．\n3.3.1\n時間領域解析\n時間領域解析は，心拍",
            "て，自律神経系の活動状態を把握することが可能である．\n3.3.1\n時間領域解析\n時間領域解析は，心拍間隔(RR 間隔) の変動を時間の観点から解析する手法であり，主\nに自律神経系の活動や心拍の規則性を評価するために用いられる．この解析では，心拍間\n隔を座標上にプロットし，その変動の大きさや傾向を観察する．具体的には，縦軸と横軸\nの単位がいずれも「時間」となり，縦軸には心拍間隔を示すミリ秒[ms]，横軸には経過時\n間を示す秒[s] を使用する．この方法では，時間軸上の変化として心拍間隔の増減を視覚\n的に捉えることができ，心拍の安定性やリズムの乱れを直感的に評価することが可能であ\nる．また，時間領域解析では，平均心拍間隔やその標準偏差，隣接する心拍間隔の差分に\n基づく統計指標(例：SDNN，RMSSD，pNN50) を算出することにより，心拍変動の特徴\nを定量的に評価する．\n特にこの手法は，心拍間隔が時間とともにどのように変化するかを明確に把握すること\nに適しており，ストレス，疾患，運動負荷などの影響を解析する際に広く応用されている．\n一方で，時間領域解析は周波数特性や周期性の詳細な解析に",
            "などの影響を解析する際に広く応用されている．\n一方で，時間領域解析は周波数特性や周期性の詳細な解析には向いていないため，必要に\n応じて周波数領域解析や非線形解析と組み合わせることが推奨される．\n16\n3.3.2\n周波数領域解析\n周波数領域解析は，心拍間隔の変動特性を周波数の観点から解析する方法であり，自律神\n経系の活動を詳細に評価するために広く用いられる．この解析手法では，時系列データと\nして得られる心拍間隔の変動を周波数帯域ごとに分離し，各帯域のエネルギーや寄与度を\n分析する．波形の周波数成分を分離するには，フーリエ変換（FFT: Fast Fourier Transform）\nやウェルチ法などの信号処理技術を用いる．\n具体的には，心拍間隔の変動を周波数として表現し，そのパワースペクトル密度（Power\nSpectral Density，PSD）を求めることで，交感神経系および副交感神経系の活動状態を定\n量的に評価できる．\n• 高周波数帯域（HF: High Frequency，0.15～0.40 Hz）：副交感神経（迷走神経）の\n活動を反映し，呼吸と連動する心拍変動成分を示す．\n•",
            "5～0.40 Hz）：副交感神経（迷走神経）の\n活動を反映し，呼吸と連動する心拍変動成分を示す．\n• 低周波数帯域（LF: Low Frequency，0.05～0.15 Hz）：交感神経および副交感神経\nの双方が関与する心拍変動成分を示すが，特に交感神経の影響が強いとされる．\nこれらの帯域のパワーを比較することで，交感神経と副交感神経のバランスや，交感神経\nの相対的な活動量を評価できる．特に，LF/HF 比は交感神経優位性を示す重要な指標であ\nり，ストレス，疲労，精神的緊張の評価に活用される．\n周波数領域解析は，心拍変動の周期性を明確に捉えられるため，時間領域解析では見え\nにくい情報を補完する．加えて，特定の周波数成分を取り出して解析できることから，自\n律神経系の活動状態をより精緻に理解する手法として有用である．\n図3-2: 心拍変動時系列データのパワースペクトル( [33] より引用)\n17\n3.4\n集中力の定義\n一般的に，LF/HF 値は2 以上の時，人はストレス状態にあり，LF/HF 値が2 未満の時は\nリラックス状態にある．そこで，本実験では集中している状態をストレスを感じて",
            "HF 値が2 未満の時は\nリラックス状態にある．そこで，本実験では集中している状態をストレスを感じている状\n態(リラックスしていない状態) と定義することとした[6]．\n18\n第4章\n集中力回復のための休憩方法比較検証\n本章では, 集中力を回復させるための休憩方法比較検証実験について述べる．評価実験\nにおける被験者は実験説明を受け，実験に対する同意書による同意をもって，実験に参加\nする．先行研究( [6]) では，仮眠，運動(ジョギング)，喫煙が作業パフォーマンスの向上\nに寄与することが示されている．しかし，運動に関しては負荷が過大であると結論付けら\nれていたため，本研究ではストレッチ( [34]) に置き換えた．また，仮眠に関しては，先行\n研究における5 分という短時間設定では十分な効果が得られないと考え，休憩効果を高め\nるために10 分へと延長した．仮眠の時間設定はgirafeenap のウェブサイト( [35]) を参考\nにした．さらに，喫煙は非喫煙者に適用できないため，その代替として，ManpowerGroup\n株式会社のウェブサイト( [5]) を基に，音楽を聴くという新たな",
            "して，ManpowerGroup\n株式会社のウェブサイト( [5]) を基に，音楽を聴くという新たな休憩方法を採用した．こ\nの手法は先行研究では検討されておらず，本研究において新たな視点として取り入れた．\n4.1\n実験目的\n4.1.1\n実験概要\n実験では，集中力を回復させるために最適な休憩方法を比較するために3 つの休憩方法\nで集中力の推移を比較検証する．\n4.2\n実験概要及び手順\n本実験は，静かで空調設備も整った部屋で行い，実験中は被験者以外いない作業に集中\nしやすい環境で行った．今回の被験者は，大学生・大学院生の10 人とする．\n心拍数測定の実験手順\n実験は次の手順で実施する．\n1. 被験者に椅子に座った状態でスマートウォッチを装着してもらい，アプリ(RRI) を\n起動してもらう．\n2. アプリ上で測定開始ボタンを押してもらい，そこから3 分の安静時間をおく．\n19\n3. 安静後，被験者には自由に20 分間作業を実施してもらう．\n4. デスクワーク後，各休憩をとってもらう．\n5. 休憩後には再度20 分間の自由な作業を行ってもらう．この際，休憩前後での集中度\nの比較をするため，休憩",
            "憩後には再度20 分間の自由な作業を行ってもらう．この際，休憩前後での集中度\nの比較をするため，休憩前後では同じ分量の作業を行ってもらう．\n6. 作業終了後にアプリ上の測定終了ボタンを押してもらう．\n7. 被験者には3 回の実験後にアンケートの記入を実施してもらう．\n図4-1 は実験の手順を表した図である．休憩方法は，好きな音楽を聴く，軽いストレッ\nチをする，仮眠するのいずれかを行う．また，休憩時間は仮眠の場合のみ10 分で，他の\n2 つの休憩は3 分とする．各被験者この3 種類の休憩方法でそれぞれ実験を行う際，集中\n力への影響を考え，1 日1 種類を3 日間かけて行った．\n図4-1: 実験の手順\nまた，図4-2，図4-3 は実験中の作業中の様子であり，図4-4 は仮眠の休憩中，図4-5 は\nストレッチの休憩中，図4-6 は音楽を聴く休憩中の様子である．\n20\n図4-2: 実験風景\n図4-3: 実験風景\n図4-4: 休憩風景(仮眠)\n図4-5: 休憩風景(ストレッチ)\n図4-6: 休憩風景(音楽)\n4.3\n集中力回復の評価に用いる指標\n4.3.1\n定量効果について\nt 検定とは，ある仮",
            "景(音楽)\n4.3\n集中力回復の評価に用いる指標\n4.3.1\n定量効果について\nt 検定とは，ある仮説が正しいかどうかを判断するための仮説検定の手法の一つであり，\nt 分布を利用して分析を行う．t 分布は，最も一般的な分布である正規分布に基づいている\n21\nが，母集団(データ全体) に関する分散が分からない場合に使用される統計的分布である．\nこの分布は，母分散が未知であるときに，標本データを基に母集団の特性を推定する際に\n役立つ．そのため，t 分布は標本サイズが小さい場合や母集団の分布が完全には分からな\nい場合でも頻繁に使用される．t 検定の目的は，2 つのグループの平均値の違いが偶然に\nよるものか，それとも統計的に有意な違いがあるかを判断することである．この検定で\nは，まず「帰無仮説」と呼ばれる仮説を立てる．帰無仮説は，調べたい仮説とは反対の内\n容を主張するもので，例えば「2 つのグループの平均値には差がない」というものが典型\n的である．t 検定では，帰無仮説が正しいと仮定した場合のデータの発生確率(p 値) を計\n算し，このp 値を事前に設定した有意水準と比較する．もしp 値が有意",
            "ータの発生確率(p 値) を計\n算し，このp 値を事前に設定した有意水準と比較する．もしp 値が有意水準よりも低けれ\nば，帰無仮説を否定し，「偶然では説明できない差がある」と判断する．これにより，元々\nの仮説(対立仮説) が支持されることになる．一般的にt 値とは，2 つのグループ間の平均\n値の差が統計的に意味があるかどうかを示す指標である．t 値が大きいほど，2 つの平均\n値の間に差がある可能性が高くなる．p 値は，得られたデータが「帰無仮説が正しいと仮\n定した場合」に観測される希少性を表す．p 値が小さいほど，観測された結果が偶然によ\nる可能性が低いと考えられる．有意水準は，p 値がどの程度小さいときに「統計的に有意\nである」と判断するかを示す基準である．一般的に，有意水準は0.05 に設定されること\nが多い．これは，5 ％以下の確率でしか起こらない事象を「偶然ではない」と見なすこと\nを意味する( [36])．また，分析の手順は以下のようになる．\n1. 帰無仮説を設定する．\n2. 実際のデータからt 値を計算し，そこからp 値を求める．\n3. p 値を有意水準(通常は0.05) と",
            "際のデータからt 値を計算し，そこからp 値を求める．\n3. p 値を有意水準(通常は0.05) と比較する．p 値が有意水準よりも小さい場合，帰無仮\n説を棄却する．これにより，仮説(対立仮説) が統計的に有意であると判断される．\n一元分散分析(ANOVA:Analysis of Variance) は，3 つ以上のグループ間の平均値の差を\n統計的に検証するための手法であり，単一の独立変数(因子) が従属変数に与える影響を解\n析する際に用いられる．この手法では，グループ間の分散とグループ内の分散を比較し，\n観測された差が偶然によるものではないかどうかを判断する．帰無仮説と対立仮説の下，\n分散比(F 値) を計算し，F 分布に基づく検定で有意性を評価する．一元分散分析の適用に\nは，データが独立していること，正規分布に従っていること，そしてグループ間の分散が\n等しいことが条件とされる．この手法は，複数のグループ間での比較を効率的に行える\n( [37])．\nTukey の多重比較検定(Tukey 法) は，3 つ以上のグループ間で平均値の差を比較し，どの\nグループ間に有意な差が存在するかを明",
            "y 法) は，3 つ以上のグループ間で平均値の差を比較し，どの\nグループ間に有意な差が存在するかを明らかにするための統計手法である．この手法は，\n分散分析(ANOVA) で全体的な有意差が検出された後，具体的にどのグループ間で差があ\n22\nるのかを特定する際に用いられる．Tukey 法は他の多重比較法と比べて検出力が高く，検\n定の精度が優れているとされる．ただし，適用するためには各グループの分散が等しく，\nデータが正規分布に従っていることが前提条件となる．Tukey 法は多重比較法の中でも非\n常によく用いられ，特に各グループのサンプルサイズが等しい場合に適している( [38])．\n4.3.2\n定性的評価について\n[H] 以下の図4-7，4-8，4-9，4-10 は評価実験で使用する評価アンケートである．11 個\nの質問で構成され，質問は「1. 全くそう思わない」から「5. とてもそう思う」の5 段階で\nの評価尺度を使用するもの，選択式のもの，自由記述のものを含む．\n図4-7: アンケート問1，問2\n23\n図4-8: アンケート問3，問4，問5\n図4-9: アンケート問6，問7，問8\n2",
            "問1，問2\n23\n図4-8: アンケート問3，問4，問5\n図4-9: アンケート問6，問7，問8\n24\n図4-10: アンケート問9，問10，問11\n25\n第5章\n比較検証実験の結果及び考察\n5.1\n心拍変動指標のt 検定による評価\n3 種類の休憩方法(仮眠，音楽を聴く，ストレッチ) の効果を比較するために，各被験者\n(10 名) の休憩後と休憩前の作業時におけるLF/HF 値を用いて分析を行った．具体的には，\n以下の手順で解析を実施した．\n1. 変化量の計算\n各休憩方法において，被験者ごとに以下の式で変化量を算出した：\n∆LF/HF = 平均値(休憩後の作業時のLF/HF)−平均値(休憩前の作業時のLF/HF)\n2. 組み合わせごとのt 検定\n3 種類の休憩方法から2 組ずつ(仮眠・音楽，仮眠・ストレッチ，音楽・ストレッチ)\nの合計3 パターンの組み合わせについて，対応のない2 群間の平均値の差を検定す\nるため，独立標本t 検定を行った．t 検定の有意水準はα = 0.05 とした．\n表5-1，5-2，5-3 は一対の標本による平均の検定によってt 検定を行った結果の表である．\n表か",
            "表5-1，5-2，5-3 は一対の標本による平均の検定によってt 検定を行った結果の表である．\n表から分かるようにどの組み合わせにおいても有意差は見られなかった．\n表5-1: 音楽とストレッチ間のt 検定の結果\n項目\n音楽\nストレッチ\n平均\n0.887\n1.021\n分散\n0.200\n0.089\n観測数\n10\n10\nピアソン相関\n-0.519\n仮説平均との差異\n0\n自由度\n9\nt 値\n-0.650\nP 値(片側)\n0.266\nt 境界値(片側)\n1.833\n26\n表5-2: 音楽と仮眠間のt 検定の結果\n項目\n音楽\n仮眠\n平均\n0.887\n0.878\n分散\n0.200\n0.218\n観測数\n10\n10\nピアソン相関\n0.048\n仮説平均との差異\n0\n自由度\n9\nt 値\n0.043\nP 値(片側)\n0.483\nt 境界値(片側)\n1.833\n表5-3: ストレッチと仮眠間のt 検定の結果\n項目\nストレッチ\n仮眠\n平均\n1.021\n0.878\n分散\n0.089\n0.218\n観測数\n10\n10\nピアソン相関\n-0.330\n仮説平均との差異\n0\n自由度\n9\nt 値\n0.716\nP 値(片側)\n0.",
            "アソン相関\n-0.330\n仮説平均との差異\n0\n自由度\n9\nt 値\n0.716\nP 値(片側)\n0.246\nt 境界値(片側)\n1.833\n5.2\n心拍変動指標の一元配置分散分析・多重比較による評価\n休憩方法(仮眠，音楽，ストレッチ) がLF/HF 値に与える影響を検討するため，一元配\n置分散分析(ANOVA) およびTukey の多重比較検定を用いて解析を行ったが，いずれの休\n憩方法間においても統計的有意差(p ＞0.05) は認められず，LF/HF 比の変化量(Δ LF/HF)\nの平均値は仮眠で0.88 ± 0.47，音楽で0.89 ± 0.45，ストレッチで1.02 ± 0.30 であった．\n27\n表5-4: 分散分析の結果\n指標\n値\nF 値\n0.38127\n因子の自由度(df factor)\n2\n残差の自由度(df error)\n27\n因子平方和(SS factor)\n0.12911\n残差平方和(SS error)\n4.5715\n表5-5: 多重比較検定の結果(Tukey HSD)\n比較\n平均の差\nq 値\n判定\nMusic vs Nap\n0.009\n0.047\n有意差なし\nMu",
            ")\n比較\n平均の差\nq 値\n判定\nMusic vs Nap\n0.009\n0.047\n有意差なし\nMusic vs Stretch\n0.135\n0.732\n有意差なし\nNap vs Stretch\n0.143\n0.779\n有意差なし\n表5-6: 休憩方法ごとの統計量\n休憩方法\n平均変化量\n標準偏差\nMusic\n0.89\n0.45\nNap\n0.88\n0.47\nStretch\n1.02\n0.30\n5.3\nアンケートによる主観的評価\nアンケートによる主観的評価を行った．本実験では，休憩方法に対する集中力向上の効\n果，設定時間の適切性，リラックス効果についてアンケート調査を実施した．その結果を\n以下に示す．\n5.3.1\n各休憩方法の効果についての評価\n• 音楽を聴く: 音楽を聴いた後に集中力が向上したと感じた被験者は，「とてもそう思\nう」が20 ％，「そう思う」が70 ％であり，肯定的な回答が全体の90 ％を占めた．一\n方で，「どちらでもない」と回答した被験者は10 ％にとどまった．\n• ストレッチをする: ストレッチを行った後に集中力が向上したと感じた被験者は，「と\nてもそう思う」が20 ％，",
            "チをする: ストレッチを行った後に集中力が向上したと感じた被験者は，「と\nてもそう思う」が20 ％，「そう思う」が60 ％で，肯定的な回答は全体の80 ％を占\n28\nめた．「どちらでもない」と「そう思わない」の回答がそれぞれ10 ％ずつ見られた．\n• 仮眠をとる: 仮眠をとった後に集中力が向上したと感じた被験者は，「とてもそう思\nう」が40 ％，「そう思う」が60 ％であり，全体で100 ％が肯定的な評価を示した．\n5.3.2\n各休憩方法の設定時間についての評価\n• 音楽を聴く: 音楽を聴く際の設定時間について適切だと感じた被験者は，「とてもそ\nう思う」が30 ％，「そう思う」が30 ％であったが，「そう思わない」と回答した被\n験者が40 ％に上り，時間設定に課題があることが示唆された．\n• ストレッチをする: ストレッチの設定時間について適切だと感じた被験者は，「とて\nもそう思う」が40 ％，「そう思う」が40 ％で，肯定的な回答が全体の80 ％を占め\nた．一方で，「そう思わない」とする回答が20 ％見られた．\n• 仮眠をとる: 仮眠の設定時間について適切だと感じた被験者は，「とても",
            "る回答が20 ％見られた．\n• 仮眠をとる: 仮眠の設定時間について適切だと感じた被験者は，「とてもそう思う」が\n20 ％，「そう思う」が40 ％であり，合わせて60 ％が肯定的であった．しかし，「そ\nう思わない」と回答した被験者も40 ％を占め，時間設定の改善が必要であることが\n示された．\n5.3.3\n各休憩方法のリラックス効果\n• 音楽を聴く: 音楽を聴いた際にリラックスできたと回答した被験者は，「とてもそう\n思う」が50 ％，「そう思う」が50 ％であり，全員が肯定的な評価を示した．\n• ストレッチをする: ストレッチを行った際にリラックスできたと回答した被験者は，\n「とてもそう思う」が40 ％，「そう思う」が50 ％で，肯定的な回答が全体の90 ％を\n占めた．「どちらでもない」とする回答が10 ％見られた．\n• 仮眠をとる: 仮眠をとった際にリラックスできたと回答した被験者は，「とてもそう\n思う」が50 ％，「そう思う」が40 ％で，肯定的な回答が全体の90 ％を占めた．「ど\nちらでもない」と回答した被験者が10 ％存在した．\n5.3.4\n集中を妨げる要因\n休憩中に集中を妨げる",
            "らでもない」と回答した被験者が10 ％存在した．\n5.3.4\n集中を妨げる要因\n休憩中に集中を妨げる要因として，以下の項目が挙げられた．\n• 「特になし」と回答した被験者が40 ％と最も多かった．\n29\n• 一方で，「仮眠の体勢が寝づらかった」が20 ％，「明るくて仮眠が取りづらかった」\nが10 ％といった仮眠中の物理的な要因が指摘された．\n• その他，「スマートウォッチのバイブレーションが気になった」(10 ％)，「音楽の時\n間が短すぎた」(10 ％)，「休憩時間が適切でなかった」(10 ％) といった設定上の課題\nも挙げられた．\n以上のアンケート結果から主観的評価においては，「仮眠をとる」がもっとも集中力回復\nに効果的な休憩方法であり，次に「ストレッチをする」，「音楽を聴く」の順に効果的な休\n憩方法だと言える．\n5.4\n考察\n解析結果から，今回の実験で有意差が出なかった原因として，以下の要因が考えられる．\n• サンプルサイズの不足: 被験者数が10 人と少ないため，統計的検出力が不足してい\nる可能性があります．サンプルサイズを増やすことで，ばらつきを減少させ，有意\n差が検出される可",
            "してい\nる可能性があります．サンプルサイズを増やすことで，ばらつきを減少させ，有意\n差が検出される可能性が高まります．\n• 個人差の影響: LF/HF 比は個人ごとに基準値や変化量が異なるため，被験者間のば\nらつきが効果を埋もれさせる可能性があります．同じ被験者を繰り返し測定するデ\nザインを採用することで，この影響を軽減できます．\n• LF/HF 比の特性: LF/HF 比は感受性が高く，短時間の休憩では大きな変化が生じに\nくい場合があります．測定方法や他の補助指標の併用を検討する必要があります．\n• 休憩方法の効果に対する個人差: 各休憩方法における集中力向上の評価では，「とて\nもそう思う」と「そう思う」の回答が多数を占めた一方で，「どちらでもない」また\nは「そう思わない」とした回答が一定数存在しました．このことから，休憩方法の\n効果には被験者間で個人差が大きく，統一的な効果を示すことが困難だったと推測\nされます．\n• 休憩時間の適切性に関する評価: 休憩時間について，「音楽を聴く」「ストレッチをす\nる」「仮眠をとる」のいずれにおいても設定時間が適切でなかったとする回答が見ら\nれまし",
            "ストレッチをす\nる」「仮眠をとる」のいずれにおいても設定時間が適切でなかったとする回答が見ら\nれました．特に，「音楽を聴く」では「そう思わない」が40%，「仮眠をとる」では\n「そう思わない」が40%に上っており，休憩時間が効果を十分に発揮するのに適して\nいなかった可能性があります．\n• 休憩中の環境要因: 休憩中に集中を妨げる要因として，「仮眠の体勢が寝づらかった」\n「明るくて仮眠が取りづらかった」といった物理的要因や，「音楽の時間が短すぎた」\n30\n「休憩時間が適切でなかった」といった設定上の問題が挙げられました．これらの要\n因が，被験者における休憩効果を低下させたと考えられます．\n• リラックス効果のばらつき: リラックス効果に関する評価では，肯定的な回答が多\nかったものの，「どちらでもない」とした回答も見られました．このことは，被験者\nが感じるリラックス効果に個人差があることを示しており，それが集中力向上の主\n観的評価に影響を及ぼした可能性があります．\n5.5\n実験の改善点\n以上を踏まえ，以下の改善点が考えられる．\n• サンプルサイズの拡大: 被験者数を増加させ，統計的検出力を向",
            "踏まえ，以下の改善点が考えられる．\n• サンプルサイズの拡大: 被験者数を増加させ，統計的検出力を向上させる．例えば，\n20 人以上の被験者を対象とすることで，効果のばらつきを軽減し，有意差を検出す\nる可能性を高める．\n• 個人差を考慮したデザイン: 被験者間の個人差を軽減するため，同じ被験者に複数\nの休憩方法を繰り返し適用し，その前後でLF/HF 比を測定する「被験者内デザイン」\nを採用する．また，事前に被験者の基礎的な自律神経指標を測定し，個人差を補正\nする方法を検討する．\n• 休憩時間の再設定: 各休憩方法において，効果が最大限発揮される適切な時間設定\nを再検討する．例えば，仮眠の時間を20 分程度に延長し，音楽の聴取時間もリラッ\nクス効果を十分に引き出す長さに調整する．\n• 環境要因の統一: 仮眠時の環境を改善するため，明るさを調整可能な部屋や快適な\n仮眠姿勢を取れる椅子やリクライニングを用意する．音楽の音量や選曲を統一する\nことで，外的要因を最小限に抑える．\n• 測定指標の追加: LF/HF 比以外にも，主観的なストレスレベルや集中力の自己評価\nアンケートを併用し，多角的に休",
            ": LF/HF 比以外にも，主観的なストレスレベルや集中力の自己評価\nアンケートを併用し，多角的に休憩方法の効果を評価する．また，他の生理指標(心\n拍数，血圧，皮膚電気活動など) の測定も検討する．\n• 休憩方法のバリエーション拡大: 仮眠や音楽以外のリラックス手法(深呼吸法，瞑想\nなど) を取り入れ，それぞれの効果を比較することで，より適切な休憩方法を特定\nする．\n• リラックス効果の個別最適化: 被験者ごとに最適な休憩方法を事前に調査するプロ\nセスを導入し，個別に最適化された休憩を提供する．例えば，リラックス効果が高\nい音楽のジャンルや仮眠の時間を事前に確認する．\n31\nこれらの改善点を反映することで，実験結果の精度や信頼性が向上し，より明確な効果\nを示す結果が得られることが期待される．\n32\n第6章\n結論\n6.1\nまとめ\n本論文では，「音楽を聴く」「ストレッチをする」「仮眠をとる」の３種類の休憩方法に\nおいてどれが最も集中力回復に効果的かの検証を実施した．\n6.1.1\n集中度についての定量的評価\n被験者のLF/HF スコアを用いてt 検定，分散分析・多重比較を行った結果，統計的に",
            "ての定量的評価\n被験者のLF/HF スコアを用いてt 検定，分散分析・多重比較を行った結果，統計的に有\n意な差があるとは言えなかった．本研究は，10 人と少ないサンプル数での実験だったた\nめ，被験者によってLF/HF スコアの増減の差が激しく，より多くの被験者からLF/HF ス\nコアを取ることでより精度の高い実験結果となり，有意な差が見られる可能性もあると考\nえられる．\n6.1.2\n集中度についての定性的評価\n被験者に対してアンケートを行った結果，「仮眠をとる」「ストレッチをする」「音楽を\n聴く」の順で集中度が回復したという結果になった。数値としては有意差が見られなかっ\nたが，被験者自身の感覚としては休憩方法によって集中度の回復に差が見られる結果と\nなった。\n6.2\n今後の展望\n本研究では，休憩方法が集中力向上に及ぼす効果を評価したが，有意差が見られなかっ\nた。この結果には，個人差，設定時間，環境要因，リラックス効果のばらつきが関与して\nいる可能性が示唆された。今後の展望としては，休憩方法ごとの効果を最大化するために\n最適な時間設定を再検討し，事前調査やパイロット実験を通じて適切な休憩",
            "法ごとの効果を最大化するために\n最適な時間設定を再検討し，事前調査やパイロット実験を通じて適切な休憩時間を特定す\nる必要がある。また，仮眠時の体勢や光量，音楽の再生時間や音量の調整など，快適な休\n憩環境を提供するための物理的・設定上の問題の改善が求められる。さらに，休憩効果に\nは個人差が大きいことが示唆されているため，クラスター分析や多変量解析を用いたデー\nタ分析を通じて被験者の特性ごとに適した休憩方法を明らかにし，より多様なバックグラ\n33\nウンドを持つ対象者を取り入れることで汎用性や適応性を高めることも重要である。加え\nて，生理的データと主観的評価を統合的に解析することで休憩効果を客観的に評価し，そ\nの科学的裏付けを強化する必要がある。これらの改善を通じて，休憩方法と集中力向上の\n関係をより明確にし，効果的な休憩設計を実現することで，オフィス環境や業務パフォー\nマンスの向上に貢献できると期待される。\n34\n謝辞\n本稿の執筆に際し，ご指導していただいた青山学院大学理工学部情報テクノロジー学科\nロペス・ギヨーム教授，木村正子助手に深く感謝申し上げます．研究室の設備・機器や\n研究環境を整",
            "ー学科\nロペス・ギヨーム教授，木村正子助手に深く感謝申し上げます．研究室の設備・機器や\n研究環境を整えて下さった他，研究目標を達成するためのアドバイスやアイデアを提供し\nて下さり，研究を最後まで取り組むことができました．そして，問題解決のために様々な\n視点でのご意見や励ましをいただいたロペズ研究室の先輩方，実験に参加していただきま\nした被験者の皆様に深く感謝いたします．\n35\n質疑応答\n戸辺　義人　情報テクノロジー学科　教授\nQ\n休憩前後のLF/HF 変化量を出したということは、作業が終わってすぐにLF/HF を\n計測したということですか。\nA\n実験が始まってから終了するまで心拍数を測り続け、実験後に休憩前のデータと休\n憩後のデータを抜き出し変化量を求めました。\n戸辺　義人　情報テクノロジー学科　教授\nQ\nLF/HF の値はどのような時間変化を示したか。\nA\nなだらかではなく明らかな変化が見られました。具体的には、休憩に入ったタイミ\nングで明LF/HF は低下し、また作業を再開するとLF/HF は上昇する結果でした。\n戸辺　義人　情報テクノロジー学科　教授\nQ\nLF/HF の値になだら",
            "/HF は上昇する結果でした。\n戸辺　義人　情報テクノロジー学科　教授\nQ\nLF/HF の値になだらかではなく明らかな変化が見られたということは、休憩方法に\n関わらず作業をやめればLF/HF 値は下がるという仮説も立てられますか。\nA\n本実験では、何もせずに過ごす休憩を比較していないので確実な結論は出せません\nが、その可能性もあると考えます。\n36\n伊藤雄一情報テクノロジー学科教授\nQ\nLF の周期はどれくらいで設定されていますか。\nA\n本実験は5 分で設定しました。\n伊藤雄一情報テクノロジー学科教授\nQ\n20 分間のデスクワークはどれくらいの負荷になっていますか。\nA\nより現実的な設定で行うために各被験者に自由なデスクワークを行ってもらったた\nめ作業の負荷については把握できていません。また、自由なデスクワークを行って\nもらうに当たり、前半の20 分と後半の20 分がそれぞれ同程度の負荷のものという\n条件のみを課しました。\n伊藤雄一情報テクノロジー学科教授\nQ\n仮眠、音楽、ストレッチ以外に被験者が実際に普段行っている休憩方法も比較基準\nとして行いましたか。\nA\n本実験では、仮眠、音楽、",
            "に被験者が実際に普段行っている休憩方法も比較基準\nとして行いましたか。\nA\n本実験では、仮眠、音楽、ストレッチ以外の休憩方法は行えていないので、今後の\n改善点として参考にさせていただきます。\n山下優依情報テクノロジー学科戸辺研究室助手\nQ\n被験者のコンディションが実験結果に大きく関係すると思うのですが、被験者が実\n験前に何を行っていたかのアンケートは取りましたか。\nA\nそれについてのヒアリングは行えていません。ただ、3 日間とも同じ時間帯に実験\nを行ったのでよほど1 日のルーティーンが決まっていない人でない限り、3 日間の\nコンディションに大きな差はないと考えます。\n37\n参考文献\n[1] DigitalKnowledge 株式会社：オンデマンド学習に関するレポート，https:\n//www.digital-knowledge.co.jp/wp-content/uploads/2023/11/\nreport_ondemand.pdf. (参照日2025/01/28).\n[2] 全国大学生活協同組合連合会：第59 回学生生活実態調査報告，https://www.\nunivcoop.or.",
            "活協同組合連合会：第59 回学生生活実態調査報告，https://www.\nunivcoop.or.jp/press/life/report.html. (参照日2025/01/28).\n[3] ダイヤモンド・オンライン：休憩の取り方で、生産性とウェルビーイングは劇的に\n向上する，https://dhbr.diamond.jp/articles/-/9732?page=2. (参照日\n2025/01/23).\n[4] 閏間莉央，小池崇文ほか：ウェアラブルデバイスによる心拍・視線移動の測定を用\nいた歩行時における異性への好意判定手法の検討，第79 回全国大会講演論文集，\nVol. 2017, No. 1, pp. 979–980 (2017).\n[5] Japan,\nM.:\n会社での休憩時間の過ごし方\n～リフレッシュ方法6 選\n～\n，https://www.manpowergroup.jp/staff/column/career/\nhow-to-spend-rest-time-in-company.html. (参照日2025/01/23).\n[6] 三木隆裕，寺田努，前田俊幸，唐澤鵬翔",
            "pany.html. (参照日2025/01/23).\n[6] 三木隆裕，寺田努，前田俊幸，唐澤鵬翔，安達淳，塚本昌彦ほか：休憩時間の過ごし\n方が作業パフォーマンスに及ぼす影響の調査，研究報告ユビキタスコンピューティ\nングシステム(UBI)，Vol. 2018, No. 3, pp. 1–8 (2018).\n[7] 吉村梓，打越大成，岩本健嗣，松本三千人ほか：観光地評価のための腕時計型心拍\nセンサによる内面状態推定手法，第77 回全国大会講演論文集，Vol. 2015, No. 1, pp.\n131–132 (2015).\n[8] 浦野健太，廣井慧，米澤拓郎，河口信夫ほか：ドキドキをセンシングして可視化す\nるLED ライティングデバイス，マルチメディア, 分散協調とモバイルシンポジウム\n2248 論文集，Vol. 2020, pp. 1616–1622 (2020).\n[9] 青木渉，桐山伸也ほか：心拍センシングに基づくマルチモーダル体感状況理解，第\n79 回全国大会講演論文集，Vol. 2017, No. 1, pp. 161–162 (2017).\n38\n[10] 角田啓介，江口佳",
            " 2017, No. 1, pp. 161–162 (2017).\n38\n[10] 角田啓介，江口佳那，吉田和広，渡部智樹，水野理ほか：心拍と呼吸を用いたコンテ\nンツ視聴による気分変化の推定: コメディ視聴における検討，情報処理学会論文誌コ\nンシューマ・デバイス& システム(CDS)，Vol. 7, No. 1, pp. 44–52 (2017).\n[11] 東海林綾，竹下怜花，横窪安奈ほか：心拍変動解析を用いた動画鑑賞の客観的評価，\nマルチメディア, 分散協調とモバイルシンポジウム2021 論文集，Vol. 2021, No. 1,\npp. 1149–1154 (2021).\n[12] 野本大雅，花田祥典，横窪安奈ほか：脈拍変動を用いたスポーツ観戦時における情\n動の客観的評価，マルチメディア, 分散協調とモバイルシンポジウム2105 論文集，\nVol. 2020, pp. 588–592 (2020).\n[13] 田島真沙美ほか：母親のストレスマネジメントに関する研究: 腕時計型ウェアラブル\nデバイスを用いて，紀要，Vol. 58, pp. 35–47 (2023).\n[14] 伊村",
            "ラブル\nデバイスを用いて，紀要，Vol. 58, pp. 35–47 (2023).\n[14] 伊村一成，後藤佑介，酒井晃二，小原雄，田添潤，三浦寛司，廣田達哉，内山彰，乃\n村能成ほか：ウェアラブルセンサデバイスを用いた医師のストレス推定手法の提案，\n研究報告電子化知的財産・社会基盤(EIP)，Vol. 2021, No. 5, pp. 1–8 (2021).\n[15] 鈴木伊織，佐藤文明ほか：ウェアラブル端末により検知した心拍変動に基づくスト\nレス推定，研究報告コンピュータセキュリティ(CSEC)，Vol. 2020, No. 30, pp. 1–7\n(2020).\n[16] 宮崎裕哉，杉村博ほか：オンライン受講者向け集中力持続支援システム，第84 回全\n国大会講演論文集，Vol. 2022, No. 1, pp. 269–270 (2022).\n[17] 森川聖也，吉野孝ほか：スマートグラスを用いた視界の制限による集中力向上手法\nの提案，第85 回全国大会講演論文集，Vol. 2023, No. 1, pp. 197–198 (2023).\n[18] 菅野真功，小林稔ほか：プレゼン",
            "3, No. 1, pp. 197–198 (2023).\n[18] 菅野真功，小林稔ほか：プレゼンテーション時における心拍フィードバックによる緊\n張緩和手法の検討，研究報告デジタルコンテンツクリエーション(DCC)，Vol. 2019,\nNo. 45, pp. 1–6 (2019).\n[19] 河端留奈，相川大吾，江木啓訓ほか：脚部動作計測に基づいて学習活動の休憩を提\n案する手法，第82 回全国大会講演論文集，Vol. 2020, No. 1, pp. 55–56 (2020).\n[20] 濱谷尚志，内山彰，東野輝夫ほか：種々のセンサを併用した集中度センシング法の\n検討，研究報告高度交通システムとスマートコミュニティ(ITS)，Vol. 2015, No. 10,\npp. 1–6 (2015).\n39\n[21] 川崎勇佑，横窪安奈ほか：勉強中における心拍数を用いた精神状態度合の推定，マ\nルチメディア, 分散協調とモバイルシンポジウム2021 論文集，Vol. 2021, No. 1, pp.\n936–942 (2021).\n[22] 徳田博行，高橋雄太，音田恭宏，金谷勇輝，荒川豊，安",
            "pp.\n936–942 (2021).\n[22] 徳田博行，高橋雄太，音田恭宏，金谷勇輝，荒川豊，安本慶一ほか：アイウェアによ\nる集中力センシングに基づいた行動変容システムの設計，2017 年度情報処理学会関\n西支部支部大会講演論文集，Vol. 2017 (2017).\n[23] 橘卓見，岡部浩之，佐藤未知，福嶋政期，梶本浩之：PC 作業時の集中力向上のため\nの作業用壁紙，Interaction (2012).\n[24] 小松勇輝，下条和暉，西山勇毅，瀬崎薫ほか：腕時計型ウェアラブルデバイスを用い\nた会話時間計測手法の構築に向けて，第84 回全国大会講演論文集，Vol. 2022, No. 1,\npp. 219–220 (2022).\n[25] 千葉桂也，阿部昭博，市川尚，富澤浩樹，工藤彰ほか：ウェアラブルデバイスを活用\nした健康増進型野外ミュージアム鑑賞支援システムの提案，第79 回全国大会講演論\n文集，Vol. 2017, No. 1, pp. 807–808 (2017).\n[26] 吉田崇洋，井口信和，野田潤ほか：ユーザロケーションに応じた腕時計型ウェアラ\nブルデバイスによる動",
            "] 吉田崇洋，井口信和，野田潤ほか：ユーザロケーションに応じた腕時計型ウェアラ\nブルデバイスによる動的な情報提示システムの開発，第78 回全国大会講演論文集，\nVol. 2016, No. 1, pp. 409–410 (2016).\n[27] 岡部真子，佐々木新介：腕時計型ウェアラブルデバイスでのセルフモニタリングが\n地域住民の歩数と睡眠時間にもたらす効果，ヒューマンケア研究学会誌，Vol. 13,\nNo. 1, pp. 1–7 (2022).\n[28] 本多祥子，太田洋一：一般人による寺院での坐禅が自律神経機能に与える影響，健\n康レクリエーション研究= Japanese journal of health recreation，Vol. 17, pp. 23–31\n(2022).\n[29] 後藤和彦，相川大吾，江木啓訓ほか：脚部動作計測に基づく学習効果向上のための休\n憩提案システム，第83 回全国大会講演論文集，Vol. 2021, No. 1, pp. 129–130 (2021).\n[30] 荻野隼：休憩時の運動が生体情報と集中力に及ぼす影響，日本知能情報ファジィ学\n会ファジィ",
            ".\n[30] 荻野隼：休憩時の運動が生体情報と集中力に及ぼす影響，日本知能情報ファジィ学\n会ファジィシステムシンポジウム講演論文集第36 回ファジィシステムシンポジ\nウム，日本知能情報ファジィ学会，pp. 35–36 (2020).\n[31] 渡部貴史，小林未来：休憩時の音楽聴取が作業遂行に及ぼす影響，新潟医療福祉学\n会誌，Vol. 20, No. 1, pp. 39–39 (2020).\n40\n[32] 看護roo：心電図波形の名称と意味～幅と高さ｜心電図とはなんだろう，https:\n//www.kango-roo.com/learning/1708/ (2015). (参照日2022/1/7).\n[33] ストレスと自律神経の科学：ストレス指標のHF，LF とは？，http://hclab.\nsakura.ne.jp/stress_novice_LFHF.html. (参照日2022/6/22).\n[34] Work, H.: 集中力を高める休憩の取り方：生産性を上げるためのポイント，https:\n//note.com/hiromoneywork/n/n1202c250d8e0. ",
            "，https:\n//note.com/hiromoneywork/n/n1202c250d8e0. (参照日2025/01/23).\n[35] G-NAP: 仮眠の効果～15～20 分程度の仮眠で疲労回復効果～，https://g-nap.\ncom/post-987/. (参照日2025/01/23).\n[36] Surveroid: t 検定とは～データ分析手法の基本～，https://surveroid.jp/\nmr-journal/data_analysis_method/5Xiot. (参照日2025/01/23).\n[37] JMP:\n一元分散分析（ANOVA）とは，https://www.jmp.com/ja_jp/\nstatistics-knowledge-portal/one-way-anova.html.\n(参照日\n2025/01/23).\n[38] Radi-Toko: 3 群以上パラメトリックデータをTukey 法で多重比較する，https://\nradi-toko.com/statistic-tukey/. (参照日2025/01/23).\n41\n",
            ".com/statistic-tukey/. (参照日2025/01/23).\n41\n"
        ]
    },
    {
        "id": "paper_6",
        "filename": "B2024_SoraIwamoto_t.pdf",
        "title": "B2024_SoraIwamoto_t",
        "fulltext": "青山学院大学理工学部\n情報テクノロジー学科\n２０２４年度卒業研究論文\nImmersion Neckwear:\n動画体験拡張ネックウェア\n２０２５年１月２８日提出\n指導教員ロペズ・ギヨーム　教授\n提出者学生番号　氏名\n１５８２１００９岩本空\n青山学院大学 理工学部 情報テクノロジー学科 \n2024 年度（令和6 年度）卒業論文要旨 \n- 1 - \nImmersion Neckwear:  \n動画体験拡張ネックウェア \n岩本 空（15821009） \nロペズ研究室 \n \n１．はじめに \n定額制動画配信サービスの普及により，有料動画配\n信サービスの利用者が増加している．これに伴い，動\n画視聴の形態も大きく変化し，インターネット回線を\n活用した動画鑑賞の市場規模が拡大している．一方，\n技術の進化により，映画館での視聴体験も新たな楽し\nみ方として提案されており，特に4DX （Four \nDimensional eXperience）技術の導入により，五感を\n刺激する没入型の体験が提供されている[1]．  \nよって，本研究の目的は，動画の映像に合わせて，\n五感を刺激するフィードバックを行い，自宅での動画\n体験を拡張することである．そのため，研究目標とし\nて，映像に合わせて振動・風の強弱・温冷感を提示す\nる頸部装着型ウェアラブルシステムImmersion \nNeckwear を創作し，一人での動画鑑賞の没入感を向\n上することを目指す．Immersion Neckwear を利用し\nた動画鑑賞のイメージ図を図1 に示す． \n \n図1 Immersion Neckwear を利用した動画鑑賞の\n例 \n \n２．関連研究 \n岡本ら[2]は，ワイヤアクションゲームをプレイ中の\n風の強度が臨場感に与える影響を検証した．風なし，\n一定の風，ワイヤアクションで引っ張られるときの速\n度に応じた風の3 つの条件で評価したところ，風力変\n化がある状態が最も臨場感が高いことが判明した．前\n田[3]らは，複数の体の部位に装着可能な熱フィードバ\nックシステムTherModule を提案した．実験では，\nTherModule を装着し，視覚と温度フィードバックを\n受けながら映画を鑑賞した被験者は，視覚のみの被験\n者に比べて「楽しさ」と「興奮度」が有意に高いこと\nが確認された．Kim [4]らは，触覚刺激が映画鑑賞中の\n感情変化と没入感に与える影響を調査した．ポジティ\nブなシーンで柔らかい刺激を受けるとポジティブな感\n情と没入感が増加し，ネガティブなシーンでは柔らか\nい刺激がネガティブな感情を軽減することがわかった． \n上記のように，風や温度，触覚刺激が没入感や感情\nに与える影響は示されたが，多感覚フィードバック（振\n動，風，温冷感）の統合的な効果は十分に検証されて\nいない．そのため，本研究では振動，風の強弱，温冷\n感を組み合わせた多感覚フィードバックシステム\nImmersion Neckwear を創作し，これが動画鑑賞にお\nける没入感やユーザ体験に与える影響を評価する． \n \n３．Immersion Neckwear の概要 \n本研究で創作した頸部装着型の没入感向上デバイス，\nImmersion Neckwear，の画像は図2 に示し，構成し\nている主な要素は以下にまとめている． \n⚫ \nインターフェース部：nRF Connect \n⚫ \n制御部：Arduino Nano 33 BLE \n⚫ \n電源部：5500mAh リチウムイオンバッテリ \n⚫ \n温冷部：ペルチェ素子TEC1-03105 \n⚫ \n風部：ターボブロワファンB0DB5SDX91 \n⚫ \n振動部：振動モータLBV10B-009 \n \n \n- 2 - \n    \n \n図2 Immersion Neckwear の全体像 \n \n４．Immersion Neckwear の没入感効果検証実験 \nImmersion Neckwearの有無による動画体験の印象\nの違いを比較し，有効性を検証した．被験者は20 代の\n男女10 名（男性:8 人，女性2 人）が，25 分程度のア\nクションアニメを視聴し，視聴後SD 法を用いたアン\nケートで主観的な評価を収集した．実験手順として，\n表1 に対応している，フィードバックを起こす場面の\n個数がほぼ等しい2 つの動画を用意し，被験者は\nImmersion Neckwear の有無で動画鑑賞を行った．視\n聴後にはSD 法によるアンケートに回答し，さらに\nImmersion Neckwear を使用した被験者にはSUS ア\nンケートを実施した．  \n表1: 場面とフィードバックの種類の対応 \n \n \n５．結果 \n表2，表3 はImmersion Neckwear の有無での SD \n法に基づいた形容詞対による印象評価を因子分析した\n結果から，因子解釈を行った結果を示す．装着時に，\n評価性が高まることから，動画視聴の没入体験が高ま\nったと考えられる． \nまた，SUS アンケートによるユーザビリティ評価で\nは，平均値が65 点であり，本システムのユーザビリテ\nィは改善の必要があると考えられる．また，システム\nの装着および起動に技術的サポートが必要と感じた被\n験者，デバイスの重さおよび大きさが不快に感じる被\n験者もいた． \n \n表2: システムありの時の，因子解釈 \n表3: システムなしの時の，因子解釈 \n \n \n6．まとめ \n本研究では，多感覚フィードバックを提供する没入\n感向上デバイスImmersion Neckwear を開発した．実\n験結果では，Immersion Neckwear を装着した動画鑑\n賞において，ユーザがよりポジティブな印象を抱き，\n動画の没入感が向上することが確認された．特に，SD\n法によるアンケートの因子分析で，システムの装着に\nより評価性が高まることが示された．一方，ユーザビ\nリティをより向上させるためには，ユーザインターフ\nェースの改善，デバイスの軽量化が必要である \n \n参考文献 \n[1] \n株式会社ＩＣＴ総研:2023 年有料動画配信サー\nビス利用動向に関する調査. \nhttps://ictr.co.jp/report/20230421.html/. ( 最終\n参照日：2025/1/3) \n[2] \n岡本早織,羽田久一： ゲームプレイ中の風の強度\nによる臨場感の変化, エンタテインメントコン\nピューティングシンポジウム 2022 論文集, pp. \n135–138 (Aug 2022). \n[3] \n前田智祐,倉橋哲郎：ウェアラブルな温冷覚多点\n提示システム TherModule の基礎検討, 第 23 \n回日本バーチャルリアリティ学会大会論文集\n(Sep. 2018) \n[4] \nKim. A, Bae. H, and Lee. K.: Effects of Tactile \nPerception on Emotion and Immersion to Film \nViewing in a Virtual Environment， VRST ‘19: \nProceedings of the 25th ACM Symposium on \nVirtual Reality Software and Technology, pp.1–\n3 (Nov 2019) \n目次\n第1 章\n序章\n1\n1.1\n研究背景. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n1\n1.1.1\n映像体験の変化. . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n1\n1.1.2\n映画館での視聴体験\n. . . . . . . . . . . . . . . . . . . . . . . . . .\n2\n1.1.3\n映画館での視聴体験の拡張\n. . . . . . . . . . . . . . . . . . . . . .\n2\n1.2\n研究目的と目標. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n3\n1.3\n本論文の構成. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n4\n第2 章\n関連研究\n5\n2.1\nコンテンツ体験の拡張. . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n5\n2.2\n動画鑑賞時の感情推定. . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n6\n2.3\nコンテンツ評価. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n7\n2.4\nフィードバックによるコンテンツ体験の変化. . . . . . . . . . . . . . . . .\n8\n2.4.1\n風による動画体験の拡張に関する研究\n. . . . . . . . . . . . . . . .\n8\n2.4.2\n温度による動画体験の拡張に関する研究. . . . . . . . . . . . . . .\n9\n2.4.3\n振動によるコンテンツ体験の拡張に関する研究\n. . . . . . . . . . .\n10\n2.4.4\n香りによるコンテンツ体験の拡張に関する研究\n. . . . . . . . . . .\n11\n2.5\n映画鑑賞体験の拡張\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n12\n2.6\n評価実験によるコンテンツ評価. . . . . . . . . . . . . . . . . . . . . . . .\n13\n2.7\n本研究の位置づけ. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n15\n第3 章\nImmersion Neckwear:\n動画体験拡張ネックウェア\n16\n3.1\nImmersion Neckwear の概要\n. . . . . . . . . . . . . . . . . . . . . . . . . .\n16\n3.2\nImmersion Neckwear の基本設計. . . . . . . . . . . . . . . . . . . . . . . .\n17\n3.2.1\n各要素の機能詳細\n. . . . . . . . . . . . . . . . . . . . . . . . . . .\n17\n3.3\nハードウェアの設計\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n18\n3.3.1\n熱源の選定と温度制御. . . . . . . . . . . . . . . . . . . . . . . . .\n18\n3.3.2\nその他電子部品の選定. . . . . . . . . . . . . . . . . . . . . . . . .\n22\ni\n第4 章\nImmersion Neckwear の没入感効果検証実験\n25\n4.1\n実験概要. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n25\n4.2\n実験手順. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n25\n4.3\nSD 法\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n26\n4.4\nSUS . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n27\n第5 章\n実験結果および考察\n29\n5.1\n実験結果. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n29\n5.1.1\nSD 法の評価結果. . . . . . . . . . . . . . . . . . . . . . . . . . . .\n29\n5.1.2\nSUS の評価結果. . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n31\n5.2\n考察. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n31\n5.2.1\nSD 法の評価結果に関する考察. . . . . . . . . . . . . . . . . . . . .\n31\n5.2.2\nSUS の結果に関する考察. . . . . . . . . . . . . . . . . . . . . . . .\n32\n第6 章\n結論\n34\n6.1\nまとめ. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n34\n6.2\n今後の展望\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n34\n参考文献\n37\n付録A 　SD 法に基づいたアンケートフォーム\n42\n付録B\n　SUS に基づいたアンケートフォーム\n46\nii\n第1章\n序章\n本章では，本研究における研究背景，目的および本論文の構成について述べる．\n1.1\n研究背景\n1.1.1\n映像体験の変化\n近年，定額制で利用可能なサービスの増加および，新型コロナウイルス感染拡大によっ\nて高まった巣ごもり需要によって有料動画配信サービスの利用者が増加している．図1-1\nの示すように，動画配信サービスの利用者数の需要予測では2025 年には3900 万人まで利\n用者が拡大すると予測されている[1]．\n図1-1: 有料動画配信サービスの利用者の需要予測（[1] より引用）\n有料動画配信サービスの普及に伴い，動画視聴の形態も大きく変化している．好きなタ\nイミングで視聴を開始でき，チケット代および交通費などのコストを削減可能なインター\nネット回線を活用した動画鑑賞が数年で市場規模を拡大している．図1-2 で示すように，\nGEM Partners 株式会社が発表した，2023 年の動画配信（VOD）市場規模推計と，その後\n2028 年までの各年の市場規模を3 つのシナリオで予測した「動画配信（VOD）市場5 年間\n予測（2024-2028 年）レポート」によると，有料配信の市場規模はコロナ禍前の2019 年と\n比較するとほぼ倍に成長すると予測されている．さらに，2028 年には7371 億円に増加す\nることが予測されており，更なる成長が期待されている．有料配信の市場規模の拡大と付\n随して，特定の配信サービスのみで視聴可能なオリジナルコンテンツも増加している[2]．\n1\n図1-2: 動画配信サービス国内の市場規模の推移と予測（[2] より引用）\n1.1.2\n映画館での視聴体験\n株式会社プラネットが実施した映画に関する意識調査によると，図1-3 から，映画を見\nるときに，映画館で映画を見たい人が全体の3 割を占めており，特に20 代については男\n女ともに自宅で映画を見たい人より映画館で見たいと回答した人の方が上回っている．映\n画館で見たいと回答した人の中には映画館で見ることのメリットとして「観客の笑い声や\n泣き声などに包まれ，一体感をもたらしてくれるところ」と回答している[3]．他の調査\nでも映画を映画館で見たい理由として，非日常感を味わえることおよび，没入感を感じら\nれることが上げられている[4]．\n株式会社スパコロが実施した映画館の利用意識調査によると，「コロナ禍の映画館にお\nいてみたいと思う作品はどんな作品か？」の問いに対して，図1-4 で示すように，回答結\n果を分析・可視化したところ「アクション」「迫力」「SF」「サスペンス」「映像」「臨場感」\n「アニメ」など語句が目立っており，劇場だからこそのダイナミックな映画体験が感じら\nれる作品が映画館で観たい作品と考えられていることがわかる[5]．\n1.1.3\n映画館での視聴体験の拡張\n近年，映画館での視聴体験は大きく変化しており，技術の進化とともに新たな楽しみ方\nが提案されている．特に注目されるのが4DX（Four Dimensional eXperience）技術の導入\nである．映像と連動して座席が動く，水しぶきおよび風，香りなどの特殊効果を体感可能\nなシステムで，観客に五感を刺激する没入型の体験を提供する．本技術により，単に映画\nを「見る」だけでなく，まるで映画の中に入り込んだかのような臨場感を楽しむことが可\n2\n図1-3: 映画を見る際の，映画館鑑賞と自宅鑑賞の比率（[4] より引用）\n能である．図1-5 は，MediaMation 社が開発した体験型4D シアタシステムの概要図であ\nる．また，IMAX およびDolby Atmos などの大画面・高音質技術も進化しており，映像美\nと音響効果がよりリアルに感じられるようになっている．これにより，映画館での視聴体\n験は単なるエンターテインメントから，特別なイベントかつ記憶に残る体験へと変化して\nきている．\n1.2\n研究目的と目標\n定額制で利用可能なサービスの増加および，新型コロナウイルス感染拡大によって高\nまった巣ごもり需要に伴い，多くの人が配信を利用した自宅動画鑑賞に親しんでいる．一\n方で，映画館で映画を楽しんでいる人も大勢おり，その中には「没入感」および「一体感」\nの観点，映画のジャンルによって，映画館での映画鑑賞を好む人がいる．本研究では，動\n画の映像に合わせて五感を刺激するフィードバックを行い，自宅動画体験を拡張すること\nを目的としている．本技術が実現すれば，自宅での動画体験の満足度の向上が可能とな\nる．その目標に向けて，本論文では映像に合わせて振動・風の強弱，温冷感提示をするシ\nステムを創作する．\n3\n図1-4: 映画館で見たいと思う作品はどんな作品？：ワードクラウド（頻出語句）（[5] より引用）\n図1-5: MediaMation 社「MX4D」（[6] より引用）\n1.3\n本論文の構成\n第1 章では，本論文の研究背景，研究目的及び論文の構成について述べる．第2 章では\n関連研究について説明する．第3 章では，システムの概要について説明する．第4 章で\nは，実験方法について説明する．第5 章では，実験結果と考察について説明する．第6 章\nでは，本論文の結論と今後の展望について述べる．\n4\n第2章\n関連研究\n本章では，関連研究について述べる．\n2.1\nコンテンツ体験の拡張\n代蔵らは，図2-1に示すような他者の存在を感じながら動画を鑑賞するシステム「ExciTV」\nを活用し，ユーザの興奮度を皮膚コンダクタンス反応で評価することを提案した．ユーザ\nのSCR データと動画に対する評価には相関が見られ，他者の反応を含めて動画を楽しむ\nことが可能であることが確認された[7]．\n図2-1: ExciTV（[7] より引用）\n松井らは，周辺視にエフェクトを提示することで，動画の印象および視聴体験がどのよ\nうに変化するかを調査した．視線検出装置を使用して，エフェクト提示中の視線情報を取\n得し，アンケートで印象の変化を評価した．エフェクトの提示は動画の印象を変化させる\nことが確認され，特に現実空間を撮影した動画はアニメおよびゲームのような二次元空間\nを撮影した動画と比較して，印象変化が顕著にみられた．エフェクト提示により動画視聴\n体験の拡張が有効であることが確認された[8]．\n三上らは，従来の音楽体験を向上のために，電気的筋肉刺激を用いて音楽に合わせた身\n体動作を外部から強制的に提示することシステムを提案した．音楽体験の印象を評価語に\n対して7 段階で評定してもらったところ，「Interesting」「Enjoyable」「Exciting」「Lively」\n5\n「Light」「Fast」「Heavy」において，曲の文脈に合わせて電気的筋肉刺激を提示したとき\n（条件2）の方が，音楽だけのとき（条件1）及び一定の間隔で電気的筋肉刺激を提示し\nたとき（条件3）よりも印象評価による評定得点が大きな値となった．特に「Interesting」\n「Exciting」において音楽のみの条件1 と条件2 および条件2 と条件3 との間に有意差が認\nめられた[9]．\n2.2\n動画鑑賞時の感情推定\n三ツ木らは，音楽ライブにおいて，生体反応センサーを用いて観客の感情的な盛り上が\nりを推定することを実現することで，観客間での盛り上がりの共有および演者へのフィー\nドバックに有効であると考えた．図2-2 で示すようなシステムで，脳波と皮膚電気信号を\n用いて，音楽ライブ中の観客の感情的な盛り上がりを推定するシステムを提案した．脳波\nとEDA データから，音楽鑑賞中の盛り上がりおよび感情の推定が可能であることが示唆\nされた[10]．\n図2-2: 脳波と皮膚電気信号を用いたシステム概要図（[10] より引用）\n寺澤らは，脳波を用いて，映画鑑賞中の連続的な感情変化を追跡する手法を提案した．\nアニメ映画鑑賞の脳波データを収集し，感情状態を分類および予測を行ったところ，最良\nの分類精度は77.6%，最良の回帰モデルの相関係数は0.645 であった．これにより，脳波\nベースの方法で連続的な感情状態が概ね予測可能であることが確認された[11]．\n平松らは，脈波と脳波を活用して，Russell の環状モデルを用いてユーザの気分変化を\n推定する手法を提案した．ジャグリングの実演を鑑賞中のユーザの気分推定を行ったとこ\nろ，提案手法による感情分析と主観評価による感情分析には相関があることがわかった．\n結果から，生体情報を用いた感情分類手法が有効であることが認められた[12]．\n角田らは，コメディ動画視聴によるユーザの気分変化を，心拍数と呼吸数の長期変動を\n6\n用いて低負荷で推定する手法を提案した．本手法から心拍数と呼吸数の長期変動の類似度\nが減少すると，ネガティブな気分が高まることがことが判明した．結果から，コンテンツ\n視聴中の生体情報を用いて，ユーザの気分変化を低負荷で推定可能であることが示唆され\nた[13]．\n2.3\nコンテンツ評価\nLiu らは，図2-3 で示すシステムを用いて，映画の予告編の評価において脳波計とアイ\nトラッカを同時に使用する新しいプラットフォームを提案した．YouTube での評判と専門\n家の評価によって良いと判断された予告編は悪いと判断された予告編よりも前頭葉と後\n頭葉エリアでの高い同期性を示し，シーンの変化の際に，眼球運動と脳の活動が同期する\nことが判明した[14]．\n図2-3: 脳波計とアイトラッカを用いたシステム概要図（[14] より引用）\nHe らは，ユーザの没入感の発生，関連要因，および脳波活動との関連を明らかにし，さ\nらに脳波信号を使用して没入感を予測し，ユーザの満足度の指標として活用することを提\n案した．音質と没入感には有意な正の相関があり，ノイズ量，画面のコントラストと没入\n感には有意な負の相関があることがわかった．低周波帯では脳波信号と没入感に負の相関\nがあり，前頭葉のガンマ波と没入感に正の相関がある．提案手法を用いることで，予測没\n入感スコアがユーザの満足度を評価するのに有効であることが示唆された[15]．\n三角らは，音楽が前頭前野の脳血液量に与える影響を調査した．ユーザはリラックした\n音楽と騒々しい音楽を聴取し，その間の脳血液量の変化を測定した結果，図2-4 のグラフ\nのように，音楽聴取時に酸素化ヘモグロビンと総ヘモグロビンが増加し，その後減少．脱\n酸素化ヘモグロビンはほとんど変化がないことが判明した．音楽聴取は前頭前野の脳活動\nの一時的な活性化とその後の抑制を引き起こすことが示唆された[16]．\n7\n図2-4: 脳血液量の変化を示すグラフ（[16] より引用）\n宮本らは，動画レコメンドシステムがユーザの興味に沿った動画を推薦するために，生\n体信号を利用してユーザの動画に対する印象を評価する方法を提案した．皮膚電気活動，\n指尖皮膚温，心拍数などの生体信号を測定し，これらのデータを基にユーザの動画に対す\nる嗜好性を推定した．実験の結果，興奮刺激の多い動画では皮膚電気活動の値が高くなる\nことが判明した[17]．\n2.4\nフィードバックによるコンテンツ体験の変化\n2.4.1\n風による動画体験の拡張に関する研究\n岡本らは，ワイヤアクションゲームプレイ中の風の強度によって臨場感がどのように変\n化するかについて検証した．プレイヤに風を当てる条件を3 つ設定（風なし，一定の風，\nワイヤアクションで引っ張られるときの速度に応じた風）し，臨場感をアンケートで評価\nしたところ，風がある状態の方が臨場感が高く，特に風力変化がある状態が最も臨場感を\n感じやすいことが判明した[18]．\n伊藤らは，VR 環境での現実感向上のため，風覚を利用して全周囲から風を感じる方法\nを提案した．HMD を装着した被験者に対し，特定の角度に配置した送風機から風を送る\n実験を実施したところ，4 台の送風機を特定の角度に配置することで，被験者は全方向か\nら風を感じる錯覚を体験した．本研究により，VR 体験の没入感を高めるための新しいア\nプローチが示唆された[19]．\n村田らは，前方への自己運動を示唆する皮膚感覚がベクション（実際には静止している\n8\n人間が，視覚情報によって移動しているような感覚が引き起こされてしまう現象）を促進\nまたは抑制するかを調査した．被験者の顔に電気ファンを使用して風を送ることで，2 つ\nの条件（熱風と通常の温度の風）を設定した．通常の温度の風ではベクションの強度が増\n加し，熱風では抑制されることが判明した[20]．\n小島らは，ユーザの移動を可能にし，狭い領域への風提示を実現する新しい風ディスプ\nレイの構築を提案した．図2-5 のように，軽量な自転車ヘルメットを使用し，耳近傍に風\nを提示するためのスピーカユニットを搭載した．本デバイスにより，速度感，爽快感の増\n強が実現可能と考えられた[21]．\n図2-5: 耳近傍に風を提示するためのスピーカユニット（[21] より引用）\n2.4.2\n温度による動画体験の拡張に関する研究\n前田らは，複数の体の部位に装着可能なモジュール式の熱フィードバックシステム「Ther-\nModule」を提案した．実験では，図2-6 のように，TherModule を使用して，視覚と温度\nフィードバックを同期させた映画体験被験者が，TherModule を手首，前腕，足首に装着\nし，視覚と温度フィードバックを受けながら映画を鑑賞したところ，視覚と温度フィード\nバックを受けた被験者は，視覚のみの被験者に比べて「楽しさ」と「興奮度」が有意に高\nかった．以上より，TherModule は映画体験を強化することが判明した[22]．\n牛尾らは，図2-7 のようなシステムを用いて，温度感覚を利用し，ゲーム中のプレイヤ\nの情動（興奮，安静など）を制御する手法の効果を検証した．ゲーム「スプラトゥーン2」\nの映像に合わせて温感を呈示し，情動の変化をアンケートとインタビュで評価した．実験\nの結果，楽しさ，面白さ，緊張感において有意な効果が確認されたが，冷静さ，興奮，焦\nりには効果が認められなかった．また，温感呈示のタイミングおよび温度設定に個人差が\nあり，長時間の温感呈示は集中を妨げる可能性があると示唆された[23]．\n9\n図2-6: TherModule のシステム概要図（[22] より引用）\n図2-7: 温度感覚を用いたシステム概要図（[23] より引用）\n2.4.3\n振動によるコンテンツ体験の拡張に関する研究\n安保らは，オンラインライブパフォーマンスにおける一体感を向上させるために，図\n2-8 に示すような他人の盛り上がりの度合いを振動によるフィードバックを可能にする衣\n服型ウェアラブルデバイス「ONEParka」を提案した．振動が盛り上がりの認知に効果的\nであることが明らかになった[24]．\nKim らは，触覚刺激が映画鑑賞の感情変化と没入感との関連性を調査した．ポジティブ\nなシーンで柔らかい刺激を受けると，他の条件よりもポジティブな感情と没入感が増加し\nた．ネガティブなシーンでは，柔らかい刺激がネガティブな感情を軽減したが，トゲのあ\nる刺激は感情および没入感に影響を与えないことがわかった[25]．\nMazzoni らは，触覚刺激を通じて新たな映画体験を提供する手法を提案した．8 つの振\n10\n図2-8: ONEParka（[24] より引用）\n動モータを手袋に取り付け，異なる強度と周波数の振動パターンを設計したところ，低強\n度・低周波数の触覚刺激はユーザに落ち着いを，低強度・高周波数の刺激は興奮を，高強\n度・高周波数の刺激は緊張感を高めることが示唆された．また，映画視聴中の触覚刺激は\n覚醒レベルが有意に高まることもわかった．映画視聴体験を触覚刺激によって強化可能で\nあることが確認された[26]．\n久保らは，振動および揺動を「快」の視点から取り扱い，快感情を誘発する振動・揺動\nを生理・心理・物理の三指標から評価した．自発的揺動刺激実験により，血圧がその評価\nにおいて有効な指標の一つであることが示唆された．また上下振動刺激実験から，ヒトは\n振動により消極的快と積極的快が誘発されることが明らかになり，その評価には血圧が有\n効な指標であることが示唆された[27]．\n久原らは，リモートコミュニケーションに振動触覚刺激を追加することで生じる心理的\n効果を調査した．振動触覚刺激による心理的効果を確認するために，感情的な合成音声に\n振動触覚刺激を追加する実験を行い，振動触覚刺激が合成音声のポジティブまたはネガ\nティブに聞こえる度合いに影響を与えることを示唆した．遅いリズムでは音声はネガティ\nブに，速いリズムではポジティブに聞こえることが確認された[28]．\n2.4.4\n香りによるコンテンツ体験の拡張に関する研究\n須佐見らは，映像と香りの相互作用が臨場感に及ぼす効果を検討した．「映像情報のみ」，\n「映像+映像にマッチした香り」，「映像+映像にミスマッチな香り」の3 条件について，評\n価値の条件差をSD 法を用いて測定した．その結果，「映像のみ」では遠隔的，空想的，外\n的な感じがするが，香りを付加すると映像のみの場合よりも女性的で，接近感，現実感，\n没入感が増す傾向が見られた．これらの結果から，映像に香りを付けると臨場感，特に近\n11\n空間への没入感が増加することが示唆された[29]．\n阿久津らは，香りが音楽によって引き起こされる感情に与える影響を調査した．参加者\nがペパーミントとラベンダの香りを嗅ぎながら，楽しい音楽と陰鬱な音楽を聴き，感情の\n評価を行った．楽しい音楽はラベンダによって誘発された楽しい気分を増幅し，陰鬱な音\n楽は両方のオイルによって誘発された楽しい気分を減少した．以上より，音楽がエッセン\nシャルオイルの香りによる感情に大きな影響を与えることが示唆された[30]．\n田中は，好きな香りが心理状態と知的作業遂行に与える影響について検討した．状態不\n安を低減する手段として，好きな香りが有効である可能性が示唆された．また，好きな香\nりが気分をいい方向に変化させる効果があることも示唆され，作業効率も向上されること\nも示唆された[31].\n2.5\n映画鑑賞体験の拡張\nOh らは，4DX 映画の観客が感じる臨場感について調査し，4DX 効果がどのように影響\nするかを分析した．7 つのジャンルの映画を対象に，35 名の観客に対して詳細なインタ\nビュを実施し，グラウンド理論を用いて結果を解析した．4DX 映画はリアリズムとして\nの臨場感，没入感，メディア内での社会的役割，社会的豊かさ，共感的移動感，社会的存\n在としての臨場感の6 つのタイプを引き起こすことが判明した．特に，モーションコント\nロールおよび振動，空気，匂いの効果が臨場感を高める重要な要因であることが示唆され\nた[32]．\nJeong らは，図2-9 のような椅子を設定して，4DX 映画におけるモーション効果が観客\nの感情に与える影響を調査した．特に，共感レベルに応じた感情反応の違いを分析し，高\nい共感を持つ参加者が短いモーション効果でより強い恐怖を感じることを明らかにした．\nまた，映画クリップとモーション効果の組み合わせが観客の感情を変化させることが示さ\nれ，モーション効果の設計に関するガイドラインを提案し，感情体験の向上に寄与する方\n法を示唆している[33]．\nLee らは，4DX 映画におけるモーション効果の迅速な設計を可能にするアルゴリズムを\n提案した．4DX 映画は視覚だけでなく，聴覚および触覚を通じて観客に没入感を提供す\nるため，モーション効果が重要な役割を果たす．提案されたアルゴリズムは視聴者中心の\nレンダリング戦略に基づき，視覚的注意の動きに合わせて椅子の動きを調整した．これに\nより，観客の体験を向上が実現された．さらに，本アプローチは自動化されており，手動\nでの作成に比べて10 倍以上の速度で動き効果を生成することが可能になった．実験によ\nり，生成されたモーション効果の主観的品質が評価され，視覚的に妥当な効果を提供する\nことが確認された．本研究は，4DX 映画の制作プロセスを効率化し，観客の体験をより\n12\n図2-9: 3-DOF motion chair（[33] より引用）\n豊かにするための新たな手法を示唆された[34]．\nNicolae は，従来の映画館とVR 映画館の違いを分析した．VR 映画館はヘッドセットが\n周囲の気を散らすものを遮断し，観客は映画に集中することを求められるが，従来の映画\n館での鑑賞と比較して社会交流が減少すると分析した．また，VR 作品の質は様々で，強\nい感情的な没入感を提供するものもあれば，「そこにいる」効果のみに依存するものもあ\nると述べた．VR 技術は従来の映画では実現できない強力な「臨場感」を生みだした[35]．\nKim らは，VR が人々の感情に与える影響を調査した．ヘッドマウントディスプレイ\n（HMD）を使用した視聴条件と使用しない視聴条件（No-HMD）を比較し，ホラーと共感\nの2 種類の感情的コンテンツを適用した．結果，HMD を使用してホラー映画を見た視聴\n者は，No-HMD の視聴者よりも恐怖を感じやすかったことが判明した．しかし，共感を\n誘発する映画では，HMD とNo-HMD の視聴者の間に有意な感情の差は見られなかった．\n研究では，VR がホラー映画に対して特に感情反応を強化することを示し，没入感と感情\nの関係を確認した[36]．\n2.6\n評価実験によるコンテンツ評価\n杉原らは，音楽に対する感性がどのように表現されるかを探求した．音楽の聴取中に音\n楽が引き起こす印象を評価するために，SD 法を使用した実験を実施し，音楽の特徴が聴\n取者の感情に与える影響を示唆した．楽曲から受ける印象の程度は男性と女性で異なるこ\nとおよび，感性語対によっても異なることが判明した[37]．\n仁科らは，観賞用の葉植物，花（バラ），および香りが人間に与える生理的および心理\n的影響を，脳波（アルファ波とベータ波の比率）およびSD 法を用いて分析した．その結\n13\n果，香りの存在によりアルファ波とベータ波の比率が高くなることが観察された．香りが\n人間の生理面に影響を与えることを示唆した．一方，バラの存在は高い評価得点をもたら\nし，花が人間の心理面に影響を与えることも示唆した[38]．\n寺本らは，非研究者が「没入感」をどのように概念化しているかを探求した．調査の結\n果，因子分析により，「評価」「インパクト」「活動性」「機械的性質」の4 つの因子が没入\n感の構成要素として抽出された．没入感が高いイベントは，好ましく，印象的で，動的で\nあると評価される傾向があった[39]．\n安藤は，図2-10 で示すように臨場感は複数の感覚要素の複合体として捉えることが可\n能であると考えた．これらの感覚要素としては，立体感，質感，包囲感からなる空間要素，\n動感，リアルタイム感，同時感からなる時間要素，さらに自己存在感，インタラクティブ\n感，情感からなる「身体要素」を挙げられた．臨場感の評価手法として，主観評価，心理\n物理評価，脳活動計測，生体信号計測，行動計測の五つの手法を提案した．これらの手法\nを統合して臨場感を客観的・定量的に評価する必要があることを示唆した．映像の質感\n評価では，立体映像が質感を強調し，心理物理実験により光沢感の定量的評価が行われ\nた[40]．\n図2-10: 臨場感の構成要素と生起要因（[40] より引用）\n飯村らは，VR を用いたシステムに関する臨場感と現実感の評価を行った．印象調査の\n結果，臨場感は「動き」など視覚との結びつきが強く，映画またはゲームなどから感じ取\nれるもので，「その場にいるような感覚」と定義された．一方，現実感は視覚以外に痛覚\nとの結びつきが強く，不安および痛みなどから感じ取れるもので，「非現実を現実と感じ\nる」と定義された．因子分析の結果，臨場感には迫力因子と評価性因子，現実感には現実\n性因子があることがわかった[41]．\n14\n2.7\n本研究の位置づけ\n上記のように，風や温度，触覚刺激が没入感や感情に与える影響やコンテンツ体験の拡\n張・評価方法は示されたが，多感覚フィードバック（振動，風，温冷感）の統合的な効果\nは十分に検証されていない．そのため，本研究では振動，風の強弱，温冷感を組み合わせ\nた多感覚フィードバックシステムImmersion Neckwear を開発し，これが動画鑑賞におけ\nる没入感やユーザ体験に与える影響を評価する．\n15\n第3章\nImmersion Neckwear:\n動画体験拡張ネックウェア\n3.1\nImmersion Neckwear の概要\nImmersion Neckwear では，映像に合わせて五感を刺激するフィードバックを行うこと\nで，自宅での動画鑑賞者が映像により没入することを目指している．どこでも4DX のよ\nうな感覚刺激を楽しむことができ，利用者の自由度が高く，多感覚のフィードバックを提\n供する頸部装着型の没入感向上デバイスを創作した．Immersion Neckwear のイメージ図\nを図3-1 に示す．\n図3-1: Immersion Neckwear を利用した動画鑑賞の例\n図3-2 は本研究で創作した頸部装着型の没入感向上デバイスImmersion Neckwear であ\nる．Immersion Neckwear とは，Immersion（没入）とNeckwear（ネックウェア）を用い\nて創作した今回のシステムの名称である．Immersion Neckwear の重さは約844g であり，\nImmersion Neckwear が本実験中に不快感を与えるか調査した．\n16\n図3-2: Immersion Neckwear の全体像\n3.2\nImmersion Neckwear の基本設計\n表3-1 は各構成要素の機能概要であり，図3-3 にImmersion Neckwear の基本システム構\n成を示す．Immersion Neckwear は制御部を中心に，電源部，フィードバック部，インター\nフェース部の4 つに分類される．\n表3-1: 各構成要素の機能概要\n要素名\n機能\n構成部品\nインターフェース部\n開始時間の出力\nnRF Connect\n電源部\n電源の供給\n5500mAh リチウムイオンバッテリ\n制御部\n電子部品の起動時間の制御\nペルチェ素子TEC1-03105\nフィードバック部\n映像に合わせたフィードバック\n温冷部：ペルチェ素子TEC1-03105\n風部：ターボブロワファンB0DB5SDX91\n振動部：振動モータLBV10B-009\n3.2.1\n各要素の機能詳細\nインターフェース部は，スマートフォンを用いてマイクロコンピュータと接続すること\nで，映像に合わせてシステムの開始を出力する．\n17\n図3-3: システムの基本設計\n電源部は，制御部に電源を供給する．\n制御部は，他の構成要素の制御を行う．映像に合わせて電子部品の起動時間の制御を行\nう．また，電源部からの電源供給により，フィードバック部に電源供給を行う．\nフィードバック部は，制御部からの電源供給により，映像に沿ったフィードバックを\n行う．\n3.3\nハードウェアの設計\nImmersion Neckwear は，ペルチェ素子TEC1-03105（図3-4），Arduino Nano 33 BLE（図\n3-9），ターボブロワファンB0DB5SDX91（図3-10），振動モータLBV10B-009（図3-11），\n超音波ミストB0DBLL2TKL（図3-12），バッテリはKeepPower 26650 リチウムイオンバッ\nテリ5500mAh（図3-13）から構成する．\n3.3.1\n熱源の選定と温度制御\nImmersion Neckwear では，温刺激，冷刺激を瞬時に生じさせる必要があった．よって，\nエネルギ効率が電熱線より高く，電流の向きにより加熱と冷却が同一の電子部品で実現\n可能な，ペルチェ素子TEC1-03105 を用いた．TEC1-03105 のサイズは縦横15mm，厚さ\n3.1mm である．TEC1-03105 は，直流電流を流すことで一方の面が吸熱し反対面に発熱が\n起こす．電流の極性を逆転させると，特性が反転する[42]．\n18\n図3-4: ペルチェ素子（[42] より引用）\n温度提示面の温度検出として，NTC サーミスタを用いた（図3-5）．NTC サーミスタは，\n温度上昇に対して抵抗値を減少させる性質があり，以下の式（1）を満たす[42]．よって，\n式変形した式（2）を用い，温度検出を行った．\nR = R0 exp\n(\nB\n( 1\nT −1\nT0\n))\n・・・（1）\nT =\n\n\n1\n1\nT0 + 1\nB log\n(\nR\nR0\n)\n\n\n・・・（2）\nR0\n温度T0 [K] 時のサーミスタ抵抗[Ω]\nR\n温度T [K] 時のサーミスタ抵抗[Ω]\nB\nサーミスタB 定数\nT0\n基準温度[K]\nT1\n測定温度[K]\n温度制御は，マイクロコンピュータのPWM（Pulse Width Modulation）出力を用いて，\n19\n図3-5: NTC サーミスタ\nPID 制御を行った．PWM 制御は，デジタル信号を用いてアナログ信号を模倣する手法で\nあり，制御対象の平均電圧を調整することで精密な制御を実現する．これにより，デバイ\nスはエネルギ効率を高めつつ，目的の動作を実現する．\nPWM 信号は，デューティサイクルと呼ばれる高電圧状態と低電圧状態の比率によって\n制御される．\n図3-6 に示すように，PWM 信号は一定周期でON とOFF を繰り返すデジタル波形であ\nる．デジタル波形を用いることで，加熱素子および冷却素子に供給されるエネルギの平均\nを調整し，温度を適切に制御をすることが可能になる．\n図3-6: PWM 出力の概念図（[43] より引用）\n20\nまた，本研究では，ペルチェ素子の同一面で温熱面と冷却面の両方を制御する必要が\nあった．よって，モータに回転，逆回転，ストップ，プレーキ等の制御を行うことができ\nるモータドライバを用いた．モータドライバTA7291P（図3-7）とPWM 出力を用いてペ\nルチェ素子の温度制御を行った．本研究では，温度センサを用いたPID 制御を行うこと\nで，温熱面を40 ℃，冷却面を20 ℃に設定してフィードバックをした．\n図3-7: モータードライバ（TA7291P）（[44] より引用）\nPID 制御とは，proportional（比例），integral（積分），differential（微分）の三つの制御\n要素を組み合わせた制御手法であり，設定温度に対する誤差を最小限に抑えるためのもの\nである．PID 制御を用いることで，図3-8 に示すように，目標とする温度に迅速かつ安定\n的に達成することが可能となる．具体的には，温度センサで検出した現在の温度と目標温\n度の差をもとに，ペルチェ素子への電力供給を調整する．これにより，過剰な温度変動を\n防ぎ，安定した温度制御が可能となった．\n21\n図3-8: PID 制御による温度制御（[45] より引用）\n3.3.2\nその他電子部品の選定\nImmersion Neckwear では，首にデバイスをかけて映像を見てもらうため，利用者の映像\n体験に影響を与えることを防ぐために軽量化する必要があった．また，インターフェース\n部と制御部をBluetooth で接続可能なマイクロコンピュータを選定した．Arduino Nano 33\nBLE は，Arduino が開発した長辺40.64mm，短辺17.76mm の小型のマイクロコントロー\nラボードである．Bluetooth Low Energy（BLE）機能を内蔵しており，スマートフォンお\nよび他のIoT デバイスとの無線通信が可能である．本研究では，提案ボードの低消費電力\n性と小型性を活かし，システム全体の制御に利用した[46]．\n図3-9: Arduino Nano 33 BLE（[46] より引用）\n使用者の不快感を考慮し軽量化かつ，フィードバックの強い電子部品を選択した．風に\nよるフィードバックとして利用するターボブロワファンは定格回転速度6000RPM，風量\n4.0CFM，静圧6.61mmAq である[47]．\n22\n図3-10: ターボブロワファンB0DB5SDX91\n振動によるフィードバックとして利用する円盤形ブラシレス振動モータは，直径10mm\nであり，バラスト重心の偏芯によって，高速回転時に強い振動を発生させた[46]．\n図3-11: 振動モータLBV10B-009（[46] より引用）\nミストによるフィードバックとして超音波霧化メーカを用いた．モジュールのサイズ\nは長辺29.5mm，短辺18.6mm，厚さ7mm，共振周波数108～110KHz である．また，提\n案デバイスを用いて香り付きの水を噴霧することで香りによるフィードバックを実現し\nた[48]．\n23\n図3-12: 超音波ミストB0DBLL2TKL\n本研究では，多くの電子部品を用いるので，電気容量が高いバッテリが必要であった．\n実験で使用するKeepPower-26650 は，定格容量5500mAh であり，本研究の実験中の連続\n稼働が可能であることから選択した[49]．\n図3-13: KeepPower 26650 リチウムイオンバッテリ5500mAh（[49] より引用）\n24\n第4章\nImmersion Neckwearの没入感効果検証\n実験\n本章では，Immersion Neckwear を用いた評価実験について述べる．\n4.1\n実験概要\n第1 章で説明したように，Immersion Neckwear の有無によって動画体験の印象を違いを\n比較し，有効性の検証を行うことを目的とする．\n被験者は成人男性8 名，成人女性2 名の計10 名（年齢層は22 歳から26 歳）に協力し\nてもらった．実験では，25 分程度の初めて視聴するアクションアニメを視聴してもらっ\nた．鑑賞終了後には，被験者にSD 法（Semantic Differential Method）を用いたアンケー\nトを記入してもらい，動画鑑賞に対する主観的な評価を収集した．また，正確な制御が困\n難であり被験者の実験中に怪我を負わせる可能性があったので，今回，超音波ミストの使\n用を中止した．\n4.2\n実験手順\n本実験では，フィードバックを起こす場面の個数がほぼ等しい25 分程度の2 つの動画\nを用意し，被験者はImmersion Neckwear を使用した場合と使用していない場合で動画鑑\n賞を行った．表4-1 は場面とフィードバックの種類の対応を示している．システム有無\nによる動画鑑賞はそれぞれ別日に行なった．動画の視聴が終了後，被験者にはSD 法によ\nるアンケートに回答してもらい，視聴体験に対する主観的な評価を収集した．さらに，\nImmersion Neckwear を使用して視聴した被験者については，システムの使いやすさに関\nする評価を行うために，SUS（System Usability Scale）を用いてアンケートを実施した．\nSUS アンケートでは，システムの全体的な使いやすさおよび利便性，直感的な操作性な\nどを評価した．図4-1 はImmersion Neckwear を装着した場合の実験中の様子である．\n25\n表4-1: 場面の種類に応じたフィードバックの対応\n場面の種類\nフィードバック\nそよ風，爆風，向かい風\n風\n爆発，炎が出現するシーン\n温感\n氷が出現するシーン\n冷感\n戦闘シーン(攻撃が当たるシーン)\n振動\n図4-1: 実験の様子\n4.3\nSD 法\nSD 法は各刺激に対して人が抱く印象，イメージを明らかにするために用いる手法で，\n相反する形容詞対を多数用いて刺激を評価することにより，人がその刺激に対して，どの\nように感じるかといった情緒的な印象を明らかにすることが可能となる[50]．\n以下に，アンケートに用いる印象語対を記す．\n• 好きな　＿＿＿＿＿＿＿＿＿　嫌いな\n• 良い　＿＿＿＿＿＿＿＿＿＿　悪い\n• 気持ちの良い　＿＿＿＿＿＿　気持ちの悪い\n• はっきりした　＿＿＿＿＿＿　ぼんやりした\n26\n• 迫力のある　＿＿＿＿＿＿＿　迫力のない\n• リアリティのある　＿＿＿＿　リアリティのない\n• 動的な　＿＿＿＿＿＿＿＿＿　静的な\n• 弱い　＿＿＿＿＿＿＿＿＿＿　強い\n• 興奮した　＿＿＿＿＿＿＿＿　落ち着いた\nそして，各形容詞対を左から「非常に」，「かなり」，「やや」，「どちらでもない」，「やや」，\n「かなり」，「非常に」の7 段階で評価した．付録A は，本実験で使用したアンケートフォー\nムである．\n4.4\nSUS\nSUS は，製品およびサービスの使いやすさを評価するためのアンケートのことである．\nこれは，ソフトウェア，ハードウェアを問わず，さまざまな新しいシステムのユーザビリ\nティを評価し，洞察を得るための定量的な手法として使用される．リッカート尺度を使用\nして回答する10 個の質問で構成される．本研究では，「強く同意する」から「強く同意し\nない」までの5 段階で評価した[51]．\nまず，SUS 調査の各回答選択肢を対応する評定を割り当てる．回答が「強く反対」の場\n合は1 点，「反対」の場合は2 点，「どちらでもない」の場合は3 点，「同意する」の場合\nは4 点，そして「強く同意」の場合は5 点とする．\n各質問項目への回答（評点X）に基づき，以下の方法で得点を計算する．\n• 奇数番目の項目：X －1 点\n• 偶数番目の項目：5 －X 点\n• 未回答の項目：3 点\nこれらの得点を合計し，その合計値に2.5 を乗じることで，0-100 点のSUS スコアが算出\nする．SUS スコアが高いほど，評価対象の製品，システム自体，およびその利用開始まで\nの過程または利用後に期待される効果に対するユーザの満足度が高いと判断される[52]．\nSUS (System Usability Scale) のスコアリングと解釈について，以下のようにまとめる．\n• A+: 84.1–100 (96th–100th percentile)\n• A: 80.8–84.0 (90th–95th percentile)\n27\n• A －: 78.9–80.7 (85th–89th percentile)\n• B+: 77.2–78.8 (80th–84th percentile)\n• B: 74.1–77.1 (70th–79th percentile)\n• B －: 72.6–74.0 (65th–69th percentile)\n• C+: 71.1–72.5 (60th–64th percentile)\n• C: 65.0–71.0 (41st–59th percentile; 平均的なユーザビリティ)\n• C －: 62.7–64.9 (35th–40th percentile)\n• D: 51.7–62.6 (15th–34th percentile)\n• F: 0.0–51.6 (0th–14th percentile; 低いユーザビリティ)\nグローバル平均SUS スコアは約68 で，これはC グレード(平均的なユーザビリティ) に\n相当する．50 未満のスコアは欠陥があると見なされ，80 以上のスコアを持つシステムは，\n平均以上のユーザエクスペリエンスを示し，優れたユーザビリティに関連している．65\nから80 のスコアは受け入れ可能だが，改善の余地があることを示唆している．65 未満の\nスコアは，ユーザビリティの問題があることを示しており，注意が必要である．\nSUS は，その信頼性と有効性が広く認められており，さまざまな製品およびシステムの\nユーザビリティ評価に使用されている．さらに，SUS は柔軟性があり，軽微な文言変更に\nも影響されず，異なる言語，文化にも適用可能である．SUS の規範データは代表的なグ\nループから収集され，スコアの解釈を強化するために使用される[53]．\n付録B は，本実験で使用したアンケートフォームである．\n28\n第5章\n実験結果および考察\n5.1\n実験結果\n5.1.1\nSD 法の評価結果\n動画鑑賞後にSD 法を用いたアンケートを実施した．本アンケートを「プロフィール分\n析」と「因子分析」を利用してデータの分析を行うことで，Immersion Neckwear の有無に\nよる映画体験の没入感の変化を評価した．\n図5-1 は被験者が回答したデータから，評定尺度ごとの回答平均値を算出して図式化し\nたプロフィール分析の結果である．縦軸は各形容詞対を表し，横軸は形容詞対に対する7\n段階の評価尺度を表す．青線がImmersion Neckwear を装着をした場合の動画鑑賞時の印\n象を示しており，赤線がImmersion Neckwear を装着しなかった場合の動画鑑賞時の印象\nを示している．プロフィール分析によって，Immersion Neckwear を装着した場合としな\nかった場合の印象の違い，Immersion Neckwear の装着が被験者の印象に与える影響を視\n覚的に比較可能になる．\n図5-1: Immersion Neckwear のプロフィール分析\n共通因子を特定するために，アンケートデータに対して因子分析を実施した．Immersion\nNeckwear を装着した場合の因子分析の結果を表5-1 に示す．初期の固有値の大きさと減\n衰状況から，因子数は3 と判断した．因子負荷量は，因子と変数の間に有意な相関がある\n29\nと言われている絶対値0.4 以上とし，斜交回転法を用いて因子間の相関関係を考慮できる\nプロマックス回転を適用した．因子負荷量の絶対値が1 に近いほど，因子との関係性が\n強いことを示す．因子1 は「好きな」，「良い」，「迫力ある」などの形容詞と強く関連して\nいることがわかった．また，因子2 は「興奮した」，「強い」，「気持ちのいい」，因子3 は\n「はっきりした」，「リアリティのある」などの形容詞と関連が深いことが判明した．\n表5-1: システムを装着する時の因子負荷量\n形容詞1\n形容詞2\n因子1\n因子2\n因子3\n嫌いな\n好きな\n0.888\n-0.376\n-0.073\n悪い\n良い\n0.820\n0.321\n-0.043\n迫力のない\n迫力のある\n0.744\n0.317\n0.189\n落ち着いた\n興奮した\n-0.027\n0.982\n-0.245\n弱い\n強い\n-0.080\n0.651\n0.107\n気持ちの悪い\n気持ちのいい\n-0.278\n0.505\n0.207\nぼんやりした\nはっきりした\n0.062\n0.055\n0.998\nリアリティのない\nリアリティのある\n-0.108\n-0.024\n0.824\n寄与率\n30.282\n20.791\n14.951\n回転後の負荷量平方和\n2.457\n2.313\n1.849\nImmersion Neckwear を装着しなかった場合の因子分析の結果を表5-2 に示す．因子負荷\n量の絶対値が1 に近いほど，因子との関係性が強いことを示す．因子1 は「迫力のある」，\n「良い」，「興奮した」，「強い」などの形容詞と強く関連していることがわかった．また，因\n子2 は「はっきりした」，「リアリティのある」などの形容詞と関連が深いことが判明した．\n表5-2: システムを装着しない時の因子負荷量\n形容詞1\n形容詞2\n因子1\n因子2\n迫力のある\n迫力のない\n0.953\n0.157\n良い\n悪い\n0.861\n-0.066\n興奮した\n落ち着いた\n0.669\n-0.256\n強い\n弱い\n0.500\n-0.027\nはっきりした\nぼんやりした\n0.116\n0.994\nリアリティのある\nリアリティのない\n-0.232\n0.842\n寄与率\n46.164\n30.801\n回転後の負荷量平方和\n2.414\n1.792\n30\n5.1.2\nSUS の評価結果\nImmersion Neckwear のユーザビリティを評価するために，SUS によるアンケートを行っ\nた．表5-3 は被験者ごとのSUS によるアンケートの回答結果をまとめたものである．\n表5-3: SUS のアンケート結果\n被験者ID\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ8\nQ9\nQ10\nスコア\n1\n5\n2\n5\n2\n2\n2\n4\n4\n4\n4\n65\n2\n4\n3\n5\n3\n1\n2\n5\n4\n4\n3\n60\n3\n4\n1\n5\n1\n4\n4\n5\n1\n5\n5\n77.5\n4\n5\n2\n5\n2\n2\n3\n5\n2\n5\n4\n72.5\n5\n4\n1\n5\n4\n5\n5\n5\n1\n4\n4\n70\n6\n5\n3\n4\n1\n5\n2\n5\n1\n4\n5\n77.5\n7\n4\n3\n4\n5\n3\n4\n4\n3\n4\n5\n47.5\n8\n3\n4\n3\n5\n2\n3\n3\n2\n1\n2\n40\n9\n5\n2\n4\n4\n4\n2\n4\n4\n4\n3\n65\n10\n5\n3\n5\n2\n5\n3\n5\n2\n5\n5\n75\n平均値\n4.4\n2.4\n4.5\n2.9\n3.3\n3\n4.5\n2.4\n4\n4\n65\n標準偏差\n0.63\n0.87\n0.64\n1.38\n1.35\n0.95\n0.64\n1.14\n1.04\n0.95\n11.48\nまた自由記述欄にて，「微妙な重さが少し気になった」，「デバイスが大きいと感じた」，\n「温度が人によっては暑すぎる」などの指摘がされた．一方で，「アニメに合わせて温度変\n化があり楽しかった」，「cooler とwarmer 機能は実際に感じて，リアルタイム性も高いと\n思った」のようなImmersion Neckwear の使用にポジティブな意見もあった．\n5.2\n考察\n5.2.1\nSD 法の評価結果に関する考察\nプロフィール分析の結果，Immersion Neckwear を装着した場合と装着しなかった場合\nの印象に違いがみられた．Immersion Neckwear を装着した場合，各形容詞対全体で肯定\n的な評価が確認された．これにより，Immersion Neckwear はユーザのポジティブな印象\nを高める効果があると推察する．よって，動画鑑賞におけるImmersion Neckwear の装着\nが，動画の印象を向上させる要因となることが考えられる．特に，「動的な-静的な」に関\nして，Immersion Neckwear の有無によって印象の変化が推察される．これはImmersion\nNeckwear が画面に応じて起動されることを，「動的」と捉えたと考える．\n表5-4 と表5-5 は，形容詞を使った印象の評価を分析した結果を示している．結果に基\nづき，Immersion Neckwear を使ったときの印象を整理した．\n31\nImmersion Neckwear を装着すると，因子1 は「好きな」「良い」「迫力ある」といった言\n葉と強く結びつきことがわかる．これを「評価」とまとめた．因子2 は「興奮した」「強\nい」「気持ちのいい」と関連が深かったため，「活力」とした．因子3 は「好きな」「はっ\nきりした」「リアリティのある」などの言葉と関係があったので，「現実性」とした．\n結果から，Immersion Neckwear を装着した動画鑑賞において，「評価」「活力」「現実性」\nの印象を持つことが考えられる．\n表5-4: システムを装着した場合の，形容詞と因子の意味付け\n因子\n形容詞\n因子の解釈\n1\n「好きな」，「良い」，「迫力のある」\n評価\n2\n「興奮した」，「強い」，「気持ちのいい」\n活力\n3\n「はっきりした」，「リアリティのある」\n現実性\nImmersion Neckwear を装着しない場合，因子1 は「迫力のある」，「良い」，「興奮した」，\n「強い」といった言葉と強く結びつきことがわかる．これを「活力」とまとめた．因子2\nは「はっきりした」「リアリティのある」と関連が深かったため，「現実性」とした．\n結果から，Immersion Neckwear を装着した動画鑑賞において，「活力」「現実性」の印象\nを抱くことが考えられる．\n表5-5: システムを装着しない場合の，形容詞と因子の意味付け\n因子\n形容詞\n因子の解釈\n1\n「迫力のある」，「良い」，「興奮した」，「強い」\n活力\n2\n「はっきりした」，「リアリティのある」\n現実性\n因子の解釈から，従来の動画鑑賞での印象を包括しながらも，\n「評価性」といった新たな肯\n定的印象が増えていることがわかる．よって，因子分析の結果として，Immersion Neckwear\nを用いた動画鑑賞は，Immersion Neckwear を使用しない場合よりも優れた鑑賞体験を提\n供することを推察する．また，寺本らの研究では，評価性が没入感の要素として抽出され\nておりImmersion Neckwear を使った動画鑑賞がより没入感のある体験と考えられる[39]．\n5.2.2\nSUS の結果に関する考察\nSUS によって評価されたシステム全体の平均値が68 点であり，今回のSUS スコアが65\n点であることから，C グレードに相当する．よって，Immersion Neckwear のユーザビリ\nティは改善の必要があると考える．質問4（技術的サポートの必要性），質問8（操作性）\nでは平均点が低く，回答にばらつきが見られた．実験では，被験者に動画を鑑賞すること\nだけを指示し，システムの装着および起動は研究担当者が行ったため，一部の被験者はシ\n32\nステムの使用に技術的サポートが必要と感じたと考えられる．さらに，使用感に関しても\n一部の被験者から不満が出た．Immersion Neckwear の重さが800g を超えており，これが\n動画鑑賞中の不快感につながり，システムの使用が面倒だと感じたと考えられる．以上の\nSUS に基づくアンケート結果から，システムのユーザビリティには改善の余地があると\n考えられる．ただし，「アニメに合わせた温度変化が楽しかった」，「cooler とwarmer 機能\nがリアルタイムで感じられた」などのポジティブな意見もあり，Immersion Neckwear が\n動画鑑賞の没入感向上に有効であることが推察できる．\n33\n第6章\n結論\n6.1\nまとめ\n本論文では，自宅での動画鑑賞体験を拡張することを目的として，多感覚フィードバッ\nクを提供する頸部装着型没入感向上デバイスImmersion Neckwear を創作した．Immersion\nNeckwear は，映像に合わせて振動，風の強弱，温感，冷感などを提示することで，映画\n館での没入感に近い体験を自宅でも再現することを目指している．\n実験結果から，Immersion Neckwear を装着した動画鑑賞では，被験者がよりポジティブ\nな印象を抱き，動画の没入感が向上することが確認された．具体的には，SD 法によるア\nンケートの因子分析で，システムの装着により評価性が高まることが確認された．\n一方，SUS によるユーザビリティ評価では，平均値が65 点となり，技術的サポートの\n必要性およびシステムの重さ・大きさに関する不満が一部の被験者から指摘された．しか\nし，「アニメに合わせた温度変化が楽しかった」，「cooler とwarmer 機能がリアルタイムで\n感じられた」といったポジティブな意見も多く，Immersion Neckwear が動画鑑賞の没入\n感向上に有効であることが示唆された．\n6.2\n今後の展望\n今後の展望として，ユーザビリティの向上が必要である．SUS アンケート結果から示\nされた技術的サポートの必要性およびシステムの重さ，大きさに関する不満を解消するた\nめ，ユーザインターフェースの改善，デバイスの軽量化，コンパクト化が求められる．具\n体的には，より直感的な操作が可能なインターフェースデザインを採用し，ユーザが簡単\nにシステムを操作可能にすることが挙げられる．また，使用する素材の見直しおよび電子\n部品の改良によって，デバイス全体の軽量化を図ることが考えられる．今回，映像に合わ\nせて，風，振動，温冷部を実装したが，ミストや香りによるフィードバックの実装を目指\nす．これにより，ユーザが映像から感じる臨場感が向上すると考える．さらに，フィード\nバック機能の強化も重要な課題である．Immersion Neckwear は，振動，風の強弱，温感，\n冷感といった多感覚のフィードバックを提供しているが，これらのフィードバックの精\n度，リアルタイム性の向上が求められる．特に，映像に合わせたフィードバックのタイミ\nング，強度をより正確に制御するための技術開発が必要である．これらにより，ユーザに\n34\nより一層没入感を感じさせることができると考えられる．また本研究では，20 代の男女\n10 名の被験者データのみ取得したが，より多くの被験者を対象にした大規模な実験を実\n施し，統計的に有意なデータを収集することで，Immersion Neckwear の効果をより明確に\n示す必要があると考えられる．また，異なる年齢層および文化背景を持つ被験者を対象に\nした研究を行うことで，ユーザビリティ，没入感に対する高度なシステムを実現したい．\n35\n謝辞\n本研究を進めるうえで，親身に相談に乗って下さった青山学院大学理工学部情報テクノ\nロジー学科ロペズ・ギヨーム教授に深く感謝をいたします．また，研究初期において，電\n子工作のやり方など助言を下さった青山学院大学理工学研究科理工学専攻知能情報コー\nス博士前期課程１年ボデガ　パロメケ　ペドロ氏，3D プリンタの使用をサポートとして\nくださった田崎研究室の山田様，研究環境の補助をしてくださった大熊氏，論文の添削を\n通してアドバイスをくださった高山先輩をはじめとするロペズ研究室の院生の方々，同期\nの方々に深く感謝いたします．また，実験に協力していただいた被験者の方々にも感謝い\nたします．\n2025 年1 月24 日\n岩本空\n36\n参考文献\n[1] 株式会社ＩＣＴ総研：2023 年有料動画配信サービス利用動向に関する調査，https:\n//ictr.co.jp/report/20230421.html/. (最終参照日: 2025/1/3).\n[2] GEMPartners 株式会社：動画配信（VOD）市場5 年間予測（2024-2028 年）レポート，\nhttps://gem-standard.com/columns/789/. (最終参照日: 2025/1/5).\n[3] 株式会社プラネット：映画に関する意識調査，https://www.planet-van.co.\njp/shiru/from_planet/vol210.html. (最終参照日: 2025/1/5).\n[4] 株式会社宣成社：映画離れする映画館，https://senseisha.co.jp/useful/\nkiji.php?n=23. (最終参照日: 2025/1/5).\n[5] 株式会社スパコロ：映画館の利用意識調査～コロナ禍、映画館利用意識どう変わっ\nた？～，https://prtimes.jp/main/html/rd/p/000000041.000060722.\nhtml. (最終参照日: 2025/1/5).\n[6] TOHO\nシネマズ：MX4D™,\nhttps://www.tohotheater.jp/service/\nmx4d/. (最終参照日: 2025/1/5).\n[7] 代蔵巧，棟方渚，小野哲雄，松原仁：他者の存在を感じる動画鑑賞システム，研究報\n告エンタテインメントコンピューティング（EC），Vol. 2011-EC-19, No. 2, pp. 1–6\n(2011).\n[8] 松井啓司，中村聡史：周辺視へのエフェクト提示による動画の印象変化に関する調\n査，第78 回全国大会講演論文集，Vol. 2016, No. 1, pp. 303–304 (2016).\n[9] 三上紀一，小川剛史：音楽体験向上のための電気的筋肉刺激を用いた感情増幅手法\nの検討，研究報告グループウェアとネットワークサービス（GN），pp. 1–6 (2019).\n[10] 三ツ木萌，丸山一貴：脳波と皮膚電気活動を用いた観客の盛り上がり推定の試み，エ\nンタテインメントコンピューティングシンポジウム論文集，Vol. 2021, pp. 370–374\n(2021).\n37\n[11] Terasawa, N., Tanaka, H., Sakti, S. and Nakamura, S.: Tracking liking state in brain\nactivity while watching multiple movies, Proc. of the 19th ACM International Conference\non Multimodal Interaction (ICMI ’17), pp. 321–325 (2017).\n[12] 平松拓也，池田悠平，保科篤志，馮晨，高橋裕也，菅谷みどり：生体情報による感情\n推定手法とステージの観客反応による評価，マルチメディア, 分散協調とモバイルシ\nンポジウム2017 論文集，pp. 857–864 (2017).\n[13] 角田啓介，江口佳那，吉田和広，渡部智樹，水野理：心拍と呼吸を用いたコンテンツ\n視聴による気分変化の推定：コメディ視聴における検討，情報処理学会論文誌コン\nシューマ・デバイス＆システム（CDS），Vol. 7, No. 1, pp. 44–52 (2017).\n[14] Liu, S., Lv, J., Hou, Y., Shoemaker, T., Dong, Q., Li, K. and Liu, T.: What Makes a Good\nMovie Trailer?: Interpretation from Simultaneous EEG and Eyetracker Recording, MM\n’16: Proceedings of the 24th ACM international conference on Multimedia, pp. 82–86\n(2016).\n[15] He, Z., Zhang, S., Sun, P., Li, J., Xie, X., Zhang, M. and Liu, Y.: Understanding User Im-\nmersion in Online Short Video Interaction, CIKM ’23: Proceedings of the 32nd ACM In-\nternational Conference on Information and Knowledge Management, pp. 731–740 (2023).\n[16] 三角真，折居英章，SHARMIN, T.，三島健司，西原宏：fNIRS による音楽聴取時の前\n頭前野における脳血液量の測定と考察，福岡大学工学集報，Vol. 96, pp. 25–28 (2016).\n[17] 宮本晴司，代蔵巧，棟方渚，小野哲雄：生体信号を用いた動画視聴中のユーザ評価の\n推定，エンタテインメントコンピューティングシンポジウム，Vol. 2015, pp. 568–573\n(2015).\n[18] 岡本早織，羽田久一：ゲームプレイ中の風の強度による臨場感の変化，エンタテイ\nンメントコンピューティングシンポジウム，Vol. 2022, pp. 135–138 (2022).\n[19] 伊藤亘輝，小野龍一，羽田久一：VR 空間で全周囲から風を感じる為の送風機の配置\nの検討，研究報告コンシューマ・デバイス& システム(CDS)，Vol. 2019, No. 48, pp.\n1–5 (2019).\n[20] 村田佳代子，妹尾武治：風によるベクションの促進と抑制―温風の効果について―，\n日本バーチャルリアリティ学会論文誌，Vol. 22, No. 2, pp. 287–290 (2017).\n[21] 小島雄一郎，橋本悠希，梶本裕之：頭部搭載型風ディスプレ，インタラクション，\nVol. 2009 (2009).\n38\n[22] Maeda, T. and Kurahashi, T.: Thermodule: Wearable and modular thermal feedback sys-\ntem based on a wireless platform, Proceedings of the 10th Augmented Human Interna-\ntional Conference 2019, pp. 1–8 (2019).\n[23] 牛尾大翔，黒田千晶，水口充ほか：温感呈示による情動制御手法の効果の検証，エンタ\nテインメントコンピューティングシンポジウム2022 論文集，Vol. 2022, pp. 102–105\n(2022).\n[24] 安保友香梨，松井遼太，柳沢豊，竹川佳成，平田圭二：ONE Parka：オンラインライブ\nパフォーマンス視聴のための一体感を促進する衣服型ウェアラブルデバイスの設計\nと実装，情報処理学会論文誌デジタルコンテンツ（DCON），Vol. 12, No. 1, pp. 18–28\n(2024).\n[25] Kim, A., Bae, H. and Lee, K.: Effects of Tactile Perception on Emotion and Immersion\nto Film Viewing in a Virtual Environment, VRST ‘19: Proceedings of the 25th ACM\nSymposium on Virtual Reality Software and Technology，pp. 1–3 (2019).\n[26] Mazzoni, A. and Bryan-Kinns, N.: Mood Glove: A Haptic Wearable Prototype System\nto Enhance Mood Music in Film, Media and Arts Technology Centre for Doctoral Train-\ning, School of Electronic Engineering and Computer Science, Queen Mary University of\nLondon, pp. 1–8 (2016).\n[27] 久保光徳，寺方将之，寺内文雄，青木弘行：揺動・振動刺激下における快感情評価，\n日本デザイン学会研究発表大会概要集，Vol. 53, No. 0, pp. 99–99 (2006).\n[28] 久原拓巳，細田千尋，南角吉彦，加藤昇平，田中由浩：感情付き合成音声を伴う振\n動触覚刺激の心理的影響の調査，ロボティクス・メカトロニクス講演会講演概要集\n2022，pp. 2P2–B09 (2022).\n[29] 須佐見憲史，安藤広志：映像に対する香りの付加が臨場感に及ぼす効果(日本基礎心\n理学会第26 回大会, 大会発表要旨)，基礎心理学研究，Vol. 26, No. 2, p. 225 (2008).\n[30] 阿久津洋巳，市原茂，石戸谷真由子：香りの感情価に及ぼす音楽の影響，日本官能\n評価学会誌，Vol. 9, No. 2, pp. 116–121 (2005).\n[31] 田中昭子：香りによってもたらされる快適感の生理心理作用，生活工学研究，Vol. 2,\nNo. 1, pp. 18–19 (2000).\n[32] Oh, E., Lee, M. and Lee, S.: How 4D effects cause different types of presence experience?,\nVRCAI ’11, Association for Computing Machinery, p. 375–378 (2011).\n39\n[33] Jeong, D., Han, S. H., Jeong, D. Y., Kwon, K. and Choi, S.: Investigating 4D movie\naudiences’ emotional responses to motion effects and empathy，Computers in Human\nBehavior, Vol. 121, p. 106797 (2021).\n[34] Lee, J., Han, B. and Choi, S.: Interactive motion effects design for a moving object in 4D\nﬁlms, Association for Computing Machinery, p. 219–228 (2016).\n[35] Nicolae, D. F.: Spectator perspectives in virtual reality cinematography. The witness, the\nhero and the impersonator, Ekphrasis. Images, Cinema, Theory, Media, Vol. 20, No. 2, pp.\n168–180 (2018).\n[36] Kim, A., Chang, M., Choi, Y., Jeon, S. and Lee, K.: The Effect of Immersion on Emotional\nResponses to Film Viewing in a Virtual Environment, 2018 IEEE Conference on Virtual\nReality and 3D User Interfaces (VR), pp. 601–602 (2018).\n[37] 杉原太郎，森本一成，黒川隆夫：SD 法を通してみた音楽に対する感性の基本特性，映\n像情報メディア学会技術報告25.48，一般社団法人映像情報メディア学会，pp. 57–63\n(2001).\n[38] 仁科弘重，中本有美：観葉植物, 花, 香りが人間に及ぼす生理・心理的効果の脳波およ\nびSD 法による解析，日本建築学会計画系論文集，Vol. 63, No. 509, pp. 71–75 (1998).\n[39] 寺本渉，吉田和博，浅井暢子，日高聡太，行場次朗，鈴木陽一：臨場感の素朴な理\n解(¡ 特集¿ VR 心理学4)，日本バーチャルリアリティ学会論文誌，Vol. 15, No. 1, pp.\n7–16 (2010).\n[40] 安藤広志：2. 人が感じる臨場感の知覚認知メカニズムと評価技術，映像情報メディ\nア学会誌，Vol. 63, No. 12, pp. 1727–1730 (2009).\n[41] 飯村浩平，中村広幸，大倉典子，小松剛：臨場感と現実感の定量化と評価の実験，日\n本人間工学会大会講演集，Vol. 48, No. 0, pp. 432–433 (2012).\n[42] 徳田貴拓，磯山直也，ロペズギヨーム：Pico-Band: リストバンド型省エネ個別暖房\nデバイスの開発-温熱感を持続させる温度制御法の提案，IEICE Conferences Archives\n(2016).\n[43] Inc, M.:\nパルス幅変調とは?，https://www.mathworks.com/discovery/\npulse-width-modulation.html. (最終参照日: 2025/1/8).\n[44] Key Electronics 合同会社：DigiKey, https://www.digikey.jp/. (最終参照日:\n2025/1/8).\n40\n[45] 株式会社モトヤマ：PID\n制御とは，https://www.motoyama.co.jp/\nengineer/engi106.htm. (最終参照日: 2025/1/8).\n[46] 株式会社秋月電子通商：秋月電子通商，https://akizukidenshi.com/\ncatalog/default.asp. (最終参照日: 2025/1/8).\n[47] 深セン鵬林オプトエレクトロニクス株式会社：PENGLIN,\nhttp://www.\nszpelink.com/. (最終参照日: 2025/1/8).\n[48] 株式会社スイッチサイエンス：スイッチサイエンス，https://www.\nswitch-science.com/. (最終参照日: 2025/1/8).\n[49] キープパワーテクノロジー株式会社：KEEP POWER, https://www.keeppower.\ncom/. (最終参照日: 2025/1/8).\n[50] 福田忠彦，福田涼子，福田忠彦研究室：増補版人間工学ガイド- 感性を科学する方\n法-，株式会社サイエンティスト社(2009).\n[51] Inc., Q.:\nSystem Usability Scale:\nWhat it is, Calculation + Usage, https://\nwww.questionpro.com/blog/system-usability-scale/.\n(最終参照日:\n2025/1/8).\n[52] 山内繁：人を対象とする研究計画入門: 科学的合理性と倫理的妥当性，丸善出版(2015).\n[53] Lewis, J. R.: The system usability scale: past, present, and future, International Journal\nof Human–Computer Interaction, Vol. 34, No. 7, pp. 577–590 (2018).\n41\n付録A\n　SD法に基づいたアンケートフォーム\n42\n43 \n \n \n動画鑑賞で感じたイメージについて最もよくあてはまると思うものをお選びくだ \nさい。 \nPlease select the image that best describes your impression of the video. \n動画鑑賞に関するアンケート \n・似たような項⽬を以前に回答したと感じるときがあるかもしれませんが、すべての項⽬ \nは完全に別々のものですので、以前に回答した項⽬を読み返したり思い返したりしないで \nください \n・この評価実験は能⼒を判定するものではありませんので、あまり考えこまず、⾃分の感 \nじた通りに評価を⾏ってください。 \n  アカウントを切り替え \nる \n共有なし \n 必須の質問です \n名前  \n回答を⼊⼒ \n2025/01/23 17:29 \n動画鑑賞に関するアンケート \n44 \n \n \n動的な \n  \n \n \n \n \n \n \n \n \n静的な  \n  \n気持ちのいい \n \n  \n \n \n \n \n \n \n \n気持ちの悪い \n  \n \n迫⼒のある  \n  \n \n \n \n \n \n \n \n迫⼒のない  \n  \nはっきりした \n \n  \n \n \n \n \n \n \n \nぼんやりした \n \n  \n強い  \n  \n \n \n \n \n \n \n \n弱い \n \n \n \n \n \n \n \n \n45 \n \n \n \n送信 \nフォームをクリア \nGoogle フォームでパスワードを送信しないでください。 \nこのコンテンツは Google が作成または承認したものではありません。 - 利⽤規約 - プライバシー ポリシー \nDoes this form look suspicious? レポート \n好きな \n \n \n \n \n \n \n \n \n \n \n嫌いな \n  \n \nリアリティのある \n \n \n \n \n \n \n \n \n \n \nリアリティのない \n \n  \n興奮した  \n  \n \n \n \n \n \n \n \n落ち着いた  \n  \n良い \n \n \n \n \n \n \n \n \n \n \n悪い  \n  \n \n \n \n \n \n付録B\n　SUSに基づいたアンケートフォーム\n46\n \n47 \n  \n  \n \n  \nImmersionFan  に 関 するあなたの 経験 に 基 づいて、 次 の 記述 に 対 する 同意 または 不   \n同意 の レベル を 記⼊ してください   \n  Based on your experience with immersionFan, please indicate your level of  \nagreement or disagreement with the following statements  \nImmersionFan   の ユーザビリティ に 関 する   \nアンケート   \n   に \nイ \nログ   ン   す   る と 作業内容 を 保存 できます。   \n詳細   \n  必須 の 質問 です   \n名前     \n回答 を ⼊⼒   \n \n48  \n  \n \n \n49  \n  \n \n \n50  \n  \n \n 送信  \nフォームをクリア  \nGoogle フォームでパスワードを送信しないでください。  \nこのコンテンツは Google が作成または承認したものではありません。 - 利⽤規約 - プライバシー ポリシー  \nDoes this form look suspicious? レポート \n フォーム  \n  \nポイント  \n強 く 同意 しない   \n  \n  \n  \n  \n  \n強 く 同意 する   \n  ポイント  \n強 く 同意 しない   \n  \n  \n  \n  \n  \n強 く 同意 する   \nこの システム を 使⽤ することに ⾃信 をもっています   \nI am confident in using this system  \n  \nこの システム を 使 い 始 める 前 に 学 ぶべきことがたくさんあると 思 います   \nI thought there was a lot to learn before I started using this system  \n  \nデバイス に 気 づいたこと・ 気 になったことを ⾃由 に 記述 してください   \nPlease feel free to describe what you noticed/concerned about the device  \n回答 を ⼊⼒   \n質疑応答\n戸辺　義人　情報テクノロジー学科　教授\nQ\nどのようにPID 制御を行いましたか．\nA\nサーミスタを用いて温度制御を行いました．PID 制御についてのパラメータは先行\n研究を参考に、限界感度法を用いて決定しました．\n伊藤雄一情報テクノロジー学科教授\nQ\n振動はズレによって影響がありませんか．映像とのズレが気になったという人はい\nませんでしたか．\nA\n映像とのズレが気になったという人はいませんでしたが，リアルタイム性の向上に\nついては今後の課題と考えています．\n伊藤雄一情報テクノロジー学科教授\nQ\n温度変化について，温度の推移過程での視聴の影響はありませんか．\nA\n今回，推移時の視聴における影響は考慮していませんでした．今後の研究で反映し\nます．\n51\nロペズ　ギヨーム情報テクノロジー学科教授\nQ\n目標温度に到達するまでの時間を教えてください．\nA\n5，6 秒ほどで目標温度まで到達します．\n戸辺　義人　情報テクノロジー学科　教授\nQ\n風の刺激が局所的だと没入感に影響は与えないのでしょうか．\nA\n今後，局所的な刺激についての没入感の影響について調べたいと思います．\n伊藤雄一情報テクノロジー学科教授\nQ\n風覚に関する論文は参考にしましたか．風速などについて数値的な参考にしたもの\nがあれば教えてください．\nA\n風覚に関する論文は拝読しましたが，システムに風速などの数値的な反映はできて\nいません．今後の実装の参考にさせていただきます．\n52\n",
        "chunks": [
            "B2024_SoraIwamoto_t. B2024_SoraIwamoto_t. B2024_SoraIwamoto_t",
            "青山学院大学理工学部\n情報テクノロジー学科\n２０２４年度卒業研究論文\nImmersion Neckwear:\n動画体験拡張ネックウェア\n２０２５年１月２８日提出\n指導教員ロペズ・ギヨーム　教授\n提出者学生番号　氏名\n１５８２１００９岩本空\n青山学院大学 理工学部 情報テクノロジー学科 \n2024 年度（令和6 年度）卒業論文要旨 \n- 1 - \nImmersion Neckwear:  \n動画体験拡張ネックウェア \n岩本 空（15821009） \nロペズ研究室 \n \n１．はじめに \n定額制動画配信サービスの普及により，有料動画配\n信サービスの利用者が増加している．これに伴い，動\n画視聴の形態も大きく変化し，インターネット回線を\n活用した動画鑑賞の市場規模が拡大している．一方，\n技術の進化により，映画館での視聴体験も新たな楽し\nみ方として提案されており，特に4DX （Four \nDimensional eXperience）技術の導入により，五感を\n刺激する没入型の体験が提供されている[1]．  \nよって，本研究の目的は，動画の映像に合わせて，\n五感を刺激するフィードバックを行い，自宅で",
            "]．  \nよって，本研究の目的は，動画の映像に合わせて，\n五感を刺激するフィードバックを行い，自宅での動画\n体験を拡張することである．そのため，研究目標とし\nて，映像に合わせて振動・風の強弱・温冷感を提示す\nる頸部装着型ウェアラブルシステムImmersion \nNeckwear を創作し，一人での動画鑑賞の没入感を向\n上することを目指す．Immersion Neckwear を利用し\nた動画鑑賞のイメージ図を図1 に示す． \n \n図1 Immersion Neckwear を利用した動画鑑賞の\n例 \n \n２．関連研究 \n岡本ら[2]は，ワイヤアクションゲームをプレイ中の\n風の強度が臨場感に与える影響を検証した．風なし，\n一定の風，ワイヤアクションで引っ張られるときの速\n度に応じた風の3 つの条件で評価したところ，風力変\n化がある状態が最も臨場感が高いことが判明した．前\n田[3]らは，複数の体の部位に装着可能な熱フィードバ\nックシステムTherModule を提案した．実験では，\nTherModule を装着し，視覚と温度フィードバックを\n受けながら映画を鑑賞した被験者は，視覚のみの被験",
            "Module を装着し，視覚と温度フィードバックを\n受けながら映画を鑑賞した被験者は，視覚のみの被験\n者に比べて「楽しさ」と「興奮度」が有意に高いこと\nが確認された．Kim [4]らは，触覚刺激が映画鑑賞中の\n感情変化と没入感に与える影響を調査した．ポジティ\nブなシーンで柔らかい刺激を受けるとポジティブな感\n情と没入感が増加し，ネガティブなシーンでは柔らか\nい刺激がネガティブな感情を軽減することがわかった． \n上記のように，風や温度，触覚刺激が没入感や感情\nに与える影響は示されたが，多感覚フィードバック（振\n動，風，温冷感）の統合的な効果は十分に検証されて\nいない．そのため，本研究では振動，風の強弱，温冷\n感を組み合わせた多感覚フィードバックシステム\nImmersion Neckwear を創作し，これが動画鑑賞にお\nける没入感やユーザ体験に与える影響を評価する． \n \n３．Immersion Neckwear の概要 \n本研究で創作した頸部装着型の没入感向上デバイス，\nImmersion Neckwear，の画像は図2 に示し，構成し\nている主な要素は以下にまとめている． \n⚫ \nイ",
            "n Neckwear，の画像は図2 に示し，構成し\nている主な要素は以下にまとめている． \n⚫ \nインターフェース部：nRF Connect \n⚫ \n制御部：Arduino Nano 33 BLE \n⚫ \n電源部：5500mAh リチウムイオンバッテリ \n⚫ \n温冷部：ペルチェ素子TEC1-03105 \n⚫ \n風部：ターボブロワファンB0DB5SDX91 \n⚫ \n振動部：振動モータLBV10B-009 \n \n \n- 2 - \n    \n \n図2 Immersion Neckwear の全体像 \n \n４．Immersion Neckwear の没入感効果検証実験 \nImmersion Neckwearの有無による動画体験の印象\nの違いを比較し，有効性を検証した．被験者は20 代の\n男女10 名（男性:8 人，女性2 人）が，25 分程度のア\nクションアニメを視聴し，視聴後SD 法を用いたアン\nケートで主観的な評価を収集した．実験手順として，\n表1 に対応している，フィードバックを起こす場面の\n個数がほぼ等しい2 つの動画を用意し，被験者は\nImmersion Neckwear の有無で動",
            "の\n個数がほぼ等しい2 つの動画を用意し，被験者は\nImmersion Neckwear の有無で動画鑑賞を行った．視\n聴後にはSD 法によるアンケートに回答し，さらに\nImmersion Neckwear を使用した被験者にはSUS ア\nンケートを実施した．  \n表1: 場面とフィードバックの種類の対応 \n \n \n５．結果 \n表2，表3 はImmersion Neckwear の有無での SD \n法に基づいた形容詞対による印象評価を因子分析した\n結果から，因子解釈を行った結果を示す．装着時に，\n評価性が高まることから，動画視聴の没入体験が高ま\nったと考えられる． \nまた，SUS アンケートによるユーザビリティ評価で\nは，平均値が65 点であり，本システムのユーザビリテ\nィは改善の必要があると考えられる．また，システム\nの装着および起動に技術的サポートが必要と感じた被\n験者，デバイスの重さおよび大きさが不快に感じる被\n験者もいた． \n \n表2: システムありの時の，因子解釈 \n表3: システムなしの時の，因子解釈 \n \n \n6．まとめ \n本研究では，多感覚フィードバックを提供する没入\n",
            "ステムなしの時の，因子解釈 \n \n \n6．まとめ \n本研究では，多感覚フィードバックを提供する没入\n感向上デバイスImmersion Neckwear を開発した．実\n験結果では，Immersion Neckwear を装着した動画鑑\n賞において，ユーザがよりポジティブな印象を抱き，\n動画の没入感が向上することが確認された．特に，SD\n法によるアンケートの因子分析で，システムの装着に\nより評価性が高まることが示された．一方，ユーザビ\nリティをより向上させるためには，ユーザインターフ\nェースの改善，デバイスの軽量化が必要である \n \n参考文献 \n[1] \n株式会社ＩＣＴ総研:2023 年有料動画配信サー\nビス利用動向に関する調査. \nhttps://ictr.co.jp/report/20230421.html/. ( 最終\n参照日：2025/1/3) \n[2] \n岡本早織,羽田久一： ゲームプレイ中の風の強度\nによる臨場感の変化, エンタテインメントコン\nピューティングシンポジウム 2022 論文集, pp. \n135–138 (Aug 2022). \n[3] \n前田智祐,倉橋哲郎：ウ",
            "22 論文集, pp. \n135–138 (Aug 2022). \n[3] \n前田智祐,倉橋哲郎：ウェアラブルな温冷覚多点\n提示システム TherModule の基礎検討, 第 23 \n回日本バーチャルリアリティ学会大会論文集\n(Sep. 2018) \n[4] \nKim. A, Bae. H, and Lee. K.: Effects of Tactile \nPerception on Emotion and Immersion to Film \nViewing in a Virtual Environment， VRST ‘19: \nProceedings of the 25th ACM Symposium on \nVirtual Reality Software and Technology, pp.1–\n3 (Nov 2019) \n目次\n第1 章\n序章\n1\n1.1\n研究背景. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n1\n1.1.1\n映像体験の変化. . . . . . . . ",
            " . . . . . . . . .\n1\n1.1.1\n映像体験の変化. . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n1\n1.1.2\n映画館での視聴体験\n. . . . . . . . . . . . . . . . . . . . . . . . . .\n2\n1.1.3\n映画館での視聴体験の拡張\n. . . . . . . . . . . . . . . . . . . . . .\n2\n1.2\n研究目的と目標. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n3\n1.3\n本論文の構成. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n4\n第2 章\n関連研究\n5\n2.1\nコンテンツ体験の拡張. . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n5\n2.2\n動画鑑賞時の感情推定. . . . . . ",
            ". . . . . . . . . . .\n5\n2.2\n動画鑑賞時の感情推定. . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n6\n2.3\nコンテンツ評価. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n7\n2.4\nフィードバックによるコンテンツ体験の変化. . . . . . . . . . . . . . . . .\n8\n2.4.1\n風による動画体験の拡張に関する研究\n. . . . . . . . . . . . . . . .\n8\n2.4.2\n温度による動画体験の拡張に関する研究. . . . . . . . . . . . . . .\n9\n2.4.3\n振動によるコンテンツ体験の拡張に関する研究\n. . . . . . . . . . .\n10\n2.4.4\n香りによるコンテンツ体験の拡張に関する研究\n. . . . . . . . . . .\n11\n2.5\n映画鑑賞体験の拡張\n. . . . . . . . . . . . . . .",
            ". .\n11\n2.5\n映画鑑賞体験の拡張\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n12\n2.6\n評価実験によるコンテンツ評価. . . . . . . . . . . . . . . . . . . . . . . .\n13\n2.7\n本研究の位置づけ. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n15\n第3 章\nImmersion Neckwear:\n動画体験拡張ネックウェア\n16\n3.1\nImmersion Neckwear の概要\n. . . . . . . . . . . . . . . . . . . . . . . . . .\n16\n3.2\nImmersion Neckwear の基本設計. . . . . . . . . . . . . . . . . . . . . . . .\n17\n3.2.1\n各要素の機能詳細\n. . . . . . . . . . . . . . . . . . . . . . . . . .",
            " . . . . . . . . . . . . . . . . . . . . . . . . . .\n17\n3.3\nハードウェアの設計\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n18\n3.3.1\n熱源の選定と温度制御. . . . . . . . . . . . . . . . . . . . . . . . .\n18\n3.3.2\nその他電子部品の選定. . . . . . . . . . . . . . . . . . . . . . . . .\n22\ni\n第4 章\nImmersion Neckwear の没入感効果検証実験\n25\n4.1\n実験概要. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n25\n4.2\n実験手順. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n25\n4.3\nSD 法\n. . . . . ",
            ". . . . . . . . . . . . . .\n25\n4.3\nSD 法\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n26\n4.4\nSUS . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n27\n第5 章\n実験結果および考察\n29\n5.1\n実験結果. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n29\n5.1.1\nSD 法の評価結果. . . . . . . . . . . . . . . . . . . . . . . . . . . .\n29\n5.1.2\nSUS の評価結果. . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n31\n5.2\n考察. . . . . . . . . . . . . . . . .",
            ". . . .\n31\n5.2\n考察. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n31\n5.2.1\nSD 法の評価結果に関する考察. . . . . . . . . . . . . . . . . . . . .\n31\n5.2.2\nSUS の結果に関する考察. . . . . . . . . . . . . . . . . . . . . . . .\n32\n第6 章\n結論\n34\n6.1\nまとめ. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n34\n6.2\n今後の展望\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n34\n参考文献\n37\n付録A 　SD 法に基づいたアンケートフォーム\n42\n付録B\n　SUS に基づいたアンケートフォーム\n46\nii\n第1章\n序章\n本章では，本研究における研究",
            "録B\n　SUS に基づいたアンケートフォーム\n46\nii\n第1章\n序章\n本章では，本研究における研究背景，目的および本論文の構成について述べる．\n1.1\n研究背景\n1.1.1\n映像体験の変化\n近年，定額制で利用可能なサービスの増加および，新型コロナウイルス感染拡大によっ\nて高まった巣ごもり需要によって有料動画配信サービスの利用者が増加している．図1-1\nの示すように，動画配信サービスの利用者数の需要予測では2025 年には3900 万人まで利\n用者が拡大すると予測されている[1]．\n図1-1: 有料動画配信サービスの利用者の需要予測（[1] より引用）\n有料動画配信サービスの普及に伴い，動画視聴の形態も大きく変化している．好きなタ\nイミングで視聴を開始でき，チケット代および交通費などのコストを削減可能なインター\nネット回線を活用した動画鑑賞が数年で市場規模を拡大している．図1-2 で示すように，\nGEM Partners 株式会社が発表した，2023 年の動画配信（VOD）市場規模推計と，その後\n2028 年までの各年の市場規模を3 つのシナリオで予測した「動画配信（VOD）市場5 年",
            "，その後\n2028 年までの各年の市場規模を3 つのシナリオで予測した「動画配信（VOD）市場5 年間\n予測（2024-2028 年）レポート」によると，有料配信の市場規模はコロナ禍前の2019 年と\n比較するとほぼ倍に成長すると予測されている．さらに，2028 年には7371 億円に増加す\nることが予測されており，更なる成長が期待されている．有料配信の市場規模の拡大と付\n随して，特定の配信サービスのみで視聴可能なオリジナルコンテンツも増加している[2]．\n1\n図1-2: 動画配信サービス国内の市場規模の推移と予測（[2] より引用）\n1.1.2\n映画館での視聴体験\n株式会社プラネットが実施した映画に関する意識調査によると，図1-3 から，映画を見\nるときに，映画館で映画を見たい人が全体の3 割を占めており，特に20 代については男\n女ともに自宅で映画を見たい人より映画館で見たいと回答した人の方が上回っている．映\n画館で見たいと回答した人の中には映画館で見ることのメリットとして「観客の笑い声や\n泣き声などに包まれ，一体感をもたらしてくれるところ」と回答している[3]．他の調査\nでも映画",
            "い声や\n泣き声などに包まれ，一体感をもたらしてくれるところ」と回答している[3]．他の調査\nでも映画を映画館で見たい理由として，非日常感を味わえることおよび，没入感を感じら\nれることが上げられている[4]．\n株式会社スパコロが実施した映画館の利用意識調査によると，「コロナ禍の映画館にお\nいてみたいと思う作品はどんな作品か？」の問いに対して，図1-4 で示すように，回答結\n果を分析・可視化したところ「アクション」「迫力」「SF」「サスペンス」「映像」「臨場感」\n「アニメ」など語句が目立っており，劇場だからこそのダイナミックな映画体験が感じら\nれる作品が映画館で観たい作品と考えられていることがわかる[5]．\n1.1.3\n映画館での視聴体験の拡張\n近年，映画館での視聴体験は大きく変化しており，技術の進化とともに新たな楽しみ方\nが提案されている．特に注目されるのが4DX（Four Dimensional eXperience）技術の導入\nである．映像と連動して座席が動く，水しぶきおよび風，香りなどの特殊効果を体感可能\nなシステムで，観客に五感を刺激する没入型の体験を提供する．本技術により，単に",
            "どの特殊効果を体感可能\nなシステムで，観客に五感を刺激する没入型の体験を提供する．本技術により，単に映画\nを「見る」だけでなく，まるで映画の中に入り込んだかのような臨場感を楽しむことが可\n2\n図1-3: 映画を見る際の，映画館鑑賞と自宅鑑賞の比率（[4] より引用）\n能である．図1-5 は，MediaMation 社が開発した体験型4D シアタシステムの概要図であ\nる．また，IMAX およびDolby Atmos などの大画面・高音質技術も進化しており，映像美\nと音響効果がよりリアルに感じられるようになっている．これにより，映画館での視聴体\n験は単なるエンターテインメントから，特別なイベントかつ記憶に残る体験へと変化して\nきている．\n1.2\n研究目的と目標\n定額制で利用可能なサービスの増加および，新型コロナウイルス感染拡大によって高\nまった巣ごもり需要に伴い，多くの人が配信を利用した自宅動画鑑賞に親しんでいる．一\n方で，映画館で映画を楽しんでいる人も大勢おり，その中には「没入感」および「一体感」\nの観点，映画のジャンルによって，映画館での映画鑑賞を好む人がいる．本研究では，動\n画の映像",
            "一体感」\nの観点，映画のジャンルによって，映画館での映画鑑賞を好む人がいる．本研究では，動\n画の映像に合わせて五感を刺激するフィードバックを行い，自宅動画体験を拡張すること\nを目的としている．本技術が実現すれば，自宅での動画体験の満足度の向上が可能とな\nる．その目標に向けて，本論文では映像に合わせて振動・風の強弱，温冷感提示をするシ\nステムを創作する．\n3\n図1-4: 映画館で見たいと思う作品はどんな作品？：ワードクラウド（頻出語句）（[5] より引用）\n図1-5: MediaMation 社「MX4D」（[6] より引用）\n1.3\n本論文の構成\n第1 章では，本論文の研究背景，研究目的及び論文の構成について述べる．第2 章では\n関連研究について説明する．第3 章では，システムの概要について説明する．第4 章で\nは，実験方法について説明する．第5 章では，実験結果と考察について説明する．第6 章\nでは，本論文の結論と今後の展望について述べる．\n4\n第2章\n関連研究\n本章では，関連研究について述べる．\n2.1\nコンテンツ体験の拡張\n代蔵らは，図2-1に示すような他者の存在を感じながら動画",
            "いて述べる．\n2.1\nコンテンツ体験の拡張\n代蔵らは，図2-1に示すような他者の存在を感じながら動画を鑑賞するシステム「ExciTV」\nを活用し，ユーザの興奮度を皮膚コンダクタンス反応で評価することを提案した．ユーザ\nのSCR データと動画に対する評価には相関が見られ，他者の反応を含めて動画を楽しむ\nことが可能であることが確認された[7]．\n図2-1: ExciTV（[7] より引用）\n松井らは，周辺視にエフェクトを提示することで，動画の印象および視聴体験がどのよ\nうに変化するかを調査した．視線検出装置を使用して，エフェクト提示中の視線情報を取\n得し，アンケートで印象の変化を評価した．エフェクトの提示は動画の印象を変化させる\nことが確認され，特に現実空間を撮影した動画はアニメおよびゲームのような二次元空間\nを撮影した動画と比較して，印象変化が顕著にみられた．エフェクト提示により動画視聴\n体験の拡張が有効であることが確認された[8]．\n三上らは，従来の音楽体験を向上のために，電気的筋肉刺激を用いて音楽に合わせた身\n体動作を外部から強制的に提示することシステムを提案した．音楽体験の印象を評",
            "を用いて音楽に合わせた身\n体動作を外部から強制的に提示することシステムを提案した．音楽体験の印象を評価語に\n対して7 段階で評定してもらったところ，「Interesting」「Enjoyable」「Exciting」「Lively」\n5\n「Light」「Fast」「Heavy」において，曲の文脈に合わせて電気的筋肉刺激を提示したとき\n（条件2）の方が，音楽だけのとき（条件1）及び一定の間隔で電気的筋肉刺激を提示し\nたとき（条件3）よりも印象評価による評定得点が大きな値となった．特に「Interesting」\n「Exciting」において音楽のみの条件1 と条件2 および条件2 と条件3 との間に有意差が認\nめられた[9]．\n2.2\n動画鑑賞時の感情推定\n三ツ木らは，音楽ライブにおいて，生体反応センサーを用いて観客の感情的な盛り上が\nりを推定することを実現することで，観客間での盛り上がりの共有および演者へのフィー\nドバックに有効であると考えた．図2-2 で示すようなシステムで，脳波と皮膚電気信号を\n用いて，音楽ライブ中の観客の感情的な盛り上がりを推定するシステムを提案した．脳波\nとEDA",
            "気信号を\n用いて，音楽ライブ中の観客の感情的な盛り上がりを推定するシステムを提案した．脳波\nとEDA データから，音楽鑑賞中の盛り上がりおよび感情の推定が可能であることが示唆\nされた[10]．\n図2-2: 脳波と皮膚電気信号を用いたシステム概要図（[10] より引用）\n寺澤らは，脳波を用いて，映画鑑賞中の連続的な感情変化を追跡する手法を提案した．\nアニメ映画鑑賞の脳波データを収集し，感情状態を分類および予測を行ったところ，最良\nの分類精度は77.6%，最良の回帰モデルの相関係数は0.645 であった．これにより，脳波\nベースの方法で連続的な感情状態が概ね予測可能であることが確認された[11]．\n平松らは，脈波と脳波を活用して，Russell の環状モデルを用いてユーザの気分変化を\n推定する手法を提案した．ジャグリングの実演を鑑賞中のユーザの気分推定を行ったとこ\nろ，提案手法による感情分析と主観評価による感情分析には相関があることがわかった．\n結果から，生体情報を用いた感情分類手法が有効であることが認められた[12]．\n角田らは，コメディ動画視聴によるユーザの気分変化を，心拍数と呼吸数の",
            "あることが認められた[12]．\n角田らは，コメディ動画視聴によるユーザの気分変化を，心拍数と呼吸数の長期変動を\n6\n用いて低負荷で推定する手法を提案した．本手法から心拍数と呼吸数の長期変動の類似度\nが減少すると，ネガティブな気分が高まることがことが判明した．結果から，コンテンツ\n視聴中の生体情報を用いて，ユーザの気分変化を低負荷で推定可能であることが示唆され\nた[13]．\n2.3\nコンテンツ評価\nLiu らは，図2-3 で示すシステムを用いて，映画の予告編の評価において脳波計とアイ\nトラッカを同時に使用する新しいプラットフォームを提案した．YouTube での評判と専門\n家の評価によって良いと判断された予告編は悪いと判断された予告編よりも前頭葉と後\n頭葉エリアでの高い同期性を示し，シーンの変化の際に，眼球運動と脳の活動が同期する\nことが判明した[14]．\n図2-3: 脳波計とアイトラッカを用いたシステム概要図（[14] より引用）\nHe らは，ユーザの没入感の発生，関連要因，および脳波活動との関連を明らかにし，さ\nらに脳波信号を使用して没入感を予測し，ユーザの満足度の指標として活用する",
            "動との関連を明らかにし，さ\nらに脳波信号を使用して没入感を予測し，ユーザの満足度の指標として活用することを提\n案した．音質と没入感には有意な正の相関があり，ノイズ量，画面のコントラストと没入\n感には有意な負の相関があることがわかった．低周波帯では脳波信号と没入感に負の相関\nがあり，前頭葉のガンマ波と没入感に正の相関がある．提案手法を用いることで，予測没\n入感スコアがユーザの満足度を評価するのに有効であることが示唆された[15]．\n三角らは，音楽が前頭前野の脳血液量に与える影響を調査した．ユーザはリラックした\n音楽と騒々しい音楽を聴取し，その間の脳血液量の変化を測定した結果，図2-4 のグラフ\nのように，音楽聴取時に酸素化ヘモグロビンと総ヘモグロビンが増加し，その後減少．脱\n酸素化ヘモグロビンはほとんど変化がないことが判明した．音楽聴取は前頭前野の脳活動\nの一時的な活性化とその後の抑制を引き起こすことが示唆された[16]．\n7\n図2-4: 脳血液量の変化を示すグラフ（[16] より引用）\n宮本らは，動画レコメンドシステムがユーザの興味に沿った動画を推薦するために，生\n体信号を利用してユー",
            "宮本らは，動画レコメンドシステムがユーザの興味に沿った動画を推薦するために，生\n体信号を利用してユーザの動画に対する印象を評価する方法を提案した．皮膚電気活動，\n指尖皮膚温，心拍数などの生体信号を測定し，これらのデータを基にユーザの動画に対す\nる嗜好性を推定した．実験の結果，興奮刺激の多い動画では皮膚電気活動の値が高くなる\nことが判明した[17]．\n2.4\nフィードバックによるコンテンツ体験の変化\n2.4.1\n風による動画体験の拡張に関する研究\n岡本らは，ワイヤアクションゲームプレイ中の風の強度によって臨場感がどのように変\n化するかについて検証した．プレイヤに風を当てる条件を3 つ設定（風なし，一定の風，\nワイヤアクションで引っ張られるときの速度に応じた風）し，臨場感をアンケートで評価\nしたところ，風がある状態の方が臨場感が高く，特に風力変化がある状態が最も臨場感を\n感じやすいことが判明した[18]．\n伊藤らは，VR 環境での現実感向上のため，風覚を利用して全周囲から風を感じる方法\nを提案した．HMD を装着した被験者に対し，特定の角度に配置した送風機から風を送る\n実験を実施したところ",
            "案した．HMD を装着した被験者に対し，特定の角度に配置した送風機から風を送る\n実験を実施したところ，4 台の送風機を特定の角度に配置することで，被験者は全方向か\nら風を感じる錯覚を体験した．本研究により，VR 体験の没入感を高めるための新しいア\nプローチが示唆された[19]．\n村田らは，前方への自己運動を示唆する皮膚感覚がベクション（実際には静止している\n8\n人間が，視覚情報によって移動しているような感覚が引き起こされてしまう現象）を促進\nまたは抑制するかを調査した．被験者の顔に電気ファンを使用して風を送ることで，2 つ\nの条件（熱風と通常の温度の風）を設定した．通常の温度の風ではベクションの強度が増\n加し，熱風では抑制されることが判明した[20]．\n小島らは，ユーザの移動を可能にし，狭い領域への風提示を実現する新しい風ディスプ\nレイの構築を提案した．図2-5 のように，軽量な自転車ヘルメットを使用し，耳近傍に風\nを提示するためのスピーカユニットを搭載した．本デバイスにより，速度感，爽快感の増\n強が実現可能と考えられた[21]．\n図2-5: 耳近傍に風を提示するためのスピーカユニット",
            "快感の増\n強が実現可能と考えられた[21]．\n図2-5: 耳近傍に風を提示するためのスピーカユニット（[21] より引用）\n2.4.2\n温度による動画体験の拡張に関する研究\n前田らは，複数の体の部位に装着可能なモジュール式の熱フィードバックシステム「Ther-\nModule」を提案した．実験では，図2-6 のように，TherModule を使用して，視覚と温度\nフィードバックを同期させた映画体験被験者が，TherModule を手首，前腕，足首に装着\nし，視覚と温度フィードバックを受けながら映画を鑑賞したところ，視覚と温度フィード\nバックを受けた被験者は，視覚のみの被験者に比べて「楽しさ」と「興奮度」が有意に高\nかった．以上より，TherModule は映画体験を強化することが判明した[22]．\n牛尾らは，図2-7 のようなシステムを用いて，温度感覚を利用し，ゲーム中のプレイヤ\nの情動（興奮，安静など）を制御する手法の効果を検証した．ゲーム「スプラトゥーン2」\nの映像に合わせて温感を呈示し，情動の変化をアンケートとインタビュで評価した．実験\nの結果，楽しさ，面白さ，緊張感において有意な",
            "し，情動の変化をアンケートとインタビュで評価した．実験\nの結果，楽しさ，面白さ，緊張感において有意な効果が確認されたが，冷静さ，興奮，焦\nりには効果が認められなかった．また，温感呈示のタイミングおよび温度設定に個人差が\nあり，長時間の温感呈示は集中を妨げる可能性があると示唆された[23]．\n9\n図2-6: TherModule のシステム概要図（[22] より引用）\n図2-7: 温度感覚を用いたシステム概要図（[23] より引用）\n2.4.3\n振動によるコンテンツ体験の拡張に関する研究\n安保らは，オンラインライブパフォーマンスにおける一体感を向上させるために，図\n2-8 に示すような他人の盛り上がりの度合いを振動によるフィードバックを可能にする衣\n服型ウェアラブルデバイス「ONEParka」を提案した．振動が盛り上がりの認知に効果的\nであることが明らかになった[24]．\nKim らは，触覚刺激が映画鑑賞の感情変化と没入感との関連性を調査した．ポジティブ\nなシーンで柔らかい刺激を受けると，他の条件よりもポジティブな感情と没入感が増加し\nた．ネガティブなシーンでは，柔らかい刺激がネガティブ",
            "他の条件よりもポジティブな感情と没入感が増加し\nた．ネガティブなシーンでは，柔らかい刺激がネガティブな感情を軽減したが，トゲのあ\nる刺激は感情および没入感に影響を与えないことがわかった[25]．\nMazzoni らは，触覚刺激を通じて新たな映画体験を提供する手法を提案した．8 つの振\n10\n図2-8: ONEParka（[24] より引用）\n動モータを手袋に取り付け，異なる強度と周波数の振動パターンを設計したところ，低強\n度・低周波数の触覚刺激はユーザに落ち着いを，低強度・高周波数の刺激は興奮を，高強\n度・高周波数の刺激は緊張感を高めることが示唆された．また，映画視聴中の触覚刺激は\n覚醒レベルが有意に高まることもわかった．映画視聴体験を触覚刺激によって強化可能で\nあることが確認された[26]．\n久保らは，振動および揺動を「快」の視点から取り扱い，快感情を誘発する振動・揺動\nを生理・心理・物理の三指標から評価した．自発的揺動刺激実験により，血圧がその評価\nにおいて有効な指標の一つであることが示唆された．また上下振動刺激実験から，ヒトは\n振動により消極的快と積極的快が誘発されることが明らか",
            "が示唆された．また上下振動刺激実験から，ヒトは\n振動により消極的快と積極的快が誘発されることが明らかになり，その評価には血圧が有\n効な指標であることが示唆された[27]．\n久原らは，リモートコミュニケーションに振動触覚刺激を追加することで生じる心理的\n効果を調査した．振動触覚刺激による心理的効果を確認するために，感情的な合成音声に\n振動触覚刺激を追加する実験を行い，振動触覚刺激が合成音声のポジティブまたはネガ\nティブに聞こえる度合いに影響を与えることを示唆した．遅いリズムでは音声はネガティ\nブに，速いリズムではポジティブに聞こえることが確認された[28]．\n2.4.4\n香りによるコンテンツ体験の拡張に関する研究\n須佐見らは，映像と香りの相互作用が臨場感に及ぼす効果を検討した．「映像情報のみ」，\n「映像+映像にマッチした香り」，「映像+映像にミスマッチな香り」の3 条件について，評\n価値の条件差をSD 法を用いて測定した．その結果，「映像のみ」では遠隔的，空想的，外\n的な感じがするが，香りを付加すると映像のみの場合よりも女性的で，接近感，現実感，\n没入感が増す傾向が見られた．これらの結果",
            "を付加すると映像のみの場合よりも女性的で，接近感，現実感，\n没入感が増す傾向が見られた．これらの結果から，映像に香りを付けると臨場感，特に近\n11\n空間への没入感が増加することが示唆された[29]．\n阿久津らは，香りが音楽によって引き起こされる感情に与える影響を調査した．参加者\nがペパーミントとラベンダの香りを嗅ぎながら，楽しい音楽と陰鬱な音楽を聴き，感情の\n評価を行った．楽しい音楽はラベンダによって誘発された楽しい気分を増幅し，陰鬱な音\n楽は両方のオイルによって誘発された楽しい気分を減少した．以上より，音楽がエッセン\nシャルオイルの香りによる感情に大きな影響を与えることが示唆された[30]．\n田中は，好きな香りが心理状態と知的作業遂行に与える影響について検討した．状態不\n安を低減する手段として，好きな香りが有効である可能性が示唆された．また，好きな香\nりが気分をいい方向に変化させる効果があることも示唆され，作業効率も向上されること\nも示唆された[31].\n2.5\n映画鑑賞体験の拡張\nOh らは，4DX 映画の観客が感じる臨場感について調査し，4DX 効果がどのように影響\nするかを分析",
            "h らは，4DX 映画の観客が感じる臨場感について調査し，4DX 効果がどのように影響\nするかを分析した．7 つのジャンルの映画を対象に，35 名の観客に対して詳細なインタ\nビュを実施し，グラウンド理論を用いて結果を解析した．4DX 映画はリアリズムとして\nの臨場感，没入感，メディア内での社会的役割，社会的豊かさ，共感的移動感，社会的存\n在としての臨場感の6 つのタイプを引き起こすことが判明した．特に，モーションコント\nロールおよび振動，空気，匂いの効果が臨場感を高める重要な要因であることが示唆され\nた[32]．\nJeong らは，図2-9 のような椅子を設定して，4DX 映画におけるモーション効果が観客\nの感情に与える影響を調査した．特に，共感レベルに応じた感情反応の違いを分析し，高\nい共感を持つ参加者が短いモーション効果でより強い恐怖を感じることを明らかにした．\nまた，映画クリップとモーション効果の組み合わせが観客の感情を変化させることが示さ\nれ，モーション効果の設計に関するガイドラインを提案し，感情体験の向上に寄与する方\n法を示唆している[33]．\nLee らは，4DX 映画にお",
            "インを提案し，感情体験の向上に寄与する方\n法を示唆している[33]．\nLee らは，4DX 映画におけるモーション効果の迅速な設計を可能にするアルゴリズムを\n提案した．4DX 映画は視覚だけでなく，聴覚および触覚を通じて観客に没入感を提供す\nるため，モーション効果が重要な役割を果たす．提案されたアルゴリズムは視聴者中心の\nレンダリング戦略に基づき，視覚的注意の動きに合わせて椅子の動きを調整した．これに\nより，観客の体験を向上が実現された．さらに，本アプローチは自動化されており，手動\nでの作成に比べて10 倍以上の速度で動き効果を生成することが可能になった．実験によ\nり，生成されたモーション効果の主観的品質が評価され，視覚的に妥当な効果を提供する\nことが確認された．本研究は，4DX 映画の制作プロセスを効率化し，観客の体験をより\n12\n図2-9: 3-DOF motion chair（[33] より引用）\n豊かにするための新たな手法を示唆された[34]．\nNicolae は，従来の映画館とVR 映画館の違いを分析した．VR 映画館はヘッドセットが\n周囲の気を散らすものを遮断し，観客は映画",
            "VR 映画館の違いを分析した．VR 映画館はヘッドセットが\n周囲の気を散らすものを遮断し，観客は映画に集中することを求められるが，従来の映画\n館での鑑賞と比較して社会交流が減少すると分析した．また，VR 作品の質は様々で，強\nい感情的な没入感を提供するものもあれば，「そこにいる」効果のみに依存するものもあ\nると述べた．VR 技術は従来の映画では実現できない強力な「臨場感」を生みだした[35]．\nKim らは，VR が人々の感情に与える影響を調査した．ヘッドマウントディスプレイ\n（HMD）を使用した視聴条件と使用しない視聴条件（No-HMD）を比較し，ホラーと共感\nの2 種類の感情的コンテンツを適用した．結果，HMD を使用してホラー映画を見た視聴\n者は，No-HMD の視聴者よりも恐怖を感じやすかったことが判明した．しかし，共感を\n誘発する映画では，HMD とNo-HMD の視聴者の間に有意な感情の差は見られなかった．\n研究では，VR がホラー映画に対して特に感情反応を強化することを示し，没入感と感情\nの関係を確認した[36]．\n2.6\n評価実験によるコンテンツ評価\n杉原らは，音楽に対",
            "，没入感と感情\nの関係を確認した[36]．\n2.6\n評価実験によるコンテンツ評価\n杉原らは，音楽に対する感性がどのように表現されるかを探求した．音楽の聴取中に音\n楽が引き起こす印象を評価するために，SD 法を使用した実験を実施し，音楽の特徴が聴\n取者の感情に与える影響を示唆した．楽曲から受ける印象の程度は男性と女性で異なるこ\nとおよび，感性語対によっても異なることが判明した[37]．\n仁科らは，観賞用の葉植物，花（バラ），および香りが人間に与える生理的および心理\n的影響を，脳波（アルファ波とベータ波の比率）およびSD 法を用いて分析した．その結\n13\n果，香りの存在によりアルファ波とベータ波の比率が高くなることが観察された．香りが\n人間の生理面に影響を与えることを示唆した．一方，バラの存在は高い評価得点をもたら\nし，花が人間の心理面に影響を与えることも示唆した[38]．\n寺本らは，非研究者が「没入感」をどのように概念化しているかを探求した．調査の結\n果，因子分析により，「評価」「インパクト」「活動性」「機械的性質」の4 つの因子が没入\n感の構成要素として抽出された．没入感が高いイベント",
            "ト」「活動性」「機械的性質」の4 つの因子が没入\n感の構成要素として抽出された．没入感が高いイベントは，好ましく，印象的で，動的で\nあると評価される傾向があった[39]．\n安藤は，図2-10 で示すように臨場感は複数の感覚要素の複合体として捉えることが可\n能であると考えた．これらの感覚要素としては，立体感，質感，包囲感からなる空間要素，\n動感，リアルタイム感，同時感からなる時間要素，さらに自己存在感，インタラクティブ\n感，情感からなる「身体要素」を挙げられた．臨場感の評価手法として，主観評価，心理\n物理評価，脳活動計測，生体信号計測，行動計測の五つの手法を提案した．これらの手法\nを統合して臨場感を客観的・定量的に評価する必要があることを示唆した．映像の質感\n評価では，立体映像が質感を強調し，心理物理実験により光沢感の定量的評価が行われ\nた[40]．\n図2-10: 臨場感の構成要素と生起要因（[40] より引用）\n飯村らは，VR を用いたシステムに関する臨場感と現実感の評価を行った．印象調査の\n結果，臨場感は「動き」など視覚との結びつきが強く，映画またはゲームなどから感じ取\nれるもので，",
            "査の\n結果，臨場感は「動き」など視覚との結びつきが強く，映画またはゲームなどから感じ取\nれるもので，「その場にいるような感覚」と定義された．一方，現実感は視覚以外に痛覚\nとの結びつきが強く，不安および痛みなどから感じ取れるもので，「非現実を現実と感じ\nる」と定義された．因子分析の結果，臨場感には迫力因子と評価性因子，現実感には現実\n性因子があることがわかった[41]．\n14\n2.7\n本研究の位置づけ\n上記のように，風や温度，触覚刺激が没入感や感情に与える影響やコンテンツ体験の拡\n張・評価方法は示されたが，多感覚フィードバック（振動，風，温冷感）の統合的な効果\nは十分に検証されていない．そのため，本研究では振動，風の強弱，温冷感を組み合わせ\nた多感覚フィードバックシステムImmersion Neckwear を開発し，これが動画鑑賞におけ\nる没入感やユーザ体験に与える影響を評価する．\n15\n第3章\nImmersion Neckwear:\n動画体験拡張ネックウェア\n3.1\nImmersion Neckwear の概要\nImmersion Neckwear では，映像に合わせて五感を刺激する",
            " Neckwear の概要\nImmersion Neckwear では，映像に合わせて五感を刺激するフィードバックを行うこと\nで，自宅での動画鑑賞者が映像により没入することを目指している．どこでも4DX のよ\nうな感覚刺激を楽しむことができ，利用者の自由度が高く，多感覚のフィードバックを提\n供する頸部装着型の没入感向上デバイスを創作した．Immersion Neckwear のイメージ図\nを図3-1 に示す．\n図3-1: Immersion Neckwear を利用した動画鑑賞の例\n図3-2 は本研究で創作した頸部装着型の没入感向上デバイスImmersion Neckwear であ\nる．Immersion Neckwear とは，Immersion（没入）とNeckwear（ネックウェア）を用い\nて創作した今回のシステムの名称である．Immersion Neckwear の重さは約844g であり，\nImmersion Neckwear が本実験中に不快感を与えるか調査した．\n16\n図3-2: Immersion Neckwear の全体像\n3.2\nImmersion Neckwear",
            "-2: Immersion Neckwear の全体像\n3.2\nImmersion Neckwear の基本設計\n表3-1 は各構成要素の機能概要であり，図3-3 にImmersion Neckwear の基本システム構\n成を示す．Immersion Neckwear は制御部を中心に，電源部，フィードバック部，インター\nフェース部の4 つに分類される．\n表3-1: 各構成要素の機能概要\n要素名\n機能\n構成部品\nインターフェース部\n開始時間の出力\nnRF Connect\n電源部\n電源の供給\n5500mAh リチウムイオンバッテリ\n制御部\n電子部品の起動時間の制御\nペルチェ素子TEC1-03105\nフィードバック部\n映像に合わせたフィードバック\n温冷部：ペルチェ素子TEC1-03105\n風部：ターボブロワファンB0DB5SDX91\n振動部：振動モータLBV10B-009\n3.2.1\n各要素の機能詳細\nインターフェース部は，スマートフォンを用いてマイクロコンピュータと接続すること\nで，映像に合わせてシステムの開始を出力する．\n17\n図3-3: システムの基本設計\n電源部は，制御部に電源を供",
            "合わせてシステムの開始を出力する．\n17\n図3-3: システムの基本設計\n電源部は，制御部に電源を供給する．\n制御部は，他の構成要素の制御を行う．映像に合わせて電子部品の起動時間の制御を行\nう．また，電源部からの電源供給により，フィードバック部に電源供給を行う．\nフィードバック部は，制御部からの電源供給により，映像に沿ったフィードバックを\n行う．\n3.3\nハードウェアの設計\nImmersion Neckwear は，ペルチェ素子TEC1-03105（図3-4），Arduino Nano 33 BLE（図\n3-9），ターボブロワファンB0DB5SDX91（図3-10），振動モータLBV10B-009（図3-11），\n超音波ミストB0DBLL2TKL（図3-12），バッテリはKeepPower 26650 リチウムイオンバッ\nテリ5500mAh（図3-13）から構成する．\n3.3.1\n熱源の選定と温度制御\nImmersion Neckwear では，温刺激，冷刺激を瞬時に生じさせる必要があった．よって，\nエネルギ効率が電熱線より高く，電流の向きにより加熱と冷却が同一の電子部品で実現\n可能な",
            "た．よって，\nエネルギ効率が電熱線より高く，電流の向きにより加熱と冷却が同一の電子部品で実現\n可能な，ペルチェ素子TEC1-03105 を用いた．TEC1-03105 のサイズは縦横15mm，厚さ\n3.1mm である．TEC1-03105 は，直流電流を流すことで一方の面が吸熱し反対面に発熱が\n起こす．電流の極性を逆転させると，特性が反転する[42]．\n18\n図3-4: ペルチェ素子（[42] より引用）\n温度提示面の温度検出として，NTC サーミスタを用いた（図3-5）．NTC サーミスタは，\n温度上昇に対して抵抗値を減少させる性質があり，以下の式（1）を満たす[42]．よって，\n式変形した式（2）を用い，温度検出を行った．\nR = R0 exp\n(\nB\n( 1\nT −1\nT0\n))\n・・・（1）\nT =\n\n\n1\n1\nT0 + 1\nB log\n(\nR\nR0\n)\n\n\n・・・（2）\nR0\n温度T0 [K] 時のサーミスタ抵抗[Ω]\nR\n温度T [K] 時のサーミスタ抵抗[Ω]\nB\nサーミスタB 定数\nT0\n基準温度[K]\nT1\n測定温度[K]\n温度制御は，マイクロコンピュータのP",
            "サーミスタB 定数\nT0\n基準温度[K]\nT1\n測定温度[K]\n温度制御は，マイクロコンピュータのPWM（Pulse Width Modulation）出力を用いて，\n19\n図3-5: NTC サーミスタ\nPID 制御を行った．PWM 制御は，デジタル信号を用いてアナログ信号を模倣する手法で\nあり，制御対象の平均電圧を調整することで精密な制御を実現する．これにより，デバイ\nスはエネルギ効率を高めつつ，目的の動作を実現する．\nPWM 信号は，デューティサイクルと呼ばれる高電圧状態と低電圧状態の比率によって\n制御される．\n図3-6 に示すように，PWM 信号は一定周期でON とOFF を繰り返すデジタル波形であ\nる．デジタル波形を用いることで，加熱素子および冷却素子に供給されるエネルギの平均\nを調整し，温度を適切に制御をすることが可能になる．\n図3-6: PWM 出力の概念図（[43] より引用）\n20\nまた，本研究では，ペルチェ素子の同一面で温熱面と冷却面の両方を制御する必要が\nあった．よって，モータに回転，逆回転，ストップ，プレーキ等の制御を行うことができ\nるモータドライバを用いた．モ",
            "って，モータに回転，逆回転，ストップ，プレーキ等の制御を行うことができ\nるモータドライバを用いた．モータドライバTA7291P（図3-7）とPWM 出力を用いてペ\nルチェ素子の温度制御を行った．本研究では，温度センサを用いたPID 制御を行うこと\nで，温熱面を40 ℃，冷却面を20 ℃に設定してフィードバックをした．\n図3-7: モータードライバ（TA7291P）（[44] より引用）\nPID 制御とは，proportional（比例），integral（積分），differential（微分）の三つの制御\n要素を組み合わせた制御手法であり，設定温度に対する誤差を最小限に抑えるためのもの\nである．PID 制御を用いることで，図3-8 に示すように，目標とする温度に迅速かつ安定\n的に達成することが可能となる．具体的には，温度センサで検出した現在の温度と目標温\n度の差をもとに，ペルチェ素子への電力供給を調整する．これにより，過剰な温度変動を\n防ぎ，安定した温度制御が可能となった．\n21\n図3-8: PID 制御による温度制御（[45] より引用）\n3.3.2\nその他電子部品の選定\nImme",
            "-8: PID 制御による温度制御（[45] より引用）\n3.3.2\nその他電子部品の選定\nImmersion Neckwear では，首にデバイスをかけて映像を見てもらうため，利用者の映像\n体験に影響を与えることを防ぐために軽量化する必要があった．また，インターフェース\n部と制御部をBluetooth で接続可能なマイクロコンピュータを選定した．Arduino Nano 33\nBLE は，Arduino が開発した長辺40.64mm，短辺17.76mm の小型のマイクロコントロー\nラボードである．Bluetooth Low Energy（BLE）機能を内蔵しており，スマートフォンお\nよび他のIoT デバイスとの無線通信が可能である．本研究では，提案ボードの低消費電力\n性と小型性を活かし，システム全体の制御に利用した[46]．\n図3-9: Arduino Nano 33 BLE（[46] より引用）\n使用者の不快感を考慮し軽量化かつ，フィードバックの強い電子部品を選択した．風に\nよるフィードバックとして利用するターボブロワファンは定格回転速度6000RPM，風量\n4.0CFM，静圧6.",
            "ードバックとして利用するターボブロワファンは定格回転速度6000RPM，風量\n4.0CFM，静圧6.61mmAq である[47]．\n22\n図3-10: ターボブロワファンB0DB5SDX91\n振動によるフィードバックとして利用する円盤形ブラシレス振動モータは，直径10mm\nであり，バラスト重心の偏芯によって，高速回転時に強い振動を発生させた[46]．\n図3-11: 振動モータLBV10B-009（[46] より引用）\nミストによるフィードバックとして超音波霧化メーカを用いた．モジュールのサイズ\nは長辺29.5mm，短辺18.6mm，厚さ7mm，共振周波数108～110KHz である．また，提\n案デバイスを用いて香り付きの水を噴霧することで香りによるフィードバックを実現し\nた[48]．\n23\n図3-12: 超音波ミストB0DBLL2TKL\n本研究では，多くの電子部品を用いるので，電気容量が高いバッテリが必要であった．\n実験で使用するKeepPower-26650 は，定格容量5500mAh であり，本研究の実験中の連続\n稼働が可能であることから選択した[49]．\n図3-13: KeepP",
            " であり，本研究の実験中の連続\n稼働が可能であることから選択した[49]．\n図3-13: KeepPower 26650 リチウムイオンバッテリ5500mAh（[49] より引用）\n24\n第4章\nImmersion Neckwearの没入感効果検証\n実験\n本章では，Immersion Neckwear を用いた評価実験について述べる．\n4.1\n実験概要\n第1 章で説明したように，Immersion Neckwear の有無によって動画体験の印象を違いを\n比較し，有効性の検証を行うことを目的とする．\n被験者は成人男性8 名，成人女性2 名の計10 名（年齢層は22 歳から26 歳）に協力し\nてもらった．実験では，25 分程度の初めて視聴するアクションアニメを視聴してもらっ\nた．鑑賞終了後には，被験者にSD 法（Semantic Differential Method）を用いたアンケー\nトを記入してもらい，動画鑑賞に対する主観的な評価を収集した．また，正確な制御が困\n難であり被験者の実験中に怪我を負わせる可能性があったので，今回，超音波ミストの使\n用を中止した．\n4.2\n実験手順\n本実験で",
            "怪我を負わせる可能性があったので，今回，超音波ミストの使\n用を中止した．\n4.2\n実験手順\n本実験では，フィードバックを起こす場面の個数がほぼ等しい25 分程度の2 つの動画\nを用意し，被験者はImmersion Neckwear を使用した場合と使用していない場合で動画鑑\n賞を行った．表4-1 は場面とフィードバックの種類の対応を示している．システム有無\nによる動画鑑賞はそれぞれ別日に行なった．動画の視聴が終了後，被験者にはSD 法によ\nるアンケートに回答してもらい，視聴体験に対する主観的な評価を収集した．さらに，\nImmersion Neckwear を使用して視聴した被験者については，システムの使いやすさに関\nする評価を行うために，SUS（System Usability Scale）を用いてアンケートを実施した．\nSUS アンケートでは，システムの全体的な使いやすさおよび利便性，直感的な操作性な\nどを評価した．図4-1 はImmersion Neckwear を装着した場合の実験中の様子である．\n25\n表4-1: 場面の種類に応じたフィードバックの対応\n場面の種類\nフィードバッ",
            "中の様子である．\n25\n表4-1: 場面の種類に応じたフィードバックの対応\n場面の種類\nフィードバック\nそよ風，爆風，向かい風\n風\n爆発，炎が出現するシーン\n温感\n氷が出現するシーン\n冷感\n戦闘シーン(攻撃が当たるシーン)\n振動\n図4-1: 実験の様子\n4.3\nSD 法\nSD 法は各刺激に対して人が抱く印象，イメージを明らかにするために用いる手法で，\n相反する形容詞対を多数用いて刺激を評価することにより，人がその刺激に対して，どの\nように感じるかといった情緒的な印象を明らかにすることが可能となる[50]．\n以下に，アンケートに用いる印象語対を記す．\n• 好きな　＿＿＿＿＿＿＿＿＿　嫌いな\n• 良い　＿＿＿＿＿＿＿＿＿＿　悪い\n• 気持ちの良い　＿＿＿＿＿＿　気持ちの悪い\n• はっきりした　＿＿＿＿＿＿　ぼんやりした\n26\n• 迫力のある　＿＿＿＿＿＿＿　迫力のない\n• リアリティのある　＿＿＿＿　リアリティのない\n• 動的な　＿＿＿＿＿＿＿＿＿　静的な\n• 弱い　＿＿＿＿＿＿＿＿＿＿　強い\n• 興奮した　＿＿＿＿＿＿＿＿　落ち着いた\nそして，各形容詞対を左から「非常に」，「かなり」，「",
            "い\n• 興奮した　＿＿＿＿＿＿＿＿　落ち着いた\nそして，各形容詞対を左から「非常に」，「かなり」，「やや」，「どちらでもない」，「やや」，\n「かなり」，「非常に」の7 段階で評価した．付録A は，本実験で使用したアンケートフォー\nムである．\n4.4\nSUS\nSUS は，製品およびサービスの使いやすさを評価するためのアンケートのことである．\nこれは，ソフトウェア，ハードウェアを問わず，さまざまな新しいシステムのユーザビリ\nティを評価し，洞察を得るための定量的な手法として使用される．リッカート尺度を使用\nして回答する10 個の質問で構成される．本研究では，「強く同意する」から「強く同意し\nない」までの5 段階で評価した[51]．\nまず，SUS 調査の各回答選択肢を対応する評定を割り当てる．回答が「強く反対」の場\n合は1 点，「反対」の場合は2 点，「どちらでもない」の場合は3 点，「同意する」の場合\nは4 点，そして「強く同意」の場合は5 点とする．\n各質問項目への回答（評点X）に基づき，以下の方法で得点を計算する．\n• 奇数番目の項目：X －1 点\n• 偶数番目の項目：5 －X 点\n• ",
            "下の方法で得点を計算する．\n• 奇数番目の項目：X －1 点\n• 偶数番目の項目：5 －X 点\n• 未回答の項目：3 点\nこれらの得点を合計し，その合計値に2.5 を乗じることで，0-100 点のSUS スコアが算出\nする．SUS スコアが高いほど，評価対象の製品，システム自体，およびその利用開始まで\nの過程または利用後に期待される効果に対するユーザの満足度が高いと判断される[52]．\nSUS (System Usability Scale) のスコアリングと解釈について，以下のようにまとめる．\n• A+: 84.1–100 (96th–100th percentile)\n• A: 80.8–84.0 (90th–95th percentile)\n27\n• A －: 78.9–80.7 (85th–89th percentile)\n• B+: 77.2–78.8 (80th–84th percentile)\n• B: 74.1–77.1 (70th–79th percentile)\n• B －: 72.6–74.0 (65th–69th percentile)\n• C+: 71.1–7",
            "B －: 72.6–74.0 (65th–69th percentile)\n• C+: 71.1–72.5 (60th–64th percentile)\n• C: 65.0–71.0 (41st–59th percentile; 平均的なユーザビリティ)\n• C －: 62.7–64.9 (35th–40th percentile)\n• D: 51.7–62.6 (15th–34th percentile)\n• F: 0.0–51.6 (0th–14th percentile; 低いユーザビリティ)\nグローバル平均SUS スコアは約68 で，これはC グレード(平均的なユーザビリティ) に\n相当する．50 未満のスコアは欠陥があると見なされ，80 以上のスコアを持つシステムは，\n平均以上のユーザエクスペリエンスを示し，優れたユーザビリティに関連している．65\nから80 のスコアは受け入れ可能だが，改善の余地があることを示唆している．65 未満の\nスコアは，ユーザビリティの問題があることを示しており，注意が必要である．\nSUS は，その信頼性と有効性が広く認められており，さまざまな製品お",
            "示しており，注意が必要である．\nSUS は，その信頼性と有効性が広く認められており，さまざまな製品およびシステムの\nユーザビリティ評価に使用されている．さらに，SUS は柔軟性があり，軽微な文言変更に\nも影響されず，異なる言語，文化にも適用可能である．SUS の規範データは代表的なグ\nループから収集され，スコアの解釈を強化するために使用される[53]．\n付録B は，本実験で使用したアンケートフォームである．\n28\n第5章\n実験結果および考察\n5.1\n実験結果\n5.1.1\nSD 法の評価結果\n動画鑑賞後にSD 法を用いたアンケートを実施した．本アンケートを「プロフィール分\n析」と「因子分析」を利用してデータの分析を行うことで，Immersion Neckwear の有無に\nよる映画体験の没入感の変化を評価した．\n図5-1 は被験者が回答したデータから，評定尺度ごとの回答平均値を算出して図式化し\nたプロフィール分析の結果である．縦軸は各形容詞対を表し，横軸は形容詞対に対する7\n段階の評価尺度を表す．青線がImmersion Neckwear を装着をした場合の動画鑑賞時の印\n象を示しており",
            "を表す．青線がImmersion Neckwear を装着をした場合の動画鑑賞時の印\n象を示しており，赤線がImmersion Neckwear を装着しなかった場合の動画鑑賞時の印象\nを示している．プロフィール分析によって，Immersion Neckwear を装着した場合としな\nかった場合の印象の違い，Immersion Neckwear の装着が被験者の印象に与える影響を視\n覚的に比較可能になる．\n図5-1: Immersion Neckwear のプロフィール分析\n共通因子を特定するために，アンケートデータに対して因子分析を実施した．Immersion\nNeckwear を装着した場合の因子分析の結果を表5-1 に示す．初期の固有値の大きさと減\n衰状況から，因子数は3 と判断した．因子負荷量は，因子と変数の間に有意な相関がある\n29\nと言われている絶対値0.4 以上とし，斜交回転法を用いて因子間の相関関係を考慮できる\nプロマックス回転を適用した．因子負荷量の絶対値が1 に近いほど，因子との関係性が\n強いことを示す．因子1 は「好きな」，「良い」，「迫力ある」などの形容詞と強く",
            "ど，因子との関係性が\n強いことを示す．因子1 は「好きな」，「良い」，「迫力ある」などの形容詞と強く関連して\nいることがわかった．また，因子2 は「興奮した」，「強い」，「気持ちのいい」，因子3 は\n「はっきりした」，「リアリティのある」などの形容詞と関連が深いことが判明した．\n表5-1: システムを装着する時の因子負荷量\n形容詞1\n形容詞2\n因子1\n因子2\n因子3\n嫌いな\n好きな\n0.888\n-0.376\n-0.073\n悪い\n良い\n0.820\n0.321\n-0.043\n迫力のない\n迫力のある\n0.744\n0.317\n0.189\n落ち着いた\n興奮した\n-0.027\n0.982\n-0.245\n弱い\n強い\n-0.080\n0.651\n0.107\n気持ちの悪い\n気持ちのいい\n-0.278\n0.505\n0.207\nぼんやりした\nはっきりした\n0.062\n0.055\n0.998\nリアリティのない\nリアリティのある\n-0.108\n-0.024\n0.824\n寄与率\n30.282\n20.791\n14.951\n回転後の負荷量平方和\n2.457\n2.313\n1.849\nImmersion Neckwear ",
            "1\n回転後の負荷量平方和\n2.457\n2.313\n1.849\nImmersion Neckwear を装着しなかった場合の因子分析の結果を表5-2 に示す．因子負荷\n量の絶対値が1 に近いほど，因子との関係性が強いことを示す．因子1 は「迫力のある」，\n「良い」，「興奮した」，「強い」などの形容詞と強く関連していることがわかった．また，因\n子2 は「はっきりした」，「リアリティのある」などの形容詞と関連が深いことが判明した．\n表5-2: システムを装着しない時の因子負荷量\n形容詞1\n形容詞2\n因子1\n因子2\n迫力のある\n迫力のない\n0.953\n0.157\n良い\n悪い\n0.861\n-0.066\n興奮した\n落ち着いた\n0.669\n-0.256\n強い\n弱い\n0.500\n-0.027\nはっきりした\nぼんやりした\n0.116\n0.994\nリアリティのある\nリアリティのない\n-0.232\n0.842\n寄与率\n46.164\n30.801\n回転後の負荷量平方和\n2.414\n1.792\n30\n5.1.2\nSUS の評価結果\nImmersion Neckwear のユーザビリティを評価するために，SUS ",
            "SUS の評価結果\nImmersion Neckwear のユーザビリティを評価するために，SUS によるアンケートを行っ\nた．表5-3 は被験者ごとのSUS によるアンケートの回答結果をまとめたものである．\n表5-3: SUS のアンケート結果\n被験者ID\nQ1\nQ2\nQ3\nQ4\nQ5\nQ6\nQ7\nQ8\nQ9\nQ10\nスコア\n1\n5\n2\n5\n2\n2\n2\n4\n4\n4\n4\n65\n2\n4\n3\n5\n3\n1\n2\n5\n4\n4\n3\n60\n3\n4\n1\n5\n1\n4\n4\n5\n1\n5\n5\n77.5\n4\n5\n2\n5\n2\n2\n3\n5\n2\n5\n4\n72.5\n5\n4\n1\n5\n4\n5\n5\n5\n1\n4\n4\n70\n6\n5\n3\n4\n1\n5\n2\n5\n1\n4\n5\n77.5\n7\n4\n3\n4\n5\n3\n4\n4\n3\n4\n5\n47.5\n8\n3\n4\n3\n5\n2\n3\n3\n2\n1\n2\n40\n9\n5\n2\n4\n4\n4\n2\n4\n4\n4\n3\n65\n10\n5\n3\n5\n2\n5\n3\n5\n2\n5\n5\n75\n平均値\n4.4\n2.4\n4.5\n2.9\n3.3\n3\n4.5\n2.4\n4\n4\n65\n標準偏差\n0.63\n0.87\n0.64\n1.38\n1.35\n0.95\n",
            "4.5\n2.4\n4\n4\n65\n標準偏差\n0.63\n0.87\n0.64\n1.38\n1.35\n0.95\n0.64\n1.14\n1.04\n0.95\n11.48\nまた自由記述欄にて，「微妙な重さが少し気になった」，「デバイスが大きいと感じた」，\n「温度が人によっては暑すぎる」などの指摘がされた．一方で，「アニメに合わせて温度変\n化があり楽しかった」，「cooler とwarmer 機能は実際に感じて，リアルタイム性も高いと\n思った」のようなImmersion Neckwear の使用にポジティブな意見もあった．\n5.2\n考察\n5.2.1\nSD 法の評価結果に関する考察\nプロフィール分析の結果，Immersion Neckwear を装着した場合と装着しなかった場合\nの印象に違いがみられた．Immersion Neckwear を装着した場合，各形容詞対全体で肯定\n的な評価が確認された．これにより，Immersion Neckwear はユーザのポジティブな印象\nを高める効果があると推察する．よって，動画鑑賞におけるImmersion Neckwear の装着\nが，動画の印象を向上させる要因となる",
            "，動画鑑賞におけるImmersion Neckwear の装着\nが，動画の印象を向上させる要因となることが考えられる．特に，「動的な-静的な」に関\nして，Immersion Neckwear の有無によって印象の変化が推察される．これはImmersion\nNeckwear が画面に応じて起動されることを，「動的」と捉えたと考える．\n表5-4 と表5-5 は，形容詞を使った印象の評価を分析した結果を示している．結果に基\nづき，Immersion Neckwear を使ったときの印象を整理した．\n31\nImmersion Neckwear を装着すると，因子1 は「好きな」「良い」「迫力ある」といった言\n葉と強く結びつきことがわかる．これを「評価」とまとめた．因子2 は「興奮した」「強\nい」「気持ちのいい」と関連が深かったため，「活力」とした．因子3 は「好きな」「はっ\nきりした」「リアリティのある」などの言葉と関係があったので，「現実性」とした．\n結果から，Immersion Neckwear を装着した動画鑑賞において，「評価」「活力」「現実性」\nの印象を持つことが考えられる．\n表5-",
            "ar を装着した動画鑑賞において，「評価」「活力」「現実性」\nの印象を持つことが考えられる．\n表5-4: システムを装着した場合の，形容詞と因子の意味付け\n因子\n形容詞\n因子の解釈\n1\n「好きな」，「良い」，「迫力のある」\n評価\n2\n「興奮した」，「強い」，「気持ちのいい」\n活力\n3\n「はっきりした」，「リアリティのある」\n現実性\nImmersion Neckwear を装着しない場合，因子1 は「迫力のある」，「良い」，「興奮した」，\n「強い」といった言葉と強く結びつきことがわかる．これを「活力」とまとめた．因子2\nは「はっきりした」「リアリティのある」と関連が深かったため，「現実性」とした．\n結果から，Immersion Neckwear を装着した動画鑑賞において，「活力」「現実性」の印象\nを抱くことが考えられる．\n表5-5: システムを装着しない場合の，形容詞と因子の意味付け\n因子\n形容詞\n因子の解釈\n1\n「迫力のある」，「良い」，「興奮した」，「強い」\n活力\n2\n「はっきりした」，「リアリティのある」\n現実性\n因子の解釈から，従来の動画鑑賞での印象を包括しながらも，\n「評価性",
            "」，「リアリティのある」\n現実性\n因子の解釈から，従来の動画鑑賞での印象を包括しながらも，\n「評価性」といった新たな肯\n定的印象が増えていることがわかる．よって，因子分析の結果として，Immersion Neckwear\nを用いた動画鑑賞は，Immersion Neckwear を使用しない場合よりも優れた鑑賞体験を提\n供することを推察する．また，寺本らの研究では，評価性が没入感の要素として抽出され\nておりImmersion Neckwear を使った動画鑑賞がより没入感のある体験と考えられる[39]．\n5.2.2\nSUS の結果に関する考察\nSUS によって評価されたシステム全体の平均値が68 点であり，今回のSUS スコアが65\n点であることから，C グレードに相当する．よって，Immersion Neckwear のユーザビリ\nティは改善の必要があると考える．質問4（技術的サポートの必要性），質問8（操作性）\nでは平均点が低く，回答にばらつきが見られた．実験では，被験者に動画を鑑賞すること\nだけを指示し，システムの装着および起動は研究担当者が行ったため，一部の被験者はシ\n32\nス",
            "すること\nだけを指示し，システムの装着および起動は研究担当者が行ったため，一部の被験者はシ\n32\nステムの使用に技術的サポートが必要と感じたと考えられる．さらに，使用感に関しても\n一部の被験者から不満が出た．Immersion Neckwear の重さが800g を超えており，これが\n動画鑑賞中の不快感につながり，システムの使用が面倒だと感じたと考えられる．以上の\nSUS に基づくアンケート結果から，システムのユーザビリティには改善の余地があると\n考えられる．ただし，「アニメに合わせた温度変化が楽しかった」，「cooler とwarmer 機能\nがリアルタイムで感じられた」などのポジティブな意見もあり，Immersion Neckwear が\n動画鑑賞の没入感向上に有効であることが推察できる．\n33\n第6章\n結論\n6.1\nまとめ\n本論文では，自宅での動画鑑賞体験を拡張することを目的として，多感覚フィードバッ\nクを提供する頸部装着型没入感向上デバイスImmersion Neckwear を創作した．Immersion\nNeckwear は，映像に合わせて振動，風の強弱，温感，冷感などを提",
            "創作した．Immersion\nNeckwear は，映像に合わせて振動，風の強弱，温感，冷感などを提示することで，映画\n館での没入感に近い体験を自宅でも再現することを目指している．\n実験結果から，Immersion Neckwear を装着した動画鑑賞では，被験者がよりポジティブ\nな印象を抱き，動画の没入感が向上することが確認された．具体的には，SD 法によるア\nンケートの因子分析で，システムの装着により評価性が高まることが確認された．\n一方，SUS によるユーザビリティ評価では，平均値が65 点となり，技術的サポートの\n必要性およびシステムの重さ・大きさに関する不満が一部の被験者から指摘された．しか\nし，「アニメに合わせた温度変化が楽しかった」，「cooler とwarmer 機能がリアルタイムで\n感じられた」といったポジティブな意見も多く，Immersion Neckwear が動画鑑賞の没入\n感向上に有効であることが示唆された．\n6.2\n今後の展望\n今後の展望として，ユーザビリティの向上が必要である．SUS アンケート結果から示\nされた技術的サポートの必要性およびシステムの重さ，",
            "の向上が必要である．SUS アンケート結果から示\nされた技術的サポートの必要性およびシステムの重さ，大きさに関する不満を解消するた\nめ，ユーザインターフェースの改善，デバイスの軽量化，コンパクト化が求められる．具\n体的には，より直感的な操作が可能なインターフェースデザインを採用し，ユーザが簡単\nにシステムを操作可能にすることが挙げられる．また，使用する素材の見直しおよび電子\n部品の改良によって，デバイス全体の軽量化を図ることが考えられる．今回，映像に合わ\nせて，風，振動，温冷部を実装したが，ミストや香りによるフィードバックの実装を目指\nす．これにより，ユーザが映像から感じる臨場感が向上すると考える．さらに，フィード\nバック機能の強化も重要な課題である．Immersion Neckwear は，振動，風の強弱，温感，\n冷感といった多感覚のフィードバックを提供しているが，これらのフィードバックの精\n度，リアルタイム性の向上が求められる．特に，映像に合わせたフィードバックのタイミ\nング，強度をより正確に制御するための技術開発が必要である．これらにより，ユーザに\n34\nより一層没入感を感じさせ",
            "より正確に制御するための技術開発が必要である．これらにより，ユーザに\n34\nより一層没入感を感じさせることができると考えられる．また本研究では，20 代の男女\n10 名の被験者データのみ取得したが，より多くの被験者を対象にした大規模な実験を実\n施し，統計的に有意なデータを収集することで，Immersion Neckwear の効果をより明確に\n示す必要があると考えられる．また，異なる年齢層および文化背景を持つ被験者を対象に\nした研究を行うことで，ユーザビリティ，没入感に対する高度なシステムを実現したい．\n35\n謝辞\n本研究を進めるうえで，親身に相談に乗って下さった青山学院大学理工学部情報テクノ\nロジー学科ロペズ・ギヨーム教授に深く感謝をいたします．また，研究初期において，電\n子工作のやり方など助言を下さった青山学院大学理工学研究科理工学専攻知能情報コー\nス博士前期課程１年ボデガ　パロメケ　ペドロ氏，3D プリンタの使用をサポートとして\nくださった田崎研究室の山田様，研究環境の補助をしてくださった大熊氏，論文の添削を\n通してアドバイスをくださった高山先輩をはじめとするロペズ研究室の院生の",
            "ださった大熊氏，論文の添削を\n通してアドバイスをくださった高山先輩をはじめとするロペズ研究室の院生の方々，同期\nの方々に深く感謝いたします．また，実験に協力していただいた被験者の方々にも感謝い\nたします．\n2025 年1 月24 日\n岩本空\n36\n参考文献\n[1] 株式会社ＩＣＴ総研：2023 年有料動画配信サービス利用動向に関する調査，https:\n//ictr.co.jp/report/20230421.html/. (最終参照日: 2025/1/3).\n[2] GEMPartners 株式会社：動画配信（VOD）市場5 年間予測（2024-2028 年）レポート，\nhttps://gem-standard.com/columns/789/. (最終参照日: 2025/1/5).\n[3] 株式会社プラネット：映画に関する意識調査，https://www.planet-van.co.\njp/shiru/from_planet/vol210.html. (最終参照日: 2025/1/5).\n[4] 株式会社宣成社：映画離れする映画館，https://senseisha.co.jp/us",
            ".\n[4] 株式会社宣成社：映画離れする映画館，https://senseisha.co.jp/useful/\nkiji.php?n=23. (最終参照日: 2025/1/5).\n[5] 株式会社スパコロ：映画館の利用意識調査～コロナ禍、映画館利用意識どう変わっ\nた？～，https://prtimes.jp/main/html/rd/p/000000041.000060722.\nhtml. (最終参照日: 2025/1/5).\n[6] TOHO\nシネマズ：MX4D™,\nhttps://www.tohotheater.jp/service/\nmx4d/. (最終参照日: 2025/1/5).\n[7] 代蔵巧，棟方渚，小野哲雄，松原仁：他者の存在を感じる動画鑑賞システム，研究報\n告エンタテインメントコンピューティング（EC），Vol. 2011-EC-19, No. 2, pp. 1–6\n(2011).\n[8] 松井啓司，中村聡史：周辺視へのエフェクト提示による動画の印象変化に関する調\n査，第78 回全国大会講演論文集，Vol. 2016, No. 1, pp. 303–304 (2016",
            "第78 回全国大会講演論文集，Vol. 2016, No. 1, pp. 303–304 (2016).\n[9] 三上紀一，小川剛史：音楽体験向上のための電気的筋肉刺激を用いた感情増幅手法\nの検討，研究報告グループウェアとネットワークサービス（GN），pp. 1–6 (2019).\n[10] 三ツ木萌，丸山一貴：脳波と皮膚電気活動を用いた観客の盛り上がり推定の試み，エ\nンタテインメントコンピューティングシンポジウム論文集，Vol. 2021, pp. 370–374\n(2021).\n37\n[11] Terasawa, N., Tanaka, H., Sakti, S. and Nakamura, S.: Tracking liking state in brain\nactivity while watching multiple movies, Proc. of the 19th ACM International Conference\non Multimodal Interaction (ICMI ’17), pp. 321–325 (2017).\n[12] 平松拓也，池田悠平，保科",
            " (ICMI ’17), pp. 321–325 (2017).\n[12] 平松拓也，池田悠平，保科篤志，馮晨，高橋裕也，菅谷みどり：生体情報による感情\n推定手法とステージの観客反応による評価，マルチメディア, 分散協調とモバイルシ\nンポジウム2017 論文集，pp. 857–864 (2017).\n[13] 角田啓介，江口佳那，吉田和広，渡部智樹，水野理：心拍と呼吸を用いたコンテンツ\n視聴による気分変化の推定：コメディ視聴における検討，情報処理学会論文誌コン\nシューマ・デバイス＆システム（CDS），Vol. 7, No. 1, pp. 44–52 (2017).\n[14] Liu, S., Lv, J., Hou, Y., Shoemaker, T., Dong, Q., Li, K. and Liu, T.: What Makes a Good\nMovie Trailer?: Interpretation from Simultaneous EEG and Eyetracker Recording, MM\n’16: Proceedings of the 24th ACM inter",
            "cording, MM\n’16: Proceedings of the 24th ACM international conference on Multimedia, pp. 82–86\n(2016).\n[15] He, Z., Zhang, S., Sun, P., Li, J., Xie, X., Zhang, M. and Liu, Y.: Understanding User Im-\nmersion in Online Short Video Interaction, CIKM ’23: Proceedings of the 32nd ACM In-\nternational Conference on Information and Knowledge Management, pp. 731–740 (2023).\n[16] 三角真，折居英章，SHARMIN, T.，三島健司，西原宏：fNIRS による音楽聴取時の前\n頭前野における脳血液量の測定と考察，福岡大学工学集報，Vol. 96, pp. 25–28 (2016).\n[17] 宮本晴司，代蔵巧，棟方渚，小野哲雄：生体信",
            ". 96, pp. 25–28 (2016).\n[17] 宮本晴司，代蔵巧，棟方渚，小野哲雄：生体信号を用いた動画視聴中のユーザ評価の\n推定，エンタテインメントコンピューティングシンポジウム，Vol. 2015, pp. 568–573\n(2015).\n[18] 岡本早織，羽田久一：ゲームプレイ中の風の強度による臨場感の変化，エンタテイ\nンメントコンピューティングシンポジウム，Vol. 2022, pp. 135–138 (2022).\n[19] 伊藤亘輝，小野龍一，羽田久一：VR 空間で全周囲から風を感じる為の送風機の配置\nの検討，研究報告コンシューマ・デバイス& システム(CDS)，Vol. 2019, No. 48, pp.\n1–5 (2019).\n[20] 村田佳代子，妹尾武治：風によるベクションの促進と抑制―温風の効果について―，\n日本バーチャルリアリティ学会論文誌，Vol. 22, No. 2, pp. 287–290 (2017).\n[21] 小島雄一郎，橋本悠希，梶本裕之：頭部搭載型風ディスプレ，インタラクション，\nVol. 2009 (2009).\n38\n[22] M",
            "：頭部搭載型風ディスプレ，インタラクション，\nVol. 2009 (2009).\n38\n[22] Maeda, T. and Kurahashi, T.: Thermodule: Wearable and modular thermal feedback sys-\ntem based on a wireless platform, Proceedings of the 10th Augmented Human Interna-\ntional Conference 2019, pp. 1–8 (2019).\n[23] 牛尾大翔，黒田千晶，水口充ほか：温感呈示による情動制御手法の効果の検証，エンタ\nテインメントコンピューティングシンポジウム2022 論文集，Vol. 2022, pp. 102–105\n(2022).\n[24] 安保友香梨，松井遼太，柳沢豊，竹川佳成，平田圭二：ONE Parka：オンラインライブ\nパフォーマンス視聴のための一体感を促進する衣服型ウェアラブルデバイスの設計\nと実装，情報処理学会論文誌デジタルコンテンツ（DCON），Vol. 12, No. 1, pp. 18",
            "実装，情報処理学会論文誌デジタルコンテンツ（DCON），Vol. 12, No. 1, pp. 18–28\n(2024).\n[25] Kim, A., Bae, H. and Lee, K.: Effects of Tactile Perception on Emotion and Immersion\nto Film Viewing in a Virtual Environment, VRST ‘19: Proceedings of the 25th ACM\nSymposium on Virtual Reality Software and Technology，pp. 1–3 (2019).\n[26] Mazzoni, A. and Bryan-Kinns, N.: Mood Glove: A Haptic Wearable Prototype System\nto Enhance Mood Music in Film, Media and Arts Technology Centre for Doctoral Train-\ning, School of Electronic Engi",
            "for Doctoral Train-\ning, School of Electronic Engineering and Computer Science, Queen Mary University of\nLondon, pp. 1–8 (2016).\n[27] 久保光徳，寺方将之，寺内文雄，青木弘行：揺動・振動刺激下における快感情評価，\n日本デザイン学会研究発表大会概要集，Vol. 53, No. 0, pp. 99–99 (2006).\n[28] 久原拓巳，細田千尋，南角吉彦，加藤昇平，田中由浩：感情付き合成音声を伴う振\n動触覚刺激の心理的影響の調査，ロボティクス・メカトロニクス講演会講演概要集\n2022，pp. 2P2–B09 (2022).\n[29] 須佐見憲史，安藤広志：映像に対する香りの付加が臨場感に及ぼす効果(日本基礎心\n理学会第26 回大会, 大会発表要旨)，基礎心理学研究，Vol. 26, No. 2, p. 225 (2008).\n[30] 阿久津洋巳，市原茂，石戸谷真由子：香りの感情価に及ぼす音楽の影響，日本官能\n評価学会誌，Vol. 9, No. 2, pp",
            "戸谷真由子：香りの感情価に及ぼす音楽の影響，日本官能\n評価学会誌，Vol. 9, No. 2, pp. 116–121 (2005).\n[31] 田中昭子：香りによってもたらされる快適感の生理心理作用，生活工学研究，Vol. 2,\nNo. 1, pp. 18–19 (2000).\n[32] Oh, E., Lee, M. and Lee, S.: How 4D effects cause different types of presence experience?,\nVRCAI ’11, Association for Computing Machinery, p. 375–378 (2011).\n39\n[33] Jeong, D., Han, S. H., Jeong, D. Y., Kwon, K. and Choi, S.: Investigating 4D movie\naudiences’ emotional responses to motion effects and empathy，Computers in Human\nBehavior, Vol. 121, p. 10",
            "pathy，Computers in Human\nBehavior, Vol. 121, p. 106797 (2021).\n[34] Lee, J., Han, B. and Choi, S.: Interactive motion effects design for a moving object in 4D\nﬁlms, Association for Computing Machinery, p. 219–228 (2016).\n[35] Nicolae, D. F.: Spectator perspectives in virtual reality cinematography. The witness, the\nhero and the impersonator, Ekphrasis. Images, Cinema, Theory, Media, Vol. 20, No. 2, pp.\n168–180 (2018).\n[36] Kim, A., Chang, M., Choi, Y., Jeon, S. and Lee, K.: The Effect of Immersi",
            "i, Y., Jeon, S. and Lee, K.: The Effect of Immersion on Emotional\nResponses to Film Viewing in a Virtual Environment, 2018 IEEE Conference on Virtual\nReality and 3D User Interfaces (VR), pp. 601–602 (2018).\n[37] 杉原太郎，森本一成，黒川隆夫：SD 法を通してみた音楽に対する感性の基本特性，映\n像情報メディア学会技術報告25.48，一般社団法人映像情報メディア学会，pp. 57–63\n(2001).\n[38] 仁科弘重，中本有美：観葉植物, 花, 香りが人間に及ぼす生理・心理的効果の脳波およ\nびSD 法による解析，日本建築学会計画系論文集，Vol. 63, No. 509, pp. 71–75 (1998).\n[39] 寺本渉，吉田和博，浅井暢子，日高聡太，行場次朗，鈴木陽一：臨場感の素朴な理\n解(¡ 特集¿ VR 心理学4)，日本バーチャルリアリティ学会論文誌，Vol. 15,",
            "感の素朴な理\n解(¡ 特集¿ VR 心理学4)，日本バーチャルリアリティ学会論文誌，Vol. 15, No. 1, pp.\n7–16 (2010).\n[40] 安藤広志：2. 人が感じる臨場感の知覚認知メカニズムと評価技術，映像情報メディ\nア学会誌，Vol. 63, No. 12, pp. 1727–1730 (2009).\n[41] 飯村浩平，中村広幸，大倉典子，小松剛：臨場感と現実感の定量化と評価の実験，日\n本人間工学会大会講演集，Vol. 48, No. 0, pp. 432–433 (2012).\n[42] 徳田貴拓，磯山直也，ロペズギヨーム：Pico-Band: リストバンド型省エネ個別暖房\nデバイスの開発-温熱感を持続させる温度制御法の提案，IEICE Conferences Archives\n(2016).\n[43] Inc, M.:\nパルス幅変調とは?，https://www.mathworks.com/discovery/\npulse-width-modulation.html. (最終参照日: 2025/1/8).\n[44] Key Electronics 合同会社",
            "html. (最終参照日: 2025/1/8).\n[44] Key Electronics 合同会社：DigiKey, https://www.digikey.jp/. (最終参照日:\n2025/1/8).\n40\n[45] 株式会社モトヤマ：PID\n制御とは，https://www.motoyama.co.jp/\nengineer/engi106.htm. (最終参照日: 2025/1/8).\n[46] 株式会社秋月電子通商：秋月電子通商，https://akizukidenshi.com/\ncatalog/default.asp. (最終参照日: 2025/1/8).\n[47] 深セン鵬林オプトエレクトロニクス株式会社：PENGLIN,\nhttp://www.\nszpelink.com/. (最終参照日: 2025/1/8).\n[48] 株式会社スイッチサイエンス：スイッチサイエンス，https://www.\nswitch-science.com/. (最終参照日: 2025/1/8).\n[49] キープパワーテクノロジー株式会社：KEEP POWER, https://www.ke",
            ".\n[49] キープパワーテクノロジー株式会社：KEEP POWER, https://www.keeppower.\ncom/. (最終参照日: 2025/1/8).\n[50] 福田忠彦，福田涼子，福田忠彦研究室：増補版人間工学ガイド- 感性を科学する方\n法-，株式会社サイエンティスト社(2009).\n[51] Inc., Q.:\nSystem Usability Scale:\nWhat it is, Calculation + Usage, https://\nwww.questionpro.com/blog/system-usability-scale/.\n(最終参照日:\n2025/1/8).\n[52] 山内繁：人を対象とする研究計画入門: 科学的合理性と倫理的妥当性，丸善出版(2015).\n[53] Lewis, J. R.: The system usability scale: past, present, and future, International Journal\nof Human–Computer Interaction, Vol. 34, No. 7, pp. 5",
            " Human–Computer Interaction, Vol. 34, No. 7, pp. 577–590 (2018).\n41\n付録A\n　SD法に基づいたアンケートフォーム\n42\n43 \n \n \n動画鑑賞で感じたイメージについて最もよくあてはまると思うものをお選びくだ \nさい。 \nPlease select the image that best describes your impression of the video. \n動画鑑賞に関するアンケート \n・似たような項⽬を以前に回答したと感じるときがあるかもしれませんが、すべての項⽬ \nは完全に別々のものですので、以前に回答した項⽬を読み返したり思い返したりしないで \nください \n・この評価実験は能⼒を判定するものではありませんので、あまり考えこまず、⾃分の感 \nじた通りに評価を⾏ってください。 \n  アカウントを切り替え \nる \n共有なし \n 必須の質問です \n名前  \n回答を⼊⼒ \n2025/01/23 17:29 \n動画鑑賞に関するアンケート \n44 \n \n \n動的な \n  \n \n \n \n \n \n \n \n \n静的な  ",
            "鑑賞に関するアンケート \n44 \n \n \n動的な \n  \n \n \n \n \n \n \n \n \n静的な  \n  \n気持ちのいい \n \n  \n \n \n \n \n \n \n \n気持ちの悪い \n  \n \n迫⼒のある  \n  \n \n \n \n \n \n \n \n迫⼒のない  \n  \nはっきりした \n \n  \n \n \n \n \n \n \n \nぼんやりした \n \n  \n強い  \n  \n \n \n \n \n \n \n \n弱い \n \n \n \n \n \n \n \n \n45 \n \n \n \n送信 \nフォームをクリア \nGoogle フォームでパスワードを送信しないでください。 \nこのコンテンツは Google が作成または承認したものではありません。 - 利⽤規約 - プライバシー ポリシー \nDoes this form look suspicious? レポート \n好きな \n \n \n \n \n \n \n \n \n \n \n嫌いな \n  \n \nリアリティのある \n \n \n \n \n \n \n \n \n \n \nリアリティのない \n \n  \n興奮した  \n  \n \n \n \n \n \n \n \n落ち着いた  \n  \n良い \n \n \n \n \n \n \n \n \n ",
            "\n  \n \n \n \n \n \n \n \n落ち着いた  \n  \n良い \n \n \n \n \n \n \n \n \n \n \n悪い  \n  \n \n \n \n \n \n付録B\n　SUSに基づいたアンケートフォーム\n46\n \n47 \n  \n  \n \n  \nImmersionFan  に 関 するあなたの 経験 に 基 づいて、 次 の 記述 に 対 する 同意 または 不   \n同意 の レベル を 記⼊ してください   \n  Based on your experience with immersionFan, please indicate your level of  \nagreement or disagreement with the following statements  \nImmersionFan   の ユーザビリティ に 関 する   \nアンケート   \n   に \nイ \nログ   ン   す   る と 作業内容 を 保存 できます。   \n詳細   \n  必須 の 質問 です   \n名前     \n回答 を ⼊⼒   \n \n48  \n  \n \n \n49  \n  \n \n \n50  \n  ",
            "     \n回答 を ⼊⼒   \n \n48  \n  \n \n \n49  \n  \n \n \n50  \n  \n \n 送信  \nフォームをクリア  \nGoogle フォームでパスワードを送信しないでください。  \nこのコンテンツは Google が作成または承認したものではありません。 - 利⽤規約 - プライバシー ポリシー  \nDoes this form look suspicious? レポート \n フォーム  \n  \nポイント  \n強 く 同意 しない   \n  \n  \n  \n  \n  \n強 く 同意 する   \n  ポイント  \n強 く 同意 しない   \n  \n  \n  \n  \n  \n強 く 同意 する   \nこの システム を 使⽤ することに ⾃信 をもっています   \nI am confident in using this system  \n  \nこの システム を 使 い 始 める 前 に 学 ぶべきことがたくさんあると 思 います   \nI thought there was a lot to learn before I started using this syst",
            "as a lot to learn before I started using this system  \n  \nデバイス に 気 づいたこと・ 気 になったことを ⾃由 に 記述 してください   \nPlease feel free to describe what you noticed/concerned about the device  \n回答 を ⼊⼒   \n質疑応答\n戸辺　義人　情報テクノロジー学科　教授\nQ\nどのようにPID 制御を行いましたか．\nA\nサーミスタを用いて温度制御を行いました．PID 制御についてのパラメータは先行\n研究を参考に、限界感度法を用いて決定しました．\n伊藤雄一情報テクノロジー学科教授\nQ\n振動はズレによって影響がありませんか．映像とのズレが気になったという人はい\nませんでしたか．\nA\n映像とのズレが気になったという人はいませんでしたが，リアルタイム性の向上に\nついては今後の課題と考えています．\n伊藤雄一情報テクノロジー学科教授\nQ\n温度変化について，温度の推移過程での視聴の影響はありませんか．\nA\n今回，推移時の視聴における影響は考慮していま",
            "いて，温度の推移過程での視聴の影響はありませんか．\nA\n今回，推移時の視聴における影響は考慮していませんでした．今後の研究で反映し\nます．\n51\nロペズ　ギヨーム情報テクノロジー学科教授\nQ\n目標温度に到達するまでの時間を教えてください．\nA\n5，6 秒ほどで目標温度まで到達します．\n戸辺　義人　情報テクノロジー学科　教授\nQ\n風の刺激が局所的だと没入感に影響は与えないのでしょうか．\nA\n今後，局所的な刺激についての没入感の影響について調べたいと思います．\n伊藤雄一情報テクノロジー学科教授\nQ\n風覚に関する論文は参考にしましたか．風速などについて数値的な参考にしたもの\nがあれば教えてください．\nA\n風覚に関する論文は拝読しましたが，システムに風速などの数値的な反映はできて\nいません．今後の実装の参考にさせていただきます．\n52\n"
        ]
    },
    {
        "id": "paper_7",
        "filename": "B2024_TakatoTanaka_t.pdf",
        "title": "B2024_TakatoTanaka_t",
        "fulltext": "青山学院大学理工学部\n情報テクノロジー学科\n２０２４年度卒業研究論文\n拡張と仮想現実の違いがタスクパ\nフォーマンスに与える影響の比較\n２０２５年１月２８日提出\n指導教員ロペズ・ギヨーム教授\n提出者学生番号　氏名\n１５８２１０５７田中　崇登\n青山学院大学 理工学部 情報テクノロジー学科 \n2024（令和6）年度卒業論文要旨 \n- 1 - \n \n拡張と仮想現実の違いがタスクパフォーマンスに \n与える影響の比較 \n \n田中崇登（15821057） \nロ  ぺ  ズ 研 究 室 \n \n１．はじめに \n拡張現実（AR）技術と仮想現実（VR）技術の市場\n規模は急速に拡大しており，その応用範囲は教育，医\n療，エンターテインメント，製造業など多岐にわたる\n[1]． 特に製造業では，生産性向上やコスト削減を目\n的にXR 技術の導入が進んでおり，MR グラスを活用し\nたシステムを導入し，パネルの組立作業の作業効率を\n向上させた事例が存在する[2]．一方，これら両技術の\n特性やユーザー体験における差異についての比較研究\nは十分に行われていない． \nそこで本研究では，AR およびVR を用いたタスク\n遂行システムを構築し，両技術の性能とユーザー体験\nの差異を比較・評価する． \n２．関連研究 \nVerhulst らは，博物館の体験イベントを題材に，VR\nデバイスとAR デバイスのユーザー体験を比較し，VR\nがAR よりも空間的臨場感や没入感で優位性を示すこ\nとを報告した[3]．また，Hirota らは，VR ヘッドマウ\nントディスプレイと2D ディスプレイを用いた視覚的\n疲労の比較を行い，瞬目回数が視覚的疲労を評価する\n指標として有効である可能性を示した[4]．特に，瞬目\n回数が少ないほど視覚的負荷が高まり，疲労を引き起\nこしやすいことが示唆されており，この指標は視覚的\nストレスやデバイスの影響を測定する上で有用である． \n３．AR・VR を用いたアームロボット操作システム \n本研究では阿部ら[5]がHoloLens2[6]向けに制作・\n開発した「拡張現実とインプットデバイスを用いたア\nームロボットリモートコントロールシステム」（以下\nAR アプリと記載）を元に，Meta Quest 3[7]向けのア\nームロボット操作システムを開発した（以下VR アプ\nリと記載）． \n図1-2 にアプリケーションの全体図を示す．それぞ\nれのアプリでは仮想的に提示されたボタンを操作し，\nロボットアームを動かしてブロックを指定の位置に移\n動させるタスクを遂行する．図3 にタスク実行中の様\n子を示す．  \nさらに，AR およびVR 環境でタスクを実行中の瞬\n目回数をタスクパフォーマンス評価指標の一つとして\n用いるため，HoloLens 2 にはPupil Labs HoloLens \nAdd-on[8]を，Meta Quest 3 にはPupil Labs VR/AR \nEye Tracking Module[9]をそれぞれ装着し，視線情報\nを取得した．本研究では，瞬目回数が視覚的疲労を評\n価する客観的指標として有効であることがHirota ら\nの研究[4]で示されていることから，これをパフォーマ\nンス評価と関連付けて使用する．特に，AR およびVR\nデバイスでの視覚的負荷がタスク遂行能力に与える影\n響を定量的に把握する目的がある． \n \n図 1  AR アプリの全体図 \n \n図 2  VR アプリの全体図 \n \n \n \n図 3  タスク実行中の様子 \n４．各アプリケーションのパフォーマンス比較手順 \nAR 及びVR アプリにて同様のタスクを課し，違い\nを比較し評価した．本研究では各アプリでのタスク実\n行時間と， 実行中の瞬目回数を定量評価指標として用\nいた． \n実験手順として，被験者10 名（男性:8 人， 女性:2\n人）は操作説明を受けた後に5 人はAR， 5 人はVR\nアプリを先に使用する．その後5 分間の休憩をとり，\nもう一方のアプリを使用する． また操作後に操作性， \n視認性を評価するためSUS アンケートと独自に作成\nしたアンケートを実施した． \n５．結果 \n図4 にタスク実行時間の結果を示す．VR アプリに\nてタスクを行った際はAR アプリに比べてタスク完了\n時間が有意に短縮されることが示された（p<0.01）． \nタスク実行中の瞬目回数に関してはAR アプリにて\nタスクを行った際にVR アプリよりも瞬目回数が有意\nに減少することが示された．（p<0.01）． \nまた主観評価に関して，SUS アンケートによるユー\nザビリティ評価では平均値がAR アプリが54.8 点， \nVR アプリが70.8 点であり， VR アプリの方が評価が\n高い結果となった．また，主観評価に関して，独自の\nアンケートの結果では，操作性と視認性でVR がAR\nを上回る一方，UI は両者で同程度の評価となった．こ\nれにより，VR は操作性と視認性で優位性を示すこと\nが確認された． \n \n図 4 各アプリケーションでのタスク完了時間の比較 \n６．まとめ \n本研究では,AR とVR を用いたアームロボット操作\nシステムを構築し,性能を比較評価した.結果,VR はタ\nスク実行時間が短く,ユーザビリティに優れる一方,AR\nは瞬目回数が少ない結果を示した. \n本研究では，評価は1 回のタスク実施に限られ,慣れ\nや習熟度の影響は未検討である.今後は長期的評価や\n他システムへの適用を通じ,より直感的で効率的な設\n計を目指す. \n参考文献 \n[1] \nFujitsu : その課題，情くんにおまかせ！第10 話， \nhttps://jp.fujitsu.com/platform/server/advanta\nges/special/jokun/10-ar/ （2025/1/24 参照） \n[2] \n三菱重工技報 Vol.59 No．3: MR グラス活用によ\nる現場作業効率化， \nhttps://www.mhi.co.jp/technology/review/pdf/5\n93/593090.pdf （2025/1/24 参照） \n[3] \nI.Verhulst，A.Woods， L.Whittaker， J.Bennett， \nP.Dalton:Do VR and AR versions of an \nimmersive \ncultural \nexperience \nengender \ndifferent user experiences?,  Computers in \nHuman Behavior 125． \nhttps://www.sciencedirect.com/science/article/p\nii/S0747563221002740?ref=cra_js_challenge&f\nr=RR-1 \n[4] \nM. Hirota， H. Kanda， T. Endo， T. Miyoshi， \nS. Miyagawa， Y. Hirohara， T. Yamaguchi， \nM.Saika，T.Morimoto，T. Fujikado:Comparison \nof visual fatigue caused by head-mounted \ndisplay for virtual reality and two-dimensional \ndisplay \nusing \nobjective \nand \nsubjective \nevaluation． \nhttps://www.tandfonline.com/doi/epdf/10.1080/\n00140139.2019.1582805?needAccess=true \n[5] \nH.Abe， V. Blanco Bataller， H.Terävä， M． \nLuimula， G．Lopez， \"Combining AR and ball-\nshape input interface to control remotely a \nrobot-arm，\" AHFE Open Access， vol 121 \n（2024）． doi:10.54941/ahfe1004628  \n[6] \nHoloLens2， Microsoft 社．  \nhttps://www.microsoft.com/ja-jp/d/hololens-\n2/91pnzzznzwcp?activetab=pivot:%E6%A6%82\n%E8%A6%81tab \n[7] \nMeta Quest3．Meta 社 ， \nhttps://www.meta.com/jp/quest/quest-3/\n（2025/1/24 参照） \n[8] \nHololens and BT300 eye tracking add-ons．\nPupilLabs 社 ， \nhttps://pupil-labs.com/blog/hololens-bt300-\naddon（2025/1/24 参照） \n[9] \nEye tracking for mixed reality．PupilLabs 社 ， \nhttps://pupil-labs.com/products/vr-ar\n（2025/1/24 参照） \n目次\n第1 章\n序章\n1\n1.1\n研究背景. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n1\n1.1.1\n拡張現実・仮想空間技術の現状. . . . . . . . . . . . . . . . . . . .\n1\n1.1.2\n拡張現実技術と仮想空間技術の差別化\n. . . . . . . . . . . . . . . .\n2\n1.1.3\n製造業におけるXR 技術の活用. . . . . . . . . . . . . . . . . . . .\n3\n1.2\n研究目的. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n4\n1.3\n本論文の構成. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n5\n第2 章\n拡張現実・仮想空間に関する研究\n6\n2.1\nAR・VR に関する研究. . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n6\n2.1.1\n製造業でのXR 研究\n. . . . . . . . . . . . . . . . . . . . . . . . . .\n6\n2.1.2\n医療分野でのXR 研究. . . . . . . . . . . . . . . . . . . . . . . . .\n8\n2.1.3\n教育分野でのXR 研究. . . . . . . . . . . . . . . . . . . . . . . . .\n9\n2.1.4\nエンタメ分野でのXR 研究. . . . . . . . . . . . . . . . . . . . . . .\n9\n2.2\n視覚的負荷に関する研究. . . . . . . . . . . . . . . . . . . . . . . . . . . .\n10\n2.3\nAR/VR の比較に関する研究. . . . . . . . . . . . . . . . . . . . . . . . . .\n11\n2.4\n先行研究のまとめ. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n11\n第3 章\n拡張現実・仮想空間技術を用いたアームロボット操作システム\n12\n3.1\nシステム概要. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n12\n3.2\nアプリケーションのタスク内容. . . . . . . . . . . . . . . . . . . . . . . .\n14\n3.3\n使用デバイス. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n15\n3.3.1\nAR デバイス\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n15\n3.3.2\nVR デバイス\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n16\n3.3.3\nAR デバイスに装着する視線情報取得デバイス. . . . . . . . . . . .\n16\n3.3.4\nVR デバイスに装着する視線情報取得デバイス. . . . . . . . . . . .\n17\n3.4\nソフトウェア開発. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n20\n3.4.1\nアプリケーション開発. . . . . . . . . . . . . . . . . . . . . . . . .\n20\n3.4.2\nAR アプリケーション開発. . . . . . . . . . . . . . . . . . . . . . .\n20\ni\n3.4.3\nVR アプリケーション開発. . . . . . . . . . . . . . . . . . . . . . .\n21\n第4 章\nユーザ評価実験\n22\n4.1\n実験目的. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n22\n4.2\n実験環境. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n22\n4.3\n実験方法. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n22\n4.4\n評価方法. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n24\n4.4.1\n定量評価指標. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n24\n4.4.2\n主観的な評価の指標\n. . . . . . . . . . . . . . . . . . . . . . . . . .\n24\n第5 章\n実験結果及び考察\n26\n5.1\n定量評価の実験結果及び考察\n. . . . . . . . . . . . . . . . . . . . . . . . .\n26\n5.2\n主観的な操作のしやすさの実験結果と考察. . . . . . . . . . . . . . . . . .\n28\n第6 章\n結論と今後の展望\n34\n6.1\n結論. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n34\n6.2\n今後の展望\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n35\n謝辞\n36\n参考文献\n37\nii\n第1章\n序章\n本章では，本研究における研究背景，目的および本論文の構成について述べる．\n1.1\n研究背景\n1.1.1\n拡張現実・仮想空間技術の現状\n拡張現実（AR）とはユーザが見ている現実のシーンにコンピュータグラフィックスに\nよって描かれた仮想物体を重畳表示することで，ユーザがいる場所に応じた情報を直感的\nに提示する技術である[1]．\n近年，拡張現実技術の市場規模は拡大し続けている. 図1-1 で示すように，2020 年の調\n査によると，2020 年のAR スマートグラス，MR スマートグラスの世界での市場規模は\n441 億円の見込みであるが，2030 年にはその規模は13 兆9500 億円であると予測されて\nおり，この数字は2020 年の市場規模の約320 倍である[2]．なお，AR スマートグラス・\nMR スマートグラスとは肉眼に見える視界にデジタル情報を重ねて表示する機能を持つデ\nジタルデバイスである．\n図1-1: スマートグラスの世界市場（[2] より引用）\n1\n仮想空間（VR）とは，CG で作られた世界や360 度動画等の実写映像を「あたかもその\n場所に居るかのような没入感」で味わうことができる技術である[3]．拡張現実技術と同\n様に，仮想空間技術の市場規模は拡大し続けている．図1-2 で示すように，2020 年の調査\nでは，仮想空間技術を利用する際に使用するデバイスであるヘッドマウントディスプレイ\nの世界での市場規模は，2020 年では1914 億円の見込みであるが，2030 年には1 兆3272\n億円に上ると予測されている[2]．\n図1-2: スマートグラスの世界市場（[2] より引用）\n上記のように拡張現実・仮想空間技術の市場規模が急速に成長しており，これらの技\n術はこれからの私たちの生活や産業においてますます重要な役割を果たすことを示して\nいる．\n1.1.2\n拡張現実技術と仮想空間技術の差別化\nクロスリアリティ（XR）技術とは拡張現実（AR），仮想空間（VR），複合現実（MR）\nなど現実世界と仮想世界の組み合わせで新たな体験を生み出す技術の総称である．仮想空\n間（VR）と拡張現実（AR）は，現実世界を拡張または仮想化する技術として，教育，エ\nンターテインメント，文化遺産保護，医療，産業など多岐にわたる分野で応用が進展して\nいる．これらの技術はユーザー体験に与える影響が異なるとされており，その違いを明確\nにする研究が注目されている．しかし，これら二つの技術はしばしば混同されることがあ\nり，両者の差異に言及した研究は依然として限られている．Verhulst ら（2021）は，ロン\nドンのナショナル・ギャラリーにおける「バーチャル・ヴェロネーゼ」体験を題材に，VR\n2\nデバイス（Oculus Quest）とAR デバイス（Magic Leap およびMira Prism）のユーザー体\n験を比較した[4]．この研究では，臨場感，楽しさ，認知的および感情的関与，行動的関\n与が評価され，VR は空間的な臨場感や「その場にいる」感覚がAR よりも高いという結\n果が得られた．これらの知見は，デバイスの特性が提供される体験の質に影響を与えるこ\nとを示している．しかし，同一のタスクやプロジェクトを実行する際，これらの技術が具\n体的にどのような差異を生じさせるのかについては，依然として明らかにされていない点\nが多い．\n1.1.3\n製造業におけるXR 技術の活用\nXR 技術はエンターテイメント業界での利用が注目されがちであるが，製造業において\nも金銭コストの削減，生産性の向上を目的とした導入事例が数多くある．富士通は工場の\n保守点検業務において点検ノウハウを紙からタブレットを用いたAR システムに変更する\nことで作業内容が映像と音声で指示できるようになり作業品質が向上した[5]．鋼管製造\nを行うテナリス社は保守作業の効率化と人的ミスの削減のため端末で点検が必要な場所を\nアイコンで表示するAR システムを導入している[6]．三菱重工株式会社では，航空機胴\n体パネルの組立て作業において，作業効率の向上を目的として作業者が装着するヘッドマ\nウント型MR グラスに，実物に対して取付け後の部品を含む3D モデル及び，作業箇所に\nリベットの位置や種類，工作情報などを重ね合わせ表示するシステムを導入した[7]．図\n1-3 に実際にヘッドマウント型ディスプレイを使用している様子を示す．\n3\n図1-3: ヘッドマウント型ディスプレイ使用時の様子（[7] より引用）\n以上のように今日製造業の様々な現場でMR 技術が活用され，生産性や効率の向上に寄\n与するとともにコスト削減にも寄与している．\n1.2\n研究目的\n1.1 節で述べたように，拡張現実（AR）技術とバーチャル・リアリティ（VR）技術の\n市場規模は急速に拡大しており，その応用範囲は教育，医療，エンターテインメント，製\n造業など多岐にわたる．一方で，これらの技術が特定のタスク遂行においてどのような影\n響を与えるかについての体系的な検討は十分に行われておらず，最適な環境設定に関する\n指針も確立されていない．そこで本研究では，AR/VR 環境における負荷軽減と操作性向\n上を両立するシステムを開発・提案することを目的とする．この目的を達成するために，\n以下の2 つの目標を設定する．\n• AR およびVR 環境で実施可能なタスクを提案し，AR 及びVR 環境における適切な\nタスク設計とシステム構築の指針を示す\n• AR 及びVR 環境における操作性および視覚的負荷の違いを明確にする\n4\n1.3\n本論文の構成\n第1 章では，本論文の研究背景，研究目的，及び本論文の構成について述べた．第2 章\nでは，関連研究について説明する．第3 章では，システムの概要について説明する．第\n4 章では，実験方法について説明する．第5 章では，実験結果と考察について説明する．\n第6 章では，本論文の結論と今後の展望について述べる．\n5\n第2章\n拡張現実・仮想空間に関する研究\n本章では，AR・VR に関する研究について述べる．2.1 節ではAR・VR を用いたシステ\nム開発，2.2 節では視覚的負荷に関する研究，2.3 節ではVR とAR の比較に関するに関す\nる研究について述べる．\n2.1\nAR・VR に関する研究\nVR・AR は製造業，教育，医療，エンタメ分野など様々な分野で開発，導入されている．\n2.1.1\n製造業でのXR 研究\nRom´an-Ib´a˜nez ら（2018）は，低コストで没入型のVR システムを開発し，ロボットアー\nム操作の教育における有効性を検証した．この研究では，シミュレーション環境を活用\nすることで，ロボットアームの高コストや安全性の課題を解決し，学生がロボティクス\nの実践的な知識を習得するための効果的な学習ツールとしてVR を提示している．また，\nシミュレーターに組み込まれた衝突検知やトラジェクトリ計画などの高度な機能により，\n実際の産業環境を模擬することが可能となり，教育現場での実用性が評価された．本研究\nは，VR 技術が持つ教育的可能性を示すとともに，タスク遂行における没入型技術の活用\nを検討する上での基盤を提供している[8]．図2-1 にRom´an-Ib´a˜nez らの提案するシステム\n使用時の様子を示す．\n図2-1: 実際のロボットと仮想空間上でのロボット（[8] より引用）\n6\nP´erez ら（2019）は，VR 技術を活用した人間とロボットの協調的なインターフェース\nを提案し，トレーニング，シミュレーション，そしてロボット制御を一体化した新たなア\nプローチを示した．この研究では，VR による没入型のトレーニング環境が，学習プロセ\nスの効率を高め，安全性を向上させることを実証している．さらに，VR 技術を活用する\nことで，ロボットプログラムの事前検証やエラー検出が可能となり，工場環境でのリスク\n軽減とコスト削減を実現した[9]．図2-2，2-3 にP´erez らの提案するシステムで使用する\n実際のロボットと仮想空間上のインターフェースの様子を示す．\n図2-2: 実際のロボット（[9] より引用）\n図2-3: 仮想空間上のインターフェース（[9] より引用）\nHashimoto ら（2011）は，拡張現実（AR）技術を活用したロボットのリモート操作シ\nステム「TouchMe」を提案し，その有効性を検証した．このシステムでは，カメラを通じ\nた三人称視点の画像に仮想ロボットモデルを重ね合わせ，タッチスクリーン上で直感的な\n操作を可能にしている．特に，タッチ操作によるロボットの各部の直接的な操作が可能で\nあり，従来のジョイスティック操作のような高度な訓練が不要であることが特徴である．\n7\n研究では，操作スケジューリングの異なる3 つの手法を比較し，ユーザーの操作性や効率\n性を評価した．さらに，このシステムが初心者にも使いやすいことを示し，製造業などの\n産業分野におけるロボット操作の効率向上に寄与する可能性を提案している．本研究は，\nAR 技術を用いた直感的なロボット操作の基盤を提供し，さらなる応用の可能性を広げて\nいる[10]．\nMakhataeva ら（2020）は，2015 年から2019 年の5 年間における拡張現実（AR）技術\nを用いたロボット工学の研究をレビューし，医療ロボット，動作計画と制御，人間とロ\nボットの相互作用（HRI），および群ロボットシステムの4 つのカテゴリに分類して分析\nを行った．この研究は，AR がロボット工学において如何に統合され，各分野にどのよう\nな改善をもたらしたかを詳細に探究している．また，AR がカメラのローカリゼーション\nや環境マッピングの課題に直面しつつも，効率性やヒューマン・マシン・インタラクショ\nンを大幅に向上させる可能性を示している．このレビューは，産業界を含むさまざまな分\n野でAR 技術がいかに適用される可能性があるかの基盤を提供しており，今後の研究方向\n性も示唆している[11]．\nBambuˇsek ら（2021）は，空間拡張現実（ISAR）とヘッドマウントディスプレイ（HMD）\nを組み合わせた手法による協働ロボットのエンドユーザープログラミングを提案した．本\n研究では，HMD とタッチテーブルを活用し，従来のキネステティック・ティーチングと比\n較して，作業負担の軽減とプログラミング速度の向上を目指した．20 名の被験者による\n評価実験では，タスク遂行の効率性とユーザー体験（UX）がそれぞれ33.84 ％，28.46 ％\n向上し，ロボット不在時のプログラミングが可能となる利点も示された．本研究は，ISAR\nとHMD の統合が協働ロボットの操作性向上に寄与することを示唆している[12]．\n2.1.2\n医療分野でのXR 研究\nElendu ら（2024）は，シミュレーションベースのトレーニング（SBT）の医療教育にお\nける重要性をレビューし，その進化と利点を概説した．本研究では，初期の訓練ツールか\nら高精度シミュレーターやバーチャルリアリティ（VR）環境への進展が詳述され，安全\nな環境下で技術的および非技術的スキルを練習できることや即時フィードバックを通じた\n学習者の能力向上の効果が示された．一方で，導入コストの高さや教員への専門的トレー\nニングの必要性，現実の臨床環境との相違といった課題も指摘されている．さらに，人工\n知能（AI）やVR 技術の進展がSBT のさらなる発展に寄与する可能性が論じられ，SBT\nが医療教育において不可欠なツールであると結論付けられた[13]．\n志賀ら（2020）は，複合現実（MR），拡張現実（AR），仮想空間（VR）技術をロボッ\nト支援腎部分切除術（RAPN）に応用し，その有用性を検討した．本研究では，術前患者\n画像を3D ホログラム化し，HoloLens を用いて手術中に活用した結果，腫瘍切除時間の短\n8\n縮や出血量の低減に寄与したことが示された．さらに，空間認識の向上や術者目線での手\n術記録を通じた教育効果も確認された．本研究は，MR およびVR 技術が手術支援や教育\nにおいて有用なツールであることを示し，これらの技術が医療分野におけるさらなる発展\nを促す可能性を強調している[14]．\n2.1.3\n教育分野でのXR 研究\n山元（2019）は，AR（拡張現実）とVR（仮想空間）の教育・学習支援への活用事例と\n課題を検討した．AR は現実環境に仮想情報を重ねることで認知負荷を軽減し，直感的な\n学習を支援する一方，VR は没入型環境を提供し，身体活動を伴う学習を可能にする利点\nが示された．しかし，導入にはコストや教員の専門知識不足が課題とされている．本研究\nは，AR/VR 独自の学習支援の可能性を探る重要性を強調している[15]．\n渡邉ら（2022）は，Mozilla Hubs を活用したVR 外国語教育の実践を報告し，学習者が\n体験的に学ぶことで中国語の定着を促進する効果を示した．VR 空間内での声調練習や対\n話型タスクにより，学習の動機づけと理解が向上し，オンライン授業の柔軟性も評価され\nた．今後は長期的な学習効果の検証が課題とされている[16]．\n2.1.4\nエンタメ分野でのXR 研究\nKohenら（2021）は，Microsoft HoloLens 2を活用した拡張現実（AR）格闘ゲーム「HoloFight」\nを開発し，マルチプレイヤー型の没入体験を提供するシステムを提案した．本ゲームは，\nXbox コントローラーやHoloLens の空間認識機能を組み合わせることで，物理環境との\n連動や自然なキャラクター操作を可能にしている．また，プレイヤーが同一空間にいる場\n合の視点の自動調整機能や，異なる空間間で対戦できるリモートモードも搭載し，安全で\n柔軟なゲーム体験を実現している[17]．本研究は，AR 技術と従来型ゲームの要素を融合\nし，エンターテインメントの新たな可能性を探るとともに，COVID-19 パンデミック下で\nの安全な娯楽の提供を目指している．今後は，アバターの動作拡張や視線追跡機能の活用\nを進め，さらなる没入感を提供する予定である．\nHackl とAnthes（2021）は，拡張現実（AR）を活用したピアノ学習アプリケーション\n「HoloKeys」を開発し，その設計と実装を報告した．HoloKeys は，ヘッドマウントディス\nプレイ（HMD）を使用して，物理的なピアノの鍵盤に重ねて演奏すべきキーを表示する\nシステムであり，MIDI ファイルを利用して音楽データを動的に処理する[18]．\nこのアプリケーションは，ユーザーの位置をトラッキングし，適切に補強情報を表示す\nる機能を備える．また，リアルタイムの視覚的ガイドと音声出力を提供し，初心者でも効\n率的に楽曲を学習できるよう設計されている．さらに，ゲーム要素を取り入れることで学\n9\n習意欲を高める可能性が指摘されている．本研究は，AR 技術が音楽教育に与える可能性\nを示す一例であり，将来的にはより広範な楽器学習への応用が期待されている．\n2.2\n視覚的負荷に関する研究\nPavel ら（2023）は，コンピュータ視覚症候群（CVS），別名デジタル眼精疲労（DES）\nについて，デジタルデバイスの長時間使用に起因する眼科的，筋骨格系，および行動上の\n症状を引き起こす現代の病態として検討した．本論文では，CVS の主な環境的，眼科的，\n筋骨格系の原因をレビューし，デジタルデバイスの使用頻度の増加とDES の高い有病率\nを考慮し，眼科医が質の高い研究に基づいた助言と管理オプションを提供することの重要\n性を強調している[19]．\nKaur ら（2022）は，デジタル眼精疲労（DES）の症状，原因，管理戦略を包括的にレ\nビューした．長時間のデジタルデバイス使用が乾燥感，かゆみ，頭痛，視力のぼやけなど\nを引き起こし，特にCOVID-19 パンデミック中に発生率が増加したと報告されている．管\n理には，エルゴノミクスの改善，20-20-20 ルールの実践，ブルーライトフィルターやアン\nチリフレクティブ眼鏡の使用が有効とされる．本研究は，DES の理解を深め，効果的な\n対策の開発を促進する重要性を示した[20]．\n伊藤ら（2020）は，スマートグラス（SG），液晶ディスプレイ（LCD），および印刷物\n（Paper）を用いた作業における眼精疲労の程度を比較検討した．77 名の学生および教員を\n対象に，それぞれの方法で1 時間の作業負荷を与え，フリッカー値，瞬き回数，調節微小\n振動の高周波成分（HFC），脈拍数，主観的疲労感を測定した．結果として，SG 使用時は\nLCD や印刷物に比べて瞬き回数の減少が少なく，眼精疲労が軽減される傾向が見られた．\nまた，主観的評価では，LCD や印刷物と比べ，SG の使用による疲労感は少なかった．こ\nれにより，SG を用いたハンズフリーマニュアル（HF マニュアル）は，作業中の眼精疲労\nが問題とならないことが示唆された[21]．\nHirota ら（2019）は，VR ヘッドマウントディスプレイ（VR-HMD）と2D ディスプレ\nイの視覚疲労への影響を比較評価した．視覚タスク後，両デバイスで双眼融合維持能力\n（BFM）の低下と主観的な眼症状スコアの増加が見られたが，有意差は認められなかった．\n本研究は，低い視覚誘発運動病（VIMS）を伴うVR コンテンツ使用時，VR-HMD の視覚\n疲労が2D ディスプレイと同程度であることを示唆している[22]．\nSouchet ら（2022）は，VR ヘッドマウントディスプレイ（VR-HMD）を用いた学習に\nおける視覚疲労と認知負荷を眼球運動計測で評価する方法をレビューした．視覚疲労は\n瞬目頻度，認知負荷は瞳孔径の変化で測定されるが，両者の区別は課題であることが示さ\nれた．一方で，眼球運動計測は学習中のリアルタイム評価に有望であり，より精度の高い\n10\nデータ解釈モデルの開発が必要である．本研究は，VR 学習の効率向上と技術設計におけ\nる重要な基盤を提供している[23]．\nWang ら（2023）は，AR メガネを用いた2D および3D 視聴が視覚疲労と眼表面に与え\nる影響を比較した．1 時間の視聴後，視覚疲労は両モードで増加したが，2D 視聴後に脂\n質層厚（LLT）や瞬き頻度がより顕著に増加．一方，涙液破壊時間（NIBUT）や涙液メニ\nスカス高（TMH）には有意差はなかった．本研究は，AR メガネ視聴による視覚負荷を評\n価し，特に3D コンテンツが視覚的負荷を高める可能性を示唆している[24]．\n2.3\nAR/VR の比較に関する研究\nSouchet ら（2021）は，VR およびAR を用いた没入型文化体験がユーザーエクスペリエ\nンスに与える影響を比較した．VR は高い没入感と感情的関与を促進し，AR は現実世界\nとの統合による直感的な操作性が評価された．ユーザーの満足度や学習効果の観点でいず\nれも有用であるが，利用目的に応じた技術選択の重要性が示された．本研究は，没入型技\n術の設計や応用における基盤を提供している[4]．\n2.4\n先行研究のまとめ\n従来の研究では，AR/VR 技術が製造業，医療，教育，エンターテインメントなど幅広\nい分野で活用されており，特にロボット操作や協調作業の効率化に寄与することが示され\nている．また，AR/VR の比較研究では，VR が没入感や感情的関与を強化し，AR が現実\n環境との統合による直感的な操作を可能にすることが明らかになっている．しかし，多感\n覚フィードバックを統合した評価や，視覚的負荷を考慮したAR/VR の適用に関する検討\nは十分ではない．そこで本研究では，ロボットアーム操作を題材にAR/VR の操作性や負\n荷の違いを明確にし，最適な環境設定指針を示すことを目的とする．\n11\n第3章\n拡張現実・仮想空間技術を用いたアームロ\nボット操作システム\n3.1\nシステム概要\n本研究で用いた拡張現実を用いたアームロボット操作システムは，阿部らが制作・開発\nした「拡張現実とインプットデバイスを用いたアームロボットリモートコントロールシス\nテム」であった（以下AR アプリケーションと記載）[25]．AR デバイスを装着した状態\nで，ハンドトラッキング機能を用い，仮想的に提示されたボタンを押し，同様に仮想的\nに提示されたアームロボットを操作し，ブロックを指定の位置まで移動させるというタス\nクを行うシステムとなっている．本研究では，AR アプリケーションをVR デバイスで使\n用できるよう移植し，両デバイスにて同様のタスクを行うことでタスク遂行時間，タスク\n中の瞬きの回数，主観評価に差異が生まれるのか比較を行った．そしてタスク中の瞬きの\n回数を取得するため，AR デバイス，VR デバイスにてタスクを行う際，それぞれ異なる\n視線情報取得デバイスを装着した．図3-1 に本システムの概要図を示す．また，図3-2 に\nAR アプリケーションの全体図を示す．\n図3-1: 本システムの概要図\n12\n図3-2: AR アプリケーションの全体図\n尚，AR アプリケーションを実装するデバイスとしてMicrosoft 社のHololens2 を用い\nる[26]．hololens2 は透過型のヘッドマウントディスプレイであり，前面に配置された\nRGB カメラ及び環境認識カメラを用いた高精度なハンドトラッキング機能を有している\nことに加えて別途のコントローラを必要とせずに操作を行うことが可能である点や幅広い\n視野角でユーザが快適かつ正確にホログラムを操作可能である点に優れており本システ\nムに適している．そして本研究では評価指標としてアプリケーションを操作している際の\n瞬きを検出するため，Pupil Labs 社が提供するhololens のadd-on を使用した[27]．また，\n本研究ではVR デバイスで同様のタスクが行えるよう，このAR アプリケーションを元に\nVR デバイスで使用可能なアプリを開発した（以下，VR アプリケーションと記す）．VR\nアプリケーションの基本的なシステムはAR アプリケーションと同様であるが，ボタンを\n押す際の動作はハンドトラッキングではなく，コントローラの操作によって行う．図3-3\nにAR アプリケーションの全体図を示す．尚，VR アプリケーションを実装するデバイス\nとしてMeta 社のMeta Quest 3 は，VR アプリケーションを実装および実行するためのデ\nバイスであり，スタンドアロン型のヘッドセットとして広視野角および精密なトラッキン\nグを搭載することで，直感的な操作とスムーズなユーザー体験を可能にしており，本シス\nテムに適している[28]．そして瞬きを検出するための機器として，Pupil Lab 社が提供す\nるVR 用のadd-on を使用した[29]．図3-3 にVR アプリケーションの全体図を示す．\n13\n図3-3: VR アプリケーションの全体図\n3.2\nアプリケーションのタスク内容\n両アプリケーションでは同様のタスクを行う．アプリケーション内での目標は，ロボッ\nトアームの左側にある青色のブロックを，ロボットアームを操作しブロックをつかんで移\n動させ，緑色のブロックの位置まで移動させることである．このブロックを移動させる動\n作を3 回分行うことで，目標達成となる．アプリケーションを起動後，ユーザはアームロ\nボット，メニューボタン，スタートボタン及びリセットボタンが確認可能である（VR ア\nプリケーションの起動時の画面は図3-3 に示す）．この状態ではアームロボットの操作は\nできず，ボタンを押してもアームロボットは動作しない．この状態からスタートボタン\nを押すことでロボットアームの操作が可能となる．その後，矢印のボタンを押すことで，\nアームロボットを動かすができる．また，リセットボタンによりアームロボットを初期状\n態へ戻すことが可能である．初期状態ではアームロボットをブロックに近づけても掴むこ\nとができないが，「グラブ/リリースボタン」を押すことでブロックを掴むことが可能な状\n態へ移行することができる．そしてもう一度「グラブ/リリースボタン」を押すことでブ\nロックを離すと可能である．タスク実行中の様子を図3-4 に示す．\n14\n図3-4: タスク実行中の様子\n3.3\n使用デバイス\n本節では，このシステムを構成するデバイスの説明について述べる．\n3.3.1\nAR デバイス\n本研究で利用するAR デバイスは，Microsoft 社が開発したHoloLens2 である[26]．図\n3-5 に使用するHoloLens2 を示す．HoloLens 2 は本研究において，AR 環境でのタスク遂\n行システムの実行デバイスとして用いられた．ハンドトラッキング機能を活用し，被験者\nがAR 環境内で自然かつ直感的にタスクを操作することを可能にした．\n図3-5: Microsoft 社が開発した「HoloLens2」（[26] より引用）\n15\n3.3.2\nVR デバイス\n本研究で使用するVR デバイスは，Meta 社が開発した「Meta Quest 3」である[28]．図\n3-6 に使用するMeta Quest 3 を示す．Meta Quest 3 は本研究において，VR 環境でのタス\nク遂行システムの実行デバイスとして使用された．内蔵のセンサーによる高精度な位置\n追跡と，ハンドトラッキング機能を活用し，ユーザーがVR 空間内で直感的にタスクを操\n作できるようになっている．本デバイスは，被験者のVR 体験におけるユーザーインター\nフェースと操作性の評価を行うために重要な役割を果たした．\n図3-6: Meta 社が開発した「Meta Quest 3」（[28] より引用）\n3.3.3\nAR デバイスに装着する視線情報取得デバイス\n本研究では評価指標の一つとして実験中の瞬きの回数を用いるため，AR デバイス，VR\nデバイスにてそれぞれ視線情報取得デバイスを取り付けて使用した．\nAR デバイスとして使用したHoloLens 2 には，Pupil Labs 社が提供する「HoloLens Add-\non」を装着した[27]．図3-7 に使用する「HoloLens Add-on」を示す．HoloLens Add-on は，\nPupil Core ヘッドセットに基づく高精度な視線追跡テクノロジーを搭載しており，左右の\n瞳孔の動きを正確に検出することができる．デバイスはHoloLens に無理なく取り付けら\nれるよう設計されており，ユーザーの視覚体験を妨げることなく動作する．また，視線\nデータはPupil Capture ソフトウェアを通じてリアルタイムで記録および分析され，瞬きや\n視線の移動パターンの詳細な解析が可能となる．なおこのデバイスは初代HoloLens [30]\nに対応するデバイスとして設計されているが，HoloLens2 には直接取り付けることができ\nないため，マスキングテープを用いて装着・固定化した（図3-7）\n16\n図3-7: HoloLens 用のアイトラッキング\nアドオン（[27] より引用）\n図3-8: 視線情報取得デバイスを装着し\nたHololens2\nしかし，この装着方法ではデバイスの安定性が十分ではなく，視線追跡の精度が低下し\nたため，瞬きや視線の移動パターンをリアルタイムで正確に取得することができなかった．\nそのため，Pupil Capture ソフトウェアを用いて実験中の目元の映像を録画し，後処理と\nして映像を手動で解析する方法を採用した．具体的には，録画された映像を確認し，被験\n者の瞬きの回数を目視でカウントした．このプロセスにより，リアルタイムで取得できな\nかったデータを補完し，瞬き回数に関する定量的な情報を得ることができた．図3-9 に実\n験中に収録した目元の映像の一例を示す．\n図3-9: HoloLens Add-on で収録した目元の映像\n3.3.4\nVR デバイスに装着する視線情報取得デバイス\nVR デバイスとして使用したMeta Quest3 には，Pupil Labs 社が開発した「Pupil Labs\nVR/AR Eye Tracking Module」を使用した[29]．図3-10 に使用する「Pupil Labs VR/AR\nEye Tracking Module」を示す．このデバイスは，VR ヘッドセットに統合可能な高精度の\n17\n視線追跡システムであり，被験者の瞬きや視線移動をリアルタイムで記録・分析すること\nが可能である．本研究では，Meta Quest 3 にこのデバイスを装着し，VR 環境内でのタス\nク遂行中の視線情報を収集しVR 環境下での瞬きの頻度の定量的解析に活用された．\n図3-10: Pupil Labs VR/AR Eye Tracking Module（[29] より引用）\nPupil Labs VR/AR Eye Tracking Module は，視線情報をリアルタイムで確認および保存\nするための包括的なエコシステムを提供している．このデバイスは，Neon Companion と\n呼ばれるスマートフォンアプリ（図3-11）と連携して動作する[31]．有線接続を通じて，\n視線データをリアルタイムでアプリ上に表示することが可能であり，被験者の視線移動や\n瞬きの状況をその場で確認することができる．\nNeon Companion には録画機能が備わっており，収録された映像データは自動的にPupil\nLabs が提供するPupil Cloud というクラウドプラットフォームにアップロードされる．こ\nのクラウドプラットフォーム（図3-12）では，録画された映像に基づく詳細な視線データ\nの解析が可能である[32]．瞬きの回数や視線移動のパターンといった定量的な情報も提\n供されるため，これらのデータを後処理で解析することにより，被験者がVR アプリケー\nションを操作している間の瞬き頻度を正確に評価することができた．\n18\n図3-11:\nスマホアプリ\n「Neon Companion」\n（[31]\nより引用）\n図3-12: Pupil Cloud のWEB ページ\n図3-13: 通信のフローチャート\n19\n本研究では，この機能を活用してMeta Quest 3 上でタスク遂行中の被験者の瞬きの回数\nを測定し，収集したデータを解析した．これにより，VR 環境下での瞬き頻度を定量的に\n評価するための信頼性の高いデータセットを構築することが可能となった．\n3.4\nソフトウェア開発\n3.4.1\nアプリケーション開発\n本節ではアプリケーション開発に用いたソフトウェアについて述べる．本研究ではクロ\nスプラットフォームのゲームエンジンであるUnity を使用してアプリケーションを開発し\nた．Unity は，高度なリアルタイムレンダリング機能を備え，多様なデバイスに対応する\nための柔軟な開発環境を提供する[33]．特に，HoloLens 2（AR）やMeta Quest 3（VR）\nといった異なるプラットフォーム上でアプリケーションを開発・実行できる点は，本研究\nの目的に非常に適している．また，Unity は基本機能を無料で利用可能であり，高性能な\nアプリケーションをコストを抑えて開発できるという利点もある．本研究のアプリケー\nション開発においては，以下の機能を実現するためにUnity を活用した．\n1. 視覚的ユーザーインターフェースの設計\n• 被験者が直感的に操作できるよう，タスク遂行中に必要な指示やフィードバッ\nクを表示するUI を設計した\n2. 実験シナリオの構築\n• AR およびVR 環境それぞれにおけるタスクシミュレーションを構築し，実験条\n件を再現可能な形で設定した\nAR アプリケーションは，HoloLens 2 上でロボットアームの操作を行うための機能を中\n心に設計されており，VR アプリケーションはMeta Quest 3 において同様の操作環境を再\n現する形で構築された．\n3.4.2\nAR アプリケーション開発\nAR アプリケーションの開発においては，Unity で使用可能なMicrosoft 社が提供する\nMixed Reality Toolkit（MRTK）を利用した[34]．MRTK は，HoloLens 2 をはじめとする\nMixed Reality デバイス向けに最適化された開発ツールキットであり，直感的なUI の設計\nやインタラクションの実装を効率的に行うことができる．本研究では，ロボットアーム\nを操作するためのボタンをMRTK の標準コンポーネントを用いて実装した．このボタン\nは，ハンドトラッキングを活用して被験者が自然な操作でタスクを遂行できるよう設計さ\n20\nれている．AR アプリケーションではユーザーはボタンを押すことでアームロボットを動\nかすことができるが，その手法は現在一般的に広く用いられているアームロボットのヘッ\nドの位置姿勢及びグリッパーの開閉をそれぞれ方向ボタン，グリッパー開閉ボタンを用い\nて決定し各関節角を逆運動を用いて決定することで操作する手法である．\n3.4.3\nVR アプリケーション開発\nVR アプリケーションの開発ではMRTK を使用せず，Meta Quest 3 に最適化された独自\nのアプローチを採用した．具体的には，Oculus Integration パッケージを用いてMeta Quest\nデバイスにおける操作やインタラクションを実現した．このパッケージは，Meta Quest\n向けの開発を効率化するためのツール群を提供しており，ハンドトラッキングやコント\nローラー操作の実装に利用された．ユーザーインターフェース（UI）の構築に際しては，\nCanvas システムを使用し，VR 環境内で視覚的に認識しやすい3D ボタンを作成した．こ\nれらのUI 要素は，被験者がコントローラーを通じて直感的に操作できるよう配置され，操\n作性を考慮したデザインとなっている．また，UI の配置やサイズ調整については，視覚的\nな快適性を確保するために，Meta Quest 3 の視野角や解像度に基づいて最適化を行った．\n21\n第4章\nユーザ評価実験\n4.1\n実験目的\n本章では，本研究で提案するシステムの有効性を検証するために実施したユーザ評価実\n験について述べる．ユーザ評価実験は，提案システムの操作性およびユーザー体験を定量\n的かつ定性的に評価することを目的として行われた．本実験では，従来手法と提案システ\nムを比較し，タスク遂行における効率性，正確性，直感的な操作性の向上を検証する．さ\nらに，実験中に得られた視線データを解析することで，認知的負荷やユーザーの主観的評\n価との関連性についても調査する．\n4.2\n実験環境\n本実験では，使用するデバイスの特性が実験結果に与える影響を最小限に抑えるため，\n実験環境を慎重に設計した．特に，HoloLens 2 はシースルー型のヘッドマウントディスプ\nレイ（HMD）であり，現実世界の視界とデジタル情報を同時に提示する機能を持つ．こ\nの特性により，外部環境の違いが被験者の視覚的注意やタスク遂行に影響を与える可能\n性がある．そのため，本研究では外部環境の影響を排除するため，実験を行う部屋を固定\nし，すべての被験者が同一の環境で実験を行うようにした．被験者の向きも統一し，視界\nに壁のみが入るよう配置を調整することで，外部刺激を最小限に抑えた．また，部屋の照\n明や配置物も統一し，環境条件が一貫するよう配慮した．VR デバイスを使用した実験に\nついても，同様の環境条件下で実施した．VR デバイスであるMeta Quest 3 は，完全に仮\n想空間内での体験を提供するため，被験者が外部環境を視覚的に認識することはない．し\nかし，外部環境の変化が被験者の心理的状態や実験中の集中度に影響を与える可能性を排\n除するため，HoloLens 2 の実験と同じ固定された部屋で行い，実験条件の一貫性を確保し\nた．被験者は20 代の男女10 名であり，AR アプリケーションシステムとVR アプリケー\nションシステムの比較実験を行った．\n4.3\n実験方法\n本研究では，提案するAR アプリケーションシステムおよびVR アプリケーションシス\nテムの操作性やユーザー体験を評価するため，被験者にそれぞれのシステムを一度ずつ\n22\n体験してもらう形式で実験を実施した．各被験者は，AR アプリケーションシステムおよ\nびVR アプリケーションシステムを使用してタスクを遂行した．2 つのシステム間の体験\nが連続すると，被験者の疲労や集中力の低下がタスク遂行に影響を与える可能性がある\nため，各システムの体験の間に5 分間の休憩を設けた．また，どちらのシステムを先に使\n用するかによって，被験者がシステム操作に慣れてしまうことでタスク遂行時間に偏り\nが生じる可能性を考慮した．この影響を排除するため，被験者10 人を2 つのグループに\n分け，5 人にはAR アプリケーションを先に体験してもらい，残りの5 人にはVR アプリ\nケーションを先に体験してもらうようランダムに割り当てた．これにより，両システムの\nタスク遂行における公平な比較が可能となり，システム間の特性や操作性に関する偏りの\nないデータを取得することを目指した．図4-1 に実験の手順を示す．\n図4-1: 実験の手順を示すフロー図\n本実験で被験者に与えられたタスクは，アプリケーション内で3 つのブロックをそれぞ\nれ指定された位置まで移動させる作業である．このタスクは，AR およびVR アプリケー\nションを使用して行われ，ロボットアームを操作することでブロックを掴み，指定された\n位置に正確に配置することを求められる．被験者は，まずアプリケーション内でブロッ\nクが配置されている初期位置を確認した後，ロボットアームを操作してブロックを掴む．\n次に，指示された目標位置までロボットアームを動かし，ブロックを所定の位置に配置す\nる．この手順を3 つのブロックそれぞれに対して繰り返し，全てのブロックを正確に配置\n23\nすることがタスク完了の条件となる．このタスクは，ロボットアーム操作における正確\n性，効率性，および直感的な操作性を評価する目的で設計されており，AR およびVR シ\nステムの比較を可能にするよう構築されている．\n4.4\n評価方法\n4.4.1\n定量評価指標\n本研究では，AR およびVR アプリケーションの操作性やユーザー体験を評価するため\nに，定量評価指標としてタスク実行時間とタスク実行中の1 分当たりの瞬目回数を用い\nた．タスク実行時間は，被験者がアプリケーション内で3 つのブロックを全て指定の位置\nに正確に配置するまでに要した時間として計測された．瞬目回数は，タスク実行中にお\nける瞬目の総回数を測定し，1 分間あたりの平均回数として算出された．タスク実行時間\nは，ボットアームを正確かつ効率的に操作できたかという操作性と，ボタンが押しやす\nくUI が操作に適しているかというインターフェースの使いやすさの2 点の観点でアプリ\nケーションの性能を測定するために選定した．タスク実行中の1 分当たりの瞬目回数は，\nAR およびVR デバイスを使用する際の視覚的負荷を測定するために選定した．\n4.4.2\n主観的な評価の指標\n被験者がAR およびVR アプリケーションを使用した際の主観的な操作のしやすさを評\n価するために，System Usability Scale（SUS）を用いた[35]．SUS は，システム全体の使\nいやすさを評価するための信頼性が高く広く使用されている10 項目のアンケート形式の\n評価指標である．被験者には，それぞれのアプリケーションを体験した後に，SUS アン\nケートに回答してもらった．アンケート項目は，システムが簡単に使えたか，必要な機能\nが適切に提供されていたか，また使用中に困難を感じたかといった視点に基づいており，\n5 段階のリッカート尺度で評価された．各回答はスコアとして集計され，0 から100 の範\n囲で使いやすさを定量的に測定するSUS におけるスコアの基準を表4-1 に示す．\nこれに加え，主観的にアームロボットの操作が容易かつ意図した通りに行えたか，文字\nやオブジェクトが見やすかったかという視認性及びUI を評価するため独自に作成したア\nンケートを用いた．\n24\n表4-1: SUS におけるスコアと評価の対応\nSUS score\nGrade\nAdjective Rating\n>80.3\nA\nExcellent\n68 - 80.3\nB\nGood\n68\nC\nOkay\n51 - 68\nD\nPoor\n<51\nE\nAwful\n25\n第5章\n実験結果及び考察\n5.1\n定量評価の実験結果及び考察\n図5-1 にAR アプリケーション及びVR アプリケーションでのタスク完了時間の比較を\n示す．エラーバーは標準誤差を示す．AR アプリケーションとVR アプリケーションのタ\nスク完了時間を比較した結果，VR アプリケーションにてタスクを行った際はAR アプリ\nケーションに比べてタスク完了時間が短縮されることが示され，二つの手法間のタスク完\n了時間には有意差が見られた．VR アプリケーションでの操作は，コントローラを動かし\nポインタをボタンの位置に合わせて，コントローラのボタンを押すことでアームロボット\nを操作することができ，操作が直感的に感じられたところがタスク完了時間の短縮に寄与\nしたと考えられる．AR アプリケーションではハンドトラッキング機能を用いて実際の指\nの動きでボタンを押すため，デバイスが指の動き正確に認識できず意図した通りの操作が\n難しい一方でVR アプリケーションではアームロボットを動かしたい方向のボタンに向け\nてコントローラを動かすのみで操作可能であるため，意図した通りの操作が可能である点\nもタスク完了時間の短縮に寄与したと考えられる．\n26\n図5-1: AR 及びVR アプリケーションでのタスク完了時間の比較\n図5-2 にAR アプリケーション及びVR アプリケーション実行中の1 分当たりの瞬目回数\nの比較を示す．エラーバーは標準誤差を示す．この項目を比較した結果，AR アプリケー\nションにてタスクを行った際に瞬目回数が減少することが示され，二つの手法間の実行中\nの1 分当たりの瞬目回数には有意差が見られた．2 つのアプリケーションにて表示される\nオブジェクトは同じであるが，VR アプリケーションでは完全な仮想空間上に表示される\nのに対して，AR アプリケーションでは実空間に重ねてオブジェクトが表示されるため，\nオブジェクトとの距離感がつかみづらく，オブジェクトをより注視しなければならなかっ\nたことが瞬目回数に影響したと考えられる．\n27\n図5-2: AR 及びVR アプリケーション実行中の1 分当たりの瞬目回数\n5.2\n主観的な操作のしやすさの実験結果と考察\n表5-1 にAR 及びVR アプリケーションにおけるSUS スコアの平均を示す．結果とし\nて，AR アプリケーションでは54.8 点でありVR アプリケーションでは70.8 点であり，一\n般に良いシステムとされる68 点という基準をVR アプリケーションでは満たしたが，AR\nアプリケーションでは下回る結果となった．VR アプリケーションとAR アプリケーショ\nンでは操作開始時にスタートボタンを押すことや任意のタイミングでメニューボタンを\n押すことで操作が中断可能であること，リセットボタンを押すことでアームロボットを初\n期姿勢に戻すことが可能であることは共通である．今回の研究ではどちらのアプリケー\nションでもアームロボットの頭部の位置や姿勢，グリッパーの制御を全てボタンで行うた\nめボタン数が多い．AR アプリケーションではハンドトラッキング機能を用いて指でボタ\nンをそして操作するため，ハンドトラッキングの精度によって自分の意図の通りにボタン\nを操作できない事例がたびたび起きた．このことがシステム全体に対して使用することが\n28\n難しいと感じさせ，基準を下回る結果になったと考えられる．これに対しVR アプリケー\nションではコントローラのポインタを合わせるだけでボタンを押すことができるため，操\n作中のシステムの仕様が容易であると感じさせることができ，基準を満たす結果になった\nと考えられる．\n表5-1: AR アプリケーション及びVR アプリケーションにおける平均SUS スコア\n手法\nSUS スコア\nAR\n54.8\nVR\n70.8\n以下にアンケート評価の結果と考察を述べる．アンケートの各項目は「全く思わない」\nを1，「非常に思う」を5 としてスコアリングした．また，スコアリングした値を用いて各\nモードの各項目の平均スコアを算出した．表5-2 に被験者に回答してもらったアンケート\n項目及び表5-3 にアンケート評価結果を示す．アンケートの各項目について考察を行う．\n表5-2: 評価実験のアンケート項目\nquestion\nQ1 アームロボットの操作は直感的に感じましたか？\nQ2 アームロボットの操作は難しく感じましたか？\nQ3 アームロボットの操作の精度に満足していますか？\nQ4 アームロボットの操作の習得は容易であると感じましたか？\nQ5 操作のインターフェースは理解しやすかったですか？\nQ6 課されたタスクは難しいと感じましたか？\nQ7 アームロボットは意図した通りに動きましたか？\nQ8 アームロボットの操作中に目の疲労を感じましたか？\nQ9 アームロボットの操作中に体の疲労を感じましたか？\nQ10 画面上の文字や情報が見やすかったですか？\nQ11 ロボットアームやブロックの位置が正確に認識できましたか？\nQ12 ロボットアームとブロックとの距離感を正確に掴めましたか？\nQ13 デバイスを使用している間，視界に違和感や疲れを感じましたか？\nQ14 自分の意図の通りにボタンが押せましたか？\nQ15 ロボットアームの微調整が簡単に行えると感じましたか？\nQ16 長時間の操作でも，快適に作業を続けられると感じましたか？\n29\n表5-3: 評価実験のアンケート結果\n質問番号\nAR\nVR\nQ1\n3.9\n4.5\nQ2\n4.0\n2.1\nQ3\n3.0\n4.1\nQ4\n3.4\n1.8\nQ5\n4.4\n4.4\nQ6\n3.4\n2.4\nQ7\n2.9\n3.8\nQ8\n3.7\n2.1\nQ9\n1.9\n1.9\nQ10\n3.4\n4.6\nQ11\n3.2\n4.2\nQ12\n3.3\n3.8\nQ13\n3.1\n2.1\nQ14\n3.0\n4.7\nQ15\n3.0\n4.3\nQ16\n2.4\n3.7\nQ1 アームロボットの操作は直感的に感じましたか？\nAR アプリケーションとVR アプリケーションの比較において，AR アプリケーショ\nンで3.9 点であり，VR アプリケーションで4.9 点という結果になった．2 つの手法\nではボタンを用いてアームロボットを操作するという操作手法は共通しているが，\nAR アプリケーションではハンドトラッキング機能を用いて指でボタンを押すため，\nデバイスが指を正確に認識できなければボタンを押すことができない．その事象に\nよって，直感的ではないと感じられたと考えられる．一方でVR アプリケーション\nではコントローラのポインタを合わせてコントローラのボタンを押すのみで操作が\n行えるため，操作がより容易に感じられたと考えられる．\nQ2 アームロボットの操作は難しく感じましたか？\nAR アプリケーションとVR アプリケーションの比較において，AR アプリケーショ\nンで4.0 点であり，VR アプリケーションで2.1 点という結果になった．AR アプリ\nケーションではデバイスの構成上一度に画面内に表示できる情報がVR アプリケー\nションに比べ限られているため，ボタンを操作する際はアームロボットとブロック\nがある位置から視線を移動させ，ボタンがある方向を向かなければならない．その\nため，VR アプリケーションと比較して操作に必要な手順が1 つ多くなってしまうこ\nとが，主観的な操作の難しさに影響を与えたと考えられる．\nQ3 アームロボットの操作の精度に満足していますか？\nAR アプリケーションとVR アプリケーションの比較において，AR アプリケーショ\nンで3.0 点であり，VR アプリケーションで4.1 点という結果になった．本システム\nでは，ボタンを押し続けることでロボットアームを動かし続けることが可能である\n30\nが，VR アプリケーションでは，コントローラのボタンによって，ロボットアーム操\n作のボタンを容易に押すことが可能である．一方で，AR アプリケーションではハン\nドトラッキングにより正確なボタン入力が難しい場合があり，精度に対する満足度\nが低下したと考えられる．\nQ4 アームロボットの操作の習得は容易であると感じましたか？\nAR アプリケーションとVR アプリケーションの比較において，AR アプリケーショ\nンで3.4 点であり，VR アプリケーションで1.8 点という結果になった．Q1 で述べた\n通り，AR アプリケーションではハンドトラッキング機能で指を認識してボタンを押\nさなければならないため，デバイスが指を正しく認識できないときに意図通りの操\n作ができないという点が影響したと考えられる．\nQ5 操作のインターフェースは理解しやすかったですか？\nAR アプリケーションとVR アプリケーションの比較において，AR アプリケーショ\nンで4.4 点であり，VR アプリケーションで4.4 点という結果になり，評価に差は見\nられなかった．この結果は，両アプリケーションで同じUI が使用されていることが\n影響していると考えられる．\nQ6 課されたタスクは難しいと感じましたか？\nAR アプリケーションとVR アプリケーションの比較において，AR アプリケーショ\nンで3.4 点であり，VR アプリケーションで2.4 点という結果になった．両アプリケー\nションで課されたタスクは同じであったが，この違いは，Q2 やQ3 で述べたように，\nAR アプリケーションでは操作の容易さや精度においてVR に劣る点が影響したと考\nえられる．\nQ7 アームロボットは意図した通りに動きましたか？\nAR アプリケーションとVR アプリケーションの比較において，AR アプリケーショ\nンで2.9 点であり，VR アプリケーションで3.8 点という結果となり，VR アプリケー\nションの方が高評価であった．この結果は，Q3 で述べたようにVR の方が操作の精\n度が高いことが影響したと考えられる．\nQ8 アームロボットの操作中に目の疲労を感じましたか？\nAR アプリケーションとVR アプリケーションの比較において，AR アプリケーショ\nンで3.7 点であり，VR アプリケーションで2.1 点という結果となり，AR アプリケー\nションの方が疲労感が強く感じられた．この理由として，AR は実世界にオブジェ\nクトを重ねて表示する特性上，オブジェクトとの距離感が正しく測りづらいことで，\n被験者がより注視しなければならない点が挙げられる．\n31\nQ9 アームロボットの操作中に体の疲労を感じましたか？\nAR アプリケーションとVR アプリケーションの比較において，AR アプリケーショ\nンで1.9 点であり，VR アプリケーションで1.9 点という結果となり，評価に差は見\nられなかった．\nQ10 画面上の文字や情報が見やすかったですか？\nAR アプリケーションとVR アプリケーションの比較において，AR アプリケーショ\nンで3.4 点であり，VR アプリケーションで4.6 点という結果となり，VR アプリケー\nションの方が高評価であった．この理由として，Q8 で述べたような距離感の問題が\nVR では解消されていることが寄与したと考えられる．\nQ11 ロボットアームやブロックの位置が正確に認識できましたか？\nAR アプリケーションとVR アプリケーションの比較において，AR アプリケーショ\nンで3.2 点であり，VR アプリケーションで4.2 点という結果となり，VR アプリケー\nションの方が高評価であった．この結果も，Q8 で述べた距離感に起因する問題が関\n係していると考えられる．\nQ12 ロボットアームとブロックとの距離感を正確に掴めましたか？\nAR アプリケーションとVR アプリケーションの比較において，AR アプリケーショ\nンで3.3 点であり，VR アプリケーションで3.8 点という結果となり，VR アプリケー\nションの方が高評価であった．この結果も，Q8 で述べた理由と同様に，距離感を掴\nみやすい点が評価に影響したと考えられる．\nQ13 デバイスを使用している間，視界に違和感や疲れを感じましたか？\nAR アプリケーションとVR アプリケーションの比較において，AR アプリケーショ\nンで3.1 点であり，VR アプリケーションで2.1 点という結果となり，AR アプリケー\nションの方が疲れを感じたと評価された．この理由として，Q2 で述べたように，AR\nデバイスでは一度に表示できる情報が限られており，視界の端にあるオブジェクト\nが見えづらいことが影響したと考えられる．\nQ14 自分の意図の通りにボタンが押せましたか？\nAR アプリケーションとVR アプリケーションの比較において，AR アプリケーショ\nンで3 点であり，VR アプリケーションで4.7 点という結果となり，VR アプリケー\nションの方が高評価であった. この結果は，Q1 で述べたように，VR の方が操作の直\n感性が高いことが影響していると考えられる．\nQ15 ロボットアームの微調整が簡単に行えると感じましたか？\nAR アプリケーションとVR アプリケーションの比較において，AR アプリケーショ\n32\nンで3 点であり，VR アプリケーションで4.3 点という結果となり，VR アプリケー\nションの方が高評価であった．この結果は，Q3 やQ14 で述べたように，VR ではボ\nタンの押しやすさや操作の精度が高いことが寄与していると考えられる．\nQ16 長時間の操作でも，快適に作業を続けられると感じましたか？\nAR アプリケーションとVR アプリケーションの比較において，AR アプリケーショ\nンで2.4 点であり，VR アプリケーションで3.7 点という結果となり，VR アプリケー\nションの方が高評価であった．この結果は，Q3 やQ8 で述べたように，VR では操\n作の精度が高いことと視覚的負荷が小さいことが寄与していると考えられる．\n33\n第6章\n結論と今後の展望\n6.1\n結論\n本研究では，AR およびVR 技術が市場規模の拡大とともにエンターテインメント，医\n療，製造業など多岐にわたる業界で活用されている中で，両技術の差別化が明確でない点\nに着目した．特に，製造業界におけるロボットアームの操作システムを題材に，既存の\nAR アプリケーションをVR デバイス向けに移植・開発し，両システムを比較する評価実\n験を行った．\nAR およびVR アプリケーションはどちらもボタン操作によるロボットアームの制御を\n目的としたが，AR ではハンドトラッキング機能を用いて指でボタンを押す一方，VR で\nはコントローラを用いてボタンを操作するという違いがあった．評価実験の結果，以下の\n点が明らかになった．\nタスク完了時間\nVR アプリケーションではタスク完了までの時間が有意に短く，操作の効率性に優れ\nていることが確認された．これは，コントローラを用いたVR アプリケーションで\nは，ボタン操作が容易で意図した通りの動きを行いやすいためと考えられる．\n瞬目回数\nAR アプリケーションでは，タスク実行中の瞬目回数が有意に少ないという結果が得\nられた．これは，AR が現実世界に仮想オブジェクトを重ねる特性上，オブジェクト\nとの距離感がつかみにくく，ユーザーがより注視する必要があったためと推察され\nる．一方，VR は完全な仮想空間であるため，視覚的な負荷が軽減されていると考え\nられる．\nシステムの使いやすさ\nSUS（System Usability Scale）の結果から，AR アプリケーションは基準を満たさず，\n操作が難しいと評価された．一方，VR アプリケーションは一定以上の使いやすさを\n持つシステムであることが示された．また，アンケート結果においても，VR アプリ\nケーションが従来手法に比べ直感的かつ容易で，意図した通りの操作が可能である\nという点で高い評価を得た．\n34\n以上の結果から，ロボットアームの操作システムに関してはVR アプリケーションは操\n作性や効率性，使いやすさにおいて優れていることが明らかとなった．また，本研究で対\n象としたような実世界のオブジェクトを必要としないタスクにおいては，仮想オブジェク\nトの視認性に優れるVR アプリケーションの方が使用者にとって高い評価を得やすい可能\n性があると考えられる．\n6.2\n今後の展望\n本研究では，AR およびVR を用いたアームロボット操作システムの比較評価を行い，両\nシステムの特性や性能に関する知見を得た．しかし，本研究の評価実験では各操作手法で\n一回のみタスクを行ったため，操作手法への慣れによる操作のしやすさやタスク実行時間\nの変化，両手法間の差異については十分に明らかにされていない．今後は，異なるタスク\nを対象とした比較，評価を行い，AR およびVR がどのような場面で適しているかをより\n詳細に検討する必要がある．例えば，本研究ではロボットアームの操作を対象としたが，\n医療現場における手術シミュレーションなど，実世界における複雑な作業環境を想定した\nタスクに適用することで，AR とVR の特性がどのように異なるかを明確にすることがで\nきる．\nさらに，本研究ではタスク遂行時間や主観的評価を主な指標としたが，今後の研究では，\n異なる評価指標を用いた比較，評価も重要となる．例えば，本研究では視覚的負荷に焦点\nを当てたが，HMD を使用することによる首や肩への身体的負荷，長時間使用による疲労，\nさらにVR 環境特有の酔いやすさ（サイバーモーションシックネス）などの生理的影響も\n評価する必要がある．特に，HMD の重量や装着時間が首や肩の筋疲労に与える影響を測\n定することで，AR とVR の長時間使用時の快適性を比較できると考えられる．また，使\n用者がどの程度VR 酔いを感じるかを定量化することで，異なるタスクにおけるVR の適\n用可能性についてもより詳細な検討が可能となる．こうした評価指標を導入することで，\nAR/VR 環境がユーザーに与える影響をより多角的に分析できると考えられる．\n加えて，これらの知見をもとに，負荷軽減と操作性向上のための環境設定やシステム\n開発を進めることが求められる．具体的には，視覚的負荷の軽減を目的としたインター\nフェース設計や，適切なタスク環境の構築を通じて，ユーザーがより直感的かつ効率的に\nタスクを遂行できるシステムの開発が期待される．今後の研究を通じて，AR およびVR\nの適用可能性をより広範囲に明らかにし，それぞれの技術の特性を最大限に活かしたシス\nテム設計の指針を提供することが目標である．\n35\n謝辞\n本研究を進めるうえで，親身に相談に乗って下さった青山学院大学理工学部情報テクノ\nロジー学科ロペズ・ギヨーム教授に深く感謝をいたします．また，自身が制作されたAR\nのロボットアーム操作システムを本研究において使用することを快諾してくださり，さら\nにVR アプリケーション開発の際に助言をいただいた阿部先輩にも心より感謝申し上げま\nす．研究環境の補助をしてくださった大熊氏，論文の添削を通してアドバイスをくださっ\nた高橋先輩をはじめとするロペズ研究室の院生の方々，同期の方々に深く感謝いたしま\nす．また，実験に協力していただいた被験者の方々にも感謝いたします．\n2025 年1 月28 日\n田中崇登\n36\n参考文献\n[1] 神原誠之：拡張現実感（Augmented Reality: AR）概論，情報処理，Vol. 51, No. 4, pp.\n367–372 (2010).\n[2] 富士キメラ総研：『AR ／VR 関連市場の将来展望2020』まとまる，https://www.\nfcr.co.jp/pr/20088.htm (2020).\n[3] 経済産業省：令和２年度コンテンツ海外展開促進事業（仮想空間の今後の可能性と諸課\n題に関する調査分析事業），https://www.meti.go.jp/policy/mono_info_\nservice/contents/downloadfiles/report/kasou-houkoku.pdf\n(2021).\n[4] Verhulst, I., Woods, A., Whittaker, L., Bennett, J. and Dalton, P.: Do VR and AR versions\nof an immersive cultural experience engender different user experiences?, Computers in\nHuman Behavior, Vol. 125, p. 106951 (2021).\n[5] Fujitsu: その課題、情くんにおまかせ！第10 話，https://jp.fujitsu.com/\nplatform/server/advantages/special/jokun/10-ar/ (2013).\n[6] Tenaris:\nVR\nand\nAR\ntechnology\nused\nto\nmanage\nArgentine\nproject\nfrom\nItaly,\nhttps://www.tenaris.com/en/news/2021/\nvr-and-ar-technology-used-to-manage-argentine-project-from-italy\n(2021).\n[7] 三菱重工技報：MR グラス活用による現場作業効率化，https://www.mhi.co.\njp/technology/review/pdf/593/593090.pdf (2022).\n[8] Rom´an-Ib´a˜nez, V., Pujol-L´opez, F. A., Mora-Mora, H., Pertegal-Felices, M. L. and\nJimeno-Morenilla, A.: A low-cost immersive virtual reality system for teaching robotic\nmanipulators programming, Sustainability, Vol. 10, No. 4, p. 1102 (2018).\n[9] P´erez, L., Diez, E., Usamentiaga, R. and Garc´ıa, D. F.: Industrial robot control and opera-\ntor training using virtual reality interfaces, Computers in Industry, Vol. 109, pp. 114–120\n(2019).\n37\n[10] Hashimoto, S., Ishida, A., Inami, M. and Igarashi, T.: Touchme: An augmented reality\nbased remote robot manipulation, Vol. 2 (2011).\n[11] Makhataeva, Z. and Varol, H. A.: Augmented reality for robotics: A review, Robotics,\nVol. 9, No. 2, p. 21 (2020).\n[12] Bambuˆsek, D., Materna, Z., Kapinus, M., Beran, V. and Smrˇz, P.: Combining interac-\ntive spatial augmented reality with head-mounted display for end-user collaborative robot\nprogramming, pp. 1–8 (2019).\n[13] Elendu, C., Amaechi, D. C., Okatta, A. U., Amaechi, E. C., Elendu, T. C., Ezeh, C. P. and\nElendu, I. D.: The impact of simulation-based training in medical education: A review,\nMedicine, Vol. 103, No. 27, p. e38813 (2024).\n[14] 志賀淑之，杉本真樹，安部光洋，錦見礼央，保科勇斗，米岡祐輔，斎川周，井上泰，\n吉松正，日下部将史ほか：複合現実MR, 拡張現実AR, 仮想現実VR を応用した泌\n尿器ナビゲーション手術の検討，Japanese Journal of Endourology, Vol. 31, No. 2, pp.\n253–259 (2018).\n[15] 山元翔：AR/VR の教育・学習支援システムへの利用と課題，教育システム情報学会\n誌，Vol. 36, No. 2, pp. 49–56 (2019).\n[16] 渡邉ゆきこ，小渡悟，大前智美：VR 空間内での活動を経験記憶につなげる外国語教\n育，pp. 199–202 (2022).\n[17] Kohen, S., Elvezio, C. and Feiner, S.: HoloFight: An augmented reality ﬁghting game, pp.\n1–2 (2021).\n[18] Hackl, D. and Anthes, C.: HoloKeys-an augmented reality application for learning the\npiano., pp. 140–144 (2017).\n[19] Pavel, I. A., Bogdanici, C. M., Donica, V. C., Anton, N., Savu, B., Chiriac, C. P., Pavel,\nC. D. and Salavastru, S. C.: Computer Vision Syndrome: An Ophthalmic Pathology of\nthe Modern Era, Medicina, Vol. 59, No. 2, p. 412 (online), https://doi.org/10.\n3390/medicina59020412 (2023).\n[20] Kaur, K., Gurnani, B., Nayak, S., Deori, N., Kaur, S., Jethani, J., Singh, D., Agarkar,\nS., Hussaindeen, J. R., Sukhija, J. and Mishra, D.: Digital Eye Strain- A Comprehensive\nReview, Ophthalmology and Therapy, Vol. 11, No. 3, pp. 1655–1680 (online), https:\n//doi.org/10.1007/s40123-022-00466-5 (2022).\n38\n[21] 伊藤奈々，武田朴，笠井亮佑，上條史記，加納敬，島峰徹也，荻野稔，日向奈惠，篠原\n一彦，田仲浩平：VDT 作業における眼精疲労度の比較―スマートグラスとLCD お\nよび印刷物の比較―，医療機器学，Vol. 90, No. 5, pp. 405–413 (2020).\n[22] Hirota, M., Kanda, H., Endo, T., Miyoshi, T., Miyagawa, S., Hirohara, Y., Yamaguchi,\nT., Saika, M., Morimoto, T. and Fujikado, T.: Comparison of visual fatigue caused by\nhead-mounted display for virtual reality and two-dimensional display using objective and\nsubjective evaluation, Ergonomics, Vol. 62, No. 6, pp. 759–766 (2019).\n[23] Souchet, A. D., Philippe, S., Lourdeaux, D. and Leroy, L.: Measuring visual fatigue and\ncognitive load via eye tracking while learning with virtual reality head-mounted displays:\nA review, International Journal of Human–Computer Interaction, Vol. 38, No. 9, pp. 801–\n824 (2022).\n[24] Wang, X., Liu, L., Hu, X., Wu, Y., Liu, Y., Ni, B. and Ke, B.: Comparison of changes in\nvisual fatigue and ocular surface after 3D and 2D viewing with augmented reality glasses,\nDisplays, Vol. 78, p. 102401 (2023).\n[25] H.Abe，Bataller, V. B.，H.Ter¨av¨a，M．Luimula，G．Lopez：Combining AR and ball-\nshape input interface to control remotely a robot-arm, AHFE Open Access, Vol. 121\n(2024).\n[26] 日経クロステック：まるでパズル、コスト度外視HoloLens 2 のスゴイ中身，https:\n//xtech.nikkei.com/atcl/nxt/column/18/01267/00084/ (2020).\n[27] Labs, P.: Hololens and BT300 eye tracking add-ons, https://pupil-labs.com/\nblog/hololens-bt300-addon. (最終参照日: 2025/1/15).\n[28] meta: Meta Quest 3, https://www.meta.com/jp/quest/quest-3/. (最終参照\n日: 2025/1/15).\n[29] Labs, P.: Eye tracking for mixed reality, https://pupil-labs.com/products/\nvr-ar. (最終参照日: 2025/1/15).\n[30] Microsoft:\nHoloLens, https://learn.microsoft.com/ja-jp/hololens/\nhololens1-hardware. (最終参照日: 2025/1/15).\n[31] Labs, P.:\nNeon Companion App Terms of Use, https://pupil-labs.com/\nlegal/neon-companion-terms-of-use. (最終参照日: 2025/1/15).\n39\n[32] Docs, P. L.:\nPupil Cloud - NEON, https://docs.pupil-labs.com/neon/\npupil-cloud/. (最終参照日: 2025/1/15).\n[33] Technologies, U.: Unity, https://unity.com/ja. (最終参照日: 2025/1/15).\n[34] Microsoft:\nMixed\nReality\nToolkit,\nhttps://hololabinc.github.io/\nMixedRealityToolkit-Unity/Documentation.ja/WelcomeToMRTK.\nhtml. (最終参照日: 2025/1/15).\n[35] QuestionPro: System Usability Scale: What it is, Calculation + Usage, https://\nwww.questionpro.com/blog/system-usability-scale/.\n(最終参照日:\n2025/1/15).\n40\n質疑応答\n伊藤　雄一　情報テクノロジー学科　教授\nQ\nどんなタスクでしたか．\nA\nロボットアームの左側にあるブロックを，ロボットアームを操作しブロックをつか\nんで移動させ，所定の位置まで移動させる動作を3 回分行うという内容です．\nQ\n研究の目的と構築したシステムが合っていますか．\nA\nAR 及びVR アプリケーションで同様のタスクを行っているため，研究の目的と合\n致していると考えております．\nQ\nパフォーマンスに影響を与えているのは何ですか．\nA\nパフォーマンスに影響を与えている要因は，操作性の違いと視認性が挙げられます．\nVR ではコントローラ，AR ではハンドトラッキングによる指の操作を用いるため操\n作性が異なり，さらにオブジェクトの視認性の差も影響を及ぼしていると考えてお\nります．\nQ\nVR デバイスの場合は実空間に投影するのではなく背景が設定されていますが，コ\nントローラの違いだけがパフォーマンスに影響を与えていますか．\nA\n今回，VR デバイスでは背景を設定することが一般的であると考え，背景を設定し\nました．そのため，背景の有無もパフォーマンスに影響を与えている要因の一つと\n考えております．\n上堀　さん　情報テクノロジー学科　\nQ\nコントローラなどへの慣れが影響しませんか．\nA\n実験後のアンケートで普段AR 及びVR デバイスを使用するかという質問項目を設\nけており，その結果どちらのデバイスでも日常的に使用する人はいなかったので，コ\nントローラ操作への慣れは影響していないと考えております．\n41\n",
        "chunks": [
            "B2024_TakatoTanaka_t. B2024_TakatoTanaka_t. B2024_TakatoTanaka_t",
            "青山学院大学理工学部\n情報テクノロジー学科\n２０２４年度卒業研究論文\n拡張と仮想現実の違いがタスクパ\nフォーマンスに与える影響の比較\n２０２５年１月２８日提出\n指導教員ロペズ・ギヨーム教授\n提出者学生番号　氏名\n１５８２１０５７田中　崇登\n青山学院大学 理工学部 情報テクノロジー学科 \n2024（令和6）年度卒業論文要旨 \n- 1 - \n \n拡張と仮想現実の違いがタスクパフォーマンスに \n与える影響の比較 \n \n田中崇登（15821057） \nロ  ぺ  ズ 研 究 室 \n \n１．はじめに \n拡張現実（AR）技術と仮想現実（VR）技術の市場\n規模は急速に拡大しており，その応用範囲は教育，医\n療，エンターテインメント，製造業など多岐にわたる\n[1]． 特に製造業では，生産性向上やコスト削減を目\n的にXR 技術の導入が進んでおり，MR グラスを活用し\nたシステムを導入し，パネルの組立作業の作業効率を\n向上させた事例が存在する[2]．一方，これら両技術の\n特性やユーザー体験における差異についての比較研究\nは十分に行われていない． \nそこで本研究では，AR およびVR を用いたタスク\n遂行シス",
            "の比較研究\nは十分に行われていない． \nそこで本研究では，AR およびVR を用いたタスク\n遂行システムを構築し，両技術の性能とユーザー体験\nの差異を比較・評価する． \n２．関連研究 \nVerhulst らは，博物館の体験イベントを題材に，VR\nデバイスとAR デバイスのユーザー体験を比較し，VR\nがAR よりも空間的臨場感や没入感で優位性を示すこ\nとを報告した[3]．また，Hirota らは，VR ヘッドマウ\nントディスプレイと2D ディスプレイを用いた視覚的\n疲労の比較を行い，瞬目回数が視覚的疲労を評価する\n指標として有効である可能性を示した[4]．特に，瞬目\n回数が少ないほど視覚的負荷が高まり，疲労を引き起\nこしやすいことが示唆されており，この指標は視覚的\nストレスやデバイスの影響を測定する上で有用である． \n３．AR・VR を用いたアームロボット操作システム \n本研究では阿部ら[5]がHoloLens2[6]向けに制作・\n開発した「拡張現実とインプットデバイスを用いたア\nームロボットリモートコントロールシステム」（以下\nAR アプリと記載）を元に，Meta Quest 3[7]",
            "ットリモートコントロールシステム」（以下\nAR アプリと記載）を元に，Meta Quest 3[7]向けのア\nームロボット操作システムを開発した（以下VR アプ\nリと記載）． \n図1-2 にアプリケーションの全体図を示す．それぞ\nれのアプリでは仮想的に提示されたボタンを操作し，\nロボットアームを動かしてブロックを指定の位置に移\n動させるタスクを遂行する．図3 にタスク実行中の様\n子を示す．  \nさらに，AR およびVR 環境でタスクを実行中の瞬\n目回数をタスクパフォーマンス評価指標の一つとして\n用いるため，HoloLens 2 にはPupil Labs HoloLens \nAdd-on[8]を，Meta Quest 3 にはPupil Labs VR/AR \nEye Tracking Module[9]をそれぞれ装着し，視線情報\nを取得した．本研究では，瞬目回数が視覚的疲労を評\n価する客観的指標として有効であることがHirota ら\nの研究[4]で示されていることから，これをパフォーマ\nンス評価と関連付けて使用する．特に，AR およびVR\nデバイスでの視覚的負荷がタスク遂行能力に与える",
            "ンス評価と関連付けて使用する．特に，AR およびVR\nデバイスでの視覚的負荷がタスク遂行能力に与える影\n響を定量的に把握する目的がある． \n \n図 1  AR アプリの全体図 \n \n図 2  VR アプリの全体図 \n \n \n \n図 3  タスク実行中の様子 \n４．各アプリケーションのパフォーマンス比較手順 \nAR 及びVR アプリにて同様のタスクを課し，違い\nを比較し評価した．本研究では各アプリでのタスク実\n行時間と， 実行中の瞬目回数を定量評価指標として用\nいた． \n実験手順として，被験者10 名（男性:8 人， 女性:2\n人）は操作説明を受けた後に5 人はAR， 5 人はVR\nアプリを先に使用する．その後5 分間の休憩をとり，\nもう一方のアプリを使用する． また操作後に操作性， \n視認性を評価するためSUS アンケートと独自に作成\nしたアンケートを実施した． \n５．結果 \n図4 にタスク実行時間の結果を示す．VR アプリに\nてタスクを行った際はAR アプリに比べてタスク完了\n時間が有意に短縮されることが示された（p<0.01）． \nタスク実行中の瞬目回数に関してはAR アプリにて\n",
            "意に短縮されることが示された（p<0.01）． \nタスク実行中の瞬目回数に関してはAR アプリにて\nタスクを行った際にVR アプリよりも瞬目回数が有意\nに減少することが示された．（p<0.01）． \nまた主観評価に関して，SUS アンケートによるユー\nザビリティ評価では平均値がAR アプリが54.8 点， \nVR アプリが70.8 点であり， VR アプリの方が評価が\n高い結果となった．また，主観評価に関して，独自の\nアンケートの結果では，操作性と視認性でVR がAR\nを上回る一方，UI は両者で同程度の評価となった．こ\nれにより，VR は操作性と視認性で優位性を示すこと\nが確認された． \n \n図 4 各アプリケーションでのタスク完了時間の比較 \n６．まとめ \n本研究では,AR とVR を用いたアームロボット操作\nシステムを構築し,性能を比較評価した.結果,VR はタ\nスク実行時間が短く,ユーザビリティに優れる一方,AR\nは瞬目回数が少ない結果を示した. \n本研究では，評価は1 回のタスク実施に限られ,慣れ\nや習熟度の影響は未検討である.今後は長期的評価や\n他システムへの適用を通じ,よ",
            "ク実施に限られ,慣れ\nや習熟度の影響は未検討である.今後は長期的評価や\n他システムへの適用を通じ,より直感的で効率的な設\n計を目指す. \n参考文献 \n[1] \nFujitsu : その課題，情くんにおまかせ！第10 話， \nhttps://jp.fujitsu.com/platform/server/advanta\nges/special/jokun/10-ar/ （2025/1/24 参照） \n[2] \n三菱重工技報 Vol.59 No．3: MR グラス活用によ\nる現場作業効率化， \nhttps://www.mhi.co.jp/technology/review/pdf/5\n93/593090.pdf （2025/1/24 参照） \n[3] \nI.Verhulst，A.Woods， L.Whittaker， J.Bennett， \nP.Dalton:Do VR and AR versions of an \nimmersive \ncultural \nexperience \nengender \ndifferent user experiences?,  Computers in \nHu",
            "er \ndifferent user experiences?,  Computers in \nHuman Behavior 125． \nhttps://www.sciencedirect.com/science/article/p\nii/S0747563221002740?ref=cra_js_challenge&f\nr=RR-1 \n[4] \nM. Hirota， H. Kanda， T. Endo， T. Miyoshi， \nS. Miyagawa， Y. Hirohara， T. Yamaguchi， \nM.Saika，T.Morimoto，T. Fujikado:Comparison \nof visual fatigue caused by head-mounted \ndisplay for virtual reality and two-dimensional \ndisplay \nusing \nobjective \nand \nsubjective \nevaluation． \nhttps://www.tandfonline.com/doi/epdf/10.1080/\n00140",
            "ttps://www.tandfonline.com/doi/epdf/10.1080/\n00140139.2019.1582805?needAccess=true \n[5] \nH.Abe， V. Blanco Bataller， H.Terävä， M． \nLuimula， G．Lopez， \"Combining AR and ball-\nshape input interface to control remotely a \nrobot-arm，\" AHFE Open Access， vol 121 \n（2024）． doi:10.54941/ahfe1004628  \n[6] \nHoloLens2， Microsoft 社．  \nhttps://www.microsoft.com/ja-jp/d/hololens-\n2/91pnzzznzwcp?activetab=pivot:%E6%A6%82\n%E8%A6%81tab \n[7] \nMeta Quest3．Meta 社 ， \nhttps://www.meta.com/jp/quest/quest-3/\n（2025/1/24 参照",
            "tps://www.meta.com/jp/quest/quest-3/\n（2025/1/24 参照） \n[8] \nHololens and BT300 eye tracking add-ons．\nPupilLabs 社 ， \nhttps://pupil-labs.com/blog/hololens-bt300-\naddon（2025/1/24 参照） \n[9] \nEye tracking for mixed reality．PupilLabs 社 ， \nhttps://pupil-labs.com/products/vr-ar\n（2025/1/24 参照） \n目次\n第1 章\n序章\n1\n1.1\n研究背景. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n1\n1.1.1\n拡張現実・仮想空間技術の現状. . . . . . . . . . . . . . . . . . . .\n1\n1.1.2\n拡張現実技術と仮想空間技術の差別化\n. . . . . . . . . . . . . . . .\n2",
            "張現実技術と仮想空間技術の差別化\n. . . . . . . . . . . . . . . .\n2\n1.1.3\n製造業におけるXR 技術の活用. . . . . . . . . . . . . . . . . . . .\n3\n1.2\n研究目的. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n4\n1.3\n本論文の構成. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n5\n第2 章\n拡張現実・仮想空間に関する研究\n6\n2.1\nAR・VR に関する研究. . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n6\n2.1.1\n製造業でのXR 研究\n. . . . . . . . . . . . . . . . . . . . . . . . . .\n6\n2.1.2\n医療分野でのXR 研究. . . . . . . . . . . . . . . . . .",
            "1.2\n医療分野でのXR 研究. . . . . . . . . . . . . . . . . . . . . . . . .\n8\n2.1.3\n教育分野でのXR 研究. . . . . . . . . . . . . . . . . . . . . . . . .\n9\n2.1.4\nエンタメ分野でのXR 研究. . . . . . . . . . . . . . . . . . . . . . .\n9\n2.2\n視覚的負荷に関する研究. . . . . . . . . . . . . . . . . . . . . . . . . . . .\n10\n2.3\nAR/VR の比較に関する研究. . . . . . . . . . . . . . . . . . . . . . . . . .\n11\n2.4\n先行研究のまとめ. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n11\n第3 章\n拡張現実・仮想空間技術を用いたアームロボット操作システム\n12\n3.1\nシステム概要. . . . . . . . . . . .",
            "アームロボット操作システム\n12\n3.1\nシステム概要. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n12\n3.2\nアプリケーションのタスク内容. . . . . . . . . . . . . . . . . . . . . . . .\n14\n3.3\n使用デバイス. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n15\n3.3.1\nAR デバイス\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n15\n3.3.2\nVR デバイス\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n16\n3.3.3\nAR デバイスに装着する視線情報取得デバイス. . . . . . . . . . . .\n16\n3.3.4\nVR デバイスに装着する視線情報取得デバイス. . . . . . . .",
            ". .\n16\n3.3.4\nVR デバイスに装着する視線情報取得デバイス. . . . . . . . . . . .\n17\n3.4\nソフトウェア開発. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n20\n3.4.1\nアプリケーション開発. . . . . . . . . . . . . . . . . . . . . . . . .\n20\n3.4.2\nAR アプリケーション開発. . . . . . . . . . . . . . . . . . . . . . .\n20\ni\n3.4.3\nVR アプリケーション開発. . . . . . . . . . . . . . . . . . . . . . .\n21\n第4 章\nユーザ評価実験\n22\n4.1\n実験目的. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n22\n4.2\n実験環境. . . . . . . . . . . . . . . . . . . . . .",
            ".2\n実験環境. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n22\n4.3\n実験方法. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n22\n4.4\n評価方法. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n24\n4.4.1\n定量評価指標. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n24\n4.4.2\n主観的な評価の指標\n. . . . . . . . . . . . . . . . . . . . . . . . . .\n24\n第5 章\n実験結果及び考察\n26\n5.1\n定量評価の実験結果及び考察\n. . . . . . . . . . . . . . . . . . . . . . . . .\n26\n5.2\n主観的な操作のし",
            " . . . . . . . . . . . . . . . . .\n26\n5.2\n主観的な操作のしやすさの実験結果と考察. . . . . . . . . . . . . . . . . .\n28\n第6 章\n結論と今後の展望\n34\n6.1\n結論. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n34\n6.2\n今後の展望\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n35\n謝辞\n36\n参考文献\n37\nii\n第1章\n序章\n本章では，本研究における研究背景，目的および本論文の構成について述べる．\n1.1\n研究背景\n1.1.1\n拡張現実・仮想空間技術の現状\n拡張現実（AR）とはユーザが見ている現実のシーンにコンピュータグラフィックスに\nよって描かれた仮想物体を重畳表示することで，ユーザがいる場所に応じた情報を直感的\nに提示する技術である[1]．\n近年，拡張現実技術の市場規模は拡大し続けている. 図",
            "じた情報を直感的\nに提示する技術である[1]．\n近年，拡張現実技術の市場規模は拡大し続けている. 図1-1 で示すように，2020 年の調\n査によると，2020 年のAR スマートグラス，MR スマートグラスの世界での市場規模は\n441 億円の見込みであるが，2030 年にはその規模は13 兆9500 億円であると予測されて\nおり，この数字は2020 年の市場規模の約320 倍である[2]．なお，AR スマートグラス・\nMR スマートグラスとは肉眼に見える視界にデジタル情報を重ねて表示する機能を持つデ\nジタルデバイスである．\n図1-1: スマートグラスの世界市場（[2] より引用）\n1\n仮想空間（VR）とは，CG で作られた世界や360 度動画等の実写映像を「あたかもその\n場所に居るかのような没入感」で味わうことができる技術である[3]．拡張現実技術と同\n様に，仮想空間技術の市場規模は拡大し続けている．図1-2 で示すように，2020 年の調査\nでは，仮想空間技術を利用する際に使用するデバイスであるヘッドマウントディスプレイ\nの世界での市場規模は，2020 年では1914 億円の見込み",
            "バイスであるヘッドマウントディスプレイ\nの世界での市場規模は，2020 年では1914 億円の見込みであるが，2030 年には1 兆3272\n億円に上ると予測されている[2]．\n図1-2: スマートグラスの世界市場（[2] より引用）\n上記のように拡張現実・仮想空間技術の市場規模が急速に成長しており，これらの技\n術はこれからの私たちの生活や産業においてますます重要な役割を果たすことを示して\nいる．\n1.1.2\n拡張現実技術と仮想空間技術の差別化\nクロスリアリティ（XR）技術とは拡張現実（AR），仮想空間（VR），複合現実（MR）\nなど現実世界と仮想世界の組み合わせで新たな体験を生み出す技術の総称である．仮想空\n間（VR）と拡張現実（AR）は，現実世界を拡張または仮想化する技術として，教育，エ\nンターテインメント，文化遺産保護，医療，産業など多岐にわたる分野で応用が進展して\nいる．これらの技術はユーザー体験に与える影響が異なるとされており，その違いを明確\nにする研究が注目されている．しかし，これら二つの技術はしばしば混同されることがあ\nり，両者の差異に言及した研究は依然として限られている",
            "，これら二つの技術はしばしば混同されることがあ\nり，両者の差異に言及した研究は依然として限られている．Verhulst ら（2021）は，ロン\nドンのナショナル・ギャラリーにおける「バーチャル・ヴェロネーゼ」体験を題材に，VR\n2\nデバイス（Oculus Quest）とAR デバイス（Magic Leap およびMira Prism）のユーザー体\n験を比較した[4]．この研究では，臨場感，楽しさ，認知的および感情的関与，行動的関\n与が評価され，VR は空間的な臨場感や「その場にいる」感覚がAR よりも高いという結\n果が得られた．これらの知見は，デバイスの特性が提供される体験の質に影響を与えるこ\nとを示している．しかし，同一のタスクやプロジェクトを実行する際，これらの技術が具\n体的にどのような差異を生じさせるのかについては，依然として明らかにされていない点\nが多い．\n1.1.3\n製造業におけるXR 技術の活用\nXR 技術はエンターテイメント業界での利用が注目されがちであるが，製造業において\nも金銭コストの削減，生産性の向上を目的とした導入事例が数多くある．富士通は工場の\n保守点検業務にお",
            "\nも金銭コストの削減，生産性の向上を目的とした導入事例が数多くある．富士通は工場の\n保守点検業務において点検ノウハウを紙からタブレットを用いたAR システムに変更する\nことで作業内容が映像と音声で指示できるようになり作業品質が向上した[5]．鋼管製造\nを行うテナリス社は保守作業の効率化と人的ミスの削減のため端末で点検が必要な場所を\nアイコンで表示するAR システムを導入している[6]．三菱重工株式会社では，航空機胴\n体パネルの組立て作業において，作業効率の向上を目的として作業者が装着するヘッドマ\nウント型MR グラスに，実物に対して取付け後の部品を含む3D モデル及び，作業箇所に\nリベットの位置や種類，工作情報などを重ね合わせ表示するシステムを導入した[7]．図\n1-3 に実際にヘッドマウント型ディスプレイを使用している様子を示す．\n3\n図1-3: ヘッドマウント型ディスプレイ使用時の様子（[7] より引用）\n以上のように今日製造業の様々な現場でMR 技術が活用され，生産性や効率の向上に寄\n与するとともにコスト削減にも寄与している．\n1.2\n研究目的\n1.1 節で述べたように，拡張現実",
            "寄\n与するとともにコスト削減にも寄与している．\n1.2\n研究目的\n1.1 節で述べたように，拡張現実（AR）技術とバーチャル・リアリティ（VR）技術の\n市場規模は急速に拡大しており，その応用範囲は教育，医療，エンターテインメント，製\n造業など多岐にわたる．一方で，これらの技術が特定のタスク遂行においてどのような影\n響を与えるかについての体系的な検討は十分に行われておらず，最適な環境設定に関する\n指針も確立されていない．そこで本研究では，AR/VR 環境における負荷軽減と操作性向\n上を両立するシステムを開発・提案することを目的とする．この目的を達成するために，\n以下の2 つの目標を設定する．\n• AR およびVR 環境で実施可能なタスクを提案し，AR 及びVR 環境における適切な\nタスク設計とシステム構築の指針を示す\n• AR 及びVR 環境における操作性および視覚的負荷の違いを明確にする\n4\n1.3\n本論文の構成\n第1 章では，本論文の研究背景，研究目的，及び本論文の構成について述べた．第2 章\nでは，関連研究について説明する．第3 章では，システムの概要について説明する．第\n4 章で",
            "第2 章\nでは，関連研究について説明する．第3 章では，システムの概要について説明する．第\n4 章では，実験方法について説明する．第5 章では，実験結果と考察について説明する．\n第6 章では，本論文の結論と今後の展望について述べる．\n5\n第2章\n拡張現実・仮想空間に関する研究\n本章では，AR・VR に関する研究について述べる．2.1 節ではAR・VR を用いたシステ\nム開発，2.2 節では視覚的負荷に関する研究，2.3 節ではVR とAR の比較に関するに関す\nる研究について述べる．\n2.1\nAR・VR に関する研究\nVR・AR は製造業，教育，医療，エンタメ分野など様々な分野で開発，導入されている．\n2.1.1\n製造業でのXR 研究\nRom´an-Ib´a˜nez ら（2018）は，低コストで没入型のVR システムを開発し，ロボットアー\nム操作の教育における有効性を検証した．この研究では，シミュレーション環境を活用\nすることで，ロボットアームの高コストや安全性の課題を解決し，学生がロボティクス\nの実践的な知識を習得するための効果的な学習ツールとしてVR を提示している．また，\nシミュ",
            "ティクス\nの実践的な知識を習得するための効果的な学習ツールとしてVR を提示している．また，\nシミュレーターに組み込まれた衝突検知やトラジェクトリ計画などの高度な機能により，\n実際の産業環境を模擬することが可能となり，教育現場での実用性が評価された．本研究\nは，VR 技術が持つ教育的可能性を示すとともに，タスク遂行における没入型技術の活用\nを検討する上での基盤を提供している[8]．図2-1 にRom´an-Ib´a˜nez らの提案するシステム\n使用時の様子を示す．\n図2-1: 実際のロボットと仮想空間上でのロボット（[8] より引用）\n6\nP´erez ら（2019）は，VR 技術を活用した人間とロボットの協調的なインターフェース\nを提案し，トレーニング，シミュレーション，そしてロボット制御を一体化した新たなア\nプローチを示した．この研究では，VR による没入型のトレーニング環境が，学習プロセ\nスの効率を高め，安全性を向上させることを実証している．さらに，VR 技術を活用する\nことで，ロボットプログラムの事前検証やエラー検出が可能となり，工場環境でのリスク\n軽減とコスト削減を実現した",
            "ロボットプログラムの事前検証やエラー検出が可能となり，工場環境でのリスク\n軽減とコスト削減を実現した[9]．図2-2，2-3 にP´erez らの提案するシステムで使用する\n実際のロボットと仮想空間上のインターフェースの様子を示す．\n図2-2: 実際のロボット（[9] より引用）\n図2-3: 仮想空間上のインターフェース（[9] より引用）\nHashimoto ら（2011）は，拡張現実（AR）技術を活用したロボットのリモート操作シ\nステム「TouchMe」を提案し，その有効性を検証した．このシステムでは，カメラを通じ\nた三人称視点の画像に仮想ロボットモデルを重ね合わせ，タッチスクリーン上で直感的な\n操作を可能にしている．特に，タッチ操作によるロボットの各部の直接的な操作が可能で\nあり，従来のジョイスティック操作のような高度な訓練が不要であることが特徴である．\n7\n研究では，操作スケジューリングの異なる3 つの手法を比較し，ユーザーの操作性や効率\n性を評価した．さらに，このシステムが初心者にも使いやすいことを示し，製造業などの\n産業分野におけるロボット操作の効率向上に寄与する可能性を提",
            "者にも使いやすいことを示し，製造業などの\n産業分野におけるロボット操作の効率向上に寄与する可能性を提案している．本研究は，\nAR 技術を用いた直感的なロボット操作の基盤を提供し，さらなる応用の可能性を広げて\nいる[10]．\nMakhataeva ら（2020）は，2015 年から2019 年の5 年間における拡張現実（AR）技術\nを用いたロボット工学の研究をレビューし，医療ロボット，動作計画と制御，人間とロ\nボットの相互作用（HRI），および群ロボットシステムの4 つのカテゴリに分類して分析\nを行った．この研究は，AR がロボット工学において如何に統合され，各分野にどのよう\nな改善をもたらしたかを詳細に探究している．また，AR がカメラのローカリゼーション\nや環境マッピングの課題に直面しつつも，効率性やヒューマン・マシン・インタラクショ\nンを大幅に向上させる可能性を示している．このレビューは，産業界を含むさまざまな分\n野でAR 技術がいかに適用される可能性があるかの基盤を提供しており，今後の研究方向\n性も示唆している[11]．\nBambuˇsek ら（2021）は，空間拡張現実（ISA",
            "後の研究方向\n性も示唆している[11]．\nBambuˇsek ら（2021）は，空間拡張現実（ISAR）とヘッドマウントディスプレイ（HMD）\nを組み合わせた手法による協働ロボットのエンドユーザープログラミングを提案した．本\n研究では，HMD とタッチテーブルを活用し，従来のキネステティック・ティーチングと比\n較して，作業負担の軽減とプログラミング速度の向上を目指した．20 名の被験者による\n評価実験では，タスク遂行の効率性とユーザー体験（UX）がそれぞれ33.84 ％，28.46 ％\n向上し，ロボット不在時のプログラミングが可能となる利点も示された．本研究は，ISAR\nとHMD の統合が協働ロボットの操作性向上に寄与することを示唆している[12]．\n2.1.2\n医療分野でのXR 研究\nElendu ら（2024）は，シミュレーションベースのトレーニング（SBT）の医療教育にお\nける重要性をレビューし，その進化と利点を概説した．本研究では，初期の訓練ツールか\nら高精度シミュレーターやバーチャルリアリティ（VR）環境への進展が詳述され，安全\nな環境下で技術的および非技術的スキルを練習でき",
            "チャルリアリティ（VR）環境への進展が詳述され，安全\nな環境下で技術的および非技術的スキルを練習できることや即時フィードバックを通じた\n学習者の能力向上の効果が示された．一方で，導入コストの高さや教員への専門的トレー\nニングの必要性，現実の臨床環境との相違といった課題も指摘されている．さらに，人工\n知能（AI）やVR 技術の進展がSBT のさらなる発展に寄与する可能性が論じられ，SBT\nが医療教育において不可欠なツールであると結論付けられた[13]．\n志賀ら（2020）は，複合現実（MR），拡張現実（AR），仮想空間（VR）技術をロボッ\nト支援腎部分切除術（RAPN）に応用し，その有用性を検討した．本研究では，術前患者\n画像を3D ホログラム化し，HoloLens を用いて手術中に活用した結果，腫瘍切除時間の短\n8\n縮や出血量の低減に寄与したことが示された．さらに，空間認識の向上や術者目線での手\n術記録を通じた教育効果も確認された．本研究は，MR およびVR 技術が手術支援や教育\nにおいて有用なツールであることを示し，これらの技術が医療分野におけるさらなる発展\nを促す可能性を強調してい",
            "て有用なツールであることを示し，これらの技術が医療分野におけるさらなる発展\nを促す可能性を強調している[14]．\n2.1.3\n教育分野でのXR 研究\n山元（2019）は，AR（拡張現実）とVR（仮想空間）の教育・学習支援への活用事例と\n課題を検討した．AR は現実環境に仮想情報を重ねることで認知負荷を軽減し，直感的な\n学習を支援する一方，VR は没入型環境を提供し，身体活動を伴う学習を可能にする利点\nが示された．しかし，導入にはコストや教員の専門知識不足が課題とされている．本研究\nは，AR/VR 独自の学習支援の可能性を探る重要性を強調している[15]．\n渡邉ら（2022）は，Mozilla Hubs を活用したVR 外国語教育の実践を報告し，学習者が\n体験的に学ぶことで中国語の定着を促進する効果を示した．VR 空間内での声調練習や対\n話型タスクにより，学習の動機づけと理解が向上し，オンライン授業の柔軟性も評価され\nた．今後は長期的な学習効果の検証が課題とされている[16]．\n2.1.4\nエンタメ分野でのXR 研究\nKohenら（2021）は，Microsoft HoloLens 2を",
            "\nエンタメ分野でのXR 研究\nKohenら（2021）は，Microsoft HoloLens 2を活用した拡張現実（AR）格闘ゲーム「HoloFight」\nを開発し，マルチプレイヤー型の没入体験を提供するシステムを提案した．本ゲームは，\nXbox コントローラーやHoloLens の空間認識機能を組み合わせることで，物理環境との\n連動や自然なキャラクター操作を可能にしている．また，プレイヤーが同一空間にいる場\n合の視点の自動調整機能や，異なる空間間で対戦できるリモートモードも搭載し，安全で\n柔軟なゲーム体験を実現している[17]．本研究は，AR 技術と従来型ゲームの要素を融合\nし，エンターテインメントの新たな可能性を探るとともに，COVID-19 パンデミック下で\nの安全な娯楽の提供を目指している．今後は，アバターの動作拡張や視線追跡機能の活用\nを進め，さらなる没入感を提供する予定である．\nHackl とAnthes（2021）は，拡張現実（AR）を活用したピアノ学習アプリケーション\n「HoloKeys」を開発し，その設計と実装を報告した．HoloKeys は，ヘッドマウントディス\n",
            "「HoloKeys」を開発し，その設計と実装を報告した．HoloKeys は，ヘッドマウントディス\nプレイ（HMD）を使用して，物理的なピアノの鍵盤に重ねて演奏すべきキーを表示する\nシステムであり，MIDI ファイルを利用して音楽データを動的に処理する[18]．\nこのアプリケーションは，ユーザーの位置をトラッキングし，適切に補強情報を表示す\nる機能を備える．また，リアルタイムの視覚的ガイドと音声出力を提供し，初心者でも効\n率的に楽曲を学習できるよう設計されている．さらに，ゲーム要素を取り入れることで学\n9\n習意欲を高める可能性が指摘されている．本研究は，AR 技術が音楽教育に与える可能性\nを示す一例であり，将来的にはより広範な楽器学習への応用が期待されている．\n2.2\n視覚的負荷に関する研究\nPavel ら（2023）は，コンピュータ視覚症候群（CVS），別名デジタル眼精疲労（DES）\nについて，デジタルデバイスの長時間使用に起因する眼科的，筋骨格系，および行動上の\n症状を引き起こす現代の病態として検討した．本論文では，CVS の主な環境的，眼科的，\n筋骨格系の原因をレビューし，デジタ",
            "の病態として検討した．本論文では，CVS の主な環境的，眼科的，\n筋骨格系の原因をレビューし，デジタルデバイスの使用頻度の増加とDES の高い有病率\nを考慮し，眼科医が質の高い研究に基づいた助言と管理オプションを提供することの重要\n性を強調している[19]．\nKaur ら（2022）は，デジタル眼精疲労（DES）の症状，原因，管理戦略を包括的にレ\nビューした．長時間のデジタルデバイス使用が乾燥感，かゆみ，頭痛，視力のぼやけなど\nを引き起こし，特にCOVID-19 パンデミック中に発生率が増加したと報告されている．管\n理には，エルゴノミクスの改善，20-20-20 ルールの実践，ブルーライトフィルターやアン\nチリフレクティブ眼鏡の使用が有効とされる．本研究は，DES の理解を深め，効果的な\n対策の開発を促進する重要性を示した[20]．\n伊藤ら（2020）は，スマートグラス（SG），液晶ディスプレイ（LCD），および印刷物\n（Paper）を用いた作業における眼精疲労の程度を比較検討した．77 名の学生および教員を\n対象に，それぞれの方法で1 時間の作業負荷を与え，フリッカー値，瞬き回数，調",
            " 名の学生および教員を\n対象に，それぞれの方法で1 時間の作業負荷を与え，フリッカー値，瞬き回数，調節微小\n振動の高周波成分（HFC），脈拍数，主観的疲労感を測定した．結果として，SG 使用時は\nLCD や印刷物に比べて瞬き回数の減少が少なく，眼精疲労が軽減される傾向が見られた．\nまた，主観的評価では，LCD や印刷物と比べ，SG の使用による疲労感は少なかった．こ\nれにより，SG を用いたハンズフリーマニュアル（HF マニュアル）は，作業中の眼精疲労\nが問題とならないことが示唆された[21]．\nHirota ら（2019）は，VR ヘッドマウントディスプレイ（VR-HMD）と2D ディスプレ\nイの視覚疲労への影響を比較評価した．視覚タスク後，両デバイスで双眼融合維持能力\n（BFM）の低下と主観的な眼症状スコアの増加が見られたが，有意差は認められなかった．\n本研究は，低い視覚誘発運動病（VIMS）を伴うVR コンテンツ使用時，VR-HMD の視覚\n疲労が2D ディスプレイと同程度であることを示唆している[22]．\nSouchet ら（2022）は，VR ヘッドマウントディスプレイ（VR",
            "とを示唆している[22]．\nSouchet ら（2022）は，VR ヘッドマウントディスプレイ（VR-HMD）を用いた学習に\nおける視覚疲労と認知負荷を眼球運動計測で評価する方法をレビューした．視覚疲労は\n瞬目頻度，認知負荷は瞳孔径の変化で測定されるが，両者の区別は課題であることが示さ\nれた．一方で，眼球運動計測は学習中のリアルタイム評価に有望であり，より精度の高い\n10\nデータ解釈モデルの開発が必要である．本研究は，VR 学習の効率向上と技術設計におけ\nる重要な基盤を提供している[23]．\nWang ら（2023）は，AR メガネを用いた2D および3D 視聴が視覚疲労と眼表面に与え\nる影響を比較した．1 時間の視聴後，視覚疲労は両モードで増加したが，2D 視聴後に脂\n質層厚（LLT）や瞬き頻度がより顕著に増加．一方，涙液破壊時間（NIBUT）や涙液メニ\nスカス高（TMH）には有意差はなかった．本研究は，AR メガネ視聴による視覚負荷を評\n価し，特に3D コンテンツが視覚的負荷を高める可能性を示唆している[24]．\n2.3\nAR/VR の比較に関する研究\nSouchet ら（2021",
            "可能性を示唆している[24]．\n2.3\nAR/VR の比較に関する研究\nSouchet ら（2021）は，VR およびAR を用いた没入型文化体験がユーザーエクスペリエ\nンスに与える影響を比較した．VR は高い没入感と感情的関与を促進し，AR は現実世界\nとの統合による直感的な操作性が評価された．ユーザーの満足度や学習効果の観点でいず\nれも有用であるが，利用目的に応じた技術選択の重要性が示された．本研究は，没入型技\n術の設計や応用における基盤を提供している[4]．\n2.4\n先行研究のまとめ\n従来の研究では，AR/VR 技術が製造業，医療，教育，エンターテインメントなど幅広\nい分野で活用されており，特にロボット操作や協調作業の効率化に寄与することが示され\nている．また，AR/VR の比較研究では，VR が没入感や感情的関与を強化し，AR が現実\n環境との統合による直感的な操作を可能にすることが明らかになっている．しかし，多感\n覚フィードバックを統合した評価や，視覚的負荷を考慮したAR/VR の適用に関する検討\nは十分ではない．そこで本研究では，ロボットアーム操作を題材にAR/VR の操作",
            " の適用に関する検討\nは十分ではない．そこで本研究では，ロボットアーム操作を題材にAR/VR の操作性や負\n荷の違いを明確にし，最適な環境設定指針を示すことを目的とする．\n11\n第3章\n拡張現実・仮想空間技術を用いたアームロ\nボット操作システム\n3.1\nシステム概要\n本研究で用いた拡張現実を用いたアームロボット操作システムは，阿部らが制作・開発\nした「拡張現実とインプットデバイスを用いたアームロボットリモートコントロールシス\nテム」であった（以下AR アプリケーションと記載）[25]．AR デバイスを装着した状態\nで，ハンドトラッキング機能を用い，仮想的に提示されたボタンを押し，同様に仮想的\nに提示されたアームロボットを操作し，ブロックを指定の位置まで移動させるというタス\nクを行うシステムとなっている．本研究では，AR アプリケーションをVR デバイスで使\n用できるよう移植し，両デバイスにて同様のタスクを行うことでタスク遂行時間，タスク\n中の瞬きの回数，主観評価に差異が生まれるのか比較を行った．そしてタスク中の瞬きの\n回数を取得するため，AR デバイス，VR デバイスにてタスクを行う際",
            "行った．そしてタスク中の瞬きの\n回数を取得するため，AR デバイス，VR デバイスにてタスクを行う際，それぞれ異なる\n視線情報取得デバイスを装着した．図3-1 に本システムの概要図を示す．また，図3-2 に\nAR アプリケーションの全体図を示す．\n図3-1: 本システムの概要図\n12\n図3-2: AR アプリケーションの全体図\n尚，AR アプリケーションを実装するデバイスとしてMicrosoft 社のHololens2 を用い\nる[26]．hololens2 は透過型のヘッドマウントディスプレイであり，前面に配置された\nRGB カメラ及び環境認識カメラを用いた高精度なハンドトラッキング機能を有している\nことに加えて別途のコントローラを必要とせずに操作を行うことが可能である点や幅広い\n視野角でユーザが快適かつ正確にホログラムを操作可能である点に優れており本システ\nムに適している．そして本研究では評価指標としてアプリケーションを操作している際の\n瞬きを検出するため，Pupil Labs 社が提供するhololens のadd-on を使用した[27]．また，\n本研究ではVR デバイスで同様",
            "提供するhololens のadd-on を使用した[27]．また，\n本研究ではVR デバイスで同様のタスクが行えるよう，このAR アプリケーションを元に\nVR デバイスで使用可能なアプリを開発した（以下，VR アプリケーションと記す）．VR\nアプリケーションの基本的なシステムはAR アプリケーションと同様であるが，ボタンを\n押す際の動作はハンドトラッキングではなく，コントローラの操作によって行う．図3-3\nにAR アプリケーションの全体図を示す．尚，VR アプリケーションを実装するデバイス\nとしてMeta 社のMeta Quest 3 は，VR アプリケーションを実装および実行するためのデ\nバイスであり，スタンドアロン型のヘッドセットとして広視野角および精密なトラッキン\nグを搭載することで，直感的な操作とスムーズなユーザー体験を可能にしており，本シス\nテムに適している[28]．そして瞬きを検出するための機器として，Pupil Lab 社が提供す\nるVR 用のadd-on を使用した[29]．図3-3 にVR アプリケーションの全体図を示す．\n13\n図3-3: VR アプリケーションの",
            "9]．図3-3 にVR アプリケーションの全体図を示す．\n13\n図3-3: VR アプリケーションの全体図\n3.2\nアプリケーションのタスク内容\n両アプリケーションでは同様のタスクを行う．アプリケーション内での目標は，ロボッ\nトアームの左側にある青色のブロックを，ロボットアームを操作しブロックをつかんで移\n動させ，緑色のブロックの位置まで移動させることである．このブロックを移動させる動\n作を3 回分行うことで，目標達成となる．アプリケーションを起動後，ユーザはアームロ\nボット，メニューボタン，スタートボタン及びリセットボタンが確認可能である（VR ア\nプリケーションの起動時の画面は図3-3 に示す）．この状態ではアームロボットの操作は\nできず，ボタンを押してもアームロボットは動作しない．この状態からスタートボタン\nを押すことでロボットアームの操作が可能となる．その後，矢印のボタンを押すことで，\nアームロボットを動かすができる．また，リセットボタンによりアームロボットを初期状\n態へ戻すことが可能である．初期状態ではアームロボットをブロックに近づけても掴むこ\nとができないが，「グラブ/リリ",
            "が可能である．初期状態ではアームロボットをブロックに近づけても掴むこ\nとができないが，「グラブ/リリースボタン」を押すことでブロックを掴むことが可能な状\n態へ移行することができる．そしてもう一度「グラブ/リリースボタン」を押すことでブ\nロックを離すと可能である．タスク実行中の様子を図3-4 に示す．\n14\n図3-4: タスク実行中の様子\n3.3\n使用デバイス\n本節では，このシステムを構成するデバイスの説明について述べる．\n3.3.1\nAR デバイス\n本研究で利用するAR デバイスは，Microsoft 社が開発したHoloLens2 である[26]．図\n3-5 に使用するHoloLens2 を示す．HoloLens 2 は本研究において，AR 環境でのタスク遂\n行システムの実行デバイスとして用いられた．ハンドトラッキング機能を活用し，被験者\nがAR 環境内で自然かつ直感的にタスクを操作することを可能にした．\n図3-5: Microsoft 社が開発した「HoloLens2」（[26] より引用）\n15\n3.3.2\nVR デバイス\n本研究で使用するVR デバイスは，Meta 社が開発した",
            "り引用）\n15\n3.3.2\nVR デバイス\n本研究で使用するVR デバイスは，Meta 社が開発した「Meta Quest 3」である[28]．図\n3-6 に使用するMeta Quest 3 を示す．Meta Quest 3 は本研究において，VR 環境でのタス\nク遂行システムの実行デバイスとして使用された．内蔵のセンサーによる高精度な位置\n追跡と，ハンドトラッキング機能を活用し，ユーザーがVR 空間内で直感的にタスクを操\n作できるようになっている．本デバイスは，被験者のVR 体験におけるユーザーインター\nフェースと操作性の評価を行うために重要な役割を果たした．\n図3-6: Meta 社が開発した「Meta Quest 3」（[28] より引用）\n3.3.3\nAR デバイスに装着する視線情報取得デバイス\n本研究では評価指標の一つとして実験中の瞬きの回数を用いるため，AR デバイス，VR\nデバイスにてそれぞれ視線情報取得デバイスを取り付けて使用した．\nAR デバイスとして使用したHoloLens 2 には，Pupil Labs 社が提供する「HoloLens Add-\non」を装着した[",
            "ens 2 には，Pupil Labs 社が提供する「HoloLens Add-\non」を装着した[27]．図3-7 に使用する「HoloLens Add-on」を示す．HoloLens Add-on は，\nPupil Core ヘッドセットに基づく高精度な視線追跡テクノロジーを搭載しており，左右の\n瞳孔の動きを正確に検出することができる．デバイスはHoloLens に無理なく取り付けら\nれるよう設計されており，ユーザーの視覚体験を妨げることなく動作する．また，視線\nデータはPupil Capture ソフトウェアを通じてリアルタイムで記録および分析され，瞬きや\n視線の移動パターンの詳細な解析が可能となる．なおこのデバイスは初代HoloLens [30]\nに対応するデバイスとして設計されているが，HoloLens2 には直接取り付けることができ\nないため，マスキングテープを用いて装着・固定化した（図3-7）\n16\n図3-7: HoloLens 用のアイトラッキング\nアドオン（[27] より引用）\n図3-8: 視線情報取得デバイスを装着し\nたHololens2\nしかし，この装着方法ではデ",
            "り引用）\n図3-8: 視線情報取得デバイスを装着し\nたHololens2\nしかし，この装着方法ではデバイスの安定性が十分ではなく，視線追跡の精度が低下し\nたため，瞬きや視線の移動パターンをリアルタイムで正確に取得することができなかった．\nそのため，Pupil Capture ソフトウェアを用いて実験中の目元の映像を録画し，後処理と\nして映像を手動で解析する方法を採用した．具体的には，録画された映像を確認し，被験\n者の瞬きの回数を目視でカウントした．このプロセスにより，リアルタイムで取得できな\nかったデータを補完し，瞬き回数に関する定量的な情報を得ることができた．図3-9 に実\n験中に収録した目元の映像の一例を示す．\n図3-9: HoloLens Add-on で収録した目元の映像\n3.3.4\nVR デバイスに装着する視線情報取得デバイス\nVR デバイスとして使用したMeta Quest3 には，Pupil Labs 社が開発した「Pupil Labs\nVR/AR Eye Tracking Module」を使用した[29]．図3-10 に使用する「Pupil Labs VR/AR\nEye",
            " Module」を使用した[29]．図3-10 に使用する「Pupil Labs VR/AR\nEye Tracking Module」を示す．このデバイスは，VR ヘッドセットに統合可能な高精度の\n17\n視線追跡システムであり，被験者の瞬きや視線移動をリアルタイムで記録・分析すること\nが可能である．本研究では，Meta Quest 3 にこのデバイスを装着し，VR 環境内でのタス\nク遂行中の視線情報を収集しVR 環境下での瞬きの頻度の定量的解析に活用された．\n図3-10: Pupil Labs VR/AR Eye Tracking Module（[29] より引用）\nPupil Labs VR/AR Eye Tracking Module は，視線情報をリアルタイムで確認および保存\nするための包括的なエコシステムを提供している．このデバイスは，Neon Companion と\n呼ばれるスマートフォンアプリ（図3-11）と連携して動作する[31]．有線接続を通じて，\n視線データをリアルタイムでアプリ上に表示することが可能であり，被験者の視線移動や\n瞬きの状況をその場で確認することができる",
            "ムでアプリ上に表示することが可能であり，被験者の視線移動や\n瞬きの状況をその場で確認することができる．\nNeon Companion には録画機能が備わっており，収録された映像データは自動的にPupil\nLabs が提供するPupil Cloud というクラウドプラットフォームにアップロードされる．こ\nのクラウドプラットフォーム（図3-12）では，録画された映像に基づく詳細な視線データ\nの解析が可能である[32]．瞬きの回数や視線移動のパターンといった定量的な情報も提\n供されるため，これらのデータを後処理で解析することにより，被験者がVR アプリケー\nションを操作している間の瞬き頻度を正確に評価することができた．\n18\n図3-11:\nスマホアプリ\n「Neon Companion」\n（[31]\nより引用）\n図3-12: Pupil Cloud のWEB ページ\n図3-13: 通信のフローチャート\n19\n本研究では，この機能を活用してMeta Quest 3 上でタスク遂行中の被験者の瞬きの回数\nを測定し，収集したデータを解析した．これにより，VR 環境下での瞬き頻度を定量的に\n評価するた",
            "回数\nを測定し，収集したデータを解析した．これにより，VR 環境下での瞬き頻度を定量的に\n評価するための信頼性の高いデータセットを構築することが可能となった．\n3.4\nソフトウェア開発\n3.4.1\nアプリケーション開発\n本節ではアプリケーション開発に用いたソフトウェアについて述べる．本研究ではクロ\nスプラットフォームのゲームエンジンであるUnity を使用してアプリケーションを開発し\nた．Unity は，高度なリアルタイムレンダリング機能を備え，多様なデバイスに対応する\nための柔軟な開発環境を提供する[33]．特に，HoloLens 2（AR）やMeta Quest 3（VR）\nといった異なるプラットフォーム上でアプリケーションを開発・実行できる点は，本研究\nの目的に非常に適している．また，Unity は基本機能を無料で利用可能であり，高性能な\nアプリケーションをコストを抑えて開発できるという利点もある．本研究のアプリケー\nション開発においては，以下の機能を実現するためにUnity を活用した．\n1. 視覚的ユーザーインターフェースの設計\n• 被験者が直感的に操作できるよう，タスク遂行",
            "用した．\n1. 視覚的ユーザーインターフェースの設計\n• 被験者が直感的に操作できるよう，タスク遂行中に必要な指示やフィードバッ\nクを表示するUI を設計した\n2. 実験シナリオの構築\n• AR およびVR 環境それぞれにおけるタスクシミュレーションを構築し，実験条\n件を再現可能な形で設定した\nAR アプリケーションは，HoloLens 2 上でロボットアームの操作を行うための機能を中\n心に設計されており，VR アプリケーションはMeta Quest 3 において同様の操作環境を再\n現する形で構築された．\n3.4.2\nAR アプリケーション開発\nAR アプリケーションの開発においては，Unity で使用可能なMicrosoft 社が提供する\nMixed Reality Toolkit（MRTK）を利用した[34]．MRTK は，HoloLens 2 をはじめとする\nMixed Reality デバイス向けに最適化された開発ツールキットであり，直感的なUI の設計\nやインタラクションの実装を効率的に行うことができる．本研究では，ロボットアーム\nを操作するためのボタンをMRTK の標準コン",
            "を効率的に行うことができる．本研究では，ロボットアーム\nを操作するためのボタンをMRTK の標準コンポーネントを用いて実装した．このボタン\nは，ハンドトラッキングを活用して被験者が自然な操作でタスクを遂行できるよう設計さ\n20\nれている．AR アプリケーションではユーザーはボタンを押すことでアームロボットを動\nかすことができるが，その手法は現在一般的に広く用いられているアームロボットのヘッ\nドの位置姿勢及びグリッパーの開閉をそれぞれ方向ボタン，グリッパー開閉ボタンを用い\nて決定し各関節角を逆運動を用いて決定することで操作する手法である．\n3.4.3\nVR アプリケーション開発\nVR アプリケーションの開発ではMRTK を使用せず，Meta Quest 3 に最適化された独自\nのアプローチを採用した．具体的には，Oculus Integration パッケージを用いてMeta Quest\nデバイスにおける操作やインタラクションを実現した．このパッケージは，Meta Quest\n向けの開発を効率化するためのツール群を提供しており，ハンドトラッキングやコント\nローラー操作の実装に利用された．",
            "効率化するためのツール群を提供しており，ハンドトラッキングやコント\nローラー操作の実装に利用された．ユーザーインターフェース（UI）の構築に際しては，\nCanvas システムを使用し，VR 環境内で視覚的に認識しやすい3D ボタンを作成した．こ\nれらのUI 要素は，被験者がコントローラーを通じて直感的に操作できるよう配置され，操\n作性を考慮したデザインとなっている．また，UI の配置やサイズ調整については，視覚的\nな快適性を確保するために，Meta Quest 3 の視野角や解像度に基づいて最適化を行った．\n21\n第4章\nユーザ評価実験\n4.1\n実験目的\n本章では，本研究で提案するシステムの有効性を検証するために実施したユーザ評価実\n験について述べる．ユーザ評価実験は，提案システムの操作性およびユーザー体験を定量\n的かつ定性的に評価することを目的として行われた．本実験では，従来手法と提案システ\nムを比較し，タスク遂行における効率性，正確性，直感的な操作性の向上を検証する．さ\nらに，実験中に得られた視線データを解析することで，認知的負荷やユーザーの主観的評\n価との関連性についても調査する",
            "に得られた視線データを解析することで，認知的負荷やユーザーの主観的評\n価との関連性についても調査する．\n4.2\n実験環境\n本実験では，使用するデバイスの特性が実験結果に与える影響を最小限に抑えるため，\n実験環境を慎重に設計した．特に，HoloLens 2 はシースルー型のヘッドマウントディスプ\nレイ（HMD）であり，現実世界の視界とデジタル情報を同時に提示する機能を持つ．こ\nの特性により，外部環境の違いが被験者の視覚的注意やタスク遂行に影響を与える可能\n性がある．そのため，本研究では外部環境の影響を排除するため，実験を行う部屋を固定\nし，すべての被験者が同一の環境で実験を行うようにした．被験者の向きも統一し，視界\nに壁のみが入るよう配置を調整することで，外部刺激を最小限に抑えた．また，部屋の照\n明や配置物も統一し，環境条件が一貫するよう配慮した．VR デバイスを使用した実験に\nついても，同様の環境条件下で実施した．VR デバイスであるMeta Quest 3 は，完全に仮\n想空間内での体験を提供するため，被験者が外部環境を視覚的に認識することはない．し\nかし，外部環境の変化が被験者の心",
            "験を提供するため，被験者が外部環境を視覚的に認識することはない．し\nかし，外部環境の変化が被験者の心理的状態や実験中の集中度に影響を与える可能性を排\n除するため，HoloLens 2 の実験と同じ固定された部屋で行い，実験条件の一貫性を確保し\nた．被験者は20 代の男女10 名であり，AR アプリケーションシステムとVR アプリケー\nションシステムの比較実験を行った．\n4.3\n実験方法\n本研究では，提案するAR アプリケーションシステムおよびVR アプリケーションシス\nテムの操作性やユーザー体験を評価するため，被験者にそれぞれのシステムを一度ずつ\n22\n体験してもらう形式で実験を実施した．各被験者は，AR アプリケーションシステムおよ\nびVR アプリケーションシステムを使用してタスクを遂行した．2 つのシステム間の体験\nが連続すると，被験者の疲労や集中力の低下がタスク遂行に影響を与える可能性がある\nため，各システムの体験の間に5 分間の休憩を設けた．また，どちらのシステムを先に使\n用するかによって，被験者がシステム操作に慣れてしまうことでタスク遂行時間に偏り\nが生じる可能性を考慮した．",
            "かによって，被験者がシステム操作に慣れてしまうことでタスク遂行時間に偏り\nが生じる可能性を考慮した．この影響を排除するため，被験者10 人を2 つのグループに\n分け，5 人にはAR アプリケーションを先に体験してもらい，残りの5 人にはVR アプリ\nケーションを先に体験してもらうようランダムに割り当てた．これにより，両システムの\nタスク遂行における公平な比較が可能となり，システム間の特性や操作性に関する偏りの\nないデータを取得することを目指した．図4-1 に実験の手順を示す．\n図4-1: 実験の手順を示すフロー図\n本実験で被験者に与えられたタスクは，アプリケーション内で3 つのブロックをそれぞ\nれ指定された位置まで移動させる作業である．このタスクは，AR およびVR アプリケー\nションを使用して行われ，ロボットアームを操作することでブロックを掴み，指定された\n位置に正確に配置することを求められる．被験者は，まずアプリケーション内でブロッ\nクが配置されている初期位置を確認した後，ロボットアームを操作してブロックを掴む．\n次に，指示された目標位置までロボットアームを動かし，ブロックを所定の",
            "ームを操作してブロックを掴む．\n次に，指示された目標位置までロボットアームを動かし，ブロックを所定の位置に配置す\nる．この手順を3 つのブロックそれぞれに対して繰り返し，全てのブロックを正確に配置\n23\nすることがタスク完了の条件となる．このタスクは，ロボットアーム操作における正確\n性，効率性，および直感的な操作性を評価する目的で設計されており，AR およびVR シ\nステムの比較を可能にするよう構築されている．\n4.4\n評価方法\n4.4.1\n定量評価指標\n本研究では，AR およびVR アプリケーションの操作性やユーザー体験を評価するため\nに，定量評価指標としてタスク実行時間とタスク実行中の1 分当たりの瞬目回数を用い\nた．タスク実行時間は，被験者がアプリケーション内で3 つのブロックを全て指定の位置\nに正確に配置するまでに要した時間として計測された．瞬目回数は，タスク実行中にお\nける瞬目の総回数を測定し，1 分間あたりの平均回数として算出された．タスク実行時間\nは，ボットアームを正確かつ効率的に操作できたかという操作性と，ボタンが押しやす\nくUI が操作に適しているかというインターフェ",
            "効率的に操作できたかという操作性と，ボタンが押しやす\nくUI が操作に適しているかというインターフェースの使いやすさの2 点の観点でアプリ\nケーションの性能を測定するために選定した．タスク実行中の1 分当たりの瞬目回数は，\nAR およびVR デバイスを使用する際の視覚的負荷を測定するために選定した．\n4.4.2\n主観的な評価の指標\n被験者がAR およびVR アプリケーションを使用した際の主観的な操作のしやすさを評\n価するために，System Usability Scale（SUS）を用いた[35]．SUS は，システム全体の使\nいやすさを評価するための信頼性が高く広く使用されている10 項目のアンケート形式の\n評価指標である．被験者には，それぞれのアプリケーションを体験した後に，SUS アン\nケートに回答してもらった．アンケート項目は，システムが簡単に使えたか，必要な機能\nが適切に提供されていたか，また使用中に困難を感じたかといった視点に基づいており，\n5 段階のリッカート尺度で評価された．各回答はスコアとして集計され，0 から100 の範\n囲で使いやすさを定量的に測定するSUS にお",
            "た．各回答はスコアとして集計され，0 から100 の範\n囲で使いやすさを定量的に測定するSUS におけるスコアの基準を表4-1 に示す．\nこれに加え，主観的にアームロボットの操作が容易かつ意図した通りに行えたか，文字\nやオブジェクトが見やすかったかという視認性及びUI を評価するため独自に作成したア\nンケートを用いた．\n24\n表4-1: SUS におけるスコアと評価の対応\nSUS score\nGrade\nAdjective Rating\n>80.3\nA\nExcellent\n68 - 80.3\nB\nGood\n68\nC\nOkay\n51 - 68\nD\nPoor\n<51\nE\nAwful\n25\n第5章\n実験結果及び考察\n5.1\n定量評価の実験結果及び考察\n図5-1 にAR アプリケーション及びVR アプリケーションでのタスク完了時間の比較を\n示す．エラーバーは標準誤差を示す．AR アプリケーションとVR アプリケーションのタ\nスク完了時間を比較した結果，VR アプリケーションにてタスクを行った際はAR アプリ\nケーションに比べてタスク完了時間が短縮されることが示され，二つの手法間のタスク完\n了時",
            "AR アプリ\nケーションに比べてタスク完了時間が短縮されることが示され，二つの手法間のタスク完\n了時間には有意差が見られた．VR アプリケーションでの操作は，コントローラを動かし\nポインタをボタンの位置に合わせて，コントローラのボタンを押すことでアームロボット\nを操作することができ，操作が直感的に感じられたところがタスク完了時間の短縮に寄与\nしたと考えられる．AR アプリケーションではハンドトラッキング機能を用いて実際の指\nの動きでボタンを押すため，デバイスが指の動き正確に認識できず意図した通りの操作が\n難しい一方でVR アプリケーションではアームロボットを動かしたい方向のボタンに向け\nてコントローラを動かすのみで操作可能であるため，意図した通りの操作が可能である点\nもタスク完了時間の短縮に寄与したと考えられる．\n26\n図5-1: AR 及びVR アプリケーションでのタスク完了時間の比較\n図5-2 にAR アプリケーション及びVR アプリケーション実行中の1 分当たりの瞬目回数\nの比較を示す．エラーバーは標準誤差を示す．この項目を比較した結果，AR アプリケー\nションにてタスクを行った",
            "示す．エラーバーは標準誤差を示す．この項目を比較した結果，AR アプリケー\nションにてタスクを行った際に瞬目回数が減少することが示され，二つの手法間の実行中\nの1 分当たりの瞬目回数には有意差が見られた．2 つのアプリケーションにて表示される\nオブジェクトは同じであるが，VR アプリケーションでは完全な仮想空間上に表示される\nのに対して，AR アプリケーションでは実空間に重ねてオブジェクトが表示されるため，\nオブジェクトとの距離感がつかみづらく，オブジェクトをより注視しなければならなかっ\nたことが瞬目回数に影響したと考えられる．\n27\n図5-2: AR 及びVR アプリケーション実行中の1 分当たりの瞬目回数\n5.2\n主観的な操作のしやすさの実験結果と考察\n表5-1 にAR 及びVR アプリケーションにおけるSUS スコアの平均を示す．結果とし\nて，AR アプリケーションでは54.8 点でありVR アプリケーションでは70.8 点であり，一\n般に良いシステムとされる68 点という基準をVR アプリケーションでは満たしたが，AR\nアプリケーションでは下回る結果となった．VR アプリケーシ",
            "R アプリケーションでは満たしたが，AR\nアプリケーションでは下回る結果となった．VR アプリケーションとAR アプリケーショ\nンでは操作開始時にスタートボタンを押すことや任意のタイミングでメニューボタンを\n押すことで操作が中断可能であること，リセットボタンを押すことでアームロボットを初\n期姿勢に戻すことが可能であることは共通である．今回の研究ではどちらのアプリケー\nションでもアームロボットの頭部の位置や姿勢，グリッパーの制御を全てボタンで行うた\nめボタン数が多い．AR アプリケーションではハンドトラッキング機能を用いて指でボタ\nンをそして操作するため，ハンドトラッキングの精度によって自分の意図の通りにボタン\nを操作できない事例がたびたび起きた．このことがシステム全体に対して使用することが\n28\n難しいと感じさせ，基準を下回る結果になったと考えられる．これに対しVR アプリケー\nションではコントローラのポインタを合わせるだけでボタンを押すことができるため，操\n作中のシステムの仕様が容易であると感じさせることができ，基準を満たす結果になった\nと考えられる．\n表5-1: AR アプリケーシ",
            "あると感じさせることができ，基準を満たす結果になった\nと考えられる．\n表5-1: AR アプリケーション及びVR アプリケーションにおける平均SUS スコア\n手法\nSUS スコア\nAR\n54.8\nVR\n70.8\n以下にアンケート評価の結果と考察を述べる．アンケートの各項目は「全く思わない」\nを1，「非常に思う」を5 としてスコアリングした．また，スコアリングした値を用いて各\nモードの各項目の平均スコアを算出した．表5-2 に被験者に回答してもらったアンケート\n項目及び表5-3 にアンケート評価結果を示す．アンケートの各項目について考察を行う．\n表5-2: 評価実験のアンケート項目\nquestion\nQ1 アームロボットの操作は直感的に感じましたか？\nQ2 アームロボットの操作は難しく感じましたか？\nQ3 アームロボットの操作の精度に満足していますか？\nQ4 アームロボットの操作の習得は容易であると感じましたか？\nQ5 操作のインターフェースは理解しやすかったですか？\nQ6 課されたタスクは難しいと感じましたか？\nQ7 アームロボットは意図した通りに動きましたか？\nQ8 アームロボットの",
            "は難しいと感じましたか？\nQ7 アームロボットは意図した通りに動きましたか？\nQ8 アームロボットの操作中に目の疲労を感じましたか？\nQ9 アームロボットの操作中に体の疲労を感じましたか？\nQ10 画面上の文字や情報が見やすかったですか？\nQ11 ロボットアームやブロックの位置が正確に認識できましたか？\nQ12 ロボットアームとブロックとの距離感を正確に掴めましたか？\nQ13 デバイスを使用している間，視界に違和感や疲れを感じましたか？\nQ14 自分の意図の通りにボタンが押せましたか？\nQ15 ロボットアームの微調整が簡単に行えると感じましたか？\nQ16 長時間の操作でも，快適に作業を続けられると感じましたか？\n29\n表5-3: 評価実験のアンケート結果\n質問番号\nAR\nVR\nQ1\n3.9\n4.5\nQ2\n4.0\n2.1\nQ3\n3.0\n4.1\nQ4\n3.4\n1.8\nQ5\n4.4\n4.4\nQ6\n3.4\n2.4\nQ7\n2.9\n3.8\nQ8\n3.7\n2.1\nQ9\n1.9\n1.9\nQ10\n3.4\n4.6\nQ11\n3.2\n4.2\nQ12\n3.3\n3.8\nQ13\n3.1\n2.1\nQ14\n3.0\n4.",
            "4.6\nQ11\n3.2\n4.2\nQ12\n3.3\n3.8\nQ13\n3.1\n2.1\nQ14\n3.0\n4.7\nQ15\n3.0\n4.3\nQ16\n2.4\n3.7\nQ1 アームロボットの操作は直感的に感じましたか？\nAR アプリケーションとVR アプリケーションの比較において，AR アプリケーショ\nンで3.9 点であり，VR アプリケーションで4.9 点という結果になった．2 つの手法\nではボタンを用いてアームロボットを操作するという操作手法は共通しているが，\nAR アプリケーションではハンドトラッキング機能を用いて指でボタンを押すため，\nデバイスが指を正確に認識できなければボタンを押すことができない．その事象に\nよって，直感的ではないと感じられたと考えられる．一方でVR アプリケーション\nではコントローラのポインタを合わせてコントローラのボタンを押すのみで操作が\n行えるため，操作がより容易に感じられたと考えられる．\nQ2 アームロボットの操作は難しく感じましたか？\nAR アプリケーションとVR アプリケーションの比較において，AR アプリケーショ\nンで4.0 点であり，VR アプリケーションで2",
            "プリケーションの比較において，AR アプリケーショ\nンで4.0 点であり，VR アプリケーションで2.1 点という結果になった．AR アプリ\nケーションではデバイスの構成上一度に画面内に表示できる情報がVR アプリケー\nションに比べ限られているため，ボタンを操作する際はアームロボットとブロック\nがある位置から視線を移動させ，ボタンがある方向を向かなければならない．その\nため，VR アプリケーションと比較して操作に必要な手順が1 つ多くなってしまうこ\nとが，主観的な操作の難しさに影響を与えたと考えられる．\nQ3 アームロボットの操作の精度に満足していますか？\nAR アプリケーションとVR アプリケーションの比較において，AR アプリケーショ\nンで3.0 点であり，VR アプリケーションで4.1 点という結果になった．本システム\nでは，ボタンを押し続けることでロボットアームを動かし続けることが可能である\n30\nが，VR アプリケーションでは，コントローラのボタンによって，ロボットアーム操\n作のボタンを容易に押すことが可能である．一方で，AR アプリケーションではハン\nドトラッキングにより正",
            "のボタンを容易に押すことが可能である．一方で，AR アプリケーションではハン\nドトラッキングにより正確なボタン入力が難しい場合があり，精度に対する満足度\nが低下したと考えられる．\nQ4 アームロボットの操作の習得は容易であると感じましたか？\nAR アプリケーションとVR アプリケーションの比較において，AR アプリケーショ\nンで3.4 点であり，VR アプリケーションで1.8 点という結果になった．Q1 で述べた\n通り，AR アプリケーションではハンドトラッキング機能で指を認識してボタンを押\nさなければならないため，デバイスが指を正しく認識できないときに意図通りの操\n作ができないという点が影響したと考えられる．\nQ5 操作のインターフェースは理解しやすかったですか？\nAR アプリケーションとVR アプリケーションの比較において，AR アプリケーショ\nンで4.4 点であり，VR アプリケーションで4.4 点という結果になり，評価に差は見\nられなかった．この結果は，両アプリケーションで同じUI が使用されていることが\n影響していると考えられる．\nQ6 課されたタスクは難しいと感じましたか？",
            "I が使用されていることが\n影響していると考えられる．\nQ6 課されたタスクは難しいと感じましたか？\nAR アプリケーションとVR アプリケーションの比較において，AR アプリケーショ\nンで3.4 点であり，VR アプリケーションで2.4 点という結果になった．両アプリケー\nションで課されたタスクは同じであったが，この違いは，Q2 やQ3 で述べたように，\nAR アプリケーションでは操作の容易さや精度においてVR に劣る点が影響したと考\nえられる．\nQ7 アームロボットは意図した通りに動きましたか？\nAR アプリケーションとVR アプリケーションの比較において，AR アプリケーショ\nンで2.9 点であり，VR アプリケーションで3.8 点という結果となり，VR アプリケー\nションの方が高評価であった．この結果は，Q3 で述べたようにVR の方が操作の精\n度が高いことが影響したと考えられる．\nQ8 アームロボットの操作中に目の疲労を感じましたか？\nAR アプリケーションとVR アプリケーションの比較において，AR アプリケーショ\nンで3.7 点であり，VR アプリケーションで2.1 点と",
            "ョンの比較において，AR アプリケーショ\nンで3.7 点であり，VR アプリケーションで2.1 点という結果となり，AR アプリケー\nションの方が疲労感が強く感じられた．この理由として，AR は実世界にオブジェ\nクトを重ねて表示する特性上，オブジェクトとの距離感が正しく測りづらいことで，\n被験者がより注視しなければならない点が挙げられる．\n31\nQ9 アームロボットの操作中に体の疲労を感じましたか？\nAR アプリケーションとVR アプリケーションの比較において，AR アプリケーショ\nンで1.9 点であり，VR アプリケーションで1.9 点という結果となり，評価に差は見\nられなかった．\nQ10 画面上の文字や情報が見やすかったですか？\nAR アプリケーションとVR アプリケーションの比較において，AR アプリケーショ\nンで3.4 点であり，VR アプリケーションで4.6 点という結果となり，VR アプリケー\nションの方が高評価であった．この理由として，Q8 で述べたような距離感の問題が\nVR では解消されていることが寄与したと考えられる．\nQ11 ロボットアームやブロックの位置が正確に認",
            "R では解消されていることが寄与したと考えられる．\nQ11 ロボットアームやブロックの位置が正確に認識できましたか？\nAR アプリケーションとVR アプリケーションの比較において，AR アプリケーショ\nンで3.2 点であり，VR アプリケーションで4.2 点という結果となり，VR アプリケー\nションの方が高評価であった．この結果も，Q8 で述べた距離感に起因する問題が関\n係していると考えられる．\nQ12 ロボットアームとブロックとの距離感を正確に掴めましたか？\nAR アプリケーションとVR アプリケーションの比較において，AR アプリケーショ\nンで3.3 点であり，VR アプリケーションで3.8 点という結果となり，VR アプリケー\nションの方が高評価であった．この結果も，Q8 で述べた理由と同様に，距離感を掴\nみやすい点が評価に影響したと考えられる．\nQ13 デバイスを使用している間，視界に違和感や疲れを感じましたか？\nAR アプリケーションとVR アプリケーションの比較において，AR アプリケーショ\nンで3.1 点であり，VR アプリケーションで2.1 点という結果となり，AR ア",
            " アプリケーショ\nンで3.1 点であり，VR アプリケーションで2.1 点という結果となり，AR アプリケー\nションの方が疲れを感じたと評価された．この理由として，Q2 で述べたように，AR\nデバイスでは一度に表示できる情報が限られており，視界の端にあるオブジェクト\nが見えづらいことが影響したと考えられる．\nQ14 自分の意図の通りにボタンが押せましたか？\nAR アプリケーションとVR アプリケーションの比較において，AR アプリケーショ\nンで3 点であり，VR アプリケーションで4.7 点という結果となり，VR アプリケー\nションの方が高評価であった. この結果は，Q1 で述べたように，VR の方が操作の直\n感性が高いことが影響していると考えられる．\nQ15 ロボットアームの微調整が簡単に行えると感じましたか？\nAR アプリケーションとVR アプリケーションの比較において，AR アプリケーショ\n32\nンで3 点であり，VR アプリケーションで4.3 点という結果となり，VR アプリケー\nションの方が高評価であった．この結果は，Q3 やQ14 で述べたように，VR ではボ\nタンの押しや",
            "\nションの方が高評価であった．この結果は，Q3 やQ14 で述べたように，VR ではボ\nタンの押しやすさや操作の精度が高いことが寄与していると考えられる．\nQ16 長時間の操作でも，快適に作業を続けられると感じましたか？\nAR アプリケーションとVR アプリケーションの比較において，AR アプリケーショ\nンで2.4 点であり，VR アプリケーションで3.7 点という結果となり，VR アプリケー\nションの方が高評価であった．この結果は，Q3 やQ8 で述べたように，VR では操\n作の精度が高いことと視覚的負荷が小さいことが寄与していると考えられる．\n33\n第6章\n結論と今後の展望\n6.1\n結論\n本研究では，AR およびVR 技術が市場規模の拡大とともにエンターテインメント，医\n療，製造業など多岐にわたる業界で活用されている中で，両技術の差別化が明確でない点\nに着目した．特に，製造業界におけるロボットアームの操作システムを題材に，既存の\nAR アプリケーションをVR デバイス向けに移植・開発し，両システムを比較する評価実\n験を行った．\nAR およびVR アプリケーションはどちらもボタン操作",
            "し，両システムを比較する評価実\n験を行った．\nAR およびVR アプリケーションはどちらもボタン操作によるロボットアームの制御を\n目的としたが，AR ではハンドトラッキング機能を用いて指でボタンを押す一方，VR で\nはコントローラを用いてボタンを操作するという違いがあった．評価実験の結果，以下の\n点が明らかになった．\nタスク完了時間\nVR アプリケーションではタスク完了までの時間が有意に短く，操作の効率性に優れ\nていることが確認された．これは，コントローラを用いたVR アプリケーションで\nは，ボタン操作が容易で意図した通りの動きを行いやすいためと考えられる．\n瞬目回数\nAR アプリケーションでは，タスク実行中の瞬目回数が有意に少ないという結果が得\nられた．これは，AR が現実世界に仮想オブジェクトを重ねる特性上，オブジェクト\nとの距離感がつかみにくく，ユーザーがより注視する必要があったためと推察され\nる．一方，VR は完全な仮想空間であるため，視覚的な負荷が軽減されていると考え\nられる．\nシステムの使いやすさ\nSUS（System Usability Scale）の結果から，AR アプ",
            "\nシステムの使いやすさ\nSUS（System Usability Scale）の結果から，AR アプリケーションは基準を満たさず，\n操作が難しいと評価された．一方，VR アプリケーションは一定以上の使いやすさを\n持つシステムであることが示された．また，アンケート結果においても，VR アプリ\nケーションが従来手法に比べ直感的かつ容易で，意図した通りの操作が可能である\nという点で高い評価を得た．\n34\n以上の結果から，ロボットアームの操作システムに関してはVR アプリケーションは操\n作性や効率性，使いやすさにおいて優れていることが明らかとなった．また，本研究で対\n象としたような実世界のオブジェクトを必要としないタスクにおいては，仮想オブジェク\nトの視認性に優れるVR アプリケーションの方が使用者にとって高い評価を得やすい可能\n性があると考えられる．\n6.2\n今後の展望\n本研究では，AR およびVR を用いたアームロボット操作システムの比較評価を行い，両\nシステムの特性や性能に関する知見を得た．しかし，本研究の評価実験では各操作手法で\n一回のみタスクを行ったため，操作手法への慣れによる操作の",
            "．しかし，本研究の評価実験では各操作手法で\n一回のみタスクを行ったため，操作手法への慣れによる操作のしやすさやタスク実行時間\nの変化，両手法間の差異については十分に明らかにされていない．今後は，異なるタスク\nを対象とした比較，評価を行い，AR およびVR がどのような場面で適しているかをより\n詳細に検討する必要がある．例えば，本研究ではロボットアームの操作を対象としたが，\n医療現場における手術シミュレーションなど，実世界における複雑な作業環境を想定した\nタスクに適用することで，AR とVR の特性がどのように異なるかを明確にすることがで\nきる．\nさらに，本研究ではタスク遂行時間や主観的評価を主な指標としたが，今後の研究では，\n異なる評価指標を用いた比較，評価も重要となる．例えば，本研究では視覚的負荷に焦点\nを当てたが，HMD を使用することによる首や肩への身体的負荷，長時間使用による疲労，\nさらにVR 環境特有の酔いやすさ（サイバーモーションシックネス）などの生理的影響も\n評価する必要がある．特に，HMD の重量や装着時間が首や肩の筋疲労に与える影響を測\n定することで，AR とVR の",
            "ある．特に，HMD の重量や装着時間が首や肩の筋疲労に与える影響を測\n定することで，AR とVR の長時間使用時の快適性を比較できると考えられる．また，使\n用者がどの程度VR 酔いを感じるかを定量化することで，異なるタスクにおけるVR の適\n用可能性についてもより詳細な検討が可能となる．こうした評価指標を導入することで，\nAR/VR 環境がユーザーに与える影響をより多角的に分析できると考えられる．\n加えて，これらの知見をもとに，負荷軽減と操作性向上のための環境設定やシステム\n開発を進めることが求められる．具体的には，視覚的負荷の軽減を目的としたインター\nフェース設計や，適切なタスク環境の構築を通じて，ユーザーがより直感的かつ効率的に\nタスクを遂行できるシステムの開発が期待される．今後の研究を通じて，AR およびVR\nの適用可能性をより広範囲に明らかにし，それぞれの技術の特性を最大限に活かしたシス\nテム設計の指針を提供することが目標である．\n35\n謝辞\n本研究を進めるうえで，親身に相談に乗って下さった青山学院大学理工学部情報テクノ\nロジー学科ロペズ・ギヨーム教授に深く感謝をいたします．ま",
            "って下さった青山学院大学理工学部情報テクノ\nロジー学科ロペズ・ギヨーム教授に深く感謝をいたします．また，自身が制作されたAR\nのロボットアーム操作システムを本研究において使用することを快諾してくださり，さら\nにVR アプリケーション開発の際に助言をいただいた阿部先輩にも心より感謝申し上げま\nす．研究環境の補助をしてくださった大熊氏，論文の添削を通してアドバイスをくださっ\nた高橋先輩をはじめとするロペズ研究室の院生の方々，同期の方々に深く感謝いたしま\nす．また，実験に協力していただいた被験者の方々にも感謝いたします．\n2025 年1 月28 日\n田中崇登\n36\n参考文献\n[1] 神原誠之：拡張現実感（Augmented Reality: AR）概論，情報処理，Vol. 51, No. 4, pp.\n367–372 (2010).\n[2] 富士キメラ総研：『AR ／VR 関連市場の将来展望2020』まとまる，https://www.\nfcr.co.jp/pr/20088.htm (2020).\n[3] 経済産業省：令和２年度コンテンツ海外展開促進事業（仮想空間の今後の可能性と諸課\n題に関す",
            ".\n[3] 経済産業省：令和２年度コンテンツ海外展開促進事業（仮想空間の今後の可能性と諸課\n題に関する調査分析事業），https://www.meti.go.jp/policy/mono_info_\nservice/contents/downloadfiles/report/kasou-houkoku.pdf\n(2021).\n[4] Verhulst, I., Woods, A., Whittaker, L., Bennett, J. and Dalton, P.: Do VR and AR versions\nof an immersive cultural experience engender different user experiences?, Computers in\nHuman Behavior, Vol. 125, p. 106951 (2021).\n[5] Fujitsu: その課題、情くんにおまかせ！第10 話，https://jp.fujitsu.com/\nplatform/server/advantages/special/jokun/10-ar/ (2013)",
            "form/server/advantages/special/jokun/10-ar/ (2013).\n[6] Tenaris:\nVR\nand\nAR\ntechnology\nused\nto\nmanage\nArgentine\nproject\nfrom\nItaly,\nhttps://www.tenaris.com/en/news/2021/\nvr-and-ar-technology-used-to-manage-argentine-project-from-italy\n(2021).\n[7] 三菱重工技報：MR グラス活用による現場作業効率化，https://www.mhi.co.\njp/technology/review/pdf/593/593090.pdf (2022).\n[8] Rom´an-Ib´a˜nez, V., Pujol-L´opez, F. A., Mora-Mora, H., Pertegal-Felices, M. L. and\nJimeno-Morenilla, A.: A low-cost immersive virtual reality system for t",
            " A low-cost immersive virtual reality system for teaching robotic\nmanipulators programming, Sustainability, Vol. 10, No. 4, p. 1102 (2018).\n[9] P´erez, L., Diez, E., Usamentiaga, R. and Garc´ıa, D. F.: Industrial robot control and opera-\ntor training using virtual reality interfaces, Computers in Industry, Vol. 109, pp. 114–120\n(2019).\n37\n[10] Hashimoto, S., Ishida, A., Inami, M. and Igarashi, T.: Touchme: An augmented reality\nbased remote robot manipulation, Vol. 2 (2011).\n[11] Makhataeva, Z. a",
            "manipulation, Vol. 2 (2011).\n[11] Makhataeva, Z. and Varol, H. A.: Augmented reality for robotics: A review, Robotics,\nVol. 9, No. 2, p. 21 (2020).\n[12] Bambuˆsek, D., Materna, Z., Kapinus, M., Beran, V. and Smrˇz, P.: Combining interac-\ntive spatial augmented reality with head-mounted display for end-user collaborative robot\nprogramming, pp. 1–8 (2019).\n[13] Elendu, C., Amaechi, D. C., Okatta, A. U., Amaechi, E. C., Elendu, T. C., Ezeh, C. P. and\nElendu, I. D.: The impact of simulation-based tr",
            "d\nElendu, I. D.: The impact of simulation-based training in medical education: A review,\nMedicine, Vol. 103, No. 27, p. e38813 (2024).\n[14] 志賀淑之，杉本真樹，安部光洋，錦見礼央，保科勇斗，米岡祐輔，斎川周，井上泰，\n吉松正，日下部将史ほか：複合現実MR, 拡張現実AR, 仮想現実VR を応用した泌\n尿器ナビゲーション手術の検討，Japanese Journal of Endourology, Vol. 31, No. 2, pp.\n253–259 (2018).\n[15] 山元翔：AR/VR の教育・学習支援システムへの利用と課題，教育システム情報学会\n誌，Vol. 36, No. 2, pp. 49–56 (2019).\n[16] 渡邉ゆきこ，小渡悟，大前智美：VR 空間内での活動を経験記憶につなげる外国語教\n育，pp. 199–202 (2022).\n[17] Kohen, S., Elvezio, C. and Feiner, S.: Ho",
            "2).\n[17] Kohen, S., Elvezio, C. and Feiner, S.: HoloFight: An augmented reality ﬁghting game, pp.\n1–2 (2021).\n[18] Hackl, D. and Anthes, C.: HoloKeys-an augmented reality application for learning the\npiano., pp. 140–144 (2017).\n[19] Pavel, I. A., Bogdanici, C. M., Donica, V. C., Anton, N., Savu, B., Chiriac, C. P., Pavel,\nC. D. and Salavastru, S. C.: Computer Vision Syndrome: An Ophthalmic Pathology of\nthe Modern Era, Medicina, Vol. 59, No. 2, p. 412 (online), https://doi.org/10.\n3390/medicina59",
            " 412 (online), https://doi.org/10.\n3390/medicina59020412 (2023).\n[20] Kaur, K., Gurnani, B., Nayak, S., Deori, N., Kaur, S., Jethani, J., Singh, D., Agarkar,\nS., Hussaindeen, J. R., Sukhija, J. and Mishra, D.: Digital Eye Strain- A Comprehensive\nReview, Ophthalmology and Therapy, Vol. 11, No. 3, pp. 1655–1680 (online), https:\n//doi.org/10.1007/s40123-022-00466-5 (2022).\n38\n[21] 伊藤奈々，武田朴，笠井亮佑，上條史記，加納敬，島峰徹也，荻野稔，日向奈惠，篠原\n一彦，田仲浩平：VDT 作業における眼精疲労度の比較―スマートグラスとLCD お\nよび印刷物の比較―，医療機器学，Vol. 90, No. 5, pp. 40",
            "ートグラスとLCD お\nよび印刷物の比較―，医療機器学，Vol. 90, No. 5, pp. 405–413 (2020).\n[22] Hirota, M., Kanda, H., Endo, T., Miyoshi, T., Miyagawa, S., Hirohara, Y., Yamaguchi,\nT., Saika, M., Morimoto, T. and Fujikado, T.: Comparison of visual fatigue caused by\nhead-mounted display for virtual reality and two-dimensional display using objective and\nsubjective evaluation, Ergonomics, Vol. 62, No. 6, pp. 759–766 (2019).\n[23] Souchet, A. D., Philippe, S., Lourdeaux, D. and Leroy, L.: Measuring visual fatigue and\ncognitiv",
            "d Leroy, L.: Measuring visual fatigue and\ncognitive load via eye tracking while learning with virtual reality head-mounted displays:\nA review, International Journal of Human–Computer Interaction, Vol. 38, No. 9, pp. 801–\n824 (2022).\n[24] Wang, X., Liu, L., Hu, X., Wu, Y., Liu, Y., Ni, B. and Ke, B.: Comparison of changes in\nvisual fatigue and ocular surface after 3D and 2D viewing with augmented reality glasses,\nDisplays, Vol. 78, p. 102401 (2023).\n[25] H.Abe，Bataller, V. B.，H.Ter¨av¨a，M．Luimula",
            ").\n[25] H.Abe，Bataller, V. B.，H.Ter¨av¨a，M．Luimula，G．Lopez：Combining AR and ball-\nshape input interface to control remotely a robot-arm, AHFE Open Access, Vol. 121\n(2024).\n[26] 日経クロステック：まるでパズル、コスト度外視HoloLens 2 のスゴイ中身，https:\n//xtech.nikkei.com/atcl/nxt/column/18/01267/00084/ (2020).\n[27] Labs, P.: Hololens and BT300 eye tracking add-ons, https://pupil-labs.com/\nblog/hololens-bt300-addon. (最終参照日: 2025/1/15).\n[28] meta: Meta Quest 3, https://www.meta.com/jp/quest/quest-3/. (最終参照\n日: 2025/1/15).\n[29]",
            "a.com/jp/quest/quest-3/. (最終参照\n日: 2025/1/15).\n[29] Labs, P.: Eye tracking for mixed reality, https://pupil-labs.com/products/\nvr-ar. (最終参照日: 2025/1/15).\n[30] Microsoft:\nHoloLens, https://learn.microsoft.com/ja-jp/hololens/\nhololens1-hardware. (最終参照日: 2025/1/15).\n[31] Labs, P.:\nNeon Companion App Terms of Use, https://pupil-labs.com/\nlegal/neon-companion-terms-of-use. (最終参照日: 2025/1/15).\n39\n[32] Docs, P. L.:\nPupil Cloud - NEON, https://docs.pupil-labs.com/neon/\npupil-cloud/. (最終参照日: 2025/1/15).\n[",
            "labs.com/neon/\npupil-cloud/. (最終参照日: 2025/1/15).\n[33] Technologies, U.: Unity, https://unity.com/ja. (最終参照日: 2025/1/15).\n[34] Microsoft:\nMixed\nReality\nToolkit,\nhttps://hololabinc.github.io/\nMixedRealityToolkit-Unity/Documentation.ja/WelcomeToMRTK.\nhtml. (最終参照日: 2025/1/15).\n[35] QuestionPro: System Usability Scale: What it is, Calculation + Usage, https://\nwww.questionpro.com/blog/system-usability-scale/.\n(最終参照日:\n2025/1/15).\n40\n質疑応答\n伊藤　雄一　情報テクノロジー学科　教授\nQ\nどんなタスクでしたか．\nA\nロボットアームの左側にあるブロックを，ロボットアームを操",
            "学科　教授\nQ\nどんなタスクでしたか．\nA\nロボットアームの左側にあるブロックを，ロボットアームを操作しブロックをつか\nんで移動させ，所定の位置まで移動させる動作を3 回分行うという内容です．\nQ\n研究の目的と構築したシステムが合っていますか．\nA\nAR 及びVR アプリケーションで同様のタスクを行っているため，研究の目的と合\n致していると考えております．\nQ\nパフォーマンスに影響を与えているのは何ですか．\nA\nパフォーマンスに影響を与えている要因は，操作性の違いと視認性が挙げられます．\nVR ではコントローラ，AR ではハンドトラッキングによる指の操作を用いるため操\n作性が異なり，さらにオブジェクトの視認性の差も影響を及ぼしていると考えてお\nります．\nQ\nVR デバイスの場合は実空間に投影するのではなく背景が設定されていますが，コ\nントローラの違いだけがパフォーマンスに影響を与えていますか．\nA\n今回，VR デバイスでは背景を設定することが一般的であると考え，背景を設定し\nました．そのため，背景の有無もパフォーマンスに影響を与えている要因の一つと\n考えております．\n上堀　さん　情報テ",
            "ため，背景の有無もパフォーマンスに影響を与えている要因の一つと\n考えております．\n上堀　さん　情報テクノロジー学科　\nQ\nコントローラなどへの慣れが影響しませんか．\nA\n実験後のアンケートで普段AR 及びVR デバイスを使用するかという質問項目を設\nけており，その結果どちらのデバイスでも日常的に使用する人はいなかったので，コ\nントローラ操作への慣れは影響していないと考えております．\n41\n"
        ]
    },
    {
        "id": "paper_8",
        "filename": "M2024_Harutaka_Abe.pdf",
        "title": "M2024_Harutaka_Abe",
        "fulltext": " \n \n \n \n \n青  山  学  院  大  学 \n \n理  工  学  研  究  科 \n \n \n \n理工学専攻    知能情報    コース \n \n \n \n \n修  士  論  文 \n \n \n \n       学 生 番 号           35623214       \n \n \n       氏     名      阿部 悠貴       \n \n \n研究指導教員    ロペズ・ギヨーム      \n \nThe Academic Year of 2024, Submitted on January 31st, 2025 \n \nGraduate School of Science and Engineering, Aoyama Gakuin University \n \nTitle: Combining AR and input device to control remotely a robot-arm  \nStudent Name: Harutaka Abe  \nID Number: 35623214 \nDegree: Master of Engineering \nCourse: Intelligence and Information \nThesis Advisor: Professor Guillaume Lopez \n \nAbstract  \n　The introduction of robotics has attracted attention in factories and other workplaces to \nimprove productivity and safety. Furthermore, remote and unmanned robotics are rapidly \nadvancing due to the impact of COVID-19, and the number of industrial robots being \nintroduced is increasing yearly. The trend towards the introduction of industrial robots is to \nautomate various tasks. However, it is not easy to automate all tasks, and detailed tasks \nrequire human work or the operation of industrial robots by humans. Besides, the lack of \npersonnel who can operate industrial robots is an obstacle to the introduction of industrial \nrobots.  \n　This study focuses on arm robots, widely used as industrial robots, and proposes an \nintuitive and easy-to-operate teleoperation method combining an Augmented Reality (AR) \ninterface and an original intuitive input device (TIARC). The proposed method enables the \nreal environment arm robot to be operated in synchronization with the arm robot by \noperating the arm robot virtually in an AR application. The manipulator controls the \nfollowing three pieces of information, and the joint angles of the robot arm are then \ndetermined using inverse kinematics. \n●​ The hand position determines the position of the robot arm head. \n●​ TIARC orientation determines the robot's arm posture. \n●​ TIARC gripping force determines the opening and closing of the robot arm gripper.  \nEvaluation experiments were conducted to verify the effectiveness of the proposed \nmethod and to investigate whether the size of the operable area of the gripper affects the \noperation. Subjects were asked to complete a task using a conventional system with \nmultiple virtual buttons, TIARC, and similar intuitive input devices provided by Ai2AI \n(Pall0v2 and Pall0v3). \nThe results showed that TIARC reduced task completion time while ensuring operation \naccuracy similar to that of the conventional system. Besides, subjective assessment \nresults showed that TIARC is more intuitive and easier to operate. Compared with Pall0v2 \nand Pall0v3, whose gripper control areas are smaller and more prominent than the TIARC \none, the control accuracy was the same, but Pall0v3 task completion time was the \nshortest. This indicates that the area in which the gripper can be manipulated influences \nthe operability of the arm robot. \nIn the evaluation experiments in this study, the task was performed only once for each \nmanipulation technique, so changes due to familiarisation with the manipulation are \nunclear. Future long-term experiments should be conducted to investigate changes in \noperability and task execution time. In order to improve the accuracy of operations, a \nmethod to distinguish between unintended and intended movements is required. In this \nstudy, only synchronization between the arm robot in the application and the actual \nenvironment was carried out, but the surrounding situation is also an important factor \nand needs to be synchronized. In addition, developing a more generalized operation \nmethod for various arm robots is necessary. \n理工学専攻修士論文要旨 \n \n \n： 2024年度 \n： 2025年　1月　31日 \n専修コース： 知能情報コース \n： 35623214 \n： 阿部　悠貴 \n研究指導教員： ロペズ　ギヨーム　教授 \n \n（論文題目） \n拡張現実及びインプットデバイスを用いたアームロボットリモートコントロールシステム \n \n（内容の要旨） \n　 \n工場などの現場では生産性や安全性の向上を目的としたロボティクスの導入が注目されている．さらに，新\n型コロナウイルス感染症（COVID-19）の影響でリモート化や無人化が急速に進展しており，産業用ロボットの\n導入台数は年々増加している．産業用ロボット導入の動向として様々な作業を自動化する傾向にあるが，す\nべての作業を自動化することは難しく細かなタスクは人による作業や人による産業用ロボットの操作が必要で\nあり，操作ができる人材の不足が産業用ロボット導入の妨げとなっている． \n本研究では産業用ロボットとして広く利用されているアームロボットに注目し，その直感的かつ容易に操作\n可能な遠隔操作手法の開発を目的としている．具体的に，拡張現実（AR）による遠隔ロボットの状態\nの可視化と，アームロボットを直感的に操作可能とする物理的な入力インタフェースを組み合わせ\nたシステムを考案・実装し，その有効性を検証することを目標とした． \n開発したARアプリケーション内，仮想的に配置された操作対象のアームロボットを操作することで，それに\n同期した実際のアームロボットも操作可能にしている．また，自作した直感的入力デバイスTIARCを用いて\n，以下の３つのアームロボットの情報を決定し，各関節角を逆運動学から導く方法を実装している． \n●​\n操作者の手の位置がアームロボットの位置を決定する． \n●​\nTIARCの姿勢がアームロボットの姿勢を決定する． \n●​\nTIARCを握る度合いがアームロボットのグリッパーの開閉を決定する． \nTIARCの有効性の検証及びグリッパーの操作可能な部分の面積の大きさが操作に影響を与えるかを調査\nした．有効性の検証のための評価実験においては従来手法として，仮想空間内の複数のボタンで操作を行\nうシステムとTIARCを用いた提案システムで被験者にタスクを課し比較した．グリッパー操作可能エリアの\n影響を検証するため，TIARCと，Ai2AI社が提供するPall0v2（小さなボタンによる制御）及びPall0v3\n（デバイス全面積にうよる制御）を比較した． \n結果として提案システムで優位にタスク完了時間が短縮され，従来システムと同程度のせ精度で操作が可\n能であることが明らかとなった．アンケート評価の結果からは提案手法がより直感的かつ容易な操作が可能で\nあることが示された．特定の位置のボタンによりグリッパーの操作を行うPall0v2とデバイスを強く握ることでグ\nリッパーの操作を行うPall0v3の比較においては精度は同程度であったがPall0v3で優位にタスク完了時間が\n短縮されたことから提案手法においてグリッパーの操作が可能な面積がアームロボットの操作性に影響を与\nえることが示された． \n本研究の評価実験では、各操作手法で一回のみタスクを行ったため，操作の慣れによる変化は明らかに\nなっていない．今後は長期的な実験を行い，操作性やタスク実行時間の変化を調査する必要がある．操作の\n正確性向上のため，意図しない手の揺れと意図した動作を区別する手法が求められる．本研究にいおいて\nはアプリケーション内と実環境のアームロボットの同期のみを行ったが，周囲の状況も重要な要素であり，同\n期を行うひつようがある．また，多様なアームロボットへの対応が課題であり、より汎用的な操作手法の開発が\n必要である． \n​\n \n青山学院大学大学院理工学研究科 \n拡張現実及びインプットデバイスを用いたアームロボットリ\nモートコントロールシステム\n阿部　悠貴\n2025/02/24\n目次\n第1 章\n序論\n1\n1.1\n研究背景. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n1\n1.1.1\n製造業の現場における産業用ロボット\n. . . . . . . . . . . . . . . .\n1\n1.1.2\n製造業のリモート化\n. . . . . . . . . . . . . . . . . . . . . . . . . .\n2\n1.1.3\n製造業におけるXR 技術の活用. . . . . . . . . . . . . . . . . . . .\n3\n1.2\n研究目的・目標. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n4\n第2 章\n関連研究・技術\n6\n2.1\n既存のアームロボット操作手法. . . . . . . . . . . . . . . . . . . . . . . .\n6\n2.2\n直接操作型のアームロボット操作手法\n. . . . . . . . . . . . . . . . . . . .\n7\n2.3\nジェスチャ及び身体動作用いたアームロボット操作手法\n. . . . . . . . . .\n10\n2.4\n自然インターフェースを用いたアームロボット操作手法\n. . . . . . . . . .\n15\n2.5\nまとめ. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n17\n第3 章\n拡張現実とインプットデバイスを用いたアームロボットリモートコントロー\nルシステム\n19\n3.1\nシステム概要. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n19\n3.2\nインプットデバイス\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n20\n3.2.1\nPALL0 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n21\n3.2.2\nマルチセンサデバイス. . . . . . . . . . . . . . . . . . . . . . . . .\n22\n3.3\n仮想的に配置されたアームロボットの操作手法\n. . . . . . . . . . . . . . .\n24\n3.4\n各デバイス間の通信手法. . . . . . . . . . . . . . . . . . . . . . . . . . . .\n26\n3.4.1\nMQTT プロトコルによる通信の概要\n. . . . . . . . . . . . . . . . .\n26\n3.4.2\nPall0 を用いた各デバイス間の通信\n. . . . . . . . . . . . . . . . . .\n26\n3.4.3\nTIARC を用いた各デバイス間の通信. . . . . . . . . . . . . . . . .\n27\n3.5\nシステムの使用方法\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n28\n第4 章\nユーザ評価実験\n30\n4.1\n実験目的. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n30\n4.2\n実験環境. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n30\n4.3\n実験方法. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n31\n4.4\n評価方法. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n32\n4.4.1\n定量評価指標. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n32\n4.4.2\n主観的な操作のしやすさの評価指標\n. . . . . . . . . . . . . . . . .\n32\ni\n第5 章\n実験結果及び考察\n34\n5.1\n定量評価の実験結果及び考察\n. . . . . . . . . . . . . . . . . . . . . . . . .\n34\n5.2\n主観的な操作のしやすさの実験結果と考察. . . . . . . . . . . . . . . . . .\n39\n第6 章\n結論と今後の展望\n44\n6.1\n結論. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n44\n6.2\n今後の展望\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n45\n謝辞\n47\n参考文献\n47\nii\n第1章\n序論\n1.1\n研究背景\n1.1.1\n製造業の現場における産業用ロボット\n今日，日本では超高齢化社会に伴い様々なところで人手不足が指摘されている．[1] 図\n1.1 から日本における生産年齢人口（15～64 歳）は1995 年をピークに減少しており，2050\n年には5,275 万人（2021 年から29.2 ％減）に減少すると見込まれると同時に労働力の不\n足などの課題が深刻化すると懸念されている．[2] 生産年齢人口の減少に伴い，生産性を\n高める手段としてロボティクスへの期待が高まっている．\n図1.1 高齢化の推移と将来推計( [2] より引用)\n製造業の現場においてもロボティクスへの期待が高まる傾向にあり，近年の産業用ロ\nボット技術は多くの産業の現場に導入され，作業者の安全性と作業の生産性を向上させる\nとともに，3K 職場の改善など働き方にも影響を及ぼしている．これらの利点から産業用\nロボットの導入は先進工業国にとどまらず，新興国も含め世界的に大きな潮流となりつつ\nある．[3]．図1.2 に産業用ロボットの稼働台数の推移及び図1.3 に産業用ロボットの年間\n導入台数を示す．産業用ロボットの稼働台数は年々増加しており，今後もさらなる拡大が\n1\n見込まれる．\n図1.2 産業用ロボットの稼働台数の推移( [4] より引用)\n実際の導入事例としてはオムロン株式会社のアームロボットが挙げられる[5]．オムロ\nン株式会社が提供するアームロボットは様々な現場に導入され，省人化による人手不足の\n解消や作業時間の短縮による生産効率の向上などその有用性を示している．また，株式会\n社KEYENCE が提供している産業用ロボット[6] は人体への負荷が大きい作業にアームロ\nボットを導入することで品質の安定化や作業の効率化を図るだけでなく作業環境の改善に\n寄与しその有用性を示している．\n1.1.2\n製造業のリモート化\nこれらの動きに加えて，2020 年世界的に流行した新型コロナウイルスの影響を受け，あ\nらゆる作業がリモート化，無人化に関連したソリューションが登場し，新しい産業形態の\n変化が訪れている[7]．工場においてもコロナ禍が始まった2020 年から緊急対応としてリ\nモート化を行う企業が多かったが、2021 年以降は恒久的な体制として整備が進みつつあ\nり、今後さらにリモート化が進む見込みである[8]．図1.3 に産業用ロボットの年間導入\n台数を示す．2013 年から新型コロナウイルスが流行する以前までの年間導入台数は多い\n年で年間430 万台となっているが，新型コロナウイルスが流行した2020 年の翌年から年\n間530 万台程度で推移しており，産業用ロボットの年間導入台数から見ても製造業のリ\nモート化，無人化が進められていることが明らかである．しかし，産業用ロボットの導入\nに伴い，産業用ロボットの操作の複雑さから効果的に活用するために必要なスキルを持つ\n人材が不足していることや，導入するための資本の不足等様々な課題が挙げられている\n[9][10][11]．また，産業用ロボットの利用の動向として様々な工程の自動化が進められて\nいるが，完全な自動化は難しく，自動化が難しい工程については人が作業を行うことや人\n間による産業用ロボットの操作が必要である[12]．\n2\n図1.3 産業用ロボットの年間導入台数( [4] より引用)\n実際に製造業、産業のリモート化を可能にした事例として，トヨタ自動車の3D CAD\nVDI があげられる[13]．3D CAD VDI の導入により，設計職は自宅のノートPC からイン\nターネット経由で仮想環境の3D CAD アプリにアクセス可能となりリモート化が実現し\nた．また，東京で溶接の町工場を営むクリエイティブワークスは，技能者育成用の溶接\nキットにインカム、カメラ、通信機能を搭載した独自開発のIoT 溶接機と汎用クラウドの\n生産管理システムを用いて溶接職人のリモート化を実現している[14]．さらに，人間に\nよる操作が必要なタスクをリモート化する試みも進められている．ManageReact は従来人\nが現場で行ているシンプルな作業を遠隔化する取り組みSocoCacico を提案している[15]．\nこれらの事例のように製造業，産業の現場でリモート化が導入されつつあり今後更なるリ\nモート化の推進が予想される．\n1.1.3\n製造業におけるXR 技術の活用\n拡張現実(AR)，仮想現実(VR)，複合現実(MR) から成るxR と呼ばれる基本的な概念は\nヘッドマウントディスプレイやサングラス型のXR グラスなどに仮想的なオブジェクトで\nあるホログラムを映すものである．\n製造業においては設計，製造，メンテナンスなどのエンジニアリングチェーン全体をデ\nジタルツインでつなぐことや各プロセスにXR を活用する動きが起こっている[16][17]．\nAIMultiple は拡張現実を利用することで作業指示や情報のオーバレイを行う事ができ，組\nみ立て工程を効率化するソリューションを提供している．同社はXR 技術を用いることで\n遠隔での共同作業を可能にし，効率性や正確性を向上させている．その他にもアルゼンチ\nンの同管理製造メーカーであるテナリス社ではAR 技術を導入することで設備メンテナン\nスや製造工程の運用管理を効率化することに成功した事例[18] や富士通沼図工場では保\n守点検にAR を導入し管理ノウハウを見えるかすることで関係者全体が共有可能にするシ\nステムを導入した事例[19] など今日様々な製造業の現場でXR が活用されている．また，\n製造の工程だけでなく教育訓練にXR を活用することで教育訓練にかかる時間の短縮，効\n率化を可能にしている事例が多く存在する．一例として株式会社ホロラボは教育訓練に\nMR を用いたサービスassists を提供している[20]．図1.4 にassists 使用時の様子を示す．\n3\nassists はMR 技術を用いて空間にテキストや画像，3D モデルといったデジタル情報を縦\n走し，直感的で学習効率の高い体験形式での教育訓練を可能にしている．これにより，反\n復して自主学習を行えるため指導矢が常駐する必要がなく教育コストの軽減に成功して\nいる．\n図1.4 Assists 使用時の様子( [20] より引用)\n以上のように今日製造業の様々な現場でMR 技術が活用され，生産性や効率の向上に寄\n与するとともにコスト削減にも寄与している．\n1.2\n研究目的・目標\n今日日本では超高齢化社会に伴い様々なところで人手不足が指摘されている中，労働力\n不足の課題が深刻化すると懸念されており，生産性を高める手段としてロボティクスへの\n関心が高まっている．製造業の現場においてもロボティクスへの期待が高まる傾向にあ\nり，近年産業用ロボットは多くの現場に導入され作業者の安全性と作業の生産性を向上さ\nせている．様々な利点から産業用ロボットの導入は我が国を含む先進工業国にとどまらず\n新興国も含め世界的に大きな潮流となりつつある．これらの動きに加えて2020 年世界的\nに流行した新型コロナウイルスの影響を受けあらゆる作業のリモート化，無人化に関連し\nたソリューションが登場している．工場においても産業用ロボットを導入するなどの方法\nでリモート化，無人化を進めており，この動きは今後さらに進む見込みである．しかし，\n産業用ロボットの導入には資金的な課題や産業用ロボットを扱える人材が不足しているな\nどの課題も存在している．また，産業用ロボットの利用の動向としては工程の自動化が主\nに進められているが完全な自動化が難しく人による操作が必要な作業も存在している．リ\nモート化，無人化に関連したソリューションとして設計，製造，メンテナンスなど全体に\nXR を活用する動きが起こっており，様々な事例が存在する．\n4\n以上のことから産業用ロボットの操作に特別な知識を必要としない程度簡単で直感的で\nあり，遠隔地からリアルタイムな操作が可能な産業用ロボットの操作手法が必要である．\nそこで本研究では産業用ロボットの中でも多くの工程に用いられているアームロボットに\n焦点を当て，特別な知識を必要とせず遠隔地からリアルタイムで操作が可能な操作手法の\n提案を目標とする．そのため本研究では以下3 点を目標とし，評価実験を行い目標が達成\nされたかを検証する．\n• 直感的に操作可能な操作手法\n• 認知的負荷の小さい操作手法\n• 操作が簡単に感じられる操作手法\n本研究で提案する手法はアームロボットの状態などの情報提示手法として拡張現実を用\nい，拡張現実で仮想的に提示されたアームロボットを操作することでその動きに連動して\n実際のアームロボットも操作可能なシステムとなっている．拡張現実で仮想的に配置され\nたアームとボットはハンドトラッキングを用いて取得する手の位置及び操作デバイスを用\nいて取得する姿勢を用いてアームロボットのヘッドの位置姿勢を決定することで各関節角\nを決定し操作を行う．グリッパーの開閉は操作デバイスを用いて操作する．\n5\n第2章\n関連研究・技術\n2.1\n既存のアームロボット操作手法\n製品化されているアームロボットの手動操作手法はタッチパネル上の複数の方向ボタン\nを用いてアームロボット操作する手法が多く用いられている[21][22]．図2.1 に方向ボタ\nンを用いたアームロボット操作手法の例を示す．一般的に方向ボタンを用いてアームロ\nボットのヘッドの位置姿勢を決定し制御する逆運動学を用いることで各関節角を制御する\n方法より簡単に操作が可能な一方で，アームロボットの自由度の高さからボタン数が多く\nなり直感的な操作が難しい課題が存在している．\n図2.1 方向ボタンを用いたアームロボット操作手法の例( [22] より引用)\nより直感的な操作を可能にする操作手法としてジョイスティックなどのコントローラを用\nいて操作を行う手法が存在する[23]．図2.2 にアームロボット操作に用いるジョイスティッ\nクの例を示す．スティックを倒すことでその方向にアームロボットのヘッドの位置を移動\nさせるなど方向ボタンを用いて操作する手法に比べ簡単な操作が可能であるが，奥行き方\n向の操作時にはボタンを押す必要があることや回転の操作についても特定のコマンドを\n入力する必要があるなどアームロボットの動作を意識した操作が必要なことから方向ボタ\nンを用いた操作と同様に直感的な操作や意図したとおりの操作が難しい課題が残されて\nいる．\n6\n図2.2 アームロボット操作に用いるジョイスティックの例( [23] より引用)\n2.2\n直接操作型のアームロボット操作手法\nアームロボットの操作手法を提案する研究は数多く行われている．リアルタイムのロ\nボットの手動操作においては，ジョイスティックなどのコントローラやタッチパネルを用\nいて複数のボタンを用いた操作手法が多く提案されている[24][25][26]．\nHashimoto らはCG の重曹表示を用いてロボットを直感的に操作することができるシス\nテムTouchMe を提案している[27]．TouchMe は入力デバイスとしてタッチスクリーンを\n使用しており，画面上には操作対象のロボット三人称視点からとらえたカメラ画像が表示\nされている．ユーザは画面上に表示されているロボットの操作したい部位に直接触れ，ド\nラッグすることによってロボットを任意の位置姿勢にすることができる．図2.3 にTouchMe\nを用いたアームロボット操作時の例を示す．TouchMe ではアームロボットのヘッドを動か\nしたい方向へドラッグすることで操作を可能にしている．TouchMe でアームロボットを\n操作する際にタッチパネルを用いて操作を行っているため，二次元平面での操作は直感的\nで容易であるが，三次元空間での操作は難しい課題が残されている．\n7\n図2.3 TouchMe を用いたアームロボット操作時の例( [27] より引用)\n竹内らは操作者が周囲の確認を目視と1 台のカメラで行い物体把持を簡単に行えるタッ\nチパネルを利用したロボットアーム手先目標指定インターフェースを提案している[28]．\n図2.4 に竹内らの提案するシステム使用時の様子を示す．竹内らの提案するシステムでは\nタッチパネル上での操作によりロボットアームを動作させ，少ない操作回数で物体の把持\nを可能にしている．竹内らの提案するシステムでは，目視とカメラで対象物体の確認を\n行っていることから，遠隔地からの操作を想定した際に奥行き方向の認識が難しく操作が\n難しくなる課題が残されている．竹内らはさらにUI を追加する改善案も述べており，認\n知的負荷がより大きくなる，アームロボットの動作をより意識する必要がある課題も残さ\nれている．\n図2.4 竹内らの提案するシステム使用時の様子( [28] より引用)\n8\nChenchireddy らはAruduino コントローラを用いたアームロボットの操作手法を提案し\nている[29]．図2.5 にChenchireddy らの提案する操作手法の全体図を示す．Chenchireddy\nらが提案する操作手法ではアームロボットの各関節を操作するAruduino コントローラと\nセンサを統合して精密活動的な操作を可能にしている．Aruduino コントローラとセンサ\nのみを用いるため他の手法に比べて安価であり，コスト面に優れている．しかし，各関節\nを操作する手法は操作の直感性にかけており，使用する人の知識を必要とする課題が残さ\nれている．\n図2.5 Chenchireddy らの提案する操作手法の全体図( [29] より引用)\nジョイスティックなどのコントローラを用いた操作手法については様々な形のコントロー\nラが提案されている[30][31][32]．コントローラを用いた手法では精密な操作のため複数\nのボタンを用いることやタッチパネルなどと組み合わせるなどの手法が存在しているが，\n用いるボタンやタッチパネル内のUI が多くなる程アームロボットの操作に対する専門性\nが必要になり直感的な操作が難しくなる．これに対し，図2.6 に示すようなより簡素化し\nたコントローラも多く提案されている．このようなコントローラは複数のボタンを用いる\n手法に比べ操作が容易である利点があるが，細かな操作が難しい課題が残されている．ま\nた，操作ミスを防ぐために触覚や聴覚によるフィードバックを行う手法も存在しており\n9\n図2.6 アームロボットコントローラの例( [30] より引用)\n以上のようにジョイスティックなどのコントローラを用いる手法やタッチパネルを用い\nる手法，タッチパネルとコントローラを組み合わせる手法など様々な直接操作型のアー\nムロボット操作手法が提案されている．タッチパネルを用いた操作手法ではアームロボッ\nトの自由度の高さからUI が複雑になり直感的な操作が難しい課題が挙げられ，ジョイス\nティックなどのコントローラを用いた手法では奥行き方向や精密な操作が難しい課題が残\nされている．\n2.3\nジェスチャ及び身体動作用いたアームロボット操作手法\nロボットの操作手法においてタッチパネルやコントローラを用いた操作に比べ専門的な\n知識を必要とせず，直感的な手法としてジェスチャ操作や身体動作を用いた操作が挙げら\nれる．これらの操作手法を提案する先行研究は数多く存在する．手袋型で指の動きを認識\nする手法，カメラで身体動作をコマンドとして認識する手法，センサを用いて人の動作を\n認識しコマンドとして用いる手法など，身体動作の認識方法及びその活用方法などその手\n法は多岐にわたる[33][34][35]．\n川西らはLeap Motion を使用したロボットアームの操作手法を提案している[36]．川西\nらが提案するシステムではLeap Motion で取得した手の座標データを用いてアームロボッ\nトの操作を行っている．この手法は手の動きがアームロボットの動きに反映されるため非\n常に直感的であるが，その他のグリッパーの制御やヘッドの回転などの操作手法について\nは言及されてなく，操作手法として不十分である．これに対し日置らはLeap Motion を用\n10\nいて手の動きを認識し，特定の動作をアームロボットの特定動作のコマンドとして用いる\nことでアームロボットの操作を行う手法を提案している[37]．図2.7 日置らの提案するシ\nステムを用いたアームロボット操作の様子を示す．に日置らの提案する手法では例えば指\nで円を描く動作をした際にモータ3 の角度を20 度上げるなど特定の動作を特定のモータ\nの動きに割り当てることで操作を可能にしている．川西らの提案する操作手法に比べ，多\nくの動作に対応可能であることから操作手法として十分であると言えるが，一度のコマン\nドで一定量アームロボットが動くことから細かな操作が難しい事や，各身体動作が対応す\nるコマンドを覚える必要があり直感的な操作が難しい課題が残されている．\n11\n図2.7 日置らの提案するシステムを用いたアームロボット操作の様子( [37] より引用)\nChen はMR を用いて仮想的に表示されたアームロボットをオブジェクトトラッキング\nを用いて操作を行う手法を提案している[38]．図2.8 にchen が提案する手法を用いたアー\nムロボット操作の様子を示す．アームロボットは逆運動学を用いて制御され，赤いボール\n12\nを追跡する．赤いボールは手を用いて移動させることが可能であり，この位置に応じて\nアームロボットが適切な姿勢で追跡することで操作を可能にしている．赤いボールの移動\nについては操作者自身の手を用いて触れるなどで移動させることが可能であり非常に容\n易である．Chen の提案する手法ではヘッドの回転やグリッパーの制御に関する記述がな\nく操作方法としては不十分ではあるが，アームロボットの操作に必要な動作が赤いボール\nを動かすのみであるため専門的な知識を必要とせず直感的な操作が可能であるなどの利\n点が挙げられる．\n図2.8 chen が提案する手法を用いたアームロボット操作の様子( [38] より引用)\n福岡らは顔表情をアームロボットの動きにマッピングすることで操作を行う手法faceDrive\nを提案している[39]．図2.9にfaceDriveを用いたアームロボット操作の例を示す．FaceDrive\nでは，機械学習を通じて表情とアーム動作コマンドのマッピングを行う操作手法を用いて\nいる．四肢の自由を底縄地に操作が可能である点においては優れた操作手法である一方，\nコマンドとしての顔表情を記憶する必要がある点や顔表情のご認識により意図しない動\n作が発生する可能性がある点などの課題が残されている．\n13\n図2.9 faceDrive を用いたアームロボット操作の例( [39] より引用)\n木村らは頭部動作に基づいてアームロボットの操作を行う手法を提案している[40]．図\n2.10 に木村らの提案するアームロボット操作時の様子を示す．木村らの提案する手法では\n操作開始時ににヘッドマウントディスプレイに搭載されたウェブカメラを用いてアームロ\nボットに貼り付けられているコードを読み取る．アームロボット動作はコードに割り当て\nられている情報によって切り替えられ，読み取りが完了するとロボットアームがユーザの\n頭部動作に基づいて動作するようになる．アームロボットの操作時にはヘッドマウント\nディスプレイに取り付けられた慣性センサを用いて頭部動作を認識し，アームロボットの\n旋回運動及び上下運動を制御する．木村らの提案する手法は任意のタイミングでアームロ\nボットを操作可能であるため意図しないタイミングでの操作を避けられる利点がある一\n方，アームロボットの動作に対応した頭部の動きを覚える必要があるため直感的な操作が\n難しい点や頭部を動かしている際にアームロボットを視界に入れ続けることが難しい点に\n課題が残されている．\n図2.10 木村らの提案するアームロボット操作時の様子( [40] より引用)\n14\n以上のようにジェスチャや身体動作を用いた操作手法は数多く提案されている．仮想的\nに表示されたオブジェクトを移動させることでそれに追従するアームロボットの操作を行\nう手法や手の動きを用いて操作を行う手法など非常に直感的であり意図したとおりの操\n作が可能な手法が提案されているが回転やグリッパーの制御については言及されていない\nなど操作手法として不十分である．その他の身体動作を用いた手法は複雑なUI を必要と\nせず，操作手法を簡単に理解可能である利点があるが，アームロボットの動作に対応した\n身体動作を覚える必要があり，アームロボットの動作に近い動作ではない事などから直感\n的な操作が難しい課題が残されている．\n2.4\n自然インターフェースを用いたアームロボット操作手法\nタッチパネルやジョイスティックなどのコントローラ，身体動作やジェスチャなどを用い\nた操作手法以外の操作手法も多く提案されている．その例として大規模言語モデルへのプ\nロんプティングをもとに得たタスク実行手順を用いてアームロボットを操作する手法[41]\nや実際のアームロボットに対して言語を用いて指示を与えて実行するPaLM-SayCan[42]，\n運動イメージ脳信号とインピーダンス制御を組み合わせることで操作を行う手法[43] な\nど自然言語や脳波を用いた操作手法が挙げられる．\nZhang らは脳波を用いて意図を推定し，アームロボットの操作を可能にする手法を提案\nしている[44]．図2.11 にzhang らが提案する手法の概要図を示す．zhang らが提案する手\n法では操作者に「物をつかむ」や「前に進む」などの具体的な動作をイメージしてもら\nい，運動関連領域で生成される脳波パターンを学習し意図推定に用いる．実際に操作を行\nう際には操作者がイメージした運動を事前に学習したモデルを用いて意図推移帝を行い\n推定結果を制御コマンドに変換することで操作を行う．zhang らが提案する手法では運動\nをイメージするのみでアームロボットの操作を可能にしている点で直感的であり優れてい\nる一方，脳波から正確に意図を推定することが難しい点や汎用性に欠ける点などの課題が\n残されている．\n図2.11 zhang らが提案する手法の概要図( [44] より引用)\n15\n久保山らは大規模自然言語モデルを用いて指示を生成することでアームロボットの操作\nを可能にする手法を提案している[45]．図2.12 に久保山らが提案する手法の概要図を示\nす．久保山らが提案する手法では大規模言語モデルを用いて抽象的な自然言語指示をロ\nボットの制御に適した具体的な行動の手続きを示した分のリストに変換し，その文とロ\nボットの行動コマンドを結びつけることで操作を可能にしている．\n図2.12 久保山らが提案する手法の概要図( [45] より引用)\n黄瀬らは大規模言語モデルによるコード生成と機械学習によるロボット制御を組み合わ\nせることで言語指示によりアームロボットの操作を行う手法を提案している[46]．図2.13\nに黄瀬らの提案する手法の概要図を示す．黄瀬らの提案する手法では大規模言語モデルが\n生成したLMP はNewtonianVAE によって事前学習された世界モデルの潜在空間を利用し\nて制御を行う．世界モデルを用いることで，アームロボットの座標や関節角，物体位置な\nどの情報を利用することなく自然言語文で指示される道のタスクや動作に対して自立制\n御を可能にしている．\n久保山らや黄瀬らなどが提案する自然言語を用いた操作手法は脳波を用いた手法と同程\n度に直感的であると言えるが，自然言語の曖昧さから意図しない動作が発生する可能性が\nあるなどの課題が残されている．\n16\n図2.13 黄瀬らの提案する手法の概要図( [46] より引用)\n2.5\nまとめ\n既存の操作手法としてタッチパネル上で複数のボタンを用いることやジョイスティック\nなどのコントローラを用いた手法が存在するが，アームロボットの自由度の高さから操作\nが煩雑になる課題があり，アームロボット導入の妨げとなっている．この課題を解決する\nために既存の操作手法を改善しより簡潔にする手法を提案する研究は数多く存在するが\n簡易化する事には限界があり，認知的負荷が大きい課題が残されている．これに対し，身\n体動作やジェスチャを用いた操作手法が数多く提案されている．これらの手法はタッチパ\nネルなどを用いた手法に比べて必要なボタン数が少なく認知的負荷が小さい点で優れて\nいる．しかし，アームロボットの動作に対応するジェスチャや身体動作を意識する必要が\nあるため直感的な操作が難しい点に課題が残されている．仮想的に表示されたオブジェク\nトを移動させることでそれに追従するアームロボットの操作を行う手法や手の動きを用い\nて操作を行う手法など非常に直感的であり意図したとおりの操作が可能であるが，回転や\nグリッパーの制御については言及されていないなど操作手法として不十分である課題が残\nされている．脳波や自然言語を用いた操作手法は認知的負荷が小さく特別な身体動作など\nのコマンドを意識する必要がなくより直感的な手法であると言えるが，自然言語の曖昧さ\nなどから意図しない動作が発生する可能性がある点に課題が残されている．\n17\n以上のことから本論文ではアームロボットの状態などの情報提示手法として拡張現実を\n用い，拡張現実で仮想的に提示されたアームロボットを操作することでその動きに連動し\nて実際のアームロボットも操作可能なシステムをていあんする．拡張現実で仮想的に配置\nされたアームとボットはハンドトラッキングを用いて取得する手の位置及び入力デバイス\nを用いて取得する姿勢を用いてアームロボットのヘッドの位置姿勢を決定することで各関\n節角を決定し操作を行う．グリッパーの開閉は入力デバイスを用いて操作する．\n18\n第3章\n拡張現実とインプットデバイスを用いた\nアームロボットリモートコントロールシス\nテム\n3.1\nシステム概要\n本研究で提案するシステムは拡張現実を用いて仮想的に提示されたアームロボットのモ\nデルを操作することでその動きに連動した実際のアームロボットの操作も可能にするシス\nテムとなっている．図3.1 に提案システムの概要図を示す．インプットデバイスを用いて\n姿勢情報及びグリッパーの開閉情報をAR アプリケーションへ送信し，AR アプリケーショ\nンでは受け取った情報及びアプリケーション内でハンドトラッキングを用いて取得する手\nの位置情報を用いてアームロボットの各関節角を計算する．その後，AR アプリケーショ\nンで計算された各関節角の情報を実際のアームロボットへ送信することで操作を行う．イ\nンプットデバイス，AR アプリケーション間及びAR アプリケーション，アームロボット間\nの通信はMQTT プロトコルを用いる．MQTT プロトコルはhttp のようにプレーンテキス\nトでの情報ではなく，ビット単位での情報によりオーバヘッドが少なく軽量であり，コネ\nクション指向のプロトコルである．また，要求-応答型モデルであり，Topic を用いること\nで双方向で1 対多，多対多の通信が可能であるため柔軟に拡張可能である[47]．これらの\n利点を有するMQTT プロトコルは直感的な操作のため低遅延でリアルタイムに通信を行\nう必要がある本システムに適している．また，AR アプリケーションを実装するデバイス\nとしてMicrosoft 社のHololens2 を用いる．図3.2 に使用するhololens2 を示す．hololens2\nは透過型のヘッドマウントディスプレイであり，前面に配置されたRGB カメラ及び環境\n認識カメラを用いた高精度なハンドトラッキング機能を有していることに加えて別途のコ\nントローラを必要とせずに操作を行うことが可能である点や幅広い視野角でユーザが快\n適かつ正確にホログラムを操作可能である点に優れており[48] 本システムに適している．\n19\n図3.1 提案システムの概要図\n図3.2 使用するHoloLens2\n3.2\nインプットデバイス\nアームロボットのリアルタイム操作を行うにあたり，ハンドトラッキングを用いた手の\n位置情報及び姿勢情報，開閉情報を用いて操作が可能であれば直感的な操作を可能にしな\nがら専門的な知識を必要とせず容易な操作が可能である．しかし，姿勢を制御するために\n20\n手を傾けた際などに手が隠れてしまいhololens2 のカメラでとらえられない際に姿勢や開\n閉の認識が難しく正確な操作が難しい．そのため本研究では手が隠れた際にも正確に姿勢\n及び把持の認識を正確に行うためインプットデバイスを用いる．\n3.2.1\nPALL0\n姿勢及び把持推定が可能なデバイスととしてAI2AI が提供するPall0 が挙げられる．図\n3.3 にPall0 の構成図を示す．Pall0 は，ボールという物理的な特性と高度なデジタルセン\nサー、多モーダルフィードバックを融合させたデバイスであり，は主に身体活動の促進や\nリハビリテーションを目的として設計されているが，現在では産業用制御システムにも応\n用されている．加速度、角速度、外部環境要因を追跡するセンサーを搭載し，PALL0 は\n多様な応用分野に対応するユニークで直感的なインターフェースを提供する[49]．\n図3.3 Pall0 の構成図( [49] より引用)\n図3.4 に使用するPall0 の外見を示す．Pall0 は上下各4 か所ずつ計8 か所に圧力センサを\n用いたボタンが設置されており，様々なインタラクションが可能である．本研究において\nは把持認識にボタンを用いる．また，本節で紹介しているPall0 はPall0v2 であり現在では\nデバイスの全面に圧力センサを搭載し把持認識が可能なPall0v3 が提供されいる．Pall0v2\nではあらかじめ配置されているがあり，グリッパーの制御において特定の位置にあるボタ\nンを開閉の操作療法で押す必要がある．これに対しPall0v3 ではデバイスを握り続けてい\nる間はグリッパーを閉じ，緩めた際にグリッパーを開くという制御が可能である．そのた\nめ本研究ではこれら二つの制御方法で操作の容易さや直感性に差異が出るかを検証する．\n21\n図3.4 使用するPall0 の外見\n3.2.2\nマルチセンサデバイス\n手で持って操作を行うインプットデバイスを用いる際，形状は重要な要素であり，デバ\nイスの握りやすさや持ちやすさを調査する文献は多岐にわたる．その中でも，特に道具や\nデバイスの把持部が円柱状である点に着目した研究が数多く存在する．これらの研究で\nは，道具の把持部を円筒形に単純化し，その形状やサイズが握りやすさや使いやすさに与\nえる影響を評価している[50][51][52]．このような背景を踏まえ，本研究では姿勢推定お\nよび把持認識が可能な円柱状のデバイスを新たに開発し，これを「Tangible Interface for\nArm Robot Control（TIARC）」と命名した。\n図3.5 に制作したTIARC の外見及び図3.6 にTIARC 使用時の様子を示す．TIARC は片\n手で容易に使用できる大きさを持ち，表面には把持認識を実現するための圧力センサが取\nり付けられている．また，TIARC のケースは3D プリンタを用いて製作されており，内部\n構造を保護しつつ，充電用および配線用の穴を備えている．この設計により，取り扱いが\n簡便で，センサの付け替えなどのメンテナンスも容易である．図3.7 にTIARC を構成する\nM5StickC 及び圧力センサを示す．M5StickC はESP32 を搭載したオープンソースのIOT\n開発ボードであり，6 軸のIMU センサやWI-FI が利用可能である．6 軸のIMU センサを用\nいることでTIARC の姿勢を高精度で推定することが可能であり，WI-FI を用いることで\nセンサ値をリアルタイムでAR アプリケーションへ送信することが可能である．またバッ\nテリー駆動であり外部電源を必要せずにTIARC を動作させることが可能であるため，持\nち運びが容易で様々な環境での使用が可能である．圧力センサには、Interlink Electronics\n22\n社が提供するFSR406 圧力センサを採用している．このセンサは，M5StickC に直接接続\n可能な小型で柔軟性のある設計が特徴であり，非常に軽量で取り扱いが容易である．ま\nた，フレキシブルな特性を持つため，円柱状のTIARC の表面に沿うように配置すること\nが可能であり，デバイス全体の形状や機能性を損なうことなく高い感度で圧力を検知する\nことが可能である．\n図3.5 TIARC の外見\n図3.6 TIARC 使用時の様子\n23\n図3.7 TIARC を構成するM5StickC（左側）及び圧力センサ（右側）\n3.3\n仮想的に配置されたアームロボットの操作手法\nAR アプリケーションにおいて，仮想的に配置されたアームロボットの各関節角度は，逆\n運動学の計算を用いて決定される．そのため，アームロボットの頭部の位置および姿勢\nを適切に決定することが必要である．図3.8 に仮想的に配置されたアームロボット操作時\nの様子を示す．このアプリケーションでは，ハンドトラッキング技術を用いて手の位置を\nリアルタイムで追跡し，その追跡された位置を白い立方体として視覚的に表現している．\n白い立方体による位置表示は，仮想オブジェクトとユーザーの手が重なった際にも手の位\n置を視認可能に保ち，誤操作や混乱を防ぐために使用される．手とアームロボットの頭\n部にはそれぞれ基準点が設けられている．この基準点を基に取得する手の基準点から差\nの情報と，アームロボットの頭部の基準点からの差情の情報を同期させることで，アー\nムロボットの頭部の位置を決定する．これにより，操作者はアームロボットの頭部を動か\nしたい方向に手を動かすのみで位置の操作ができ，直感的で容易な操作を可能にしてい\nる．図3.9 に仮想的に配置されたアームロボットの頭部の姿勢操作時の様子を示す．アー\nムロボットの頭部を傾けたい方向にインプットデバイスを持った手を傾けることで操作を\n行う．手を傾け続けている間はアームロボットの頭部が回転し続け，手を水平な状態に戻\nすことで回転を止め姿勢を固定する．グリッパーの操作手法はPall0v2，Pallov3，TIARC\nで異なる．Pall0v2 ではグリッパーを閉じる際に特定のボタンを押し，開く際に再度同じ\nボタンを押す．TIARC ではグリッパーを閉じる際にデバイスを強く握り，開く際に再度\n強く握る．Pall0v3 ではデバイスを強く握っている間グリッパーが閉じ続ける．Pall0v2 と\nTIARC はグリッパーの開閉を切り替えることで操作する点で同様であるが，特定の位置\nのボタンを押す必要があるか単純にデバイスを握るのみで操作可能かという点において\n異なる．また，TIARC とPall0v3 はデバイスを握るのみで操作可能である点では同様であ\n24\nるが，グリッパーの開閉を切り替えることで行うか握っている間はグリッパーが閉じ続け\nるかという点でことなる．これらの操作手法を比較することで，度の操作手法が最も直感\n的かつ容易かを検証する．\n図3.8 仮想的に配置されたアームロボット操作時の様子\n図3.9 仮想的に配置されたアームロボットの頭部の姿勢操作時の様子\n25\n3.4\n各デバイス間の通信手法\n3.4.1\nMQTT プロトコルによる通信の概要\n3.1 節で述べた通り，提案システムでは各デバイス間の通信にMQTT プロトコルを用い\nる．このMQTT プロトコルはパブリッシュ/サブスクライブという通信パターンを採用し\nており，様々なデバイス間での効率的なデータ交換を可能にしている．このパターンに\nおいて，メッセージを送信する役割を担うクライアントは「パブリッシャー」と呼ばれ，\nメッセージを受信する側のクライアントは「サブスクライバー」と呼ばれる．また，これ\nらの間で通信を仲介するサーバーは「ブローカー」と呼ばれる．実際にに通信を行う際に\nは，各メッセージにトピックと呼ばれる属性が付与され，このトピックによってどのメッ\nセージがどのクライアントに送られるかが決定される．mqtt プロトコルによる通信の概\n要図を3.10 に示す．複数のデバイスが/Time というトピックをサブスクライブしているた\nめ，パブリッシャーとして機能するデバイスがメッセージの属性値に/Time というトピッ\nクをつけてパブリッシュするとブローカーを介して各デバイスにメッセージが送られる．\nこの際，/Time 以外のトピックをサブスクライブしているデバイスはメッセージを受信し\nない．ブローカーはすべてのメッセージの受信，トピックに関心を持つデバイスの決定，\nサブスクライブしているすべてのクライアントへのっメッセージの送信を行う．オープン\nソースのブローカーも数多く存在しており，実装が容易である利点を持つ．\n図3.10 mqtt プロトコルによる通信の概要図\n3.4.2\nPall0 を用いた各デバイス間の通信\n図3.11 にPall0 を用いた際の通信の概要図を示す通信の信頼性およびリアルタイム性を\n確保するためには，Hololens2 へセンサデータを直接Bluetooth で送信することが理想的で\nある．しかし，Hololens2 が主にサポートしているBluetooth デバイスはキーボードやマウ\n26\nスに限定されており，センサデータをBluetooth 経由でAR アプリケーションに送信する\nことが技術的に困難であるという課題が存在する．さらに，Pall0 自体はWi-Fi が利用で\nきず，単体でMQTT ブローカーにデータをパブリッシュすることができないという制約\nもある．このため，Pall0 が取得する加速度，角速度，圧力センサの値をBluetooth 経由で\nPC に送信し，PC 上で動作するコンソールアプリケーションにこれらのデータを取り込\nむ．このコンソールアプリケーションは，受信した各センサデータに「トピック1」とい\nう属性を付与したメッセージを作成し，MQTT ブローカーへパブリッシュする．AR アプ\nリケーションは，コンソールアプリケーションによってパブリッシュされたセンサデータ\nをサブスクライブすることで，必要なデータをリアルタイムで取得する．AR アプリケー\nションではコンソールアプリケーションがパブリッシュしたセンサデータをサブスクライ\nブにより取得し，3.3 節で述べた通りに操作を行い，仮想的に配置されたアームロボット\nの各関節角度を決定する．AR アプリケーションは各関節角度からトピック2 という属性\nを付与したメッセージを作成後にパブリッシュし，アームロボットがサブスクライブする\nことによりAR アプリケーション内の仮想ロボットと同様の動作を遠隔地で再現する．こ\nのように各デバイス間の通信を行うことで物理的なアームロボットが仮想環境と同期して\n動作し，リアルタイムでの遠隔操作が可能となる。\n図3.11 Pall0 を用いた際の通信の概要図\n3.4.3\nTIARC を用いた各デバイス間の通信\nTIARC はWI-FI が利用可能であるため外部のPC などのを介さずにMQTT ブローカーへ\nのパブリッシュが可能である．さらにデバイス内で姿勢推定が可能であるため，AR アプリ\nケーション内において姿勢推定の必要がなく処理の軽減が可能である．図3.12 にTIFARC\nを用いた際の通信の概要図を示す．TIARC では加速度，角速度，圧力センサ値を取得し\nTIARC の姿勢を推定する．その後，推定結果である姿勢及び圧力センサ値に「トピック\n1」という属性を付与してメッセージを作成，パブリッシュする．以降は3.4.2 節と同様に\n通信を行いアームロボットのリアルタイムでの遠隔操作を行う．\n27\n図3.12 TIFARC を用いた際の通信の概要図\n3.5\nシステムの使用方法\n図3.13 にシステム起動時のAR アプリケーションの様子を示す．AR アプリケーション\n起動後，ユーザはアームロボット，メニューボタン，スタートボタン及びリセットボタン\nが確認可能である．この状態ではアームロボットの操作はできず，手を動かすことやイン\nプットデバイスを操作してもアームロボットは動作しない．アームロボットの操作が不可\n能な状態を用いることで意図しないタイミングで誤ってアームロボットを動作させてしま\nうことを防ぐ．この状態からスタートボタンを押すことで図3.14 に示す状態へ遷移する．\nテキストによる指示が表示され，指示に従いオレンジ色の立方体に自身の手の位置である\n立方体を重ね合わせることでアームロボットの操作を開始する．メニューボタンはアーム\nロボットの操作中も常時表示されており，任意のタイミングで押すことで操作を中断可能\nである．メニューボタン押下後はシステム起動時と同様の状態へ遷移し，操作を開始する\n際と同様の手順で操作の再開が可能である．操作再開時にはオレンジ色の立方体が操作を\n中断した点に出現する．また，リセットボタンによりアームロボットを初期状態へ戻すこ\nとが可能である．\n本システムにおいて使用される画面内のボタンUI は前述の通りメニューボタン，スター\nトボタン，リセットボタンの3 種類のみで構成されている．このようにUI のボタン数を\n既存の手法と比較して大幅に削減していることによりユーザに対する認知的負荷が大幅\nに低減されている．ボタンが少ないため，ユーザは複雑な操作を覚える必要がなく，簡単\nにシステムを利用することが可能となる。また，操作が可能な状態と不可能な状態を明確\nに分けているため，常時操作が可能なシステムに比べ意図しないタイミングでの誤動作の\nリスクを大幅に低減することが可能である．\n28\n図3.13 システム起動時のAR アプリケーションの様子\n図3.14 スタートボタン押下後のAR アプリケーションの様子\n29\n第4章\nユーザ評価実験\n4.1\n実験目的\n本研究で提案するシステムが従来手法に比べ直感的かつ容易に操作が可能であったかを\n検証するためユーザ評価実験を行う．この評価においては従来手法とTIARC を用いた提\n案システムで比較を行う．図4.1 に従来手法を用いたアームロボット操作手法を示す．比\n較対象である従来手法は現在一般的に広く用いられているアームロボットのヘッドの位置\n姿勢及びグリッパーの開閉をそれぞれ方向ボタン，グリッパー開閉ボタンを用いて決定し\n各関節角を逆運動を用いて決定することで操作する手法とする．また，Pall0v2 とPall0v3\nでは把持認識の際に特定のボタンを押すかデバイス自体を握るかという差があるため，こ\nの表面積の差が操作の直観性及び容易さに影響を与えるか検証する．\n図4.1 従来手法用いたアームロボット操作手法\n4.2\n実験環境\nhololens2 はシースルー型ヘッドマウントディスプレイであり外部の様子が視界に入る．\nそのため本実験では部屋の違いによる影響を少なくするため図4.2 に示す部屋を設定し，\n実験時の被験者の向きを固定した．被験者は実験中，実空間では壁のみが視界に入るよ\nう椅子に座る．被験者は提案システムと従来システムの比較実験で男女10 名，Pall0v2 と\n30\nPall0v3 の比較実験で男女15 名であり，本実験ではアームロボットの操作性の比較を目的\nとしているため，操作及び評価AR アプリケーション内の操作のみで行った．\n図4.2 実験環境の全体図\n4.3\n実験方法\n各実験参加者は従来手法及び提案手法またはPall0v2 を用いた操作及びPall0v3 を用いた\n操作を使用して仮想的に配置されたアームロボットを操作した．それぞれ操作を行う順番\nはランダムとした．最初に操作時の動画を用いて操作方法及びインプットデバイスの使用\n方法，行うタスクの説明をした．図4.3 にタスク実行中の様子を示す．被験者にタスクと\nして3 個のブロックをそれぞれの異なる目標位置へ運ぶことを指示し，目標位置に置く際\nには可能な限り目標位置の中心にブロックを置くことを指示した．被験者が理解したこと\nを確認した．その後，被験者にHololens2 を装着してもらい，視度や明るさ，頭のバンド\nの締め具合を調整してもらった．被験者は実験担当者の合図でタスクを開始し，タスクの\n31\n終了後にアンケートに回答した．実験担当者はAR アプリケーション内に表示されるタス\nクの成績を記録した．同様の手順でもう一方の操作を用いてタスクを実行した．\n図4.3 タスク実行中の様子\n4.4\n評価方法\n4.4.1\n定量評価指標\nアームロボットが直感的かつ容易に操作可能かという操作性及び意図したとおりの正確\nな操作が可能であるかを評価するための定量評価指標としてタスク実行時間及びブロック\nを運んだ際の目標位置の中心からの差を用いた．タスクの実行時間はスタートボタンを押\nしてから三つ目のブロックを目標位置に移動させるまでの時間とした．また，定量評価に\nおいては二つの手法に対してタスクの成績を評価するため，f 検定を用い等分散と仮定さ\nれるかを確認し，それに応じたt 検定を行うことで有意差の有無を確認した．この際，優\n位水準は5%とした．\n4.4.2\n主観的な操作のしやすさの評価指標\nアームロボット操作開始までを含めたシステム全体の使いやすさの評価としてSystem\nUsability Scale（SUS）を用いた．SUS は10 の質問に対し5 段階で評価を行う質問票であ\nり，ユーザビリティと学習能力を測定し指標化する[53]．すべての質問の5 段階評価の結\n果は0 から100 の範囲でスコアリングされる，SUS におけるスコアの基準を表4.1 に示す．\n平均点は68 点となっており，平均点以上が良いシステムと言われる．SUS のアンケート\n回答者は各項目を5 段階で評価する．集計方法は奇数の質問の回答スコアから1 を引き，\n偶数の質問スコアを5 から引く．その後，すべてのスコアを合算し2.5 倍したものがSUS\nスコアとなるこれに加え，主観的にアームロボットの操作が直感的かつ容易であったか，\n32\n意図したとおりに操作が可能であったかを検証するため独自に作成したアンケートを用\nいた．\n表4.1 SUS におけるスコアと評価の対応\nSUS score\nGrade\nAdjective Rating\n>80.3\nA\nExcellent\n68 - 80.3\nB\nGood\n68\nC\nOkay\n51 - 68\nD\nPoor\n<51\nE\nAwful\n33\n第5章\n実験結果及び考察\n5.1\n定量評価の実験結果及び考察\n図5.1 に従来手法及びTIARC のタスク完了時間の比較を示す．エラーバーは標準誤差を\n示す．従来手法とTIARC のタスク完了時間を比較した結果，TIARC を用いた提案手法を\n用いてタスクを行った際に従来手法に比べてタスク完了時間が短縮されることが示され，\n二つの手法間のタスク完了時間には有意差が見られた．提案手法はアームロボットを動か\nしたい方向へ手を動かすことやTIARC を持った手を傾ける事でアームロボットの操作が\n可能であり，グリッパーの制御においてもTIARC を強く握るのみで可能であるため，操\n作が直感的に感じられとこがタスク完了時間の短縮に寄与したと考えられる．直感的な操\n作が可能なため，タスク開始から実際の操作に迷わずタスクを行うことが可能であったこ\nともタスク完了時間が短縮されたと考えられる．従来手法はボタン数の多さから操作の間\n隔をつかむことが難しく意図した通りの操作が難しい一方で提案手法はアームロボットを\n動かしたい方向に手を動かすのみで操作可能であるため，意図した通りの操作が可能であ\nる点もタスク完了時間の短縮に寄与したと考えられる．以上のようにタスク完了時間は\nTIARC を用いた提案手法で大幅に短縮されることが明らかとなったがタスク完了時間の\nばらつきは提案手法の方が大きい．従来手法はボタン数が多く操作が複雑なため直感的な\n意図した操作が難しい一方でアームロボットの操作に限らず様々な場面で一般的なユーザ\nインターフェースであるため，個人差が小さくなったと考えられる．これに対し提案手法\nでは手の位置及び手に持ったTIARC の姿勢を用いた操作手法やTIARC を強く握ること\nでグリッパーを操作する手法はユーザが初めて体験する操作手法であり，それに慣れる時\n間には個人差があるため，タスク完了時間のばらつきが大きくなったと考えられる．\n34\n図5.1 従来手法及びTIARC のタスク完了時間の比較\n*:p<0.05\n図5.2 にPall0v2 及びPall0v3 のタスク完了時間の比較を示す．エラーバーは標準誤差を\n示す．Pall0v2 を用いた提案手法とPall0v3 を用いた提案手法のタスク完了時間を比較した\n結果，Pall0v3 を用いた際にタスク完了時間が短縮されることが示され，二つの手法間の\nタスク完了時間には有意差が見られた．Pall0v2 とPall0v3 の差はグリッパーの操作時の\nみである．Pall0v2 では特定の位置にあるボタンを押し，開閉を切り替える必要があるが，\nPall0v3 ではデバイスを握っている間はグリッパーが閉じ続ける制御を行っている．すな\nわち，グリッパーの操作が可能な部分の表面積が異なっている点が最も大きな違いであ\nる．Pall0v3 を用いた提案手法で優位にタスク間長時間が短縮されたことはグリッパーを\n操作可能である部分の表面積を大きくすることは直感的で意図した操作を可能にするこ\nとに寄与していると考えられる．また，Pall0v3 を握っている間グリッパーを閉じる操作\n手法はボタンで切り替える手法に比べて実際のアームロボットの動作に近くより直感的な\n操作が可能であったことがタスク完了時間の短縮に寄与したと考えられる．\nタスク間長時間のばらつきはPall0v3 を用いた提案手法に比べPall0v2 を用いた提案手\n法で大きくなることが示された．Pall0v2 は特定の位置にあるボタンを用いてグリッパー\n35\nの制御を行うためボタンの位置を常に把握しているかという点がタスク完了時間に影響\nしていると考えられる．実際に個々の被験者のタスク完了時間を見ると，Pall0v2 を用い\nた際とPall0v3 を用いた際で差が数秒程度の被験者が複数存在する．このことからグリッ\nパーの操作を行うボタンの位置に迷わず操作を行えた被験者はPall0v3 同程度の時間でタ\nスクを完了することが可能であったと考えられる．これに対し，グリッパーの操作を行う\nボタンの位置を常に把握することが難しかった被験者は通常の操作に加えそのボタンを探\nすことを行ったため，タスク完了時間に影響したと考えられる．\n以上のことからグリッパーの操作が可能な部分の表面積が大きいことは重要な要素であ\nり，その面積がより大きいことがタスク完了時間の短縮に寄与すると考えられる．\n図5.2 Pall0v2 及びPall0v3 のタスク完了時間の比較\n*:p<0.05\nTIARC とPall0v2 の比較においては大きな差が見られない結果となった．TIARC と\nPall0v2 の最も大きな差は円柱型であるか球型であるかという点である．表面の材質の\n差などから単純に比較することは難しいが，本実験の結果からアームロボットの操作にお\nいて使用するインプットデバイスの形状は操作性及びタスク完了時間に影響を与えないこ\nとが明らかとなった．TIARC は表面に取り付けた圧力センサの部分を強く握ることでグ\n36\nリッパーの操作が可能でありPall0v2 に比べグリッパーの操作が可能な部分の面積は大き\nいが，デバイスの任意の部分を握ることでの操作は難しく特定の位置を握る必要がある点\nでPall0v2 と同様であることもタスク完了時間に大きな差が出なかった要因であると考え\nられる．そのため，TIARC においてはデバイス表面全体で把持認識を可能にすることで\nタスク完了時間がより短縮されると考えられる．\n図5.3 に従来手法及びTIARC の目標位置の中心からの差の比較を示す．エラーバーは標\n準誤差を示す．従来手法とTIARC を用いた提案手法でタスクを行った際の目標位置の中\n心からの差を比較した結果，わずかにTIARC を用いた提案手法が小さいことが明らかと\nなったが，有意差は見られなかった．これは，従来手法と提案手法が同等程度の正確な操\n作が可能であることを示しており，操作性の向上により細かな操作が難しくなるなどの欠\n点が提案手法に見られないことを示している．しかし，提案手法においては操作時に手の\n全ての動作を用いて操作を行っており，操作を意図しない微細な動きと操作を意図した動\nきの区別を行っていないため，操作精度が低下した可能性がある．そのため，これらを区\n別し，操作を意図しない微細な手の動きをアームロボットの操作から排除することでより\n操作精度が向上すると考えられる．\n37\n図5.3 従来手法及びTIARC の目標位置の中心からの差の比較\n図5.4 にPall0v2 及びPall0v3 の目標位置の中心からの差の比較を示す．エラーバーは標\n準誤差を示す．Pall0v2 及びPall0v3 を用いた提案手法の目標位置の中心からの差を比較し\nた結果わずかにPall0v2 を用いた手法が小さいことが明らかとなったが，有意差は見られ\nなかった．このことは，アームロボット操作の精度において，グリッパーの操作手法は影\n響を与えないことが示された．Pall0v2 を用いた際にグリッパーを制御するボタンの位置\nに迷い，精度が低下する可能性があるが，提案手法のアームロボット操作が容易であり位\n置の調整が容易であるためグリッパーを制御するボタンを発見後にもアームロボットの頭\n部の位置の調整が行いやすく，操作精度が維持されたと考えられる．\n38\n図5.4 Pall0v2 及びPall0v3 の目標位置の中心からの差の比較\n5.2\n主観的な操作のしやすさの実験結果と考察\n表5.1 に従来手法及びTIARC を用いた提案手法のSUS スコアの平均を示す．結果とし\nて，従来手法で45.7 点であり提案手法で72.2 点であり，4.4.2 節で述べた一般に良いシス\nテムとされる68 点という基準を提案手法では満たしたが，従来手法では大幅に下回る結\n果となった．従来手法と提案手法では操作開始時にスタートボタンを押すことや任意のタ\nイミングでメニューボタンを押すことで操作が中断可能であること，リセットボタンを押\nすことでアームロボットを初期姿勢に戻すことが可能であることは共通である．そのため\n実際にアームロボットの操作を行う際のシステムの使いやすさが評価に影響を与えたと考\nえられる．実際にアームロボットを操作する際には従来手法ではアームロボットの頭部の\n位置や姿勢，グリッパーの制御を全てボタンで行うためボタン数が多くなり，認知的負荷\nが大きく操作が煩雑である．このことがシステム全体に対して使用することが難しい，使\n用には特別な知識が必要だと感じさせ，基準を大きく下回る結果になったと考えられる．\n39\nこれに対し提案手法ではアームロボットの操作中に表示されているボタンはメニューボタ\nンのみであり，認知的負荷が小さい設計となっている．そのため，操作中のシステムの仕\n様が容易であると感じさせることができ，基準を満たす結果となったと考えられる．\n表5.1 従来手法及び提案手法における平均SUS スコア\n手法\nSUS スコア\n従来手法\n45.7\n提案手法\n72.2\nいかにアンケート評価の結果と考察を述べる．アンケートの各項目は「全く思わない」\nを1，\n「非常に思う」を5 としてスコアリングした．また，スコアリングした値を用いて各\nモードの各項目の平均スコアを算出した．表5.2 に被験者に回答してもらったアンケート\n項目及び表5.3 にアンケート評価結果を示す．アンケートの各項目について考察を行う．\nQ1 　アームロボットの操作は直感的に感じましたか？\n従来手法とTIARC の比較において，従来手法で2.8 点でありTIARC で4.2 点という\n結果になった．従来手法のアームロボットの頭部の位置や姿勢，グリッパーの操作\nを全てボタンで行う操作手法は操作中どのボタンがどの方向に動くかを常に把握し\nておく必要があるため，例えば「右側に動かしたい」と考えてから実際に動かすま\nでに右側へ動かすボタンを認識し，ボタンを押すという工程が必要なため直感的で\nはないと感じられたと考えられる．これに対し，提案手法ではアームロボットの頭\n部の位置を動かしたい方向に手を動かす，傾けるやTIARC を握るのみであるため，\n実際のアームロボットの動作に近く直感的に操作できると感じられたと考えられる．\nPall0v2 とPall0v3 の結果を比較すると，Pall0v2 で2.9 点，Pall0v3 で3.6 点という結\n果になった．Pall0v2 ではグリッパーの操作の差異に特定の位置のボタンを押す必要\nがあることが実際の動作に近くなく，直感的ではないと感じられたと考えられる．こ\nれに対し，Pall0v3 は強く握っている間グリッパーを閉じ続けるという実際のアーム\nロボットの動作に近い操作が可能なため直感的に感じられたと考えられる．\nQ2 　アームロボットの操作は難しく感じましたか？\n従来手法とTIARC の比較において，従来手法で4.3 点でありTIARC で2.9 点という\n結果になった．Q1 で述べた通り，従来手法はどのボタンがどの方向に動かすかを把\n握しておく必要があることやボタン数が多いことから操作が煩雑であることが操作が\n難しいと感じさせたと考えられる．これに対して直感的な操作が可能な提案手法では\n操作者が実際にボタンを押すなどして操作を行うことが少ないため操作が容易に感じ\nられたと考えられる．Pall0v2 とPall0v3 を比較すると，Pall0v2 で3.0 点，Pall0v3 で\n3.2 点であり大きな差は見られなかった．このことは，本実験においてはグリッパー\nを操作する部分の表面積の大きさはアームロボットの操作自体が難しく感じるかと\nいう点に影響を与えないことを示している．グリッパーの操作はアームロボットの\n操作の内の一部分でありその操作を行う時間はアームロボットの頭部の位置や姿勢\nの操作を行う時間に比べて少ないため，主観的な操作の難しさに影響を与えなかっ\nたと考えられる．\n40\nQ3 　アームロボットの操作の精度に満足していますか？\n従来手法とTIARC の比較において，従来手法で2.5 点でありTIARC で4.0 点という\n結果になった．定量評価の結果においては従来手法と提案手法の操作精度を比較す\nる目標位置の中心からの差の比較においては大きな差が見られなかったにも関わら\nず，差が見られたことは主観的に意図した通りの操作が可能であったかが影響を与\nえていると考えられる．意図した通りの操作が可能であったことで，素早く意図し\nた箇所にアームロボットを動かすことが可能になり，精度高く操作をしていると感\nじさせたと考えられる．Pall0v2 とPall0v3 の比較においては両手法で3.1 点と差が見\nられなかった．これはQ2 と同様にグリッパーを操作する時間とアームロボットの頭\n部の位置及び姿勢を操作する時間の差からグリッパーを操作の影響が小さく，同程\n度の操作精度の満足度となったと考えられる．\nQ4 　アームロボットの操作の習得は容易であると感じましたか？\n従来手法とTIARC の比較において，従来手法で2.4 点でありTIARC で3.4 点という\n結果になった．操作の習得という点においては操作が単純であるかや覚えやすいか\nという点が影響していると考えられる．操作が単純であるかという点においては従\n来手法はQ2 で述べた通り操作が煩雑であるため難しく感じられた可能性がある一方\nで提案手法ではアームロボットの操作中に必要なボタンがなく操作自体が単純に感\nじられたと考えられる．また，従来手法ではボタン数の多さからどのボタンがどの\nような操作が可能かを覚えることが難しいことが操作の習得が難しいと感じさせた\nと考えられる一方で定量評価やこれまでのアンケート評価から示されたように直感\n的かつ容易な操作が可能な提案手法では覚える必要があることが少なく習得が容易\nであると感じさせたと考えられる．Pall0v2 とPall0v3 の比較結果を見るとPall0v2 で\n3.6 点でありPall0v3 で4.0 点とわずかにPall0v3 が容易に操作を習得可能と感じられ\nることが明らかとなった．これまで述べた通りPall0v2 ではグリッパーの操作をボタ\nンで行うためボタンの位置を覚える必要があることが操作手法を容易に習得可能と\n感じるかに影響を与えたと考えられ，Pall0v3 ではこの操作を行う部分の表面積が大\nきいことが操作手法を容易に習得可能と感じさせることに寄与したと考えられる．\nQ5 　アームロボットの操作中に疲労を感じましたか？\n従来手法とTIARC の比較において，従来手法で2.8 点でありTIARC で2.5 点と両手\n法でおおよそ同程度日疲労を感じている結果になった．従来手法においては操作に\n必要なボタン数が多いため操作中の認知的負荷が大きくなり，一定の疲労が感じら\nれたと考えられる．提案手法においては操作が必要なボタン数が少ないため認知的\n負荷を低減可能である一方でアームロボットの操作中は常に手を動かす必要がある\nため身体的な疲労が大きく一定の疲労が感じられたと考えられる．Pall0v2 とPall0v3\nの比較においてはPall0v2 で1.7 点でありPall0v3 で3.3 点とPall0v3 を用いた手法で\nより疲労を感じられることが明らかとなった．Pall0v3 ではグリッパーの操作におい\nて握っている間グリッパーを閉じる操作を行っているため，一定以上握力を必要と\nする時間がPall0v2 に比べて長くなり身体的な疲労が大きいためより疲労を感じられ\nていると考えられる．\nQ6 　操作のインターフェースは理解しやすかったですか？\n41\n従来手法とTIARC の比較において，従来手法で3.4 点でありTIARC で3.7 点と大き\nな差は見られないという結果になった．従来手法において認知的負荷の大きい操作\nインターフェースでありながら提案手法と同程度理解しやすいと感じられたことは，\n従来手法で用いているボタン型のインターフェースはアームロボットの操作に限らず\n多くの場面で利用されているものであるため，理解しやすいと感じられたと考えら\nれる．提案手法においては操作が必要なボタン型のインターフェースが少ないこと\nに加え，アームロボットの操作時にもTIARC を強く握るのみの操作であったため理\n解しやすいと感じられたと考えられる．Pall0v2 とPall0v3 の比較においてはPall0v2\nで3.6 点でありPall0v3 で3.8 点と同程度インターフェースが理解しやすいと感じら\nれていることが明らかとなった．グリッパーの操作において単純にデバイスを握る\nのみで操作が可能であることと特定の位置のボタンを押す必要があることの差によ\nり理解のしやすさにわずかに差が生じているが，操作が必要なボタン型のインター\nフェースは両手法で少なくなっているため理解しやすいと感じられたと考えられる．\nQ7 　課されたタスクは難しいと感じましたか？\n従来手法とTIARC の比較において，従来手法で3.2 点でありTIARC で2.0 点と提案\n手法を用いた際によりタスクを簡単に感じていることが明らかとなった．従来手法\nにおいては操作時の認知的負荷が大きいことに加え，操作が煩雑であり直感的かつ\n容易な操作が難しいため，タスク自体を難しく感じたと考えられる．これに対し提\n案手法においてはQ4 の考察で述べた通り直感的かつ容易な操作が可能であるため，\nアームロボットの操作に迷うことなくタスクを行うことが可能となりタスク自体が\n簡単に感じられたと考えられる．Pall0v2 とPall0v3 の比較においてはPall0v2 で2.1\n点，Pall0v3 で1.8 点とわずかにPall0v3 を用いた際にタスクが簡単に感じられる結果\nとなった．両手法においてアームロボットの頭部の位置及び姿勢の決定の操作は直\n感的かつ容易に行うことが可能であったため一定以上タスクが簡単に感じられたと\n考えられる．Pall0v3 においてはグリッパーの操作においてより実際のグリッパーの\n動きに近くボタンの位置を常に把握する必要のない操作が可能であったためPall0v2\nに比べ直感的かつ容易に感じられわずかにタスク自体が簡単に感じられたと考えら\nれる．\nQ8 　アームロボットは意図した通りに動きましたか？\n従来手法とTIARC の比較において，従来手法で2.5 点でありTIARC で4.0 点と提案\n手法において大幅に意図した通りの操作が可能であると感じられることが明らかと\nなった．従来手法においては常に各ボタンを押したことによるアームロボットの動\n作を把握する必要があるため操作ミスが起きやすく意図した通りの操作が難しいと\n感じられたと考えられる．これに対して提案手法においてはこれまで述べた通り直\n感的かつ容易な操作が可能であることに加えて手の動きに合わせてアームロボット\nが動作するため操作ミスが起きずらく，意図した通りの操作が可能であったと考え\nられる．Pall0v2 とPall0v3 の比較においてはPall0v2 で3.0 点でありPall0v3 で3.1 点\nと大きな差は見れれない結果となった．これはアームロボットの頭部の位置及び姿\n勢の決定のおいては同様の操作手法でありその操作手法がTIARC を用いた場合と同\n様に直感的な操作が可能であるため意図した通りの操作が可能であったと考えられ\nる．また，グリッパーの制御において意図した通りの操作が可能かという点におい\n42\nてはボタンによる操作が必要か単純にデバイスを握るのみで操作可能かは影響を与\nえないことが明らかとなった．\n表5.2 評価実験のアンケート項目\nquestion\nQ1 　アームロボットの操作は直感的に感じましたか？\nQ2 　アームロボットの操作は難しく感じましたか？\nQ3 　アームロボットの操作の精度に満足していますか？\nQ4 　アームロボットの操作の習得は容易であると感じましたか？\nQ5 　アームロボットの操作中に疲労を感じましたか？\nQ6 　操作のインターフェースは理解しやすかったですか？\nQ7 　課されたタスクは難しいと感じましたか？\nQ8 　アームロボットは意図した通りに動きましたか？\n表5.3 評価実験のアンケート結果\n質問番号\n従来手法\nTIARC\nPALL0v2\nPALL0v3\nQ1\n2.8\n4.2\n2.9\n3.6\nQ2\n4.3\n2.9\n3.0\n3.2\nQ3\n2.5\n4.0\n3.1\n3.1\nQ4\n2.4\n3.4\n3.6\n4.0\nQ5\n2.8\n2.5\n1.7\n2.3\nQ6\n3.4\n3.7\n3.6\n3.8\nQ7\n3.2\n2.0\n2.1\n1.8\nQ8\n2.5\n4.0\n3.0\n3.1\n43\n第6章\n結論と今後の展望\n6.1\n結論\n本研究では，産業などの現場に導入され，生産性や安全性などを向上させているアーム\nロボットがその作業を完全に自動化することは難しく人が操作を行う必要がある場合があ\nるが，先行研究や一般に用いられている操作手法には直感的かつ意図しない動作の発生を\n防止可能な操作手法がない点に着目し，アームロボットのリモート操作手法を提案した．\n本研究で提案した手法は，AR アプリケーション内に仮想的に配置されたアームロボット\nを操作することでそれに同期した実際のアームロボットも操作可能な手法となっている．\nまた，仮想的に配置されたアームロボットについては手の位置及びインプットデバイス\nより取得した姿勢，グリッパーの開閉を用いてロボットアームのヘッドの位置姿勢を決定\nし，各関節角を逆運動学を用いて決定することで操作を行う手法である．提案システムを\n用いて従来手法である一般的に広く用いられているボタンを使用して操作を行う手法と\n比較する評価実験を行った結果，操作精度は従来手法と同程度であるが，タスク完了まで\nの時間が優位に短くなることが明らかとなった．Pall0v2 とPall0v3 の比較結果については\nPall0v3 でタスク完了時間が優位に短縮されることが明らかとなった．これはグリッパー\nの制御において，ボタンによる操作に比べ単純にデバイスを握るのみの操作が直感的かつ\n容易であり，制御可能な部分の表面積の大きさがアームロボットの操作に影響を与えるこ\nとが明らかとなった．従来手法と提案手法のシステム全体としての使いやすさを評価した\nSUS の結果から提案手法では一定以上使いやすいシステムであるが，従来手法では基準\nを満たさず使用が難しいことが明らかとなった．このことから提案手法ではボタン数の少\nなさから認知的負荷を低減可能であり操作に迷うことが少ないシステムであることが確認\nできた．また，アンケート結果から提案手法は従来手法に比べて直感的かつ容易であり，\n意図した通りの操作が可能であることが明らかとなった．Pall0v2 とPall0v3 の比較におい\nてはPall0v3 を用いた手法がより直感的に操作可能であることが判明した．このことから\nもグリッパーを制御可能な部分の表面積の大きさがアームロボットの操作の直感性に影響\nを与えることが示された．\n提案手法を用いることでアームロボットの操作を直感的かつ容易に行うことを可能にし\nた．アームロボットの操作部分以外においてもシステム全体としてボタン数を大幅に減ら\nすことで認知的負荷を低減し使いやすいシステムと感じられることが示された．また，グ\nリッパーをの制御可能な部分のひょめんせきの大きいことが直感的かつ容易な操作を可能\nにすることに寄与することが示された．\n44\n6.2\n今後の展望\n今後の展望として本研究の評価実験では各操作手法で一回のみタスクを行ったことから，\n操作手法の慣れによる操作のしやすさ，タスク実行時間の変化や差異については明らかに\nなっていないため，長期的に複数回タスクを行うことでの変化を調査する実験を行う必要\nがある．操作面においては意図しない手の揺れによる動きと操作を意図した動きを区別す\nることでより正確な操作を可能にする必要がある．仮想空間と実環境の同期においても課\n題が残っている．仮想的に配置されたアームロボットの姿勢を常に実空間のアームロボッ\nトの姿勢と同期することは難しく，実空間において周囲の安全性を損なう危険性がある．\nそのため，図6.1 に示すような操作手法を開発中である．この操作手法は実空間のアーム\nロボットと仮想アームロボットを分けて表示してあり，仮想アームロボットを操作，姿勢\nを固定後に実空間と同期したアームロボットが追従する形で動作する．追従している際\nユーザは仮想アームロボットの操作が不可能となる．この操作手法により直感的かつ容易\nな操作を維持すると同時に実空間において周囲の安全性の維持が可能になると考える．\n図6.1 安全性確保のための操作手法（開発中）\n多くのアームロボットに汎用的に対応していない点も課題である．現状のシステムでは\n特定のアームロボットにのみ対応しており，同じ自由度であってもその他もアームロボッ\nトの操作が不可能である．現在開発中の手法としてはアームロボットのヘッドのみを仮想\n的に提示，操作を行い，その位置姿勢のみを決定する手法であるが，このような手法で操\n作が可能であるかは実際のアームロボットに依存するため汎用的であるとは言えない．今\n日導入されているアームロボットの種類は数多く，その多くに対応可能なシステムとする\nことでより実用的にしていきたい．また，システム全体として実際のアームロボットの状\n態や周辺オブジェクトの状態をAR アプリケーションへフィードバックを行っていないた\nめ，これを行うことで遠隔地の実環境においてもアプリケーション内と同様な精度で操作\nを可能にする必要がある．\n45\n以上の課題を解決することでより実用的なシステムとし，提案手法を発展させていき\nたい．\n46\n謝辞\n本研究の機会を与えて下さり，研究面について大変ご丁寧なご指導を賜りました，青山\n学院大学理工学部情報テクノロジー学科Guillaume LOPEZ 教授およびトゥルク応用科学\n大学Luimula Mika 教授に深く感謝申し上げます．そして，研究会などを通して助言をいた\nだいたLOPEZ 研究室の皆様並びに実験に協力していただいた皆様に深く感謝いたします．\n2025 年1 月31 日\n阿部　悠貴\n47\n参考文献\n[1] 安藤健. コロナ禍におけるサービスロボットの活用とインタラクション技術. 計測と\n制御, Vol. 61, No. 3, pp. 231–234, 2022.\n[2] 総務省. https://www.microsoft.com/ja-jp/hololens/hardware. [ac-\ncessed 2024.08.24].\n[3] 榊原伸介. 知能ロボットによる工場自動化とiot, ai 活用について. システム/制御/情\n報, Vol. 61, No. 3, pp. 101–106, 2017.\n[4] IFR International Federation of Robotics.\nWorld robotics 2024.\nhttps://ifr.\norg/img/worldrobotics/Press_Conference_2024.pdf, 2024.\n[accessed\n2024.12.24].\n[5] オムロン株式会社.\nオムロン\n制御機器\nソリューション\n事例.\nhttps://www.fa.omron.co.jp/solution/case/.\n[6] 株式会社\nKEYENCE.\nFa\nロボットの導入事例.\nhttps://www.keyence.co.jp/landing/req/vision/cv-x 1097 04.jsp.\n[7] 三治信一朗. ロボット事例からみる, アプリケーション, ソリューション開発の方向性.\nシステム/制御/情報, Vol. 64, No. 11, pp. 447–442, 2020.\n[8] MONOist. 2022年展望. https://monoist.itmedia.co.jp/mn/articles/2201/13/news127.html.\n[9] Nichola Lowe and Thomas Kemeny. Disparities in robot adoption among u.s. manufac-\nturers. Industry and Innovation, Vol. 28, No. 9, pp. 1062–1084, 2021.\n[10] Lindsay Sanneman, Christopher Fourie, and Julie A. Shah. The state of industrial robotics:\nEmerging technologies, challenges, and key research directions. ArXiv, 2020.\n[11] J. Gray, S. Davis, and M. G. Mullins. Challenges for industrial robot applications in food\nmanufacturing. In Proceedings of the ACM International Conference on Human-Robot\nInteraction, pp. 328–472, 2018.\n[12] MONOist. 3dexperience world japan 2022. https://monoist.itmedia.co.jp/\nmn/articles/2211/24/news052.html.\n[13] 伊藤忠テクノソリューションズ株式会社. 仮想gpu によるcad vdi で設計開発プロセ\nスを加速「設計開発業務の働き方改革を実現」. https://www.ctc-g.co.jp/report/case-\nstudy/toyota02/.\n[14] NECソリューションイノベータ. 仮想gpuによるcad vdiで設計開発プロセスを加速「設\n計開発業務の働き方改革を実現」. https://www.ctc-g.co.jp/report/case-study/toyota02/.\n48\n[15] SocoCacico. Sococacico. https://sococacico.com/.\n[16] AIMultiple.\nXr/ar\nin\nmanufacturing:\n7\nuse\ncases\nwith\nexamples.\nhttps://research.aimultiple.com/ar-in-manufacturing/.\n[17] 小宮昌人. 生産現場におけるデジタルツインの今. 工場管理/日刊工業新聞社[編],\nVol. 68, No. 2, pp. 14–17, 2022.\n[18] Tenaris.\nVr and ar technology used to manage argentine project from italy.\nhttps://www.tenaris.com/en/news/2021/vr-and-ar-technology-used-to-manage-argentine-\nproject-from-italy.\n[19] FUJITSU.\n在庫管理の改善に売り上げアップ，保守点検の効率化.\nhttps://jp.fujitsu.com/platform/server/advantages/special/jokun/10-ar/.\n[20] HOLOLAB. Assists. https://hololab.co.jp/assists.\n[21] universal\nrobot.\nhttps://s3-eu-west-1.amazonaws.com/\nur-support-site/43932/UR5e_User_Manual_jp_Global.pdf,\n2022.\n[accessed 2024.08.24].\n[22] 三菱電機. Melsoft rt visualbox. https://www.mitsubishielectric.com/fa/\nproducts/rbt/assista/smerit/vb/index.html.\n[23] CHITOSE ROBOTICS.\ncrewbo studio.\nhttps://chitose-robotics.com/\narchives/233756.\n[24] 楓和憲, 坂井田千摩, 綿貫啓一. タッチパネルおよびジャイロスコープを用いた多関節\nマニピュレータの無拘束遠隔操作システムの開発. 日本機械学会論文集, Vol. 81, No.\n830, pp. 15–00177, 2015.\n[25] Paul Hebert, Jeremy Ma, James Borders, Alper Aydemir, Max Bajracharya, Nicolas Hud-\nson, Krishna Shankar, Sisir Karumanchi, Bertrand Douillard, and Joel Burdick. Super-\nvised remote robot with guided autonomy and teleoperation (surrogate): a framework for\nwhole-body manipulation. In 2015 IEEE international conference on robotics and au-\ntomation (ICRA), pp. 5509–5516. IEEE, 2015.\n[26] Reduanur Rahman, Md Sajid Rahman, and Jillor Rahman Bhuiyan. Joystick controlled\nindustrial robotic system with robotic arm. In 2019 IEEE International Conference on\nRobotics, Automation, Artiﬁcial-intelligence and Internet-of-Things (RAAICON), pp. 31–\n34. IEEE, 2019.\n[27] Sunao Hashimoto, Akihiko Ishida, Masahiko Inami, and Takeo Igarashi. Touchme: An\naugmented reality based remote robot manipulation. In The 21st International Conference\non Artiﬁcial Reality and Telexistence, Proceedings of ICAT2011, Vol. 2, 2011.\n[28] 竹内良緒, タケウチリオ. タッチパネルを用いた容易な把持幅指定によるロボットアー\nムの操作インターフェース.\n49\n[29] Kalagotla Chenchireddy, Radhika Dora, Gouse Basha Mulla, Varghese Jegathesan, and\nShabbier Ahmed Sydu.\nDevelopment of robotic arm control using arduino controller.\nIAES International Journal of Robotics and Automation (IJRA), Vol. 264, pp. 1024–1064.\n[30] Hairong Jiang, Juan P Wachs, Martin Pendergast, and Bradley S Duerstock. 3d joystick\nfor robotic arm control by individuals with high level spinal cord injuries. In 2013 IEEE\n13th International Conference on Rehabilitation Robotics (ICORR), pp. 1–5. IEEE, 2013.\n[31] Ivan Rulik, Md Samiul Haque Sunny, Javier Dario Sanjuan De Caro, Md Ishrak Islam\nZarif, Brahim Brahmi, Sheikh Iqbal Ahamed, Katie Schultz, Inga Wang, Tony Leheng,\nJason Peng Longxiang, et al. Control of a wheelchair-mounted 6dof assistive robot with\nchin and ﬁnger joysticks. Frontiers in Robotics and AI, Vol. 9, p. 885610, 2022.\n[32] Nikolaos Mavridis, Georgios Pierris, Paolo Gallina, Zacharoula Papamitsiou, and Umair\nSaad. On the subjective difﬁculty of joystick-based robot arm teleoperation with auditory\nfeedback. In 2015 IEEE 8th GCC Conference & Exhibition, pp. 1–6. IEEE, 2015.\n[33] 並木惇, 菅原悠平, 松嵜昭雄. ジェスチャーによるロボット操作におけるモデリングに\n関する一考察(2) 大学生を対象とした実験授業を事例として. 日本科学教育学会年会\n論文集42, pp. 383–386. 一般社団法人日本科学教育学会, 2018.\n[34] Poltak Sihombing, Rifky B. Muhammad, Herriyance Herriyance, and Elviwani Elviwani.\nRobotic arm controlling based on ﬁngers and hand gesture. In 2020 3rd International\nConference on Mechanical, Electronics, Computer, and Industrial Technology (MECnIT),\npp. 40–45, 2020.\n[35] Pradeep .J. Design and implementation of gesture controlled robotic arm for industrial\napplications. International Journal of Scientiﬁc Research, Vol. 3, pp. 202–209, 10 2016.\n[36] 川西巧人. Leap motion を使用したロボットアームの操作手法の開発. 2021.\n[37] 日置真優. ジェスチャを用いたアームロボットの制御. 2018.\n[38] Hanxiao Chen. Motion control of interactive robotic arms based on mixed reality devel-\nopment. 2024.\n[39] 福岡正彬, 中村文彦, 滝澤瞭, 正井克俊, 北崎充晃, 杉本麻樹. Facedrive: 顔表情による装\n着型ロボットアーム操作手法の提案. 日本バーチャルリアリティ学会論文誌, Vol. 25,\nNo. 4, pp. 451–461, 2020.\n[40] 木村拓己, 土田修平, 寺田努, 塚本昌彦ほか. 協働ロボットアームのためのハンズフリー\n制御手法の提案. 研究報告音楽情報科学(MUS), Vol. 2021, No. 43, pp. 1–8, 2021.\n[41] 高城頌太, 谷口尚平, 中野聡大, 岩澤有祐, 鈴木雅大, 熊谷亘, 谷中瞳, 松尾豊. 大規模言\n語モデルを補助に用いた言語指示ロボット学習のタスク汎用性の分析. 人工知能学会\n全国大会論文集第37 回(2023), pp. 2O1GS805–2O1GS805. 一般社団法人人工知能学\n会, 2023.\n50\n[42] Michael Ahn, Anthony Brohan, Noah Brown, Yevgen Chebotar, Omar Cortes, Byron\nDavid, Chelsea Finn, Chuyuan Fu, Keerthana Gopalakrishnan, Karol Hausman, et al.\nDo as i can, not as i say: Grounding language in robotic affordances. arXiv preprint\narXiv:2204.01691, 2022.\n[43] Maximilian St¨olzle,\nSonal Santosh Baberwal,\nDaniela Rus,\nShirley Coyle,\nand\nCosimo Della Santina.\nGuiding soft robots with motor-imagery brain signals and\nimpedance control, 2024.\n[44] Ruohan Zhang, Sharon Lee, Minjune Hwang, Ayano Hiranaka, Chen Wang, Wensi Ai, Jin\nJie Ryan Tan, Shreya Gupta, Yilun Hao, Gabrael Levine, Ruohan Gao, Anthony Norcia,\nLi Fei-Fei, and Jiajun Wu. Noir: Neural signal operated intelligent robots for everyday\nactivities, 2023.\n[45] 久保山瞳, 小林一郎. 制御コマンドの言語化による言語指示操作への取り組み. 人工\n知能学会全国大会論文集第38 回(2024), pp. 3Xin284–3Xin284. 一般社団法人人工知\n能学会, 2024.\n[46] 黄瀬輝, 奥村亮, 谷口忠大. ロボット制御における大規模言語モデルと世界モデルの融\n合. 人工知能学会全国大会論文集第37 回(2023), pp. 2G5OS21e01–2G5OS21e01. 一\n般社団法人人工知能学会, 2023.\n[47] 藤井彬, 田中和明. 低遅延かつ軽量なセンサネットワーク実現のための技術研究. 情\n報処理学会研究報告, Vol. 2016, , 2016.\n[48] HoloLens2― 概要,\n機能,\n仕様.\nhttps://www.soumu.go.jp/\njohotsusintokei/whitepaper/ja/r04/html/nd121110.html.\n[ac-\ncessed 2024.12.24].\n[49] With PALL0™the ongoing digitalization of healthcare means less screen time and\nmore engaging fun! https://www.ai2ai.fi/. [accessed 2024.08.24].\n[50] 茅原崇徳, 大山修斗, 瀬尾明彦. 個人差への対応を考慮した人間工学的設計問題の定式\n化. 日本機械学会論文集C 編, Vol. 79, No. 799, pp. 800–813, 2013.\n[51] 横山清子, 楯千弘, 藤巻吾朗, 安藤敏弘. 1e1-5 グリップ表面の凹凸模様が握り易さに\n与える影響評価. 人間工学, Vol. 50, No. Supplement, pp. S186–S187, 2014.\n[52] 笹野祐嗣. 握りやすい把持体形状デザインを目的とした3 次元把持体データの特徴分\n析に関する研究.\n[53] James R Lewis. The system usability scale: past, present, and future. International Journal\nof Human–Computer Interaction, Vol. 34, No. 7, pp. 577–590, 2018.\n51\n伊藤　雄一　情報テクノロジー学科　教授\nQ\nこのような関連研究は多いと思うが，技術的に優位な点はなにか．直接指示と間接\n指示で比較の方法がアンフェアだと思います．\nA\nまず，技術的に優位な点としては手と手に持ったインプットデバイス及びヘッドマ\nウントディスプレイのみで直感的かつ容易にアームロボットの遠隔操作が可能であ\nる点です．先行研究では直感的に操作可能ですが，意図しない動作が発生する可能\n性がある手法や意図しない操作が発生する可能性は低いですが直感的な操作が難し\nい等直感的であることと容易であることの条件を同時に満たす操作手法は見られず，\nこれら二つの条件を同時に満たしている点が技術的に優位な点であると考えていま\nす．比較の方法については，広く一般に普及している操作手法と比べる必要がある\nと考え本研究のような比較を行いました．しかし，アンフェアである点はおっしゃ\nる通りだと考えており，今後様々な先行研究で提案されている直接指示の手法と比\n較する必要があると考えています．\n52\n",
        "chunks": [
            "M2024_Harutaka_Abe. M2024_Harutaka_Abe. M2024_Harutaka_Abe",
            " \n \n \n \n \n青  山  学  院  大  学 \n \n理  工  学  研  究  科 \n \n \n \n理工学専攻    知能情報    コース \n \n \n \n \n修  士  論  文 \n \n \n \n       学 生 番 号           35623214       \n \n \n       氏     名      阿部 悠貴       \n \n \n研究指導教員    ロペズ・ギヨーム      \n \nThe Academic Year of 2024, Submitted on January 31st, 2025 \n \nGraduate School of Science and Engineering, Aoyama Gakuin University \n \nTitle: Combining AR and input device to control remotely a robot-arm  \nStudent Name: Harutaka Abe  \nID Number: 35623214 \nDegree: Master of Engineering \nCou",
            "mber: 35623214 \nDegree: Master of Engineering \nCourse: Intelligence and Information \nThesis Advisor: Professor Guillaume Lopez \n \nAbstract  \n　The introduction of robotics has attracted attention in factories and other workplaces to \nimprove productivity and safety. Furthermore, remote and unmanned robotics are rapidly \nadvancing due to the impact of COVID-19, and the number of industrial robots being \nintroduced is increasing yearly. The trend towards the introduction of industrial robots is to ",
            "wards the introduction of industrial robots is to \nautomate various tasks. However, it is not easy to automate all tasks, and detailed tasks \nrequire human work or the operation of industrial robots by humans. Besides, the lack of \npersonnel who can operate industrial robots is an obstacle to the introduction of industrial \nrobots.  \n　This study focuses on arm robots, widely used as industrial robots, and proposes an \nintuitive and easy-to-operate teleoperation method combining an Augmented Real",
            "e teleoperation method combining an Augmented Reality (AR) \ninterface and an original intuitive input device (TIARC). The proposed method enables the \nreal environment arm robot to be operated in synchronization with the arm robot by \noperating the arm robot virtually in an AR application. The manipulator controls the \nfollowing three pieces of information, and the joint angles of the robot arm are then \ndetermined using inverse kinematics. \n●​ The hand position determines the position of the ro",
            "he hand position determines the position of the robot arm head. \n●​ TIARC orientation determines the robot's arm posture. \n●​ TIARC gripping force determines the opening and closing of the robot arm gripper.  \nEvaluation experiments were conducted to verify the effectiveness of the proposed \nmethod and to investigate whether the size of the operable area of the gripper affects the \noperation. Subjects were asked to complete a task using a conventional system with \nmultiple virtual buttons, TIARC",
            "ional system with \nmultiple virtual buttons, TIARC, and similar intuitive input devices provided by Ai2AI \n(Pall0v2 and Pall0v3). \nThe results showed that TIARC reduced task completion time while ensuring operation \naccuracy similar to that of the conventional system. Besides, subjective assessment \nresults showed that TIARC is more intuitive and easier to operate. Compared with Pall0v2 \nand Pall0v3, whose gripper control areas are smaller and more prominent than the TIARC \none, the control accu",
            "re prominent than the TIARC \none, the control accuracy was the same, but Pall0v3 task completion time was the \nshortest. This indicates that the area in which the gripper can be manipulated influences \nthe operability of the arm robot. \nIn the evaluation experiments in this study, the task was performed only once for each \nmanipulation technique, so changes due to familiarisation with the manipulation are \nunclear. Future long-term experiments should be conducted to investigate changes in \nopera",
            "ould be conducted to investigate changes in \noperability and task execution time. In order to improve the accuracy of operations, a \nmethod to distinguish between unintended and intended movements is required. In this \nstudy, only synchronization between the arm robot in the application and the actual \nenvironment was carried out, but the surrounding situation is also an important factor \nand needs to be synchronized. In addition, developing a more generalized operation \nmethod for various arm r",
            "re generalized operation \nmethod for various arm robots is necessary. \n理工学専攻修士論文要旨 \n \n \n： 2024年度 \n： 2025年　1月　31日 \n専修コース： 知能情報コース \n： 35623214 \n： 阿部　悠貴 \n研究指導教員： ロペズ　ギヨーム　教授 \n \n（論文題目） \n拡張現実及びインプットデバイスを用いたアームロボットリモートコントロールシステム \n \n（内容の要旨） \n　 \n工場などの現場では生産性や安全性の向上を目的としたロボティクスの導入が注目されている．さらに，新\n型コロナウイルス感染症（COVID-19）の影響でリモート化や無人化が急速に進展しており，産業用ロボットの\n導入台数は年々増加している．産業用ロボット導入の動向として様々な作業を自動化する傾向にあるが，す\nべての作業を自動化することは難しく細かなタスクは人による作業や人による産業用ロボットの操作が必要で\nあり，操作ができる人材の不足が産業用ロボット導入の妨げとなっている． \n本研究では産業用ロボットとして広く利用されている",
            "材の不足が産業用ロボット導入の妨げとなっている． \n本研究では産業用ロボットとして広く利用されているアームロボットに注目し，その直感的かつ容易に操作\n可能な遠隔操作手法の開発を目的としている．具体的に，拡張現実（AR）による遠隔ロボットの状態\nの可視化と，アームロボットを直感的に操作可能とする物理的な入力インタフェースを組み合わせ\nたシステムを考案・実装し，その有効性を検証することを目標とした． \n開発したARアプリケーション内，仮想的に配置された操作対象のアームロボットを操作することで，それに\n同期した実際のアームロボットも操作可能にしている．また，自作した直感的入力デバイスTIARCを用いて\n，以下の３つのアームロボットの情報を決定し，各関節角を逆運動学から導く方法を実装している． \n●​\n操作者の手の位置がアームロボットの位置を決定する． \n●​\nTIARCの姿勢がアームロボットの姿勢を決定する． \n●​\nTIARCを握る度合いがアームロボットのグリッパーの開閉を決定する． \nTIARCの有効性の検証及びグリッパーの操作可能な部分の面積の大きさが操作に影響を与えるかを調査\nした．",
            "ARCの有効性の検証及びグリッパーの操作可能な部分の面積の大きさが操作に影響を与えるかを調査\nした．有効性の検証のための評価実験においては従来手法として，仮想空間内の複数のボタンで操作を行\nうシステムとTIARCを用いた提案システムで被験者にタスクを課し比較した．グリッパー操作可能エリアの\n影響を検証するため，TIARCと，Ai2AI社が提供するPall0v2（小さなボタンによる制御）及びPall0v3\n（デバイス全面積にうよる制御）を比較した． \n結果として提案システムで優位にタスク完了時間が短縮され，従来システムと同程度のせ精度で操作が可\n能であることが明らかとなった．アンケート評価の結果からは提案手法がより直感的かつ容易な操作が可能で\nあることが示された．特定の位置のボタンによりグリッパーの操作を行うPall0v2とデバイスを強く握ることでグ\nリッパーの操作を行うPall0v3の比較においては精度は同程度であったがPall0v3で優位にタスク完了時間が\n短縮されたことから提案手法においてグリッパーの操作が可能な面積がアームロボットの操作性に影響を与\nえることが示された． \n本研究",
            "おいてグリッパーの操作が可能な面積がアームロボットの操作性に影響を与\nえることが示された． \n本研究の評価実験では、各操作手法で一回のみタスクを行ったため，操作の慣れによる変化は明らかに\nなっていない．今後は長期的な実験を行い，操作性やタスク実行時間の変化を調査する必要がある．操作の\n正確性向上のため，意図しない手の揺れと意図した動作を区別する手法が求められる．本研究にいおいて\nはアプリケーション内と実環境のアームロボットの同期のみを行ったが，周囲の状況も重要な要素であり，同\n期を行うひつようがある．また，多様なアームロボットへの対応が課題であり、より汎用的な操作手法の開発が\n必要である． \n​\n \n青山学院大学大学院理工学研究科 \n拡張現実及びインプットデバイスを用いたアームロボットリ\nモートコントロールシステム\n阿部　悠貴\n2025/02/24\n目次\n第1 章\n序論\n1\n1.1\n研究背景. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n1\n1.1.1\n製造業の現場における産業用ロボット",
            " . . . . . . . . . . . .\n1\n1.1.1\n製造業の現場における産業用ロボット\n. . . . . . . . . . . . . . . .\n1\n1.1.2\n製造業のリモート化\n. . . . . . . . . . . . . . . . . . . . . . . . . .\n2\n1.1.3\n製造業におけるXR 技術の活用. . . . . . . . . . . . . . . . . . . .\n3\n1.2\n研究目的・目標. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n4\n第2 章\n関連研究・技術\n6\n2.1\n既存のアームロボット操作手法. . . . . . . . . . . . . . . . . . . . . . . .\n6\n2.2\n直接操作型のアームロボット操作手法\n. . . . . . . . . . . . . . . . . . . .\n7\n2.3\nジェスチャ及び身体動作用いたアームロボット操作手法\n. . . . . . . . . .\n10\n2.4",
            "スチャ及び身体動作用いたアームロボット操作手法\n. . . . . . . . . .\n10\n2.4\n自然インターフェースを用いたアームロボット操作手法\n. . . . . . . . . .\n15\n2.5\nまとめ. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n17\n第3 章\n拡張現実とインプットデバイスを用いたアームロボットリモートコントロー\nルシステム\n19\n3.1\nシステム概要. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n19\n3.2\nインプットデバイス\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n20\n3.2.1\nPALL0 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n21\n3.2.2\nマルチセンサデバイス. . . . ",
            " . . . . . . . . . . .\n21\n3.2.2\nマルチセンサデバイス. . . . . . . . . . . . . . . . . . . . . . . . .\n22\n3.3\n仮想的に配置されたアームロボットの操作手法\n. . . . . . . . . . . . . . .\n24\n3.4\n各デバイス間の通信手法. . . . . . . . . . . . . . . . . . . . . . . . . . . .\n26\n3.4.1\nMQTT プロトコルによる通信の概要\n. . . . . . . . . . . . . . . . .\n26\n3.4.2\nPall0 を用いた各デバイス間の通信\n. . . . . . . . . . . . . . . . . .\n26\n3.4.3\nTIARC を用いた各デバイス間の通信. . . . . . . . . . . . . . . . .\n27\n3.5\nシステムの使用方法\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n28\n第4 章\nユ",
            " . . . . . . . . . . . . . . . . . . . .\n28\n第4 章\nユーザ評価実験\n30\n4.1\n実験目的. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n30\n4.2\n実験環境. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n30\n4.3\n実験方法. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n31\n4.4\n評価方法. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n32\n4.4.1\n定量評価指標. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n32\n4.4.2\n主観的な操作のしやすさの評価指標\n. ",
            ". . . . . . . . . . .\n32\n4.4.2\n主観的な操作のしやすさの評価指標\n. . . . . . . . . . . . . . . . .\n32\ni\n第5 章\n実験結果及び考察\n34\n5.1\n定量評価の実験結果及び考察\n. . . . . . . . . . . . . . . . . . . . . . . . .\n34\n5.2\n主観的な操作のしやすさの実験結果と考察. . . . . . . . . . . . . . . . . .\n39\n第6 章\n結論と今後の展望\n44\n6.1\n結論. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n44\n6.2\n今後の展望\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n45\n謝辞\n47\n参考文献\n47\nii\n第1章\n序論\n1.1\n研究背景\n1.1.1\n製造業の現場における産業用ロボット\n今日，日本では超高齢化社会に伴い様々な",
            "1\n研究背景\n1.1.1\n製造業の現場における産業用ロボット\n今日，日本では超高齢化社会に伴い様々なところで人手不足が指摘されている．[1] 図\n1.1 から日本における生産年齢人口（15～64 歳）は1995 年をピークに減少しており，2050\n年には5,275 万人（2021 年から29.2 ％減）に減少すると見込まれると同時に労働力の不\n足などの課題が深刻化すると懸念されている．[2] 生産年齢人口の減少に伴い，生産性を\n高める手段としてロボティクスへの期待が高まっている．\n図1.1 高齢化の推移と将来推計( [2] より引用)\n製造業の現場においてもロボティクスへの期待が高まる傾向にあり，近年の産業用ロ\nボット技術は多くの産業の現場に導入され，作業者の安全性と作業の生産性を向上させる\nとともに，3K 職場の改善など働き方にも影響を及ぼしている．これらの利点から産業用\nロボットの導入は先進工業国にとどまらず，新興国も含め世界的に大きな潮流となりつつ\nある．[3]．図1.2 に産業用ロボットの稼働台数の推移及び図1.3 に産業用ロボットの年間\n導入台数を示す．産業用ロボットの稼働台",
            "ロボットの稼働台数の推移及び図1.3 に産業用ロボットの年間\n導入台数を示す．産業用ロボットの稼働台数は年々増加しており，今後もさらなる拡大が\n1\n見込まれる．\n図1.2 産業用ロボットの稼働台数の推移( [4] より引用)\n実際の導入事例としてはオムロン株式会社のアームロボットが挙げられる[5]．オムロ\nン株式会社が提供するアームロボットは様々な現場に導入され，省人化による人手不足の\n解消や作業時間の短縮による生産効率の向上などその有用性を示している．また，株式会\n社KEYENCE が提供している産業用ロボット[6] は人体への負荷が大きい作業にアームロ\nボットを導入することで品質の安定化や作業の効率化を図るだけでなく作業環境の改善に\n寄与しその有用性を示している．\n1.1.2\n製造業のリモート化\nこれらの動きに加えて，2020 年世界的に流行した新型コロナウイルスの影響を受け，あ\nらゆる作業がリモート化，無人化に関連したソリューションが登場し，新しい産業形態の\n変化が訪れている[7]．工場においてもコロナ禍が始まった2020 年から緊急対応としてリ\nモート化を行う企業が多かったが、",
            "．工場においてもコロナ禍が始まった2020 年から緊急対応としてリ\nモート化を行う企業が多かったが、2021 年以降は恒久的な体制として整備が進みつつあ\nり、今後さらにリモート化が進む見込みである[8]．図1.3 に産業用ロボットの年間導入\n台数を示す．2013 年から新型コロナウイルスが流行する以前までの年間導入台数は多い\n年で年間430 万台となっているが，新型コロナウイルスが流行した2020 年の翌年から年\n間530 万台程度で推移しており，産業用ロボットの年間導入台数から見ても製造業のリ\nモート化，無人化が進められていることが明らかである．しかし，産業用ロボットの導入\nに伴い，産業用ロボットの操作の複雑さから効果的に活用するために必要なスキルを持つ\n人材が不足していることや，導入するための資本の不足等様々な課題が挙げられている\n[9][10][11]．また，産業用ロボットの利用の動向として様々な工程の自動化が進められて\nいるが，完全な自動化は難しく，自動化が難しい工程については人が作業を行うことや人\n間による産業用ロボットの操作が必要である[12]．\n2\n図1.3 産業用ロボッ",
            "が作業を行うことや人\n間による産業用ロボットの操作が必要である[12]．\n2\n図1.3 産業用ロボットの年間導入台数( [4] より引用)\n実際に製造業、産業のリモート化を可能にした事例として，トヨタ自動車の3D CAD\nVDI があげられる[13]．3D CAD VDI の導入により，設計職は自宅のノートPC からイン\nターネット経由で仮想環境の3D CAD アプリにアクセス可能となりリモート化が実現し\nた．また，東京で溶接の町工場を営むクリエイティブワークスは，技能者育成用の溶接\nキットにインカム、カメラ、通信機能を搭載した独自開発のIoT 溶接機と汎用クラウドの\n生産管理システムを用いて溶接職人のリモート化を実現している[14]．さらに，人間に\nよる操作が必要なタスクをリモート化する試みも進められている．ManageReact は従来人\nが現場で行ているシンプルな作業を遠隔化する取り組みSocoCacico を提案している[15]．\nこれらの事例のように製造業，産業の現場でリモート化が導入されつつあり今後更なるリ\nモート化の推進が予想される．\n1.1.3\n製造業におけるXR 技術",
            "化が導入されつつあり今後更なるリ\nモート化の推進が予想される．\n1.1.3\n製造業におけるXR 技術の活用\n拡張現実(AR)，仮想現実(VR)，複合現実(MR) から成るxR と呼ばれる基本的な概念は\nヘッドマウントディスプレイやサングラス型のXR グラスなどに仮想的なオブジェクトで\nあるホログラムを映すものである．\n製造業においては設計，製造，メンテナンスなどのエンジニアリングチェーン全体をデ\nジタルツインでつなぐことや各プロセスにXR を活用する動きが起こっている[16][17]．\nAIMultiple は拡張現実を利用することで作業指示や情報のオーバレイを行う事ができ，組\nみ立て工程を効率化するソリューションを提供している．同社はXR 技術を用いることで\n遠隔での共同作業を可能にし，効率性や正確性を向上させている．その他にもアルゼンチ\nンの同管理製造メーカーであるテナリス社ではAR 技術を導入することで設備メンテナン\nスや製造工程の運用管理を効率化することに成功した事例[18] や富士通沼図工場では保\n守点検にAR を導入し管理ノウハウを見えるかすることで関係者全体が共有可能にす",
            "富士通沼図工場では保\n守点検にAR を導入し管理ノウハウを見えるかすることで関係者全体が共有可能にするシ\nステムを導入した事例[19] など今日様々な製造業の現場でXR が活用されている．また，\n製造の工程だけでなく教育訓練にXR を活用することで教育訓練にかかる時間の短縮，効\n率化を可能にしている事例が多く存在する．一例として株式会社ホロラボは教育訓練に\nMR を用いたサービスassists を提供している[20]．図1.4 にassists 使用時の様子を示す．\n3\nassists はMR 技術を用いて空間にテキストや画像，3D モデルといったデジタル情報を縦\n走し，直感的で学習効率の高い体験形式での教育訓練を可能にしている．これにより，反\n復して自主学習を行えるため指導矢が常駐する必要がなく教育コストの軽減に成功して\nいる．\n図1.4 Assists 使用時の様子( [20] より引用)\n以上のように今日製造業の様々な現場でMR 技術が活用され，生産性や効率の向上に寄\n与するとともにコスト削減にも寄与している．\n1.2\n研究目的・目標\n今日日本では超高齢化社会に伴い様々なところで",
            "にコスト削減にも寄与している．\n1.2\n研究目的・目標\n今日日本では超高齢化社会に伴い様々なところで人手不足が指摘されている中，労働力\n不足の課題が深刻化すると懸念されており，生産性を高める手段としてロボティクスへの\n関心が高まっている．製造業の現場においてもロボティクスへの期待が高まる傾向にあ\nり，近年産業用ロボットは多くの現場に導入され作業者の安全性と作業の生産性を向上さ\nせている．様々な利点から産業用ロボットの導入は我が国を含む先進工業国にとどまらず\n新興国も含め世界的に大きな潮流となりつつある．これらの動きに加えて2020 年世界的\nに流行した新型コロナウイルスの影響を受けあらゆる作業のリモート化，無人化に関連し\nたソリューションが登場している．工場においても産業用ロボットを導入するなどの方法\nでリモート化，無人化を進めており，この動きは今後さらに進む見込みである．しかし，\n産業用ロボットの導入には資金的な課題や産業用ロボットを扱える人材が不足しているな\nどの課題も存在している．また，産業用ロボットの利用の動向としては工程の自動化が主\nに進められているが完全な自動化が難しく人に",
            "また，産業用ロボットの利用の動向としては工程の自動化が主\nに進められているが完全な自動化が難しく人による操作が必要な作業も存在している．リ\nモート化，無人化に関連したソリューションとして設計，製造，メンテナンスなど全体に\nXR を活用する動きが起こっており，様々な事例が存在する．\n4\n以上のことから産業用ロボットの操作に特別な知識を必要としない程度簡単で直感的で\nあり，遠隔地からリアルタイムな操作が可能な産業用ロボットの操作手法が必要である．\nそこで本研究では産業用ロボットの中でも多くの工程に用いられているアームロボットに\n焦点を当て，特別な知識を必要とせず遠隔地からリアルタイムで操作が可能な操作手法の\n提案を目標とする．そのため本研究では以下3 点を目標とし，評価実験を行い目標が達成\nされたかを検証する．\n• 直感的に操作可能な操作手法\n• 認知的負荷の小さい操作手法\n• 操作が簡単に感じられる操作手法\n本研究で提案する手法はアームロボットの状態などの情報提示手法として拡張現実を用\nい，拡張現実で仮想的に提示されたアームロボットを操作することでその動きに連動して\n実際のアームロボット",
            "，拡張現実で仮想的に提示されたアームロボットを操作することでその動きに連動して\n実際のアームロボットも操作可能なシステムとなっている．拡張現実で仮想的に配置され\nたアームとボットはハンドトラッキングを用いて取得する手の位置及び操作デバイスを用\nいて取得する姿勢を用いてアームロボットのヘッドの位置姿勢を決定することで各関節角\nを決定し操作を行う．グリッパーの開閉は操作デバイスを用いて操作する．\n5\n第2章\n関連研究・技術\n2.1\n既存のアームロボット操作手法\n製品化されているアームロボットの手動操作手法はタッチパネル上の複数の方向ボタン\nを用いてアームロボット操作する手法が多く用いられている[21][22]．図2.1 に方向ボタ\nンを用いたアームロボット操作手法の例を示す．一般的に方向ボタンを用いてアームロ\nボットのヘッドの位置姿勢を決定し制御する逆運動学を用いることで各関節角を制御する\n方法より簡単に操作が可能な一方で，アームロボットの自由度の高さからボタン数が多く\nなり直感的な操作が難しい課題が存在している．\n図2.1 方向ボタンを用いたアームロボット操作手法の例( [22] より引",
            "しい課題が存在している．\n図2.1 方向ボタンを用いたアームロボット操作手法の例( [22] より引用)\nより直感的な操作を可能にする操作手法としてジョイスティックなどのコントローラを用\nいて操作を行う手法が存在する[23]．図2.2 にアームロボット操作に用いるジョイスティッ\nクの例を示す．スティックを倒すことでその方向にアームロボットのヘッドの位置を移動\nさせるなど方向ボタンを用いて操作する手法に比べ簡単な操作が可能であるが，奥行き方\n向の操作時にはボタンを押す必要があることや回転の操作についても特定のコマンドを\n入力する必要があるなどアームロボットの動作を意識した操作が必要なことから方向ボタ\nンを用いた操作と同様に直感的な操作や意図したとおりの操作が難しい課題が残されて\nいる．\n6\n図2.2 アームロボット操作に用いるジョイスティックの例( [23] より引用)\n2.2\n直接操作型のアームロボット操作手法\nアームロボットの操作手法を提案する研究は数多く行われている．リアルタイムのロ\nボットの手動操作においては，ジョイスティックなどのコントローラやタッチパネルを用\nいて複数のボタン",
            "\nボットの手動操作においては，ジョイスティックなどのコントローラやタッチパネルを用\nいて複数のボタンを用いた操作手法が多く提案されている[24][25][26]．\nHashimoto らはCG の重曹表示を用いてロボットを直感的に操作することができるシス\nテムTouchMe を提案している[27]．TouchMe は入力デバイスとしてタッチスクリーンを\n使用しており，画面上には操作対象のロボット三人称視点からとらえたカメラ画像が表示\nされている．ユーザは画面上に表示されているロボットの操作したい部位に直接触れ，ド\nラッグすることによってロボットを任意の位置姿勢にすることができる．図2.3 にTouchMe\nを用いたアームロボット操作時の例を示す．TouchMe ではアームロボットのヘッドを動か\nしたい方向へドラッグすることで操作を可能にしている．TouchMe でアームロボットを\n操作する際にタッチパネルを用いて操作を行っているため，二次元平面での操作は直感的\nで容易であるが，三次元空間での操作は難しい課題が残されている．\n7\n図2.3 TouchMe を用いたアームロボット操作時の例",
            "での操作は難しい課題が残されている．\n7\n図2.3 TouchMe を用いたアームロボット操作時の例( [27] より引用)\n竹内らは操作者が周囲の確認を目視と1 台のカメラで行い物体把持を簡単に行えるタッ\nチパネルを利用したロボットアーム手先目標指定インターフェースを提案している[28]．\n図2.4 に竹内らの提案するシステム使用時の様子を示す．竹内らの提案するシステムでは\nタッチパネル上での操作によりロボットアームを動作させ，少ない操作回数で物体の把持\nを可能にしている．竹内らの提案するシステムでは，目視とカメラで対象物体の確認を\n行っていることから，遠隔地からの操作を想定した際に奥行き方向の認識が難しく操作が\n難しくなる課題が残されている．竹内らはさらにUI を追加する改善案も述べており，認\n知的負荷がより大きくなる，アームロボットの動作をより意識する必要がある課題も残さ\nれている．\n図2.4 竹内らの提案するシステム使用時の様子( [28] より引用)\n8\nChenchireddy らはAruduino コントローラを用いたアームロボットの操作手法を提案し\nている[29]．図2",
            "y らはAruduino コントローラを用いたアームロボットの操作手法を提案し\nている[29]．図2.5 にChenchireddy らの提案する操作手法の全体図を示す．Chenchireddy\nらが提案する操作手法ではアームロボットの各関節を操作するAruduino コントローラと\nセンサを統合して精密活動的な操作を可能にしている．Aruduino コントローラとセンサ\nのみを用いるため他の手法に比べて安価であり，コスト面に優れている．しかし，各関節\nを操作する手法は操作の直感性にかけており，使用する人の知識を必要とする課題が残さ\nれている．\n図2.5 Chenchireddy らの提案する操作手法の全体図( [29] より引用)\nジョイスティックなどのコントローラを用いた操作手法については様々な形のコントロー\nラが提案されている[30][31][32]．コントローラを用いた手法では精密な操作のため複数\nのボタンを用いることやタッチパネルなどと組み合わせるなどの手法が存在しているが，\n用いるボタンやタッチパネル内のUI が多くなる程アームロボットの操作に対する専門性\nが必要になり直感",
            "用いるボタンやタッチパネル内のUI が多くなる程アームロボットの操作に対する専門性\nが必要になり直感的な操作が難しくなる．これに対し，図2.6 に示すようなより簡素化し\nたコントローラも多く提案されている．このようなコントローラは複数のボタンを用いる\n手法に比べ操作が容易である利点があるが，細かな操作が難しい課題が残されている．ま\nた，操作ミスを防ぐために触覚や聴覚によるフィードバックを行う手法も存在しており\n9\n図2.6 アームロボットコントローラの例( [30] より引用)\n以上のようにジョイスティックなどのコントローラを用いる手法やタッチパネルを用い\nる手法，タッチパネルとコントローラを組み合わせる手法など様々な直接操作型のアー\nムロボット操作手法が提案されている．タッチパネルを用いた操作手法ではアームロボッ\nトの自由度の高さからUI が複雑になり直感的な操作が難しい課題が挙げられ，ジョイス\nティックなどのコントローラを用いた手法では奥行き方向や精密な操作が難しい課題が残\nされている．\n2.3\nジェスチャ及び身体動作用いたアームロボット操作手法\nロボットの操作手法においてタッチパ",
            "る．\n2.3\nジェスチャ及び身体動作用いたアームロボット操作手法\nロボットの操作手法においてタッチパネルやコントローラを用いた操作に比べ専門的な\n知識を必要とせず，直感的な手法としてジェスチャ操作や身体動作を用いた操作が挙げら\nれる．これらの操作手法を提案する先行研究は数多く存在する．手袋型で指の動きを認識\nする手法，カメラで身体動作をコマンドとして認識する手法，センサを用いて人の動作を\n認識しコマンドとして用いる手法など，身体動作の認識方法及びその活用方法などその手\n法は多岐にわたる[33][34][35]．\n川西らはLeap Motion を使用したロボットアームの操作手法を提案している[36]．川西\nらが提案するシステムではLeap Motion で取得した手の座標データを用いてアームロボッ\nトの操作を行っている．この手法は手の動きがアームロボットの動きに反映されるため非\n常に直感的であるが，その他のグリッパーの制御やヘッドの回転などの操作手法について\nは言及されてなく，操作手法として不十分である．これに対し日置らはLeap Motion を用\n10\nいて手の動きを認識し，特定の",
            "して不十分である．これに対し日置らはLeap Motion を用\n10\nいて手の動きを認識し，特定の動作をアームロボットの特定動作のコマンドとして用いる\nことでアームロボットの操作を行う手法を提案している[37]．図2.7 日置らの提案するシ\nステムを用いたアームロボット操作の様子を示す．に日置らの提案する手法では例えば指\nで円を描く動作をした際にモータ3 の角度を20 度上げるなど特定の動作を特定のモータ\nの動きに割り当てることで操作を可能にしている．川西らの提案する操作手法に比べ，多\nくの動作に対応可能であることから操作手法として十分であると言えるが，一度のコマン\nドで一定量アームロボットが動くことから細かな操作が難しい事や，各身体動作が対応す\nるコマンドを覚える必要があり直感的な操作が難しい課題が残されている．\n11\n図2.7 日置らの提案するシステムを用いたアームロボット操作の様子( [37] より引用)\nChen はMR を用いて仮想的に表示されたアームロボットをオブジェクトトラッキング\nを用いて操作を行う手法を提案している[38]．図2.8 にchen が提案する手法を用い",
            "ラッキング\nを用いて操作を行う手法を提案している[38]．図2.8 にchen が提案する手法を用いたアー\nムロボット操作の様子を示す．アームロボットは逆運動学を用いて制御され，赤いボール\n12\nを追跡する．赤いボールは手を用いて移動させることが可能であり，この位置に応じて\nアームロボットが適切な姿勢で追跡することで操作を可能にしている．赤いボールの移動\nについては操作者自身の手を用いて触れるなどで移動させることが可能であり非常に容\n易である．Chen の提案する手法ではヘッドの回転やグリッパーの制御に関する記述がな\nく操作方法としては不十分ではあるが，アームロボットの操作に必要な動作が赤いボール\nを動かすのみであるため専門的な知識を必要とせず直感的な操作が可能であるなどの利\n点が挙げられる．\n図2.8 chen が提案する手法を用いたアームロボット操作の様子( [38] より引用)\n福岡らは顔表情をアームロボットの動きにマッピングすることで操作を行う手法faceDrive\nを提案している[39]．図2.9にfaceDriveを用いたアームロボット操作の例を示す．FaceDrive\nで",
            "る[39]．図2.9にfaceDriveを用いたアームロボット操作の例を示す．FaceDrive\nでは，機械学習を通じて表情とアーム動作コマンドのマッピングを行う操作手法を用いて\nいる．四肢の自由を底縄地に操作が可能である点においては優れた操作手法である一方，\nコマンドとしての顔表情を記憶する必要がある点や顔表情のご認識により意図しない動\n作が発生する可能性がある点などの課題が残されている．\n13\n図2.9 faceDrive を用いたアームロボット操作の例( [39] より引用)\n木村らは頭部動作に基づいてアームロボットの操作を行う手法を提案している[40]．図\n2.10 に木村らの提案するアームロボット操作時の様子を示す．木村らの提案する手法では\n操作開始時ににヘッドマウントディスプレイに搭載されたウェブカメラを用いてアームロ\nボットに貼り付けられているコードを読み取る．アームロボット動作はコードに割り当て\nられている情報によって切り替えられ，読み取りが完了するとロボットアームがユーザの\n頭部動作に基づいて動作するようになる．アームロボットの操作時にはヘッドマウント\nディスプレイに",
            "ザの\n頭部動作に基づいて動作するようになる．アームロボットの操作時にはヘッドマウント\nディスプレイに取り付けられた慣性センサを用いて頭部動作を認識し，アームロボットの\n旋回運動及び上下運動を制御する．木村らの提案する手法は任意のタイミングでアームロ\nボットを操作可能であるため意図しないタイミングでの操作を避けられる利点がある一\n方，アームロボットの動作に対応した頭部の動きを覚える必要があるため直感的な操作が\n難しい点や頭部を動かしている際にアームロボットを視界に入れ続けることが難しい点に\n課題が残されている．\n図2.10 木村らの提案するアームロボット操作時の様子( [40] より引用)\n14\n以上のようにジェスチャや身体動作を用いた操作手法は数多く提案されている．仮想的\nに表示されたオブジェクトを移動させることでそれに追従するアームロボットの操作を行\nう手法や手の動きを用いて操作を行う手法など非常に直感的であり意図したとおりの操\n作が可能な手法が提案されているが回転やグリッパーの制御については言及されていない\nなど操作手法として不十分である．その他の身体動作を用いた手法は複雑なUI ",
            "ついては言及されていない\nなど操作手法として不十分である．その他の身体動作を用いた手法は複雑なUI を必要と\nせず，操作手法を簡単に理解可能である利点があるが，アームロボットの動作に対応した\n身体動作を覚える必要があり，アームロボットの動作に近い動作ではない事などから直感\n的な操作が難しい課題が残されている．\n2.4\n自然インターフェースを用いたアームロボット操作手法\nタッチパネルやジョイスティックなどのコントローラ，身体動作やジェスチャなどを用い\nた操作手法以外の操作手法も多く提案されている．その例として大規模言語モデルへのプ\nロんプティングをもとに得たタスク実行手順を用いてアームロボットを操作する手法[41]\nや実際のアームロボットに対して言語を用いて指示を与えて実行するPaLM-SayCan[42]，\n運動イメージ脳信号とインピーダンス制御を組み合わせることで操作を行う手法[43] な\nど自然言語や脳波を用いた操作手法が挙げられる．\nZhang らは脳波を用いて意図を推定し，アームロボットの操作を可能にする手法を提案\nしている[44]．図2.11 にzhang らが提案する手法の",
            "ロボットの操作を可能にする手法を提案\nしている[44]．図2.11 にzhang らが提案する手法の概要図を示す．zhang らが提案する手\n法では操作者に「物をつかむ」や「前に進む」などの具体的な動作をイメージしてもら\nい，運動関連領域で生成される脳波パターンを学習し意図推定に用いる．実際に操作を行\nう際には操作者がイメージした運動を事前に学習したモデルを用いて意図推移帝を行い\n推定結果を制御コマンドに変換することで操作を行う．zhang らが提案する手法では運動\nをイメージするのみでアームロボットの操作を可能にしている点で直感的であり優れてい\nる一方，脳波から正確に意図を推定することが難しい点や汎用性に欠ける点などの課題が\n残されている．\n図2.11 zhang らが提案する手法の概要図( [44] より引用)\n15\n久保山らは大規模自然言語モデルを用いて指示を生成することでアームロボットの操作\nを可能にする手法を提案している[45]．図2.12 に久保山らが提案する手法の概要図を示\nす．久保山らが提案する手法では大規模言語モデルを用いて抽象的な自然言語指示をロ\nボットの制御に適し",
            "\nす．久保山らが提案する手法では大規模言語モデルを用いて抽象的な自然言語指示をロ\nボットの制御に適した具体的な行動の手続きを示した分のリストに変換し，その文とロ\nボットの行動コマンドを結びつけることで操作を可能にしている．\n図2.12 久保山らが提案する手法の概要図( [45] より引用)\n黄瀬らは大規模言語モデルによるコード生成と機械学習によるロボット制御を組み合わ\nせることで言語指示によりアームロボットの操作を行う手法を提案している[46]．図2.13\nに黄瀬らの提案する手法の概要図を示す．黄瀬らの提案する手法では大規模言語モデルが\n生成したLMP はNewtonianVAE によって事前学習された世界モデルの潜在空間を利用し\nて制御を行う．世界モデルを用いることで，アームロボットの座標や関節角，物体位置な\nどの情報を利用することなく自然言語文で指示される道のタスクや動作に対して自立制\n御を可能にしている．\n久保山らや黄瀬らなどが提案する自然言語を用いた操作手法は脳波を用いた手法と同程\n度に直感的であると言えるが，自然言語の曖昧さから意図しない動作が発生する可能性が\nあるなどの課題",
            "程\n度に直感的であると言えるが，自然言語の曖昧さから意図しない動作が発生する可能性が\nあるなどの課題が残されている．\n16\n図2.13 黄瀬らの提案する手法の概要図( [46] より引用)\n2.5\nまとめ\n既存の操作手法としてタッチパネル上で複数のボタンを用いることやジョイスティック\nなどのコントローラを用いた手法が存在するが，アームロボットの自由度の高さから操作\nが煩雑になる課題があり，アームロボット導入の妨げとなっている．この課題を解決する\nために既存の操作手法を改善しより簡潔にする手法を提案する研究は数多く存在するが\n簡易化する事には限界があり，認知的負荷が大きい課題が残されている．これに対し，身\n体動作やジェスチャを用いた操作手法が数多く提案されている．これらの手法はタッチパ\nネルなどを用いた手法に比べて必要なボタン数が少なく認知的負荷が小さい点で優れて\nいる．しかし，アームロボットの動作に対応するジェスチャや身体動作を意識する必要が\nあるため直感的な操作が難しい点に課題が残されている．仮想的に表示されたオブジェク\nトを移動させることでそれに追従するアームロボットの操作を行う手",
            "ている．仮想的に表示されたオブジェク\nトを移動させることでそれに追従するアームロボットの操作を行う手法や手の動きを用い\nて操作を行う手法など非常に直感的であり意図したとおりの操作が可能であるが，回転や\nグリッパーの制御については言及されていないなど操作手法として不十分である課題が残\nされている．脳波や自然言語を用いた操作手法は認知的負荷が小さく特別な身体動作など\nのコマンドを意識する必要がなくより直感的な手法であると言えるが，自然言語の曖昧さ\nなどから意図しない動作が発生する可能性がある点に課題が残されている．\n17\n以上のことから本論文ではアームロボットの状態などの情報提示手法として拡張現実を\n用い，拡張現実で仮想的に提示されたアームロボットを操作することでその動きに連動し\nて実際のアームロボットも操作可能なシステムをていあんする．拡張現実で仮想的に配置\nされたアームとボットはハンドトラッキングを用いて取得する手の位置及び入力デバイス\nを用いて取得する姿勢を用いてアームロボットのヘッドの位置姿勢を決定することで各関\n節角を決定し操作を行う．グリッパーの開閉は入力デバイスを用いて操作す",
            "の位置姿勢を決定することで各関\n節角を決定し操作を行う．グリッパーの開閉は入力デバイスを用いて操作する．\n18\n第3章\n拡張現実とインプットデバイスを用いた\nアームロボットリモートコントロールシス\nテム\n3.1\nシステム概要\n本研究で提案するシステムは拡張現実を用いて仮想的に提示されたアームロボットのモ\nデルを操作することでその動きに連動した実際のアームロボットの操作も可能にするシス\nテムとなっている．図3.1 に提案システムの概要図を示す．インプットデバイスを用いて\n姿勢情報及びグリッパーの開閉情報をAR アプリケーションへ送信し，AR アプリケーショ\nンでは受け取った情報及びアプリケーション内でハンドトラッキングを用いて取得する手\nの位置情報を用いてアームロボットの各関節角を計算する．その後，AR アプリケーショ\nンで計算された各関節角の情報を実際のアームロボットへ送信することで操作を行う．イ\nンプットデバイス，AR アプリケーション間及びAR アプリケーション，アームロボット間\nの通信はMQTT プロトコルを用いる．MQTT プロトコルはhttp のようにプレーンテキス\nトでの情",
            "通信はMQTT プロトコルを用いる．MQTT プロトコルはhttp のようにプレーンテキス\nトでの情報ではなく，ビット単位での情報によりオーバヘッドが少なく軽量であり，コネ\nクション指向のプロトコルである．また，要求-応答型モデルであり，Topic を用いること\nで双方向で1 対多，多対多の通信が可能であるため柔軟に拡張可能である[47]．これらの\n利点を有するMQTT プロトコルは直感的な操作のため低遅延でリアルタイムに通信を行\nう必要がある本システムに適している．また，AR アプリケーションを実装するデバイス\nとしてMicrosoft 社のHololens2 を用いる．図3.2 に使用するhololens2 を示す．hololens2\nは透過型のヘッドマウントディスプレイであり，前面に配置されたRGB カメラ及び環境\n認識カメラを用いた高精度なハンドトラッキング機能を有していることに加えて別途のコ\nントローラを必要とせずに操作を行うことが可能である点や幅広い視野角でユーザが快\n適かつ正確にホログラムを操作可能である点に優れており[48] 本システムに適している．\n19\n図3.1 提",
            "正確にホログラムを操作可能である点に優れており[48] 本システムに適している．\n19\n図3.1 提案システムの概要図\n図3.2 使用するHoloLens2\n3.2\nインプットデバイス\nアームロボットのリアルタイム操作を行うにあたり，ハンドトラッキングを用いた手の\n位置情報及び姿勢情報，開閉情報を用いて操作が可能であれば直感的な操作を可能にしな\nがら専門的な知識を必要とせず容易な操作が可能である．しかし，姿勢を制御するために\n20\n手を傾けた際などに手が隠れてしまいhololens2 のカメラでとらえられない際に姿勢や開\n閉の認識が難しく正確な操作が難しい．そのため本研究では手が隠れた際にも正確に姿勢\n及び把持の認識を正確に行うためインプットデバイスを用いる．\n3.2.1\nPALL0\n姿勢及び把持推定が可能なデバイスととしてAI2AI が提供するPall0 が挙げられる．図\n3.3 にPall0 の構成図を示す．Pall0 は，ボールという物理的な特性と高度なデジタルセン\nサー、多モーダルフィードバックを融合させたデバイスであり，は主に身体活動の促進や\nリハビリテーションを目的として設",
            "ルフィードバックを融合させたデバイスであり，は主に身体活動の促進や\nリハビリテーションを目的として設計されているが，現在では産業用制御システムにも応\n用されている．加速度、角速度、外部環境要因を追跡するセンサーを搭載し，PALL0 は\n多様な応用分野に対応するユニークで直感的なインターフェースを提供する[49]．\n図3.3 Pall0 の構成図( [49] より引用)\n図3.4 に使用するPall0 の外見を示す．Pall0 は上下各4 か所ずつ計8 か所に圧力センサを\n用いたボタンが設置されており，様々なインタラクションが可能である．本研究において\nは把持認識にボタンを用いる．また，本節で紹介しているPall0 はPall0v2 であり現在では\nデバイスの全面に圧力センサを搭載し把持認識が可能なPall0v3 が提供されいる．Pall0v2\nではあらかじめ配置されているがあり，グリッパーの制御において特定の位置にあるボタ\nンを開閉の操作療法で押す必要がある．これに対しPall0v3 ではデバイスを握り続けてい\nる間はグリッパーを閉じ，緩めた際にグリッパーを開くという制御が可能である．",
            "はデバイスを握り続けてい\nる間はグリッパーを閉じ，緩めた際にグリッパーを開くという制御が可能である．そのた\nめ本研究ではこれら二つの制御方法で操作の容易さや直感性に差異が出るかを検証する．\n21\n図3.4 使用するPall0 の外見\n3.2.2\nマルチセンサデバイス\n手で持って操作を行うインプットデバイスを用いる際，形状は重要な要素であり，デバ\nイスの握りやすさや持ちやすさを調査する文献は多岐にわたる．その中でも，特に道具や\nデバイスの把持部が円柱状である点に着目した研究が数多く存在する．これらの研究で\nは，道具の把持部を円筒形に単純化し，その形状やサイズが握りやすさや使いやすさに与\nえる影響を評価している[50][51][52]．このような背景を踏まえ，本研究では姿勢推定お\nよび把持認識が可能な円柱状のデバイスを新たに開発し，これを「Tangible Interface for\nArm Robot Control（TIARC）」と命名した。\n図3.5 に制作したTIARC の外見及び図3.6 にTIARC 使用時の様子を示す．TIARC は片\n手で容易に使用できる大きさを持ち，表面に",
            "3.6 にTIARC 使用時の様子を示す．TIARC は片\n手で容易に使用できる大きさを持ち，表面には把持認識を実現するための圧力センサが取\nり付けられている．また，TIARC のケースは3D プリンタを用いて製作されており，内部\n構造を保護しつつ，充電用および配線用の穴を備えている．この設計により，取り扱いが\n簡便で，センサの付け替えなどのメンテナンスも容易である．図3.7 にTIARC を構成する\nM5StickC 及び圧力センサを示す．M5StickC はESP32 を搭載したオープンソースのIOT\n開発ボードであり，6 軸のIMU センサやWI-FI が利用可能である．6 軸のIMU センサを用\nいることでTIARC の姿勢を高精度で推定することが可能であり，WI-FI を用いることで\nセンサ値をリアルタイムでAR アプリケーションへ送信することが可能である．またバッ\nテリー駆動であり外部電源を必要せずにTIARC を動作させることが可能であるため，持\nち運びが容易で様々な環境での使用が可能である．圧力センサには、Interlink Electronics\n22\n社が提供するF",
            "の使用が可能である．圧力センサには、Interlink Electronics\n22\n社が提供するFSR406 圧力センサを採用している．このセンサは，M5StickC に直接接続\n可能な小型で柔軟性のある設計が特徴であり，非常に軽量で取り扱いが容易である．ま\nた，フレキシブルな特性を持つため，円柱状のTIARC の表面に沿うように配置すること\nが可能であり，デバイス全体の形状や機能性を損なうことなく高い感度で圧力を検知する\nことが可能である．\n図3.5 TIARC の外見\n図3.6 TIARC 使用時の様子\n23\n図3.7 TIARC を構成するM5StickC（左側）及び圧力センサ（右側）\n3.3\n仮想的に配置されたアームロボットの操作手法\nAR アプリケーションにおいて，仮想的に配置されたアームロボットの各関節角度は，逆\n運動学の計算を用いて決定される．そのため，アームロボットの頭部の位置および姿勢\nを適切に決定することが必要である．図3.8 に仮想的に配置されたアームロボット操作時\nの様子を示す．このアプリケーションでは，ハンドトラッキング技術を用いて手の位置を\nリアルタイムで",
            "時\nの様子を示す．このアプリケーションでは，ハンドトラッキング技術を用いて手の位置を\nリアルタイムで追跡し，その追跡された位置を白い立方体として視覚的に表現している．\n白い立方体による位置表示は，仮想オブジェクトとユーザーの手が重なった際にも手の位\n置を視認可能に保ち，誤操作や混乱を防ぐために使用される．手とアームロボットの頭\n部にはそれぞれ基準点が設けられている．この基準点を基に取得する手の基準点から差\nの情報と，アームロボットの頭部の基準点からの差情の情報を同期させることで，アー\nムロボットの頭部の位置を決定する．これにより，操作者はアームロボットの頭部を動か\nしたい方向に手を動かすのみで位置の操作ができ，直感的で容易な操作を可能にしてい\nる．図3.9 に仮想的に配置されたアームロボットの頭部の姿勢操作時の様子を示す．アー\nムロボットの頭部を傾けたい方向にインプットデバイスを持った手を傾けることで操作を\n行う．手を傾け続けている間はアームロボットの頭部が回転し続け，手を水平な状態に戻\nすことで回転を止め姿勢を固定する．グリッパーの操作手法はPall0v2，Pallov3，TIARC",
            "\nすことで回転を止め姿勢を固定する．グリッパーの操作手法はPall0v2，Pallov3，TIARC\nで異なる．Pall0v2 ではグリッパーを閉じる際に特定のボタンを押し，開く際に再度同じ\nボタンを押す．TIARC ではグリッパーを閉じる際にデバイスを強く握り，開く際に再度\n強く握る．Pall0v3 ではデバイスを強く握っている間グリッパーが閉じ続ける．Pall0v2 と\nTIARC はグリッパーの開閉を切り替えることで操作する点で同様であるが，特定の位置\nのボタンを押す必要があるか単純にデバイスを握るのみで操作可能かという点において\n異なる．また，TIARC とPall0v3 はデバイスを握るのみで操作可能である点では同様であ\n24\nるが，グリッパーの開閉を切り替えることで行うか握っている間はグリッパーが閉じ続け\nるかという点でことなる．これらの操作手法を比較することで，度の操作手法が最も直感\n的かつ容易かを検証する．\n図3.8 仮想的に配置されたアームロボット操作時の様子\n図3.9 仮想的に配置されたアームロボットの頭部の姿勢操作時の様子\n25\n3.4\n各デバイス間の通信手法\n3",
            " 仮想的に配置されたアームロボットの頭部の姿勢操作時の様子\n25\n3.4\n各デバイス間の通信手法\n3.4.1\nMQTT プロトコルによる通信の概要\n3.1 節で述べた通り，提案システムでは各デバイス間の通信にMQTT プロトコルを用い\nる．このMQTT プロトコルはパブリッシュ/サブスクライブという通信パターンを採用し\nており，様々なデバイス間での効率的なデータ交換を可能にしている．このパターンに\nおいて，メッセージを送信する役割を担うクライアントは「パブリッシャー」と呼ばれ，\nメッセージを受信する側のクライアントは「サブスクライバー」と呼ばれる．また，これ\nらの間で通信を仲介するサーバーは「ブローカー」と呼ばれる．実際にに通信を行う際に\nは，各メッセージにトピックと呼ばれる属性が付与され，このトピックによってどのメッ\nセージがどのクライアントに送られるかが決定される．mqtt プロトコルによる通信の概\n要図を3.10 に示す．複数のデバイスが/Time というトピックをサブスクライブしているた\nめ，パブリッシャーとして機能するデバイスがメッセージの属性値に/Time というトピッ\nク",
            "ているた\nめ，パブリッシャーとして機能するデバイスがメッセージの属性値に/Time というトピッ\nクをつけてパブリッシュするとブローカーを介して各デバイスにメッセージが送られる．\nこの際，/Time 以外のトピックをサブスクライブしているデバイスはメッセージを受信し\nない．ブローカーはすべてのメッセージの受信，トピックに関心を持つデバイスの決定，\nサブスクライブしているすべてのクライアントへのっメッセージの送信を行う．オープン\nソースのブローカーも数多く存在しており，実装が容易である利点を持つ．\n図3.10 mqtt プロトコルによる通信の概要図\n3.4.2\nPall0 を用いた各デバイス間の通信\n図3.11 にPall0 を用いた際の通信の概要図を示す通信の信頼性およびリアルタイム性を\n確保するためには，Hololens2 へセンサデータを直接Bluetooth で送信することが理想的で\nある．しかし，Hololens2 が主にサポートしているBluetooth デバイスはキーボードやマウ\n26\nスに限定されており，センサデータをBluetooth 経由でAR アプリケーションに送信",
            "マウ\n26\nスに限定されており，センサデータをBluetooth 経由でAR アプリケーションに送信する\nことが技術的に困難であるという課題が存在する．さらに，Pall0 自体はWi-Fi が利用で\nきず，単体でMQTT ブローカーにデータをパブリッシュすることができないという制約\nもある．このため，Pall0 が取得する加速度，角速度，圧力センサの値をBluetooth 経由で\nPC に送信し，PC 上で動作するコンソールアプリケーションにこれらのデータを取り込\nむ．このコンソールアプリケーションは，受信した各センサデータに「トピック1」とい\nう属性を付与したメッセージを作成し，MQTT ブローカーへパブリッシュする．AR アプ\nリケーションは，コンソールアプリケーションによってパブリッシュされたセンサデータ\nをサブスクライブすることで，必要なデータをリアルタイムで取得する．AR アプリケー\nションではコンソールアプリケーションがパブリッシュしたセンサデータをサブスクライ\nブにより取得し，3.3 節で述べた通りに操作を行い，仮想的に配置されたアームロボット\nの各関節角度を決定する．A",
            "し，3.3 節で述べた通りに操作を行い，仮想的に配置されたアームロボット\nの各関節角度を決定する．AR アプリケーションは各関節角度からトピック2 という属性\nを付与したメッセージを作成後にパブリッシュし，アームロボットがサブスクライブする\nことによりAR アプリケーション内の仮想ロボットと同様の動作を遠隔地で再現する．こ\nのように各デバイス間の通信を行うことで物理的なアームロボットが仮想環境と同期して\n動作し，リアルタイムでの遠隔操作が可能となる。\n図3.11 Pall0 を用いた際の通信の概要図\n3.4.3\nTIARC を用いた各デバイス間の通信\nTIARC はWI-FI が利用可能であるため外部のPC などのを介さずにMQTT ブローカーへ\nのパブリッシュが可能である．さらにデバイス内で姿勢推定が可能であるため，AR アプリ\nケーション内において姿勢推定の必要がなく処理の軽減が可能である．図3.12 にTIFARC\nを用いた際の通信の概要図を示す．TIARC では加速度，角速度，圧力センサ値を取得し\nTIARC の姿勢を推定する．その後，推定結果である姿勢及び圧力センサ値に「トピ",
            "力センサ値を取得し\nTIARC の姿勢を推定する．その後，推定結果である姿勢及び圧力センサ値に「トピック\n1」という属性を付与してメッセージを作成，パブリッシュする．以降は3.4.2 節と同様に\n通信を行いアームロボットのリアルタイムでの遠隔操作を行う．\n27\n図3.12 TIFARC を用いた際の通信の概要図\n3.5\nシステムの使用方法\n図3.13 にシステム起動時のAR アプリケーションの様子を示す．AR アプリケーション\n起動後，ユーザはアームロボット，メニューボタン，スタートボタン及びリセットボタン\nが確認可能である．この状態ではアームロボットの操作はできず，手を動かすことやイン\nプットデバイスを操作してもアームロボットは動作しない．アームロボットの操作が不可\n能な状態を用いることで意図しないタイミングで誤ってアームロボットを動作させてしま\nうことを防ぐ．この状態からスタートボタンを押すことで図3.14 に示す状態へ遷移する．\nテキストによる指示が表示され，指示に従いオレンジ色の立方体に自身の手の位置である\n立方体を重ね合わせることでアームロボットの操作を開始する．メニューボタ",
            "立方体に自身の手の位置である\n立方体を重ね合わせることでアームロボットの操作を開始する．メニューボタンはアーム\nロボットの操作中も常時表示されており，任意のタイミングで押すことで操作を中断可能\nである．メニューボタン押下後はシステム起動時と同様の状態へ遷移し，操作を開始する\n際と同様の手順で操作の再開が可能である．操作再開時にはオレンジ色の立方体が操作を\n中断した点に出現する．また，リセットボタンによりアームロボットを初期状態へ戻すこ\nとが可能である．\n本システムにおいて使用される画面内のボタンUI は前述の通りメニューボタン，スター\nトボタン，リセットボタンの3 種類のみで構成されている．このようにUI のボタン数を\n既存の手法と比較して大幅に削減していることによりユーザに対する認知的負荷が大幅\nに低減されている．ボタンが少ないため，ユーザは複雑な操作を覚える必要がなく，簡単\nにシステムを利用することが可能となる。また，操作が可能な状態と不可能な状態を明確\nに分けているため，常時操作が可能なシステムに比べ意図しないタイミングでの誤動作の\nリスクを大幅に低減することが可能である．\n28",
            "可能なシステムに比べ意図しないタイミングでの誤動作の\nリスクを大幅に低減することが可能である．\n28\n図3.13 システム起動時のAR アプリケーションの様子\n図3.14 スタートボタン押下後のAR アプリケーションの様子\n29\n第4章\nユーザ評価実験\n4.1\n実験目的\n本研究で提案するシステムが従来手法に比べ直感的かつ容易に操作が可能であったかを\n検証するためユーザ評価実験を行う．この評価においては従来手法とTIARC を用いた提\n案システムで比較を行う．図4.1 に従来手法を用いたアームロボット操作手法を示す．比\n較対象である従来手法は現在一般的に広く用いられているアームロボットのヘッドの位置\n姿勢及びグリッパーの開閉をそれぞれ方向ボタン，グリッパー開閉ボタンを用いて決定し\n各関節角を逆運動を用いて決定することで操作する手法とする．また，Pall0v2 とPall0v3\nでは把持認識の際に特定のボタンを押すかデバイス自体を握るかという差があるため，こ\nの表面積の差が操作の直観性及び容易さに影響を与えるか検証する．\n図4.1 従来手法用いたアームロボット操作手法\n4.2\n実験環境\nh",
            "易さに影響を与えるか検証する．\n図4.1 従来手法用いたアームロボット操作手法\n4.2\n実験環境\nhololens2 はシースルー型ヘッドマウントディスプレイであり外部の様子が視界に入る．\nそのため本実験では部屋の違いによる影響を少なくするため図4.2 に示す部屋を設定し，\n実験時の被験者の向きを固定した．被験者は実験中，実空間では壁のみが視界に入るよ\nう椅子に座る．被験者は提案システムと従来システムの比較実験で男女10 名，Pall0v2 と\n30\nPall0v3 の比較実験で男女15 名であり，本実験ではアームロボットの操作性の比較を目的\nとしているため，操作及び評価AR アプリケーション内の操作のみで行った．\n図4.2 実験環境の全体図\n4.3\n実験方法\n各実験参加者は従来手法及び提案手法またはPall0v2 を用いた操作及びPall0v3 を用いた\n操作を使用して仮想的に配置されたアームロボットを操作した．それぞれ操作を行う順番\nはランダムとした．最初に操作時の動画を用いて操作方法及びインプットデバイスの使用\n方法，行うタスクの説明をした．図4.3 にタスク実行中の様子を示す．",
            "法及びインプットデバイスの使用\n方法，行うタスクの説明をした．図4.3 にタスク実行中の様子を示す．被験者にタスクと\nして3 個のブロックをそれぞれの異なる目標位置へ運ぶことを指示し，目標位置に置く際\nには可能な限り目標位置の中心にブロックを置くことを指示した．被験者が理解したこと\nを確認した．その後，被験者にHololens2 を装着してもらい，視度や明るさ，頭のバンド\nの締め具合を調整してもらった．被験者は実験担当者の合図でタスクを開始し，タスクの\n31\n終了後にアンケートに回答した．実験担当者はAR アプリケーション内に表示されるタス\nクの成績を記録した．同様の手順でもう一方の操作を用いてタスクを実行した．\n図4.3 タスク実行中の様子\n4.4\n評価方法\n4.4.1\n定量評価指標\nアームロボットが直感的かつ容易に操作可能かという操作性及び意図したとおりの正確\nな操作が可能であるかを評価するための定量評価指標としてタスク実行時間及びブロック\nを運んだ際の目標位置の中心からの差を用いた．タスクの実行時間はスタートボタンを押\nしてから三つ目のブロックを目標位置に移動させるまでの時間とし",
            "．タスクの実行時間はスタートボタンを押\nしてから三つ目のブロックを目標位置に移動させるまでの時間とした．また，定量評価に\nおいては二つの手法に対してタスクの成績を評価するため，f 検定を用い等分散と仮定さ\nれるかを確認し，それに応じたt 検定を行うことで有意差の有無を確認した．この際，優\n位水準は5%とした．\n4.4.2\n主観的な操作のしやすさの評価指標\nアームロボット操作開始までを含めたシステム全体の使いやすさの評価としてSystem\nUsability Scale（SUS）を用いた．SUS は10 の質問に対し5 段階で評価を行う質問票であ\nり，ユーザビリティと学習能力を測定し指標化する[53]．すべての質問の5 段階評価の結\n果は0 から100 の範囲でスコアリングされる，SUS におけるスコアの基準を表4.1 に示す．\n平均点は68 点となっており，平均点以上が良いシステムと言われる．SUS のアンケート\n回答者は各項目を5 段階で評価する．集計方法は奇数の質問の回答スコアから1 を引き，\n偶数の質問スコアを5 から引く．その後，すべてのスコアを合算し2.5 倍したものがSUS",
            " を引き，\n偶数の質問スコアを5 から引く．その後，すべてのスコアを合算し2.5 倍したものがSUS\nスコアとなるこれに加え，主観的にアームロボットの操作が直感的かつ容易であったか，\n32\n意図したとおりに操作が可能であったかを検証するため独自に作成したアンケートを用\nいた．\n表4.1 SUS におけるスコアと評価の対応\nSUS score\nGrade\nAdjective Rating\n>80.3\nA\nExcellent\n68 - 80.3\nB\nGood\n68\nC\nOkay\n51 - 68\nD\nPoor\n<51\nE\nAwful\n33\n第5章\n実験結果及び考察\n5.1\n定量評価の実験結果及び考察\n図5.1 に従来手法及びTIARC のタスク完了時間の比較を示す．エラーバーは標準誤差を\n示す．従来手法とTIARC のタスク完了時間を比較した結果，TIARC を用いた提案手法を\n用いてタスクを行った際に従来手法に比べてタスク完了時間が短縮されることが示され，\n二つの手法間のタスク完了時間には有意差が見られた．提案手法はアームロボットを動か\nしたい方向へ手を動かすことやTIARC を持った手を",
            "意差が見られた．提案手法はアームロボットを動か\nしたい方向へ手を動かすことやTIARC を持った手を傾ける事でアームロボットの操作が\n可能であり，グリッパーの制御においてもTIARC を強く握るのみで可能であるため，操\n作が直感的に感じられとこがタスク完了時間の短縮に寄与したと考えられる．直感的な操\n作が可能なため，タスク開始から実際の操作に迷わずタスクを行うことが可能であったこ\nともタスク完了時間が短縮されたと考えられる．従来手法はボタン数の多さから操作の間\n隔をつかむことが難しく意図した通りの操作が難しい一方で提案手法はアームロボットを\n動かしたい方向に手を動かすのみで操作可能であるため，意図した通りの操作が可能であ\nる点もタスク完了時間の短縮に寄与したと考えられる．以上のようにタスク完了時間は\nTIARC を用いた提案手法で大幅に短縮されることが明らかとなったがタスク完了時間の\nばらつきは提案手法の方が大きい．従来手法はボタン数が多く操作が複雑なため直感的な\n意図した操作が難しい一方でアームロボットの操作に限らず様々な場面で一般的なユーザ\nインターフェースであるため，個人差が小さ",
            "方でアームロボットの操作に限らず様々な場面で一般的なユーザ\nインターフェースであるため，個人差が小さくなったと考えられる．これに対し提案手法\nでは手の位置及び手に持ったTIARC の姿勢を用いた操作手法やTIARC を強く握ること\nでグリッパーを操作する手法はユーザが初めて体験する操作手法であり，それに慣れる時\n間には個人差があるため，タスク完了時間のばらつきが大きくなったと考えられる．\n34\n図5.1 従来手法及びTIARC のタスク完了時間の比較\n*:p<0.05\n図5.2 にPall0v2 及びPall0v3 のタスク完了時間の比較を示す．エラーバーは標準誤差を\n示す．Pall0v2 を用いた提案手法とPall0v3 を用いた提案手法のタスク完了時間を比較した\n結果，Pall0v3 を用いた際にタスク完了時間が短縮されることが示され，二つの手法間の\nタスク完了時間には有意差が見られた．Pall0v2 とPall0v3 の差はグリッパーの操作時の\nみである．Pall0v2 では特定の位置にあるボタンを押し，開閉を切り替える必要があるが，\nPall0v3 ではデバイスを握っている間は",
            "位置にあるボタンを押し，開閉を切り替える必要があるが，\nPall0v3 ではデバイスを握っている間はグリッパーが閉じ続ける制御を行っている．すな\nわち，グリッパーの操作が可能な部分の表面積が異なっている点が最も大きな違いであ\nる．Pall0v3 を用いた提案手法で優位にタスク間長時間が短縮されたことはグリッパーを\n操作可能である部分の表面積を大きくすることは直感的で意図した操作を可能にするこ\nとに寄与していると考えられる．また，Pall0v3 を握っている間グリッパーを閉じる操作\n手法はボタンで切り替える手法に比べて実際のアームロボットの動作に近くより直感的な\n操作が可能であったことがタスク完了時間の短縮に寄与したと考えられる．\nタスク間長時間のばらつきはPall0v3 を用いた提案手法に比べPall0v2 を用いた提案手\n法で大きくなることが示された．Pall0v2 は特定の位置にあるボタンを用いてグリッパー\n35\nの制御を行うためボタンの位置を常に把握しているかという点がタスク完了時間に影響\nしていると考えられる．実際に個々の被験者のタスク完了時間を見ると，Pall0v2 を用い\n",
            "間に影響\nしていると考えられる．実際に個々の被験者のタスク完了時間を見ると，Pall0v2 を用い\nた際とPall0v3 を用いた際で差が数秒程度の被験者が複数存在する．このことからグリッ\nパーの操作を行うボタンの位置に迷わず操作を行えた被験者はPall0v3 同程度の時間でタ\nスクを完了することが可能であったと考えられる．これに対し，グリッパーの操作を行う\nボタンの位置を常に把握することが難しかった被験者は通常の操作に加えそのボタンを探\nすことを行ったため，タスク完了時間に影響したと考えられる．\n以上のことからグリッパーの操作が可能な部分の表面積が大きいことは重要な要素であ\nり，その面積がより大きいことがタスク完了時間の短縮に寄与すると考えられる．\n図5.2 Pall0v2 及びPall0v3 のタスク完了時間の比較\n*:p<0.05\nTIARC とPall0v2 の比較においては大きな差が見られない結果となった．TIARC と\nPall0v2 の最も大きな差は円柱型であるか球型であるかという点である．表面の材質の\n差などから単純に比較することは難しいが，本実験の結果からアームロボッ",
            "かという点である．表面の材質の\n差などから単純に比較することは難しいが，本実験の結果からアームロボットの操作にお\nいて使用するインプットデバイスの形状は操作性及びタスク完了時間に影響を与えないこ\nとが明らかとなった．TIARC は表面に取り付けた圧力センサの部分を強く握ることでグ\n36\nリッパーの操作が可能でありPall0v2 に比べグリッパーの操作が可能な部分の面積は大き\nいが，デバイスの任意の部分を握ることでの操作は難しく特定の位置を握る必要がある点\nでPall0v2 と同様であることもタスク完了時間に大きな差が出なかった要因であると考え\nられる．そのため，TIARC においてはデバイス表面全体で把持認識を可能にすることで\nタスク完了時間がより短縮されると考えられる．\n図5.3 に従来手法及びTIARC の目標位置の中心からの差の比較を示す．エラーバーは標\n準誤差を示す．従来手法とTIARC を用いた提案手法でタスクを行った際の目標位置の中\n心からの差を比較した結果，わずかにTIARC を用いた提案手法が小さいことが明らかと\nなったが，有意差は見られなかった．これは，従来手法と提案",
            "C を用いた提案手法が小さいことが明らかと\nなったが，有意差は見られなかった．これは，従来手法と提案手法が同等程度の正確な操\n作が可能であることを示しており，操作性の向上により細かな操作が難しくなるなどの欠\n点が提案手法に見られないことを示している．しかし，提案手法においては操作時に手の\n全ての動作を用いて操作を行っており，操作を意図しない微細な動きと操作を意図した動\nきの区別を行っていないため，操作精度が低下した可能性がある．そのため，これらを区\n別し，操作を意図しない微細な手の動きをアームロボットの操作から排除することでより\n操作精度が向上すると考えられる．\n37\n図5.3 従来手法及びTIARC の目標位置の中心からの差の比較\n図5.4 にPall0v2 及びPall0v3 の目標位置の中心からの差の比較を示す．エラーバーは標\n準誤差を示す．Pall0v2 及びPall0v3 を用いた提案手法の目標位置の中心からの差を比較し\nた結果わずかにPall0v2 を用いた手法が小さいことが明らかとなったが，有意差は見られ\nなかった．このことは，アームロボット操作の精度において，グリッパー",
            "明らかとなったが，有意差は見られ\nなかった．このことは，アームロボット操作の精度において，グリッパーの操作手法は影\n響を与えないことが示された．Pall0v2 を用いた際にグリッパーを制御するボタンの位置\nに迷い，精度が低下する可能性があるが，提案手法のアームロボット操作が容易であり位\n置の調整が容易であるためグリッパーを制御するボタンを発見後にもアームロボットの頭\n部の位置の調整が行いやすく，操作精度が維持されたと考えられる．\n38\n図5.4 Pall0v2 及びPall0v3 の目標位置の中心からの差の比較\n5.2\n主観的な操作のしやすさの実験結果と考察\n表5.1 に従来手法及びTIARC を用いた提案手法のSUS スコアの平均を示す．結果とし\nて，従来手法で45.7 点であり提案手法で72.2 点であり，4.4.2 節で述べた一般に良いシス\nテムとされる68 点という基準を提案手法では満たしたが，従来手法では大幅に下回る結\n果となった．従来手法と提案手法では操作開始時にスタートボタンを押すことや任意のタ\nイミングでメニューボタンを押すことで操作が中断可能であること，リセットボタン",
            "ンを押すことや任意のタ\nイミングでメニューボタンを押すことで操作が中断可能であること，リセットボタンを押\nすことでアームロボットを初期姿勢に戻すことが可能であることは共通である．そのため\n実際にアームロボットの操作を行う際のシステムの使いやすさが評価に影響を与えたと考\nえられる．実際にアームロボットを操作する際には従来手法ではアームロボットの頭部の\n位置や姿勢，グリッパーの制御を全てボタンで行うためボタン数が多くなり，認知的負荷\nが大きく操作が煩雑である．このことがシステム全体に対して使用することが難しい，使\n用には特別な知識が必要だと感じさせ，基準を大きく下回る結果になったと考えられる．\n39\nこれに対し提案手法ではアームロボットの操作中に表示されているボタンはメニューボタ\nンのみであり，認知的負荷が小さい設計となっている．そのため，操作中のシステムの仕\n様が容易であると感じさせることができ，基準を満たす結果となったと考えられる．\n表5.1 従来手法及び提案手法における平均SUS スコア\n手法\nSUS スコア\n従来手法\n45.7\n提案手法\n72.2\nいかにアンケート評価の結果と考察を",
            "ア\n手法\nSUS スコア\n従来手法\n45.7\n提案手法\n72.2\nいかにアンケート評価の結果と考察を述べる．アンケートの各項目は「全く思わない」\nを1，\n「非常に思う」を5 としてスコアリングした．また，スコアリングした値を用いて各\nモードの各項目の平均スコアを算出した．表5.2 に被験者に回答してもらったアンケート\n項目及び表5.3 にアンケート評価結果を示す．アンケートの各項目について考察を行う．\nQ1 　アームロボットの操作は直感的に感じましたか？\n従来手法とTIARC の比較において，従来手法で2.8 点でありTIARC で4.2 点という\n結果になった．従来手法のアームロボットの頭部の位置や姿勢，グリッパーの操作\nを全てボタンで行う操作手法は操作中どのボタンがどの方向に動くかを常に把握し\nておく必要があるため，例えば「右側に動かしたい」と考えてから実際に動かすま\nでに右側へ動かすボタンを認識し，ボタンを押すという工程が必要なため直感的で\nはないと感じられたと考えられる．これに対し，提案手法ではアームロボットの頭\n部の位置を動かしたい方向に手を動かす，傾けるやTIARC を握る",
            "し，提案手法ではアームロボットの頭\n部の位置を動かしたい方向に手を動かす，傾けるやTIARC を握るのみであるため，\n実際のアームロボットの動作に近く直感的に操作できると感じられたと考えられる．\nPall0v2 とPall0v3 の結果を比較すると，Pall0v2 で2.9 点，Pall0v3 で3.6 点という結\n果になった．Pall0v2 ではグリッパーの操作の差異に特定の位置のボタンを押す必要\nがあることが実際の動作に近くなく，直感的ではないと感じられたと考えられる．こ\nれに対し，Pall0v3 は強く握っている間グリッパーを閉じ続けるという実際のアーム\nロボットの動作に近い操作が可能なため直感的に感じられたと考えられる．\nQ2 　アームロボットの操作は難しく感じましたか？\n従来手法とTIARC の比較において，従来手法で4.3 点でありTIARC で2.9 点という\n結果になった．Q1 で述べた通り，従来手法はどのボタンがどの方向に動かすかを把\n握しておく必要があることやボタン数が多いことから操作が煩雑であることが操作が\n難しいと感じさせたと考えられる．これに対して直感的な操作",
            "が多いことから操作が煩雑であることが操作が\n難しいと感じさせたと考えられる．これに対して直感的な操作が可能な提案手法では\n操作者が実際にボタンを押すなどして操作を行うことが少ないため操作が容易に感じ\nられたと考えられる．Pall0v2 とPall0v3 を比較すると，Pall0v2 で3.0 点，Pall0v3 で\n3.2 点であり大きな差は見られなかった．このことは，本実験においてはグリッパー\nを操作する部分の表面積の大きさはアームロボットの操作自体が難しく感じるかと\nいう点に影響を与えないことを示している．グリッパーの操作はアームロボットの\n操作の内の一部分でありその操作を行う時間はアームロボットの頭部の位置や姿勢\nの操作を行う時間に比べて少ないため，主観的な操作の難しさに影響を与えなかっ\nたと考えられる．\n40\nQ3 　アームロボットの操作の精度に満足していますか？\n従来手法とTIARC の比較において，従来手法で2.5 点でありTIARC で4.0 点という\n結果になった．定量評価の結果においては従来手法と提案手法の操作精度を比較す\nる目標位置の中心からの差の比較においては大き",
            "価の結果においては従来手法と提案手法の操作精度を比較す\nる目標位置の中心からの差の比較においては大きな差が見られなかったにも関わら\nず，差が見られたことは主観的に意図した通りの操作が可能であったかが影響を与\nえていると考えられる．意図した通りの操作が可能であったことで，素早く意図し\nた箇所にアームロボットを動かすことが可能になり，精度高く操作をしていると感\nじさせたと考えられる．Pall0v2 とPall0v3 の比較においては両手法で3.1 点と差が見\nられなかった．これはQ2 と同様にグリッパーを操作する時間とアームロボットの頭\n部の位置及び姿勢を操作する時間の差からグリッパーを操作の影響が小さく，同程\n度の操作精度の満足度となったと考えられる．\nQ4 　アームロボットの操作の習得は容易であると感じましたか？\n従来手法とTIARC の比較において，従来手法で2.4 点でありTIARC で3.4 点という\n結果になった．操作の習得という点においては操作が単純であるかや覚えやすいか\nという点が影響していると考えられる．操作が単純であるかという点においては従\n来手法はQ2 で述べた通り操",
            "う点が影響していると考えられる．操作が単純であるかという点においては従\n来手法はQ2 で述べた通り操作が煩雑であるため難しく感じられた可能性がある一方\nで提案手法ではアームロボットの操作中に必要なボタンがなく操作自体が単純に感\nじられたと考えられる．また，従来手法ではボタン数の多さからどのボタンがどの\nような操作が可能かを覚えることが難しいことが操作の習得が難しいと感じさせた\nと考えられる一方で定量評価やこれまでのアンケート評価から示されたように直感\n的かつ容易な操作が可能な提案手法では覚える必要があることが少なく習得が容易\nであると感じさせたと考えられる．Pall0v2 とPall0v3 の比較結果を見るとPall0v2 で\n3.6 点でありPall0v3 で4.0 点とわずかにPall0v3 が容易に操作を習得可能と感じられ\nることが明らかとなった．これまで述べた通りPall0v2 ではグリッパーの操作をボタ\nンで行うためボタンの位置を覚える必要があることが操作手法を容易に習得可能と\n感じるかに影響を与えたと考えられ，Pall0v3 ではこの操作を行う部分の表面積が大\nきいことが操",
            "\n感じるかに影響を与えたと考えられ，Pall0v3 ではこの操作を行う部分の表面積が大\nきいことが操作手法を容易に習得可能と感じさせることに寄与したと考えられる．\nQ5 　アームロボットの操作中に疲労を感じましたか？\n従来手法とTIARC の比較において，従来手法で2.8 点でありTIARC で2.5 点と両手\n法でおおよそ同程度日疲労を感じている結果になった．従来手法においては操作に\n必要なボタン数が多いため操作中の認知的負荷が大きくなり，一定の疲労が感じら\nれたと考えられる．提案手法においては操作が必要なボタン数が少ないため認知的\n負荷を低減可能である一方でアームロボットの操作中は常に手を動かす必要がある\nため身体的な疲労が大きく一定の疲労が感じられたと考えられる．Pall0v2 とPall0v3\nの比較においてはPall0v2 で1.7 点でありPall0v3 で3.3 点とPall0v3 を用いた手法で\nより疲労を感じられることが明らかとなった．Pall0v3 ではグリッパーの操作におい\nて握っている間グリッパーを閉じる操作を行っているため，一定以上握力を必要と\nする時間がPa",
            "作におい\nて握っている間グリッパーを閉じる操作を行っているため，一定以上握力を必要と\nする時間がPall0v2 に比べて長くなり身体的な疲労が大きいためより疲労を感じられ\nていると考えられる．\nQ6 　操作のインターフェースは理解しやすかったですか？\n41\n従来手法とTIARC の比較において，従来手法で3.4 点でありTIARC で3.7 点と大き\nな差は見られないという結果になった．従来手法において認知的負荷の大きい操作\nインターフェースでありながら提案手法と同程度理解しやすいと感じられたことは，\n従来手法で用いているボタン型のインターフェースはアームロボットの操作に限らず\n多くの場面で利用されているものであるため，理解しやすいと感じられたと考えら\nれる．提案手法においては操作が必要なボタン型のインターフェースが少ないこと\nに加え，アームロボットの操作時にもTIARC を強く握るのみの操作であったため理\n解しやすいと感じられたと考えられる．Pall0v2 とPall0v3 の比較においてはPall0v2\nで3.6 点でありPall0v3 で3.8 点と同程度インターフェースが理解し",
            "いてはPall0v2\nで3.6 点でありPall0v3 で3.8 点と同程度インターフェースが理解しやすいと感じら\nれていることが明らかとなった．グリッパーの操作において単純にデバイスを握る\nのみで操作が可能であることと特定の位置のボタンを押す必要があることの差によ\nり理解のしやすさにわずかに差が生じているが，操作が必要なボタン型のインター\nフェースは両手法で少なくなっているため理解しやすいと感じられたと考えられる．\nQ7 　課されたタスクは難しいと感じましたか？\n従来手法とTIARC の比較において，従来手法で3.2 点でありTIARC で2.0 点と提案\n手法を用いた際によりタスクを簡単に感じていることが明らかとなった．従来手法\nにおいては操作時の認知的負荷が大きいことに加え，操作が煩雑であり直感的かつ\n容易な操作が難しいため，タスク自体を難しく感じたと考えられる．これに対し提\n案手法においてはQ4 の考察で述べた通り直感的かつ容易な操作が可能であるため，\nアームロボットの操作に迷うことなくタスクを行うことが可能となりタスク自体が\n簡単に感じられたと考えられる．Pall0v2 とP",
            "ことなくタスクを行うことが可能となりタスク自体が\n簡単に感じられたと考えられる．Pall0v2 とPall0v3 の比較においてはPall0v2 で2.1\n点，Pall0v3 で1.8 点とわずかにPall0v3 を用いた際にタスクが簡単に感じられる結果\nとなった．両手法においてアームロボットの頭部の位置及び姿勢の決定の操作は直\n感的かつ容易に行うことが可能であったため一定以上タスクが簡単に感じられたと\n考えられる．Pall0v3 においてはグリッパーの操作においてより実際のグリッパーの\n動きに近くボタンの位置を常に把握する必要のない操作が可能であったためPall0v2\nに比べ直感的かつ容易に感じられわずかにタスク自体が簡単に感じられたと考えら\nれる．\nQ8 　アームロボットは意図した通りに動きましたか？\n従来手法とTIARC の比較において，従来手法で2.5 点でありTIARC で4.0 点と提案\n手法において大幅に意図した通りの操作が可能であると感じられることが明らかと\nなった．従来手法においては常に各ボタンを押したことによるアームロボットの動\n作を把握する必要があるため操作ミスが",
            "手法においては常に各ボタンを押したことによるアームロボットの動\n作を把握する必要があるため操作ミスが起きやすく意図した通りの操作が難しいと\n感じられたと考えられる．これに対して提案手法においてはこれまで述べた通り直\n感的かつ容易な操作が可能であることに加えて手の動きに合わせてアームロボット\nが動作するため操作ミスが起きずらく，意図した通りの操作が可能であったと考え\nられる．Pall0v2 とPall0v3 の比較においてはPall0v2 で3.0 点でありPall0v3 で3.1 点\nと大きな差は見れれない結果となった．これはアームロボットの頭部の位置及び姿\n勢の決定のおいては同様の操作手法でありその操作手法がTIARC を用いた場合と同\n様に直感的な操作が可能であるため意図した通りの操作が可能であったと考えられ\nる．また，グリッパーの制御において意図した通りの操作が可能かという点におい\n42\nてはボタンによる操作が必要か単純にデバイスを握るのみで操作可能かは影響を与\nえないことが明らかとなった．\n表5.2 評価実験のアンケート項目\nquestion\nQ1 　アームロボットの操作は直感",
            "となった．\n表5.2 評価実験のアンケート項目\nquestion\nQ1 　アームロボットの操作は直感的に感じましたか？\nQ2 　アームロボットの操作は難しく感じましたか？\nQ3 　アームロボットの操作の精度に満足していますか？\nQ4 　アームロボットの操作の習得は容易であると感じましたか？\nQ5 　アームロボットの操作中に疲労を感じましたか？\nQ6 　操作のインターフェースは理解しやすかったですか？\nQ7 　課されたタスクは難しいと感じましたか？\nQ8 　アームロボットは意図した通りに動きましたか？\n表5.3 評価実験のアンケート結果\n質問番号\n従来手法\nTIARC\nPALL0v2\nPALL0v3\nQ1\n2.8\n4.2\n2.9\n3.6\nQ2\n4.3\n2.9\n3.0\n3.2\nQ3\n2.5\n4.0\n3.1\n3.1\nQ4\n2.4\n3.4\n3.6\n4.0\nQ5\n2.8\n2.5\n1.7\n2.3\nQ6\n3.4\n3.7\n3.6\n3.8\nQ7\n3.2\n2.0\n2.1\n1.8\nQ8\n2.5\n4.0\n3.0\n3.1\n43\n第6章\n結論と今後の展望\n6.1\n結論\n本研究では，産業などの現場に導入され，生産性",
            "\n3.1\n43\n第6章\n結論と今後の展望\n6.1\n結論\n本研究では，産業などの現場に導入され，生産性や安全性などを向上させているアーム\nロボットがその作業を完全に自動化することは難しく人が操作を行う必要がある場合があ\nるが，先行研究や一般に用いられている操作手法には直感的かつ意図しない動作の発生を\n防止可能な操作手法がない点に着目し，アームロボットのリモート操作手法を提案した．\n本研究で提案した手法は，AR アプリケーション内に仮想的に配置されたアームロボット\nを操作することでそれに同期した実際のアームロボットも操作可能な手法となっている．\nまた，仮想的に配置されたアームロボットについては手の位置及びインプットデバイス\nより取得した姿勢，グリッパーの開閉を用いてロボットアームのヘッドの位置姿勢を決定\nし，各関節角を逆運動学を用いて決定することで操作を行う手法である．提案システムを\n用いて従来手法である一般的に広く用いられているボタンを使用して操作を行う手法と\n比較する評価実験を行った結果，操作精度は従来手法と同程度であるが，タスク完了まで\nの時間が優位に短くなることが明らかとなった．P",
            "，操作精度は従来手法と同程度であるが，タスク完了まで\nの時間が優位に短くなることが明らかとなった．Pall0v2 とPall0v3 の比較結果については\nPall0v3 でタスク完了時間が優位に短縮されることが明らかとなった．これはグリッパー\nの制御において，ボタンによる操作に比べ単純にデバイスを握るのみの操作が直感的かつ\n容易であり，制御可能な部分の表面積の大きさがアームロボットの操作に影響を与えるこ\nとが明らかとなった．従来手法と提案手法のシステム全体としての使いやすさを評価した\nSUS の結果から提案手法では一定以上使いやすいシステムであるが，従来手法では基準\nを満たさず使用が難しいことが明らかとなった．このことから提案手法ではボタン数の少\nなさから認知的負荷を低減可能であり操作に迷うことが少ないシステムであることが確認\nできた．また，アンケート結果から提案手法は従来手法に比べて直感的かつ容易であり，\n意図した通りの操作が可能であることが明らかとなった．Pall0v2 とPall0v3 の比較におい\nてはPall0v3 を用いた手法がより直感的に操作可能であることが判明した．この",
            "v3 の比較におい\nてはPall0v3 を用いた手法がより直感的に操作可能であることが判明した．このことから\nもグリッパーを制御可能な部分の表面積の大きさがアームロボットの操作の直感性に影響\nを与えることが示された．\n提案手法を用いることでアームロボットの操作を直感的かつ容易に行うことを可能にし\nた．アームロボットの操作部分以外においてもシステム全体としてボタン数を大幅に減ら\nすことで認知的負荷を低減し使いやすいシステムと感じられることが示された．また，グ\nリッパーをの制御可能な部分のひょめんせきの大きいことが直感的かつ容易な操作を可能\nにすることに寄与することが示された．\n44\n6.2\n今後の展望\n今後の展望として本研究の評価実験では各操作手法で一回のみタスクを行ったことから，\n操作手法の慣れによる操作のしやすさ，タスク実行時間の変化や差異については明らかに\nなっていないため，長期的に複数回タスクを行うことでの変化を調査する実験を行う必要\nがある．操作面においては意図しない手の揺れによる動きと操作を意図した動きを区別す\nることでより正確な操作を可能にする必要がある．仮想空間と実環境の",
            "る動きと操作を意図した動きを区別す\nることでより正確な操作を可能にする必要がある．仮想空間と実環境の同期においても課\n題が残っている．仮想的に配置されたアームロボットの姿勢を常に実空間のアームロボッ\nトの姿勢と同期することは難しく，実空間において周囲の安全性を損なう危険性がある．\nそのため，図6.1 に示すような操作手法を開発中である．この操作手法は実空間のアーム\nロボットと仮想アームロボットを分けて表示してあり，仮想アームロボットを操作，姿勢\nを固定後に実空間と同期したアームロボットが追従する形で動作する．追従している際\nユーザは仮想アームロボットの操作が不可能となる．この操作手法により直感的かつ容易\nな操作を維持すると同時に実空間において周囲の安全性の維持が可能になると考える．\n図6.1 安全性確保のための操作手法（開発中）\n多くのアームロボットに汎用的に対応していない点も課題である．現状のシステムでは\n特定のアームロボットにのみ対応しており，同じ自由度であってもその他もアームロボッ\nトの操作が不可能である．現在開発中の手法としてはアームロボットのヘッドのみを仮想\n的に提示，操作を",
            "\nトの操作が不可能である．現在開発中の手法としてはアームロボットのヘッドのみを仮想\n的に提示，操作を行い，その位置姿勢のみを決定する手法であるが，このような手法で操\n作が可能であるかは実際のアームロボットに依存するため汎用的であるとは言えない．今\n日導入されているアームロボットの種類は数多く，その多くに対応可能なシステムとする\nことでより実用的にしていきたい．また，システム全体として実際のアームロボットの状\n態や周辺オブジェクトの状態をAR アプリケーションへフィードバックを行っていないた\nめ，これを行うことで遠隔地の実環境においてもアプリケーション内と同様な精度で操作\nを可能にする必要がある．\n45\n以上の課題を解決することでより実用的なシステムとし，提案手法を発展させていき\nたい．\n46\n謝辞\n本研究の機会を与えて下さり，研究面について大変ご丁寧なご指導を賜りました，青山\n学院大学理工学部情報テクノロジー学科Guillaume LOPEZ 教授およびトゥルク応用科学\n大学Luimula Mika 教授に深く感謝申し上げます．そして，研究会などを通して助言をいた\nだいたLOPEZ 研",
            "a Mika 教授に深く感謝申し上げます．そして，研究会などを通して助言をいた\nだいたLOPEZ 研究室の皆様並びに実験に協力していただいた皆様に深く感謝いたします．\n2025 年1 月31 日\n阿部　悠貴\n47\n参考文献\n[1] 安藤健. コロナ禍におけるサービスロボットの活用とインタラクション技術. 計測と\n制御, Vol. 61, No. 3, pp. 231–234, 2022.\n[2] 総務省. https://www.microsoft.com/ja-jp/hololens/hardware. [ac-\ncessed 2024.08.24].\n[3] 榊原伸介. 知能ロボットによる工場自動化とiot, ai 活用について. システム/制御/情\n報, Vol. 61, No. 3, pp. 101–106, 2017.\n[4] IFR International Federation of Robotics.\nWorld robotics 2024.\nhttps://ifr.\norg/img/worldrobotics/Press_Conference_2024.pdf, 2",
            "org/img/worldrobotics/Press_Conference_2024.pdf, 2024.\n[accessed\n2024.12.24].\n[5] オムロン株式会社.\nオムロン\n制御機器\nソリューション\n事例.\nhttps://www.fa.omron.co.jp/solution/case/.\n[6] 株式会社\nKEYENCE.\nFa\nロボットの導入事例.\nhttps://www.keyence.co.jp/landing/req/vision/cv-x 1097 04.jsp.\n[7] 三治信一朗. ロボット事例からみる, アプリケーション, ソリューション開発の方向性.\nシステム/制御/情報, Vol. 64, No. 11, pp. 447–442, 2020.\n[8] MONOist. 2022年展望. https://monoist.itmedia.co.jp/mn/articles/2201/13/news127.html.\n[9] Nichola Lowe and Thomas Kemeny. Disparities in robot adoption ",
            " and Thomas Kemeny. Disparities in robot adoption among u.s. manufac-\nturers. Industry and Innovation, Vol. 28, No. 9, pp. 1062–1084, 2021.\n[10] Lindsay Sanneman, Christopher Fourie, and Julie A. Shah. The state of industrial robotics:\nEmerging technologies, challenges, and key research directions. ArXiv, 2020.\n[11] J. Gray, S. Davis, and M. G. Mullins. Challenges for industrial robot applications in food\nmanufacturing. In Proceedings of the ACM International Conference on Human-Robot\nInteractio",
            "International Conference on Human-Robot\nInteraction, pp. 328–472, 2018.\n[12] MONOist. 3dexperience world japan 2022. https://monoist.itmedia.co.jp/\nmn/articles/2211/24/news052.html.\n[13] 伊藤忠テクノソリューションズ株式会社. 仮想gpu によるcad vdi で設計開発プロセ\nスを加速「設計開発業務の働き方改革を実現」. https://www.ctc-g.co.jp/report/case-\nstudy/toyota02/.\n[14] NECソリューションイノベータ. 仮想gpuによるcad vdiで設計開発プロセスを加速「設\n計開発業務の働き方改革を実現」. https://www.ctc-g.co.jp/report/case-study/toyota02/.\n48\n[15] SocoCacico. Sococacico. https://sococacico.com/.\n[16] AIMult",
            ". Sococacico. https://sococacico.com/.\n[16] AIMultiple.\nXr/ar\nin\nmanufacturing:\n7\nuse\ncases\nwith\nexamples.\nhttps://research.aimultiple.com/ar-in-manufacturing/.\n[17] 小宮昌人. 生産現場におけるデジタルツインの今. 工場管理/日刊工業新聞社[編],\nVol. 68, No. 2, pp. 14–17, 2022.\n[18] Tenaris.\nVr and ar technology used to manage argentine project from italy.\nhttps://www.tenaris.com/en/news/2021/vr-and-ar-technology-used-to-manage-argentine-\nproject-from-italy.\n[19] FUJITSU.\n在庫管理の改善に売り上げアップ，保守点検の効率化.\nhttps://jp.fujitsu.com/platform/ser",
            "げアップ，保守点検の効率化.\nhttps://jp.fujitsu.com/platform/server/advantages/special/jokun/10-ar/.\n[20] HOLOLAB. Assists. https://hololab.co.jp/assists.\n[21] universal\nrobot.\nhttps://s3-eu-west-1.amazonaws.com/\nur-support-site/43932/UR5e_User_Manual_jp_Global.pdf,\n2022.\n[accessed 2024.08.24].\n[22] 三菱電機. Melsoft rt visualbox. https://www.mitsubishielectric.com/fa/\nproducts/rbt/assista/smerit/vb/index.html.\n[23] CHITOSE ROBOTICS.\ncrewbo studio.\nhttps://chitose-robotics.com/\narchives/233756.\n[24] 楓和憲, 坂井田千摩, 綿",
            "-robotics.com/\narchives/233756.\n[24] 楓和憲, 坂井田千摩, 綿貫啓一. タッチパネルおよびジャイロスコープを用いた多関節\nマニピュレータの無拘束遠隔操作システムの開発. 日本機械学会論文集, Vol. 81, No.\n830, pp. 15–00177, 2015.\n[25] Paul Hebert, Jeremy Ma, James Borders, Alper Aydemir, Max Bajracharya, Nicolas Hud-\nson, Krishna Shankar, Sisir Karumanchi, Bertrand Douillard, and Joel Burdick. Super-\nvised remote robot with guided autonomy and teleoperation (surrogate): a framework for\nwhole-body manipulation. In 2015 IEEE international conference on robotics and au-\ntom",
            "E international conference on robotics and au-\ntomation (ICRA), pp. 5509–5516. IEEE, 2015.\n[26] Reduanur Rahman, Md Sajid Rahman, and Jillor Rahman Bhuiyan. Joystick controlled\nindustrial robotic system with robotic arm. In 2019 IEEE International Conference on\nRobotics, Automation, Artiﬁcial-intelligence and Internet-of-Things (RAAICON), pp. 31–\n34. IEEE, 2019.\n[27] Sunao Hashimoto, Akihiko Ishida, Masahiko Inami, and Takeo Igarashi. Touchme: An\naugmented reality based remote robot manipulation",
            "\naugmented reality based remote robot manipulation. In The 21st International Conference\non Artiﬁcial Reality and Telexistence, Proceedings of ICAT2011, Vol. 2, 2011.\n[28] 竹内良緒, タケウチリオ. タッチパネルを用いた容易な把持幅指定によるロボットアー\nムの操作インターフェース.\n49\n[29] Kalagotla Chenchireddy, Radhika Dora, Gouse Basha Mulla, Varghese Jegathesan, and\nShabbier Ahmed Sydu.\nDevelopment of robotic arm control using arduino controller.\nIAES International Journal of Robotics and Automation (IJRA), Vol. 264, pp. 1024–1064.\n[30] Hairong ",
            "ion (IJRA), Vol. 264, pp. 1024–1064.\n[30] Hairong Jiang, Juan P Wachs, Martin Pendergast, and Bradley S Duerstock. 3d joystick\nfor robotic arm control by individuals with high level spinal cord injuries. In 2013 IEEE\n13th International Conference on Rehabilitation Robotics (ICORR), pp. 1–5. IEEE, 2013.\n[31] Ivan Rulik, Md Samiul Haque Sunny, Javier Dario Sanjuan De Caro, Md Ishrak Islam\nZarif, Brahim Brahmi, Sheikh Iqbal Ahamed, Katie Schultz, Inga Wang, Tony Leheng,\nJason Peng Longxiang, et al.",
            "ga Wang, Tony Leheng,\nJason Peng Longxiang, et al. Control of a wheelchair-mounted 6dof assistive robot with\nchin and ﬁnger joysticks. Frontiers in Robotics and AI, Vol. 9, p. 885610, 2022.\n[32] Nikolaos Mavridis, Georgios Pierris, Paolo Gallina, Zacharoula Papamitsiou, and Umair\nSaad. On the subjective difﬁculty of joystick-based robot arm teleoperation with auditory\nfeedback. In 2015 IEEE 8th GCC Conference & Exhibition, pp. 1–6. IEEE, 2015.\n[33] 並木惇, 菅原悠平, 松嵜昭雄. ジェスチャーによるロボット操作におけるモデリングに\n関する一",
            "3] 並木惇, 菅原悠平, 松嵜昭雄. ジェスチャーによるロボット操作におけるモデリングに\n関する一考察(2) 大学生を対象とした実験授業を事例として. 日本科学教育学会年会\n論文集42, pp. 383–386. 一般社団法人日本科学教育学会, 2018.\n[34] Poltak Sihombing, Rifky B. Muhammad, Herriyance Herriyance, and Elviwani Elviwani.\nRobotic arm controlling based on ﬁngers and hand gesture. In 2020 3rd International\nConference on Mechanical, Electronics, Computer, and Industrial Technology (MECnIT),\npp. 40–45, 2020.\n[35] Pradeep .J. Design and implementation of gesture controlled robotic arm for industrial\nappl",
            "gesture controlled robotic arm for industrial\napplications. International Journal of Scientiﬁc Research, Vol. 3, pp. 202–209, 10 2016.\n[36] 川西巧人. Leap motion を使用したロボットアームの操作手法の開発. 2021.\n[37] 日置真優. ジェスチャを用いたアームロボットの制御. 2018.\n[38] Hanxiao Chen. Motion control of interactive robotic arms based on mixed reality devel-\nopment. 2024.\n[39] 福岡正彬, 中村文彦, 滝澤瞭, 正井克俊, 北崎充晃, 杉本麻樹. Facedrive: 顔表情による装\n着型ロボットアーム操作手法の提案. 日本バーチャルリアリティ学会論文誌, Vol. 25,\nNo. 4, pp. 451–461, 2020.\n[40] 木村拓己, 土田修平, 寺田努, 塚本昌彦ほか. 協働ロボットアーム",
            "461, 2020.\n[40] 木村拓己, 土田修平, 寺田努, 塚本昌彦ほか. 協働ロボットアームのためのハンズフリー\n制御手法の提案. 研究報告音楽情報科学(MUS), Vol. 2021, No. 43, pp. 1–8, 2021.\n[41] 高城頌太, 谷口尚平, 中野聡大, 岩澤有祐, 鈴木雅大, 熊谷亘, 谷中瞳, 松尾豊. 大規模言\n語モデルを補助に用いた言語指示ロボット学習のタスク汎用性の分析. 人工知能学会\n全国大会論文集第37 回(2023), pp. 2O1GS805–2O1GS805. 一般社団法人人工知能学\n会, 2023.\n50\n[42] Michael Ahn, Anthony Brohan, Noah Brown, Yevgen Chebotar, Omar Cortes, Byron\nDavid, Chelsea Finn, Chuyuan Fu, Keerthana Gopalakrishnan, Karol Hausman, et al.\nDo as i can, not as i say: Grounding language in robot",
            "s i can, not as i say: Grounding language in robotic affordances. arXiv preprint\narXiv:2204.01691, 2022.\n[43] Maximilian St¨olzle,\nSonal Santosh Baberwal,\nDaniela Rus,\nShirley Coyle,\nand\nCosimo Della Santina.\nGuiding soft robots with motor-imagery brain signals and\nimpedance control, 2024.\n[44] Ruohan Zhang, Sharon Lee, Minjune Hwang, Ayano Hiranaka, Chen Wang, Wensi Ai, Jin\nJie Ryan Tan, Shreya Gupta, Yilun Hao, Gabrael Levine, Ruohan Gao, Anthony Norcia,\nLi Fei-Fei, and Jiajun Wu. Noir: Neural",
            "ny Norcia,\nLi Fei-Fei, and Jiajun Wu. Noir: Neural signal operated intelligent robots for everyday\nactivities, 2023.\n[45] 久保山瞳, 小林一郎. 制御コマンドの言語化による言語指示操作への取り組み. 人工\n知能学会全国大会論文集第38 回(2024), pp. 3Xin284–3Xin284. 一般社団法人人工知\n能学会, 2024.\n[46] 黄瀬輝, 奥村亮, 谷口忠大. ロボット制御における大規模言語モデルと世界モデルの融\n合. 人工知能学会全国大会論文集第37 回(2023), pp. 2G5OS21e01–2G5OS21e01. 一\n般社団法人人工知能学会, 2023.\n[47] 藤井彬, 田中和明. 低遅延かつ軽量なセンサネットワーク実現のための技術研究. 情\n報処理学会研究報告, Vol. 2016, , 2016.\n[48] HoloLens2― 概要,\n機能,\n仕様.\nhttps://www.soumu.go.jp/\njohotsusintokei",
            ",\n機能,\n仕様.\nhttps://www.soumu.go.jp/\njohotsusintokei/whitepaper/ja/r04/html/nd121110.html.\n[ac-\ncessed 2024.12.24].\n[49] With PALL0™the ongoing digitalization of healthcare means less screen time and\nmore engaging fun! https://www.ai2ai.fi/. [accessed 2024.08.24].\n[50] 茅原崇徳, 大山修斗, 瀬尾明彦. 個人差への対応を考慮した人間工学的設計問題の定式\n化. 日本機械学会論文集C 編, Vol. 79, No. 799, pp. 800–813, 2013.\n[51] 横山清子, 楯千弘, 藤巻吾朗, 安藤敏弘. 1e1-5 グリップ表面の凹凸模様が握り易さに\n与える影響評価. 人間工学, Vol. 50, No. Supplement, pp. S186–S187, 2014.\n[52] 笹野祐嗣. 握りやすい把持体形状デ",
            "ement, pp. S186–S187, 2014.\n[52] 笹野祐嗣. 握りやすい把持体形状デザインを目的とした3 次元把持体データの特徴分\n析に関する研究.\n[53] James R Lewis. The system usability scale: past, present, and future. International Journal\nof Human–Computer Interaction, Vol. 34, No. 7, pp. 577–590, 2018.\n51\n伊藤　雄一　情報テクノロジー学科　教授\nQ\nこのような関連研究は多いと思うが，技術的に優位な点はなにか．直接指示と間接\n指示で比較の方法がアンフェアだと思います．\nA\nまず，技術的に優位な点としては手と手に持ったインプットデバイス及びヘッドマ\nウントディスプレイのみで直感的かつ容易にアームロボットの遠隔操作が可能であ\nる点です．先行研究では直感的に操作可能ですが，意図しない動作が発生する可能\n性がある手法や意図しない操作が発生する可能性は低いですが直感的な操作が難し\nい等直感的であることと容易であ",
            "る手法や意図しない操作が発生する可能性は低いですが直感的な操作が難し\nい等直感的であることと容易であることの条件を同時に満たす操作手法は見られず，\nこれら二つの条件を同時に満たしている点が技術的に優位な点であると考えていま\nす．比較の方法については，広く一般に普及している操作手法と比べる必要がある\nと考え本研究のような比較を行いました．しかし，アンフェアである点はおっしゃ\nる通りだと考えており，今後様々な先行研究で提案されている直接指示の手法と比\n較する必要があると考えています．\n52\n"
        ]
    },
    {
        "id": "paper_9",
        "filename": "M2024_imura.pdf",
        "title": "M2024_imura",
        "fulltext": "青　　山　　学　　院　　大　　学\n理　　工　　学　　研　　究　　科\n理工学専攻　　　知能情報　　　　　コース\n修　　士　　論　　文\n　　　　　　　学 生 番 号　　　　　35622202　　　　　　　　\n　　　　　　　氏 　 　 名　　　　　井村　和樹　　　　　　　\n研究指導教員　　　　ロペズ　ギヨーム　　　　 \n \n理工学専攻修士論文要旨 \n \n \n： 2024年度 \n： 2025年　1月　31日 \n専修コース：　知能情報　コース \n： 35622202 \n： 井村　和樹 \n研究指導教員： ロペズ　ギヨーム　教授 \n \n（論文題目）社会経済ニーズに応えるランニングアプリとスタンプラリー融合型運動促進システムの\n設計と社会調査に対する結果と課題 \n \n（内容の要旨） \n　健康とは、身体的、精神的、社会的に完全に良好な状態を指し、単に病気や虚弱でないことではな\nいと世界保健機関（WHO）は定義している。この定義に基づき、健康を維持するためには適切な食事、\n十分な睡眠、そして運動習慣が健康において重要である。しかし、日本では多くの人々が運動不足に\n悩んでおり、それが健康問題を引き起こす一因となっている。これらの健康リスクは個人の生活の質\nを低下させるだけでなく、医療費の増加や労働生産性の低下といった社会的コストももたらす。こう\nした背景の中で、運動不足の解消に向けた取り組みが進行しており、地方自治体や企業による健康増\n進プログラム、テクノロジーを活用した運動量の記録システムが注目されている。本研究では、運動\n不足の現状とその要因に焦点を当て、運動習慣の形成を促進するための効果的な方法を検討する。 \n　具体的にどのようなことが求められているか理解するために、社会調査を行なった結果を行なっ\nた。社会調査では20人の大学生の男女にアンケート方式で社会調査を行なった。そしてスタンプラ\nリー形式と心理的負担の関係「小さな目標が心理的負担を軽減する」と「スタンプラリー形式が心理\n的負担を軽減する」には強い正の相関（0.736）が見られた。先行研究と同様に、進捗の可視化、段階\n的な達成感、報酬感等を提供するフィードバックの仕組みは、心理的負担を軽減する効果が見込め\nる。特に運動初心者には有効で、継続率の向上に寄与する調査結果となった。一方、「長期的な運動\n目標への心理的負担軽減」と「運動経験」には弱い負の相関（-0.191）があり、経験者はスタンプラ\nリーの効果をあまり必要としないことが示唆された。運動経験者は、自身で運動に対する目標を発見\nしやすく、より高度で競技要素の強い目標設定や内発的動機を強化する仕組みが求められていること\nが考えられる。 \n今回の研究において社会調査の結果から多くの人々が運動不足に直面しつつも継続的な運動を難しいと感\nじていることが明らかになった。その主な要因として、運動の単調さや達成感の欠如、さらに運動成果が短期間\nでは見えにくいことによるモチベーション低下が挙げられる。これらの課題に対応するため、本研究では、運動\nを楽しくするためのゲーム的要素としてスタンプラリー機能を取り入れることを提案した。具体的には、以下の３\nつの革新的な要素を統合するようなアプリケーションの設計を行った。 \n●​\n目標地点を訪れることでスタンプを獲得する仕組み \n●​\n運動成果を可視化するスコアシステム \n●​\n写真撮影による達成の記録 \nこれにより、運動を楽しさや挑戦感のあるものに変え、ユーザーのモチベーションを維持しやすく\nすることが期待できる。 \n \n​\n \n青山学院大学大学院理工学研究科 \n \n \nAcademic Year of 2024, Submitted on January 31st, 2025 \n \nGraduate School of Science and Engineering, Aoyama Gakuin University \n \nTitle: Design of a running app and stamp rally-integrated exercise promotion system that \nmeets socio-economic needs and the results and challenges of social surveys \n \nStudent Name: Kazuki Imura  \nID Number: 35622202 \nDegree: Master of Engineering \nCourse: Intelligence and Information  \nThesis Advisor: Guillaume Lopez \n \nAbstract  \nThe World Health Organization (WHO) defines health as complete physical, mental, and social \nwell-being rather than merely the absence of disease or infirmity. Based on this definition, maintaining \nhealth requires an appropriate diet, sufficient sleep, and regular exercise. However, in Japan, many \npeople struggle with a lack of physical activity. These health risks lower individuals' quality of life and \nimpose social costs, such as increased medical expenses and decreased labor productivity. This study \nfocuses on the current state of insufficient physical activity and its contributing factors, aiming to \nexplore effective methods for promoting exercise habits.　 \nA social survey targeting 20 university students was conducted to understand the needs better. A \nstrong positive correlation (0.736) was observed between \"small goals reducing psychological burden\" \nand \"the stamp rally format reducing psychological burden.\" The stamp rally format, which provides a \nstep-by-step sense of achievement and reward, is expected to help reduce psychological burdens. It is \nparticularly effective for beginners, increasing the exercise adherence rate. However, a weak negative \ncorrelation (-0.191) was found between \"reduced psychological burden toward long-term exercise goals\" \nand \"exercise experience,\" suggesting that experienced individuals benefit less from stamp rallies. \nIndeed, experienced exercisers can set their own exercise goals more efficiently and may benefit more \nfrom systems that emphasize advanced and competition-driven objectives. \nThe social survey has revealed that while many people lack physical activity, they struggle to maintain \nconsistent exercise habits. The primary factors contributing to this challenge include the monotony of \nexercise, a lack of a sense of accomplishment, and decreased motivation due to the inability to see \ntangible results in the short term. To address these issues, this study proposes an exercise promotion \napplication design incorporating a gamified element—a stamp rally function—to make exercise more \nenjoyable. Specifically, the application integrates innovative elements such as a system where users earn \nstamps by visiting target locations, a scoring system that visualizes exercise achievements, and a photo \nfunction for recording accomplishments. This approach aims to sustain user motivation and encourage \nconsistent participation by transforming exercise into an engaging and goal-oriented activity. \n \n目次\n第1 章\n研究背景\n6\n1.1\n日本人の健康と運動習慣. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n6\n1.2\n日本人の運動習慣の歴史的背景\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n6\n1.3\nエンターテインメントのデジタル化. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n7\n1.4\n筋力と骨密度の向上\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n8\n1.5\n体重管理と代謝の活性\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n9\n1.6\nストレス軽減とリラクゼーション. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n10\n1.7\n気分改善と鬱症状の軽減. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n11\n1.8\n社会的繋がりの強化\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n11\n1.9\n自己効力感の向上. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n12\n1.10 ゲーミフィケーション\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n13\n第2 章\n関連研究\n15\n2.1\nフィットネスバイクの利用に対して内発的動機づけを図る仮想スタンプラリーシステムの評価. . .\n15\n2.2\n寄り道促進アプリケーションを用いたウェルビーイング向上の枠組み\n. . . . . . . . . . . . . . . .\n15\n2.3\nEﬀectiveness of Behaviorally Designed Gamiﬁcation Interventions With Social Incentives for In-\ncreasing Physical Activity Among Overweight and Obese Adults Across the United States: The\nSTEP UP Randomized Clinical Trial.\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n16\n2.4\nProfessional Esports Players: Motivation and Physical Activity Levels . . . . . . . . . . . . . . .\n16\n2.5\nThefuntheory.com\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n16\n2.6\nPiano Staircase . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n17\n2.7\nThe World’s Deepest Bin\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n18\n2.8\nBottle Bank Arcade Machine\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n18\n2.9\nThe Green Light for Green Behaviour\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n20\n2.10 運動頻度と精神的ストレスの関係. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n20\n2.11 ランニングの魅力が形成されるプロセス\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n21\n第3 章\n社会背景調査\n23\n3.1\n社会背景調査目的. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n23\n3.2\n調査対象. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n23\n3.3\n分析手法. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n24\n3.4\nランニングの頻度について. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n24\n3.5\nランニングの心理的負荷. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n25\n3.6\n性別間のランニング頻度の差. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n25\n3.7\nスタンプラリー形式の効果. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n27\n3.8\n運動経験者に対するスタンプラリーの効果. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n28\n4\n第4 章\nランニングアプリとスタンプラリー融合型運動促進システムの設計\n29\n4.1\nアプリの概要. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n29\n4.2\nスタンプラリー機能について. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n30\n4.3\nスタンプや配点の基準の設計. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n30\n4.4\nスタンプや配点の技術設計. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n30\n4.5\n社会的意義におけるスタンプラリー機能の影響と可能性. . . . . . . . . . . . . . . . . . . . . . . .\n31\n第5 章\n結論\n33\n5.1\n研究の背景と課題の明確化. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n33\n5.2\nスタンプラリー機能による運動促進の提案. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n33\n5.3\n課題. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n33\n第6 章\n今後の展望\n34\n6.1\nパーソナライズとAI 技術の統合\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n34\n6.2\nゲーミフィケーションのさらなる深化. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n35\n6.3\n地域との連携強化. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n36\n6.4\n社会的包摂を目指した機能追加\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n37\n6.5\n環境意識を高める仕組みの導入\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n37\n6.6\nクロスプラットフォーム展開と他サービスとの統合. . . . . . . . . . . . . . . . . . . . . . . . . .\n38\n6.7\n学習要素の追加. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n39\n6.8\nグローバル展開. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n40\n6.9\nデータ解析による継続的な改善\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n41\n6.10 持続可能な運用モデルの構築. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n42\n第7 章\nQ&A\n46\n5\n第1章\n研究背景\n1.1\n日本人の健康と運動習慣\n初めに健康とは何かについて、世界保健機関（WHO）憲章では、「健康とは、身体的、精神的、社会的に完全\nに良好な状態を指し、単に病気や虚弱でないことではない」と定義されている。この定義に基づけば、健康を維\n持するためには、適切な食事、十分な睡眠、そして運動習慣が重要である。しかしながら、日本においては、多\nくの人々が日常的に運動を行っておらず、これが健康問題を引き起こす一因となっている。日本生命保険相互会社\nが実施したアンケート調査によれば、運動不足の理由として「忙しくて時間がない」と回答した人が約50 パーセ\nントにのぼる。この結果は、現代の多忙な生活スタイルが運動習慣の形成を妨げていることを示唆している。ま\nた、同調査では、週に1 回以上運動している人は全体の約30 パーセントに過ぎないという結果も得られており、\n日本人の運動習慣が十分ではないことが明らかである。WHO 身体活動、座位活動ガイドライン[1] によると、健\n康維持および疾病予防のために、以下の運動が推奨されている。具体的な推奨量としては中等度の有酸素運動を週\n150～300 分、または高強度の有酸素運動を週75～150 分行うことが推奨されている。運動不足は、個人の健康に\n深刻な影響を及ぼす。例えば、運動不足は肥満、糖尿病、心血管疾患などの慢性疾患のリスクを高める。さらに、\n高齢者においては筋力低下や骨密度の減少を引き起こし、転倒や骨折のリスクが増加することが報告されている。\nこれらの健康リスクは、個人の生活の質を低下させるだけでなく、医療費の増加や労働生産性の低下といった社会\n的コストをもたらす。一方で、運動不足の解消に向けた取り組みにおいてテクノロジーの活用も注目されており\nウェアラブル端末の普及に伴い、ＰＨＲ（パーソナル・ヘルス・レコード）等のＩＣＴを活用したサービスの拡\n充など、自身の健康情報を入手・活用できる環境の整備が急速に進んでいる[2]。本研究では、日本人の運動不足\nの現状を詳細に検討し、その要因と影響を明らかにすることを目的とする。さらに、運動習慣の形成を促進する\nための効果的な介入方法についても議論する。具体的には、生活の中で手軽に実践可能な運動プログラムの設計、\nそしてテクノロジーの活用による動機付け手法の可能性を検討する。運動習慣の形成は、個人の健康を向上させ\nるだけでなく、社会全体の医療費削減や生産性向上にも寄与する。本研究の成果が、持続可能な健康政策の策定\nや実行に資することを期待する。\n1.2\n日本人の運動習慣の歴史的背景\n日本における運動習慣の変遷を理解するためには、その歴史的背景を考察することが不可欠である。近代以前\nの日本社会においては、日常生活における身体活動が不可欠な要素であった。農村部では農作業や漁業が主要な産\n業として営まれ、都市部においても徒歩や人力車が主要な移動手段として用いられていた。これらの生活様式に\nより、日常的な身体活動量は確保されており、現代における「運動不足」に相当する概念は存在していなかった。\nしかし近代化に伴い徐々に日常的な運動の機会は減少していった。そして世界的なパンデミックにより、リモート\nワークが普及し労働形態の大規模な変化が生じた。徒歩移動の機会が減少し、職業における身体活動量もさらに\n低下した。これにより、従来の生活に比べてより一層自然な身体活動は減少し、運動を意図的に取り入れる必要\n性が増加した。身体活動を必要としない生活様式が一般化した現代ではSNS やオンラインコンテンツの普及によ\nり、外出をしなくても様々な経験をすることが可能になった。こうした歴史的な生活様式の変遷は、現代の日本社\n会における運動不足の問題に直結している。労働環境の変化、生活スタイルの変容、さらにはデジタル技術の発\n展に伴う利便性の向上が、身体活動量のさらなる減少をもたらし、運動不足が健康問題として顕在化する要因と\nなっている。\n6\n1.3\nエンターテインメントのデジタル化\nさらに最新のデジタル社会では、エンターテインメントのデジタル化が身体活動量に大きな影響を及ぼしてい\nる。具体的には、Netﬂix やAmazon Prime Video などのストリーミングサービスの普及により、自宅で映画やド\nラマを長時間視聴することが一般化している。\n図1.1: Netﬂix\nまた、YouTube やTikTok のような動画共有プラットフォームの利用も急増しており、これらに費やす時間は\n大幅に増加している。これらのサービスは、時間や場所を問わずアクセス可能であるため利便性は高いが、結果的\nに座りっぱなしのライフスタイルを助長する傾向がある。加えて、ゲーム分野でも家庭用ゲーム機のPlayStation\nやXbox、PC 向けプラットフォームのSteam、さらにはスマートフォン向けの「Poke Poke」[3] や「原神」など、\n多様なゲームが提供されている。これらのゲームの多くはオンラインでのプレイを前提としており、長時間にわ\nたり座ったまま画面に集中することが一般的である。一方で、身体を動かすゲームも登場しており、「Ring Fit\nAdventure」（Nintendo Switch）や、VR を活用した「Beat Saber」などが注目を集めている。しかし、これらの\n身体活動を伴うゲームは主流とは言えず、一般的なゲームに比べて利用者数は限られている。ソーシャルメディ\nアもまた、エンターテインメントのデジタル化における主要な存在である。Instagram、Facebook、X(Twitter)\nといったプラットフォームは、人々が情報を共有し、他者とつながる場を提供している。そしてそのユーザー数\nは年々増加している。しかし、それらの使用時間が長引くほど、身体活動が制限されるという課題が浮き彫りに\nなっている。さらに、TikTok のような短い動画形式のサービスは、コンテンツの消費が容易であり、次々に新し\nい動画を視聴する「無限スクロール」の仕組みにより、時間を忘れて没入しやすい。一方で、近年注目されてい\nるメタバースの発展も、デジタルエンターテインメントにおける重要な動向である。メタバースプラットフォー\nムとして代表的なものには、Meta（旧Facebook）が提供する「Horizon Worlds」、Epic Games の「Fortnite」、\nVRChat、Roblox などがある。これらの仮想空間では、ユーザーがデジタルアバターを介して他者と交流し、会\n議、ゲーム、ショッピングなど多岐にわたる活動を行うことができる。しかし、メタバース内での活動はほとんど\nの場合、座った状態や立ったままでの最小限の動きに留まり、日常的な身体活動にはつながりにくい。メタバース\nは、職場や教育の場でも利用され始めている。例えば、「Horizon Workrooms」[?] を使用した仮想会議は、従来\nのオフィスワークをデジタル空間に移行する試みとして注目されている。また、教育分野ではRoblox が仮想空間\nを利用した学習体験を提供している。しかし、これらの利便性や創造性の向上は歓迎される一方で、身体活動の\n欠如が新たな問題として浮上している。このように、エンターテインメントのデジタル化とメタバースの発展は、\n現代社会に多くの利便性と魅力をもたらしているが、同時に身体活動不足という大きな課題を生んでいる。この\n7\n問題に対処するためには、ウェアラブルデバイスやオンラインフィットネスサービスなどを活用し、デジタル技術\nと身体活動を組み合わせた新しい取り組みが必要である。Peloton[4] のようなインタラクティブな運動プログラム\nや、身体を動かすゲームをメタバース内に取り入れる試みがその一例である。また、AR（拡張現実）技術を用い\nて日常生活に運動を組み込むアプローチも有望視されている。エンターテインメントのデジタル化は不可逆的な\n進展を遂げているが、社会全体で運動の重要性を再認識し、デジタルと身体活動の調和を目指す取り組みが求め\nられている。特に、これからの社会においては、運動不足がもたらす健康への影響を軽減しながら、デジタル技\n術を有効活用する方法を模索する必要がある。まず、教育現場では、子どもたちに運動の重要性を認識させるた\nめのデジタルツールが有効である。例えば、AR（拡張現実）やVR（仮想現実）を活用した教育用ゲームは、身\n体を動かしながら学習を行う新しいアプローチとして注目されている。これにより、運動が単なる体育の授業に\nとどまらず、日常的な習慣として定着する可能性が高まる。学校に導入されている例として、デジタルフィットネ\nスプログラム「ClassVR」や、動きながら課題を解決するインタラクティブな学習プラットフォームが挙げられ\nる。これらの取り組みを拡大することで、若年層の運動不足を解消する手段がさらに多様化するだ職場での健康維\n持を目的とした取り組みも重要である。だがこれらの取り組みは依然として実験段階である。だが企業レベルで\nはすでに実証されているものもある。テレワークが広がる中、従業員の健康を支援する企業向けデジタルツール\nが増加している。たとえば、ウェアラブルデバイスを用いて日々の歩数や運動量を可視化するプログラムや、リ\nモートワークの合間に短時間で行えるエクササイズを推奨するアプリが普及している。また、バーチャルフィット\nネスセッションやオンラインヨガクラスを取り入れることで、従業員が気軽に運動を取り入れられる環境が整い\nつつある。具体例として、企業向け健康プログラムを提供する「Wellable」や、フィットネスチャレンジを楽しむ\n「Strava」の活用が進んでいる。[5, 6] さらに、高齢者の健康をサポートするためのデジタル技術も進化している。\n例えば、家庭で簡単に使えるデジタル運動機器や、専門家とリモートでつながるオンラインリハビリプログラム\nが人気を集めている。高齢者向けには、運動不足を解消しながら転倒リスクを軽減することを目的としたプログ\nラムが重要であり、フィットネスとゲームを組み合わせた「SilverSneakers GO」や、VR を活用して身体機能を\n維持する「VirtuCare」のようなサービスが注目されている。これらの技術は、高齢者に運動の楽しさと健康維持\nの重要性を再認識させる役割を果たしている。また、社会全体で運動を促進するためには、公共スペースや地域\nコミュニティでの取り組みも欠かせない。デジタル技術を活用して、住民が参加できるバーチャルマラソンやコ\nミュニティフィットネスチャレンジが広がりを見せている。このように、デジタルと身体活動の調和を目指す取り\n組みは、個人から地域、そしてグローバルな規模まで多岐にわたる。これらの活動が広がることで、持続可能な\n健康的社会の構築が現実味を帯びてくるだろう。最終的には、デジタル技術を通じて運動を「負担」ではなく「楽\nしみ」として位置づけることが鍵となっているので、実情について調査する必要がある。\n1.4\n筋力と骨密度の向上\n筋力トレーニングは、筋肉量と骨密度の増加に重要な役割を果たす運動であり、あらゆる年齢層にとって多くの\n健康上のメリットを提供する。特に高齢者においては、筋力と骨密度の維持は転倒や骨折のリスクを軽減し、生活\nの質（Quality of Life; QOL）を向上させるために極めて重要である。筋力トレーニングは、筋肉に負荷をかける\nことで筋線維を刺激し、筋肥大（筋肉量の増加）を促進する運動である。この過程では、筋線維に微細な損傷が\n生じ、それを修復する際に筋肉がより強く成長する仕組みが働く。これにより、日常生活で必要とされる筋力が向\n上し、重い荷物を持つ、階段を上るといった基本的な活動が容易になる。また、筋力トレーニングは基礎代謝を\n向上させる効果もある。筋肉量が増えることで体内のエネルギー消費量が高まり、肥満や生活習慣病の予防にも\n寄与する。このため、筋力トレーニングは中高年層にとっても若年層にとっても有益な運動である。骨密度の維\n持と向上は、骨粗しょう症の予防において非常に重要である。骨粗しょう症は骨が脆くなる疾患で、特に閉経後\nの女性や高齢者に多く見られる。この疾患は骨折のリスクを大幅に増加させ、寝たきりや要介護状態の原因とな\nることが多い。筋力トレーニングは、骨に機械的な負荷を与えることで骨形成を促進する。骨は、負荷がかかる\nと骨細胞が活性化し、骨密度が高まるという特性を持つ。たとえば、スクワットやデッドリフトといったウェイ\nトトレーニングは、大腿骨や脊椎など、骨折リスクが高い部位の骨密度向上に効果的であることが報告されてい\n8\nる[7]。また、高強度のレジスタンストレーニング（HRT）は、骨密度を増加させるだけでなく、骨の構造そのも\nのを強化する可能性がある。高齢者における転倒は、骨折や寝たきりの主要な原因である。筋力トレーニングは、\n下肢筋力を向上させることで転倒リスクを軽減する。具体的には、大腿四頭筋や腓腹筋などの下肢筋肉が強化さ\nれることで、バランス能力が向上し、不安定な地面でも安定して歩行する能力が高まる。さらに、筋力トレーニ\nングは反射神経や柔軟性の向上にも寄与し、転倒を未然に防ぐための身体能力を強化する。転倒予防プログラム\nの一環として筋力トレーニングを取り入れることは、多くの医療機関や自治体で推奨されており、その効果が広\nく認知されている。閉経後の女性は、エストロゲン分泌の減少に伴い、急激な骨密度の低下を経験する。このた\nめ、骨粗しょう症リスクが高まる傾向がある。筋力トレーニングは、骨密度の低下を抑えるだけでなく、筋肉を\n強化することで骨にかかる負荷を適切に分散させ、骨折の予防に役立つ。加えて、筋力トレーニングは女性の姿\n勢改善にも寄与する。姿勢が良くなることで骨の配列が正しく保たれ、骨への過度なストレスを軽減できる。ま\nた、腰痛の予防や体型維持という観点でも、女性にとって筋力トレーニングは非常に効果的な運動である。中高\n年層では、加齢に伴い筋肉量と骨密度が自然に減少する。この減少はサルコペニアと呼ばれ、特に何も対策を取\nらない場合、運動能力が大幅に低下するリスクがある。このため、筋力トレーニングは中高年層にとって不可欠\nな運動といえる。中高年層向けの筋力トレーニングには、安全性を考慮した低負荷・高頻度の運動が適している。\nたとえば、自重を利用したスクワットや軽いダンベルを用いた運動は、筋肉と骨に適度な刺激を与えると同時に、\n怪我のリスクを低減する。筋力と骨密度の向上を目的としたトレーニングは、個人の健康維持だけでなく、社会\n全体の医療費削減にも寄与する可能性がある。転倒や骨折の予防に成功すれば、医療費の増加を抑制でき、介護\nに必要な社会的コストも削減できる。自治体や企業が筋力トレーニングを推奨し、普及させるための取り組みを\n行うことは、国民全体の健康水準を向上させる重要な手段である。\n1.5\n体重管理と代謝の活性\n運動は、体重管理において非常に効果的な手段とされています。定期的な運動を行うことによって、カロリー消\n費が増加し、基礎代謝が向上するため、健康的な体重を維持するのに役立ちます。カロリー消費の増加は、運動に\nよるエネルギー消費の直接的な効果だけでなく、運動後における「アフターバーン効果」として知られる現象にも\n関係している。これは運動後に筋肉が回復するためにエネルギーを消費し続ける現象であり、これにより脂肪燃焼\nが長時間継続することが期待できる。これにより、日常的な運動習慣を維持することが、長期的に見て体重管理\nにおいて重要な役割を果たす。体重管理が重要である理由は、肥満が引き起こすさまざまな健康リスクを未然に\n防ぐためである。肥満は2 型糖尿病、心臓病、脂質異常症、高血圧、そして一部のがんのリスクを増加させるこ\nとが知られている。これらの疾患は、いずれも生活習慣病の一部であり、体重の過剰な増加が直接的に関与して\nいるため、肥満を予防し適切な体重を維持することは、これらの疾患の発症リスクを低減し、全体的な健康状態\nを改善するために極めて重要である。また、体重管理をすることは、生活の質を向上させるだけでなく、老後の健\n康維持にも大きく寄与する。適切な体重を維持することにより、日常的な活動が容易になり、体力の低下を防ぎ、\n健康寿命を延ばすことが可能になる。運動は、体重を維持するために不可欠な要素であり、特に有酸素運動と筋\n力トレーニングを組み合わせた運動が推奨されている。有酸素運動（例：ジョギング、ウォーキング、サイクリン\nグ）は、脂肪を効率的に燃焼させ、エネルギー消費を高めるため非常に有効な方法である。特に、週に150 分以\n上の中強度の有酸素運動を行うことが、体重減少に寄与することが複数の研究で示されている[1]。さらに、筋力\nトレーニングは、筋肉量の維持および増加を促進することで、基礎代謝率を向上させ、運動後のエネルギー消費\nを増加させる役割を果たし、筋肉量が増えると、安静時でもエネルギー消費が高くなるため、基礎代謝の向上が\n期待できる。代謝は、体内でのエネルギーの消費と変換を指し、基礎代謝は安静時に消費されるエネルギー量を\n表している。定期的な運動は基礎代謝を向上させることが知られており、これにより脂肪がより効率的に燃焼さ\nれるようになり、筋肉の増加は脂肪と比較するとエネルギーを多く消費するため、筋肉量を増やすことが長期的\nな体重管理において重要な要素である。運動が引き起こす代謝の活性化は、運動後にも持続し脂肪燃焼が長時間\nにわたって続いていくため、高強度インターバルトレーニング（HIIT）は、短時間で高いカロリー消費を促進し、\n代謝を効率的に向上させることが示されている。このようなトレーニングは、体脂肪を減少させ、筋肉量を維持\n9\nするのに非常に有効である。体重管理において運動を実践することは、食事だけに頼るダイエットとは異なりよ\nり健康的で持続可能な方法である。食事制限による急激な体重減少は、筋肉の減少や基礎代謝の低下を引き起こ\nす可能性があり、リバウンドの原因となる。一方、運動は筋肉量を維持しながら脂肪を減少させるため、体重管理\nをより安定的に行うことができ、また運動を定期的に行うことで、食事に対する意識が改善され、過食を防ぐた\nめの自己管理能力が高まる。運動と食事のバランスをとることで、より健康的な体重を維持することができ、肥\n満による健康リスクを軽減することが可能となる。体重管理を維持するためには、運動習慣を生活の一部として\n取り入れることが重要です。定期的な運動は、カロリー消費を高めるだけでなく、心身の健康を促進する効果もあ\nります。運動によって分泌されるエンドルフィンは、ストレスの軽減や気分の向上を助け、過食の予防にもつなが\nる。さらに、運動は、心理的な側面においてもポジティブな影響を与えることが多く、ストレスや不安を軽減し、\n精神的な健康を維持するための重要な手段となる。運動は、単に体重を減少させるだけでなく、基礎代謝を向上\nさせるため、健康的な体重維持には不可欠な要素である。生活の質を高め、将来的な健康リスクを減少させるこ\nとが重要である。\n1.6\nストレス軽減とリラクゼーション\n運動は、現代社会においてストレス管理の有効な手段として広く認識されている。特に、身体活動はストレスホ\nルモンであるコルチゾールの分泌を抑制し、同時にエンドルフィンと呼ばれる気分改善物質の分泌を促進する作\n用があることが複数の研究で示されている。コルチゾールはストレス応答の一環として分泌されるホルモンであ\nり、一時的にはエネルギー供給や免疫活性化に寄与するが、長期的な過剰分泌は免疫機能の低下、睡眠障害、さら\nには心血管疾患のリスク増加をもたらす可能性が指摘されている。一方、運動を行うことでエンドルフィンが生成\nされると、脳内の快楽中枢が刺激され、自然な幸福感やリラクゼーション効果が得られる。このため、運動は身\n体的および精神的ストレスの軽減を図る上で、重要な役割を果たすといえる。有酸素運動は特にストレス軽減の\n効果が高いとされており、その一例としてウォーキング、ジョギング、サイクリング、ヨガなどが挙げられる。有\n酸素運動は心拍数を緩やかに上昇させ、血液循環を促進することにより、脳内への酸素供給を増加させる。この\n酸素供給の向上は、セロトニンやドーパミンといった神経伝達物質の分泌を促進し、気分の安定化や幸福感の向\n上に寄与することが示されている。たとえば、20 分から30 分程度の中等強度のジョギングや、自然環境の中での\nウォーキングは、ストレスを軽減し、リラクゼーション効果をもたらす有効な手段であることが報告されている。\nさらに、運動は間接的にストレス軽減を促進する要因として、睡眠の質の向上にも寄与する。複数の研究によれ\nば、定期的な身体活動は深い睡眠を誘発し、睡眠障害を緩和する効果があることが明らかにされている。良質な\n睡眠はストレス管理において不可欠であり、身体的および精神的な回復をもたらす基盤である。たとえば、夕方\nに軽い運動を行うことで、一時的な体温上昇と運動後の体温低下がリラックス効果をもたらし、自然な睡眠につ\nながる。運動によるストレス軽減効果は個人の状況に応じて異なる場合がある。長時間のデスクワークによる身\n体的な緊張や精神的な疲労を感じているオフィスワーカーにとっては、短時間のストレッチや散歩が効果的であ\nる。一方で、強いストレスや不安を抱える場合には、中等強度のランニングやグループで行う運動が、身体的なリ\nフレッシュに加えて社会的な交流機会を提供するため、さらなる効果が期待される[8]。運動の種類や強度を適切\nに選択することが、個人のストレス軽減において重要である。職場や教育機関においても、運動はストレス管理\nの手段として活用されている。いくつかの企業では、従業員の健康維持を目的に運動プログラムを導入しており、\nこれが職場の生産性や従業員満足度の向上に寄与している[9]。一方、学校では運動が生徒の集中力を高めるだけ\nでなく、心身の健康維持にも寄与している。短時間の体操やエクササイズであっても、継続的に行うことで、スト\nレス管理とパフォーマンス向上に効果があることが確認されている。最後に、運動は心理的側面にも良好な影響\nを及ぼす。身体活動を通じて達成感や自己効力感を得ることで、自尊心や自己肯定感が高まり、ストレス耐性が強\n化される。さらに、運動習慣を持つことで、自己管理能力が向上し、健康維持に対する自己のコントロール感が\n強化される。このような心理的効果は、ストレス軽減だけでなく、総合的なメンタルヘルスの向上にも寄与する。\n10\n1.7\n気分改善と鬱症状の軽減\n定期的な運動は、うつ病や不安障害の予防および改善に対して効果的であることが多くの研究によって明らか\nにされています。これらの精神的健康への影響は、身体的な変化のみならず、心理的および社会的な要因に基づく\nものであると考えられています。運動を行うことで自信や達成感が得られ、気分が向上するだけでなく、心理的ス\nトレスの軽減やポジティブな感情の増幅にも寄与します。このため、運動は心理的健康を維持し、改善するための\n重要な手段として広く認識されています。特に、運動は軽度から中等度のうつ病症状を抱える人々に対して有効で\nあり、治療法としても注目されています。米国精神医学会（APA）は、軽度から中等度のうつ症状に対する補助\n療法として運動を推奨しており、運動が従来の心理療法や薬物療法と補完的に作用する可能性があることを示し\nています。実際、研究では、定期的な運動がセロトニンやドーパミンといった神経伝達物質の分泌を促進し、これ\nが脳内の神経回路の調整に寄与することで、うつ症状を軽減する効果が確認されています。有酸素運動や筋力ト\nレーニングは特に効果が高いとされており、これらの運動は脳内のストレス応答系を調整することで、心理的ス\nトレスを軽減する働きを持ちます。有酸素運動では、心拍数の上昇に伴ってエンドルフィンが分泌され、幸福感を\nもたらすことが知られています。一方、筋力トレーニングは身体的な強さの向上を通じて自己効力感を高める効\n果があり、これが精神的健康の改善につながります。例えば、週に3 回以上、30 分から1 時間程度の運動を行う\nことで、症状の軽減が期待できるとされています。また、運動には心理的な効果だけでなく、社会的な側面におい\nてもポジティブな影響があります。例えば、グループエクササイズやスポーツ活動を通じた社会的交流は孤独感を\n軽減し、社会的支援ネットワークの形成に寄与します。これにより、孤立感や疎外感が減少し、精神的健康が向上\nすることが示されています。特に、うつ症状を抱える人々にとって、他者との交流は自己肯定感の向上や回復意欲\nの増進に寄与する重要な要因となります。運動が気分改善に寄与する具体的なメカニズムには、神経可塑性の向\n上が挙げられます。運動により脳由来神経栄養因子（BDNF）の分泌が促進されることで、神経細胞の成長や再\n生が活性化されることが知られています。これが脳内の構造的および機能的変化をもたらし、うつ症状の緩和に\nつながるとされています。特に、海馬と呼ばれる記憶や感情調整に関与する脳領域において、この効果が顕著で\nあることが研究で示されています。さらに、運動は睡眠の質を向上させることを通じても気分改善に寄与します。\n睡眠障害はうつ病や不安障害の主な症状の一つであり、運動を行うことで深い睡眠が誘発され、睡眠の質が向上\nすることで、これらの症状が緩和されると考えられています。例えば、夕方に適度な運動を行うことで体温調節\nが改善され、その結果としてリラックス効果と良質な睡眠が得られることが知られています。さらに、運動はスト\nレスホルモンであるコルチゾールの分泌を抑制することで、心理的なストレスを軽減する役割も果たします。コ\nルチゾールの過剰分泌はうつ症状を悪化させる要因となるため、その分泌を抑えることは症状の管理において重\n要です。また、運動を通じて分泌されるエンドルフィンやセロトニンは、心理的な安定感や幸福感を促進するだけ\nでなく、ストレスへの対処能力を強化する効果も持っています。運動が精神的健康に与える影響は個人差があるも\nのの、その効果を最大限に引き出すためには、適切な運動プログラムの選択が重要です。軽度のうつ症状を持つ\n人々には、ウォーキングやヨガといった低強度の運動が適している一方で、中等度の症状を抱える人々にはジョギ\nングやダンスなどの中強度の運動が推奨されます。また、運動を長期間にわたって継続することが重要であり、こ\nれが気分改善効果の維持につながります。総じて、運動は気分改善やうつ症状の軽減において多面的な効果を持\nつ有効な手段であり、その実践は精神的健康の維持と向上に不可欠であるといえます。これらの効果は、身体的、\n心理的、社会的な側面を包括的に改善することで実現されるため、運動を日常生活に取り入れることが、健康的\nなライフスタイルの基盤となります。\n1.8\n社会的繋がりの強化\nグループでの運動やスポーツ活動は、個人の社会的ネットワークを広げ、仲間との交流や協力を促進すること\nで、社会的なつながりを深める効果があり、このような活動は、単に身体的健康を向上させるだけでなく、心理的\nおよび社会的な幸福感を高める重要な役割を果たしたいる。特に、運動を通じた社会的交流は、孤独感の軽減や\nストレス管理において大きな影響を与えることが多くの研究で示されている。\n11\n社会的なつながりは、メンタルヘルスの改善において重要な要素の一つであり、運動を通じて得られる他者と\nの交流は、心理的なサポートネットワークを形成し、自己肯定感や達成感を高める効果があります。例えば、チー\nムスポーツに参加することで、共同目標の達成に向けた協力やコミュニケーションが促進され、信頼関係や友情\nが築かれることがあり、このような経験は個人の社会的な絆を強化し、精神的な安定感をもたらすことに繋がり\n精神的な安定にもつながる。運動による社会的交流は、ストレスを軽減する効果もあり、ストレスを抱えている\n人々にとって、他者とのポジティブな交流は心の支えとなり、問題を共有しやすい環境を提供する。特に、グルー\nプエクササイズやスポーツ活動では、共同体験を通じて連帯感や安心感が生まれ、これがストレス管理や精神的\n健康の改善に寄与する。また、これらの活動に参加することで、孤独感や疎外感が改善し、社会的包摂感をえる\nことができる。\n運動を通じた社会的つながりは、年齢や性別を問わず、幅広い層にメリットをもたらす。例えば、高齢者にとっ\nては、地域コミュニティで行われる体操教室やウォーキンググループが孤立を防ぎ、精神的健康を維持する手助\nけとなり、学生や若者にとっては、学校のクラブ活動や地域のスポーツチームへの参加が、社会的スキルの向上や\n友人関係の構築する。これらの活動は、異なる背景を持つ人々との交流を促進し、多様性を尊重する姿勢を育む\n機会にもなる。\nさらに、運動は職場においても社会的つながりを強化する手段として活用されています。多くの企業では、従業\n員の健康促進やチームビルディングを目的とした運動プログラムやスポーツイベントが導入されています。これ\nにより、従業員間のコミュニケーションが活発化し、職場の雰囲気が改善されるだけでなく、生産性の向上や職務\n満足度の向上にも寄与します。たとえば、ランニングクラブやヨガクラスに参加することで、部門や役職を超え\nた交流が生まれ、協力関係が強化されることがあります。\nまた、運動を通じた社会的交流は、地域社会全体にも影響を及ぼします。地域のスポーツイベントやマラソン大\n会は、地域住民が集まり、共通の目標に向かって活動する機会を提供します。これにより、地域の連帯感が強化さ\nれ、社会的な結束力が高まると同時に、地域全体の健康意識が向上します。こうしたイベントは、参加者同士の交\n流を促進するだけでなく、地域の活性化にも寄与します。\n運動による社会的つながりの効果は、心理的および社会的な側面にとどまらず、健康行動の維持にも影響を与\nえます。グループでの運動は、個人のモチベーションを高め、継続性を促進する効果があります。仲間と一緒に活\n動することで、互いに励まし合い、目標に向かって努力する意欲が湧くため、運動習慣を長期的に維持しやすく\nなります。また、他者との交流を通じて、健康に関する情報やアドバイスを共有する機会が増え、より健康的なラ\nイフスタイルを追求する動機づけが強化されます。\nこのように、運動は身体的健康を向上させるだけでなく、社会的つながりを深める手段としても重要な役割を\n果たします。個人の健康と幸福感を向上させるだけでなく、地域社会や職場全体の活性化にも寄与する運動の価値\nは、ますます注目されています。運動を日常生活に取り入れることで、社会的なつながりを強化し、精神的および\n身体的健康の両面で豊かな生活を実現することが可能となります。\n1.9\n自己効力感の向上\n運動は、身体的な健康の向上だけでなく、心理的な自己効力感を高めるうえでも重要な役割を果たします。自己\n効力感とは、自分自身の力で目標を達成できるという信念を指し、日常生活における成功や達成感に基づいて形\n成されます。運動を通じて目標を達成する経験は、自己効力感を向上させる強力な手段であり、その効果は他の生\n活領域にも良い影響を及ぼします。\n運動における目標設定とその達成は、自己効力感を高める最も直接的な方法の一つです。たとえば、5 キロの\nジョギングを完走する、筋力トレーニングで一定の回数を達成する、あるいはヨガの特定のポーズを習得するな\nど、運動における小さな目標を達成することで、自分自身の能力に対する信頼感が高まります。このような成功\n体験は、達成感をもたらすだけでなく、自分が努力すれば結果を出せるというポジティブな自己イメージを形成す\nる助けになる。さらに、運動による自己効力感の向上は、他の生活領域にも波及効果をもたらします。運動を通\nじて得られる成功体験は、仕事や学業、さらには人間関係においてもポジティブな影響を及ぼします。たとえば、\n12\n運動を通じて自分の目標を達成できたという感覚は、仕事や学業においても「挑戦を乗り越えられる」という自\n信につながり、意欲の向上や効率の改善に寄与します。また、運動による達成感は、ポジティブな自己イメージの\n構築をサポートし、精神的な安定感をもたらす。自己効力感が高まることで、人々はより積極的に健康的な行動を\n選択する傾向があり、運動により自己効力感が向上した人は、より健康的な食事を選び喫煙や過度な飲酒を控え\nるなど、健康維持に貢献する行動を志向するようになる。また、自己効力感の向上は、ストレスや困難な状況に\n対処する能力の向上にもつながり、レジリエンス（回復力）を高める効果がある。これにより、精神的な健康がさ\nらに向上し、人生全般における満足度が高まることが期待される。\n運動の成功体験は、特に長期的な目標に向けた意志力や忍耐力を養う助けにもなります。たとえば、トレーニン\nグプログラムに取り組む中で、小さな進歩を積み重ねる経験は、長期的な目標に向かって努力を継続する力を育む\nと同時に、忍耐力や計画性を強化し、このような特性は、運動以外の領域でも役立つ。仕事におけるプロジェク\nトの遂行や学業の課題への取り組みにおいても、運動で培った意志力が発揮される場合もある。\nまた、運動による自己効力感の向上は、精神的な幸福感にも寄与し、成功験を重ねることで、脳内の報酬系が\n刺激され、ドーパミンやセロトニンといった「幸福ホルモン」の分泌が促進されます。これにより、日常生活にお\nけるモチベーションが高まり、精神的な充実感が得られると同時に、ネガティブな感情を軽減する効果が期待され\nる。さらに、自己効力感が高まることで、他者とのポジティブな関係性を築く力も向上し、人間関係における満\n足感も高まる。運動はまた、自己効力感の形成において、社会的要素も重要な役割を果たす。たとえば、グループ\nでの運動やトレーニングに参加することで、他者からの励ましやフィードバックを受ける機会が増える。このよ\nうな社会的なサポートは、自己効力感を強化するうえで重要な要素とされています。たとえば、仲間と一緒に運\n動することで、目標達成に向けたモチベーションが高まり、達成感がさらに大きくなることが期待される。このよ\nうに、運動は自己効力感の向上を通じて、身体的および精神的な健康の向上に大きく貢献する。さらに、その効\n果は個人の生活全般に波及し、仕事や学業、社会生活におけるポジティブな変化をもたらす。運動を通じて得られ\nる自己効力感は、人生全般における幸福感を高め、充実した生活を実現する基盤となるものといえる。\n1.10\nゲーミフィケーション\nスマートフォンやゲーム機器の普及に伴い、ゲームの要素を他の領域に応用する「ゲーミフィケーション」が注\n目を集めています。ゲーミフィケーションとは、ゲームの特徴的な要素や仕組みを教育、医療、ビジネス、エクサ\nサイズなどの非ゲーム領域に取り入れることによって、ユーザーのシステムへの参加率や継続率を向上させる手\n法である。この手法は、ユーザーが自発的にシステムに参加したり、繰り返し利用したくなるような動機付けを\n高める効果があるため、様々な分野で積極的に活用され始めている。例えば、教育分野においては、学習管理シ\nステムにポイントやバッジを導入し、学生の学習意欲を高める取り組みが行われています。また、健康やフィット\nネス分野では、エクササイズにゲーム要素を加えることで、運動を楽しく続けられるようなシステムが多く開発\nされている。ゲーミフィケーションを用いたサービスの代表例として、Niantic, Inc. が開発した「Ingress」が挙\nげられる。Ingress は現実世界を舞台にした位置情報ゲームで、ユーザーが「エンライテンド」と「レジスタンス」\nという2 つのチームに分かれ、ポータルと呼ばれる設定された場所に移動し、陣取りを行うゲームである。この\nゲームでは、プレイヤーが実際に街中を歩き回り、指定されたポータルの場所に到達することで、ゲーム画面上に\n表示されるポータルをタップしてアイテムや経験値を取得することができ、このように位置情報を活用して現実\nの場所をゲームの舞台として利用することで、ユーザーがゲームに没入しやすくなり、同時に現実の世界を探索\nする楽しさも味わうことができる仕組みとなっている。Ingress のリリース当初、現実世界に存在するモニュメン\nトやランドマークの写真を位置情報と共にNiantic, Inc. に送信し、それがポータルとして設定されるという審査\n機能がある。この仕組みによって、ユーザーが自分の身近な施設や特別な場所のランドマークなどの情報を大量\nに提供することが可能になり、Niantic, Inc. は利用者がよく訪れる場所や観光地の詳細な位置情報と画像を、大規\n模に集めることができ、このデータの収集は後に開発される位置情報ゲームの基盤となり、同社の次のプロジェク\nト「Pok´emon GO」にも大きな影響を与えました。Niantic, Inc. はこのデータを基に、The Pok´emon Company\nInternational、Google、任天堂の3 社から3000 万ドルの融資を受け、「Pok´emon GO」の開発した。ポケモンと\n13\nいう人気キャラクターと、現実世界での位置情報を活用したゲームプレイを組み合わせたこのゲームは、リリー\nス直後から世界中で爆発的な人気を博し、ユーザーは現実世界を歩き回り、スマートフォンの画面上に出現するポ\nケモンを捕まえたり、アイテムを集めたりすることで、ポケモントレーナーとしての体験を味合うことができる\nように設計されている。このように、ゲーム要素を他分野に加えることで、ユーザーが自発的にシステムへ参加\nし、利用を継続させる仕組みを構築することが重要である。ゲームの報酬システムや競争要素、達成感を生む仕\n組みを適用することで、従来の枠を超えた新しい体験価値が生まれ、エンターテインメント性を通じて高いユー\nザー参加率を維持することができる。\n14\n第2章\n関連研究\n2.1\nフィットネスバイクの利用に対して内発的動機づけを図る仮想スタンプラ\nリーシステムの評価\n仮想スタンプラリーを取り入れることで、エクササイズバイクを使う際の内発的動機づけを高めることを目的\nとし、その利用頻度が向上するかを評価する実験が行われた。本実験では、ユーザーがフィットネスバイクを使用\nしながら仮想空間内でスタンプラリーに参加するというゲーム要素を楽しむことで、どれだけ運動への意欲や継\n続性が増加するかを確認する。以下の図に示されているのは、この提案システムの表示画面であり、ユーザーが景\n色や進行状況を確認しながら、リアルタイムでバーチャルなスタンプを集められるインターフェースとなってい\nる。実験の結果、提案システムを利用することで、エクササイズの利用時間や運動量はシステムを使用しない場\n合と比べて大幅に増加することが明らかになった。さらに、楽しさに関する評価でも、システムを使用した場合\nの得点が大幅に上昇していることが確認された。具体的には、仮想空間の景色を楽しむ要素とスタンプラリーの\n達成感が、エクササイズの満足度を高め、運動が楽しいという感覚を促進する要因として機能したと考えられる。\nこのように、提案システムは、単に運動を行うだけではなく、ユーザーが運動の過程で喜びを感じながら継続で\nきるようにする工夫がなされている。しかし、このシステムには一部のユーザーにとって課題が残る。具体的に\nは、仮想スタンプラリーを含む専用のシステムを整えるには、一定の技術的な準備が必要であり、すべてのユー\nザーがこのシステムを簡単に利用できるわけではないという点で課題が存在する。技術的なハードルや費用が発\n生するため、システムの導入や利用環境に制約があることが挙げられる。[10]\n2.2\n寄り道促進アプリケーションを用いたウェルビーイング向上の枠組み\nこの研究では、ユーザーの幸福感向上を目指し、偶然の発見と旅の要素を取り入れたアプリケーションの効果を\n分析しています。日常生活に意図的な偶然を設計することで、ユーザーが新たな体験を得て幸福感を向上させる\nことを目的としている。具体的には、アプリはユーザーが新しい場所を発見したり、未知の情報に触れたりする\n機会を提供します。このような偶然の発見が予測不能な喜びや冒険心を喚起し、精神的な充足感をもたらす。この\nアプローチは日常の単調さを解消し、心理的な「新規性」や「変化」をもたらすことでポジティブな感情を引き\n出す重要な要因になる。また、こうした偶然性に基づいたアプローチは、従来のアプリとは異なり、ユーザーが能\n動的に探索し体験を深めることを促し、これにより、アプリの長期的な使用や持続的な幸福感の向上につながる\nことを検証している。この研究では、旅や探検を通じた偶然の発見がウェルビーイングに与える効果を実証する\nために、実験やケーススタディが行われ、偶然の発見によって幸福感が増加することが確認された。これは、現\n代のテクノロジーやアプリケーションにおける新たな方向性を示すものである。この研究が示唆するように、偶\n然性を意図的に取り入れることによって、ユーザーが自発的にアプリを活用し、探検や発見を通じてポジティブ\nな感情を感じる場を提供することが、幸福感向上に有効である。[11]\n15\n2.3\nEﬀectiveness of Behaviorally Designed Gamiﬁcation Interven-\ntions With Social Incentives for Increasing Physical Activity\nAmong Overweight and Obese Adults Across the United States:\nThe STEP UP Randomized Clinical Trial.\nこの「STEP UP ランダム化臨床試験」は、アメリカ全土において過体重および肥満と診断された成人が、身体\n活動量を増加させるために行動設計を活用したゲーミフィケーション介入の有効性を検証した。この研究の目的\nは、参加者が楽しみながら健康目標に取り組むよう促進することにあり、行動科学に基づいたゲームの要素（報\n酬、レベルアップ、仲間との競争など）と、他者との関わりを活用した社会的インセンティブ（サポートや競争）\nを組み合わせて実験を行った具体的には、アメリカ国内の過体重または肥満の成人を対象にし、異なる社会的イ\nンセンティブを導入したグループに分けて介入を実施した。この介入では、参加者の身体活動量の増加と、その\n活動がどれだけ継続されるかを測定しその結果、特に他の参加者と競争や協力を行う社会的インセンティブがあ\nる場合に身体活動量の増加に有効であることが確認された。このようなゲーミフィケーションを用いた行動変容\n支援は、持続可能な健康習慣の形成に役立つ可能性が示している。[12]\n2.4\nProfessional Esports Players: Motivation and Physical Activity\nLevels\nプロのe スポーツ選手の動機や身体活動レベルについて探求されている。この研究は、e スポーツが急速に成長\nする競技分野として注目を集める中で、選手の健康やパフォーマンスに関わる要因を明らかにする目的で行われ\nた。e スポーツ選手における動機づけの多様性を分析し多くのプロ選手が、競争心、達成感、収入、名声といった\n外発的要因に強く動機づけられていることが示されている。このような動機づけの構造は、選手のパフォーマンス\nや練習習慣に直接的な影響を与えると考えられている。さらに、研究はe スポーツ選手の身体活動レベルについ\nても評価しその結果、多くの選手が比較的低い身体活動レベルにとどまっていることが明らかになった。e スポー\nツ選手の多くは、長時間の座位を伴うゲームプレイや練習セッションに従事しており、身体活動の機会が限られて\nいる傾向がある。特に、1 日の中で長時間座り続けることが、筋骨格系の問題のリスクを高める可能性があること\nが懸念されている。この結果は、e スポーツ選手が身体的な健康を維持するために、意識的に身体活動を取り入れ\nる必要性を示唆している。トレーナーやマネージャー、さらにはe スポーツ業界全体が、身体活動を推進する取\nり組みを強化する必要がある。具体的には運動プログラムを競技スケジュールに組み込むことや、身体活動の重\n要性についての教育を行うことが推奨されている。[13]\n2.5\nThefuntheory.com\n「The Fun Theory」は、行動科学とデザインの融合により、日常的な行動をポジティブに変容させるためのア\nプローチとして注目されている。この理論は、スウェーデンの自動車メーカーであるVolkswagen が2009 年に提\n案したプロジェクトから始まり、「楽しさ」を介して人々の行動をより望ましい方向へ導くことを目的としている。\n本稿では、The Fun Theory に基づくプロジェクトがどのように行動変容を促進し、社会的な課題に対処するかを\n分析する。楽しさが行動変容にどのように寄与するのか。その効果がどの程度持続可能であるか。他の行動変容\n手法と比較してどのような特異性があるかにの三つの点について重きを置いている実験である。[14]\n16\n2.6\nPiano Staircase\n2009 年、Volkswagen 社の主導による「The Fun Theory」プロジェクトの一環として、スウェーデンにおいて\n興味深い実験が実施された。この実験は、日常生活における行動変容を「楽しさ」を介して促進することを目的\nとしており、その一環としてピアノ階段（Piano Stairs）が設置された。本取り組みの背景には、現代社会におけ\nる運動不足という問題意識が存在する。特に公共交通機関や駅においてエスカレーターが階段よりも頻繁に利用\nされる現状が、身体活動量の低下を招いていることが課題として挙げられる。このような状況を受け、階段の利\n用を促進するための新たな動機付けとして、ピアノ階段が導入された。この実験では、地下鉄駅の階段にピアノ\nの鍵盤を模した装置が設置され、各段に内蔵された感圧センサーが足の動きを感知してピアノ音を鳴らす仕組み\nを採用した。さらに、階段のデザインには白と黒の鍵盤模様が施され、視覚的にも音楽的な体験を強調する仕様\nとなっている。これにより、階段の利用が単なる移動手段としての役割を超え、音楽を奏でる体験として位置付\nけられた。この取り組みの成果として、階段利用者数が66 パーセント増加したことが報告されている。この結果\nは、ピアノ階段がもたらす「楽しさ」が行動変容に寄与したことを示唆している。先行研究においても、楽しい\n体験が行動の継続性に影響を与えることが示されており、本事例はその実証例として位置付けられる。具体的に\nは、利用者は階段を利用することでピアノ音という即時的な報酬を得ることができ、それまでエスカレーターを\n選択していた利用者が自然に階段を選ぶようになった。また、こうしたユニークな体験は、ソーシャルメディア\nを通じて広く共有され、個人の体験がコミュニティ全体に影響を与える形で波及効果を生んだ。本事例の意義は\n健康促進に留まらず、公共空間の再活性化にも寄与している。通常の階段は機能的な役割にとどまる一方で、ピ\nアノ階段は利用者に新しい価値を提供する体験型の空間として機能した。このような変化により、公共施設の利\n用者体験が向上し、社会的な繋がりや環境とのポジティブな関わりが強化されることが期待される。一方で、本\n取り組みには課題も存在する。例えば、ピアノ階段の設置や維持には高いコストが伴い、感圧センサーや音響シ\nステムの定期的なメンテナンスが必要である。また、本実験が示した行動変容の効果が長期的に持続するかにつ\nいては、さらなる検証が必要である。加えて、このアプローチの汎用性についても考察が求められる。特に、文\n化的背景や社会環境が異なる地域において、同様の効果が得られるかは未検証であり、地域ごとの適応が必要と\nなる可能性がある。以上を踏まえ、ピアノ階段の事例は「楽しさ」を活用した行動変容の可能性を示す重要なモ\nデルケースである。[14]\n図2.1: The Piano Staircase\n17\n2.7\nThe World’s Deepest Bin\n「The World ’s Deepest Bin（ザ・ワールズ・ディープスト・ビン）」は、廃棄物処理における革新的なアプロー\nチとして注目されている取り組みである。本取り組みの目的は、廃棄物を捨てるという単調かつ無機質な行為を、\nより魅力的で楽しい体験に変えることにある。このような試みを通じて、廃棄物処理の重要性を強調し、社会的\nに持続可能な行動を促進することを目指している。本論文では、この取り組みがどのようにエンターテイメント\n性を組み込み、廃棄物処理に対する社会的意識をどのように変容させようとしているのかを分析する。廃棄物問\n題は地球規模で深刻化しており、その解決には個人、企業、政府の協力が不可欠である。特に、プラスチックご\nみ、食品廃棄物、電気電子機器等の適切な処理が重要であり、これらの廃棄物が適切に処理されなければ、環境汚\n染や資源の無駄遣いが進行し、地球の持続可能性に対する悪影響が生じる。しかしながら、廃棄物処理は多くの\n人々にとって退屈で面倒な作業とされており、そのため積極的な参加の動機が不足していることが多い。このよう\nな背景から、楽しさを加えることによって廃棄物処理行動を促進しようという発想が生まれた。「The World ’s\nDeepest Bin」の基本コンセプトは、文字通り「深いゴミ箱」を設置することである。このゴミ箱は物理的に深い\n構造を持ち、廃棄物を投げ入れると長い距離を落ちる音や視覚的なフィードバックを提供する仕組みが組み込ま\nれている。具体的には、投げ込んだゴミが落ちる音や、ライトの点滅などの効果があり、これによりゴミ捨ての行\n為が一種のゲームや遊びのように感じられる。これによって、日常的なゴミ捨て行動がユニークで魅力的な体験\nに変わり、参加者はその行為を楽しみながら実行できるようになる。「The World ’s Deepest Bin」が目指すの\nは、ゴミ捨てを「遊び」や「ゲーム」として捉えさせ、廃棄物処理の積極的な参加を促すことである。従来のゴ\nミ捨て行為は、手間がかかり退屈であり、多くの人々はそれを避けようとする傾向がある。しかし、視覚的および\n音響的なフィードバックを加えることによって、ゴミを「深い穴」に投げ入れる行為は楽しい体験に変わる。こ\nの視覚的・聴覚的効果が、投棄行為に対する心理的満足感を提供し、人々を積極的にゴミ箱に誘導する。「The\nWorld ’s Deepest Bin」の効果を理解するためには、行動経済学および心理学的視点が重要である。人々がより積\n極的にゴミを捨てる行動を取る背景には、「即時的な報酬」の効果が作用している。楽しさや達成感は、行動を強\n化するための重要な要素となる。行動経済学の「即時的な報酬効果」や心理学における「強化学習理論」によれ\nば、視覚的および聴覚的なフィードバックは、ゴミ捨て行為を報酬を伴う行動として認識させ、参加者をより積\n極的にゴミ捨てに導く。「The World ’s Deepest Bin」がもたらす社会的インパクトは、単なるエンターテイメ\nントにとどまらず、環境問題に対する意識の向上にも貢献する。人々がこのようなゴミ箱を利用することで、廃棄\n物処理の重要性や環境への配慮についての意識が高まると考えられる。また、この取り組みは都市空間や公共施\n設における清潔な環境作りにも寄与することが期待される。楽しさと社会的責任を組み合わせることにより、よ\nり多くの人々が積極的に廃棄物処理に参加し、持続可能な社会作りに貢献する可能性が広がる。「The World ’s\nDeepest Bin」は、廃棄物処理行動をエンターテイメントに変える新たなアプローチを提供している。このユニー\nクなアイデアは、ゴミ捨て行為自体に楽しさを加えることで、人々の行動を変容させ、環境への配慮を促進する\n可能性を秘めている。廃棄物問題の解決には、単に強制的なルールや規制を設けるだけではなく、楽しい経験を\n通じて行動を変えるアプローチが重要であることを示唆している。このような取り組みが広がることで、社会全\n体の持続可能な行動が促進され、未来により良い環境を残すための一助となることが期待される。[14]\n2.8\nBottle Bank Arcade Machine\n「Bottle Bank Arcade Machine（ボトルバンク・アーケードマシン）」は、廃棄物処理の促進において革新的で\nユニークなアプローチを提案する取り組みの一つである。本取り組みは、リサイクルのプロセスをエンターテイメ\nントと結びつけ、一般市民が積極的に参加するように仕向けることを目的としている。従来の廃棄物処理行為は\nしばしば退屈で面倒な作業とされ、参加者がリサイクルに対して十分な関心を持ちにくい。しかし、ボトルバン\nク・アーケードマシンは、リサイクル行為をゲームのように楽しさを伴う体験に変えることで、その問題に対す\nる新たな解決策を提供している。本稿では、このアプローチがどのようにリサイクル行動を促進し、廃棄物処理\nに対する社会的意識を向上させるのかを分析する。廃棄物問題は、地球規模で深刻化しており、その解決には個\n18\n人の行動だけでなく、社会全体の協力が不可欠である。リサイクルは廃棄物の減少や資源の再利用に重要な役割\nを果たすが、多くの人々にとってリサイクル行動は意識的に行うことが少ない。特に、ガラス瓶やプラスチック\n製品のリサイクルは、正しい方法で行わないと効果が薄れ、リサイクル活動が十分に行われない場合が多い。こ\nのため、リサイクルをより魅力的で楽しいものにし、人々の参加を促す方法が求められている。「Bottle Bank\nArcade Machine」は、リサイクルのプロセスをゲームの要素で包み込むことにより、従来の廃棄物処理行動を楽\nしさと即時的な報酬で強化するアイデアである。このアーケードマシンは、リサイクルする対象物（例えば、ガラ\nス瓶）を投入することで、ゲームのように得点が加算され、視覚的および聴覚的なフィードバックが得られる仕組\nみになっている。これにより、参加者はリサイクル行為を一種のゲームとして捉え、楽しさを感じながら行動を行\nうことができる。特に、得点が表示されたり、ライトが点灯する、音が鳴るなどの反応は、参加者に即時的な報酬\nを提供し、次回もリサイクル行動を積極的に取る動機づけを行う。「Bottle Bank Arcade Machine」は、リサイ\nクルを単なる義務ではなく、楽しい体験に変えることを目指している。この機械は、参加者がリサイクルを行う際\nにエンターテイメントの要素を加えることで、行動を楽しい経験に転換し、その結果としてリサイクルの効果を\n最大化しようとする。このような体験を通じて、人々はリサイクル行為を単なる手間ではなく、ゲームのような活\n動として認識し、積極的に取り組むことができるようになる。視覚的・聴覚的フィードバックは、行動の強化に\nおいて重要な役割を果たし、リサイクル行動を強化する心理的要因となる。「Bottle Bank Arcade Machine」の\n効果を理解するためには、行動経済学や心理学的な視点が必要である。特に「即時的な報酬」の効果は重要であ\nる。人々は即座に結果が得られる行動に対してより積極的に取り組む傾向があり、このアーケードマシンはその即\n時的な報酬を提供することで、リサイクル行動を強化する。行動経済学の「即時的報酬効果」や心理学における\n「強化学習理論」に基づけば、視覚的および聴覚的なフィードバックが提供されることで、リサイクル行為が報酬\nを伴う行動として強化され、より多くの人々が積極的に参加するようになる。「Bottle Bank Arcade Machine」\nの社会的インパクトは、環境問題に対する意識の向上にも貢献する可能性が高い。リサイクル行動が楽しい体験\nとして提供されることで、参加者は自らの行動が環境への貢献に繋がっていることを認識し、環境保護に対する\n意識が高まると考えられる。また、このような仕組みは、都市空間や公共施設における清潔で持続可能な環境作\nりに寄与し、社会全体の持続可能性を向上させる一助となる。「Bottle Bank Arcade Machine」は、リサイクル\n行動をエンターテイメントと結びつける新しいアプローチを提案している。このユニークなアイデアは、リサイ\nクルを行う過程を楽しさと即時的報酬で強化することで、人々の行動を変容させ、環境問題への意識を高める可\n能性を秘めている。リサイクルの促進には、単にルールや規制を強制するだけではなく、楽しい体験を通じて行\n動を変える方法が重要であることを示唆している。このような取り組みが広がることで、より多くの人々が積極\n的にリサイクルに取り組み、持続可能な社会づくりに貢献することが期待される。[14]\n19\n図2.2: The Bottle Arcade machine\n2.9\nThe Green Light for Green Behaviour\nThe Green Light for Green Behaviour は、環境に優しい行動を促進するために設計された革新的な取り組みで\nあり、環境保護活動への積極的な参加を楽しさと即時的な報酬を通じて奨励することを目的としている。本取り組\nみの主な特徴は、公共の場においてリサイクル、ゴミ拾い、エネルギーの節約などの環境に良い行動を取った人々\nに対して、「グリーンライト」が点灯する仕組みを採用することである。このシステムは、参加者に対して行動に\n対する即時的なフィードバックを提供し、その行動が社会的に評価されていることを認識させることで、環境保\n護活動への積極的な参加を促す。即時的な報酬の提供は、行動経済学における「即時報酬効果」に基づいており、\nこの報酬が参加者の行動を強化する要因となる。具体的には、ゴミを拾うとすぐに緑色のライトが点灯すること\nで、その行動が肯定的に認識され、参加者は自分の行動が社会や環境に良い影響を与えていることを実感できる。\n視覚的なフィードバックとしての緑色のライトは、参加者に対して心理的な満足感を提供し、その行動が社会的\nに評価されているという認識を与える。このような即時的な報酬が環境保護行動に対する積極的な態度を育成し、\n行動が日常的な習慣として定着することを促進する。さらに、この取り組みは、環境保護活動を単なる義務感や\n道徳的責任として捉えるのではなく、積極的で楽しさを伴う活動として認識させる点に特徴がある。楽しさと社\n会的な評価を通じて、参加者は環境に優しい行動を自己満足や社会的な承認を得る手段として捉えるようになり、\nその結果、再度その行動を取る動機づけが強化される。このアプローチは、特に公共空間や都市空間における環\n境保護活動の促進に有効であり、個々の行動が集積することで地域社会や都市全体の持続可能な発展に貢献する\n可能性が高い。したがって、The Green Light for Green Behaviour は、環境に優しい行動を積極的に促進するた\nめの効果的な手段であり、楽しさを通じて環境保護を促進する方法として非常に有望である。[14]\n2.10\n運動頻度と精神的ストレスの関係\n運動頻度と精神的ストレスの関係について、Mark Hammer らによる研究「Dose-response relationship between\nphysical activity and mental health: the Scottish Health Survey」（2009 年、British Journal of Sports Medicine）\n20\nは、運動習慣と精神的健康との間に見られる量反応関係を探求したものである。この研究は、スコットランド健康\n調査（Scottish Health Survey）のデータを基に、運動頻度と精神的ストレス症状の関連性を分析したものであり、\n重要な知見を提供している。研究の対象は、18 歳以上の成人約20,000 人で、参加者の運動頻度、運動の種類、精\n神的ストレスのレベルが評価された。精神的ストレスの評価には、一般健康質問票（GHQ-12）が用いられ、精神\n的ストレスが高いとされるスコアを基に分析が行われた。結果として、運動頻度が高い人ほど精神的ストレスが\n低い傾向が確認された。特に、適度な運動を週に2～5 回行う人々では、精神的ストレスのリスクが最も低いこと\nが示された。一方で、全く運動をしない人々や、過度に運動を行う人々では、ストレスのレベルが高まる傾向が\n観察された。これにより、運動と精神的健康の関係において「適度な運動量」の重要性が強調された。運動の種類\nに関しては、有酸素運動や筋力トレーニングといった幅広い運動が、ストレス軽減に有効であることが示されて\nおり、特定の運動形式に限定されない効果が確認された。この研究は、運動が精神的健康に与える影響を解明す\nる上で重要な示唆を提供している。特に、「量反応関係」が示されたことで、健康的な運動習慣を促進するための\nガイドラインの策定に寄与している。また、運動を取り入れたメンタルヘルス改善の戦略が、個人レベルだけで\nなく、公衆衛生政策においても重要な要素となることが示唆されている。本研究は、運動がストレス軽減に役立\nつ科学的根拠を提供し、持続可能な運動習慣の形成が、社会全体の精神的健康の向上に寄与する可能性を明確に\n示している。Mark Hamer らの研究によると、週に5 回以上運動を行う場合、精神的ストレスのリスク軽減効果\nは飽和し、さらに運動頻度を増やしても追加的なメリットは得られにくいことが示唆されている。むしろ、一部\nのケースでは過度な運動が逆効果をもたらし、ストレスレベルが再び上昇する可能性があることも指摘されてい\nる。具体的には、過度の運動は身体的疲労や筋肉痛、慢性的な炎症反応を引き起こし、これが心理的ストレスの\n増加に繋がることがあると考えられている。また、運動頻度が非常に高い人々の中には、運動そのものが義務感\nやプレッシャーに変わり、心理的な負担となる場合もある。この結果は、「適度な運動が最適である」という結論\nをさらに支持している。運動による精神的健康のメリットは、一定の頻度や強度を超えると減少し、過剰な運動\nでは潜在的なリスクが発生することを示している。そのため、週に2～5 回の適度な運動が、最も効果的にストレ\nスを軽減し、精神的健康を維持するために適している。[15]\n2.11\nランニングの魅力が形成されるプロセス\nランニングの魅力が形成されるプロセスに関する研究によると、一般市民ランナーがランニングに対して人格\n形成，達成感，忍耐・根性などの精神的な側面に資することに価値を感じていることが継続の理由のとして挙げ\nられている。また、一般的に達成感が得られないと目的意識が希薄になり、継続意欲が減退する。本研究におい\nて、ランニングの魅力形成における達成感および段階的目標の重要性が明らかにされた。調査対象者は、日常的\nにランニングを行い、ランニングに対して愛好的な態度を形成している8 名の一般市民ランナーであり、平均年\n齢は52 歳（± 10.3）であった。調査はランニング中に実施され、録音データを文字起こしして分析に用いた。分\n析には修正版グラウンデッド・セオリー・アプローチ（M-GTA）を採用し、26 の概念、5 つのサブカテゴリー、\n6 つのカテゴリーが生成された。分析結果の中で、「競争・達成の魅力」がランニングの魅力形成における主要な\n要因として抽出された。「タイムや順位を競い合える相手を設定すること」は、ランナーのモチベーションを高め\nる重要な要素である。例えば、被験者4（以下、被験者4）はマラソンランキングで49 歳時にサブスリー（3 時間\n未満）を達成し、70 位になった。この結果は、競争を通じて得られる記録や順位の向上が、自己成長の実感を伴\nい、継続的な動機付けを促進することを示唆している。また、「速さへの憧憬」や「ライバルの発見」といった概\n念も、他者との競争や記録更新がランニングの魅力形成に寄与していることを支持する。さらに、「思いがけぬ成\n功体験」は、ランニングの魅力をさらに強化する要因として重要であることが確認された。被験者1（以下、被\n験者1）は「予想外に妻のタイムを超えたことで意欲が高まった」と述べており、意外な成功体験が新たな目標設\n定を促進し、挑戦意欲を引き出すプロセスが明確に示されている。このような成功体験は、段階的な目標設定に\nよって効果的に引き出されることが明らかとなった。さらに、「ランニング履歴の活用」もランニングの魅力形成\nにおける重要な要素である。調査対象者は、練習やレースの記録を保持し、過去の成果を振り返ることで達成感\nを確認し、新たな目標を設定している。被験者7（以下、被験者7）は「過去の記録を振り返ることで、次のレー\n21\nスへの期待が高まる」と語っており、履歴管理がランナーのモチベーション維持に寄与することが示唆された。さ\nらに、「ランニングのもつゲーム性」に注目すると、自己評価基準の設定や速さへの憧れがランニングをゲーム\nのような活動に変え、目標達成や自己挑戦が魅力を高める重要な要素となっていることが明らかとなった。被験\n者2（以下、被験者2）は「仲間との練習会で、他のランナーとのペース競争が楽しみを増幅する」と述べており、\nゲーム的要素がランニングの魅力形成をさらに強化することを示している。本研究の結果、達成感や段階的な目標\n設定は、ランニングの魅力形成において中核的な役割を果たしていることが明らかとなった。このことから、ス\nタンプラリーやバッジなどの視覚的な達成の仕組みを取り入れることは、ランニングの魅力をさらに高め、持続\n的なモチベーションを強化する効果があると考えられる。以上の知見は、ランニング教育やモチベーション向上\nを目的としたプログラムの設計において重要な示唆を与えるものである。[16]\n22\n第3章\n社会背景調査\n3.1\n社会背景調査目的\n健康とは、身体的、精神的、社会的に完全に良好な状態を指し、単に病気や虚弱でないことではないと世界保\n健機関（WHO）は定義している。この定義に基づき、健康を維持するためには適切な食事、十分な睡眠、そして\n運動習慣が健康において重要である。しかし、日本では多くの人々が運動不足に悩んでおり、それが健康問題を引\nき起こす一因となっている。これらの健康リスクは個人の生活の質を低下させるだけでなく、医療費の増加や労働\n生産性の低下といった社会的コストももたらす。こうした背景の中で、運動不足の解消に向けた取り組みが進行し\nており、地方自治体や企業による健康増進プログラム、テクノロジーを活用した運動量の記録システムが注目さ\nれている。本研究では、具体的にどのようなことが求められているか理解するために、社会調査を行なった結果\nを行ない運動不足の現状とその要因に焦点を当て、運動習慣の形成を促進するための効果的な方法を検討する。\n3.2\n調査対象\n調査対象の学生20 名(男性17 名、女性2、トランスジェンダー1 名) に対して以下の質問の調査を行った。\nQuestion 1 今までに長期間の運動経験(部活やクラブ活動、数年間ランニングを自主的に行っている) は\nありますか？\nQuestion 2 あると答えた方のみ回答をお願いします。長期間の運動(部活やクラブ活動数年間ランニン\nグ) は具体的にどのようなことを行いましたか？\nQuestion 3 あなたは現状、どのくらいの頻度でランニングをしますか？\nQuestion 4 健康管理で最も難しいと感じることは以下に項目がございますでしょうか？\nQuestion 5 ランニングに対する心理的負荷はどのくらいありますか？\nQuestion 6 ランニングや運動の継続を難しく感じる要因を教えてください。（複数選択可）\nQuestion 7 ランニングのを続ける際に以下のような要素があるとモチベーションが高まると思いますか？\nQuestion 8 ランニングをする際、以下のどのような感覚が最も重要だと感じますか？（1 つ選択）\nQuestion 9 ランニングのような長期的な目標に対して、スタンプラリーのような段階的な達成感を示す\nものがあると単純にランニングをするよりも心理的な負荷は軽減するか？\nQuestion 10 小さな目標（例：1km ごとに報酬や達成感を得られる仕組み）が心理的な負担を軽減する効\n果について、どう思いますか？\nQuestion 11 距離や回数などの目標を段階的に設定し、それを達成するごとに「スタンプ」や「バッジ」\nがもらえる仕組みがあるとしたら、ランニングを続ける動機付けになりますか？\nQuestion 12 以下の2 つの状況がある場合、どちらの方が続けやすいと感じますか？1. ゴールだけが設\n定された場合（例：10km を走る）2. ゴールまでの道のりに小さな目標が設定されている場合（例：\n1km ごとにスタンプがたまる）\nQuestion 13 このようにスタンプを取得し、ランニング中に特定のものを見つけてスタンプを取得する形\nだと特に目的なく１キロ走るのに比べて継続はしやすいですか？\nQuestion 14 あなたは以下のどの形式が最もモチベーションにつながると感じますか？\nQuestion 15 デジタルバッジやランキング表示によって、モチベーションは改善しますか？\n23\nQuestion 16 自己管理アプリでの記録（例：距離、時間、消費カロリー）などによって、ランニングに対\nするモチベーションは改善しますか？\nQuestion 17 スタンプラリー形式での要素の追加により、ランニングの心理的負荷は減少しましたか？\n3.3\n分析手法\nラベルエンコーディングを用い、上記の調査に対してピアソンの相関係数を用いて、相関分析を行なった。\nr =\n∑n\ni=1(xi −¯x)(yi −¯y)\n√∑n\ni=1(xi −¯x)2 ∑n\ni=1(yi −¯y)2\n• xi, yi はデータポイントの値\n• ¯x, ¯y はそれぞれの平均値\n• n はデータポイントの総数\n3.4\nランニングの頻度について\n調査結果によれば、最も多く挙げられた要因は「モチベーションが維持できない」であり、全体の約32 パーセ\nントを占めている。この結果は、運動継続の鍵となる心理的要因の重要性を示しており、運動を習慣化するため\nには、外部および内部からの動機付けが必要不可欠であることを示唆している。特に、短期的な目標設定や達成\n感を得られる仕組みを導入することが、モチベーションの向上に寄与すると考えられる。次に、「目標が漠然とし\nている」という回答が全体の約27 パーセントを占め、明確な目標設定の欠如が運動の継続を妨げる要因となって\nいることが示された。具体的かつ達成可能な目標の設定が、運動を継続するために重要であることは先行研究で\nも指摘されており具体的には「週に3 回、1km を走る」といった小さな目標を段階的に設定することが推奨され\nる。また、目標を細分化し、達成感を頻繁に得られるような工夫を施すことで、モチベーションを維持しやすく\nなる。一方、「身体的な負担や疲労」を挙げた回答も約14 パーセントを占め、運動計画が適切でないことが心理\n的および身体的な抵抗感を生む要因となっていることが明らかとなった。特に、初心者や長期間運動から離れて\nいた人々にとっては、負荷が過剰である場合に運動を継続する意欲が削がれる可能性が高い。そのため、初心者\n向けの軽負荷トレーニングプログラムを提供し、疲労感を軽減するためのストレッチやリカバリー情報を併せて\n提示することが効果的である。また、「長期的な達成が見えにくい」という回答も約9 パーセントを占め、運動の\n効果が即時に感じられないことが継続性の妨げとなっている可能性が示唆された。この課題に対応するためには、\n短期的な成果を可視化する仕組みが有効である。例えば、ランニングの距離や消費カロリーを記録し、進捗を可視\n化することで達成感を与えると同時に、運動を継続する意欲を促進することができる。さらに、調査では「ジム\nで走ることが多い」「その他」といった回答も見られ、特定の環境や個別の事情が運動の継続に影響を及ぼしてい\nる。これらの課題に対応するためには、各個人のライフスタイルに合わせた柔軟な運動プログラムを提案し、オ\nンラインフィットネスや自宅トレーニングなど、より多様な運動の選択肢を提供することが求められる。以上の結\n果を踏まえ、以下のような施策が有効であると考えられる。第一に、モチベーション維持を支援する仕組みとし\nて、達成感を促進するスタンプラリーやバッジの獲得機能を運動プログラムに組み込むことが挙げられる。これ\nにより、運動をゲームのように楽しむ要素が加わり、参加者の意欲が高まると期待される。第二に、他者と進捗を\n比較できるランキング機能やコミュニティ要素をアプリケーションに導入することで、他者との競争や協力を通\nじて継続意欲を高めることができる。第三に、具体的な目標設定を支援するプランニング機能を提供し、目標達\n成後には具体的な報酬や進捗記録を視覚化する仕組みを導入することが効果的である。これにより、運動の成果\nが確認しやすくなり、長期的な継続意欲を支援できる。さらに、初心者向けの軽負荷トレーニングプログラムを\n提供するだけでなく、個別の障壁に対応するためにカスタマイズ可能な運動プランの提案を強化することも重要\nである。オンラインフィットネスやモバイルアプリの活用によって、ユーザーが場所や時間を選ばずに運動を継続\n24\nできる環境を整えることが可能となる。これらの施策を総合的に実施することで、ランニングや運動の継続を難\nしくしている要因を緩和し、健康習慣の形成を促進することが期待される。\n3.5\nランニングの心理的負荷\nアンケートの回答者に75 パーセントが長期間の運動経験があるのにも関わらず、60 パーセントの人々がラン\nニングに対して心理的負荷を感じていることが明らかになった。この結果は、運動経験がランニングへの抵抗感\nの解消に直結しないことを示唆している。心理的負荷を感じる要因として、運動種目の違いや個々の体験が挙げ\nられる。例えば、筋力トレーニングやスポーツ競技を主に行ってきた人にとって、ランニングは異なる身体的要\n求やスキルを伴うため、心理的な抵抗感を生む可能性が高い。また、ランニングが単調な運動と認識されること\nが多く、精神的な疲労感や継続の難しさが心理的負荷を増大させる要因となっている。さらに、運動経験者の中\nには高い目標や自己期待を持つ人が多く、自身のパフォーマンスを他者や過去の自分と比較してしまう傾向があ\nる。その結果、達成できなかった際に生じる否定的な感情が心理的なプレッシャーとして現れることが考えられ\nる。また、ランニングは個人で行うことが多く、孤独感や自己責任の意識が強まる傾向があるため、モチベーショ\nンを維持するための外部要因が不足しやすい。特にグループスポーツ経験が豊富な人々にとって、この孤独感は大\nきな障壁となる。これらの要因を軽減するためには、対策が必要である。達成感を増幅する仕組みとして、短期\n的な目標設定や成果の可視化が有効である。例えば、ランニングアプリを活用して距離や時間を記録し、目標達\n成を視覚的にフィードバックすることは心理的負荷をポジティブな感情に変える助けとなる。また、ランニング\nの楽しさを増幅する要素を追加することも重要である。スタンプラリー形式の目標達成システムや地元観光地を\n巡るランニングイベントなどを導入することで、単なる運動からアクティビティとしての要素を持たせることが\nできる。さらに、グループランニングイベントの促進やコミュニティ形成により、ランニングの孤独感を軽減し、\n社会的な支援を強化することが可能である。初心者や心理的負荷を感じている経験者に向けた個人にカスタマイ\nズされたプログラムの提供も効果的である。例えば、初心者にはウォーキングとランニングを組み合わせたプロ\nグラムを提案し、経験者にはインターバルトレーニングや記録更新を目指したチャレンジ形式のプログラムを提\n供することが有効である。またテクノロジーの活用も心理的負荷の軽減に寄与する。ウェアラブルデバイスやス\nマートフォンアプリを活用してデータの視覚化や音声フィードバックでの励ましやアドバイスを提供する機能は\nモチベーションを維持する上で有用である。ゲーミフィケーションを取り入れたアプリケーションも有効であり、\nランニング距離やタイムに応じたポイント獲得や実社会でも使用可能な報酬を得られる仕組みを導入することで、\n心理的負担をゲーム感覚で乗り越えることができる。教育的アプローチも重要であり、ランニングに関する正し\nい知識や技術を提供することで心理的負荷を軽減することが可能である。適切なフォームやペース配分、疲労回\n復の方法を学べる機会を提供することで、運動に対する抵抗感が低減され、よりポジティブな取り組みが促進さ\nれる。これらの取り組みは、心理的負荷を軽減し、運動経験者がランニングをより魅力的に感じ、継続的に取り\n組むための鍵となる。心理的負荷の背景には個々の体験や特性が影響しているため、多角的なアプローチが求め\nられる。本考察を基に、ランニングの魅力を再発見し、運動の習慣化を支援する施策がさらなる発展を遂げるこ\nとが期待される。\n3.6\n性別間のランニング頻度の差\n性別とランニング頻度の負の相関（-0.568）が、性別がランニング頻度に影響を与えている可能性を示唆してい\nる。この負の相関は、例えば男性が女性よりも頻繁にランニングを行う傾向がある、または逆に女性がランニン\nグを頻繁に行う傾向がある。性別がランニング頻度に与える影響は多方面に及ぶ。まず、性別による運動への動\n機や目的の違いがランニング頻度の差に関連していることが確認されている。男性は競争や成果を重視する傾向\nがあり、ランニングのような自己記録の更新やパフォーマンス向上を目指す運動を選択する割合が高い。一方、女\n性は健康維持やストレス軽減などの内発的な要因を重視し、これがランニング以外の運動選択につながる場合が\n25\nある。さらに、時間的余裕やライフスタイルの違いが性別ごとのランニング頻度に影響を及ぼしている。運動に\n充てる時間を制約する要因となっている。男性は仕事中心のライフスタイルを持ちつつも、運動のための時間を\n確保する意識が強く、これがランニング頻度の違いとして現れている。社会的・文化的要因もランニング頻度に\nおける性差を説明する重要な要素である。女性はランニングを行う際に、安全性の懸念を感じやすい。夜間のラ\nンニングや人通りの少ない場所での運動は、特に女性にとって心理的な障壁となりやすい。一方で、男性はこう\nした環境要因をあまり気にせず、ランニングの実行に積極的である場合が多い。心理的な負担や運動に対する魅\n力の感じ方も性別によって異なることが指摘されている。女性は達成感や仲間との共有といった外発的な要因を\n重視する傾向があり、これに応じた仕組みがない場合、ランニングに対する意欲が低下する可能性が高い。一方、\n男性は自己記録の更新や目標達成といった内発的要因を重視するため、ランニングの頻度が高くなる。身体的な\n特徴の違いも、ランニング頻度に影響を与える重要な要因である。男性は一般的に筋力や体力が高い傾向があり、\nこれが持久力を必要とするランニングの楽しさや実行可能性を高めている。女性はホルモンや身体構造の違いか\nら、長距離ランニングに対して心理的・身体的な負担を感じやすく、これがランニング頻度の低下につながる。運\n動に関連する社会的支援やコミュニティの存在も性別による違いを示す重要な要因である。男性はスポーツクラ\nブやランニングイベントへの参加機会が多い一方で、女性はこうした環境に心理的抵抗を感じる場合がある。特\nに、男性が中心となるランニングコミュニティでは、女性が孤立感や不安を抱くことが多く、これがランニング\n頻度の低下に寄与している。これらの分析結果を踏まえ、性別によるランニング頻度の違いを解消するためには、\n性別に応じた対策が必要である。女性には、安全なランニング環境の整備や女性専用ランニングイベントの開催\nが有効であり、心理的抵抗を軽減するための初心者向けプログラムの導入が求められる。また、女性がランニン\nグを継続しやすくするために、社会的支援を強化し、コミュニティの構築を進める必要がある。一方、男性には\n競争心を高める仕組みや自己記録を簡単に管理できるデジタルツールの提供が効果的である。こうした仕組みは、\n男性の内発的動機をさらに強化し、ランニング頻度を維持するための支援となる。これらの施策を通じて、性別\nによるランニング頻度の差を縮小し、より多くの人々がランニングを楽しみながら健康を促進できる環境を構築\nすることが可能である。性別に応じた運動プログラムや政策の導入は、個々のニーズに対応するだけでなく、社会\n全体の健康促進に寄与する重要な手段である。この研究結果は、ランニングを含む運動習慣を向上させるための\n新たなアプローチを提供し、性別による課題を克服するための基盤となる。まず、性別による運動動機や目的の\n違いがランニング頻度に顕著に影響を及ぼしていることが確認された。男性は競争や成果の追求に基づく内発的\n動機が強く、自己記録の更新やパフォーマンス向上を目的とした運動（特にランニング）に積極的である。一方、\n女性は健康維持やストレス軽減といった内発的動機を重視するため、運動の種類が多様化し、ランニング以外の選\n択肢に目を向ける傾向がある。この違いは、性別ごとに異なる運動の魅力や目的意識がランニング頻度に影響を与\nえていることを示している。また、時間的余裕やライフスタイルの差異も、性別間のランニング頻度の違いを裏\n付ける重要な要素である。女性は家事や育児の負担がランニングの時間確保を妨げる一方で、男性は職場中心の\nライフスタイルの中でも、運動時間を優先的に確保する傾向が見られる。これにより、女性の運動時間の不足が\nランニング頻度の低下に直接的な影響を及ぼしている。さらに、社会的および文化的要因が性別によるランニン\nグ頻度に影響を及ぼしていることも証明される。女性が安全性の懸念や心理的な障壁を感じやすいことが、ラン\nニング頻度の低下につながっている。一方で、男性は安全性をさほど気にせず、積極的にランニングを行う傾向が\n強い。このような性別特有の社会的背景がランニング習慣における性差を助長している。心理的要因として、男\n性と女性ではランニングに対する魅力や動機の感じ方が異なり、これがランニング頻度に影響を与えていること\nも示唆される。男性は自己記録の更新や目標達成を重視し、それが継続的なランニング頻度に繋がる。一方、女\n性は達成感や他者との共有を重視するため、ランニングを継続するための仕組みが不足している場合、頻度が低\n下しやすいことが証明された。最後に、性別に応じた具体的な対策の有効性が示された。女性に対しては安全な\nランニング環境や初心者向けプログラム、女性専用のイベントを提供することで心理的抵抗を軽減し、ランニン\nグの習慣化を促進できる。一方、男性には競争心を高める仕組みや自己記録管理ツールの提供が有効であり、こ\nれがモチベーション維持とランニング頻度向上に寄与することが示唆される。これらの研究および考察結果から、\n性別に応じた運動プログラムの導入が性別間の運動頻度の差を縮小し、社会全体の健康促進に貢献する有効な手\n段であることが明確に証明された。このアプローチは、性別固有のニーズに応じた支援が、個人の運動習慣の形\n26\n成を促進し、健康的なライフスタイルの実現に寄与することを強く示唆している。\n3.7\nスタンプラリー形式の効果\n「小さな目標が心理的負担を軽減する効果」と「スタンプラリー形式での要素の追加により心理的負担が減少し\nましたか？」の間に見られた強い正の相関（0.736）は、スタンプラリー形式が小さな目標設定を通じて心理的負\n担軽減に大きな影響を与えていることを示している。この強い正の相関は、スタンプラリー形式の特性が小さな\n目標を提示し、それを達成することで得られる達成感が心理的負担を軽減するメカニズムと深く結びついている\nことを表している。正の相関の意味について考察すると、正の相関が強い（0.736）という数値は、「小さな目標が\n心理的負担を軽減する」と感じる人ほど、「スタンプラリー形式が心理的負担を軽減する」とも感じる可能性が高\nいことを示している。この関係性は、両者が同じ心理的効果をもたらすプロセスを共有していることを示唆して\nいる。具体的には、スタンプラリー形式が視覚的進捗管理や段階的な達成感、報酬感を通じて心理的負担を軽減\nする仕組みが、同時に小さな目標設定による心理的なハードル低減効果と一致している。スタンプラリー形式は、\n「目に見える形で達成感を得られる仕組み」を提供する特徴がある。視覚的な進捗管理によって目標達成の過程が\n明確になり、各ステージの達成やスタンプの獲得が分かりやすくなる。これにより、目標達成の進捗がユーザーに\n明示され、達成感が得られる頻度が高まる。次に、段階的な達成感の提供が挙げられる。1 回の運動の中で大きな\n成果を目指すのではなく、複数の小さな目標を設定し、達成することで頻繁に達成感を味わえる仕組みが心理的\n負担を軽減する。また、スタンプの獲得そのものが心理的な報酬となり、次の目標に向かうモチベーションを高\nめる。このように、スタンプラリー形式は、小さな目標を段階的に提示し、大きな目標に圧倒されることなく運\n動を継続できるようにする効果がある。さらに、この相関が示す心理的負担軽減のメカニズムについて考えると、\nいくつかの要素が挙げられる。まず、目標の具体化と達成感が心理的負担軽減に寄与している。大きな目標より\nも小さな目標のほうが達成が容易であり、達成感を得る頻度が増えるため、運動に対するポジティブなフィード\nバックが強化される。また、過負荷の回避も重要な要素である。一度に大きな目標を設定するのではなく、小さな\n目標を分割して提示することで、運動の負荷や精神的ストレスを軽減し、運動に対する心理的抵抗を減らす。さ\nらに、自信の向上も見逃せないポイントである。小さな目標を達成する過程で自己効力感が高まり、運動を続け\nることへの自信が形成される。これらの要因が組み合わさることで、スタンプラリー形式が心理的負担を軽減す\nる効果が高まっている。スタンプラリー形式の利点について、この仕組みは特に心理的課題を抱える人々にとっ\nて有効である。運動初心者にとって、大きな目標を達成することは心理的負担が大きいため、小さな目標を提示\nするスタンプラリー形式が特に効果的である。また、心理的ハードルの高い人々に対しては、運動に対する抵抗\n感や挫折感を低減し、小さな目標をクリアすることで運動に前向きになれる環境を提供する。さらに、長期的に\n運動を継続したい人々にとっては、スタンプラリー形式によって短期的な達成感を得ながら、最終的には大きな\n目標に到達するためのモチベーション維持に寄与する。実践への示唆として、この相関を基にスタンプラリー形\n式の要素を運動プログラムに取り入れることは、運動初心者への導入や継続性の向上に役立つ可能性がある。初\n心者が運動を楽しみながら取り組むきっかけとして、スタンプラリー形式が有効であり、短期的な目標を設定し、\n達成感を得られる仕組みを提供することで、運動の継続率を向上させる効果が期待される。また、視覚的なスタ\nンプやポイントの形で達成感を示すことで、心理的満足度を高め、運動への前向きな姿勢を促すことが可能であ\nる。さらに、この相関関係が示す効果をさらに活用するためには、個別化された目標設定が必要である。個々人\nの運動レベルや心理的ニーズに応じてスタンプラリー形式の目標をカスタマイズすることや、スマートフォンア\nプリやウェアラブルデバイスを通じてリアルタイムで進捗を確認できる仕組みを整備することが求められる。ま\nた、スタンプラリー形式の効果が長期的にどの程度継続するかを検証し、プログラムを改良していくことも重要\nである。このように、「小さな目標が心理的負担を軽減する効果」と「スタンプラリー形式が心理的負担を軽減す\nる効果」の間の強い正の相関は、両者が運動継続における心理的負担軽減に密接に関連していることを示してい\nる。この結果は、スタンプラリー形式が小さな目標を提示することで心理的負担を効果的に軽減できることを強\nく支持しており、これを運動プログラムに取り入れることで、幅広い人々が運動を楽しみながら継続できる環境を\n27\n提供することが可能である。このような取り組みは、心理的負担を軽減し、運動の継続性を向上させるだけでな\nく、健康促進を目指す社会全体の取り組みとしても重要である。\n3.8\n運動経験者に対するスタンプラリーの効果\nランニングのような長期的な目標に対して、スタンプラリーのような段階的な達成感を示す仕組みがある場合、\n単純にランニングを行うよりも心理的負荷が軽減するかという問いと、今までに長期間の運動経験があるかどう\nかの間に相関係数-0.191 が得られた。この値は弱い負の相関を示しており、運動経験が豊富な人ほどスタンプラ\nリーによる心理的負荷軽減効果がわずかに小さい傾向があることを意味しているが、その影響は限定的である。こ\nの結果からは、運動経験の有無がスタンプラリーの効果に完全には決定的でないことを示唆している。運動経験が\n豊富な人は、既に長期目標達成における動機付けや心理的耐性を持っている可能性が高く、スタンプラリーのよう\nな仕組みをそれほど必要としない場合がある。一方で、運動経験が浅い人や初心者にとっては、スタンプラリー\nによる達成感の可視化がモチベーションの維持や心理的負荷軽減により大きく寄与している可能性がある。また、\n動機付けの種類がこの相関に影響している可能性も考えられる。運動経験が長い人は、内発的動機付け、つまり\n運動そのものの楽しさや自己の成長に価値を見出している可能性が高い。この場合、スタンプラリーなどの外発\n的動機付けの要素は心理的負荷の軽減にはあまり寄与しない。一方、運動経験が少ない人は、外発的動機付け、つ\nまり報酬や可視化された進捗に依存しやすい傾向があるため、スタンプラリーが大きな効果をもたらす可能性が\nある。このことから、運動経験が異なる集団では、それぞれに適したモチベーション設計が必要であると考えら\nれる。さらに、この相関が弱い理由として、スタンプラリーによる心理的負荷軽減が運動経験以外の要因にも強\nく依存している可能性がある。例えば、個々の性格、モチベーションの種類、目標設定の難易度、ランニングを\n行う環境、さらにはスタンプラリーのデザイン自体が心理的負荷の軽減に影響を与える可能性がある。特に運動\nの目的が健康維持やストレス解消といった内発的な要因である場合には、外発的な仕組みの効果が薄れる傾向が\nあるかもしれない。また、運動初心者には、段階的に進捗を示す仕組みが有効であるが、経験者にはより高度な\n目標が動機付けに繋がる場合がある。このような観点から、個人の運動経験に応じて、心理的負荷を軽減しモチ\nベーションを維持するための方法が異なることが示唆される。このように、相関係数-0.191 は、運動経験が心理的\n負荷軽減に一定の影響を与えることを示唆しているものの、その影響は限定的である。この結果から、スタンプ\nラリーのような仕組みは特に運動初心者や経験の浅い人々にとって効果的であり、経験者に対してはより内発的動\n機付けを強化する仕組みが必要であると考えられる。心理的負荷の軽減とモチベーションの向上を最大化するた\nめには、運動経験や個人の動機付けスタイルに応じた柔軟な設計が重要である。この研究結果は、長期目標を持\nつ運動プログラムの設計において、経験別に異なるアプローチを導入する必要性を示している。\n28\n第4章\nランニングアプリとスタンプラリー融合型運\n動促進システムの設計\n現代社会において、健康促進と持続可能な運動習慣の形成は重要な課題である。ランニングアプリとスタンプ\nラリー融合型運動促進システムでは、ランニングやウォーキングといった運動を楽しく、継続しやすくするためと\nいう課題を解決するためにゲーミフィケーションを取り入れたアプリケーションを開発を目指している。このア\nプリは、スコアシステムやスタンプラリー機能、写真撮影を活用したインタラクティブな仕組みを通じて、運動\nの楽しさと達成感を提供するものである。本稿では、このアプリケーションの機能、技術的背景、実用性および\n社会的意義について詳細に論じる。\n図4.1: FootJourney\n4.1\nアプリの概要\n本アプリは、ユーザーがランニングまたはウォーキングを行いながら、リアルタイムでスコアを獲得し、スタ\nンプラリー形式で目標を達成することを目指して設計された。主要な機能には、タイマー機能、スコア計算、目\n標地点への訪問達成を示すスタンプ機能、写真撮影機能、アクティビティ終了ボタンが含まれる。タイマー機能\nは、設定された運動時間をカウントダウン形式で表示するものであり、ユーザーが時間内で目標を達成するため\nのモチベーションを高める役割を果たす。スコア計算機能は、移動距離に基づく「距離スコア」と、目標地点で撮\n影された写真に基づく「写真スコア」を合算して「合計スコア」を表示する。これにより、ユーザーは単なる運動\n量だけでなく、目標達成の進捗状況を定量的に把握できる。スタンプラリー機能では、画面に表示されたアイコ\nン（例: 建物、自転車、木など）が目標地点を示し、それぞれの目標達成でスタンプを獲得できる。目標の達成度\nは視覚的にわかりやすく表現され、運動の楽しさが増幅される。さらに、写真撮影機能により、ユーザーは目標地\n29\n点での活動を記録することができる。この写真がアプリにおける目標達成の判定基準としても活用される。最後\nに、アクティビティ終了ボタンを押すことで、運動セッションを任意のタイミングで終了できる設計とした。\n4.2\nスタンプラリー機能について\nスタンプラリー機能におけるスタンプや配点の基準は、ユーザー体験を向上させる重要な要素であり、適切な\n達成感や挑戦感を提供するための基盤となる。本研究では、特に時間制限や条件付き達成要素を組み込むことで、\n配点基準を最適化し、ゲーム性と健康促進を融合した運動支援アプリケーションの開発を目指している。この機\n能を実現するためには、難易度、移動距離、時間や環境条件、対象物の種類、ユーザーの行動履歴、および個別\nのインタラクション要素を考慮し、それぞれに基づいた配点基準を設定することが重要である。さらに、これら\nの要素を支える実装技術として、リアルタイムデータの処理、画像認識技術、位置情報の取得と管理、動的難易\n度調整（Dynamic Diﬃculty Adjustment, DDA）の導入が不可欠である。\n4.3\nスタンプや配点の基準の設計\nスタンプラリー機能では、達成すべき目標地点や対象物に対して適切な難易度と配点を設定する必要があるた\nめ、動的難易度調整（Dynamic Diﬃculty Adjustment, DDA) を踏まえて難易度に基づく配点、移動距離に基づ\nく配点、時間や条件を考慮した配点、対象物の種類に応じた配点の4 つの基準が考慮されるべきである。難易度\nに基づく配点は対象物の見つけやすさや撮影の難易度に応じて配点を調整する。簡単に見つけられる対象（例: 公\n園の木、建物）には10～30 点を割り当てる一方、難易度の高い対象（例: 稀少な動植物、特定のランドマーク）\nには100 点以上を設定する。この仕組みにより、初心者は手軽に達成感を得られる一方で、上級者には挑戦感を\n提供することが可能となる。移動距離に基づく配点は具体的に目標地点までの移動距離を考慮し、短距離（例: 家\nの近く）には10～20 点、中距離（例: 隣町の公園）には50～70 点、長距離（例: 観光名所）には100 点以上を\n設定する。これにより、運動量を増やす動機付けを強化できる。時間や条件を考慮した配点は特定の時間帯や気\n象条件で達成可能な目標には、特別なポイントを設定する。例えば、夕方の景色を撮影する場合には80～120 点、\n雨の日の虹や雪景色には100～150 点を付与する。このように条件付き要素を取り入れることで、達成時の特別感\nをユーザーに提供する。対象物の種類に応じた配点は具体的に自然物（例: 木や花）には10～50 点、生き物（例:\n犬、猫）には50～80 点、人工物（例: 建物、モニュメント）には30～100 点、地域固有の対象（例: 名物や店舗）\nには100～150 点を設定する。これにより、ユーザーは対象物に応じた多様な挑戦をすることができる。\n4.4\nスタンプや配点の技術設計\n写真撮影機能とスタンプ獲得機能を実現するためには、さまざまな技術が統合されており、それぞれが異なる\n役割を果たしている。まず、ML Kit による画像解析技術が、このシステムの中心的な役割を担っている。Google\nが提供する機械学習ライブラリであるML Kit は、ユーザーが撮影した写真に含まれるオブジェクトやランドマー\nクを高精度で認識する。本機能では特に、ML Kit のImage Labeling 機能が活用され、画像内の特徴点が抽出さ\nれる。この特徴点は、アプリに事前に登録された目標地点のデータと比較される。登録されたデータは、目標地\n点に対応する特徴的なビジュアル要素を学習しており、これにより、ユーザーが目標地点を訪れたかどうかを判定\nすることが可能になる。例えば、特定の建物、モニュメント、または自然のランドマークが目標地点として設定\nされている場合、その写真内の具体的な形状、色、模様などが一致しているかを確認する。この比較プロセスは\nバックエンドでリアルタイムに実行され、成功すると即座にスタンプが付与される仕組みとなっている。このよ\nうな高精度な画像解析は、ユーザーがアプリケーションを通じて得る体験の信頼性と公平性を保つ上で極めて重\n要である。次に、Fused Location Provider を活用したGPS データとの統合について述べる。この技術は、ユー\nザーの現在地を特定し、目標地点に近づいたときに写真撮影を有効化する仕組みを提供している。Fused Location\n30\nProvider は、GPS、Wi-Fi、モバイルネットワークのデータを統合することで、高精度な位置情報を効率的に提\n供する技術である。他の場所で撮影した写真を不正に使用してスタンプを獲得する際は画像認証によって一致し\nない場合は失敗のスタンプの身を獲得することにより不正にスタンプを取得することを防ぐことができる。また、\nJetpack Compose を活用したユーザーインターフェース（UI）の設計も、本システムにおいて重要な要素である。\nJetpack Compose は、Android アプリ開発のための宣言的なUI ツールキットであり、簡潔かつ直感的なコードで\n高品質なデザインを実現することができる。このアプリでは、Jetpack Compose を利用して、写真撮影ボタンや\nスタンプ獲得後のアニメーション、進捗状況を表示するインターフェースを設計している。例えば、ユーザーが目\n標地点に到達し写真を撮影した後、獲得したスタンプが画面にポップアップ表示されるようなアニメーションが\n実装されている。この視覚的なフィードバックは、ユーザーに達成感を与えるだけでなく、次の目標に向けたモチ\nベーションを喚起する役割を果たしている。さらに、スタンプの獲得状況を一覧表示する機能も搭載されており、\nユーザーが訪れた地点や残りの目標を一目で確認できる。この一覧はリアルタイムで動的に更新され、アプリ内\nでユーザーが進捗を常に把握できる仕組みとなっている。データの保存にはRoom ライブラリが使用されており、\nこれによりスタンプや写真データがローカルデータベースに効率的に保存される。Room は、SQLite データベー\nスを抽象化するためのライブラリであり、型安全で信頼性の高いデータ操作を可能にする。本アプリでは、ユー\nザーが獲得したスタンプや撮影した写真、目標地点の達成履歴などをRoom を利用して管理している。これによ\nり、アプリが再起動された場合でも、ユーザーの進捗データは保持され、アプリケーションの利用体験が損なわれ\nることがない。また、過去の記録を参照する機能も提供されており、ユーザーはこれまでの成果を振り返ること\nができる。例としてはどの目標地点をいつ達成したのか、このような記録は、ユーザーが運動の成果を定量的に\n把握する手段として有効であると同時に次の目標設定に向けた参考情報としても活用される。さらにこれらの技\n術が統合されることで、アプリ全体の一貫性が保たれ、ユーザー体験が向上する。ML Kit による画像解析結果と\nFused Location Provider による位置データが同期して動作することで、目標地点の達成判定が正確かつ迅速に行\nわれる。また、Jetpack Compose を使用したUI が、これらのバックエンドの動作をシームレスにユーザーに伝え\nる役割を果たしている。これにより、ユーザーはアプリの複雑な技術的処理を意識することなく、直感的かつス\nムーズに操作を行うことが可能となっている。このように、写真撮影機能とスタンプ獲得機能は、複数の先進的な\n技術の統合によって成り立っており、運動促進アプリとしての価値を最大限に引き出す仕組みが実現されている。\n4.5\n社会的意義におけるスタンプラリー機能の影響と可能性\nスタンプラリー機能は、単なる運動促進ツールとしての役割を超えて、個人の健康促進と社会的価値の創出を\n両立する新たなアプローチとして位置づけられる。この機能は、ユーザーが目標地点を訪れることでスタンプを獲\n得する仕組みを通じて、地域社会との結びつきを強化し、地域活性化を促進する可能性を秘めている。まず、スタ\nンプラリー機能は、個人の健康促進に直接的な貢献を果たしている。特定の目標地点を訪れるよう促すこの仕組み\nは、運動の継続性を高めるだけでなく、日常生活において新たな移動パターンを生み出す。これにより、ユーザー\nは徒歩やランニングを通じて身体活動を増加させることができ、運動不足解消やストレス軽減といった健康上の\n利点を享受できる。また、目標地点が多様であることにより、単調になりがちな運動が変化に富んだ体験となり、\nユーザーのモチベーション維持に寄与する。このような仕組みは、特に初心者が運動習慣を形成するための有効な\n支援ツールとなる。次に、地域活性化への貢献について論じる。スタンプラリー機能の設計において、目標地点\nとして観光地や地域独自の施設、地元商業施設を選定することで、地域経済に直接的な影響を与えることが可能\nである。たとえば、ユーザーがスタンプを獲得するために訪れる地点を地元の店舗や観光スポットに設定すれば、\nそれらの場所に対する訪問頻度が向上し、結果として地元経済の活性化につながる。特に観光地では、スタンプ\nラリーを通じて訪問者の流入を増やし、飲食店、土産物店、観光施設の利用促進が期待される。また、ユーザー\nが訪れる目標地点が分散されている場合には、観光客や住民が地域内を広範囲に移動することになり、地域全体\nに経済的な恩恵が波及する効果も見込まれる。さらに、スタンプラリー機能は、地域の文化的価値を再発見する\n手段としても重要な役割を果たす。目標地点として歴史的建造物、地元の伝統行事の会場、自然保護区などを選\n定することで、ユーザーが地域の歴史や文化に触れる機会を提供する。このような仕組みは、地域住民自身にも\n31\nその価値を再認識させることができ、地域全体の文化的アイデンティティを強化する要素として機能する。特に\n若年層が地域の文化や歴史に興味を持つきっかけとなり、世代を超えた地域コミュニティの形成にもつながる可能\n性がある。また、スタンプラリー機能は、ユーザー同士の交流を促進する社会的効果も期待される。特定の目標\n地点を複数のユーザーが共有することで、偶然の出会いや交流が生まれる可能性が高まる。ユーザーがスタンプ\n獲得のために同じ地点を訪れた際に、互いに情報交換を行ったり、一緒に次の目標を目指したりすることが考えら\nれる。このようなインタラクションは、ユーザー同士の新たな繋がりを生み出し、個人の社会的ウェルビーイン\nグを向上させる効果がある。また、アプリ内でスタンプラリーの進捗や成果を共有する機能を導入すれば、オン\nライン上での交流や競争が促進され、地域全体での共同体意識が醸成される。スタンプラリー機能の社会的意義\nは、特に地域イベントとの連携において最大限に発揮される。地域の祭りやマラソン大会といったイベントの一\n環としてスタンプラリーを組み込むことで、参加者のアクティビティを増やし、イベントの魅力を向上させるこ\nとが可能である。たとえば、祭りの会場内に複数のスタンプ地点を設置し、参加者がそれらを巡ることで地域文\n化に触れつつ、運動も楽しむことができる。また、このようなイベントとアプリを連動させることで、参加者の\n記録をデジタル化し、後から振り返ることができるという利便性も提供される。加えて、スタンプラリー機能は\n地域の教育的価値を高める可能性も秘めている。目標地点に関連する情報（例: 歴史的背景、自然環境の特徴、地\n元の名物など）をアプリ内で表示することで、ユーザーは運動をしながら学びを得ることができる。このような\n教育的要素は、特に学生や子どもたちにとって効果的であり、運動を通じて楽しく学べる環境を提供する。また、\n地域に訪れる観光客にとっても、単なる観光地巡りではなく、知識を深めながら楽しむ体験を提供することがで\nきる。さらに、スタンプラリー機能の持続可能性にも注目するべきである。この機能は、地域の観光資源や施設\nをデジタル化し、その価値をより広く普及させる手段として活用できる。たとえば、地元の観光協会が目標地点\nを選定し、アプリを通じて情報を発信することで、観光地の認知度を高めることが可能である。また、アプリを\n通じたデータ収集により、ユーザーの訪問頻度や移動パターンを分析し、観光戦略の最適化にも貢献する。この\nように、スタンプラリー機能は、地域の観光や経済活動の持続可能な発展を支える要素として機能する。最後に、\nスタンプラリー機能は、健康促進、地域活性化、教育的価値の提供、そして社会的交流を融合させた統合的なア\nプローチを実現するものである。この機能をさらに発展させることで、地域社会における多様な課題に対応しな\nがら、個人と社会の幸福度を同時に向上させる可能性が広がる。本研究で開発されたスタンプラリー機能は、そ\nの具体例として、多くの地域や個人に新たな価値を提供することが期待される。\n32\n第5章\n結論\n5.1\n研究の背景と課題の明確化\n本研究では、社会調査を通じて現代社会における運動不足や健康促進に関連する課題を明らかにし、それらを\n解決する手段としてスタンプラリー機能を搭載した運動促進アプリケーションの開発に至った。このアプローチ\nは、社会的な課題をテクノロジーの活用を通じて解決するという点に特徴があり、運動を継続しやすくするため\nにゲーム的要素やインタラクティブな仕組みを取り入れてユーザー体験の向上を目指している。社会調査の結果、\n多くの人々が運動不足に直面しつつも継続的な運動を難しいと感じていることが明らかになった。その主な要因\nとして、運動の単調さや達成感の欠如、さらに運動成果が短期間では見えにくいことによるモチベーション低下\nが挙げられる。\n5.2\nスタンプラリー機能による運動促進の提案\nこれらの課題に対応するため、本研究では、運動を楽しくするためのゲーム的要素としてスタンプラリー機能\nを取り入れることを提案した。具体的には、目標地点を訪れることでスタンプを獲得する仕組みや運動成果を可\n視化するスコアシステム、写真撮影による達成の記録などの革新的な要素を統合している。これにより、運動を\n楽しさや挑戦感のあるものに変え、ユーザーのモチベーションを維持しやすくすることを狙っている。また、目\n標地点を地域の観光地や商業施設とすることで、個人の健康促進だけでなく地域活性化にも寄与する可能性を持\nつという社会的意義も備えている。\n5.3\n課題\n本研究はまだ調査や設計、プロトタイプの構築にとどまり、実験的な検証は行われていない点が課題として残っ\nている。特に、スタンプラリー機能の効果、スコアシステムの有効性、写真撮影機能の利用効果、地域活性化へ\nの影響などについては、実験を通じた具体的なデータが必要である。また、アプリケーションが特定の地域や集\n団を超えて幅広いユーザー層に受け入れられるかを評価することも重要である。さらに、他の健康促進プログラ\nムや公共政策との連携を通じて、アプリケーションの社会的影響を拡大する可能性も検討する必要がある。本研\n究は運動促進と地域活性化の融合という新しいアプローチを提案したものであり、今後の研究と実験を通じてそ\nの実用性と社会的価値をさらに高めることが期待される。\n33\n第6章\n今後の展望\n6.1\nパーソナライズとAI 技術の統合\nパーソナライズとAI 技術の統合は現代のデジタルサービスにおいて重要な要素であり、ユーザーごとのニーズ\nに対応した体験を提供することでエンゲージメントを向上させることができる。本研究で提案する運動促進アプ\nリケーションでも、AI 技術を活用して個々のユーザーに最適化された目標設定やモチベーション向上を目指す仕\n組みが導入されている。AI を活用する第一歩は、ユーザーの運動履歴、スタンプラリーの進捗状況、移動距離、\n位置情報、達成した目標の種類、運動頻度や利用時間帯などのデータを収集し、解析することである。これによ\nり個別のプロファイルを構築し、ユーザーごとの行動特性や好みを特定することが可能となる。これらのデータ\nを基にアプリケーションが動的に対応し、パーソナライズされた体験を提供する仕組みを実現する。またAI 技術\nの導入により、アプリケーションはユーザーに個別化された目標やアクティビティを提案する推奨システムを構\n築することが可能となる。例えばユーザーの現在地や移動履歴をもとに最適な目標地点を提案する機能では、自\n然豊かな場所を好むユーザーには公園や森林を、都市部を好むユーザーには観光地やモニュメントを提案するこ\nとができる。さらに過去のデータを分析して適切な運動頻度や距離、ペースを設定することで初心者には短距離\nや簡単な目標を、経験者にはややチャレンジングな目標を提示することも可能である。このような推奨機能によ\nりユーザーは自分に合った形で運動を楽しむことができ、結果としてアプリケーションの利用継続率が向上する。\nAI を活用するもう一つの重要なポイントは動的難易度調整（Dynamic Diﬃculty Adjustment, DDA）の実現であ\nる。ユーザーの運動履歴や目標達成率をもとに目標地点の難易度を動的に調整することで初心者には達成しやす\nい目標を提示し、経験者には挑戦的な目標を提案する仕組みを構築できる。また過去の成功率を考慮し達成感を\n高める目標と成功体験を積み重ねる目標のバランスを最適化することでユーザーが自分の成長を実感しながら無\n理なく運動を継続できるようになる。さらにAI を活用すれば感情状態やモチベーションの変化を解析し、それに\n応じたフィードバックを提供することも可能である。運動履歴や利用頻度が低下した場合に励ましのメッセージ\nを送ったり、特別なインセンティブを提供してモチベーションを回復させる仕組みを導入することでユーザーの離\n脱を防ぐことができる。ユーザーの感情データを活用して特定の運動がストレス軽減やポジティブな感情につな\nがる場合、その運動を優先的に推奨することで体験価値を向上させることも考えられる。AI 技術を活用してユー\nザー間の交流を促進するコミュニティ機能を統合することも将来的には有望である。例えば類似した運動パター\nンや目標を持つユーザーをマッチングしグループでのスタンプラリーを楽しむ機能を構築することで、ユーザー\n同士が競争や協力を通じてモチベーションを高め合う仕組みを提供することができる。このような機能は運動を\n通じた社会的なつながりを促進し、アプリケーションの利用価値をさらに高めると期待される。一方でAI 技術の\n導入にはデータプライバシーの保護と倫理的配慮が不可欠である。運動履歴や位置情報、さらには感情状態といっ\nたデータを取り扱うため、データの匿名化やセキュリティの確保が求められる。ユーザーにデータ収集の目的や\n利用方法を明示し、選択肢を提供することで信頼関係を構築することが重要である。将来的にはAI 技術をさらに\n発展させ、運動促進アプリケーションを包括的な健康支援プラットフォームへ進化させることが考えられる。例\nえば運動習慣だけでなく栄養管理や睡眠データを統合的に分析し総合的な健康プランを提案する仕組みを構築す\nることも可能である。また拡張現実（AR）技術と組み合わせることでユーザーが目標地点をリアルタイムで視覚\n的に確認できる機能や、仮想空間上で他のユーザーと交流する仕組みを提供することも考えられる。このように\nパーソナライズとAI 技術の統合は運動促進アプリケーションをより高度で効果的なものに進化させ、ユーザーエ\nクスペリエンスを大幅に向上させる可能性を秘めている。\n34\n6.2\nゲーミフィケーションのさらなる深化\nゲーミフィケーションのさらなる深化は、運動促進アプリケーションの利用継続率やユーザーエンゲージメント\nを高めるために重要なアプローチである。単純なスコアシステムやスタンプラリーの仕組みにとどまらず、より洗\n練されたゲーム要素を組み込むことで、ユーザーに新たなモチベーションを提供し、運動を楽しさと達成感を伴う\n体験へと昇華させることが可能となる。例えば、物語性を取り入れたストーリーベースの要素は、ユーザーの感\n情的な関与を引き出すうえで有効である。ユーザーがランニングやウォーキングを進めることで仮想の冒険を進\n行させる仕組みや、特定のミッションをクリアするたびに物語が展開する構造を導入すれば、運動の単調さを軽\n減し、ユーザーの達成意欲を刺激することができる。また、アプリ内での報酬システムを拡張することも、ゲー\nミフィケーションの深化に寄与する。単なるスタンプやバッジの付与に加え、アプリ内ポイントや仮想通貨を提\n供し、それを特典やアイテム、さらには現実世界での景品と交換できる仕組みを構築することで、ユーザーにとっ\nて実用的かつ具体的なメリットを提示できる。このような報酬システムは特に継続的なモチベーションの維持に\n効果的である。また、報酬に希少性やランダム性を持たせることで、期待感を高める仕組みも考えられる。例え\nば、特定の目標を達成した際にランダムで高価値なアイテムが手に入る仕組みを導入すれば、ユーザーの挑戦意\n欲が一層高まる可能性がある。さらに、ユーザー間の競争や協力を促進する仕組みを強化することで、社会的な\n動機付けを取り入れることができる。ランキングシステムを導入して、ユーザー同士がスコアや成果を競い合う\n機会を提供することは、特に競争心の強いユーザーにとって強力なモチベーション源となる。一方で、協力型の\nゲーム要素を組み込むことで、コミュニティ意識を育むことも可能である。例えば、ユーザーがチームを組んで\n共同目標を達成する形式や、互いに応援メッセージを送り合える機能を追加することで、社会的なつながりが深\nまり、アプリへの依存度が高まる。また、リアルタイムで他のユーザーと競い合ったり協力したりできる機能を\n実装することで、オンラインでの交流やコミュニケーションが活性化する。ゲーミフィケーションをさらに深化\nさせるうえで、個別化された体験を提供するパーソナライゼーションの導入も不可欠である。AI を活用してユー\nザーの行動データや好みを分析し、個々のユーザーに最適化されたゲーム要素を提示することで、個別のニーズに\n応じた体験を提供することが可能となる。例えば、初心者には達成しやすい目標やシンプルなミッションを提示\nし、経験者にはチャレンジングな目標や高度な戦略が求められるタスクを提案することで、それぞれのユーザー\nが自分に適したレベルで楽しむことができる。このようなパーソナライズされたゲーミフィケーションの体験は、\nユーザーの継続的なエンゲージメントを促進し、運動のモチベーションを持続させる効果が期待される。また、拡\n張現実（AR）や仮想現実（VR）技術を活用することで、ゲーミフィケーションの体験をさらにリッチなものに\n進化させることができる。AR を用いて目標地点を視覚的に示したり、VR 空間で他のユーザーと競争する要素を\n組み込むことで、ゲームの没入感が高まり、現実の運動と仮想の体験が融合した新しい形のゲーミフィケーショ\nンを提供することが可能となる。具体的な例としてはランニング中にAR で仮想の敵と対決するシナリオを実現\nしたり、指定されたルートを走破することでVR 空間上で新たなエリアを解放する仕組みを構築すれば、運動そ\nのものがエンターテインメントとしての側面を持つようになる。さらに、ユーザーにとっての運動の意義を拡大\nするため、ゲーミフィケーションを教育や社会的貢献と結びつける取り組みも考えられる。例えば、特定の目標\nを達成することで地域社会への寄付が行われる仕組みや、エコランニング（環境保護を意識したランニング）を\n推進するゲーム要素を導入することで、運動を通じた社会的意識の向上を図ることができる。このような取り組\nみは、単なる個人の楽しみを超えて、より大きな目的意識をユーザーに提供することで、アプリの持続可能性と\n社会的価値を高めることができる。また、ゲーミフィケーションの深化を支える技術基盤として、リアルタイム\nデータ処理やクラウドインフラの活用が求められる。特に大規模なユーザー基盤を持つアプリケーションでは、多\n数のユーザーが同時に参加するゲーム要素をリアルタイムで動的に処理する技術が重要となる。これを実現する\nためには、クラウドベースのサーバーアーキテクチャや分散型データベースの導入が不可欠である。これにより、\nユーザーがどのようなデバイスを使用していてもスムーズにゲーム体験を享受できる環境を提供することができ\nる。ゲーミフィケーションのさらなる深化は、単なる運動支援を超えたエンターテインメント性のある健康促進\nプラットフォームを実現する可能性を秘めている。\n35\n6.3\n地域との連携強化\n地域との連携強化は、運動促進アプリケーションが単なる個人向けのツールとして機能するだけでなく、地域\n社会全体に価値を提供するプラットフォームとして進化するために重要な要素である。特にスタンプラリー機能\nは、地域の観光地や地元施設との連携を通じて、運動を促進しながら地域活性化を実現するポテンシャルを持つ。\n本アプローチでは、地域の名所や特色ある施設を目標地点として設定し、ユーザーが運動をしながらそれらの場\n所を訪れる仕組みを構築することができる。これにより、地域の知名度向上や観光客の誘致、地元経済の活性化\nが期待される。また、スタンプラリーを地域のイベントや祭りと連動させることで、運動促進アプリケーション\nはさらに高い効果を発揮することができる。例えば、季節ごとに異なるテーマを設定し、春には桜の名所、夏に\nは海や花火大会の会場、秋には紅葉スポット、冬にはイルミネーションや温泉地を目標地点とすることで、ユー\nザーに新しい発見や楽しみを提供できる。このような季節限定のスタンプラリーは、地域の観光資源を最大限に\n活用するとともに、ユーザーが定期的にアプリを利用する動機付けとなる。また、地域特有の文化や伝統を体験\nできるポイントを目標地点に組み込むことで、ユーザーがその地域の魅力をより深く知る機会を提供することも\n可能である。例えば、地元の伝統工芸品の製作体験や特産品を味わえる飲食店を目標地点に設定することで、運\n動が単なる身体活動ではなく、学びや発見を伴う豊かな体験へと昇華する。このような取り組みを通じて、運動\n促進アプリケーションは地域との強いつながりを構築することができる。さらに、地域の商業施設や店舗と提携\nし、スタンプ獲得後に特典を受けられる仕組みを導入することも効果的である。例えば、特定の目標地点を訪れ\nてスタンプを獲得したユーザーには、提携店舗で割引を受けられるクーポンやプレゼントを提供する仕組みを作\nることで、地域の店舗に足を運ぶきっかけを作り、地元経済の活性化に寄与することができる。このようなインセ\nンティブは、アプリの利用者にとっても運動を継続するモチベーションとなる。また、地元企業や自治体と連携\nして、特定のエリア内での運動促進キャンペーンを実施することも考えられる。例えば、地域全体を対象とした\n「健康増進月間」を設定し、その期間中に一定のスタンプを獲得したユーザーに地域の特産品をプレゼントする仕\n組みを構築することで、地域住民全体の健康意識を高めるとともに、地域全体での一体感を醸成することができ\nる。このようなキャンペーンは、特に自治体や地域団体が主導する場合、地域社会の課題解決に直接的に寄与す\nる可能性が高い。また、地域との連携をさらに強化するためには、アプリケーション内で地域の情報を積極的に\n発信する仕組みを導入することが重要である。例えば、目標地点に関連する歴史的背景や観光情報、地元のイベ\nント情報をアプリ内で提供することで、ユーザーが地域の魅力を深く理解し、訪れる動機を強化することができ\nる。さらに、地域の住民がスタンプラリーの目標地点や内容の提案に参加できる仕組みを構築することで、地域住\n民自らが主体的に参加できる環境を作ることも考えられる。このような双方向的なアプローチは、地域住民とア\nプリ利用者との間に新しい形のつながりを生み出す可能性を秘めている。また、スタンプラリーを地域の課題解\n決と結びつけることで、社会的な意義をさらに高めることができる。例えば、地域の清掃活動やエコプロジェク\nトと連動したスタンプラリーを実施することで、地域住民やユーザーが運動を通じて地域貢献を実感できる仕組\nみを作ることができる。このような活動は、地域の環境保護や社会課題解決にもつながり、アプリケーションの\n価値をさらに高めることができる。さらに、地域の観光協会や商工会議所との連携を強化することで、スタンプ\nラリーの内容をより充実させることが可能となる。例えば、観光地を巡るスタンプラリーを実施する際、観光協\n会が持つ情報やリソースを活用することで、より魅力的なコンテンツを提供することができる。また、商工会議\n所と連携して地元企業や店舗を巻き込むことで、スタンプラリーを通じた地域経済の活性化を図ることができる。\nこのような地域との連携を強化するためには、アプリケーションの柔軟性と拡張性を確保することが重要である。\n例えば、地域ごとの独自コンテンツを容易に追加できる機能を導入することで、さまざまな地域のニーズに応え\nることができる。また、地域の特性やニーズに応じたカスタマイズが可能なプラットフォームを構築することで、\nより多くの地域との連携を実現することができる。さらに、地域住民やアプリ利用者がスタンプラリーの企画に\n参加できる仕組みを提供することで、地域社会との一体感を強化することも可能である。このように、運動促進\nアプリケーションにおける地域との連携強化は、個人の健康促進と地域社会の活性化を両立させるうえで極めて\n重要な要素であり、今後の発展においてさらなる注目を集めることが期待される。\n36\n6.4\n社会的包摂を目指した機能追加\n社会的包摂を目指した機能の導入は、運動促進アプリケーションが多様な背景を持つユーザーに対応し、誰も\nが利用しやすい環境を提供するために不可欠な要素である。この取り組みは、高齢者や障害を持つ人々、社会的\nに孤立しがちな人々など、運動へのアクセスが制限される可能性のある層にも、健康促進の機会を提供すること\nを目的としている。そのためには、まずインクルーシブなデザインの実現が求められる。例えば、視覚障害者向\nけに画面リーダーとの互換性を確保し、音声ガイドや振動通知を導入することで、アプリの機能を視覚に依存せ\nずに利用できるようにする。また、操作をシンプルにし、直感的に利用できるインターフェースを構築すること\nも重要である。一方で、聴覚障害を持つユーザーに対しては、ビジュアル通知を強化し、運動中に重要な情報を\n適切に伝達するためのアニメーションや視覚的なフィードバックを活用することが考えられる。また、言語の壁\nを取り除くために、多言語対応を実現することも重要である。特に、移民や多文化背景を持つユーザーが増加し\nている現代では、利用者の母国語で情報を提供することが、アプリの普及と社会的包摂の観点から重要な要素と\nなる。さらに、高齢者にとって運動が心理的にも身体的にも負担とならないようにするため、負荷の少ない目標\n設定やリマインダー機能の導入も効果的である。例えば、短い距離のウォーキングや椅子に座ったままできる運\n動を提案し、それを達成可能な目標としてアプリが自動的に設定する機能を備えることが考えられる。このよう\nな機能は、ユーザーが自己効力感を高めるきっかけとなり、運動への参加を促進する。また、孤立感を感じやすい\n人々に対しては、コミュニティ機能を強化することが有効である。例えば、ユーザー同士がオンラインで交流し\nたり、励まし合うことができるプラットフォームを提供することで、社会的なつながりを構築することができる。\nまた、地域の実際のイベントや集団活動と連携させることで、アプリがデジタルとリアルの橋渡しを行い、ユー\nザーが地域社会との結びつきを感じられるようにする。このような取り組みは、運動促進だけでなく、孤独や社会\n的孤立といった課題に対応するうえでも効果的である。さらに、障害を持つ人々向けには、運動の種類をパーソ\nナライズし、個々の身体能力に合わせた提案を行う仕組みが求められる。例えば、特定の身体部分だけを動かす\n運動や、リハビリテーションと結びついたメニューを提示することで、障害の種類や程度に応じた運動を提供す\nることが可能となる。また、ゲーミフィケーションの要素を加えることで、運動を楽しい体験へと変えることも\n効果的である。例えば、バーチャルアバターを用いて運動成果を可視化し、ユーザーが達成感を感じられる仕組\nみを導入することが考えられる。このような視覚的な要素は、特に言葉や数値による情報伝達が難しい場合でも、\nユーザーが感覚的に理解しやすいという利点がある。また、AI 技術を活用してユーザーごとの運動習慣や嗜好を\n学習し、最適化された運動メニューを提案することで、個別のニーズに応えることができる。この技術は、特に\n複雑なニーズを持つユーザーに対して、パーソナライズされた体験を提供するうえで有用である。さらに、社会\n的包摂を目的とした運動促進アプリケーションは、経済的な障壁にも対応する必要がある。アプリ内の機能を無\n料または低コストで提供し、すべてのユーザーが平等にアクセスできるようにすることが重要である。また、ス\nポンサーシップや寄付を活用して、経済的に困難な状況にある人々がアプリを利用できる仕組みを構築すること\nも考えられる。こうした取り組みは、運動を始める際の心理的・経済的な負担を軽減し、社会全体で健康促進を\n支援する環境を作り出すことに寄与する。さらに、社会的包摂の観点からは、アプリのフィードバック機能も重\n要である。運動の成果を評価するだけでなく、ユーザーの努力や継続性を認めるポジティブなメッセージを提供す\nることで、心理的な支援を行うことができる。このようなポジティブなフィードバックは、特に運動に自信がな\nいユーザーに対して大きな効果を持つ。運動の効果や進捗を分かりやすく視覚化することで、ユーザーが自分の\n成長を実感できるようにすることも有効である。このように、社会的包摂を目指した機能の導入は、運動促進ア\nプリケーションをすべての人々にとって利用しやすく、魅力的なものにするための重要なステップである。これに\nより、運動の機会を広く提供し、健康促進と社会的つながりの強化を同時に達成することが期待される。\n6.5\n環境意識を高める仕組みの導入\n環境意識を高める仕組みを運動促進アプリケーションに導入することは、個人の健康促進と地球環境の保護を\n同時に推進するために重要である。この取り組みは、ユーザーが運動を通じて環境問題に対する意識を高め、日\n37\n常生活で持続可能な行動を選択するきっかけを提供することを目的としている。具体的には、アプリ内で運動と\n環境活動を結びつける仕組みを構築することが考えられる。ユーザーが一定の距離をランニングやウォーキング\nで移動するごとに、植樹や森林再生プロジェクトへの貢献としてポイントが付与されるシステムを導入する。こ\nのような仕組みによって、運動を行うことが環境保護活動への直接的な貢献につながるというモチベーションを\n提供できる。また、目標地点を環境保護に関連する場所に設定することで、ユーザーが自然環境の価値を実際に\n体験できる仕組みも有効である。地域の保護区、エコパーク、再生された森林などをスタンプラリーの目標地点\nとすることで、ユーザーは運動中に環境保護の重要性を学ぶことができる。さらに、ゴミ拾いやリサイクル活動\nと連動したイベントを企画し、それをアプリ内のチャレンジとして設定することも効果的である。例えば、ユー\nザーがランニング中に拾ったゴミの写真をアプリ内で投稿すると、ポイントやバッジを獲得できる仕組みを導入\nすることで、楽しみながら環境保護活動に参加する機会を提供することができる。運動時の消費カロリーや移動\n距離をCO2 削減量に換算し、視覚的にフィードバックする機能もユーザーの環境意識を高める一助となる。この\n機能では車や公共交通機関を使った場合と比較して、どれだけのCO2 排出を削減できたかをグラフや数値で表示\nすることで、個人の行動が環境に与えるポジティブな影響を具体的に実感できるようにする。さらに、アプリ内\nで環境に配慮した行動の提案を行うことも有効である。地域のエコイベントへの参加を推奨する通知機能や、持\n続可能なライフスタイルを学べる記事や動画を提供するセクションを設けることで、ユーザーが環境についての\n知識を深め、実際の行動につなげる機会を増やすことができる。また、アプリの利用者同士が環境活動に関する\n情報を共有できるコミュニティ機能を導入することも考えられる。これにより、ユーザー間での相互啓発が進み、\n環境意識の向上だけでなく、社会的なつながりも強化される。加えて、環境活動に積極的な企業や団体と連携し、\nアプリ内で環境保護プロジェクトの進捗状況や成果を共有することで、ユーザーに達成感や参加意識を提供する\nことも可能である。例えば、一定の運動目標を達成したユーザーに対して、企業からの寄付が環境保護プロジェク\nトに行われる仕組みを導入することで、社会的意義を感じながら運動を続けられる環境を作り出すことができる。\nまた、地域の環境問題に特化したスタンプラリーを実施することで、ユーザーが自分たちの住む地域の課題を認\n識し、それに対して主体的に取り組む機会を提供することができる。河川や公園の清掃活動をアプリ内のチャレ\nンジとして設定し、参加者にポイントや特典を与える仕組みを導入することで、地域の環境保護に貢献しながら\n運動を楽しむことができる。このように、環境意識を高める仕組みは、運動促進アプリケーションを単なる健康\n管理ツールとしてだけでなく、環境保護を促進するプラットフォームとして進化させる可能性を秘めている。これ\nらの取り組みを通じて、ユーザーが自分自身の健康を維持するだけでなく、地球環境の保護に貢献する意識を高\nめることが期待される。このような仕組みを導入することで、持続可能な社会の実現に向けた一歩を踏み出すこ\nとができる可能性がある。\n6.6\nクロスプラットフォーム展開と他サービスとの統合\nクロスプラットフォーム展開と他サービスとの統合は、運動促進アプリケーションのユーザー体験を向上させ、\n利用者の裾野を広げる上で重要な要素である。現代のデジタル環境では、異なるデバイスやプラットフォームでア\nプリを利用したいというニーズが高まっており、この要件に対応することで、ユーザーにシームレスな体験を提供\nすることが可能となる。クロスプラットフォーム展開のためには、React Native やFlutter のようなフレームワー\nクを活用して、単一のコードベースでAndroid とiOS の両方に対応したアプリケーションを構築するアプローチ\nが考えられる。このような技術を利用することで、開発コストを抑えつつ、幅広いユーザー層に対応することが\nできる。また、PWA（プログレッシブウェブアプリ）を採用することで、ネイティブアプリとしての機能を備え\nながら、デスクトップやモバイルウェブブラウザを通じて利用できるようにすることも有効である。これにより、\nアプリをインストールせずにアクセスできる利便性を提供し、より多くのユーザーに利用される可能性が高まる。\nまた、クロスプラットフォーム展開を成功させるためには、データ同期とアカウント管理の仕組みが重要である。\nユーザーが複数のデバイス間でシームレスにデータを共有できるように、クラウドベースのデータストレージを\n導入する必要がある。Firebase やAWS Amplify などのサービスを活用することで、ユーザーデータをリアルタイ\nムで同期し、デバイス間の移行をスムーズに行える仕組みを構築することができる。さらに、ユーザーの利便性\n38\nを向上させるために、他サービスとの統合を進めることも重要である。例えば、Google Fit やApple Health と連\n携することで、運動データを一元管理し、他の健康管理データと統合することが可能となる。このような統合に\nより、ユーザーは運動だけでなく、食事、睡眠、ストレス管理などの総合的な健康情報を把握することができる。\nまた、ソーシャルメディアプラットフォームとの連携も、ユーザー体験を向上させる重要な要素である。例えば、\nユーザーがアプリ内で獲得したスタンプや運動成果をInstagram やTwitter、Facebook などで共有できる機能を\n導入することで、ユーザー同士の交流が活発化し、アプリの利用が拡大する可能性がある。さらに、運動をゲーム\n化するゲーミフィケーションの要素を強化するために、他のゲーミフィケーションプラットフォームやサービスと\n統合することも考えられる。Strava やRunkeeper のような既存の運動追跡アプリと連携し、ユーザーがこれらの\nサービスで記録した運動データを活用してスタンプラリーの進捗を自動的に更新できる仕組みを導入することで、\nユーザーの利便性と満足度を向上させることができる。また、地域活性化を目指す場合には、地元の商業施設や\n観光地との統合も有効である。アプリ内で特定の目標地点を訪れたユーザーに対して、地域の提携店舗で使用で\nきるクーポンを提供する仕組みを導入することで、地域経済の活性化に貢献することができる。さらに、e コマー\nスプラットフォームとの統合も検討すべきである。例えば、アプリ内で獲得したポイントをAmazon や楽天市場\nでの買い物に使用できるようにすることで、ユーザーのモチベーションをさらに高めることが可能となる。この\nような仕組みは、ユーザーに対して明確なインセンティブを提供し、アプリの利用頻度を高める効果が期待され\nる。また、企業のウェルビーイングプログラムとの統合も考えられる。企業が従業員の健康促進の一環としてこ\nのアプリを導入し、従業員がアプリ内で設定された運動目標を達成することで企業内での特典を受けられる仕組\nみを提供することができる。このようなB2B の統合は、企業と個人の両方に価値を提供し、アプリの利用範囲を\nさらに拡大する可能性がある。さらに、学術研究や公衆衛生の分野との連携も検討することで、アプリの社会的\n意義を高めることができる。アプリで収集された匿名化データを用いて運動の健康効果や行動パターンに関する\n研究を行うことで、社会全体の健康増進に寄与することが可能となる。このようなデータは、地域ごとの運動状\n況を可視化し、公衆衛生政策の立案にも活用できる。また、クロスプラットフォーム展開や他サービスとの統合\nを進めるにあたり、データの安全性とプライバシー保護が極めて重要である。特に、個人情報や健康データを扱\nう場合、GDPR やCCPA などの国際的なプライバシー規制に準拠した仕組みを導入する必要がある。これには、\nデータ暗号化やユーザー同意の取得、データの利用目的を明確化するポリシーの策定が含まれる。クロスプラット\nフォーム展開と他サービスとの統合を通じて、運動促進アプリケーションは、個人の健康促進を超えた幅広い社\n会的価値を提供するツールへと進化する可能性を秘めている。これらの取り組みを進めることで、ユーザーがど\nのような環境や状況でもアプリを利用しやすくなるだけでなく、他のサービスやコミュニティと連携することで、\n運動を通じた新たなつながりや価値を生み出すことが期待される。\n6.7\n学習要素の追加\n学習要素の追加は、運動促進アプリケーションの価値をさらに高めるとともに、ユーザーの知識向上や意識改\n革に寄与する重要な取り組みである。このアプローチでは、運動の記録やスタンプラリー機能だけでなく、ユー\nザーが健康、運動、生理学、栄養学、環境問題などについて学ぶ機会を提供することで、アプリの利用をより有意\n義なものにすることが可能となる。具体的には、運動と学習を結びつけるためのさまざまなコンテンツや機能を\n設計することが考えられる。例えば、スタンプラリーの目標地点に関連する歴史的背景や文化的意義、自然環境\nについての解説をアプリ内に組み込むことで、ユーザーがその地域や場所についての知識を深められる仕組みを\n提供することができる。また、運動を通じて健康や栄養に関する情報を学べるセクションを導入することも有効\nである。ユーザーがランニングやウォーキングを行う際、その運動が体にどのような影響を与えるのか、どのよ\nうな栄養素を摂取すれば運動効果を高められるのかといった知識を短い記事や動画形式で提供することで、ユー\nザーは運動そのものの価値を理解しやすくなる。このような学習コンテンツをユーザーの運動データや進捗に基\nづいてパーソナライズすることで、より効果的な学びを提供することができる。例えば、一定の距離を達成した際\nに、関連するテーマの学習コンテンツをアンロックする仕組みを導入することで、運動の達成感と学習の達成感\nを同時に提供することができる。また、クイズやテスト形式の学習要素を取り入れることも効果的である。ユー\n39\nザーがスタンプラリーで特定の目標地点を訪れた際、その場所に関連する知識を問うクイズが表示される仕組み\nを導入することで、ゲーム性を高めながら知識を深めることができる。このようなクイズには、正解することで追\n加ポイントや特別なバッジを獲得できるインセンティブを付与することで、ユーザーの学習意欲をさらに高める\nことが可能となる。さらに、アプリ内で学習要素を強化するために、専門家や教育機関との連携を図ることも考\nえられる。運動科学や健康分野の専門家が監修したコンテンツを提供することで、ユーザーは信頼性の高い情報\nにアクセスすることができる。また、環境問題や地域社会に関連する教育機関と提携し、地域固有の課題につい\nての情報を提供することで、ユーザーが自身の行動の影響をより深く理解できる仕組みを作ることも有効である。\nこのほか、学習要素を強化するために、アプリ内での報酬システムを活用することも重要である。特定の学習モ\nジュールを完了することでポイントが付与され、それを他の運動チャレンジやアプリ内の特典に利用できる仕組\nみを導入することで、学びと運動の双方を促進する相乗効果を生み出すことができる。これにより、ユーザーは\n学習を単なる義務感で行うのではなく、楽しみながら進められるようになる。さらに、ソーシャル機能を活用して\n学習要素を強化することも考えられる。例えば、ユーザー同士が学んだことを共有したり、特定のテーマに関す\nるディスカッションに参加したりする機能を導入することで、学びを深めるだけでなく、コミュニティ内での交流\nを促進することが可能となる。また、学習内容に基づいてユーザーが新しい運動目標を設定できる機能を導入す\nることで、学びと実践を結びつけることができる。運動が特定の健康効果を持つことを学んだユーザーが、その\n効果を実現するための運動プランをアプリ内で設定し、それに基づいて日々の活動を管理する仕組みを提供する\nことで、学習が実際の行動変容につながる。最後に、AI 技術を活用して学習要素をパーソナライズし、ユーザー\nごとに適したコンテンツを提供することも効果的である。ユーザーの興味関心や運動パターン、進捗状況に基づ\nいて、学習内容をカスタマイズすることで、より効率的かつ魅力的な学びの体験を提供することができる。この\nような学習要素の追加により、運動促進アプリケーションは、単なる健康管理ツールを超えた教育的価値を持つプ\nラットフォームになる。\n6.8\nグローバル展開\nグローバル展開は、運動促進アプリケーションの潜在的な市場を最大化し、世界中のユーザーに健康促進と運\n動習慣を支援する機会を提供するための重要な戦略である。グローバル展開を成功させるためには、各地域の文\n化、言語、健康に関する習慣を理解し、それらをアプリの設計や機能に反映させることが不可欠である。最初の\nステップとして、アプリの多言語対応が挙げられる。主要な国際言語での翻訳を行うだけでなく、地域固有の方言\nや表現を考慮に入れることで、ユーザーが自国の文化に即した体験を得られるようにする必要がある。この多言\n語対応は、単なる文字の翻訳にとどまらず、UI デザインや文化的に適切な表現を取り入れることで、地域ごとの\n多様性に対応することが重要である。さらに、地域ごとの運動習慣やライフスタイルの違いを考慮した機能のカ\nスタマイズも必要である。一部の国では屋内での運動が主流である一方で、他の国では屋外活動が一般的である\n場合がある。これに対応して、アプリ内で提供する運動プランや目標設定を地域ごとに最適化することが求めら\nれる。また、地域特有の気候や地形、祝祭日や伝統的なイベントを考慮したスタンプラリーの目標地点やチャレ\nンジを設計することで、現地ユーザーにとって親しみやすい体験を提供することが可能になる。さらに、グロー\nバル展開を支援するためには、現地パートナーとの連携が重要である。地域の健康機関、スポーツ団体、企業と\n協力し、アプリの知名度を高めるとともに、現地ユーザーのニーズに即した機能やサービスを開発することがで\nきる。例えば、特定地域で人気のあるスポーツやアクティビティに特化したチャレンジを提供することで、現地\nユーザーの参加を促進することができる。地域の観光地や商業施設を目標地点として設定し、それらと連携した\n報酬や特典を提供することで、地域経済の活性化にも寄与する。このような取り組みは、ユーザーと地域社会の\n両方に利益をもたらすことができる。さらに、グローバル展開においては、技術的なスケーラビリティを確保す\nることも重要である。アプリが多くのユーザーに利用されるようになると、サーバー負荷の増大やデータ管理の\n複雑化が課題となる。これに対応するために、クラウドベースのインフラを活用し、地域ごとに分散型のデータ\nセンターを配置することで、各地域での迅速なレスポンスと高い可用性を確保することができる。各国のプライ\nバシー規制やデータ保護法（例: GDPR）を遵守し、ユーザーデータの安全性を確保することも必須である。こ\n40\nれには、データの暗号化や匿名化、明確なデータ利用方針の策定が含まれる。さらに、グローバル展開を成功さ\nせるためには、マーケティング戦略の適応も必要である。異なる地域ごとに効果的なプロモーション方法を選択\nし、現地の文化や習慣に合わせた広告キャンペーンを展開することが求められる。特定の地域ではソーシャルメ\nディアが主要な情報源となる一方で、他の地域ではテレビ広告や地元のイベントを活用した方が効果的な場合が\nある。このように地域ごとの消費者行動に応じた柔軟な戦略を採用することが、グローバル市場での成功に繋が\nる。また、グローバル展開を進める中で、ユーザー間の国際的なつながりを促進することも価値がある。例えば、\nアプリ内でユーザーが異なる国の参加者と運動成果を競争したり、協力して目標を達成したりすることができる\n仕組みを導入することで、国境を越えたコミュニティの形成を支援することが可能となる。このような国際的な\n交流の機会は、アプリの利用価値を高めるだけでなく、多文化理解を促進する効果も期待できる。さらに、グロー\nバル展開では、現地のユーザーからのフィードバックを積極的に取り入れ、アプリの改善に役立てることが重要\nである。ユーザーの意見を収集し、それを基に新しい機能や調整を行うことで、現地ニーズに即したアプリ体験\nを提供し続けることができる。また、地域ごとの成功事例やユーザーの声を共有することで、新規ユーザーの獲\n得にも繋がる。最後に、グローバル展開の取り組みは、単にアプリを世界中で利用可能にすることを超えて、異\nなる文化や習慣に対応しながら、ユーザーにとって価値ある体験を提供するものである。このような展開を通じ\nて、アプリは単なる健康管理ツールから、世界中の人々をつなぎ、健康的なライフスタイルを推進するための包\n括的なプラットフォームへと進化する可能性を秘めている。これにより、運動促進アプリケーションは、地域社会\nとグローバルコミュニティの双方において、社会的および経済的な価値を提供する存在となる。\n6.9\nデータ解析による継続的な改善\nデータ解析による継続的な改善は、運動促進アプリケーションの品質向上とユーザー体験の最適化において重\n要な役割を果たす。アプリケーションを通じて収集される多様なデータを活用することで、ユーザー行動のパター\nンを把握し、運動習慣の形成を支援するための効果的なインサイトを得ることが可能となる。ユーザーがどのよ\nうなタイミングでアプリを利用し、どのような運動を好むのか、またどのような要素がモチベーション維持に寄\n与しているかを分析することが含まれる。GPS データや運動の進捗状況、スタンプラリーの達成記録、写真撮影\nの頻度などのデータを統合して解析することで、ユーザーが特に達成感を感じる瞬間や、逆にアプリ利用を停止\nする要因を特定することができる。このようなデータは、アプリ設計の改善に直接的に活用され、ユーザーごと\nにパーソナライズされた体験を提供するための基盤となる。また、継続的な改善を実現するためには、データの\n収集と解析がリアルタイムで行われる仕組みを構築することが重要である。クラウドベースのデータ管理システ\nムを利用することで、大量のデータを迅速に処理し、リアルタイムでのフィードバックを可能にする。ユーザー\nがアプリ内で新しい目標を設定した場合、その目標に応じた適切な運動プランやスタンプラリーのチャレンジを\n即座に提案できる仕組みを実装することで、ユーザーエンゲージメントを向上させることができる。このような\nデータ駆動型のアプローチは、アプリケーション全体の柔軟性と適応性を高め、ユーザーの期待に応じた体験を提\n供することを可能にする。また、データ解析は新しい機能の導入や既存の機能の調整にも役立つ。どのスタンプ\nラリー目標が最も多くのユーザーに達成されているのか、またはどの機能が利用されていないのかを特定するこ\nとで、目標の難易度や報酬の調整、不要な機能の削除や改善が可能になる。さらに、ユーザー行動を時間軸で分\n析することで、長期間にわたる運動習慣の変化や、アプリ利用における課題を把握することができる。この情報\nを基に、運動習慣が継続しやすいようなアプリデザインを検討し、ユーザーがより効果的に目標を達成できるよ\nうサポートする仕組みを構築することができる。加えて、ユーザーの属性（例: 年齢、性別、運動経験の有無）に\n基づいて行動をセグメント化し、それぞれのグループに最適な体験を提供することも可能である。初心者向けに\nは簡単な目標と高頻度のポジティブフィードバックを提供し、経験者向けにはチャレンジングな目標や報酬を提\n案することで、それぞれのニーズに応じたサポートを行うことができる。また、データ解析を通じて得られるイ\nンサイトは、ユーザー自身に対しても提供されるべきである。ユーザーが自身の運動履歴や達成状況を視覚的に\n把握できるダッシュボードを用意し、継続的な改善に役立てられるようにする。月間の運動時間や消費カロリー、\n獲得したスタンプ数などをグラフやチャートで表示することで、ユーザーは自分の進捗を簡単に確認でき、次の目\n41\n標に向けたモチベーションを維持しやすくなる。このようなデータ可視化は、ユーザーが自分の行動に価値を感\nじ運動を続ける意欲を高める効果が期待される。また、データ解析はアプリケーションの品質管理にも重要な役\n割を果たす。バグやエラーの発生頻度を追跡し、ユーザーが直面している技術的な問題を早期に特定することで、\n迅速な対応が可能となる。さらに、ユーザーからのフィードバックデータを収集・分析し、それを製品改善のサイ\nクルに組み込むことで、ユーザー満足度の向上を図ることができる。これにより、アプリの信頼性とユーザー体\n験が向上し、長期的な利用を促進することができる。データ解析を活用して継続的に改善を行うことで、単なる\n運動促進ツールとしての役割を超えユーザーの健康的なライフスタイル形成を総合的に支援するプラットフォー\nムとしての地位を確立することが可能となる。これによりユーザーにとっては運動がより身近で楽しいものとな\nり、社会的には健康増進や医療費削減、地域活性化といった幅広い効果をもたらすことが期待される。\n6.10\n持続可能な運用モデルの構築\n持続可能な運用モデルの構築は、運動促進アプリケーションが長期的に効果を発揮し、安定したサービスを提\n供し続けるための基盤を形成する重要な取り組みである。これを実現するためには、収益性、ユーザーエンゲー\nジメント、社会的インパクトをバランス良く統合したアプローチが必要である。収益性の観点からは、多様な収益\n源を確保することが重要であり、特にフリーミアムモデルの採用が効果的であると考えられる。このモデルでは、\n基本的な機能を無料で提供し、プレミアム機能や追加コンテンツを有料で提供することで、幅広いユーザー層を獲\n得しつつ安定した収益を得ることが可能となる。スタンプラリー機能を無料で利用できる一方で、特別なスタンプ\nやカスタマイズ可能な報酬、詳細な運動解析データを有料オプションとして提供することで、ユーザーのニーズ\nに応じた柔軟なプランを構築できる。サブスクリプションモデルを導入し、定期的な収益を確保することも効果\n的である。ユーザーにとって価値の高い機能やコンテンツを継続的に提供することで、利用者の満足度とリテン\nション率を向上させることができ、尚且つ広告モデルや提携企業との協力によるスポンサーシップも収益源とし\nて活用できる。地域の商業施設や観光地をスタンプラリーの目標地点として設定し、それに関連する広告やプロ\nモーションを展開することで、企業や自治体との連携を強化し、収益を多角化することが可能となる。ユーザーエ\nンゲージメントの向上は、持続可能な運用モデルを構築する上で欠かせない要素である。エンゲージメントを維\n持するためには、ユーザーが継続してアプリを利用したくなるような仕組みを提供する必要がある。具体的には、\nゲーミフィケーション要素をさらに強化し、ユーザーが運動を続けるモチベーションを高める設計が求められる。\n達成した目標や収集したスタンプをSNS でシェアする機能を導入し、ユーザー同士の交流を促進することが効果\n的である。また、定期的に新しいチャレンジやイベントを開催し、飽きの来ない体験を提供することで、アクティ\nブユーザーを維持することができる。さらに、ユーザーからのフィードバックを積極的に収集し、それを基にサー\nビスを改善することで、利用者の期待に応えることが可能となる。社会的インパクトを考慮した運用モデルの構\n築も重要である。アプリを通じて健康促進や地域活性化を支援する仕組みを取り入れることで、社会的価値を提\n供し、ユーザーや地域社会からの支持を得ることができる。アプリ内で収集したスタンプを地域通貨やエコポイ\nントに交換できる仕組みを導入することで、地域経済や環境保護への貢献を促進することができる。また、特定\nの条件を達成することで寄付やチャリティ活動に参加できる機能を提供することで、社会的意識の向上と運動の\n推進を同時に実現することが可能となる。技術的な側面では、アプリの運用を効率化し、コストを抑えるための\nインフラ整備が不可欠である。クラウドベースのシステムを活用し、スケーラブルで安定したプラットフォーム\nを構築することで、多数のユーザーが利用してもシステムが安定して動作する環境を提供することができる。ま\nた、データの収集と解析を効率化するためにAI 技術を導入し、ユーザー行動の予測やパーソナライズされたサー\nビスの提供を可能にすることで、アプリの価値をさらに高めることができる。これに加え、セキュリティ対策を\n強化し、ユーザーデータの保護を徹底することで、信頼性の高いサービスを提供することが求められる。最後に、\n持続可能な運用モデルを実現するためには、長期的な視野に立った戦略的な計画が必要である。市場動向やユー\nザーニーズの変化を常に把握し、それに応じて柔軟にアプローチを調整することが重要である。また、地域や国ご\nとの特性に対応するため、ローカライズされた運用モデルを導入し、各地域のニーズに応じたサービスを提供す\nることで、グローバルな展開を成功させることが可能となる。このように、収益性、ユーザーエンゲージメント、\n42\n社会的インパクトを統合的に考慮した持続可能な運用モデルの構築は、運動促進アプリケーションが長期的に成\n長し、社会的価値を提供し続けるための鍵となる。\n43\n謝辞\n本研究を進めるにあたって終始あたたかく丁寧な相談、ご指導を戴いた青山学院大学情報テクノロジー学科\nGuillame Lopez 教授に深く感謝申し上げます。青山学院大学理工学部情報テクノロジー学科木村　正子助手には\n研究時に突き当たった問題の解決にあたり、多くの助言をしていただいたことに感謝を申し上げます。また研究を\n進めるにあたり様々な意見を交換して下さったロペズ研究室の皆様に深く感謝いたします。\n2025 年1 月31 日\n井村　和樹\n44\n関連図書\n[1] WHO 身体活動、座位活動ガイドライン2024\n[2] 厚労省: 健康づくりのための身体活動・運動ガイド2023\n[3] Pokemon Pocket:https://www.pokemontcgpocket.com/ja/\n[4] Peloton:https://www.onepeloton.com/\n[5] wellable: https://www.wellable.co/\n[6] strava:https://www.strava.com/\n[7] 高強度抵抗運動と荷重負荷運動を組み合わせたトレーニングは閉経後低密度女性の骨密度と身体機能を改善す\nる: Steven L Watson, Benjamin K Wels, Amy T Harding, Sean A Horan, Belinda R Beck.Journal of Bone\nand Mineral Research, Vol. 33, No. 2, 2018, pp 211–220\n[8] 青木邦男: 運動の不安軽減効果及びうつ軽減効果に関する文献研究. 山口県立大学大学院論集第3 号2002 年\n[9] 「スポーツエールカンパニー2021」認定企業の取組事例\n[10] 大谷隼, 木川修一: フィットネスバイクの利用に対して内的動機づけを図る仮想スタンプラリーシステムの評\n価. 情報処理学会第76 回全国大会講演集文集\n[11] 田口凌, 木下雄一郎: 寄り道促進アプリケーションを用いたウェルビーイング向上の仕組み. 日本感性工学会春\n季大会2024\n[12] Mitesh S,Dylan S,Joseph D,zMichael P. Patel:Eﬀectiveness of Behaviorally Designed Gamiﬁcation Interven-\ntions With Social Incentives for Increasing Physical Activity Among Overweight and Obese Adults Across\nthe United States: The STEP UP Randomized Clinical Trial2019\n[13] Professional Esports Players: Motivation and Physical Activity Levels\n[14] Volkswagen:The fun theory\n[15] Mark Hammer:Dose-response relationship between physical activity and mental health: the Scottish Health\nSurvey.2009 British Journal of Sports Medicine\n[16] スモールステップ方略が目標達成に及ぼす影響ースケーリング・クェスチヨンを用いたスモールステップ方\n略の提案ー: 瀧川佳苗, 鈴木俊太郎.Annual Leters of Clinical Psychology in Shinshu 2016 No.15 pp.23 34\n45\n第7章\nQ&A\nチャクラボルティ　シュデシナ　情報テクノロジー学科　助教\nQ\n現状既にある様々なアプリ（ポイントが貯まったり、ゲームだったり等）とどう違\nうのでしょうか？\nA\nご質問ありがとうございます．既存研究や既存のアプリケーションと比較し本研\n究は、心理的負担を軽減する要素を分析し寄り道やスタンプラリーのようなゲーミ\nフィケーションの要素をより重視し心理的負担を軽減することによって既存のアプ\nリケーションよりもより運動を継続しやすくしている点に違いがあります.\n46\n",
        "chunks": [
            "M2024_imura. M2024_imura. M2024_imura",
            "青　　山　　学　　院　　大　　学\n理　　工　　学　　研　　究　　科\n理工学専攻　　　知能情報　　　　　コース\n修　　士　　論　　文\n　　　　　　　学 生 番 号　　　　　35622202　　　　　　　　\n　　　　　　　氏 　 　 名　　　　　井村　和樹　　　　　　　\n研究指導教員　　　　ロペズ　ギヨーム　　　　 \n \n理工学専攻修士論文要旨 \n \n \n： 2024年度 \n： 2025年　1月　31日 \n専修コース：　知能情報　コース \n： 35622202 \n： 井村　和樹 \n研究指導教員： ロペズ　ギヨーム　教授 \n \n（論文題目）社会経済ニーズに応えるランニングアプリとスタンプラリー融合型運動促進システムの\n設計と社会調査に対する結果と課題 \n \n（内容の要旨） \n　健康とは、身体的、精神的、社会的に完全に良好な状態を指し、単に病気や虚弱でないことではな\nいと世界保健機関（WHO）は定義している。この定義に基づき、健康を維持するためには適切な食事、\n十分な睡眠、そして運動習慣が健康において重要である。しかし、日本では多くの人々が運動不足に\n悩んでおり、それが健康問題を引き起こす一因",
            "おいて重要である。しかし、日本では多くの人々が運動不足に\n悩んでおり、それが健康問題を引き起こす一因となっている。これらの健康リスクは個人の生活の質\nを低下させるだけでなく、医療費の増加や労働生産性の低下といった社会的コストももたらす。こう\nした背景の中で、運動不足の解消に向けた取り組みが進行しており、地方自治体や企業による健康増\n進プログラム、テクノロジーを活用した運動量の記録システムが注目されている。本研究では、運動\n不足の現状とその要因に焦点を当て、運動習慣の形成を促進するための効果的な方法を検討する。 \n　具体的にどのようなことが求められているか理解するために、社会調査を行なった結果を行なっ\nた。社会調査では20人の大学生の男女にアンケート方式で社会調査を行なった。そしてスタンプラ\nリー形式と心理的負担の関係「小さな目標が心理的負担を軽減する」と「スタンプラリー形式が心理\n的負担を軽減する」には強い正の相関（0.736）が見られた。先行研究と同様に、進捗の可視化、段階\n的な達成感、報酬感等を提供するフィードバックの仕組みは、心理的負担を軽減する効果が見込め\nる。特に運動初心者に",
            "、報酬感等を提供するフィードバックの仕組みは、心理的負担を軽減する効果が見込め\nる。特に運動初心者には有効で、継続率の向上に寄与する調査結果となった。一方、「長期的な運動\n目標への心理的負担軽減」と「運動経験」には弱い負の相関（-0.191）があり、経験者はスタンプラ\nリーの効果をあまり必要としないことが示唆された。運動経験者は、自身で運動に対する目標を発見\nしやすく、より高度で競技要素の強い目標設定や内発的動機を強化する仕組みが求められていること\nが考えられる。 \n今回の研究において社会調査の結果から多くの人々が運動不足に直面しつつも継続的な運動を難しいと感\nじていることが明らかになった。その主な要因として、運動の単調さや達成感の欠如、さらに運動成果が短期間\nでは見えにくいことによるモチベーション低下が挙げられる。これらの課題に対応するため、本研究では、運動\nを楽しくするためのゲーム的要素としてスタンプラリー機能を取り入れることを提案した。具体的には、以下の３\nつの革新的な要素を統合するようなアプリケーションの設計を行った。 \n●​\n目標地点を訪れることでスタンプを獲得する仕組み \n",
            "るようなアプリケーションの設計を行った。 \n●​\n目標地点を訪れることでスタンプを獲得する仕組み \n●​\n運動成果を可視化するスコアシステム \n●​\n写真撮影による達成の記録 \nこれにより、運動を楽しさや挑戦感のあるものに変え、ユーザーのモチベーションを維持しやすく\nすることが期待できる。 \n \n​\n \n青山学院大学大学院理工学研究科 \n \n \nAcademic Year of 2024, Submitted on January 31st, 2025 \n \nGraduate School of Science and Engineering, Aoyama Gakuin University \n \nTitle: Design of a running app and stamp rally-integrated exercise promotion system that \nmeets socio-economic needs and the results and challenges of social surveys \n \nStudent Name: Kazuki Imura ",
            "s of social surveys \n \nStudent Name: Kazuki Imura  \nID Number: 35622202 \nDegree: Master of Engineering \nCourse: Intelligence and Information  \nThesis Advisor: Guillaume Lopez \n \nAbstract  \nThe World Health Organization (WHO) defines health as complete physical, mental, and social \nwell-being rather than merely the absence of disease or infirmity. Based on this definition, maintaining \nhealth requires an appropriate diet, sufficient sleep, and regular exercise. However, in Japan, many \npeople str",
            "ular exercise. However, in Japan, many \npeople struggle with a lack of physical activity. These health risks lower individuals' quality of life and \nimpose social costs, such as increased medical expenses and decreased labor productivity. This study \nfocuses on the current state of insufficient physical activity and its contributing factors, aiming to \nexplore effective methods for promoting exercise habits.　 \nA social survey targeting 20 university students was conducted to understand the needs",
            "ity students was conducted to understand the needs better. A \nstrong positive correlation (0.736) was observed between \"small goals reducing psychological burden\" \nand \"the stamp rally format reducing psychological burden.\" The stamp rally format, which provides a \nstep-by-step sense of achievement and reward, is expected to help reduce psychological burdens. It is \nparticularly effective for beginners, increasing the exercise adherence rate. However, a weak negative \ncorrelation (-0.191) was fo",
            "ever, a weak negative \ncorrelation (-0.191) was found between \"reduced psychological burden toward long-term exercise goals\" \nand \"exercise experience,\" suggesting that experienced individuals benefit less from stamp rallies. \nIndeed, experienced exercisers can set their own exercise goals more efficiently and may benefit more \nfrom systems that emphasize advanced and competition-driven objectives. \nThe social survey has revealed that while many people lack physical activity, they struggle to ma",
            "people lack physical activity, they struggle to maintain \nconsistent exercise habits. The primary factors contributing to this challenge include the monotony of \nexercise, a lack of a sense of accomplishment, and decreased motivation due to the inability to see \ntangible results in the short term. To address these issues, this study proposes an exercise promotion \napplication design incorporating a gamified element—a stamp rally function—to make exercise more \nenjoyable. Specifically, the applic",
            "exercise more \nenjoyable. Specifically, the application integrates innovative elements such as a system where users earn \nstamps by visiting target locations, a scoring system that visualizes exercise achievements, and a photo \nfunction for recording accomplishments. This approach aims to sustain user motivation and encourage \nconsistent participation by transforming exercise into an engaging and goal-oriented activity. \n \n目次\n第1 章\n研究背景\n6\n1.1\n日本人の健康と運動習慣. . . . . . . . . . . . . . . . . . . . . .",
            "健康と運動習慣. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n6\n1.2\n日本人の運動習慣の歴史的背景\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n6\n1.3\nエンターテインメントのデジタル化. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n7\n1.4\n筋力と骨密度の向上\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n8\n1.5\n体重管理と代謝の活性\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n9\n1.6\nストレス軽減とリラクゼーション",
            " . . . . . . . . . . . . . .\n9\n1.6\nストレス軽減とリラクゼーション. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n10\n1.7\n気分改善と鬱症状の軽減. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n11\n1.8\n社会的繋がりの強化\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n11\n1.9\n自己効力感の向上. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n12\n1.10 ゲーミフィケーション\n. . . . . . . . . . . . . . . . . . . . . . . . . .",
            " . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n13\n第2 章\n関連研究\n15\n2.1\nフィットネスバイクの利用に対して内発的動機づけを図る仮想スタンプラリーシステムの評価. . .\n15\n2.2\n寄り道促進アプリケーションを用いたウェルビーイング向上の枠組み\n. . . . . . . . . . . . . . . .\n15\n2.3\nEﬀectiveness of Behaviorally Designed Gamiﬁcation Interventions With Social Incentives for In-\ncreasing Physical Activity Among Overweight and Obese Adults Across the United States: The\nSTEP UP Randomized Clinical Trial.\n. . . . . . . . . . . . . . . . . . . . . . . . . ",
            ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n16\n2.4\nProfessional Esports Players: Motivation and Physical Activity Levels . . . . . . . . . . . . . . .\n16\n2.5\nThefuntheory.com\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n16\n2.6\nPiano Staircase . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n17\n2.7\nThe World’s Deepest Bin\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .",
            " . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n18\n2.8\nBottle Bank Arcade Machine\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n18\n2.9\nThe Green Light for Green Behaviour\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n20\n2.10 運動頻度と精神的ストレスの関係. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n20\n2.11 ランニングの魅力が形成されるプロセス\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n21\n第3 章\n社会背景調査\n23\n3.1\n社会背景調査目的. . ",
            ". . . . . . . .\n21\n第3 章\n社会背景調査\n23\n3.1\n社会背景調査目的. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n23\n3.2\n調査対象. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n23\n3.3\n分析手法. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n24\n3.4\nランニングの頻度について. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n24\n3.5\nランニングの心理的負荷. . . . . . . . . . . . .",
            " . . .\n24\n3.5\nランニングの心理的負荷. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n25\n3.6\n性別間のランニング頻度の差. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n25\n3.7\nスタンプラリー形式の効果. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n27\n3.8\n運動経験者に対するスタンプラリーの効果. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n28\n4\n第4 章\nランニングアプリとスタンプラリー融合型運動促進システムの設計\n29\n4.1\nアプリの概要. . . . . . . . . . . . . . . . . . . . . . . . . . . ",
            ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n29\n4.2\nスタンプラリー機能について. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n30\n4.3\nスタンプや配点の基準の設計. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n30\n4.4\nスタンプや配点の技術設計. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n30\n4.5\n社会的意義におけるスタンプラリー機能の影響と可能性. . . . . . . . . . . . . . . . . . . . . . . .\n31\n第5 章\n結論\n33\n5.1\n研究の背景と課題の明確化. . .",
            " . . . . . . .\n31\n第5 章\n結論\n33\n5.1\n研究の背景と課題の明確化. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n33\n5.2\nスタンプラリー機能による運動促進の提案. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n33\n5.3\n課題. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n33\n第6 章\n今後の展望\n34\n6.1\nパーソナライズとAI 技術の統合\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n34\n6.2\nゲーミフィケーションのさらなる深化. . . . . . . . . . . . . . . . . . . . ",
            "ションのさらなる深化. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n35\n6.3\n地域との連携強化. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n36\n6.4\n社会的包摂を目指した機能追加\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n37\n6.5\n環境意識を高める仕組みの導入\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n37\n6.6\nクロスプラットフォーム展開と他サービスとの統合. . . . . . . . . . . . . . . . . . . . . . . . . .\n38\n6.7\n学習要素の追加. . . . . . . . . . . . . . .",
            " . . .\n38\n6.7\n学習要素の追加. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n39\n6.8\nグローバル展開. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n40\n6.9\nデータ解析による継続的な改善\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n41\n6.10 持続可能な運用モデルの構築. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n42\n第7 章\nQ&A\n46\n5\n第1章\n研究背景\n1.1\n日本人の健康と運動習慣\n初めに健康とは何かについて、世界保健機関（WHO）憲章では、「健康とは、身体的、精神的、",
            "と運動習慣\n初めに健康とは何かについて、世界保健機関（WHO）憲章では、「健康とは、身体的、精神的、社会的に完全\nに良好な状態を指し、単に病気や虚弱でないことではない」と定義されている。この定義に基づけば、健康を維\n持するためには、適切な食事、十分な睡眠、そして運動習慣が重要である。しかしながら、日本においては、多\nくの人々が日常的に運動を行っておらず、これが健康問題を引き起こす一因となっている。日本生命保険相互会社\nが実施したアンケート調査によれば、運動不足の理由として「忙しくて時間がない」と回答した人が約50 パーセ\nントにのぼる。この結果は、現代の多忙な生活スタイルが運動習慣の形成を妨げていることを示唆している。ま\nた、同調査では、週に1 回以上運動している人は全体の約30 パーセントに過ぎないという結果も得られており、\n日本人の運動習慣が十分ではないことが明らかである。WHO 身体活動、座位活動ガイドライン[1] によると、健\n康維持および疾病予防のために、以下の運動が推奨されている。具体的な推奨量としては中等度の有酸素運動を週\n150～300 分、または高強度の有酸素運動を週",
            "いる。具体的な推奨量としては中等度の有酸素運動を週\n150～300 分、または高強度の有酸素運動を週75～150 分行うことが推奨されている。運動不足は、個人の健康に\n深刻な影響を及ぼす。例えば、運動不足は肥満、糖尿病、心血管疾患などの慢性疾患のリスクを高める。さらに、\n高齢者においては筋力低下や骨密度の減少を引き起こし、転倒や骨折のリスクが増加することが報告されている。\nこれらの健康リスクは、個人の生活の質を低下させるだけでなく、医療費の増加や労働生産性の低下といった社会\n的コストをもたらす。一方で、運動不足の解消に向けた取り組みにおいてテクノロジーの活用も注目されており\nウェアラブル端末の普及に伴い、ＰＨＲ（パーソナル・ヘルス・レコード）等のＩＣＴを活用したサービスの拡\n充など、自身の健康情報を入手・活用できる環境の整備が急速に進んでいる[2]。本研究では、日本人の運動不足\nの現状を詳細に検討し、その要因と影響を明らかにすることを目的とする。さらに、運動習慣の形成を促進する\nための効果的な介入方法についても議論する。具体的には、生活の中で手軽に実践可能な運動プログラムの設計、\nそし",
            "果的な介入方法についても議論する。具体的には、生活の中で手軽に実践可能な運動プログラムの設計、\nそしてテクノロジーの活用による動機付け手法の可能性を検討する。運動習慣の形成は、個人の健康を向上させ\nるだけでなく、社会全体の医療費削減や生産性向上にも寄与する。本研究の成果が、持続可能な健康政策の策定\nや実行に資することを期待する。\n1.2\n日本人の運動習慣の歴史的背景\n日本における運動習慣の変遷を理解するためには、その歴史的背景を考察することが不可欠である。近代以前\nの日本社会においては、日常生活における身体活動が不可欠な要素であった。農村部では農作業や漁業が主要な産\n業として営まれ、都市部においても徒歩や人力車が主要な移動手段として用いられていた。これらの生活様式に\nより、日常的な身体活動量は確保されており、現代における「運動不足」に相当する概念は存在していなかった。\nしかし近代化に伴い徐々に日常的な運動の機会は減少していった。そして世界的なパンデミックにより、リモート\nワークが普及し労働形態の大規模な変化が生じた。徒歩移動の機会が減少し、職業における身体活動量もさらに\n低下した。これ",
            "働形態の大規模な変化が生じた。徒歩移動の機会が減少し、職業における身体活動量もさらに\n低下した。これにより、従来の生活に比べてより一層自然な身体活動は減少し、運動を意図的に取り入れる必要\n性が増加した。身体活動を必要としない生活様式が一般化した現代ではSNS やオンラインコンテンツの普及によ\nり、外出をしなくても様々な経験をすることが可能になった。こうした歴史的な生活様式の変遷は、現代の日本社\n会における運動不足の問題に直結している。労働環境の変化、生活スタイルの変容、さらにはデジタル技術の発\n展に伴う利便性の向上が、身体活動量のさらなる減少をもたらし、運動不足が健康問題として顕在化する要因と\nなっている。\n6\n1.3\nエンターテインメントのデジタル化\nさらに最新のデジタル社会では、エンターテインメントのデジタル化が身体活動量に大きな影響を及ぼしてい\nる。具体的には、Netﬂix やAmazon Prime Video などのストリーミングサービスの普及により、自宅で映画やド\nラマを長時間視聴することが一般化している。\n図1.1: Netﬂix\nまた、YouTube やTikTok の",
            "間視聴することが一般化している。\n図1.1: Netﬂix\nまた、YouTube やTikTok のような動画共有プラットフォームの利用も急増しており、これらに費やす時間は\n大幅に増加している。これらのサービスは、時間や場所を問わずアクセス可能であるため利便性は高いが、結果的\nに座りっぱなしのライフスタイルを助長する傾向がある。加えて、ゲーム分野でも家庭用ゲーム機のPlayStation\nやXbox、PC 向けプラットフォームのSteam、さらにはスマートフォン向けの「Poke Poke」[3] や「原神」など、\n多様なゲームが提供されている。これらのゲームの多くはオンラインでのプレイを前提としており、長時間にわ\nたり座ったまま画面に集中することが一般的である。一方で、身体を動かすゲームも登場しており、「Ring Fit\nAdventure」（Nintendo Switch）や、VR を活用した「Beat Saber」などが注目を集めている。しかし、これらの\n身体活動を伴うゲームは主流とは言えず、一般的なゲームに比べて利用者数は限られている。ソーシャルメディ\nアもまた、エンターテインメ",
            "は言えず、一般的なゲームに比べて利用者数は限られている。ソーシャルメディ\nアもまた、エンターテインメントのデジタル化における主要な存在である。Instagram、Facebook、X(Twitter)\nといったプラットフォームは、人々が情報を共有し、他者とつながる場を提供している。そしてそのユーザー数\nは年々増加している。しかし、それらの使用時間が長引くほど、身体活動が制限されるという課題が浮き彫りに\nなっている。さらに、TikTok のような短い動画形式のサービスは、コンテンツの消費が容易であり、次々に新し\nい動画を視聴する「無限スクロール」の仕組みにより、時間を忘れて没入しやすい。一方で、近年注目されてい\nるメタバースの発展も、デジタルエンターテインメントにおける重要な動向である。メタバースプラットフォー\nムとして代表的なものには、Meta（旧Facebook）が提供する「Horizon Worlds」、Epic Games の「Fortnite」、\nVRChat、Roblox などがある。これらの仮想空間では、ユーザーがデジタルアバターを介して他者と交流し、会\n議、ゲーム、ショッ",
            "がある。これらの仮想空間では、ユーザーがデジタルアバターを介して他者と交流し、会\n議、ゲーム、ショッピングなど多岐にわたる活動を行うことができる。しかし、メタバース内での活動はほとんど\nの場合、座った状態や立ったままでの最小限の動きに留まり、日常的な身体活動にはつながりにくい。メタバース\nは、職場や教育の場でも利用され始めている。例えば、「Horizon Workrooms」[?] を使用した仮想会議は、従来\nのオフィスワークをデジタル空間に移行する試みとして注目されている。また、教育分野ではRoblox が仮想空間\nを利用した学習体験を提供している。しかし、これらの利便性や創造性の向上は歓迎される一方で、身体活動の\n欠如が新たな問題として浮上している。このように、エンターテインメントのデジタル化とメタバースの発展は、\n現代社会に多くの利便性と魅力をもたらしているが、同時に身体活動不足という大きな課題を生んでいる。この\n7\n問題に対処するためには、ウェアラブルデバイスやオンラインフィットネスサービスなどを活用し、デジタル技術\nと身体活動を組み合わせた新しい取り組みが必要である。Pelo",
            "ネスサービスなどを活用し、デジタル技術\nと身体活動を組み合わせた新しい取り組みが必要である。Peloton[4] のようなインタラクティブな運動プログラム\nや、身体を動かすゲームをメタバース内に取り入れる試みがその一例である。また、AR（拡張現実）技術を用い\nて日常生活に運動を組み込むアプローチも有望視されている。エンターテインメントのデジタル化は不可逆的な\n進展を遂げているが、社会全体で運動の重要性を再認識し、デジタルと身体活動の調和を目指す取り組みが求め\nられている。特に、これからの社会においては、運動不足がもたらす健康への影響を軽減しながら、デジタル技\n術を有効活用する方法を模索する必要がある。まず、教育現場では、子どもたちに運動の重要性を認識させるた\nめのデジタルツールが有効である。例えば、AR（拡張現実）やVR（仮想現実）を活用した教育用ゲームは、身\n体を動かしながら学習を行う新しいアプローチとして注目されている。これにより、運動が単なる体育の授業に\nとどまらず、日常的な習慣として定着する可能性が高まる。学校に導入されている例として、デジタルフィットネ\nスプログラム「Clas",
            "して定着する可能性が高まる。学校に導入されている例として、デジタルフィットネ\nスプログラム「ClassVR」や、動きながら課題を解決するインタラクティブな学習プラットフォームが挙げられ\nる。これらの取り組みを拡大することで、若年層の運動不足を解消する手段がさらに多様化するだ職場での健康維\n持を目的とした取り組みも重要である。だがこれらの取り組みは依然として実験段階である。だが企業レベルで\nはすでに実証されているものもある。テレワークが広がる中、従業員の健康を支援する企業向けデジタルツール\nが増加している。たとえば、ウェアラブルデバイスを用いて日々の歩数や運動量を可視化するプログラムや、リ\nモートワークの合間に短時間で行えるエクササイズを推奨するアプリが普及している。また、バーチャルフィット\nネスセッションやオンラインヨガクラスを取り入れることで、従業員が気軽に運動を取り入れられる環境が整い\nつつある。具体例として、企業向け健康プログラムを提供する「Wellable」や、フィットネスチャレンジを楽しむ\n「Strava」の活用が進んでいる。[5, 6] さらに、高齢者の健康をサポートするた",
            "ンジを楽しむ\n「Strava」の活用が進んでいる。[5, 6] さらに、高齢者の健康をサポートするためのデジタル技術も進化している。\n例えば、家庭で簡単に使えるデジタル運動機器や、専門家とリモートでつながるオンラインリハビリプログラム\nが人気を集めている。高齢者向けには、運動不足を解消しながら転倒リスクを軽減することを目的としたプログ\nラムが重要であり、フィットネスとゲームを組み合わせた「SilverSneakers GO」や、VR を活用して身体機能を\n維持する「VirtuCare」のようなサービスが注目されている。これらの技術は、高齢者に運動の楽しさと健康維持\nの重要性を再認識させる役割を果たしている。また、社会全体で運動を促進するためには、公共スペースや地域\nコミュニティでの取り組みも欠かせない。デジタル技術を活用して、住民が参加できるバーチャルマラソンやコ\nミュニティフィットネスチャレンジが広がりを見せている。このように、デジタルと身体活動の調和を目指す取り\n組みは、個人から地域、そしてグローバルな規模まで多岐にわたる。これらの活動が広がることで、持続可能な\n健康的社会の構築が",
            "、そしてグローバルな規模まで多岐にわたる。これらの活動が広がることで、持続可能な\n健康的社会の構築が現実味を帯びてくるだろう。最終的には、デジタル技術を通じて運動を「負担」ではなく「楽\nしみ」として位置づけることが鍵となっているので、実情について調査する必要がある。\n1.4\n筋力と骨密度の向上\n筋力トレーニングは、筋肉量と骨密度の増加に重要な役割を果たす運動であり、あらゆる年齢層にとって多くの\n健康上のメリットを提供する。特に高齢者においては、筋力と骨密度の維持は転倒や骨折のリスクを軽減し、生活\nの質（Quality of Life; QOL）を向上させるために極めて重要である。筋力トレーニングは、筋肉に負荷をかける\nことで筋線維を刺激し、筋肥大（筋肉量の増加）を促進する運動である。この過程では、筋線維に微細な損傷が\n生じ、それを修復する際に筋肉がより強く成長する仕組みが働く。これにより、日常生活で必要とされる筋力が向\n上し、重い荷物を持つ、階段を上るといった基本的な活動が容易になる。また、筋力トレーニングは基礎代謝を\n向上させる効果もある。筋肉量が増えることで体内のエネルギー消費量が",
            "た、筋力トレーニングは基礎代謝を\n向上させる効果もある。筋肉量が増えることで体内のエネルギー消費量が高まり、肥満や生活習慣病の予防にも\n寄与する。このため、筋力トレーニングは中高年層にとっても若年層にとっても有益な運動である。骨密度の維\n持と向上は、骨粗しょう症の予防において非常に重要である。骨粗しょう症は骨が脆くなる疾患で、特に閉経後\nの女性や高齢者に多く見られる。この疾患は骨折のリスクを大幅に増加させ、寝たきりや要介護状態の原因とな\nることが多い。筋力トレーニングは、骨に機械的な負荷を与えることで骨形成を促進する。骨は、負荷がかかる\nと骨細胞が活性化し、骨密度が高まるという特性を持つ。たとえば、スクワットやデッドリフトといったウェイ\nトトレーニングは、大腿骨や脊椎など、骨折リスクが高い部位の骨密度向上に効果的であることが報告されてい\n8\nる[7]。また、高強度のレジスタンストレーニング（HRT）は、骨密度を増加させるだけでなく、骨の構造そのも\nのを強化する可能性がある。高齢者における転倒は、骨折や寝たきりの主要な原因である。筋力トレーニングは、\n下肢筋力を向上させることで転倒リスク",
            "転倒は、骨折や寝たきりの主要な原因である。筋力トレーニングは、\n下肢筋力を向上させることで転倒リスクを軽減する。具体的には、大腿四頭筋や腓腹筋などの下肢筋肉が強化さ\nれることで、バランス能力が向上し、不安定な地面でも安定して歩行する能力が高まる。さらに、筋力トレーニ\nングは反射神経や柔軟性の向上にも寄与し、転倒を未然に防ぐための身体能力を強化する。転倒予防プログラム\nの一環として筋力トレーニングを取り入れることは、多くの医療機関や自治体で推奨されており、その効果が広\nく認知されている。閉経後の女性は、エストロゲン分泌の減少に伴い、急激な骨密度の低下を経験する。このた\nめ、骨粗しょう症リスクが高まる傾向がある。筋力トレーニングは、骨密度の低下を抑えるだけでなく、筋肉を\n強化することで骨にかかる負荷を適切に分散させ、骨折の予防に役立つ。加えて、筋力トレーニングは女性の姿\n勢改善にも寄与する。姿勢が良くなることで骨の配列が正しく保たれ、骨への過度なストレスを軽減できる。ま\nた、腰痛の予防や体型維持という観点でも、女性にとって筋力トレーニングは非常に効果的な運動である。中高\n年層では、加齢に伴",
            "維持という観点でも、女性にとって筋力トレーニングは非常に効果的な運動である。中高\n年層では、加齢に伴い筋肉量と骨密度が自然に減少する。この減少はサルコペニアと呼ばれ、特に何も対策を取\nらない場合、運動能力が大幅に低下するリスクがある。このため、筋力トレーニングは中高年層にとって不可欠\nな運動といえる。中高年層向けの筋力トレーニングには、安全性を考慮した低負荷・高頻度の運動が適している。\nたとえば、自重を利用したスクワットや軽いダンベルを用いた運動は、筋肉と骨に適度な刺激を与えると同時に、\n怪我のリスクを低減する。筋力と骨密度の向上を目的としたトレーニングは、個人の健康維持だけでなく、社会\n全体の医療費削減にも寄与する可能性がある。転倒や骨折の予防に成功すれば、医療費の増加を抑制でき、介護\nに必要な社会的コストも削減できる。自治体や企業が筋力トレーニングを推奨し、普及させるための取り組みを\n行うことは、国民全体の健康水準を向上させる重要な手段である。\n1.5\n体重管理と代謝の活性\n運動は、体重管理において非常に効果的な手段とされています。定期的な運動を行うことによって、カロリー消\n費が増",
            "体重管理において非常に効果的な手段とされています。定期的な運動を行うことによって、カロリー消\n費が増加し、基礎代謝が向上するため、健康的な体重を維持するのに役立ちます。カロリー消費の増加は、運動に\nよるエネルギー消費の直接的な効果だけでなく、運動後における「アフターバーン効果」として知られる現象にも\n関係している。これは運動後に筋肉が回復するためにエネルギーを消費し続ける現象であり、これにより脂肪燃焼\nが長時間継続することが期待できる。これにより、日常的な運動習慣を維持することが、長期的に見て体重管理\nにおいて重要な役割を果たす。体重管理が重要である理由は、肥満が引き起こすさまざまな健康リスクを未然に\n防ぐためである。肥満は2 型糖尿病、心臓病、脂質異常症、高血圧、そして一部のがんのリスクを増加させるこ\nとが知られている。これらの疾患は、いずれも生活習慣病の一部であり、体重の過剰な増加が直接的に関与して\nいるため、肥満を予防し適切な体重を維持することは、これらの疾患の発症リスクを低減し、全体的な健康状態\nを改善するために極めて重要である。また、体重管理をすることは、生活の質を向上させる",
            "全体的な健康状態\nを改善するために極めて重要である。また、体重管理をすることは、生活の質を向上させるだけでなく、老後の健\n康維持にも大きく寄与する。適切な体重を維持することにより、日常的な活動が容易になり、体力の低下を防ぎ、\n健康寿命を延ばすことが可能になる。運動は、体重を維持するために不可欠な要素であり、特に有酸素運動と筋\n力トレーニングを組み合わせた運動が推奨されている。有酸素運動（例：ジョギング、ウォーキング、サイクリン\nグ）は、脂肪を効率的に燃焼させ、エネルギー消費を高めるため非常に有効な方法である。特に、週に150 分以\n上の中強度の有酸素運動を行うことが、体重減少に寄与することが複数の研究で示されている[1]。さらに、筋力\nトレーニングは、筋肉量の維持および増加を促進することで、基礎代謝率を向上させ、運動後のエネルギー消費\nを増加させる役割を果たし、筋肉量が増えると、安静時でもエネルギー消費が高くなるため、基礎代謝の向上が\n期待できる。代謝は、体内でのエネルギーの消費と変換を指し、基礎代謝は安静時に消費されるエネルギー量を\n表している。定期的な運動は基礎代謝を向上させること",
            "指し、基礎代謝は安静時に消費されるエネルギー量を\n表している。定期的な運動は基礎代謝を向上させることが知られており、これにより脂肪がより効率的に燃焼さ\nれるようになり、筋肉の増加は脂肪と比較するとエネルギーを多く消費するため、筋肉量を増やすことが長期的\nな体重管理において重要な要素である。運動が引き起こす代謝の活性化は、運動後にも持続し脂肪燃焼が長時間\nにわたって続いていくため、高強度インターバルトレーニング（HIIT）は、短時間で高いカロリー消費を促進し、\n代謝を効率的に向上させることが示されている。このようなトレーニングは、体脂肪を減少させ、筋肉量を維持\n9\nするのに非常に有効である。体重管理において運動を実践することは、食事だけに頼るダイエットとは異なりよ\nり健康的で持続可能な方法である。食事制限による急激な体重減少は、筋肉の減少や基礎代謝の低下を引き起こ\nす可能性があり、リバウンドの原因となる。一方、運動は筋肉量を維持しながら脂肪を減少させるため、体重管理\nをより安定的に行うことができ、また運動を定期的に行うことで、食事に対する意識が改善され、過食を防ぐた\nめの自己管理能力が高",
            "ができ、また運動を定期的に行うことで、食事に対する意識が改善され、過食を防ぐた\nめの自己管理能力が高まる。運動と食事のバランスをとることで、より健康的な体重を維持することができ、肥\n満による健康リスクを軽減することが可能となる。体重管理を維持するためには、運動習慣を生活の一部として\n取り入れることが重要です。定期的な運動は、カロリー消費を高めるだけでなく、心身の健康を促進する効果もあ\nります。運動によって分泌されるエンドルフィンは、ストレスの軽減や気分の向上を助け、過食の予防にもつなが\nる。さらに、運動は、心理的な側面においてもポジティブな影響を与えることが多く、ストレスや不安を軽減し、\n精神的な健康を維持するための重要な手段となる。運動は、単に体重を減少させるだけでなく、基礎代謝を向上\nさせるため、健康的な体重維持には不可欠な要素である。生活の質を高め、将来的な健康リスクを減少させるこ\nとが重要である。\n1.6\nストレス軽減とリラクゼーション\n運動は、現代社会においてストレス管理の有効な手段として広く認識されている。特に、身体活動はストレスホ\nルモンであるコルチゾールの分泌を抑制し、",
            "な手段として広く認識されている。特に、身体活動はストレスホ\nルモンであるコルチゾールの分泌を抑制し、同時にエンドルフィンと呼ばれる気分改善物質の分泌を促進する作\n用があることが複数の研究で示されている。コルチゾールはストレス応答の一環として分泌されるホルモンであ\nり、一時的にはエネルギー供給や免疫活性化に寄与するが、長期的な過剰分泌は免疫機能の低下、睡眠障害、さら\nには心血管疾患のリスク増加をもたらす可能性が指摘されている。一方、運動を行うことでエンドルフィンが生成\nされると、脳内の快楽中枢が刺激され、自然な幸福感やリラクゼーション効果が得られる。このため、運動は身\n体的および精神的ストレスの軽減を図る上で、重要な役割を果たすといえる。有酸素運動は特にストレス軽減の\n効果が高いとされており、その一例としてウォーキング、ジョギング、サイクリング、ヨガなどが挙げられる。有\n酸素運動は心拍数を緩やかに上昇させ、血液循環を促進することにより、脳内への酸素供給を増加させる。この\n酸素供給の向上は、セロトニンやドーパミンといった神経伝達物質の分泌を促進し、気分の安定化や幸福感の向\n上に寄与すること",
            "セロトニンやドーパミンといった神経伝達物質の分泌を促進し、気分の安定化や幸福感の向\n上に寄与することが示されている。たとえば、20 分から30 分程度の中等強度のジョギングや、自然環境の中での\nウォーキングは、ストレスを軽減し、リラクゼーション効果をもたらす有効な手段であることが報告されている。\nさらに、運動は間接的にストレス軽減を促進する要因として、睡眠の質の向上にも寄与する。複数の研究によれ\nば、定期的な身体活動は深い睡眠を誘発し、睡眠障害を緩和する効果があることが明らかにされている。良質な\n睡眠はストレス管理において不可欠であり、身体的および精神的な回復をもたらす基盤である。たとえば、夕方\nに軽い運動を行うことで、一時的な体温上昇と運動後の体温低下がリラックス効果をもたらし、自然な睡眠につ\nながる。運動によるストレス軽減効果は個人の状況に応じて異なる場合がある。長時間のデスクワークによる身\n体的な緊張や精神的な疲労を感じているオフィスワーカーにとっては、短時間のストレッチや散歩が効果的であ\nる。一方で、強いストレスや不安を抱える場合には、中等強度のランニングやグループで行う運動が",
            "果的であ\nる。一方で、強いストレスや不安を抱える場合には、中等強度のランニングやグループで行う運動が、身体的なリ\nフレッシュに加えて社会的な交流機会を提供するため、さらなる効果が期待される[8]。運動の種類や強度を適切\nに選択することが、個人のストレス軽減において重要である。職場や教育機関においても、運動はストレス管理\nの手段として活用されている。いくつかの企業では、従業員の健康維持を目的に運動プログラムを導入しており、\nこれが職場の生産性や従業員満足度の向上に寄与している[9]。一方、学校では運動が生徒の集中力を高めるだけ\nでなく、心身の健康維持にも寄与している。短時間の体操やエクササイズであっても、継続的に行うことで、スト\nレス管理とパフォーマンス向上に効果があることが確認されている。最後に、運動は心理的側面にも良好な影響\nを及ぼす。身体活動を通じて達成感や自己効力感を得ることで、自尊心や自己肯定感が高まり、ストレス耐性が強\n化される。さらに、運動習慣を持つことで、自己管理能力が向上し、健康維持に対する自己のコントロール感が\n強化される。このような心理的効果は、ストレス軽減だけでな",
            "し、健康維持に対する自己のコントロール感が\n強化される。このような心理的効果は、ストレス軽減だけでなく、総合的なメンタルヘルスの向上にも寄与する。\n10\n1.7\n気分改善と鬱症状の軽減\n定期的な運動は、うつ病や不安障害の予防および改善に対して効果的であることが多くの研究によって明らか\nにされています。これらの精神的健康への影響は、身体的な変化のみならず、心理的および社会的な要因に基づく\nものであると考えられています。運動を行うことで自信や達成感が得られ、気分が向上するだけでなく、心理的ス\nトレスの軽減やポジティブな感情の増幅にも寄与します。このため、運動は心理的健康を維持し、改善するための\n重要な手段として広く認識されています。特に、運動は軽度から中等度のうつ病症状を抱える人々に対して有効で\nあり、治療法としても注目されています。米国精神医学会（APA）は、軽度から中等度のうつ症状に対する補助\n療法として運動を推奨しており、運動が従来の心理療法や薬物療法と補完的に作用する可能性があることを示し\nています。実際、研究では、定期的な運動がセロトニンやドーパミンといった神経伝達物質の分泌を促",
            "を示し\nています。実際、研究では、定期的な運動がセロトニンやドーパミンといった神経伝達物質の分泌を促進し、これ\nが脳内の神経回路の調整に寄与することで、うつ症状を軽減する効果が確認されています。有酸素運動や筋力ト\nレーニングは特に効果が高いとされており、これらの運動は脳内のストレス応答系を調整することで、心理的ス\nトレスを軽減する働きを持ちます。有酸素運動では、心拍数の上昇に伴ってエンドルフィンが分泌され、幸福感を\nもたらすことが知られています。一方、筋力トレーニングは身体的な強さの向上を通じて自己効力感を高める効\n果があり、これが精神的健康の改善につながります。例えば、週に3 回以上、30 分から1 時間程度の運動を行う\nことで、症状の軽減が期待できるとされています。また、運動には心理的な効果だけでなく、社会的な側面におい\nてもポジティブな影響があります。例えば、グループエクササイズやスポーツ活動を通じた社会的交流は孤独感を\n軽減し、社会的支援ネットワークの形成に寄与します。これにより、孤立感や疎外感が減少し、精神的健康が向上\nすることが示されています。特に、うつ症状を抱える人々にと",
            "、孤立感や疎外感が減少し、精神的健康が向上\nすることが示されています。特に、うつ症状を抱える人々にとって、他者との交流は自己肯定感の向上や回復意欲\nの増進に寄与する重要な要因となります。運動が気分改善に寄与する具体的なメカニズムには、神経可塑性の向\n上が挙げられます。運動により脳由来神経栄養因子（BDNF）の分泌が促進されることで、神経細胞の成長や再\n生が活性化されることが知られています。これが脳内の構造的および機能的変化をもたらし、うつ症状の緩和に\nつながるとされています。特に、海馬と呼ばれる記憶や感情調整に関与する脳領域において、この効果が顕著で\nあることが研究で示されています。さらに、運動は睡眠の質を向上させることを通じても気分改善に寄与します。\n睡眠障害はうつ病や不安障害の主な症状の一つであり、運動を行うことで深い睡眠が誘発され、睡眠の質が向上\nすることで、これらの症状が緩和されると考えられています。例えば、夕方に適度な運動を行うことで体温調節\nが改善され、その結果としてリラックス効果と良質な睡眠が得られることが知られています。さらに、運動はスト\nレスホルモンであるコルチゾール",
            "ス効果と良質な睡眠が得られることが知られています。さらに、運動はスト\nレスホルモンであるコルチゾールの分泌を抑制することで、心理的なストレスを軽減する役割も果たします。コ\nルチゾールの過剰分泌はうつ症状を悪化させる要因となるため、その分泌を抑えることは症状の管理において重\n要です。また、運動を通じて分泌されるエンドルフィンやセロトニンは、心理的な安定感や幸福感を促進するだけ\nでなく、ストレスへの対処能力を強化する効果も持っています。運動が精神的健康に与える影響は個人差があるも\nのの、その効果を最大限に引き出すためには、適切な運動プログラムの選択が重要です。軽度のうつ症状を持つ\n人々には、ウォーキングやヨガといった低強度の運動が適している一方で、中等度の症状を抱える人々にはジョギ\nングやダンスなどの中強度の運動が推奨されます。また、運動を長期間にわたって継続することが重要であり、こ\nれが気分改善効果の維持につながります。総じて、運動は気分改善やうつ症状の軽減において多面的な効果を持\nつ有効な手段であり、その実践は精神的健康の維持と向上に不可欠であるといえます。これらの効果は、身体的、\n心",
            "な手段であり、その実践は精神的健康の維持と向上に不可欠であるといえます。これらの効果は、身体的、\n心理的、社会的な側面を包括的に改善することで実現されるため、運動を日常生活に取り入れることが、健康的\nなライフスタイルの基盤となります。\n1.8\n社会的繋がりの強化\nグループでの運動やスポーツ活動は、個人の社会的ネットワークを広げ、仲間との交流や協力を促進すること\nで、社会的なつながりを深める効果があり、このような活動は、単に身体的健康を向上させるだけでなく、心理的\nおよび社会的な幸福感を高める重要な役割を果たしたいる。特に、運動を通じた社会的交流は、孤独感の軽減や\nストレス管理において大きな影響を与えることが多くの研究で示されている。\n11\n社会的なつながりは、メンタルヘルスの改善において重要な要素の一つであり、運動を通じて得られる他者と\nの交流は、心理的なサポートネットワークを形成し、自己肯定感や達成感を高める効果があります。例えば、チー\nムスポーツに参加することで、共同目標の達成に向けた協力やコミュニケーションが促進され、信頼関係や友情\nが築かれることがあり、このような経験は個人の社",
            "た協力やコミュニケーションが促進され、信頼関係や友情\nが築かれることがあり、このような経験は個人の社会的な絆を強化し、精神的な安定感をもたらすことに繋がり\n精神的な安定にもつながる。運動による社会的交流は、ストレスを軽減する効果もあり、ストレスを抱えている\n人々にとって、他者とのポジティブな交流は心の支えとなり、問題を共有しやすい環境を提供する。特に、グルー\nプエクササイズやスポーツ活動では、共同体験を通じて連帯感や安心感が生まれ、これがストレス管理や精神的\n健康の改善に寄与する。また、これらの活動に参加することで、孤独感や疎外感が改善し、社会的包摂感をえる\nことができる。\n運動を通じた社会的つながりは、年齢や性別を問わず、幅広い層にメリットをもたらす。例えば、高齢者にとっ\nては、地域コミュニティで行われる体操教室やウォーキンググループが孤立を防ぎ、精神的健康を維持する手助\nけとなり、学生や若者にとっては、学校のクラブ活動や地域のスポーツチームへの参加が、社会的スキルの向上や\n友人関係の構築する。これらの活動は、異なる背景を持つ人々との交流を促進し、多様性を尊重する姿勢を育む\n機会にも",
            "構築する。これらの活動は、異なる背景を持つ人々との交流を促進し、多様性を尊重する姿勢を育む\n機会にもなる。\nさらに、運動は職場においても社会的つながりを強化する手段として活用されています。多くの企業では、従業\n員の健康促進やチームビルディングを目的とした運動プログラムやスポーツイベントが導入されています。これ\nにより、従業員間のコミュニケーションが活発化し、職場の雰囲気が改善されるだけでなく、生産性の向上や職務\n満足度の向上にも寄与します。たとえば、ランニングクラブやヨガクラスに参加することで、部門や役職を超え\nた交流が生まれ、協力関係が強化されることがあります。\nまた、運動を通じた社会的交流は、地域社会全体にも影響を及ぼします。地域のスポーツイベントやマラソン大\n会は、地域住民が集まり、共通の目標に向かって活動する機会を提供します。これにより、地域の連帯感が強化さ\nれ、社会的な結束力が高まると同時に、地域全体の健康意識が向上します。こうしたイベントは、参加者同士の交\n流を促進するだけでなく、地域の活性化にも寄与します。\n運動による社会的つながりの効果は、心理的および社会的な側面にとど",
            "なく、地域の活性化にも寄与します。\n運動による社会的つながりの効果は、心理的および社会的な側面にとどまらず、健康行動の維持にも影響を与\nえます。グループでの運動は、個人のモチベーションを高め、継続性を促進する効果があります。仲間と一緒に活\n動することで、互いに励まし合い、目標に向かって努力する意欲が湧くため、運動習慣を長期的に維持しやすく\nなります。また、他者との交流を通じて、健康に関する情報やアドバイスを共有する機会が増え、より健康的なラ\nイフスタイルを追求する動機づけが強化されます。\nこのように、運動は身体的健康を向上させるだけでなく、社会的つながりを深める手段としても重要な役割を\n果たします。個人の健康と幸福感を向上させるだけでなく、地域社会や職場全体の活性化にも寄与する運動の価値\nは、ますます注目されています。運動を日常生活に取り入れることで、社会的なつながりを強化し、精神的および\n身体的健康の両面で豊かな生活を実現することが可能となります。\n1.9\n自己効力感の向上\n運動は、身体的な健康の向上だけでなく、心理的な自己効力感を高めるうえでも重要な役割を果たします。自己\n効力感と",
            "体的な健康の向上だけでなく、心理的な自己効力感を高めるうえでも重要な役割を果たします。自己\n効力感とは、自分自身の力で目標を達成できるという信念を指し、日常生活における成功や達成感に基づいて形\n成されます。運動を通じて目標を達成する経験は、自己効力感を向上させる強力な手段であり、その効果は他の生\n活領域にも良い影響を及ぼします。\n運動における目標設定とその達成は、自己効力感を高める最も直接的な方法の一つです。たとえば、5 キロの\nジョギングを完走する、筋力トレーニングで一定の回数を達成する、あるいはヨガの特定のポーズを習得するな\nど、運動における小さな目標を達成することで、自分自身の能力に対する信頼感が高まります。このような成功\n体験は、達成感をもたらすだけでなく、自分が努力すれば結果を出せるというポジティブな自己イメージを形成す\nる助けになる。さらに、運動による自己効力感の向上は、他の生活領域にも波及効果をもたらします。運動を通\nじて得られる成功体験は、仕事や学業、さらには人間関係においてもポジティブな影響を及ぼします。たとえば、\n12\n運動を通じて自分の目標を達成できたという感覚は",
            "いてもポジティブな影響を及ぼします。たとえば、\n12\n運動を通じて自分の目標を達成できたという感覚は、仕事や学業においても「挑戦を乗り越えられる」という自\n信につながり、意欲の向上や効率の改善に寄与します。また、運動による達成感は、ポジティブな自己イメージの\n構築をサポートし、精神的な安定感をもたらす。自己効力感が高まることで、人々はより積極的に健康的な行動を\n選択する傾向があり、運動により自己効力感が向上した人は、より健康的な食事を選び喫煙や過度な飲酒を控え\nるなど、健康維持に貢献する行動を志向するようになる。また、自己効力感の向上は、ストレスや困難な状況に\n対処する能力の向上にもつながり、レジリエンス（回復力）を高める効果がある。これにより、精神的な健康がさ\nらに向上し、人生全般における満足度が高まることが期待される。\n運動の成功体験は、特に長期的な目標に向けた意志力や忍耐力を養う助けにもなります。たとえば、トレーニン\nグプログラムに取り組む中で、小さな進歩を積み重ねる経験は、長期的な目標に向かって努力を継続する力を育む\nと同時に、忍耐力や計画性を強化し、このような特性は、運動以外",
            "な目標に向かって努力を継続する力を育む\nと同時に、忍耐力や計画性を強化し、このような特性は、運動以外の領域でも役立つ。仕事におけるプロジェク\nトの遂行や学業の課題への取り組みにおいても、運動で培った意志力が発揮される場合もある。\nまた、運動による自己効力感の向上は、精神的な幸福感にも寄与し、成功験を重ねることで、脳内の報酬系が\n刺激され、ドーパミンやセロトニンといった「幸福ホルモン」の分泌が促進されます。これにより、日常生活にお\nけるモチベーションが高まり、精神的な充実感が得られると同時に、ネガティブな感情を軽減する効果が期待され\nる。さらに、自己効力感が高まることで、他者とのポジティブな関係性を築く力も向上し、人間関係における満\n足感も高まる。運動はまた、自己効力感の形成において、社会的要素も重要な役割を果たす。たとえば、グループ\nでの運動やトレーニングに参加することで、他者からの励ましやフィードバックを受ける機会が増える。このよ\nうな社会的なサポートは、自己効力感を強化するうえで重要な要素とされています。たとえば、仲間と一緒に運\n動することで、目標達成に向けたモチベーションが高まり",
            "な要素とされています。たとえば、仲間と一緒に運\n動することで、目標達成に向けたモチベーションが高まり、達成感がさらに大きくなることが期待される。このよ\nうに、運動は自己効力感の向上を通じて、身体的および精神的な健康の向上に大きく貢献する。さらに、その効\n果は個人の生活全般に波及し、仕事や学業、社会生活におけるポジティブな変化をもたらす。運動を通じて得られ\nる自己効力感は、人生全般における幸福感を高め、充実した生活を実現する基盤となるものといえる。\n1.10\nゲーミフィケーション\nスマートフォンやゲーム機器の普及に伴い、ゲームの要素を他の領域に応用する「ゲーミフィケーション」が注\n目を集めています。ゲーミフィケーションとは、ゲームの特徴的な要素や仕組みを教育、医療、ビジネス、エクサ\nサイズなどの非ゲーム領域に取り入れることによって、ユーザーのシステムへの参加率や継続率を向上させる手\n法である。この手法は、ユーザーが自発的にシステムに参加したり、繰り返し利用したくなるような動機付けを\n高める効果があるため、様々な分野で積極的に活用され始めている。例えば、教育分野においては、学習管理シ\nステ",
            "効果があるため、様々な分野で積極的に活用され始めている。例えば、教育分野においては、学習管理シ\nステムにポイントやバッジを導入し、学生の学習意欲を高める取り組みが行われています。また、健康やフィット\nネス分野では、エクササイズにゲーム要素を加えることで、運動を楽しく続けられるようなシステムが多く開発\nされている。ゲーミフィケーションを用いたサービスの代表例として、Niantic, Inc. が開発した「Ingress」が挙\nげられる。Ingress は現実世界を舞台にした位置情報ゲームで、ユーザーが「エンライテンド」と「レジスタンス」\nという2 つのチームに分かれ、ポータルと呼ばれる設定された場所に移動し、陣取りを行うゲームである。この\nゲームでは、プレイヤーが実際に街中を歩き回り、指定されたポータルの場所に到達することで、ゲーム画面上に\n表示されるポータルをタップしてアイテムや経験値を取得することができ、このように位置情報を活用して現実\nの場所をゲームの舞台として利用することで、ユーザーがゲームに没入しやすくなり、同時に現実の世界を探索\nする楽しさも味わうことができる仕組みとなってい",
            "ーがゲームに没入しやすくなり、同時に現実の世界を探索\nする楽しさも味わうことができる仕組みとなっている。Ingress のリリース当初、現実世界に存在するモニュメン\nトやランドマークの写真を位置情報と共にNiantic, Inc. に送信し、それがポータルとして設定されるという審査\n機能がある。この仕組みによって、ユーザーが自分の身近な施設や特別な場所のランドマークなどの情報を大量\nに提供することが可能になり、Niantic, Inc. は利用者がよく訪れる場所や観光地の詳細な位置情報と画像を、大規\n模に集めることができ、このデータの収集は後に開発される位置情報ゲームの基盤となり、同社の次のプロジェク\nト「Pok´emon GO」にも大きな影響を与えました。Niantic, Inc. はこのデータを基に、The Pok´emon Company\nInternational、Google、任天堂の3 社から3000 万ドルの融資を受け、「Pok´emon GO」の開発した。ポケモンと\n13\nいう人気キャラクターと、現実世界での位置情報を活用したゲームプレイを組み合わせたこのゲームは、リリ",
            "\nいう人気キャラクターと、現実世界での位置情報を活用したゲームプレイを組み合わせたこのゲームは、リリー\nス直後から世界中で爆発的な人気を博し、ユーザーは現実世界を歩き回り、スマートフォンの画面上に出現するポ\nケモンを捕まえたり、アイテムを集めたりすることで、ポケモントレーナーとしての体験を味合うことができる\nように設計されている。このように、ゲーム要素を他分野に加えることで、ユーザーが自発的にシステムへ参加\nし、利用を継続させる仕組みを構築することが重要である。ゲームの報酬システムや競争要素、達成感を生む仕\n組みを適用することで、従来の枠を超えた新しい体験価値が生まれ、エンターテインメント性を通じて高いユー\nザー参加率を維持することができる。\n14\n第2章\n関連研究\n2.1\nフィットネスバイクの利用に対して内発的動機づけを図る仮想スタンプラ\nリーシステムの評価\n仮想スタンプラリーを取り入れることで、エクササイズバイクを使う際の内発的動機づけを高めることを目的\nとし、その利用頻度が向上するかを評価する実験が行われた。本実験では、ユーザーがフィットネスバイクを使用\nしながら仮想空間内でスタ",
            "かを評価する実験が行われた。本実験では、ユーザーがフィットネスバイクを使用\nしながら仮想空間内でスタンプラリーに参加するというゲーム要素を楽しむことで、どれだけ運動への意欲や継\n続性が増加するかを確認する。以下の図に示されているのは、この提案システムの表示画面であり、ユーザーが景\n色や進行状況を確認しながら、リアルタイムでバーチャルなスタンプを集められるインターフェースとなってい\nる。実験の結果、提案システムを利用することで、エクササイズの利用時間や運動量はシステムを使用しない場\n合と比べて大幅に増加することが明らかになった。さらに、楽しさに関する評価でも、システムを使用した場合\nの得点が大幅に上昇していることが確認された。具体的には、仮想空間の景色を楽しむ要素とスタンプラリーの\n達成感が、エクササイズの満足度を高め、運動が楽しいという感覚を促進する要因として機能したと考えられる。\nこのように、提案システムは、単に運動を行うだけではなく、ユーザーが運動の過程で喜びを感じながら継続で\nきるようにする工夫がなされている。しかし、このシステムには一部のユーザーにとって課題が残る。具体的に\nは",
            "ようにする工夫がなされている。しかし、このシステムには一部のユーザーにとって課題が残る。具体的に\nは、仮想スタンプラリーを含む専用のシステムを整えるには、一定の技術的な準備が必要であり、すべてのユー\nザーがこのシステムを簡単に利用できるわけではないという点で課題が存在する。技術的なハードルや費用が発\n生するため、システムの導入や利用環境に制約があることが挙げられる。[10]\n2.2\n寄り道促進アプリケーションを用いたウェルビーイング向上の枠組み\nこの研究では、ユーザーの幸福感向上を目指し、偶然の発見と旅の要素を取り入れたアプリケーションの効果を\n分析しています。日常生活に意図的な偶然を設計することで、ユーザーが新たな体験を得て幸福感を向上させる\nことを目的としている。具体的には、アプリはユーザーが新しい場所を発見したり、未知の情報に触れたりする\n機会を提供します。このような偶然の発見が予測不能な喜びや冒険心を喚起し、精神的な充足感をもたらす。この\nアプローチは日常の単調さを解消し、心理的な「新規性」や「変化」をもたらすことでポジティブな感情を引き\n出す重要な要因になる。また、こうした偶",
            "な「新規性」や「変化」をもたらすことでポジティブな感情を引き\n出す重要な要因になる。また、こうした偶然性に基づいたアプローチは、従来のアプリとは異なり、ユーザーが能\n動的に探索し体験を深めることを促し、これにより、アプリの長期的な使用や持続的な幸福感の向上につながる\nことを検証している。この研究では、旅や探検を通じた偶然の発見がウェルビーイングに与える効果を実証する\nために、実験やケーススタディが行われ、偶然の発見によって幸福感が増加することが確認された。これは、現\n代のテクノロジーやアプリケーションにおける新たな方向性を示すものである。この研究が示唆するように、偶\n然性を意図的に取り入れることによって、ユーザーが自発的にアプリを活用し、探検や発見を通じてポジティブ\nな感情を感じる場を提供することが、幸福感向上に有効である。[11]\n15\n2.3\nEﬀectiveness of Behaviorally Designed Gamiﬁcation Interven-\ntions With Social Incentives for Increasing Physical Activity",
            "Social Incentives for Increasing Physical Activity\nAmong Overweight and Obese Adults Across the United States:\nThe STEP UP Randomized Clinical Trial.\nこの「STEP UP ランダム化臨床試験」は、アメリカ全土において過体重および肥満と診断された成人が、身体\n活動量を増加させるために行動設計を活用したゲーミフィケーション介入の有効性を検証した。この研究の目的\nは、参加者が楽しみながら健康目標に取り組むよう促進することにあり、行動科学に基づいたゲームの要素（報\n酬、レベルアップ、仲間との競争など）と、他者との関わりを活用した社会的インセンティブ（サポートや競争）\nを組み合わせて実験を行った具体的には、アメリカ国内の過体重または肥満の成人を対象にし、異なる社会的イ\nンセンティブを導入したグループに分けて介入を実施した。この介入では、参加者の身体活動量の増加と、その\n活動がどれだけ継続されるかを測定しその結果、特に他の参加者と競争や協力を行う社会",
            "動量の増加と、その\n活動がどれだけ継続されるかを測定しその結果、特に他の参加者と競争や協力を行う社会的インセンティブがあ\nる場合に身体活動量の増加に有効であることが確認された。このようなゲーミフィケーションを用いた行動変容\n支援は、持続可能な健康習慣の形成に役立つ可能性が示している。[12]\n2.4\nProfessional Esports Players: Motivation and Physical Activity\nLevels\nプロのe スポーツ選手の動機や身体活動レベルについて探求されている。この研究は、e スポーツが急速に成長\nする競技分野として注目を集める中で、選手の健康やパフォーマンスに関わる要因を明らかにする目的で行われ\nた。e スポーツ選手における動機づけの多様性を分析し多くのプロ選手が、競争心、達成感、収入、名声といった\n外発的要因に強く動機づけられていることが示されている。このような動機づけの構造は、選手のパフォーマンス\nや練習習慣に直接的な影響を与えると考えられている。さらに、研究はe スポーツ選手の身体活動レベルについ\nても評価しその結果、多くの選手が比較",
            "れている。さらに、研究はe スポーツ選手の身体活動レベルについ\nても評価しその結果、多くの選手が比較的低い身体活動レベルにとどまっていることが明らかになった。e スポー\nツ選手の多くは、長時間の座位を伴うゲームプレイや練習セッションに従事しており、身体活動の機会が限られて\nいる傾向がある。特に、1 日の中で長時間座り続けることが、筋骨格系の問題のリスクを高める可能性があること\nが懸念されている。この結果は、e スポーツ選手が身体的な健康を維持するために、意識的に身体活動を取り入れ\nる必要性を示唆している。トレーナーやマネージャー、さらにはe スポーツ業界全体が、身体活動を推進する取\nり組みを強化する必要がある。具体的には運動プログラムを競技スケジュールに組み込むことや、身体活動の重\n要性についての教育を行うことが推奨されている。[13]\n2.5\nThefuntheory.com\n「The Fun Theory」は、行動科学とデザインの融合により、日常的な行動をポジティブに変容させるためのア\nプローチとして注目されている。この理論は、スウェーデンの自動車メーカーであるVolkswagen",
            "ア\nプローチとして注目されている。この理論は、スウェーデンの自動車メーカーであるVolkswagen が2009 年に提\n案したプロジェクトから始まり、「楽しさ」を介して人々の行動をより望ましい方向へ導くことを目的としている。\n本稿では、The Fun Theory に基づくプロジェクトがどのように行動変容を促進し、社会的な課題に対処するかを\n分析する。楽しさが行動変容にどのように寄与するのか。その効果がどの程度持続可能であるか。他の行動変容\n手法と比較してどのような特異性があるかにの三つの点について重きを置いている実験である。[14]\n16\n2.6\nPiano Staircase\n2009 年、Volkswagen 社の主導による「The Fun Theory」プロジェクトの一環として、スウェーデンにおいて\n興味深い実験が実施された。この実験は、日常生活における行動変容を「楽しさ」を介して促進することを目的\nとしており、その一環としてピアノ階段（Piano Stairs）が設置された。本取り組みの背景には、現代社会におけ\nる運動不足という問題意識が存在する。特に公共交通機関や駅におい",
            "本取り組みの背景には、現代社会におけ\nる運動不足という問題意識が存在する。特に公共交通機関や駅においてエスカレーターが階段よりも頻繁に利用\nされる現状が、身体活動量の低下を招いていることが課題として挙げられる。このような状況を受け、階段の利\n用を促進するための新たな動機付けとして、ピアノ階段が導入された。この実験では、地下鉄駅の階段にピアノ\nの鍵盤を模した装置が設置され、各段に内蔵された感圧センサーが足の動きを感知してピアノ音を鳴らす仕組み\nを採用した。さらに、階段のデザインには白と黒の鍵盤模様が施され、視覚的にも音楽的な体験を強調する仕様\nとなっている。これにより、階段の利用が単なる移動手段としての役割を超え、音楽を奏でる体験として位置付\nけられた。この取り組みの成果として、階段利用者数が66 パーセント増加したことが報告されている。この結果\nは、ピアノ階段がもたらす「楽しさ」が行動変容に寄与したことを示唆している。先行研究においても、楽しい\n体験が行動の継続性に影響を与えることが示されており、本事例はその実証例として位置付けられる。具体的に\nは、利用者は階段を利用することでピアノ音",
            "れており、本事例はその実証例として位置付けられる。具体的に\nは、利用者は階段を利用することでピアノ音という即時的な報酬を得ることができ、それまでエスカレーターを\n選択していた利用者が自然に階段を選ぶようになった。また、こうしたユニークな体験は、ソーシャルメディア\nを通じて広く共有され、個人の体験がコミュニティ全体に影響を与える形で波及効果を生んだ。本事例の意義は\n健康促進に留まらず、公共空間の再活性化にも寄与している。通常の階段は機能的な役割にとどまる一方で、ピ\nアノ階段は利用者に新しい価値を提供する体験型の空間として機能した。このような変化により、公共施設の利\n用者体験が向上し、社会的な繋がりや環境とのポジティブな関わりが強化されることが期待される。一方で、本\n取り組みには課題も存在する。例えば、ピアノ階段の設置や維持には高いコストが伴い、感圧センサーや音響シ\nステムの定期的なメンテナンスが必要である。また、本実験が示した行動変容の効果が長期的に持続するかにつ\nいては、さらなる検証が必要である。加えて、このアプローチの汎用性についても考察が求められる。特に、文\n化的背景や社会環境が異",
            "要である。加えて、このアプローチの汎用性についても考察が求められる。特に、文\n化的背景や社会環境が異なる地域において、同様の効果が得られるかは未検証であり、地域ごとの適応が必要と\nなる可能性がある。以上を踏まえ、ピアノ階段の事例は「楽しさ」を活用した行動変容の可能性を示す重要なモ\nデルケースである。[14]\n図2.1: The Piano Staircase\n17\n2.7\nThe World’s Deepest Bin\n「The World ’s Deepest Bin（ザ・ワールズ・ディープスト・ビン）」は、廃棄物処理における革新的なアプロー\nチとして注目されている取り組みである。本取り組みの目的は、廃棄物を捨てるという単調かつ無機質な行為を、\nより魅力的で楽しい体験に変えることにある。このような試みを通じて、廃棄物処理の重要性を強調し、社会的\nに持続可能な行動を促進することを目指している。本論文では、この取り組みがどのようにエンターテイメント\n性を組み込み、廃棄物処理に対する社会的意識をどのように変容させようとしているのかを分析する。廃棄物問\n題は地球規模で深刻化しており、その解決",
            "識をどのように変容させようとしているのかを分析する。廃棄物問\n題は地球規模で深刻化しており、その解決には個人、企業、政府の協力が不可欠である。特に、プラスチックご\nみ、食品廃棄物、電気電子機器等の適切な処理が重要であり、これらの廃棄物が適切に処理されなければ、環境汚\n染や資源の無駄遣いが進行し、地球の持続可能性に対する悪影響が生じる。しかしながら、廃棄物処理は多くの\n人々にとって退屈で面倒な作業とされており、そのため積極的な参加の動機が不足していることが多い。このよう\nな背景から、楽しさを加えることによって廃棄物処理行動を促進しようという発想が生まれた。「The World ’s\nDeepest Bin」の基本コンセプトは、文字通り「深いゴミ箱」を設置することである。このゴミ箱は物理的に深い\n構造を持ち、廃棄物を投げ入れると長い距離を落ちる音や視覚的なフィードバックを提供する仕組みが組み込ま\nれている。具体的には、投げ込んだゴミが落ちる音や、ライトの点滅などの効果があり、これによりゴミ捨ての行\n為が一種のゲームや遊びのように感じられる。これによって、日常的なゴミ捨て行動がユニークで魅力",
            "ての行\n為が一種のゲームや遊びのように感じられる。これによって、日常的なゴミ捨て行動がユニークで魅力的な体験\nに変わり、参加者はその行為を楽しみながら実行できるようになる。「The World ’s Deepest Bin」が目指すの\nは、ゴミ捨てを「遊び」や「ゲーム」として捉えさせ、廃棄物処理の積極的な参加を促すことである。従来のゴ\nミ捨て行為は、手間がかかり退屈であり、多くの人々はそれを避けようとする傾向がある。しかし、視覚的および\n音響的なフィードバックを加えることによって、ゴミを「深い穴」に投げ入れる行為は楽しい体験に変わる。こ\nの視覚的・聴覚的効果が、投棄行為に対する心理的満足感を提供し、人々を積極的にゴミ箱に誘導する。「The\nWorld ’s Deepest Bin」の効果を理解するためには、行動経済学および心理学的視点が重要である。人々がより積\n極的にゴミを捨てる行動を取る背景には、「即時的な報酬」の効果が作用している。楽しさや達成感は、行動を強\n化するための重要な要素となる。行動経済学の「即時的な報酬効果」や心理学における「強化学習理論」によれ\nば、視覚的および聴覚的",
            "なる。行動経済学の「即時的な報酬効果」や心理学における「強化学習理論」によれ\nば、視覚的および聴覚的なフィードバックは、ゴミ捨て行為を報酬を伴う行動として認識させ、参加者をより積\n極的にゴミ捨てに導く。「The World ’s Deepest Bin」がもたらす社会的インパクトは、単なるエンターテイメ\nントにとどまらず、環境問題に対する意識の向上にも貢献する。人々がこのようなゴミ箱を利用することで、廃棄\n物処理の重要性や環境への配慮についての意識が高まると考えられる。また、この取り組みは都市空間や公共施\n設における清潔な環境作りにも寄与することが期待される。楽しさと社会的責任を組み合わせることにより、よ\nり多くの人々が積極的に廃棄物処理に参加し、持続可能な社会作りに貢献する可能性が広がる。「The World ’s\nDeepest Bin」は、廃棄物処理行動をエンターテイメントに変える新たなアプローチを提供している。このユニー\nクなアイデアは、ゴミ捨て行為自体に楽しさを加えることで、人々の行動を変容させ、環境への配慮を促進する\n可能性を秘めている。廃棄物問題の解決には、単に強制的なル",
            "々の行動を変容させ、環境への配慮を促進する\n可能性を秘めている。廃棄物問題の解決には、単に強制的なルールや規制を設けるだけではなく、楽しい経験を\n通じて行動を変えるアプローチが重要であることを示唆している。このような取り組みが広がることで、社会全\n体の持続可能な行動が促進され、未来により良い環境を残すための一助となることが期待される。[14]\n2.8\nBottle Bank Arcade Machine\n「Bottle Bank Arcade Machine（ボトルバンク・アーケードマシン）」は、廃棄物処理の促進において革新的で\nユニークなアプローチを提案する取り組みの一つである。本取り組みは、リサイクルのプロセスをエンターテイメ\nントと結びつけ、一般市民が積極的に参加するように仕向けることを目的としている。従来の廃棄物処理行為は\nしばしば退屈で面倒な作業とされ、参加者がリサイクルに対して十分な関心を持ちにくい。しかし、ボトルバン\nク・アーケードマシンは、リサイクル行為をゲームのように楽しさを伴う体験に変えることで、その問題に対す\nる新たな解決策を提供している。本稿では、このアプローチ",
            "しさを伴う体験に変えることで、その問題に対す\nる新たな解決策を提供している。本稿では、このアプローチがどのようにリサイクル行動を促進し、廃棄物処理\nに対する社会的意識を向上させるのかを分析する。廃棄物問題は、地球規模で深刻化しており、その解決には個\n18\n人の行動だけでなく、社会全体の協力が不可欠である。リサイクルは廃棄物の減少や資源の再利用に重要な役割\nを果たすが、多くの人々にとってリサイクル行動は意識的に行うことが少ない。特に、ガラス瓶やプラスチック\n製品のリサイクルは、正しい方法で行わないと効果が薄れ、リサイクル活動が十分に行われない場合が多い。こ\nのため、リサイクルをより魅力的で楽しいものにし、人々の参加を促す方法が求められている。「Bottle Bank\nArcade Machine」は、リサイクルのプロセスをゲームの要素で包み込むことにより、従来の廃棄物処理行動を楽\nしさと即時的な報酬で強化するアイデアである。このアーケードマシンは、リサイクルする対象物（例えば、ガラ\nス瓶）を投入することで、ゲームのように得点が加算され、視覚的および聴覚的なフィードバックが得られる仕組\nみ",
            "を投入することで、ゲームのように得点が加算され、視覚的および聴覚的なフィードバックが得られる仕組\nみになっている。これにより、参加者はリサイクル行為を一種のゲームとして捉え、楽しさを感じながら行動を行\nうことができる。特に、得点が表示されたり、ライトが点灯する、音が鳴るなどの反応は、参加者に即時的な報酬\nを提供し、次回もリサイクル行動を積極的に取る動機づけを行う。「Bottle Bank Arcade Machine」は、リサイ\nクルを単なる義務ではなく、楽しい体験に変えることを目指している。この機械は、参加者がリサイクルを行う際\nにエンターテイメントの要素を加えることで、行動を楽しい経験に転換し、その結果としてリサイクルの効果を\n最大化しようとする。このような体験を通じて、人々はリサイクル行為を単なる手間ではなく、ゲームのような活\n動として認識し、積極的に取り組むことができるようになる。視覚的・聴覚的フィードバックは、行動の強化に\nおいて重要な役割を果たし、リサイクル行動を強化する心理的要因となる。「Bottle Bank Arcade Machine」の\n効果を理解するためには、行",
            "的要因となる。「Bottle Bank Arcade Machine」の\n効果を理解するためには、行動経済学や心理学的な視点が必要である。特に「即時的な報酬」の効果は重要であ\nる。人々は即座に結果が得られる行動に対してより積極的に取り組む傾向があり、このアーケードマシンはその即\n時的な報酬を提供することで、リサイクル行動を強化する。行動経済学の「即時的報酬効果」や心理学における\n「強化学習理論」に基づけば、視覚的および聴覚的なフィードバックが提供されることで、リサイクル行為が報酬\nを伴う行動として強化され、より多くの人々が積極的に参加するようになる。「Bottle Bank Arcade Machine」\nの社会的インパクトは、環境問題に対する意識の向上にも貢献する可能性が高い。リサイクル行動が楽しい体験\nとして提供されることで、参加者は自らの行動が環境への貢献に繋がっていることを認識し、環境保護に対する\n意識が高まると考えられる。また、このような仕組みは、都市空間や公共施設における清潔で持続可能な環境作\nりに寄与し、社会全体の持続可能性を向上させる一助となる。「Bottle Bank",
            "で持続可能な環境作\nりに寄与し、社会全体の持続可能性を向上させる一助となる。「Bottle Bank Arcade Machine」は、リサイクル\n行動をエンターテイメントと結びつける新しいアプローチを提案している。このユニークなアイデアは、リサイ\nクルを行う過程を楽しさと即時的報酬で強化することで、人々の行動を変容させ、環境問題への意識を高める可\n能性を秘めている。リサイクルの促進には、単にルールや規制を強制するだけではなく、楽しい体験を通じて行\n動を変える方法が重要であることを示唆している。このような取り組みが広がることで、より多くの人々が積極\n的にリサイクルに取り組み、持続可能な社会づくりに貢献することが期待される。[14]\n19\n図2.2: The Bottle Arcade machine\n2.9\nThe Green Light for Green Behaviour\nThe Green Light for Green Behaviour は、環境に優しい行動を促進するために設計された革新的な取り組みで\nあり、環境保護活動への積極的な参加を楽しさと即時的な報酬を通じて奨励する",
            "計された革新的な取り組みで\nあり、環境保護活動への積極的な参加を楽しさと即時的な報酬を通じて奨励することを目的としている。本取り組\nみの主な特徴は、公共の場においてリサイクル、ゴミ拾い、エネルギーの節約などの環境に良い行動を取った人々\nに対して、「グリーンライト」が点灯する仕組みを採用することである。このシステムは、参加者に対して行動に\n対する即時的なフィードバックを提供し、その行動が社会的に評価されていることを認識させることで、環境保\n護活動への積極的な参加を促す。即時的な報酬の提供は、行動経済学における「即時報酬効果」に基づいており、\nこの報酬が参加者の行動を強化する要因となる。具体的には、ゴミを拾うとすぐに緑色のライトが点灯すること\nで、その行動が肯定的に認識され、参加者は自分の行動が社会や環境に良い影響を与えていることを実感できる。\n視覚的なフィードバックとしての緑色のライトは、参加者に対して心理的な満足感を提供し、その行動が社会的\nに評価されているという認識を与える。このような即時的な報酬が環境保護行動に対する積極的な態度を育成し、\n行動が日常的な習慣として定着することを促進",
            "即時的な報酬が環境保護行動に対する積極的な態度を育成し、\n行動が日常的な習慣として定着することを促進する。さらに、この取り組みは、環境保護活動を単なる義務感や\n道徳的責任として捉えるのではなく、積極的で楽しさを伴う活動として認識させる点に特徴がある。楽しさと社\n会的な評価を通じて、参加者は環境に優しい行動を自己満足や社会的な承認を得る手段として捉えるようになり、\nその結果、再度その行動を取る動機づけが強化される。このアプローチは、特に公共空間や都市空間における環\n境保護活動の促進に有効であり、個々の行動が集積することで地域社会や都市全体の持続可能な発展に貢献する\n可能性が高い。したがって、The Green Light for Green Behaviour は、環境に優しい行動を積極的に促進するた\nめの効果的な手段であり、楽しさを通じて環境保護を促進する方法として非常に有望である。[14]\n2.10\n運動頻度と精神的ストレスの関係\n運動頻度と精神的ストレスの関係について、Mark Hammer らによる研究「Dose-response relationship between\nphy",
            "mmer らによる研究「Dose-response relationship between\nphysical activity and mental health: the Scottish Health Survey」（2009 年、British Journal of Sports Medicine）\n20\nは、運動習慣と精神的健康との間に見られる量反応関係を探求したものである。この研究は、スコットランド健康\n調査（Scottish Health Survey）のデータを基に、運動頻度と精神的ストレス症状の関連性を分析したものであり、\n重要な知見を提供している。研究の対象は、18 歳以上の成人約20,000 人で、参加者の運動頻度、運動の種類、精\n神的ストレスのレベルが評価された。精神的ストレスの評価には、一般健康質問票（GHQ-12）が用いられ、精神\n的ストレスが高いとされるスコアを基に分析が行われた。結果として、運動頻度が高い人ほど精神的ストレスが\n低い傾向が確認された。特に、適度な運動を週に2～5 回行う人々では、精神的ストレスのリスクが最も低いこと\nが示された。一方で、全",
            "適度な運動を週に2～5 回行う人々では、精神的ストレスのリスクが最も低いこと\nが示された。一方で、全く運動をしない人々や、過度に運動を行う人々では、ストレスのレベルが高まる傾向が\n観察された。これにより、運動と精神的健康の関係において「適度な運動量」の重要性が強調された。運動の種類\nに関しては、有酸素運動や筋力トレーニングといった幅広い運動が、ストレス軽減に有効であることが示されて\nおり、特定の運動形式に限定されない効果が確認された。この研究は、運動が精神的健康に与える影響を解明す\nる上で重要な示唆を提供している。特に、「量反応関係」が示されたことで、健康的な運動習慣を促進するための\nガイドラインの策定に寄与している。また、運動を取り入れたメンタルヘルス改善の戦略が、個人レベルだけで\nなく、公衆衛生政策においても重要な要素となることが示唆されている。本研究は、運動がストレス軽減に役立\nつ科学的根拠を提供し、持続可能な運動習慣の形成が、社会全体の精神的健康の向上に寄与する可能性を明確に\n示している。Mark Hamer らの研究によると、週に5 回以上運動を行う場合、精神的ストレスのリス",
            "している。Mark Hamer らの研究によると、週に5 回以上運動を行う場合、精神的ストレスのリスク軽減効果\nは飽和し、さらに運動頻度を増やしても追加的なメリットは得られにくいことが示唆されている。むしろ、一部\nのケースでは過度な運動が逆効果をもたらし、ストレスレベルが再び上昇する可能性があることも指摘されてい\nる。具体的には、過度の運動は身体的疲労や筋肉痛、慢性的な炎症反応を引き起こし、これが心理的ストレスの\n増加に繋がることがあると考えられている。また、運動頻度が非常に高い人々の中には、運動そのものが義務感\nやプレッシャーに変わり、心理的な負担となる場合もある。この結果は、「適度な運動が最適である」という結論\nをさらに支持している。運動による精神的健康のメリットは、一定の頻度や強度を超えると減少し、過剰な運動\nでは潜在的なリスクが発生することを示している。そのため、週に2～5 回の適度な運動が、最も効果的にストレ\nスを軽減し、精神的健康を維持するために適している。[15]\n2.11\nランニングの魅力が形成されるプロセス\nランニングの魅力が形成されるプロセスに関する研究によると、一",
            "\nランニングの魅力が形成されるプロセス\nランニングの魅力が形成されるプロセスに関する研究によると、一般市民ランナーがランニングに対して人格\n形成，達成感，忍耐・根性などの精神的な側面に資することに価値を感じていることが継続の理由のとして挙げ\nられている。また、一般的に達成感が得られないと目的意識が希薄になり、継続意欲が減退する。本研究におい\nて、ランニングの魅力形成における達成感および段階的目標の重要性が明らかにされた。調査対象者は、日常的\nにランニングを行い、ランニングに対して愛好的な態度を形成している8 名の一般市民ランナーであり、平均年\n齢は52 歳（± 10.3）であった。調査はランニング中に実施され、録音データを文字起こしして分析に用いた。分\n析には修正版グラウンデッド・セオリー・アプローチ（M-GTA）を採用し、26 の概念、5 つのサブカテゴリー、\n6 つのカテゴリーが生成された。分析結果の中で、「競争・達成の魅力」がランニングの魅力形成における主要な\n要因として抽出された。「タイムや順位を競い合える相手を設定すること」は、ランナーのモチベーションを高め\nる重要な要素であ",
            "。「タイムや順位を競い合える相手を設定すること」は、ランナーのモチベーションを高め\nる重要な要素である。例えば、被験者4（以下、被験者4）はマラソンランキングで49 歳時にサブスリー（3 時間\n未満）を達成し、70 位になった。この結果は、競争を通じて得られる記録や順位の向上が、自己成長の実感を伴\nい、継続的な動機付けを促進することを示唆している。また、「速さへの憧憬」や「ライバルの発見」といった概\n念も、他者との競争や記録更新がランニングの魅力形成に寄与していることを支持する。さらに、「思いがけぬ成\n功体験」は、ランニングの魅力をさらに強化する要因として重要であることが確認された。被験者1（以下、被\n験者1）は「予想外に妻のタイムを超えたことで意欲が高まった」と述べており、意外な成功体験が新たな目標設\n定を促進し、挑戦意欲を引き出すプロセスが明確に示されている。このような成功体験は、段階的な目標設定に\nよって効果的に引き出されることが明らかとなった。さらに、「ランニング履歴の活用」もランニングの魅力形成\nにおける重要な要素である。調査対象者は、練習やレースの記録を保持し、過去の成果を",
            "ンニングの魅力形成\nにおける重要な要素である。調査対象者は、練習やレースの記録を保持し、過去の成果を振り返ることで達成感\nを確認し、新たな目標を設定している。被験者7（以下、被験者7）は「過去の記録を振り返ることで、次のレー\n21\nスへの期待が高まる」と語っており、履歴管理がランナーのモチベーション維持に寄与することが示唆された。さ\nらに、「ランニングのもつゲーム性」に注目すると、自己評価基準の設定や速さへの憧れがランニングをゲーム\nのような活動に変え、目標達成や自己挑戦が魅力を高める重要な要素となっていることが明らかとなった。被験\n者2（以下、被験者2）は「仲間との練習会で、他のランナーとのペース競争が楽しみを増幅する」と述べており、\nゲーム的要素がランニングの魅力形成をさらに強化することを示している。本研究の結果、達成感や段階的な目標\n設定は、ランニングの魅力形成において中核的な役割を果たしていることが明らかとなった。このことから、ス\nタンプラリーやバッジなどの視覚的な達成の仕組みを取り入れることは、ランニングの魅力をさらに高め、持続\n的なモチベーションを強化する効果があると考えら",
            "取り入れることは、ランニングの魅力をさらに高め、持続\n的なモチベーションを強化する効果があると考えられる。以上の知見は、ランニング教育やモチベーション向上\nを目的としたプログラムの設計において重要な示唆を与えるものである。[16]\n22\n第3章\n社会背景調査\n3.1\n社会背景調査目的\n健康とは、身体的、精神的、社会的に完全に良好な状態を指し、単に病気や虚弱でないことではないと世界保\n健機関（WHO）は定義している。この定義に基づき、健康を維持するためには適切な食事、十分な睡眠、そして\n運動習慣が健康において重要である。しかし、日本では多くの人々が運動不足に悩んでおり、それが健康問題を引\nき起こす一因となっている。これらの健康リスクは個人の生活の質を低下させるだけでなく、医療費の増加や労働\n生産性の低下といった社会的コストももたらす。こうした背景の中で、運動不足の解消に向けた取り組みが進行し\nており、地方自治体や企業による健康増進プログラム、テクノロジーを活用した運動量の記録システムが注目さ\nれている。本研究では、具体的にどのようなことが求められているか理解するために、社会調査を行なった",
            "さ\nれている。本研究では、具体的にどのようなことが求められているか理解するために、社会調査を行なった結果\nを行ない運動不足の現状とその要因に焦点を当て、運動習慣の形成を促進するための効果的な方法を検討する。\n3.2\n調査対象\n調査対象の学生20 名(男性17 名、女性2、トランスジェンダー1 名) に対して以下の質問の調査を行った。\nQuestion 1 今までに長期間の運動経験(部活やクラブ活動、数年間ランニングを自主的に行っている) は\nありますか？\nQuestion 2 あると答えた方のみ回答をお願いします。長期間の運動(部活やクラブ活動数年間ランニン\nグ) は具体的にどのようなことを行いましたか？\nQuestion 3 あなたは現状、どのくらいの頻度でランニングをしますか？\nQuestion 4 健康管理で最も難しいと感じることは以下に項目がございますでしょうか？\nQuestion 5 ランニングに対する心理的負荷はどのくらいありますか？\nQuestion 6 ランニングや運動の継続を難しく感じる要因を教えてください。（複数選択可）\nQuestion 7 ランニングのを続ける際",
            "継続を難しく感じる要因を教えてください。（複数選択可）\nQuestion 7 ランニングのを続ける際に以下のような要素があるとモチベーションが高まると思いますか？\nQuestion 8 ランニングをする際、以下のどのような感覚が最も重要だと感じますか？（1 つ選択）\nQuestion 9 ランニングのような長期的な目標に対して、スタンプラリーのような段階的な達成感を示す\nものがあると単純にランニングをするよりも心理的な負荷は軽減するか？\nQuestion 10 小さな目標（例：1km ごとに報酬や達成感を得られる仕組み）が心理的な負担を軽減する効\n果について、どう思いますか？\nQuestion 11 距離や回数などの目標を段階的に設定し、それを達成するごとに「スタンプ」や「バッジ」\nがもらえる仕組みがあるとしたら、ランニングを続ける動機付けになりますか？\nQuestion 12 以下の2 つの状況がある場合、どちらの方が続けやすいと感じますか？1. ゴールだけが設\n定された場合（例：10km を走る）2. ゴールまでの道のりに小さな目標が設定されている場合（例：\n1km ごとにスタンプ",
            "km を走る）2. ゴールまでの道のりに小さな目標が設定されている場合（例：\n1km ごとにスタンプがたまる）\nQuestion 13 このようにスタンプを取得し、ランニング中に特定のものを見つけてスタンプを取得する形\nだと特に目的なく１キロ走るのに比べて継続はしやすいですか？\nQuestion 14 あなたは以下のどの形式が最もモチベーションにつながると感じますか？\nQuestion 15 デジタルバッジやランキング表示によって、モチベーションは改善しますか？\n23\nQuestion 16 自己管理アプリでの記録（例：距離、時間、消費カロリー）などによって、ランニングに対\nするモチベーションは改善しますか？\nQuestion 17 スタンプラリー形式での要素の追加により、ランニングの心理的負荷は減少しましたか？\n3.3\n分析手法\nラベルエンコーディングを用い、上記の調査に対してピアソンの相関係数を用いて、相関分析を行なった。\nr =\n∑n\ni=1(xi −¯x)(yi −¯y)\n√∑n\ni=1(xi −¯x)2 ∑n\ni=1(yi −¯y)2\n• xi, yi はデータポイントの値\n",
            "\ni=1(xi −¯x)2 ∑n\ni=1(yi −¯y)2\n• xi, yi はデータポイントの値\n• ¯x, ¯y はそれぞれの平均値\n• n はデータポイントの総数\n3.4\nランニングの頻度について\n調査結果によれば、最も多く挙げられた要因は「モチベーションが維持できない」であり、全体の約32 パーセ\nントを占めている。この結果は、運動継続の鍵となる心理的要因の重要性を示しており、運動を習慣化するため\nには、外部および内部からの動機付けが必要不可欠であることを示唆している。特に、短期的な目標設定や達成\n感を得られる仕組みを導入することが、モチベーションの向上に寄与すると考えられる。次に、「目標が漠然とし\nている」という回答が全体の約27 パーセントを占め、明確な目標設定の欠如が運動の継続を妨げる要因となって\nいることが示された。具体的かつ達成可能な目標の設定が、運動を継続するために重要であることは先行研究で\nも指摘されており具体的には「週に3 回、1km を走る」といった小さな目標を段階的に設定することが推奨され\nる。また、目標を細分化し、達成感を頻繁に得られるような工夫を施すこと",
            "段階的に設定することが推奨され\nる。また、目標を細分化し、達成感を頻繁に得られるような工夫を施すことで、モチベーションを維持しやすく\nなる。一方、「身体的な負担や疲労」を挙げた回答も約14 パーセントを占め、運動計画が適切でないことが心理\n的および身体的な抵抗感を生む要因となっていることが明らかとなった。特に、初心者や長期間運動から離れて\nいた人々にとっては、負荷が過剰である場合に運動を継続する意欲が削がれる可能性が高い。そのため、初心者\n向けの軽負荷トレーニングプログラムを提供し、疲労感を軽減するためのストレッチやリカバリー情報を併せて\n提示することが効果的である。また、「長期的な達成が見えにくい」という回答も約9 パーセントを占め、運動の\n効果が即時に感じられないことが継続性の妨げとなっている可能性が示唆された。この課題に対応するためには、\n短期的な成果を可視化する仕組みが有効である。例えば、ランニングの距離や消費カロリーを記録し、進捗を可視\n化することで達成感を与えると同時に、運動を継続する意欲を促進することができる。さらに、調査では「ジム\nで走ることが多い」「その他」といった回",
            "を継続する意欲を促進することができる。さらに、調査では「ジム\nで走ることが多い」「その他」といった回答も見られ、特定の環境や個別の事情が運動の継続に影響を及ぼしてい\nる。これらの課題に対応するためには、各個人のライフスタイルに合わせた柔軟な運動プログラムを提案し、オ\nンラインフィットネスや自宅トレーニングなど、より多様な運動の選択肢を提供することが求められる。以上の結\n果を踏まえ、以下のような施策が有効であると考えられる。第一に、モチベーション維持を支援する仕組みとし\nて、達成感を促進するスタンプラリーやバッジの獲得機能を運動プログラムに組み込むことが挙げられる。これ\nにより、運動をゲームのように楽しむ要素が加わり、参加者の意欲が高まると期待される。第二に、他者と進捗を\n比較できるランキング機能やコミュニティ要素をアプリケーションに導入することで、他者との競争や協力を通\nじて継続意欲を高めることができる。第三に、具体的な目標設定を支援するプランニング機能を提供し、目標達\n成後には具体的な報酬や進捗記録を視覚化する仕組みを導入することが効果的である。これにより、運動の成果\nが確認しやすく",
            "報酬や進捗記録を視覚化する仕組みを導入することが効果的である。これにより、運動の成果\nが確認しやすくなり、長期的な継続意欲を支援できる。さらに、初心者向けの軽負荷トレーニングプログラムを\n提供するだけでなく、個別の障壁に対応するためにカスタマイズ可能な運動プランの提案を強化することも重要\nである。オンラインフィットネスやモバイルアプリの活用によって、ユーザーが場所や時間を選ばずに運動を継続\n24\nできる環境を整えることが可能となる。これらの施策を総合的に実施することで、ランニングや運動の継続を難\nしくしている要因を緩和し、健康習慣の形成を促進することが期待される。\n3.5\nランニングの心理的負荷\nアンケートの回答者に75 パーセントが長期間の運動経験があるのにも関わらず、60 パーセントの人々がラン\nニングに対して心理的負荷を感じていることが明らかになった。この結果は、運動経験がランニングへの抵抗感\nの解消に直結しないことを示唆している。心理的負荷を感じる要因として、運動種目の違いや個々の体験が挙げ\nられる。例えば、筋力トレーニングやスポーツ競技を主に行ってきた人にとって、ランニングは",
            "の体験が挙げ\nられる。例えば、筋力トレーニングやスポーツ競技を主に行ってきた人にとって、ランニングは異なる身体的要\n求やスキルを伴うため、心理的な抵抗感を生む可能性が高い。また、ランニングが単調な運動と認識されること\nが多く、精神的な疲労感や継続の難しさが心理的負荷を増大させる要因となっている。さらに、運動経験者の中\nには高い目標や自己期待を持つ人が多く、自身のパフォーマンスを他者や過去の自分と比較してしまう傾向があ\nる。その結果、達成できなかった際に生じる否定的な感情が心理的なプレッシャーとして現れることが考えられ\nる。また、ランニングは個人で行うことが多く、孤独感や自己責任の意識が強まる傾向があるため、モチベーショ\nンを維持するための外部要因が不足しやすい。特にグループスポーツ経験が豊富な人々にとって、この孤独感は大\nきな障壁となる。これらの要因を軽減するためには、対策が必要である。達成感を増幅する仕組みとして、短期\n的な目標設定や成果の可視化が有効である。例えば、ランニングアプリを活用して距離や時間を記録し、目標達\n成を視覚的にフィードバックすることは心理的負荷をポジティブな感情",
            "活用して距離や時間を記録し、目標達\n成を視覚的にフィードバックすることは心理的負荷をポジティブな感情に変える助けとなる。また、ランニング\nの楽しさを増幅する要素を追加することも重要である。スタンプラリー形式の目標達成システムや地元観光地を\n巡るランニングイベントなどを導入することで、単なる運動からアクティビティとしての要素を持たせることが\nできる。さらに、グループランニングイベントの促進やコミュニティ形成により、ランニングの孤独感を軽減し、\n社会的な支援を強化することが可能である。初心者や心理的負荷を感じている経験者に向けた個人にカスタマイ\nズされたプログラムの提供も効果的である。例えば、初心者にはウォーキングとランニングを組み合わせたプロ\nグラムを提案し、経験者にはインターバルトレーニングや記録更新を目指したチャレンジ形式のプログラムを提\n供することが有効である。またテクノロジーの活用も心理的負荷の軽減に寄与する。ウェアラブルデバイスやス\nマートフォンアプリを活用してデータの視覚化や音声フィードバックでの励ましやアドバイスを提供する機能は\nモチベーションを維持する上で有用である。ゲー",
            "声フィードバックでの励ましやアドバイスを提供する機能は\nモチベーションを維持する上で有用である。ゲーミフィケーションを取り入れたアプリケーションも有効であり、\nランニング距離やタイムに応じたポイント獲得や実社会でも使用可能な報酬を得られる仕組みを導入することで、\n心理的負担をゲーム感覚で乗り越えることができる。教育的アプローチも重要であり、ランニングに関する正し\nい知識や技術を提供することで心理的負荷を軽減することが可能である。適切なフォームやペース配分、疲労回\n復の方法を学べる機会を提供することで、運動に対する抵抗感が低減され、よりポジティブな取り組みが促進さ\nれる。これらの取り組みは、心理的負荷を軽減し、運動経験者がランニングをより魅力的に感じ、継続的に取り\n組むための鍵となる。心理的負荷の背景には個々の体験や特性が影響しているため、多角的なアプローチが求め\nられる。本考察を基に、ランニングの魅力を再発見し、運動の習慣化を支援する施策がさらなる発展を遂げるこ\nとが期待される。\n3.6\n性別間のランニング頻度の差\n性別とランニング頻度の負の相関（-0.568）が、性別がランニング頻度",
            "\n性別間のランニング頻度の差\n性別とランニング頻度の負の相関（-0.568）が、性別がランニング頻度に影響を与えている可能性を示唆してい\nる。この負の相関は、例えば男性が女性よりも頻繁にランニングを行う傾向がある、または逆に女性がランニン\nグを頻繁に行う傾向がある。性別がランニング頻度に与える影響は多方面に及ぶ。まず、性別による運動への動\n機や目的の違いがランニング頻度の差に関連していることが確認されている。男性は競争や成果を重視する傾向\nがあり、ランニングのような自己記録の更新やパフォーマンス向上を目指す運動を選択する割合が高い。一方、女\n性は健康維持やストレス軽減などの内発的な要因を重視し、これがランニング以外の運動選択につながる場合が\n25\nある。さらに、時間的余裕やライフスタイルの違いが性別ごとのランニング頻度に影響を及ぼしている。運動に\n充てる時間を制約する要因となっている。男性は仕事中心のライフスタイルを持ちつつも、運動のための時間を\n確保する意識が強く、これがランニング頻度の違いとして現れている。社会的・文化的要因もランニング頻度に\nおける性差を説明する重要な要素である。",
            "の違いとして現れている。社会的・文化的要因もランニング頻度に\nおける性差を説明する重要な要素である。女性はランニングを行う際に、安全性の懸念を感じやすい。夜間のラ\nンニングや人通りの少ない場所での運動は、特に女性にとって心理的な障壁となりやすい。一方で、男性はこう\nした環境要因をあまり気にせず、ランニングの実行に積極的である場合が多い。心理的な負担や運動に対する魅\n力の感じ方も性別によって異なることが指摘されている。女性は達成感や仲間との共有といった外発的な要因を\n重視する傾向があり、これに応じた仕組みがない場合、ランニングに対する意欲が低下する可能性が高い。一方、\n男性は自己記録の更新や目標達成といった内発的要因を重視するため、ランニングの頻度が高くなる。身体的な\n特徴の違いも、ランニング頻度に影響を与える重要な要因である。男性は一般的に筋力や体力が高い傾向があり、\nこれが持久力を必要とするランニングの楽しさや実行可能性を高めている。女性はホルモンや身体構造の違いか\nら、長距離ランニングに対して心理的・身体的な負担を感じやすく、これがランニング頻度の低下につながる。運\n動に関連する社",
            "グに対して心理的・身体的な負担を感じやすく、これがランニング頻度の低下につながる。運\n動に関連する社会的支援やコミュニティの存在も性別による違いを示す重要な要因である。男性はスポーツクラ\nブやランニングイベントへの参加機会が多い一方で、女性はこうした環境に心理的抵抗を感じる場合がある。特\nに、男性が中心となるランニングコミュニティでは、女性が孤立感や不安を抱くことが多く、これがランニング\n頻度の低下に寄与している。これらの分析結果を踏まえ、性別によるランニング頻度の違いを解消するためには、\n性別に応じた対策が必要である。女性には、安全なランニング環境の整備や女性専用ランニングイベントの開催\nが有効であり、心理的抵抗を軽減するための初心者向けプログラムの導入が求められる。また、女性がランニン\nグを継続しやすくするために、社会的支援を強化し、コミュニティの構築を進める必要がある。一方、男性には\n競争心を高める仕組みや自己記録を簡単に管理できるデジタルツールの提供が効果的である。こうした仕組みは、\n男性の内発的動機をさらに強化し、ランニング頻度を維持するための支援となる。これらの施策を通じて",
            "は、\n男性の内発的動機をさらに強化し、ランニング頻度を維持するための支援となる。これらの施策を通じて、性別\nによるランニング頻度の差を縮小し、より多くの人々がランニングを楽しみながら健康を促進できる環境を構築\nすることが可能である。性別に応じた運動プログラムや政策の導入は、個々のニーズに対応するだけでなく、社会\n全体の健康促進に寄与する重要な手段である。この研究結果は、ランニングを含む運動習慣を向上させるための\n新たなアプローチを提供し、性別による課題を克服するための基盤となる。まず、性別による運動動機や目的の\n違いがランニング頻度に顕著に影響を及ぼしていることが確認された。男性は競争や成果の追求に基づく内発的\n動機が強く、自己記録の更新やパフォーマンス向上を目的とした運動（特にランニング）に積極的である。一方、\n女性は健康維持やストレス軽減といった内発的動機を重視するため、運動の種類が多様化し、ランニング以外の選\n択肢に目を向ける傾向がある。この違いは、性別ごとに異なる運動の魅力や目的意識がランニング頻度に影響を与\nえていることを示している。また、時間的余裕やライフスタイルの差異も、",
            "意識がランニング頻度に影響を与\nえていることを示している。また、時間的余裕やライフスタイルの差異も、性別間のランニング頻度の違いを裏\n付ける重要な要素である。女性は家事や育児の負担がランニングの時間確保を妨げる一方で、男性は職場中心の\nライフスタイルの中でも、運動時間を優先的に確保する傾向が見られる。これにより、女性の運動時間の不足が\nランニング頻度の低下に直接的な影響を及ぼしている。さらに、社会的および文化的要因が性別によるランニン\nグ頻度に影響を及ぼしていることも証明される。女性が安全性の懸念や心理的な障壁を感じやすいことが、ラン\nニング頻度の低下につながっている。一方で、男性は安全性をさほど気にせず、積極的にランニングを行う傾向が\n強い。このような性別特有の社会的背景がランニング習慣における性差を助長している。心理的要因として、男\n性と女性ではランニングに対する魅力や動機の感じ方が異なり、これがランニング頻度に影響を与えていること\nも示唆される。男性は自己記録の更新や目標達成を重視し、それが継続的なランニング頻度に繋がる。一方、女\n性は達成感や他者との共有を重視するため、ランニン",
            "し、それが継続的なランニング頻度に繋がる。一方、女\n性は達成感や他者との共有を重視するため、ランニングを継続するための仕組みが不足している場合、頻度が低\n下しやすいことが証明された。最後に、性別に応じた具体的な対策の有効性が示された。女性に対しては安全な\nランニング環境や初心者向けプログラム、女性専用のイベントを提供することで心理的抵抗を軽減し、ランニン\nグの習慣化を促進できる。一方、男性には競争心を高める仕組みや自己記録管理ツールの提供が有効であり、こ\nれがモチベーション維持とランニング頻度向上に寄与することが示唆される。これらの研究および考察結果から、\n性別に応じた運動プログラムの導入が性別間の運動頻度の差を縮小し、社会全体の健康促進に貢献する有効な手\n段であることが明確に証明された。このアプローチは、性別固有のニーズに応じた支援が、個人の運動習慣の形\n26\n成を促進し、健康的なライフスタイルの実現に寄与することを強く示唆している。\n3.7\nスタンプラリー形式の効果\n「小さな目標が心理的負担を軽減する効果」と「スタンプラリー形式での要素の追加により心理的負担が減少し\nましたか？」の",
            "理的負担を軽減する効果」と「スタンプラリー形式での要素の追加により心理的負担が減少し\nましたか？」の間に見られた強い正の相関（0.736）は、スタンプラリー形式が小さな目標設定を通じて心理的負\n担軽減に大きな影響を与えていることを示している。この強い正の相関は、スタンプラリー形式の特性が小さな\n目標を提示し、それを達成することで得られる達成感が心理的負担を軽減するメカニズムと深く結びついている\nことを表している。正の相関の意味について考察すると、正の相関が強い（0.736）という数値は、「小さな目標が\n心理的負担を軽減する」と感じる人ほど、「スタンプラリー形式が心理的負担を軽減する」とも感じる可能性が高\nいことを示している。この関係性は、両者が同じ心理的効果をもたらすプロセスを共有していることを示唆して\nいる。具体的には、スタンプラリー形式が視覚的進捗管理や段階的な達成感、報酬感を通じて心理的負担を軽減\nする仕組みが、同時に小さな目標設定による心理的なハードル低減効果と一致している。スタンプラリー形式は、\n「目に見える形で達成感を得られる仕組み」を提供する特徴がある。視覚的な進捗管理に",
            "ンプラリー形式は、\n「目に見える形で達成感を得られる仕組み」を提供する特徴がある。視覚的な進捗管理によって目標達成の過程が\n明確になり、各ステージの達成やスタンプの獲得が分かりやすくなる。これにより、目標達成の進捗がユーザーに\n明示され、達成感が得られる頻度が高まる。次に、段階的な達成感の提供が挙げられる。1 回の運動の中で大きな\n成果を目指すのではなく、複数の小さな目標を設定し、達成することで頻繁に達成感を味わえる仕組みが心理的\n負担を軽減する。また、スタンプの獲得そのものが心理的な報酬となり、次の目標に向かうモチベーションを高\nめる。このように、スタンプラリー形式は、小さな目標を段階的に提示し、大きな目標に圧倒されることなく運\n動を継続できるようにする効果がある。さらに、この相関が示す心理的負担軽減のメカニズムについて考えると、\nいくつかの要素が挙げられる。まず、目標の具体化と達成感が心理的負担軽減に寄与している。大きな目標より\nも小さな目標のほうが達成が容易であり、達成感を得る頻度が増えるため、運動に対するポジティブなフィード\nバックが強化される。また、過負荷の回避も重要な要素で",
            "が増えるため、運動に対するポジティブなフィード\nバックが強化される。また、過負荷の回避も重要な要素である。一度に大きな目標を設定するのではなく、小さな\n目標を分割して提示することで、運動の負荷や精神的ストレスを軽減し、運動に対する心理的抵抗を減らす。さ\nらに、自信の向上も見逃せないポイントである。小さな目標を達成する過程で自己効力感が高まり、運動を続け\nることへの自信が形成される。これらの要因が組み合わさることで、スタンプラリー形式が心理的負担を軽減す\nる効果が高まっている。スタンプラリー形式の利点について、この仕組みは特に心理的課題を抱える人々にとっ\nて有効である。運動初心者にとって、大きな目標を達成することは心理的負担が大きいため、小さな目標を提示\nするスタンプラリー形式が特に効果的である。また、心理的ハードルの高い人々に対しては、運動に対する抵抗\n感や挫折感を低減し、小さな目標をクリアすることで運動に前向きになれる環境を提供する。さらに、長期的に\n運動を継続したい人々にとっては、スタンプラリー形式によって短期的な達成感を得ながら、最終的には大きな\n目標に到達するためのモチベーショ",
            "タンプラリー形式によって短期的な達成感を得ながら、最終的には大きな\n目標に到達するためのモチベーション維持に寄与する。実践への示唆として、この相関を基にスタンプラリー形\n式の要素を運動プログラムに取り入れることは、運動初心者への導入や継続性の向上に役立つ可能性がある。初\n心者が運動を楽しみながら取り組むきっかけとして、スタンプラリー形式が有効であり、短期的な目標を設定し、\n達成感を得られる仕組みを提供することで、運動の継続率を向上させる効果が期待される。また、視覚的なスタ\nンプやポイントの形で達成感を示すことで、心理的満足度を高め、運動への前向きな姿勢を促すことが可能であ\nる。さらに、この相関関係が示す効果をさらに活用するためには、個別化された目標設定が必要である。個々人\nの運動レベルや心理的ニーズに応じてスタンプラリー形式の目標をカスタマイズすることや、スマートフォンア\nプリやウェアラブルデバイスを通じてリアルタイムで進捗を確認できる仕組みを整備することが求められる。ま\nた、スタンプラリー形式の効果が長期的にどの程度継続するかを検証し、プログラムを改良していくことも重要\nである。この",
            "リー形式の効果が長期的にどの程度継続するかを検証し、プログラムを改良していくことも重要\nである。このように、「小さな目標が心理的負担を軽減する効果」と「スタンプラリー形式が心理的負担を軽減す\nる効果」の間の強い正の相関は、両者が運動継続における心理的負担軽減に密接に関連していることを示してい\nる。この結果は、スタンプラリー形式が小さな目標を提示することで心理的負担を効果的に軽減できることを強\nく支持しており、これを運動プログラムに取り入れることで、幅広い人々が運動を楽しみながら継続できる環境を\n27\n提供することが可能である。このような取り組みは、心理的負担を軽減し、運動の継続性を向上させるだけでな\nく、健康促進を目指す社会全体の取り組みとしても重要である。\n3.8\n運動経験者に対するスタンプラリーの効果\nランニングのような長期的な目標に対して、スタンプラリーのような段階的な達成感を示す仕組みがある場合、\n単純にランニングを行うよりも心理的負荷が軽減するかという問いと、今までに長期間の運動経験があるかどう\nかの間に相関係数-0.191 が得られた。この値は弱い負の相関を示しており、運動",
            "動経験があるかどう\nかの間に相関係数-0.191 が得られた。この値は弱い負の相関を示しており、運動経験が豊富な人ほどスタンプラ\nリーによる心理的負荷軽減効果がわずかに小さい傾向があることを意味しているが、その影響は限定的である。こ\nの結果からは、運動経験の有無がスタンプラリーの効果に完全には決定的でないことを示唆している。運動経験が\n豊富な人は、既に長期目標達成における動機付けや心理的耐性を持っている可能性が高く、スタンプラリーのよう\nな仕組みをそれほど必要としない場合がある。一方で、運動経験が浅い人や初心者にとっては、スタンプラリー\nによる達成感の可視化がモチベーションの維持や心理的負荷軽減により大きく寄与している可能性がある。また、\n動機付けの種類がこの相関に影響している可能性も考えられる。運動経験が長い人は、内発的動機付け、つまり\n運動そのものの楽しさや自己の成長に価値を見出している可能性が高い。この場合、スタンプラリーなどの外発\n的動機付けの要素は心理的負荷の軽減にはあまり寄与しない。一方、運動経験が少ない人は、外発的動機付け、つ\nまり報酬や可視化された進捗に依存しやすい傾向",
            "しない。一方、運動経験が少ない人は、外発的動機付け、つ\nまり報酬や可視化された進捗に依存しやすい傾向があるため、スタンプラリーが大きな効果をもたらす可能性が\nある。このことから、運動経験が異なる集団では、それぞれに適したモチベーション設計が必要であると考えら\nれる。さらに、この相関が弱い理由として、スタンプラリーによる心理的負荷軽減が運動経験以外の要因にも強\nく依存している可能性がある。例えば、個々の性格、モチベーションの種類、目標設定の難易度、ランニングを\n行う環境、さらにはスタンプラリーのデザイン自体が心理的負荷の軽減に影響を与える可能性がある。特に運動\nの目的が健康維持やストレス解消といった内発的な要因である場合には、外発的な仕組みの効果が薄れる傾向が\nあるかもしれない。また、運動初心者には、段階的に進捗を示す仕組みが有効であるが、経験者にはより高度な\n目標が動機付けに繋がる場合がある。このような観点から、個人の運動経験に応じて、心理的負荷を軽減しモチ\nベーションを維持するための方法が異なることが示唆される。このように、相関係数-0.191 は、運動経験が心理的\n負荷軽減に一定の",
            "法が異なることが示唆される。このように、相関係数-0.191 は、運動経験が心理的\n負荷軽減に一定の影響を与えることを示唆しているものの、その影響は限定的である。この結果から、スタンプ\nラリーのような仕組みは特に運動初心者や経験の浅い人々にとって効果的であり、経験者に対してはより内発的動\n機付けを強化する仕組みが必要であると考えられる。心理的負荷の軽減とモチベーションの向上を最大化するた\nめには、運動経験や個人の動機付けスタイルに応じた柔軟な設計が重要である。この研究結果は、長期目標を持\nつ運動プログラムの設計において、経験別に異なるアプローチを導入する必要性を示している。\n28\n第4章\nランニングアプリとスタンプラリー融合型運\n動促進システムの設計\n現代社会において、健康促進と持続可能な運動習慣の形成は重要な課題である。ランニングアプリとスタンプ\nラリー融合型運動促進システムでは、ランニングやウォーキングといった運動を楽しく、継続しやすくするためと\nいう課題を解決するためにゲーミフィケーションを取り入れたアプリケーションを開発を目指している。このア\nプリは、スコアシステムやスタンプラ",
            "ーションを取り入れたアプリケーションを開発を目指している。このア\nプリは、スコアシステムやスタンプラリー機能、写真撮影を活用したインタラクティブな仕組みを通じて、運動\nの楽しさと達成感を提供するものである。本稿では、このアプリケーションの機能、技術的背景、実用性および\n社会的意義について詳細に論じる。\n図4.1: FootJourney\n4.1\nアプリの概要\n本アプリは、ユーザーがランニングまたはウォーキングを行いながら、リアルタイムでスコアを獲得し、スタ\nンプラリー形式で目標を達成することを目指して設計された。主要な機能には、タイマー機能、スコア計算、目\n標地点への訪問達成を示すスタンプ機能、写真撮影機能、アクティビティ終了ボタンが含まれる。タイマー機能\nは、設定された運動時間をカウントダウン形式で表示するものであり、ユーザーが時間内で目標を達成するため\nのモチベーションを高める役割を果たす。スコア計算機能は、移動距離に基づく「距離スコア」と、目標地点で撮\n影された写真に基づく「写真スコア」を合算して「合計スコア」を表示する。これにより、ユーザーは単なる運動\n量だけでなく、目標達成の",
            "コア」を合算して「合計スコア」を表示する。これにより、ユーザーは単なる運動\n量だけでなく、目標達成の進捗状況を定量的に把握できる。スタンプラリー機能では、画面に表示されたアイコ\nン（例: 建物、自転車、木など）が目標地点を示し、それぞれの目標達成でスタンプを獲得できる。目標の達成度\nは視覚的にわかりやすく表現され、運動の楽しさが増幅される。さらに、写真撮影機能により、ユーザーは目標地\n29\n点での活動を記録することができる。この写真がアプリにおける目標達成の判定基準としても活用される。最後\nに、アクティビティ終了ボタンを押すことで、運動セッションを任意のタイミングで終了できる設計とした。\n4.2\nスタンプラリー機能について\nスタンプラリー機能におけるスタンプや配点の基準は、ユーザー体験を向上させる重要な要素であり、適切な\n達成感や挑戦感を提供するための基盤となる。本研究では、特に時間制限や条件付き達成要素を組み込むことで、\n配点基準を最適化し、ゲーム性と健康促進を融合した運動支援アプリケーションの開発を目指している。この機\n能を実現するためには、難易度、移動距離、時間や環境条件、対象物",
            "ーションの開発を目指している。この機\n能を実現するためには、難易度、移動距離、時間や環境条件、対象物の種類、ユーザーの行動履歴、および個別\nのインタラクション要素を考慮し、それぞれに基づいた配点基準を設定することが重要である。さらに、これら\nの要素を支える実装技術として、リアルタイムデータの処理、画像認識技術、位置情報の取得と管理、動的難易\n度調整（Dynamic Diﬃculty Adjustment, DDA）の導入が不可欠である。\n4.3\nスタンプや配点の基準の設計\nスタンプラリー機能では、達成すべき目標地点や対象物に対して適切な難易度と配点を設定する必要があるた\nめ、動的難易度調整（Dynamic Diﬃculty Adjustment, DDA) を踏まえて難易度に基づく配点、移動距離に基づ\nく配点、時間や条件を考慮した配点、対象物の種類に応じた配点の4 つの基準が考慮されるべきである。難易度\nに基づく配点は対象物の見つけやすさや撮影の難易度に応じて配点を調整する。簡単に見つけられる対象（例: 公\n園の木、建物）には10～30 点を割り当てる一方、難易度の高い対象（例: 稀少",
            "られる対象（例: 公\n園の木、建物）には10～30 点を割り当てる一方、難易度の高い対象（例: 稀少な動植物、特定のランドマーク）\nには100 点以上を設定する。この仕組みにより、初心者は手軽に達成感を得られる一方で、上級者には挑戦感を\n提供することが可能となる。移動距離に基づく配点は具体的に目標地点までの移動距離を考慮し、短距離（例: 家\nの近く）には10～20 点、中距離（例: 隣町の公園）には50～70 点、長距離（例: 観光名所）には100 点以上を\n設定する。これにより、運動量を増やす動機付けを強化できる。時間や条件を考慮した配点は特定の時間帯や気\n象条件で達成可能な目標には、特別なポイントを設定する。例えば、夕方の景色を撮影する場合には80～120 点、\n雨の日の虹や雪景色には100～150 点を付与する。このように条件付き要素を取り入れることで、達成時の特別感\nをユーザーに提供する。対象物の種類に応じた配点は具体的に自然物（例: 木や花）には10～50 点、生き物（例:\n犬、猫）には50～80 点、人工物（例: 建物、モニュメント）には30～100 点、地域固有の対象（例",
            "、猫）には50～80 点、人工物（例: 建物、モニュメント）には30～100 点、地域固有の対象（例: 名物や店舗）\nには100～150 点を設定する。これにより、ユーザーは対象物に応じた多様な挑戦をすることができる。\n4.4\nスタンプや配点の技術設計\n写真撮影機能とスタンプ獲得機能を実現するためには、さまざまな技術が統合されており、それぞれが異なる\n役割を果たしている。まず、ML Kit による画像解析技術が、このシステムの中心的な役割を担っている。Google\nが提供する機械学習ライブラリであるML Kit は、ユーザーが撮影した写真に含まれるオブジェクトやランドマー\nクを高精度で認識する。本機能では特に、ML Kit のImage Labeling 機能が活用され、画像内の特徴点が抽出さ\nれる。この特徴点は、アプリに事前に登録された目標地点のデータと比較される。登録されたデータは、目標地\n点に対応する特徴的なビジュアル要素を学習しており、これにより、ユーザーが目標地点を訪れたかどうかを判定\nすることが可能になる。例えば、特定の建物、モニュメント、または自然のランドマークが目標地点",
            "かを判定\nすることが可能になる。例えば、特定の建物、モニュメント、または自然のランドマークが目標地点として設定\nされている場合、その写真内の具体的な形状、色、模様などが一致しているかを確認する。この比較プロセスは\nバックエンドでリアルタイムに実行され、成功すると即座にスタンプが付与される仕組みとなっている。このよ\nうな高精度な画像解析は、ユーザーがアプリケーションを通じて得る体験の信頼性と公平性を保つ上で極めて重\n要である。次に、Fused Location Provider を活用したGPS データとの統合について述べる。この技術は、ユー\nザーの現在地を特定し、目標地点に近づいたときに写真撮影を有効化する仕組みを提供している。Fused Location\n30\nProvider は、GPS、Wi-Fi、モバイルネットワークのデータを統合することで、高精度な位置情報を効率的に提\n供する技術である。他の場所で撮影した写真を不正に使用してスタンプを獲得する際は画像認証によって一致し\nない場合は失敗のスタンプの身を獲得することにより不正にスタンプを取得することを防ぐことができる。また、\nJe",
            "は失敗のスタンプの身を獲得することにより不正にスタンプを取得することを防ぐことができる。また、\nJetpack Compose を活用したユーザーインターフェース（UI）の設計も、本システムにおいて重要な要素である。\nJetpack Compose は、Android アプリ開発のための宣言的なUI ツールキットであり、簡潔かつ直感的なコードで\n高品質なデザインを実現することができる。このアプリでは、Jetpack Compose を利用して、写真撮影ボタンや\nスタンプ獲得後のアニメーション、進捗状況を表示するインターフェースを設計している。例えば、ユーザーが目\n標地点に到達し写真を撮影した後、獲得したスタンプが画面にポップアップ表示されるようなアニメーションが\n実装されている。この視覚的なフィードバックは、ユーザーに達成感を与えるだけでなく、次の目標に向けたモチ\nベーションを喚起する役割を果たしている。さらに、スタンプの獲得状況を一覧表示する機能も搭載されており、\nユーザーが訪れた地点や残りの目標を一目で確認できる。この一覧はリアルタイムで動的に更新され、アプリ内\nでユーザーが進捗を",
            "や残りの目標を一目で確認できる。この一覧はリアルタイムで動的に更新され、アプリ内\nでユーザーが進捗を常に把握できる仕組みとなっている。データの保存にはRoom ライブラリが使用されており、\nこれによりスタンプや写真データがローカルデータベースに効率的に保存される。Room は、SQLite データベー\nスを抽象化するためのライブラリであり、型安全で信頼性の高いデータ操作を可能にする。本アプリでは、ユー\nザーが獲得したスタンプや撮影した写真、目標地点の達成履歴などをRoom を利用して管理している。これによ\nり、アプリが再起動された場合でも、ユーザーの進捗データは保持され、アプリケーションの利用体験が損なわれ\nることがない。また、過去の記録を参照する機能も提供されており、ユーザーはこれまでの成果を振り返ること\nができる。例としてはどの目標地点をいつ達成したのか、このような記録は、ユーザーが運動の成果を定量的に\n把握する手段として有効であると同時に次の目標設定に向けた参考情報としても活用される。さらにこれらの技\n術が統合されることで、アプリ全体の一貫性が保たれ、ユーザー体験が向上する。ML",
            "る。さらにこれらの技\n術が統合されることで、アプリ全体の一貫性が保たれ、ユーザー体験が向上する。ML Kit による画像解析結果と\nFused Location Provider による位置データが同期して動作することで、目標地点の達成判定が正確かつ迅速に行\nわれる。また、Jetpack Compose を使用したUI が、これらのバックエンドの動作をシームレスにユーザーに伝え\nる役割を果たしている。これにより、ユーザーはアプリの複雑な技術的処理を意識することなく、直感的かつス\nムーズに操作を行うことが可能となっている。このように、写真撮影機能とスタンプ獲得機能は、複数の先進的な\n技術の統合によって成り立っており、運動促進アプリとしての価値を最大限に引き出す仕組みが実現されている。\n4.5\n社会的意義におけるスタンプラリー機能の影響と可能性\nスタンプラリー機能は、単なる運動促進ツールとしての役割を超えて、個人の健康促進と社会的価値の創出を\n両立する新たなアプローチとして位置づけられる。この機能は、ユーザーが目標地点を訪れることでスタンプを獲\n得する仕組みを通じて、地域社会との結びつきを",
            "の機能は、ユーザーが目標地点を訪れることでスタンプを獲\n得する仕組みを通じて、地域社会との結びつきを強化し、地域活性化を促進する可能性を秘めている。まず、スタ\nンプラリー機能は、個人の健康促進に直接的な貢献を果たしている。特定の目標地点を訪れるよう促すこの仕組み\nは、運動の継続性を高めるだけでなく、日常生活において新たな移動パターンを生み出す。これにより、ユーザー\nは徒歩やランニングを通じて身体活動を増加させることができ、運動不足解消やストレス軽減といった健康上の\n利点を享受できる。また、目標地点が多様であることにより、単調になりがちな運動が変化に富んだ体験となり、\nユーザーのモチベーション維持に寄与する。このような仕組みは、特に初心者が運動習慣を形成するための有効な\n支援ツールとなる。次に、地域活性化への貢献について論じる。スタンプラリー機能の設計において、目標地点\nとして観光地や地域独自の施設、地元商業施設を選定することで、地域経済に直接的な影響を与えることが可能\nである。たとえば、ユーザーがスタンプを獲得するために訪れる地点を地元の店舗や観光スポットに設定すれば、\nそれらの場所に",
            "ユーザーがスタンプを獲得するために訪れる地点を地元の店舗や観光スポットに設定すれば、\nそれらの場所に対する訪問頻度が向上し、結果として地元経済の活性化につながる。特に観光地では、スタンプ\nラリーを通じて訪問者の流入を増やし、飲食店、土産物店、観光施設の利用促進が期待される。また、ユーザー\nが訪れる目標地点が分散されている場合には、観光客や住民が地域内を広範囲に移動することになり、地域全体\nに経済的な恩恵が波及する効果も見込まれる。さらに、スタンプラリー機能は、地域の文化的価値を再発見する\n手段としても重要な役割を果たす。目標地点として歴史的建造物、地元の伝統行事の会場、自然保護区などを選\n定することで、ユーザーが地域の歴史や文化に触れる機会を提供する。このような仕組みは、地域住民自身にも\n31\nその価値を再認識させることができ、地域全体の文化的アイデンティティを強化する要素として機能する。特に\n若年層が地域の文化や歴史に興味を持つきっかけとなり、世代を超えた地域コミュニティの形成にもつながる可能\n性がある。また、スタンプラリー機能は、ユーザー同士の交流を促進する社会的効果も期待される。",
            "がる可能\n性がある。また、スタンプラリー機能は、ユーザー同士の交流を促進する社会的効果も期待される。特定の目標\n地点を複数のユーザーが共有することで、偶然の出会いや交流が生まれる可能性が高まる。ユーザーがスタンプ\n獲得のために同じ地点を訪れた際に、互いに情報交換を行ったり、一緒に次の目標を目指したりすることが考えら\nれる。このようなインタラクションは、ユーザー同士の新たな繋がりを生み出し、個人の社会的ウェルビーイン\nグを向上させる効果がある。また、アプリ内でスタンプラリーの進捗や成果を共有する機能を導入すれば、オン\nライン上での交流や競争が促進され、地域全体での共同体意識が醸成される。スタンプラリー機能の社会的意義\nは、特に地域イベントとの連携において最大限に発揮される。地域の祭りやマラソン大会といったイベントの一\n環としてスタンプラリーを組み込むことで、参加者のアクティビティを増やし、イベントの魅力を向上させるこ\nとが可能である。たとえば、祭りの会場内に複数のスタンプ地点を設置し、参加者がそれらを巡ることで地域文\n化に触れつつ、運動も楽しむことができる。また、このようなイベントとアプ",
            "者がそれらを巡ることで地域文\n化に触れつつ、運動も楽しむことができる。また、このようなイベントとアプリを連動させることで、参加者の\n記録をデジタル化し、後から振り返ることができるという利便性も提供される。加えて、スタンプラリー機能は\n地域の教育的価値を高める可能性も秘めている。目標地点に関連する情報（例: 歴史的背景、自然環境の特徴、地\n元の名物など）をアプリ内で表示することで、ユーザーは運動をしながら学びを得ることができる。このような\n教育的要素は、特に学生や子どもたちにとって効果的であり、運動を通じて楽しく学べる環境を提供する。また、\n地域に訪れる観光客にとっても、単なる観光地巡りではなく、知識を深めながら楽しむ体験を提供することがで\nきる。さらに、スタンプラリー機能の持続可能性にも注目するべきである。この機能は、地域の観光資源や施設\nをデジタル化し、その価値をより広く普及させる手段として活用できる。たとえば、地元の観光協会が目標地点\nを選定し、アプリを通じて情報を発信することで、観光地の認知度を高めることが可能である。また、アプリを\n通じたデータ収集により、ユーザーの訪問頻度や移",
            "光地の認知度を高めることが可能である。また、アプリを\n通じたデータ収集により、ユーザーの訪問頻度や移動パターンを分析し、観光戦略の最適化にも貢献する。この\nように、スタンプラリー機能は、地域の観光や経済活動の持続可能な発展を支える要素として機能する。最後に、\nスタンプラリー機能は、健康促進、地域活性化、教育的価値の提供、そして社会的交流を融合させた統合的なア\nプローチを実現するものである。この機能をさらに発展させることで、地域社会における多様な課題に対応しな\nがら、個人と社会の幸福度を同時に向上させる可能性が広がる。本研究で開発されたスタンプラリー機能は、そ\nの具体例として、多くの地域や個人に新たな価値を提供することが期待される。\n32\n第5章\n結論\n5.1\n研究の背景と課題の明確化\n本研究では、社会調査を通じて現代社会における運動不足や健康促進に関連する課題を明らかにし、それらを\n解決する手段としてスタンプラリー機能を搭載した運動促進アプリケーションの開発に至った。このアプローチ\nは、社会的な課題をテクノロジーの活用を通じて解決するという点に特徴があり、運動を継続しやすくするため\nに",
            "社会的な課題をテクノロジーの活用を通じて解決するという点に特徴があり、運動を継続しやすくするため\nにゲーム的要素やインタラクティブな仕組みを取り入れてユーザー体験の向上を目指している。社会調査の結果、\n多くの人々が運動不足に直面しつつも継続的な運動を難しいと感じていることが明らかになった。その主な要因\nとして、運動の単調さや達成感の欠如、さらに運動成果が短期間では見えにくいことによるモチベーション低下\nが挙げられる。\n5.2\nスタンプラリー機能による運動促進の提案\nこれらの課題に対応するため、本研究では、運動を楽しくするためのゲーム的要素としてスタンプラリー機能\nを取り入れることを提案した。具体的には、目標地点を訪れることでスタンプを獲得する仕組みや運動成果を可\n視化するスコアシステム、写真撮影による達成の記録などの革新的な要素を統合している。これにより、運動を\n楽しさや挑戦感のあるものに変え、ユーザーのモチベーションを維持しやすくすることを狙っている。また、目\n標地点を地域の観光地や商業施設とすることで、個人の健康促進だけでなく地域活性化にも寄与する可能性を持\nつという社会的意義も備",
            "業施設とすることで、個人の健康促進だけでなく地域活性化にも寄与する可能性を持\nつという社会的意義も備えている。\n5.3\n課題\n本研究はまだ調査や設計、プロトタイプの構築にとどまり、実験的な検証は行われていない点が課題として残っ\nている。特に、スタンプラリー機能の効果、スコアシステムの有効性、写真撮影機能の利用効果、地域活性化へ\nの影響などについては、実験を通じた具体的なデータが必要である。また、アプリケーションが特定の地域や集\n団を超えて幅広いユーザー層に受け入れられるかを評価することも重要である。さらに、他の健康促進プログラ\nムや公共政策との連携を通じて、アプリケーションの社会的影響を拡大する可能性も検討する必要がある。本研\n究は運動促進と地域活性化の融合という新しいアプローチを提案したものであり、今後の研究と実験を通じてそ\nの実用性と社会的価値をさらに高めることが期待される。\n33\n第6章\n今後の展望\n6.1\nパーソナライズとAI 技術の統合\nパーソナライズとAI 技術の統合は現代のデジタルサービスにおいて重要な要素であり、ユーザーごとのニーズ\nに対応した体験を提供することでエンゲ",
            "デジタルサービスにおいて重要な要素であり、ユーザーごとのニーズ\nに対応した体験を提供することでエンゲージメントを向上させることができる。本研究で提案する運動促進アプ\nリケーションでも、AI 技術を活用して個々のユーザーに最適化された目標設定やモチベーション向上を目指す仕\n組みが導入されている。AI を活用する第一歩は、ユーザーの運動履歴、スタンプラリーの進捗状況、移動距離、\n位置情報、達成した目標の種類、運動頻度や利用時間帯などのデータを収集し、解析することである。これによ\nり個別のプロファイルを構築し、ユーザーごとの行動特性や好みを特定することが可能となる。これらのデータ\nを基にアプリケーションが動的に対応し、パーソナライズされた体験を提供する仕組みを実現する。またAI 技術\nの導入により、アプリケーションはユーザーに個別化された目標やアクティビティを提案する推奨システムを構\n築することが可能となる。例えばユーザーの現在地や移動履歴をもとに最適な目標地点を提案する機能では、自\n然豊かな場所を好むユーザーには公園や森林を、都市部を好むユーザーには観光地やモニュメントを提案するこ\nとがで",
            "場所を好むユーザーには公園や森林を、都市部を好むユーザーには観光地やモニュメントを提案するこ\nとができる。さらに過去のデータを分析して適切な運動頻度や距離、ペースを設定することで初心者には短距離\nや簡単な目標を、経験者にはややチャレンジングな目標を提示することも可能である。このような推奨機能によ\nりユーザーは自分に合った形で運動を楽しむことができ、結果としてアプリケーションの利用継続率が向上する。\nAI を活用するもう一つの重要なポイントは動的難易度調整（Dynamic Diﬃculty Adjustment, DDA）の実現であ\nる。ユーザーの運動履歴や目標達成率をもとに目標地点の難易度を動的に調整することで初心者には達成しやす\nい目標を提示し、経験者には挑戦的な目標を提案する仕組みを構築できる。また過去の成功率を考慮し達成感を\n高める目標と成功体験を積み重ねる目標のバランスを最適化することでユーザーが自分の成長を実感しながら無\n理なく運動を継続できるようになる。さらにAI を活用すれば感情状態やモチベーションの変化を解析し、それに\n応じたフィードバックを提供することも可能である。運",
            "ば感情状態やモチベーションの変化を解析し、それに\n応じたフィードバックを提供することも可能である。運動履歴や利用頻度が低下した場合に励ましのメッセージ\nを送ったり、特別なインセンティブを提供してモチベーションを回復させる仕組みを導入することでユーザーの離\n脱を防ぐことができる。ユーザーの感情データを活用して特定の運動がストレス軽減やポジティブな感情につな\nがる場合、その運動を優先的に推奨することで体験価値を向上させることも考えられる。AI 技術を活用してユー\nザー間の交流を促進するコミュニティ機能を統合することも将来的には有望である。例えば類似した運動パター\nンや目標を持つユーザーをマッチングしグループでのスタンプラリーを楽しむ機能を構築することで、ユーザー\n同士が競争や協力を通じてモチベーションを高め合う仕組みを提供することができる。このような機能は運動を\n通じた社会的なつながりを促進し、アプリケーションの利用価値をさらに高めると期待される。一方でAI 技術の\n導入にはデータプライバシーの保護と倫理的配慮が不可欠である。運動履歴や位置情報、さらには感情状態といっ\nたデータを取り扱うた",
            "ーの保護と倫理的配慮が不可欠である。運動履歴や位置情報、さらには感情状態といっ\nたデータを取り扱うため、データの匿名化やセキュリティの確保が求められる。ユーザーにデータ収集の目的や\n利用方法を明示し、選択肢を提供することで信頼関係を構築することが重要である。将来的にはAI 技術をさらに\n発展させ、運動促進アプリケーションを包括的な健康支援プラットフォームへ進化させることが考えられる。例\nえば運動習慣だけでなく栄養管理や睡眠データを統合的に分析し総合的な健康プランを提案する仕組みを構築す\nることも可能である。また拡張現実（AR）技術と組み合わせることでユーザーが目標地点をリアルタイムで視覚\n的に確認できる機能や、仮想空間上で他のユーザーと交流する仕組みを提供することも考えられる。このように\nパーソナライズとAI 技術の統合は運動促進アプリケーションをより高度で効果的なものに進化させ、ユーザーエ\nクスペリエンスを大幅に向上させる可能性を秘めている。\n34\n6.2\nゲーミフィケーションのさらなる深化\nゲーミフィケーションのさらなる深化は、運動促進アプリケーションの利用継続率やユーザーエンゲー",
            "る深化\nゲーミフィケーションのさらなる深化は、運動促進アプリケーションの利用継続率やユーザーエンゲージメント\nを高めるために重要なアプローチである。単純なスコアシステムやスタンプラリーの仕組みにとどまらず、より洗\n練されたゲーム要素を組み込むことで、ユーザーに新たなモチベーションを提供し、運動を楽しさと達成感を伴う\n体験へと昇華させることが可能となる。例えば、物語性を取り入れたストーリーベースの要素は、ユーザーの感\n情的な関与を引き出すうえで有効である。ユーザーがランニングやウォーキングを進めることで仮想の冒険を進\n行させる仕組みや、特定のミッションをクリアするたびに物語が展開する構造を導入すれば、運動の単調さを軽\n減し、ユーザーの達成意欲を刺激することができる。また、アプリ内での報酬システムを拡張することも、ゲー\nミフィケーションの深化に寄与する。単なるスタンプやバッジの付与に加え、アプリ内ポイントや仮想通貨を提\n供し、それを特典やアイテム、さらには現実世界での景品と交換できる仕組みを構築することで、ユーザーにとっ\nて実用的かつ具体的なメリットを提示できる。このような報酬システムは特",
            "構築することで、ユーザーにとっ\nて実用的かつ具体的なメリットを提示できる。このような報酬システムは特に継続的なモチベーションの維持に\n効果的である。また、報酬に希少性やランダム性を持たせることで、期待感を高める仕組みも考えられる。例え\nば、特定の目標を達成した際にランダムで高価値なアイテムが手に入る仕組みを導入すれば、ユーザーの挑戦意\n欲が一層高まる可能性がある。さらに、ユーザー間の競争や協力を促進する仕組みを強化することで、社会的な\n動機付けを取り入れることができる。ランキングシステムを導入して、ユーザー同士がスコアや成果を競い合う\n機会を提供することは、特に競争心の強いユーザーにとって強力なモチベーション源となる。一方で、協力型の\nゲーム要素を組み込むことで、コミュニティ意識を育むことも可能である。例えば、ユーザーがチームを組んで\n共同目標を達成する形式や、互いに応援メッセージを送り合える機能を追加することで、社会的なつながりが深\nまり、アプリへの依存度が高まる。また、リアルタイムで他のユーザーと競い合ったり協力したりできる機能を\n実装することで、オンラインでの交流やコミュニケーシ",
            "他のユーザーと競い合ったり協力したりできる機能を\n実装することで、オンラインでの交流やコミュニケーションが活性化する。ゲーミフィケーションをさらに深化\nさせるうえで、個別化された体験を提供するパーソナライゼーションの導入も不可欠である。AI を活用してユー\nザーの行動データや好みを分析し、個々のユーザーに最適化されたゲーム要素を提示することで、個別のニーズに\n応じた体験を提供することが可能となる。例えば、初心者には達成しやすい目標やシンプルなミッションを提示\nし、経験者にはチャレンジングな目標や高度な戦略が求められるタスクを提案することで、それぞれのユーザー\nが自分に適したレベルで楽しむことができる。このようなパーソナライズされたゲーミフィケーションの体験は、\nユーザーの継続的なエンゲージメントを促進し、運動のモチベーションを持続させる効果が期待される。また、拡\n張現実（AR）や仮想現実（VR）技術を活用することで、ゲーミフィケーションの体験をさらにリッチなものに\n進化させることができる。AR を用いて目標地点を視覚的に示したり、VR 空間で他のユーザーと競争する要素を\n組み込むことで",
            "。AR を用いて目標地点を視覚的に示したり、VR 空間で他のユーザーと競争する要素を\n組み込むことで、ゲームの没入感が高まり、現実の運動と仮想の体験が融合した新しい形のゲーミフィケーショ\nンを提供することが可能となる。具体的な例としてはランニング中にAR で仮想の敵と対決するシナリオを実現\nしたり、指定されたルートを走破することでVR 空間上で新たなエリアを解放する仕組みを構築すれば、運動そ\nのものがエンターテインメントとしての側面を持つようになる。さらに、ユーザーにとっての運動の意義を拡大\nするため、ゲーミフィケーションを教育や社会的貢献と結びつける取り組みも考えられる。例えば、特定の目標\nを達成することで地域社会への寄付が行われる仕組みや、エコランニング（環境保護を意識したランニング）を\n推進するゲーム要素を導入することで、運動を通じた社会的意識の向上を図ることができる。このような取り組\nみは、単なる個人の楽しみを超えて、より大きな目的意識をユーザーに提供することで、アプリの持続可能性と\n社会的価値を高めることができる。また、ゲーミフィケーションの深化を支える技術基盤として、リアル",
            "性と\n社会的価値を高めることができる。また、ゲーミフィケーションの深化を支える技術基盤として、リアルタイム\nデータ処理やクラウドインフラの活用が求められる。特に大規模なユーザー基盤を持つアプリケーションでは、多\n数のユーザーが同時に参加するゲーム要素をリアルタイムで動的に処理する技術が重要となる。これを実現する\nためには、クラウドベースのサーバーアーキテクチャや分散型データベースの導入が不可欠である。これにより、\nユーザーがどのようなデバイスを使用していてもスムーズにゲーム体験を享受できる環境を提供することができ\nる。ゲーミフィケーションのさらなる深化は、単なる運動支援を超えたエンターテインメント性のある健康促進\nプラットフォームを実現する可能性を秘めている。\n35\n6.3\n地域との連携強化\n地域との連携強化は、運動促進アプリケーションが単なる個人向けのツールとして機能するだけでなく、地域\n社会全体に価値を提供するプラットフォームとして進化するために重要な要素である。特にスタンプラリー機能\nは、地域の観光地や地元施設との連携を通じて、運動を促進しながら地域活性化を実現するポテンシャルを",
            "能\nは、地域の観光地や地元施設との連携を通じて、運動を促進しながら地域活性化を実現するポテンシャルを持つ。\n本アプローチでは、地域の名所や特色ある施設を目標地点として設定し、ユーザーが運動をしながらそれらの場\n所を訪れる仕組みを構築することができる。これにより、地域の知名度向上や観光客の誘致、地元経済の活性化\nが期待される。また、スタンプラリーを地域のイベントや祭りと連動させることで、運動促進アプリケーション\nはさらに高い効果を発揮することができる。例えば、季節ごとに異なるテーマを設定し、春には桜の名所、夏に\nは海や花火大会の会場、秋には紅葉スポット、冬にはイルミネーションや温泉地を目標地点とすることで、ユー\nザーに新しい発見や楽しみを提供できる。このような季節限定のスタンプラリーは、地域の観光資源を最大限に\n活用するとともに、ユーザーが定期的にアプリを利用する動機付けとなる。また、地域特有の文化や伝統を体験\nできるポイントを目標地点に組み込むことで、ユーザーがその地域の魅力をより深く知る機会を提供することも\n可能である。例えば、地元の伝統工芸品の製作体験や特産品を味わえる飲食店を目標",
            "る機会を提供することも\n可能である。例えば、地元の伝統工芸品の製作体験や特産品を味わえる飲食店を目標地点に設定することで、運\n動が単なる身体活動ではなく、学びや発見を伴う豊かな体験へと昇華する。このような取り組みを通じて、運動\n促進アプリケーションは地域との強いつながりを構築することができる。さらに、地域の商業施設や店舗と提携\nし、スタンプ獲得後に特典を受けられる仕組みを導入することも効果的である。例えば、特定の目標地点を訪れ\nてスタンプを獲得したユーザーには、提携店舗で割引を受けられるクーポンやプレゼントを提供する仕組みを作\nることで、地域の店舗に足を運ぶきっかけを作り、地元経済の活性化に寄与することができる。このようなインセ\nンティブは、アプリの利用者にとっても運動を継続するモチベーションとなる。また、地元企業や自治体と連携\nして、特定のエリア内での運動促進キャンペーンを実施することも考えられる。例えば、地域全体を対象とした\n「健康増進月間」を設定し、その期間中に一定のスタンプを獲得したユーザーに地域の特産品をプレゼントする仕\n組みを構築することで、地域住民全体の健康意識を高めると",
            "したユーザーに地域の特産品をプレゼントする仕\n組みを構築することで、地域住民全体の健康意識を高めるとともに、地域全体での一体感を醸成することができ\nる。このようなキャンペーンは、特に自治体や地域団体が主導する場合、地域社会の課題解決に直接的に寄与す\nる可能性が高い。また、地域との連携をさらに強化するためには、アプリケーション内で地域の情報を積極的に\n発信する仕組みを導入することが重要である。例えば、目標地点に関連する歴史的背景や観光情報、地元のイベ\nント情報をアプリ内で提供することで、ユーザーが地域の魅力を深く理解し、訪れる動機を強化することができ\nる。さらに、地域の住民がスタンプラリーの目標地点や内容の提案に参加できる仕組みを構築することで、地域住\n民自らが主体的に参加できる環境を作ることも考えられる。このような双方向的なアプローチは、地域住民とア\nプリ利用者との間に新しい形のつながりを生み出す可能性を秘めている。また、スタンプラリーを地域の課題解\n決と結びつけることで、社会的な意義をさらに高めることができる。例えば、地域の清掃活動やエコプロジェク\nトと連動したスタンプラリーを実施す",
            "さらに高めることができる。例えば、地域の清掃活動やエコプロジェク\nトと連動したスタンプラリーを実施することで、地域住民やユーザーが運動を通じて地域貢献を実感できる仕組\nみを作ることができる。このような活動は、地域の環境保護や社会課題解決にもつながり、アプリケーションの\n価値をさらに高めることができる。さらに、地域の観光協会や商工会議所との連携を強化することで、スタンプ\nラリーの内容をより充実させることが可能となる。例えば、観光地を巡るスタンプラリーを実施する際、観光協\n会が持つ情報やリソースを活用することで、より魅力的なコンテンツを提供することができる。また、商工会議\n所と連携して地元企業や店舗を巻き込むことで、スタンプラリーを通じた地域経済の活性化を図ることができる。\nこのような地域との連携を強化するためには、アプリケーションの柔軟性と拡張性を確保することが重要である。\n例えば、地域ごとの独自コンテンツを容易に追加できる機能を導入することで、さまざまな地域のニーズに応え\nることができる。また、地域の特性やニーズに応じたカスタマイズが可能なプラットフォームを構築することで、\nより多くの",
            "。また、地域の特性やニーズに応じたカスタマイズが可能なプラットフォームを構築することで、\nより多くの地域との連携を実現することができる。さらに、地域住民やアプリ利用者がスタンプラリーの企画に\n参加できる仕組みを提供することで、地域社会との一体感を強化することも可能である。このように、運動促進\nアプリケーションにおける地域との連携強化は、個人の健康促進と地域社会の活性化を両立させるうえで極めて\n重要な要素であり、今後の発展においてさらなる注目を集めることが期待される。\n36\n6.4\n社会的包摂を目指した機能追加\n社会的包摂を目指した機能の導入は、運動促進アプリケーションが多様な背景を持つユーザーに対応し、誰も\nが利用しやすい環境を提供するために不可欠な要素である。この取り組みは、高齢者や障害を持つ人々、社会的\nに孤立しがちな人々など、運動へのアクセスが制限される可能性のある層にも、健康促進の機会を提供すること\nを目的としている。そのためには、まずインクルーシブなデザインの実現が求められる。例えば、視覚障害者向\nけに画面リーダーとの互換性を確保し、音声ガイドや振動通知を導入することで、アプ",
            "例えば、視覚障害者向\nけに画面リーダーとの互換性を確保し、音声ガイドや振動通知を導入することで、アプリの機能を視覚に依存せ\nずに利用できるようにする。また、操作をシンプルにし、直感的に利用できるインターフェースを構築すること\nも重要である。一方で、聴覚障害を持つユーザーに対しては、ビジュアル通知を強化し、運動中に重要な情報を\n適切に伝達するためのアニメーションや視覚的なフィードバックを活用することが考えられる。また、言語の壁\nを取り除くために、多言語対応を実現することも重要である。特に、移民や多文化背景を持つユーザーが増加し\nている現代では、利用者の母国語で情報を提供することが、アプリの普及と社会的包摂の観点から重要な要素と\nなる。さらに、高齢者にとって運動が心理的にも身体的にも負担とならないようにするため、負荷の少ない目標\n設定やリマインダー機能の導入も効果的である。例えば、短い距離のウォーキングや椅子に座ったままできる運\n動を提案し、それを達成可能な目標としてアプリが自動的に設定する機能を備えることが考えられる。このよう\nな機能は、ユーザーが自己効力感を高めるきっかけとなり、運動へ",
            "機能を備えることが考えられる。このよう\nな機能は、ユーザーが自己効力感を高めるきっかけとなり、運動への参加を促進する。また、孤立感を感じやすい\n人々に対しては、コミュニティ機能を強化することが有効である。例えば、ユーザー同士がオンラインで交流し\nたり、励まし合うことができるプラットフォームを提供することで、社会的なつながりを構築することができる。\nまた、地域の実際のイベントや集団活動と連携させることで、アプリがデジタルとリアルの橋渡しを行い、ユー\nザーが地域社会との結びつきを感じられるようにする。このような取り組みは、運動促進だけでなく、孤独や社会\n的孤立といった課題に対応するうえでも効果的である。さらに、障害を持つ人々向けには、運動の種類をパーソ\nナライズし、個々の身体能力に合わせた提案を行う仕組みが求められる。例えば、特定の身体部分だけを動かす\n運動や、リハビリテーションと結びついたメニューを提示することで、障害の種類や程度に応じた運動を提供す\nることが可能となる。また、ゲーミフィケーションの要素を加えることで、運動を楽しい体験へと変えることも\n効果的である。例えば、バーチャルアバ",
            "ーションの要素を加えることで、運動を楽しい体験へと変えることも\n効果的である。例えば、バーチャルアバターを用いて運動成果を可視化し、ユーザーが達成感を感じられる仕組\nみを導入することが考えられる。このような視覚的な要素は、特に言葉や数値による情報伝達が難しい場合でも、\nユーザーが感覚的に理解しやすいという利点がある。また、AI 技術を活用してユーザーごとの運動習慣や嗜好を\n学習し、最適化された運動メニューを提案することで、個別のニーズに応えることができる。この技術は、特に\n複雑なニーズを持つユーザーに対して、パーソナライズされた体験を提供するうえで有用である。さらに、社会\n的包摂を目的とした運動促進アプリケーションは、経済的な障壁にも対応する必要がある。アプリ内の機能を無\n料または低コストで提供し、すべてのユーザーが平等にアクセスできるようにすることが重要である。また、ス\nポンサーシップや寄付を活用して、経済的に困難な状況にある人々がアプリを利用できる仕組みを構築すること\nも考えられる。こうした取り組みは、運動を始める際の心理的・経済的な負担を軽減し、社会全体で健康促進を\n支援する環境",
            "こうした取り組みは、運動を始める際の心理的・経済的な負担を軽減し、社会全体で健康促進を\n支援する環境を作り出すことに寄与する。さらに、社会的包摂の観点からは、アプリのフィードバック機能も重\n要である。運動の成果を評価するだけでなく、ユーザーの努力や継続性を認めるポジティブなメッセージを提供す\nることで、心理的な支援を行うことができる。このようなポジティブなフィードバックは、特に運動に自信がな\nいユーザーに対して大きな効果を持つ。運動の効果や進捗を分かりやすく視覚化することで、ユーザーが自分の\n成長を実感できるようにすることも有効である。このように、社会的包摂を目指した機能の導入は、運動促進ア\nプリケーションをすべての人々にとって利用しやすく、魅力的なものにするための重要なステップである。これに\nより、運動の機会を広く提供し、健康促進と社会的つながりの強化を同時に達成することが期待される。\n6.5\n環境意識を高める仕組みの導入\n環境意識を高める仕組みを運動促進アプリケーションに導入することは、個人の健康促進と地球環境の保護を\n同時に推進するために重要である。この取り組みは、ユーザーが運動",
            "は、個人の健康促進と地球環境の保護を\n同時に推進するために重要である。この取り組みは、ユーザーが運動を通じて環境問題に対する意識を高め、日\n37\n常生活で持続可能な行動を選択するきっかけを提供することを目的としている。具体的には、アプリ内で運動と\n環境活動を結びつける仕組みを構築することが考えられる。ユーザーが一定の距離をランニングやウォーキング\nで移動するごとに、植樹や森林再生プロジェクトへの貢献としてポイントが付与されるシステムを導入する。こ\nのような仕組みによって、運動を行うことが環境保護活動への直接的な貢献につながるというモチベーションを\n提供できる。また、目標地点を環境保護に関連する場所に設定することで、ユーザーが自然環境の価値を実際に\n体験できる仕組みも有効である。地域の保護区、エコパーク、再生された森林などをスタンプラリーの目標地点\nとすることで、ユーザーは運動中に環境保護の重要性を学ぶことができる。さらに、ゴミ拾いやリサイクル活動\nと連動したイベントを企画し、それをアプリ内のチャレンジとして設定することも効果的である。例えば、ユー\nザーがランニング中に拾ったゴミの写真を",
            "内のチャレンジとして設定することも効果的である。例えば、ユー\nザーがランニング中に拾ったゴミの写真をアプリ内で投稿すると、ポイントやバッジを獲得できる仕組みを導入\nすることで、楽しみながら環境保護活動に参加する機会を提供することができる。運動時の消費カロリーや移動\n距離をCO2 削減量に換算し、視覚的にフィードバックする機能もユーザーの環境意識を高める一助となる。この\n機能では車や公共交通機関を使った場合と比較して、どれだけのCO2 排出を削減できたかをグラフや数値で表示\nすることで、個人の行動が環境に与えるポジティブな影響を具体的に実感できるようにする。さらに、アプリ内\nで環境に配慮した行動の提案を行うことも有効である。地域のエコイベントへの参加を推奨する通知機能や、持\n続可能なライフスタイルを学べる記事や動画を提供するセクションを設けることで、ユーザーが環境についての\n知識を深め、実際の行動につなげる機会を増やすことができる。また、アプリの利用者同士が環境活動に関する\n情報を共有できるコミュニティ機能を導入することも考えられる。これにより、ユーザー間での相互啓発が進み、\n環境意識の",
            "るコミュニティ機能を導入することも考えられる。これにより、ユーザー間での相互啓発が進み、\n環境意識の向上だけでなく、社会的なつながりも強化される。加えて、環境活動に積極的な企業や団体と連携し、\nアプリ内で環境保護プロジェクトの進捗状況や成果を共有することで、ユーザーに達成感や参加意識を提供する\nことも可能である。例えば、一定の運動目標を達成したユーザーに対して、企業からの寄付が環境保護プロジェク\nトに行われる仕組みを導入することで、社会的意義を感じながら運動を続けられる環境を作り出すことができる。\nまた、地域の環境問題に特化したスタンプラリーを実施することで、ユーザーが自分たちの住む地域の課題を認\n識し、それに対して主体的に取り組む機会を提供することができる。河川や公園の清掃活動をアプリ内のチャレ\nンジとして設定し、参加者にポイントや特典を与える仕組みを導入することで、地域の環境保護に貢献しながら\n運動を楽しむことができる。このように、環境意識を高める仕組みは、運動促進アプリケーションを単なる健康\n管理ツールとしてだけでなく、環境保護を促進するプラットフォームとして進化させる可能性を秘",
            "単なる健康\n管理ツールとしてだけでなく、環境保護を促進するプラットフォームとして進化させる可能性を秘めている。これ\nらの取り組みを通じて、ユーザーが自分自身の健康を維持するだけでなく、地球環境の保護に貢献する意識を高\nめることが期待される。このような仕組みを導入することで、持続可能な社会の実現に向けた一歩を踏み出すこ\nとができる可能性がある。\n6.6\nクロスプラットフォーム展開と他サービスとの統合\nクロスプラットフォーム展開と他サービスとの統合は、運動促進アプリケーションのユーザー体験を向上させ、\n利用者の裾野を広げる上で重要な要素である。現代のデジタル環境では、異なるデバイスやプラットフォームでア\nプリを利用したいというニーズが高まっており、この要件に対応することで、ユーザーにシームレスな体験を提供\nすることが可能となる。クロスプラットフォーム展開のためには、React Native やFlutter のようなフレームワー\nクを活用して、単一のコードベースでAndroid とiOS の両方に対応したアプリケーションを構築するアプローチ\nが考えられる。このような技術を利用することで、開",
            "両方に対応したアプリケーションを構築するアプローチ\nが考えられる。このような技術を利用することで、開発コストを抑えつつ、幅広いユーザー層に対応することが\nできる。また、PWA（プログレッシブウェブアプリ）を採用することで、ネイティブアプリとしての機能を備え\nながら、デスクトップやモバイルウェブブラウザを通じて利用できるようにすることも有効である。これにより、\nアプリをインストールせずにアクセスできる利便性を提供し、より多くのユーザーに利用される可能性が高まる。\nまた、クロスプラットフォーム展開を成功させるためには、データ同期とアカウント管理の仕組みが重要である。\nユーザーが複数のデバイス間でシームレスにデータを共有できるように、クラウドベースのデータストレージを\n導入する必要がある。Firebase やAWS Amplify などのサービスを活用することで、ユーザーデータをリアルタイ\nムで同期し、デバイス間の移行をスムーズに行える仕組みを構築することができる。さらに、ユーザーの利便性\n38\nを向上させるために、他サービスとの統合を進めることも重要である。例えば、Google Fit や",
            "8\nを向上させるために、他サービスとの統合を進めることも重要である。例えば、Google Fit やApple Health と連\n携することで、運動データを一元管理し、他の健康管理データと統合することが可能となる。このような統合に\nより、ユーザーは運動だけでなく、食事、睡眠、ストレス管理などの総合的な健康情報を把握することができる。\nまた、ソーシャルメディアプラットフォームとの連携も、ユーザー体験を向上させる重要な要素である。例えば、\nユーザーがアプリ内で獲得したスタンプや運動成果をInstagram やTwitter、Facebook などで共有できる機能を\n導入することで、ユーザー同士の交流が活発化し、アプリの利用が拡大する可能性がある。さらに、運動をゲーム\n化するゲーミフィケーションの要素を強化するために、他のゲーミフィケーションプラットフォームやサービスと\n統合することも考えられる。Strava やRunkeeper のような既存の運動追跡アプリと連携し、ユーザーがこれらの\nサービスで記録した運動データを活用してスタンプラリーの進捗を自動的に更新できる仕組みを導入することで、",
            "ービスで記録した運動データを活用してスタンプラリーの進捗を自動的に更新できる仕組みを導入することで、\nユーザーの利便性と満足度を向上させることができる。また、地域活性化を目指す場合には、地元の商業施設や\n観光地との統合も有効である。アプリ内で特定の目標地点を訪れたユーザーに対して、地域の提携店舗で使用で\nきるクーポンを提供する仕組みを導入することで、地域経済の活性化に貢献することができる。さらに、e コマー\nスプラットフォームとの統合も検討すべきである。例えば、アプリ内で獲得したポイントをAmazon や楽天市場\nでの買い物に使用できるようにすることで、ユーザーのモチベーションをさらに高めることが可能となる。この\nような仕組みは、ユーザーに対して明確なインセンティブを提供し、アプリの利用頻度を高める効果が期待され\nる。また、企業のウェルビーイングプログラムとの統合も考えられる。企業が従業員の健康促進の一環としてこ\nのアプリを導入し、従業員がアプリ内で設定された運動目標を達成することで企業内での特典を受けられる仕組\nみを提供することができる。このようなB2B の統合は、企業と個人の両方に",
            "内での特典を受けられる仕組\nみを提供することができる。このようなB2B の統合は、企業と個人の両方に価値を提供し、アプリの利用範囲を\nさらに拡大する可能性がある。さらに、学術研究や公衆衛生の分野との連携も検討することで、アプリの社会的\n意義を高めることができる。アプリで収集された匿名化データを用いて運動の健康効果や行動パターンに関する\n研究を行うことで、社会全体の健康増進に寄与することが可能となる。このようなデータは、地域ごとの運動状\n況を可視化し、公衆衛生政策の立案にも活用できる。また、クロスプラットフォーム展開や他サービスとの統合\nを進めるにあたり、データの安全性とプライバシー保護が極めて重要である。特に、個人情報や健康データを扱\nう場合、GDPR やCCPA などの国際的なプライバシー規制に準拠した仕組みを導入する必要がある。これには、\nデータ暗号化やユーザー同意の取得、データの利用目的を明確化するポリシーの策定が含まれる。クロスプラット\nフォーム展開と他サービスとの統合を通じて、運動促進アプリケーションは、個人の健康促進を超えた幅広い社\n会的価値を提供するツールへと進化する可能",
            "運動促進アプリケーションは、個人の健康促進を超えた幅広い社\n会的価値を提供するツールへと進化する可能性を秘めている。これらの取り組みを進めることで、ユーザーがど\nのような環境や状況でもアプリを利用しやすくなるだけでなく、他のサービスやコミュニティと連携することで、\n運動を通じた新たなつながりや価値を生み出すことが期待される。\n6.7\n学習要素の追加\n学習要素の追加は、運動促進アプリケーションの価値をさらに高めるとともに、ユーザーの知識向上や意識改\n革に寄与する重要な取り組みである。このアプローチでは、運動の記録やスタンプラリー機能だけでなく、ユー\nザーが健康、運動、生理学、栄養学、環境問題などについて学ぶ機会を提供することで、アプリの利用をより有意\n義なものにすることが可能となる。具体的には、運動と学習を結びつけるためのさまざまなコンテンツや機能を\n設計することが考えられる。例えば、スタンプラリーの目標地点に関連する歴史的背景や文化的意義、自然環境\nについての解説をアプリ内に組み込むことで、ユーザーがその地域や場所についての知識を深められる仕組みを\n提供することができる。また、運動を通",
            "で、ユーザーがその地域や場所についての知識を深められる仕組みを\n提供することができる。また、運動を通じて健康や栄養に関する情報を学べるセクションを導入することも有効\nである。ユーザーがランニングやウォーキングを行う際、その運動が体にどのような影響を与えるのか、どのよ\nうな栄養素を摂取すれば運動効果を高められるのかといった知識を短い記事や動画形式で提供することで、ユー\nザーは運動そのものの価値を理解しやすくなる。このような学習コンテンツをユーザーの運動データや進捗に基\nづいてパーソナライズすることで、より効果的な学びを提供することができる。例えば、一定の距離を達成した際\nに、関連するテーマの学習コンテンツをアンロックする仕組みを導入することで、運動の達成感と学習の達成感\nを同時に提供することができる。また、クイズやテスト形式の学習要素を取り入れることも効果的である。ユー\n39\nザーがスタンプラリーで特定の目標地点を訪れた際、その場所に関連する知識を問うクイズが表示される仕組み\nを導入することで、ゲーム性を高めながら知識を深めることができる。このようなクイズには、正解することで追\n加ポイン",
            "とで、ゲーム性を高めながら知識を深めることができる。このようなクイズには、正解することで追\n加ポイントや特別なバッジを獲得できるインセンティブを付与することで、ユーザーの学習意欲をさらに高める\nことが可能となる。さらに、アプリ内で学習要素を強化するために、専門家や教育機関との連携を図ることも考\nえられる。運動科学や健康分野の専門家が監修したコンテンツを提供することで、ユーザーは信頼性の高い情報\nにアクセスすることができる。また、環境問題や地域社会に関連する教育機関と提携し、地域固有の課題につい\nての情報を提供することで、ユーザーが自身の行動の影響をより深く理解できる仕組みを作ることも有効である。\nこのほか、学習要素を強化するために、アプリ内での報酬システムを活用することも重要である。特定の学習モ\nジュールを完了することでポイントが付与され、それを他の運動チャレンジやアプリ内の特典に利用できる仕組\nみを導入することで、学びと運動の双方を促進する相乗効果を生み出すことができる。これにより、ユーザーは\n学習を単なる義務感で行うのではなく、楽しみながら進められるようになる。さらに、ソーシャル機",
            "ーザーは\n学習を単なる義務感で行うのではなく、楽しみながら進められるようになる。さらに、ソーシャル機能を活用して\n学習要素を強化することも考えられる。例えば、ユーザー同士が学んだことを共有したり、特定のテーマに関す\nるディスカッションに参加したりする機能を導入することで、学びを深めるだけでなく、コミュニティ内での交流\nを促進することが可能となる。また、学習内容に基づいてユーザーが新しい運動目標を設定できる機能を導入す\nることで、学びと実践を結びつけることができる。運動が特定の健康効果を持つことを学んだユーザーが、その\n効果を実現するための運動プランをアプリ内で設定し、それに基づいて日々の活動を管理する仕組みを提供する\nことで、学習が実際の行動変容につながる。最後に、AI 技術を活用して学習要素をパーソナライズし、ユーザー\nごとに適したコンテンツを提供することも効果的である。ユーザーの興味関心や運動パターン、進捗状況に基づ\nいて、学習内容をカスタマイズすることで、より効率的かつ魅力的な学びの体験を提供することができる。この\nような学習要素の追加により、運動促進アプリケーションは、単なる健",
            "の体験を提供することができる。この\nような学習要素の追加により、運動促進アプリケーションは、単なる健康管理ツールを超えた教育的価値を持つプ\nラットフォームになる。\n6.8\nグローバル展開\nグローバル展開は、運動促進アプリケーションの潜在的な市場を最大化し、世界中のユーザーに健康促進と運\n動習慣を支援する機会を提供するための重要な戦略である。グローバル展開を成功させるためには、各地域の文\n化、言語、健康に関する習慣を理解し、それらをアプリの設計や機能に反映させることが不可欠である。最初の\nステップとして、アプリの多言語対応が挙げられる。主要な国際言語での翻訳を行うだけでなく、地域固有の方言\nや表現を考慮に入れることで、ユーザーが自国の文化に即した体験を得られるようにする必要がある。この多言\n語対応は、単なる文字の翻訳にとどまらず、UI デザインや文化的に適切な表現を取り入れることで、地域ごとの\n多様性に対応することが重要である。さらに、地域ごとの運動習慣やライフスタイルの違いを考慮した機能のカ\nスタマイズも必要である。一部の国では屋内での運動が主流である一方で、他の国では屋外活動が一般的",
            "のカ\nスタマイズも必要である。一部の国では屋内での運動が主流である一方で、他の国では屋外活動が一般的である\n場合がある。これに対応して、アプリ内で提供する運動プランや目標設定を地域ごとに最適化することが求めら\nれる。また、地域特有の気候や地形、祝祭日や伝統的なイベントを考慮したスタンプラリーの目標地点やチャレ\nンジを設計することで、現地ユーザーにとって親しみやすい体験を提供することが可能になる。さらに、グロー\nバル展開を支援するためには、現地パートナーとの連携が重要である。地域の健康機関、スポーツ団体、企業と\n協力し、アプリの知名度を高めるとともに、現地ユーザーのニーズに即した機能やサービスを開発することがで\nきる。例えば、特定地域で人気のあるスポーツやアクティビティに特化したチャレンジを提供することで、現地\nユーザーの参加を促進することができる。地域の観光地や商業施設を目標地点として設定し、それらと連携した\n報酬や特典を提供することで、地域経済の活性化にも寄与する。このような取り組みは、ユーザーと地域社会の\n両方に利益をもたらすことができる。さらに、グローバル展開においては、技術的な",
            "、ユーザーと地域社会の\n両方に利益をもたらすことができる。さらに、グローバル展開においては、技術的なスケーラビリティを確保す\nることも重要である。アプリが多くのユーザーに利用されるようになると、サーバー負荷の増大やデータ管理の\n複雑化が課題となる。これに対応するために、クラウドベースのインフラを活用し、地域ごとに分散型のデータ\nセンターを配置することで、各地域での迅速なレスポンスと高い可用性を確保することができる。各国のプライ\nバシー規制やデータ保護法（例: GDPR）を遵守し、ユーザーデータの安全性を確保することも必須である。こ\n40\nれには、データの暗号化や匿名化、明確なデータ利用方針の策定が含まれる。さらに、グローバル展開を成功さ\nせるためには、マーケティング戦略の適応も必要である。異なる地域ごとに効果的なプロモーション方法を選択\nし、現地の文化や習慣に合わせた広告キャンペーンを展開することが求められる。特定の地域ではソーシャルメ\nディアが主要な情報源となる一方で、他の地域ではテレビ広告や地元のイベントを活用した方が効果的な場合が\nある。このように地域ごとの消費者行動に応じた柔軟",
            "ビ広告や地元のイベントを活用した方が効果的な場合が\nある。このように地域ごとの消費者行動に応じた柔軟な戦略を採用することが、グローバル市場での成功に繋が\nる。また、グローバル展開を進める中で、ユーザー間の国際的なつながりを促進することも価値がある。例えば、\nアプリ内でユーザーが異なる国の参加者と運動成果を競争したり、協力して目標を達成したりすることができる\n仕組みを導入することで、国境を越えたコミュニティの形成を支援することが可能となる。このような国際的な\n交流の機会は、アプリの利用価値を高めるだけでなく、多文化理解を促進する効果も期待できる。さらに、グロー\nバル展開では、現地のユーザーからのフィードバックを積極的に取り入れ、アプリの改善に役立てることが重要\nである。ユーザーの意見を収集し、それを基に新しい機能や調整を行うことで、現地ニーズに即したアプリ体験\nを提供し続けることができる。また、地域ごとの成功事例やユーザーの声を共有することで、新規ユーザーの獲\n得にも繋がる。最後に、グローバル展開の取り組みは、単にアプリを世界中で利用可能にすることを超えて、異\nなる文化や習慣に対応しなが",
            "バル展開の取り組みは、単にアプリを世界中で利用可能にすることを超えて、異\nなる文化や習慣に対応しながら、ユーザーにとって価値ある体験を提供するものである。このような展開を通じ\nて、アプリは単なる健康管理ツールから、世界中の人々をつなぎ、健康的なライフスタイルを推進するための包\n括的なプラットフォームへと進化する可能性を秘めている。これにより、運動促進アプリケーションは、地域社会\nとグローバルコミュニティの双方において、社会的および経済的な価値を提供する存在となる。\n6.9\nデータ解析による継続的な改善\nデータ解析による継続的な改善は、運動促進アプリケーションの品質向上とユーザー体験の最適化において重\n要な役割を果たす。アプリケーションを通じて収集される多様なデータを活用することで、ユーザー行動のパター\nンを把握し、運動習慣の形成を支援するための効果的なインサイトを得ることが可能となる。ユーザーがどのよ\nうなタイミングでアプリを利用し、どのような運動を好むのか、またどのような要素がモチベーション維持に寄\n与しているかを分析することが含まれる。GPS データや運動の進捗状況、スタンプラリー",
            "ション維持に寄\n与しているかを分析することが含まれる。GPS データや運動の進捗状況、スタンプラリーの達成記録、写真撮影\nの頻度などのデータを統合して解析することで、ユーザーが特に達成感を感じる瞬間や、逆にアプリ利用を停止\nする要因を特定することができる。このようなデータは、アプリ設計の改善に直接的に活用され、ユーザーごと\nにパーソナライズされた体験を提供するための基盤となる。また、継続的な改善を実現するためには、データの\n収集と解析がリアルタイムで行われる仕組みを構築することが重要である。クラウドベースのデータ管理システ\nムを利用することで、大量のデータを迅速に処理し、リアルタイムでのフィードバックを可能にする。ユーザー\nがアプリ内で新しい目標を設定した場合、その目標に応じた適切な運動プランやスタンプラリーのチャレンジを\n即座に提案できる仕組みを実装することで、ユーザーエンゲージメントを向上させることができる。このような\nデータ駆動型のアプローチは、アプリケーション全体の柔軟性と適応性を高め、ユーザーの期待に応じた体験を提\n供することを可能にする。また、データ解析は新しい機能の導入や",
            "を高め、ユーザーの期待に応じた体験を提\n供することを可能にする。また、データ解析は新しい機能の導入や既存の機能の調整にも役立つ。どのスタンプ\nラリー目標が最も多くのユーザーに達成されているのか、またはどの機能が利用されていないのかを特定するこ\nとで、目標の難易度や報酬の調整、不要な機能の削除や改善が可能になる。さらに、ユーザー行動を時間軸で分\n析することで、長期間にわたる運動習慣の変化や、アプリ利用における課題を把握することができる。この情報\nを基に、運動習慣が継続しやすいようなアプリデザインを検討し、ユーザーがより効果的に目標を達成できるよ\nうサポートする仕組みを構築することができる。加えて、ユーザーの属性（例: 年齢、性別、運動経験の有無）に\n基づいて行動をセグメント化し、それぞれのグループに最適な体験を提供することも可能である。初心者向けに\nは簡単な目標と高頻度のポジティブフィードバックを提供し、経験者向けにはチャレンジングな目標や報酬を提\n案することで、それぞれのニーズに応じたサポートを行うことができる。また、データ解析を通じて得られるイ\nンサイトは、ユーザー自身に対しても提供",
            "ポートを行うことができる。また、データ解析を通じて得られるイ\nンサイトは、ユーザー自身に対しても提供されるべきである。ユーザーが自身の運動履歴や達成状況を視覚的に\n把握できるダッシュボードを用意し、継続的な改善に役立てられるようにする。月間の運動時間や消費カロリー、\n獲得したスタンプ数などをグラフやチャートで表示することで、ユーザーは自分の進捗を簡単に確認でき、次の目\n41\n標に向けたモチベーションを維持しやすくなる。このようなデータ可視化は、ユーザーが自分の行動に価値を感\nじ運動を続ける意欲を高める効果が期待される。また、データ解析はアプリケーションの品質管理にも重要な役\n割を果たす。バグやエラーの発生頻度を追跡し、ユーザーが直面している技術的な問題を早期に特定することで、\n迅速な対応が可能となる。さらに、ユーザーからのフィードバックデータを収集・分析し、それを製品改善のサイ\nクルに組み込むことで、ユーザー満足度の向上を図ることができる。これにより、アプリの信頼性とユーザー体\n験が向上し、長期的な利用を促進することができる。データ解析を活用して継続的に改善を行うことで、単なる\n運動促",
            "し、長期的な利用を促進することができる。データ解析を活用して継続的に改善を行うことで、単なる\n運動促進ツールとしての役割を超えユーザーの健康的なライフスタイル形成を総合的に支援するプラットフォー\nムとしての地位を確立することが可能となる。これによりユーザーにとっては運動がより身近で楽しいものとな\nり、社会的には健康増進や医療費削減、地域活性化といった幅広い効果をもたらすことが期待される。\n6.10\n持続可能な運用モデルの構築\n持続可能な運用モデルの構築は、運動促進アプリケーションが長期的に効果を発揮し、安定したサービスを提\n供し続けるための基盤を形成する重要な取り組みである。これを実現するためには、収益性、ユーザーエンゲー\nジメント、社会的インパクトをバランス良く統合したアプローチが必要である。収益性の観点からは、多様な収益\n源を確保することが重要であり、特にフリーミアムモデルの採用が効果的であると考えられる。このモデルでは、\n基本的な機能を無料で提供し、プレミアム機能や追加コンテンツを有料で提供することで、幅広いユーザー層を獲\n得しつつ安定した収益を得ることが可能となる。スタンプラリ",
            "有料で提供することで、幅広いユーザー層を獲\n得しつつ安定した収益を得ることが可能となる。スタンプラリー機能を無料で利用できる一方で、特別なスタンプ\nやカスタマイズ可能な報酬、詳細な運動解析データを有料オプションとして提供することで、ユーザーのニーズ\nに応じた柔軟なプランを構築できる。サブスクリプションモデルを導入し、定期的な収益を確保することも効果\n的である。ユーザーにとって価値の高い機能やコンテンツを継続的に提供することで、利用者の満足度とリテン\nション率を向上させることができ、尚且つ広告モデルや提携企業との協力によるスポンサーシップも収益源とし\nて活用できる。地域の商業施設や観光地をスタンプラリーの目標地点として設定し、それに関連する広告やプロ\nモーションを展開することで、企業や自治体との連携を強化し、収益を多角化することが可能となる。ユーザーエ\nンゲージメントの向上は、持続可能な運用モデルを構築する上で欠かせない要素である。エンゲージメントを維\n持するためには、ユーザーが継続してアプリを利用したくなるような仕組みを提供する必要がある。具体的には、\nゲーミフィケーション要素をさらに",
            "プリを利用したくなるような仕組みを提供する必要がある。具体的には、\nゲーミフィケーション要素をさらに強化し、ユーザーが運動を続けるモチベーションを高める設計が求められる。\n達成した目標や収集したスタンプをSNS でシェアする機能を導入し、ユーザー同士の交流を促進することが効果\n的である。また、定期的に新しいチャレンジやイベントを開催し、飽きの来ない体験を提供することで、アクティ\nブユーザーを維持することができる。さらに、ユーザーからのフィードバックを積極的に収集し、それを基にサー\nビスを改善することで、利用者の期待に応えることが可能となる。社会的インパクトを考慮した運用モデルの構\n築も重要である。アプリを通じて健康促進や地域活性化を支援する仕組みを取り入れることで、社会的価値を提\n供し、ユーザーや地域社会からの支持を得ることができる。アプリ内で収集したスタンプを地域通貨やエコポイ\nントに交換できる仕組みを導入することで、地域経済や環境保護への貢献を促進することができる。また、特定\nの条件を達成することで寄付やチャリティ活動に参加できる機能を提供することで、社会的意識の向上と運動の\n推進",
            "を達成することで寄付やチャリティ活動に参加できる機能を提供することで、社会的意識の向上と運動の\n推進を同時に実現することが可能となる。技術的な側面では、アプリの運用を効率化し、コストを抑えるための\nインフラ整備が不可欠である。クラウドベースのシステムを活用し、スケーラブルで安定したプラットフォーム\nを構築することで、多数のユーザーが利用してもシステムが安定して動作する環境を提供することができる。ま\nた、データの収集と解析を効率化するためにAI 技術を導入し、ユーザー行動の予測やパーソナライズされたサー\nビスの提供を可能にすることで、アプリの価値をさらに高めることができる。これに加え、セキュリティ対策を\n強化し、ユーザーデータの保護を徹底することで、信頼性の高いサービスを提供することが求められる。最後に、\n持続可能な運用モデルを実現するためには、長期的な視野に立った戦略的な計画が必要である。市場動向やユー\nザーニーズの変化を常に把握し、それに応じて柔軟にアプローチを調整することが重要である。また、地域や国ご\nとの特性に対応するため、ローカライズされた運用モデルを導入し、各地域のニーズに応",
            "。また、地域や国ご\nとの特性に対応するため、ローカライズされた運用モデルを導入し、各地域のニーズに応じたサービスを提供す\nることで、グローバルな展開を成功させることが可能となる。このように、収益性、ユーザーエンゲージメント、\n42\n社会的インパクトを統合的に考慮した持続可能な運用モデルの構築は、運動促進アプリケーションが長期的に成\n長し、社会的価値を提供し続けるための鍵となる。\n43\n謝辞\n本研究を進めるにあたって終始あたたかく丁寧な相談、ご指導を戴いた青山学院大学情報テクノロジー学科\nGuillame Lopez 教授に深く感謝申し上げます。青山学院大学理工学部情報テクノロジー学科木村　正子助手には\n研究時に突き当たった問題の解決にあたり、多くの助言をしていただいたことに感謝を申し上げます。また研究を\n進めるにあたり様々な意見を交換して下さったロペズ研究室の皆様に深く感謝いたします。\n2025 年1 月31 日\n井村　和樹\n44\n関連図書\n[1] WHO 身体活動、座位活動ガイドライン2024\n[2] 厚労省: 健康づくりのための身体活動・運動ガイド2023\n[3] Pokemon ",
            "2024\n[2] 厚労省: 健康づくりのための身体活動・運動ガイド2023\n[3] Pokemon Pocket:https://www.pokemontcgpocket.com/ja/\n[4] Peloton:https://www.onepeloton.com/\n[5] wellable: https://www.wellable.co/\n[6] strava:https://www.strava.com/\n[7] 高強度抵抗運動と荷重負荷運動を組み合わせたトレーニングは閉経後低密度女性の骨密度と身体機能を改善す\nる: Steven L Watson, Benjamin K Wels, Amy T Harding, Sean A Horan, Belinda R Beck.Journal of Bone\nand Mineral Research, Vol. 33, No. 2, 2018, pp 211–220\n[8] 青木邦男: 運動の不安軽減効果及びうつ軽減効果に関する文献研究. 山口県立大学大学院論集第3 号2002 年\n[9] 「スポーツエールカンパニー2021」認定企業の",
            " 山口県立大学大学院論集第3 号2002 年\n[9] 「スポーツエールカンパニー2021」認定企業の取組事例\n[10] 大谷隼, 木川修一: フィットネスバイクの利用に対して内的動機づけを図る仮想スタンプラリーシステムの評\n価. 情報処理学会第76 回全国大会講演集文集\n[11] 田口凌, 木下雄一郎: 寄り道促進アプリケーションを用いたウェルビーイング向上の仕組み. 日本感性工学会春\n季大会2024\n[12] Mitesh S,Dylan S,Joseph D,zMichael P. Patel:Eﬀectiveness of Behaviorally Designed Gamiﬁcation Interven-\ntions With Social Incentives for Increasing Physical Activity Among Overweight and Obese Adults Across\nthe United States: The STEP UP Randomized Clinical Trial2019\n[13] Professional Esport",
            "omized Clinical Trial2019\n[13] Professional Esports Players: Motivation and Physical Activity Levels\n[14] Volkswagen:The fun theory\n[15] Mark Hammer:Dose-response relationship between physical activity and mental health: the Scottish Health\nSurvey.2009 British Journal of Sports Medicine\n[16] スモールステップ方略が目標達成に及ぼす影響ースケーリング・クェスチヨンを用いたスモールステップ方\n略の提案ー: 瀧川佳苗, 鈴木俊太郎.Annual Leters of Clinical Psychology in Shinshu 2016 No.15 pp.23 34\n45\n第7章\nQ&A\nチャクラボルティ　シュデシナ　情報テクノロジー学科　助教\nQ\n現状既にある様々なアプリ（ポイントが貯まったり、ゲームだっ",
            "ュデシナ　情報テクノロジー学科　助教\nQ\n現状既にある様々なアプリ（ポイントが貯まったり、ゲームだったり等）とどう違\nうのでしょうか？\nA\nご質問ありがとうございます．既存研究や既存のアプリケーションと比較し本研\n究は、心理的負担を軽減する要素を分析し寄り道やスタンプラリーのようなゲーミ\nフィケーションの要素をより重視し心理的負担を軽減することによって既存のアプ\nリケーションよりもより運動を継続しやすくしている点に違いがあります.\n46\n"
        ]
    },
    {
        "id": "paper_10",
        "filename": "M2024_Kazuki_Honda.pdf",
        "title": "M2024_Kazuki_Honda",
        "fulltext": " \n \n \n \n \n \n \n \n青 \n山 \n学 \n院 \n大 \n学 \n理 \n工 \n学 \n研 \n究 \n科 \n \n \n \n \n理工学専攻 \n知能情報 \nコース \n \n \n \n修 \n士 \n論 \n文 \n \n \n学 生 番 号 \n35623244 \n \n \n氏 \n名 \n本多 一騎 \n \n \n研究指導教員 \nGuillaume Lopez \n \n多様な環境における熱中症リスク評価と予防策の検討\n本多一騎\n2025/01/31\n目次\n第1 章\n序論\n3\n1.1\n研究背景. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n3\n1.1.1\n熱中症による被害\n. . . . . . . . . . . . . . . . . . . . . . . . . . .\n3\n1.1.2\n熱中症のメカニズム\n. . . . . . . . . . . . . . . . . . . . . . . . . .\n4\n1.1.3\n地表気温変化と影響\n. . . . . . . . . . . . . . . . . . . . . . . . . .\n5\n1.1.4\n現在の熱的快適性提供技術の問題点\n. . . . . . . . . . . . . . . . .\n5\n1.1.5\n熱的快適性の役割と影響. . . . . . . . . . . . . . . . . . . . . . . .\n6\n1.1.6\nウェアラブルデバイスの普及\n. . . . . . . . . . . . . . . . . . . . .\n6\n1.2\n研究目的. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n7\n1.3\n本論文の構成. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n8\n第2 章\n関連研究\n9\n2.1\n心拍変動指標に基づく生理的評価. . . . . . . . . . . . . . . . . . . . . . .\n9\n2.1.1\n心拍変動指標の健康および運動指導への応用. . . . . . . . . . . . .\n9\n2.1.2\nウェアラブル端末を用いたストレス推定. . . . . . . . . . . . . . .\n10\n2.1.3\n気温の変化による心拍変動指標への影響. . . . . . . . . . . . . . .\n10\n2.1.4\n自律神経機能の低下と熱中症のリスク\n. . . . . . . . . . . . . . . .\n11\n2.2\nウェアラブルセンサ技術を用いた熱中症リスク推定. . . . . . . . . . . . .\n12\n2.2.1\nウェアラブルセンサによる深部体温の推定. . . . . . . . . . . . . .\n12\n2.2.2\n発汗と熱中症リスクの関係\n. . . . . . . . . . . . . . . . . . . . . .\n13\n2.3\n熱中症予防対策に関する研究\n. . . . . . . . . . . . . . . . . . . . . . . . .\n15\n2.3.1\n水冷服および空調服による熱中症予防\n. . . . . . . . . . . . . . . .\n15\n2.3.2\n水分補給による熱中症予防\n. . . . . . . . . . . . . . . . . . . . . .\n15\n2.3.3\n頸部冷却による熱中症予防\n. . . . . . . . . . . . . . . . . . . . . .\n16\n第3 章\nデータ収集\n17\n3.1\n熱的快適性モデル. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n17\n3.2\n実験に使用されたデバイス. . . . . . . . . . . . . . . . . . . . . . . . . . .\n17\n3.3\n熱的快適性予測のための特徴量とデータ前処理\n. . . . . . . . . . . . . . .\n19\n3.3.1\n時間領域解析. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n19\n3.3.2\n周波数領域解析. . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n19\n3.4\n多様な環境での実験\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n22\n3.4.1\n実験室における実験\n. . . . . . . . . . . . . . . . . . . . . . . . . .\n22\n3.4.2\n現場における実験\n. . . . . . . . . . . . . . . . . . . . . . . . . . .\n24\n3.4.3\n熱中症経験者のいる現場での実験. . . . . . . . . . . . . . . . . . .\n26\n1\n第4 章\n熱的快適性の予測\n29\n4.1\n実験室から得られたデータの検証. . . . . . . . . . . . . . . . . . . . . . .\n29\n4.1.1\n元データを活用した分類性能の検証\n. . . . . . . . . . . . . . . . .\n29\n4.1.2\nオーバーサンプリング適用後の分類性能の検証\n. . . . . . . . . . .\n30\n4.2\n現場から得られたデータの検証. . . . . . . . . . . . . . . . . . . . . . . .\n33\n4.2.1\n元データを活用した分類性能の検証\n. . . . . . . . . . . . . . . . .\n33\n4.2.2\nオーバーサンプリング適用後の分類性能の検証\n. . . . . . . . . . .\n34\n4.3\n熱中症経験者のいる現場から得られたデータの検証. . . . . . . . . . . . .\n36\n第5 章\n自律型リアルタイム推定システムの検討\n39\n5.1\nE4 リストバンドとスマートウォッチから得られるデータの比較\n. . . . . .\n39\n5.1.1\n使用するスマートウォッチ\n. . . . . . . . . . . . . . . . . . . . . .\n39\n5.1.2\n使用するデータ. . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n40\n5.1.3\nフィルターの効果検証. . . . . . . . . . . . . . . . . . . . . . . . .\n41\n5.2\nPolar M600 スマートウォッチでの推定. . . . . . . . . . . . . . . . . . . .\n43\n5.2.1\nPolar M600 スマートウォッチでの推定に用いる特徴量\n. . . . . . .\n43\n5.2.2\n6 つの特徴量のみを使用した場合の推定精度. . . . . . . . . . . . .\n44\n5.2.3\nリアルタイム推定システムと画面出力\n. . . . . . . . . . . . . . . .\n45\n第6 章\n結論\n47\n6.1\nまとめ. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n47\n6.2\n今後の展望\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n47\n謝辞\n48\n参考文献\n49\n2\n第1章\n序論\n本章では，本研究における背景および研究目的，本論文の構成について述べる．\n1.1\n研究背景\n1.1.1\n熱中症による被害\n厚生労働省によると，熱中症による死者数は年々増加傾向にあり，2023 年は1600 を超\nえる人が熱中症で命を落としている[1]．図1.1 より，熱中症の死者数の中でも特に高齢\n者の割合が大きく，2010 年以降熱中症による死者数の約80%が高齢者であった[1]．\n図1.1: 熱中症死者のうち高齢者の割合（[1] より作成）\n熱中症は，環境条件や活動状況によってさまざまなレベルで発生する．環境省の指針に\nよれば，熱中症の危険性は気温や湿度などの環境条件に基づいて分類され，危険レベルが高\nいほど重篤な症状が引き起こされるリスクが増加する[2]．特に高齢者や子供は熱中症の\n影響を受けやすい．注意すべき点として，暑さ指数（WBGT: Wet Bulb Globe Temperature）\nに基づく警戒レベルがあり，この指数が28◦C を超えると，熱中症の発生リスクが急激に\n高まる[2]．\n3\n1.1.2\n熱中症のメカニズム\n人間は，外気温が高くなると体温が上昇し，体温調節機能が働く．体温が37◦C 程度に\n保たれるように，皮膚の血流が増加し，発汗によって体熱を放散しようとする．しかし，\n過度の暑さや脱水が進むと，血流の変化や発汗の低下により，体温がさらに上昇し，熱中\n症のリスクが増す．特に，環境温度が高いと，発汗による体熱放散が妨げられ，体温が急\n激に上昇する可能性がある．例えば，体重70kg の人間は発汗により体温を10◦C 低下さ\nせることが可能であるが，大量の汗をかいたとき，水分補給が不十分だと体温調節が困難\nになる．これにより，体内の水分バランスが崩れ，最終的に熱中症を引き起こす[3]．\n熱中症はその症状に応じて「熱失神（熱虚脱）」「熱痙攣」「熱疲労（熱疲弊）」「熱射病」\nの4 つに分類される．\n熱失神は，暑熱環境下で脳への血流が一時的に減少し，立ちくらみや倦怠感が生じる状\n態である．血圧の低下も見られるが，体温上昇はほとんどない．熱痙攣は，大量の発汗で\n塩分が不足し，筋肉が痙攣することである．熱疲労は，脱水による全身のだるさや吐き気，\n頭痛などの症状を特徴とし，頻脈や体温の上昇を伴うこともある．熱射病は，体温が急激\nに上昇し，意識障害や全身の痙攣が生じる重篤な状態であり，緊急の治療が必要である．\nこれらの状態は，重症度に基づいてI 度からIII 度に分類され，III 度は最も危険な状態を\n示す．\n図1.2 は，熱中症の発生メカニズムおよび症状の重症度を示している．\n図1.2: 暑熱ばく露時の体温調節反応と熱中症の発生メカニズム（[3] より引用）\n4\n1.1.3\n地表気温変化と影響\n図1.3 は，産業革命前（1850 年～1900 年）を基準とした地表気温の変化を示している．\nこれまでの気温上昇は主に人間活動による温室効果ガスの排出が原因であることが分かっ\nている．気温変化の将来的な予測は，採用される社会経済パスウェイ（SSP）によって大\nきく異なり，2100 年までの予測気温上昇は約1◦C から5◦C の範囲にわたる．\nSSP5-8.5 は，温室効果ガスの排出が最も多いシナリオであり，2100 年までに地表気温\nが最大5◦C 上昇する可能性がある．一方，SSP1-1.9 やSSP1-2.6 のシナリオは，より積極\n的な排出削減を前提としており，気温上昇を1◦C から2◦C 程度に抑えることができると\n予測されている．これらの予測は，気温上昇を抑制するために迅速かつ持続的な対策が必\n要であることを示している．\n最大約5◦C 気温の上昇は，熱波の頻発や強度の増加，生態系への悪影響，さらには人間\nの健康への重大なリスクをもたらす．\n図1.3: 1850 年～1900 年を基準とした各SSP の地表気温の変化（[4] より引用）\n1.1.4\n現在の熱的快適性提供技術の問題点\n現在，ほとんどの建物や機器は，多くの人が許容できる温熱環境条件の範囲を明確にし\nた規格に基づいて作られている．しかし，環境条件の変化や室内での活動により，身体の\n温熱感覚や快適性は大きく変化することが頻繁にある．\n最近の研究では，ASHRAE 55[5] やISO 7730[6] といった熱的快適性の基準は，室内環\n境における不満を持つ人数を過小評価していることが示されている[7]．\nまた，快適に感じる温度は人によって異なることが知られている．しかし，ほとんどの\n熱的快適性を提供する技術（空調装置など）は，建物内の全員に中立的な熱環境を設定す\nるよう設計されている．\nこの熱的快適性の設定方法は，エネルギーを大量に消費し[8]，人体の中で熱的快適性\nに最も影響を与える部位（手首，足，頭など）を冷却または加熱することがほとんどでき\nない．さらに，室内温度を常に中立的に保つのではなく，人が熱的に不快と感じたときに\nだけ調整することで，熱的快適性に必要なエネルギーを大幅に削減できる可能性がある．\n5\nこのような観点から，快適で健康的な室内環境を実現するためには，熱的快適性を評価す\nることが重要であると考えられる．\n1.1.5\n熱的快適性の役割と影響\n熱的快適性は，人間の健康と心理的な快適さに大きな影響を与える．適切な温熱環境は，\n身体的な健康だけでなく，心理的な満足感や生産性にも寄与する．特に，熱的快適性が損\nなわれた環境では，居住者の士気や作業意欲が低下し，長期的には健康被害を引き起こす\n可能性がある[9]．\n熱的快適性を評価するために使用されるPMV（予測平均温冷感）指数は，特にオフィス\n環境において，快適性とエネルギー節約の両面で効果的であることが示されている[10]．\nしかし，PMV 指数は個々の感覚に基づくものではないため，個人差を考慮する必要があ\nり，Kramer らの研究ではPMV 指数と個別の快適性の間に大きな差が見られることが報\n告されている[11]．この報告から，より個別化された熱的快適性の管理が推奨されるよう\nになっている．\nまた，個別の快適性システム（PCS）は，局所的な温熱不快感を緩和しながら，熱的快\n適性を向上させ，健康にも好影響を与える可能性がある．これにより，特にオフィス環境\nにおいて，作業効率と健康状態の改善が期待できる[12]．\n図1.4 は，Luo らが提案している頭，手，足をターゲットとするPCS である．\n図1.4: 局所的な不快感を取り除くための提案されているPCS（[12] より引用）\n1.1.6\nウェアラブルデバイスの普及\n近年，Apple Watch をはじめとしたウェアラブルデバイスが急速に普及し，健康管理，ス\nポーツ，医療分野における重要なツールとしての地位を確立している．ウェアラブルデバ\nイスは，心拍数や活動量，睡眠データのモニタリングを通じて，個人の健康状態を常に監\n視することが可能であり，これにより健康管理や病気予防の新たなアプローチが生まれて\nいる．\n医療分野において，ウェアラブルデバイスは，患者の生理データをリアルタイムで監視\nし，疾病の早期発見や治療に役立てられている[13]．特に，高齢者や慢性疾患を抱える患\n6\n者にとって，ウェアラブルデバイスは医療費の削減や医療の質向上に貢献する可能性が\n高い．\nまた，これらのデバイスは遠隔医療の普及にも寄与しており，患者が病院を訪れること\nなく，日常的な健康データを医師と共有することができる[14]．\nスポーツ分野においては，ウェアラブルデバイスを用いて，アスリートのパフォーマン\nス向上やリスク管理が行われている[15]．デバイスによる生体データのモニタリングは，\nトレーニングの効率を最適化し，ケガの予防に役立つと同時に，競技中の健康状態を監視\nするための手段としても有効である．\nウェアラブルデバイスは，ユーザーの健康状態や行動に関する多くのデータを収集し，\nリアルタイムでの分析を可能にする．しかし，このようなデバイスが収集するデータは非\n常にセンシティブであり，セキュリティやプライバシーに関する問題が懸念される．\nまず，ウェアラブルデバイスから得られるデータは，個人の健康情報や位置情報を含む\nことが多く，これらの情報が不正にアクセスされると，個人のプライバシーが侵害される\n可能性がある．特に，悪意のある攻撃者によってデータが盗まれると，個人情報が悪用\nされるリスクが高まる[16]．このような観点から，ウェアラブルデバイスの利用において\nは，セキュリティとプライバシーの保護が不可欠である．それでも，これらの技術は今後\nさらに進化し，健康管理，スポーツ，医療分野において重要な役割を担い，普及していく\nと考えられる．\n図1.4 は，北米におけるウェアラブル技術の市場規模拡大を予測したものである[17]．\n図1.5: 北米におけるウェアラブル技術の市場規模予測（単位：10 億米ドル）（[17] より引\n用）\n1.2\n研究目的\n1.1.1 項で述べたように，近年，熱中症による死者数は増加傾向にあり，近年の死者数の\nうち高齢者の割合が80%を超えてきている．\nそこで本研究の目的は，細かい粒度で熱中症のリスクを評価するとともに，普及しつつ\nあるウェアラブル技術を活用して，一人暮らしなども増えている高齢者の安心と安全およ\n7\nび，労働者の健康と安全を守る仕組みの開発である．そのため，熱中症の発生する可能性\nのある作業現場において，スマートウォッチを用いて計測できる脈拍を始めとした生理指\n標などから，熱的快適性の推定手法や頸部冷却効果の検証，またリアルタイム推定システ\nムの開発を目標とする．\n1.3\n本論文の構成\n第1 章：本論文の研究背景，研究目的および論文の構成について述べる．\n第2 章：関連研究について述べる．\n第3 章：本研究のデータ収集について述べる．\n第4 章：解析結果を述べるとともに，その結果について考察を述べる．\n第5 章：自律型リアルタイム推定システムの開発について述べる．\n第6 章：本論文のまとめと今後の展望について述べる．\n8\n第2章\n関連研究\n2.1\n心拍変動指標に基づく生理的評価\n2.1.1\n心拍変動指標の健康および運動指導への応用\n心拍変動（HRV）は，従来から心血管系の健康指標として使用されてきたが，Singh ら\nは，モバイルヘルス（mHealth）技術の普及に伴い，心拍変動が健康状態の評価や運動ト\nレーニングの指導において重要な役割を果たすことを示している[18] ．この研究では，心\n拍変動がリスク層別化や運動プログラムの最適化に利用できることが述べられており，モ\nバイルデバイスを通じた日常的なフィードバックの可能性が強調されている．\n伊倉らは，心血管疾患患者において有酸素運動中にリアルタイムで心拍変動を解析する\n手法を提案している．この研究では，心拍変動を使用して換気閾値での運動強度を連続的\nかつ非侵襲的に測定することにより，より安全かつ効果的な運動戦略を提供できることが\n示されている[19]．この手法は，心拍変動のリアルタイム分析が運動中の健康管理に役立\nつことが明らかにされている．\n図2.1: 実験手順心拍変動は継続的に記録され，運動負荷は運動中の高周波（HF）成分に\n基づいて調整される（[19] より引用）\n9\n2.1.2\nウェアラブル端末を用いたストレス推定\n鈴木らの研究では，スマートウォッチによって取得された心拍数から導出される複数の\n評価指標を用いて，ストレス検出の精度が評価されている．心拍数は，利き手でない手に\n装着されたAndroid Wear OS 搭載端末から取得された．正規化されたサポートベクターマ\nシン（SVM）を用いた場合，検出精度は73.24%，適合率は77.57%，再現率は74.92%，特\n異率は72.72%という結果が得られた．\nまた，SDNN はリラックス状態において高く，ストレス負荷状態では低くなる傾向が示\nされており，RMSSD についても同様に，リラックス時には高く，ストレス負荷時には低\nい値を示す傾向が確認された[20]．\n図2.2: 実験参加者につけられたウェアラブル端末（[20] より引用）\n2.1.3\n気温の変化による心拍変動指標への影響\n熱的快適性は主観的な心理的感覚であるため，人の生理的信号の変化をもとに熱的快適\n性を提供することは，非常に効果的であると考えられる．Nkurikiyeyezu らの研究によれ\nば，心拍変動は自律神経系のバランスおよびその機能を評価する指標となり，気温の変化\nが心拍変動に測定可能な変化をもたらすことが示されている[21]．例えば，図2.3 に示す\nように，Mean RR，VLF，サンプルエントロピーなどの指標は寒冷な環境で最も高く，暑\n熱環境では最も低い値を示すことが分かっている．\nまた，Mean RR，RMSSD，SDSD，pNN25，VLF，およびサンプルエントロピーの6 つ\nの心拍変動指標を用いた機械学習モデルを構築することで，人々の熱的快適性（暑さによ\nる不快感，寒さによる不快感，快適さ）を最大93.7%の精度で予測可能であることが明ら\nかとなった[21]．このことから，暑さによる不快感の度合いを推定できることで，熱中症\n10\nのリスクが高まっているかどうかを把握し，早期に適切な対策を講じることが可能である\nと考えられる．\n図2.3: 各環境における心拍変動指標の正規化された平均（[21] より引用）\n2.1.4\n自律神経機能の低下と熱中症のリスク\n一般的に，心拍変動は自律神経機能を評価する重要な指標として広く採用されている．\n自律神経系は交感神経と副交感神経から構成され，これらのバランスが心拍変動に反映さ\nれる[22]．高い心拍変動は副交感神経の優位を示し，ストレスが少なくリラックスした状\n態であることを意味する．一方，低い心拍変動は交感神経が優位で，ストレスや身体的負\n荷がかかっていることを示す．\n図2.4a は健康な青年男子の呼吸性心拍変動（RSA）と心拍数の関係を示し，薬物投与前\n後での変化を比較している．心拍数が副交感神経のみで制御されるとき，RSA のCCV 値\nは心拍数と直線的関係にある．\n図2.4b はMayer 波に関連した心拍変動と，動脈血圧の収縮期血圧におけるMayer 波の\n大きさ（CCV 値）の関係を示している．\n自律神経機能が低下すると，体温調節などの生理的な調整機能が劣化し，熱中症の発症\nリスクが高まることが示されている．Canini らの研究では，自律神経機能の低下が，スト\nレスに対する保護メカニズムの不全を引き起こし，熱中症に対する感受性を増加させる可\n能性が指摘されている[23]．\n11\n図2.4: (a) 健康な青年男子の呼吸性心拍変動（RSA）と心拍数の関係．(b) 心拍変動と，\n動脈血圧の収縮期血圧におけるMayer 波の大きさ（CCV 値）の関係（[22] より引用）\n2.2\nウェアラブルセンサ技術を用いた熱中症リスク推定\n2.2.1\nウェアラブルセンサによる深部体温の推定\n釜谷らは，ウェアラブルセンサとヒト熱モデルを用いて深部体温を推定する手法を提案\nしている．この研究では，二重ノードのヒト熱モデルを利用し，歩行活動中に0.07◦C の\n誤差で深部体温を推定することに成功している[24]．これにより，熱中症予防における深\n部体温の連続的なモニタリングが可能となり，特に高温環境下での熱ストレス管理に有効\nであることが示されている．\n時澤らは，熱ストレス条件下における運動中に体幹温度をリアルタイムでモニタリング\nするためのウェアラブルパッチ型センサシステムを提案している．この研究では，胸部か\nらの熱フラックスデータを利用し，体幹温度の予測精度が高いことが示されている[25]．\n予測された体幹温度は実測値とよく一致しており，このシステムは熱中症予防や高温環境\n下での健康管理に有効であることが確認されている．\nしかし，深部体温は熱中症と密接に関連しているものの，深部体温の予測自体が熱中症\nの予防に直接結びつくとは限らない．\n図2.5 が示すように，通常，発汗や血液の皮膚表面への移動を通じて体温を調整するが，\n高温環境下では熱放散が困難になり，体内に熱が蓄積される．この状態が進行すると体内\nの血液の流れが低下し，体に熱がたまり，深部体温が上昇する．この時点で既に「異常時」\nとなり，熱中症発症が近づき手遅れとなる可能性がある[26][27][28]．したがって，深部\n体温の上昇を検知する前に予防的なアラートを出すことが肝要である[29]．具体的には，\n環境条件（気温や湿度）や個人の活動レベルに基づき，早期に頸部冷却や水分補給を促す\n予防策が効果的であると考えられる．\n12\n図2.5: 熱中症の起こり方（[28] より引用）\n2.2.2\n発汗と熱中症リスクの関係\nSim らの研究では，異なる熱環境下での人間の熱的快適性のモニタリングを目的とした\nウェアラブル発汗速度センサの使用が提案されている．このセンサは発汗量を測定感度の\n変化を10%未満で測定可能であった．「快適」，「やや暖かい」，「暖かい」，「暑い」の4 段階\nの温熱状態の範囲において，各温熱状態における発汗量の差は平均（32.06 ± 27.19）g/m2h\nであった．この機能により，身体の過剰な熱ストレスを迅速に検出し，熱中症リスクを軽\n減するための迅速な対応が可能である．発汗のパターンや発汗速度の変動をリアルタイム\nで把握することで，熱中症の予防や早期対応に役立つ可能性が示唆されている[30]．\nFan らの研究では，発汗がアクティブなスポーツ時の熱的快適感に与える影響に着目し\nている．特に，衣服内の水分抵抗と湿気の蓄積が発汗に直接関係し，熱的快適性に大きな\n影響を与えることが示されている．発汗は体内の余分な熱を放散する役割を持っており，\n衣服の熱特性（通気性，吸湿性）が十分でない場合，発汗による冷却効果が減少し，熱的\n快適性が損なわれるとされている．したがって，適切な衣服の選択により，発汗を促進\nし，熱中症のリスクを軽減することが重要であると結論づけている[31]．\n13\n図2.6: (a) 手首に装着する発汗率センサー．(b)3 つの異なる条件を用いた温度状態評価に\n使用されたアンケート．(c) 温度状態制御中に被験者1 から得られた湿度センサーによる\n容量の時間変化．(d–f)3 名の被験者における温度状態による発汗率（[30] より引用）\n藤井らの研究では，プロテアーゼ活性化受容体2（PAR2）の外因性活性化が，高齢者に\nおける皮膚血管拡張および発汗の低下を引き起こすことが示されている．この研究は，高\n齢男性を対象に運動による熱ストレス時の発汗と血管反応を調査しており，特に高齢者で\nはPAR2 の活性化が発汗機能を抑制することが明らかとなった．この発見は，高齢者にお\nける自律神経機能の低下が，発汗による熱放散メカニズムに影響を与える可能性を示唆し\nている[32]．\nTan らの研究では，高齢者の発汗応答の低下が発汗腺のコリン作動性受容体の感受性の\n低下およびシグナル伝達の変化に起因することが指摘されている．これにより，高齢者は\n熱関連の障害に対して脆弱性が増し，発汗による体温調節が困難になることが報告されて\nいる．さらに，熱ストレス時に高齢者が熱的負荷に対してどのように対応するかに関する\n実践的な戦略も提案されている[33]．\nこのように，高齢者は加齢に伴う自律神経機能などの衰えにより，発汗機能の低下が顕\n著であることが報告されている．つまり，発汗センサによる熱中症予防対策は，若年層や\n十分な発汗が期待できる人々に対しては有効であるが，本研究の目的である高齢者も含め\nた熱中症予防において，発汗だけでは熱中症リスクを十分に評価できない可能性がある．\n14\n2.3\n熱中症予防対策に関する研究\n2.3.1\n水冷服および空調服による熱中症予防\n水冷服や空調服は，熱中症の予防や熱ストレスの軽減に効果的であることが多くの研究\nで示されている．Son の研究では，水冷服や空調服を使用することで熱ストレスが軽減さ\nれ，運動能力の向上が期待できることが報告されている[34]．特に，皮膚の露出や衣服の\n通気性が重要な要素であり，適切な設計により熱中症のリスクを効果的に低減できること\nが示されている．\nLi らの研究では，空調服が高温環境下での熱ストレスを効果的に軽減することが明らか\nにされている[35]．この研究では，空調服が運動強度に応じた性能を発揮し，熱を効率的\nに放散できることが確認された．特に，高温環境で働く人々にとって，このような空調服\nが快適さと安全性を提供する新しい手段として期待されている．\nさらに，Wang らは，液体と空気を利用したハイブリッド冷却服が局所的な熱ストレス\nの軽減に効果的であることを示している[36]．この研究では，コンベクションと熱伝導の\nメカニズムを組み合わせた冷却が，体表温度を効果的に下げることが確認されている．\nこれらの研究は，水冷服や空調服が熱中症予防および熱ストレス軽減に重要な役割を果\nたすことを示しており，今後の研究や実用化に向けた重要な基盤となっている．\nしかし，空調服や水冷服はにはいくつかのデメリットが存在する．Leyk によると，服\nの断熱性が原因で，汗の蒸発が妨げられ，体温を効果的に下げる蒸発冷却の作用が減少す\nることが指摘されている[37]．これは特に湿度の高い環境で顕著であり，体温調節が困難\nになり，結果として熱ストレスが増加する危険性がある．\nまた，装置が故障した場合には，冷却効果が失われるだけでなく，逆に断熱効果が体温\nを保持し，熱ストレスを悪化させるリスクがある．\nこのように，空調服や水冷服はその利便性に優れている一方で，使用環境や使用方法に\nよっては逆効果をもたらす可能性がある．特に，高温多湿な環境や長時間の使用では，こ\nれらのデメリットを十分に考慮し，適切な対策を講じる必要がある．\n図2.7: シリコンチューブ付き液空冷却衣服（[36] より引用）\n2.3.2\n水分補給による熱中症予防\n脱水症状は熱中症のリスク要因として重要な役割を果たしている．Garcia らの研究では，\n労作性熱中症の病態生理学において，脱水症がリスクを高めることが示されている[38]．\n特に，脱水により体温調節機能が低下し，熱中症の発症リスクが高まる可能性がある．\n15\n図2.8: 発汗量の実験値と潜熱損失量の総和の計算値（[40] より引用）\nまた，Costrini らによると，熱中症患者は熱疲労患者に比べて初期の脱水がより進行し\nており，血糖値が有意に低いことが確認されている[39]．さらに，熱中症患者は血清カリ\nウム濃度の低下も見られ，これが代謝反応の変化を引き起こしていることが示唆されて\nいる．\nGarcia らの研究では，脱水症による体温調節障害が熱中症の重症度を増すことが強調さ\nれており，運動時の適切な水分補給の重要性が示されている．一方，Costrini らの研究で\nは，脱水による代謝的な影響が熱中症の進行を助長することが明らかにされている．し\nたがって，脱水症は熱中症の予防および治療において，最も重要な要因の一つであると言\nえる．\n2.3.3\n頸部冷却による熱中症予防\n千葉らの研究では，暑熱環境下における頸部冷却の生理的反応に関する実験が行われ，\nその結果が詳細に報告されている．実験では，温度32◦C ，湿度60%の条件で，8 名の健\n康な男性を対象にデスクワークを行わせ，ネッククーラーを使用した条件（Case 1）と，\n使用しない条件（Case 2）を比較した．\nまず，頸部皮膚温度は，ネッククーラーを装着したCase 1 では約30.8◦C に低下し，装\n着しなかったCase 2 では約34.7◦C であったことが確認された[40]．これにより，頸部冷\n却による皮膚温の顕著な低下が生じ，発汗量が減少する傾向が見られた．図2.8 が示すよ\nうに，発汗量の実験結果では，Case 1 では発汗量が少なく，発汗による潜熱損失量もCase\n2 と比較して少ないことが確認されている．これにより，局所冷却が身体の熱的負荷を軽\n減する効果が示唆される．\nさらに，血圧に関する測定では，頸部冷却を行ったCase 1 の方が，最高血圧が有意に高\nくなった．これは，頸部冷却によって血管拡張が抑制され，血管抵抗が増加したためであ\nると考えられる[40]．結果として，暑熱環境下における循環系の負担軽減や熱中症リスク\nの低減が期待される．\n16\n第3章\nデータ収集\n3.1\n熱的快適性モデル\nPMV（Predicted Mean Vote）モデルは，様々な温度条件下で長時間にわたる大規模な実\n験室実験に基づき，熱的快適性を予測するために開発された[41]．このモデルは，その公\n平性と精度が認められ，ISO 7730 やASHRAE 55 などの国際規格に採用されている[42]．\nPMV を算出する際には，周囲の空気温度，平均放射温度，気流速度，相対湿度，代謝率，\n衣服の断熱性といった6 つの要因を考慮する必要がある[41]．\nPMV による評価は，「寒い」，「涼しい」，「少し涼しい」，「普通」，「少し暖かい」，「暖か\nい」，「暑い」の7 段階に分類される．\n本研究では，通常PMV の値が2.5 を超えると「暑い(hot)」と分類されるが，その中で\nも3.5 を超えるものを図3.1 に示すように「とても暑い(very hot)」としてラベルの拡張を\n行った．\n図3.1: 拡張されたPMV の8 段階評価指標\n3.2\n実験に使用されたデバイス\n被験者には図3.2 に示すE4 リストバンドを装着させた．E4 リストバンドは，腕時計型\nのウェアラブルデバイスであり，皮膚電気活動（Electrodermal Activity, EDA）センサ，光\n電式容積脈波（Photoplethysmography, PPG）センサ，3 軸加速度計，光温度計など，多数\nのセンサを搭載している[43]．EDA は4Hz のサンプリングレートで皮膚の電気的特性の\n変動を捉え，発汗量の増加に伴い皮膚の電気伝導度も上昇することが知られている．\n特に，PPG センサは64Hz で容積脈波（Blood Volume Pulse, BVP）を計測し，これに基づ\nいて心拍間隔（Interbeat Interval, IBI）および心拍変動（Heart Rate Variability, HRV）を算\n出することが可能である．近年の研究では，E4 リストバンドが座位安静時や一定のペー\nスでの呼吸条件下において，心拍変動を高精度に記録できることが報告されている[44]．\nこのように，E4 リストバンドは，高品質なデータ収集を目的とした精度の高いセンサを\n備えている．\n17\n図3.3 に示すC´omodo gear i3 は，富士通ゼネラルが開発したウェアラブル冷却装置であ\nる[45]．このデバイスは，主に工場などの暑熱環境下での使用を目的としており，首に装\n着して皮膚表面を冷却することで体感温度を低下させる．軽量かつコードレス設計で，作\n業の妨げにならないように工夫されている．また，バッテリー駆動により，持続的に冷却\nが可能であり，長時間の使用に適している．\n図3.2: Empatica E4 リストバンド（[43] より引用）\n図3.3: C´omodo gear i3（[45] より引用）\n18\n3.3\n熱的快適性予測のための特徴量とデータ前処理\n各実験終了後，図3.4 に示すようにに示すように，E4 リストバンドからスマートフォ\nンに同期された生体情報は，E4 コネクトというクラウドにCSV 形式でアップロードされ\nた．その後，PPG センサのノイズを除去したのち，52 個の特徴量を抽出した．\n本研究では，熱的快適性予測のための特徴量として，心拍変動指標の時間領域解析と周\n波数領域解析を選択した．また，心拍変動指標は全て300 秒の窓サイズのセグメント，30\n秒のシフトサイズで計算された．\n図3.4: 実験における生体情報の処理\n3.3.1\n時間領域解析\n時間領域の心拍変動指標は，心拍間の時間（心拍間隔）を元に算出されるものであり，計算\nも理解も容易である．具体的には，平均心拍間隔（Mean R-R interval），標準偏差（Standard\nDeviation of NN intervals, SDNN），および隣接する心拍間隔の差の二乗平均平方根（Root\nMean Square of Successive Differences, RMSSD）などが代表的な指標である．これらの指\n標は心拍間隔の変動を直接表しており，特にSDNN は全体的な変動の大きさを，RMSSD\nは短期的な変動の大きさを示す．時間領域解析はシンプルでありながら，交感神経と副交\n感神経の活動バランスを推測する上で有用である．\n本研究で使用した時間領域の心拍変動指標の一覧の一部を表3.1 に示す．\n3.3.2\n周波数領域解析\n周波数領域解析は，心拍間隔の変動を周波数成分に分解して解析する手法である．R-R\n間隔の時系列データに対して高速フーリエ変換（FFT），自己回帰（AR）モデリングによる\n19\nアプローチが広く採用されており[46]，低周波成分（Low Frequency, LF: 0.04～0.15 Hz）\nや高周波成分（High Frequency, HF: 0.15～0.40 Hz）を解析するものである．LF 成分は交\n感神経と副交感神経の両方に関連するとされ，HF 成分は主に副交感神経の活動に関連す\nると考えられている．また，LF/HF 比は自律神経のバランスを示す指標として用いられる\nことが多い．周波数領域解析により，時間領域では捉えきれない自律神経の周期的な活動\nをより詳細に分析することができる．\n本研究で使用した周波数領域の心拍変動指標の一覧の一部を表3.2 に示す．\n20\n表3.1: 選択した時間領域の特徴の説明\n時間領域の指標\n説明\nNUM IBIS\nNNI の合計値\nHRV MEAN NNI\n全NNI の平均値\nHRV MEDIAN NNI\n全NNI の中央値\nRANGE NNI\nNNI の最大値と最小値の差\nSDSD\n隣接する心拍間隔の差の標準偏差\nRMSSD\n隣接する心拍間隔の差の2 乗の平均値の平方根\nHRV NNI 50\n50 ミリ秒以上離れたNNI の数\nHRV NNI 20\n20 ミリ秒以上離れたNNI の数\nHRV pNNI 50\n50 ミリ秒以上離れたNNI の割合\nHRV pNNI 20\n20 ミリ秒以上離れたNNI の割合\nSDNN\n各心拍間隔の標準偏差\nHRV SD1\nプロット散布図における縦軸方向の標準偏差\nHRV SD2\nプロット散布図における横軸方向の標準偏差\nHR MEAN\n平均心拍数（1 分間の心拍数で測定）\nHR MIN\n心拍数の最小値（1 分間の心拍数で測定）\nHR MAX\n心拍数の最大値（1 分間の心拍数で測定）\nHR STD\n心拍数の標準偏差\nHRV MEAN\nIBI の平均値\nHRV STD\nIBI の標準偏差\nHRV MIN\nIBI の最小値\nHRV MAX\nIBI の最大値\nHRV SKEWNESS\n全IBI の歪度\nHRV KURTOSIS\n全IBI の尖度\nHRV PEAKS\nIBI のピーク値\nHRV Energy\nIBI から算出されるエネルギー\nHRV CVSD\n連続した心拍間隔の差の変動係数\nHRV n Above Mean\n平均値以上のIBI の数\nHRV n Below Mean\n平均値以下のIBI の数\nHRV IQR\nIBI の25%から75%までの四分位範囲\nHRV Entropy\nIBI のエントロピー\nHRV RMS\n隣接するNNI の差の2 乗和の平均の平方根\n21\n表3.2: 選択した周波数領域の特徴の説明\n周波数領域の指標\n説明\nHRV VLF\n0.0033～0.04Hz の周波数帯のパワースペクトル\nHRV LF\n0.04～0.15Hz の周波数帯のパワースペクトル\nHRV HF\n0.15～0.4Hz の周波帯のパワースペクトル\nHRV LF HF RATIO\nLF（低周波）とHF（高周波）のパワーの比率\nTP\n周波数0～0.4Hz のパワースペクトルのトータルパワー\nHRV LFnu\n低周波数領域(LF) のHRV の正規化\nHRV HFnu\n高周波数領域(HF) のHRV 正規化\n3.4\n多様な環境での実験\n本研究では，3 つの異なる実験環境において段階的に実験を行った．これらの実験は，\n「実験室における実験」から「現場における実験」，さらに「熱中症経験者のいる現場での\n実験」へと進展し，各実験環境における熱的快適性の評価を行った．以下に，各実験環境\nにおける具体的な内容について詳述する．\n本研究で収集したデータは，川崎市環境局環境対策部　地域環境共創課および（株）富\n士通ゼネラルの立会いの下入手した．また，実験担当者は，臨床研究に携わる人のe ラー\nニングサイト「ICR 臨床研究入門」にて，「研究倫理と被験者保護」および「人を対象と\nする医学系研究に関する倫理指針」を履修している．また，本実験は，青山学院大学理工\n学部ライフサイエンス委員会の「人に係る研究」に関する審査・承認を受け実施され（承\n認番号H21-009-1），被験者は実験説明を受け，実験に対する同意書による同意をもって，\n実験に参加頂いている．\n3.4.1\n実験室における実験\n実験室内での実験では，温度や湿度といった環境因子を制御できる実験室を用い，熱的\n快適性に関する基礎データを収集した．実験条件は，読書，転写，ラジオ体操という3 つ\nの活動に基づき，主に高温環境に焦点を当てたさまざまな条件を設定した．例えば，ラジ\nオ体操では，高温状態（温度32◦C，湿度80%）および温暖状態（温度25◦C，湿度60%）\nの条件でデータを収集した．各条件は，図3.1 に示す温熱感覚の尺度「普通(neutral)」「少\nし暖かい(slightly warm)」「暖かい(warm)」「暑い(hot)」に従って調整された．\n各活動は，日常生活と関連付けて設定されたものである．例えば，読書やテレビ鑑賞は\n読書活動に，仕事におけるデスクワークや座学は転写活動に，工場や屋外での力作業はラ\nジオ体操活動にそれぞれ対応している．実験一例としてラジオ体操の様子を図3.5 に示す．\nまた，各実験条件の詳細を表3.3 に示す．\n22\n図3.5: 実験室における実験の様子（ラジオ体操）\n表3.3: データ収集条件\n実験番号\n活動\n温度\n湿度\n期間\n1\nラジオ体操\n32◦C\n80%\n10 分\n2\nラジオ体操\n25◦C\n60%\n10 分\n3\n読書\n25◦C\n60%\n15 分\n4\n読書\n32◦C\n80%\n15 分\n5\n読書\n27◦C\n60%\n15 分\n6\n読書\n32◦C\n80%\n15 分\n7\n転写\n32◦C\n80%\n15 分\n8\n転写\n27◦C\n60%\n15 分\n実験は午前と午後にそれぞれ1 日2 グループに対して実施し，1 回の実験でのデータ収\n集は最大3 名までとした．図3.6 に年齢と性別の分布を示す成人男女44 名を対象に，4 つ\nの温湿度環境および3 つの作業条件下で，E4 リストバンド[43] を装着させ，連続的な脈\n拍間隔を測定した．\n図3.7 は，データセットに含まれる4 つの温度状態を示しており，\n「warm」および「slightly\nwarm」における記録数が他の温度状態と比較して非常に多かった．\n23\n図3.6: 被験者の年齢と性別の分布\n図3.7: 実験室実験におけるPMV を用いた温熱感覚のデータセットの量\n3.4.2\n現場における実験\n3.4.1 項の結果は統制された環境で得られたものであり，そのまま実際の現場環境に適\n用するには限界があるため，実験室を離れた実運用下での分類精度の妥当性と実用性を評\n価する必要がある．作業現場では，実験室のように環境因子を厳密に制御することが困難\nであるが，より現実的な条件下でデータを取得することが可能である．作業現場での実験\n24\nでは，製造工場や建設現場など温熱環境が異なる8 つの作業現場を選定しデータを収集し\nた．実験一例として入江崎クリーンセンターにおける様子を図3.8 に示す．\nまた，各現場の詳細を表3.4 に示す．\n図3.8: 入江崎クリーンセンターにおける実験の様子（作業場点検）\n表3.4: 各実験場所の詳細\n実験場所\n作業内容\n平均温度\n平均湿度\n実験時間\n入江崎クリーンセンター\n屋内・外での作業場点検\n34.9◦C\n44.7%\n3 時間\n川崎市環境総合研究所　多摩川イベント\n屋外での誘導および受付\n36.9◦C\n47.5%\n6 時間\nセントラル硝子（株）\n屋内での粉溶解および充填作業\n29.4◦C\n64.2%\n3 時間\n（株）レゾナック\n屋内での清掃\n33.7◦C\n69.7%\n3 時間\n富士通ゼネラルサマーフェスティバル\n屋外での会場設営および誘導\n30.4◦C\n72.8%\n6 時間\n浮島処理センター資源化処理施設\n屋内での機器点検\n33.8◦C\n57.7%\n3 時間\n久地小学校給食調理場\n屋内での清掃\n33.1◦C\n56.6%\n3 時間\n入江崎クリーンセンター\n屋外での草刈りおよび清掃\n31.0◦C\n68.2%\n3 時間\n作業者には，日常的な作業を実施してもらい，その際に脈拍間隔と熱的快適性の評価を\n行った．実験はフィードバック手法の検討として頸部冷却ありの状態と頸部冷却なしの状\n態でそれぞれ同じ作業を実施した．図3.9 は，入江崎クリーンセンターにおける実験手順\nのタイムテーブルである．\n25\n図3.9: 入江崎クリーンセンターにおける実験手順のタイムテーブル例\n被験者は20 代から60 代までの幅広い年齢層から選定し，合計51 名（男性48 名，女性\n3 名）で構成された．図3.10 は，データセットに含まれる3 つの温度状態を示しており，\n「warm」における記録数が他の温度状態と比較して非常に多かった．\n図3.10: 現場実験における拡張したPMV を用いた温熱感覚のデータセットの量\n3.4.3\n熱中症経験者のいる現場での実験\n過去に熱中症経験者が発生した作業現場を対象に，さらに実用的な実験を実施した．こ\nの実験では，特にPMV の値が2.5 を超え，多くの状態が「very hot」や「hot」と評価され\nる厳しい温熱環境下での作業を対象とした．\n熱中症経験者のいる現場での実験では，野口工業（株）において３つの異なる作業に対\nしてデータを収集した．実験一例として，プレス加工を行っている様子を図3.11 に示す．\nまた，各作業の詳細を表3.5 に示す．\n26\n図3.11: プレス加工を行っている様子\n表3.5: 各作業の詳細\n作業内容\n平均温度\n平均湿度\n実験時間\nプレス加工\n32.6◦C\n63.4%\n6 時間\n溶接\n35.3◦C\n55.2%\n6 時間\nフォークリフト\n34.7◦C\n59.1%\n6 時間\n作業者には，日常的な作業を実施してもらい，その際に脈拍間隔と熱的快適性の評価を\n行った．対象とした野口工業（株）の現場は，暑い環境での作業が常態化している．この\nため，頸部冷却を実施しないデータを取得することは安全性の観点から危険であると判断\nし，実験は頸部冷却を実施した状態でのみ実施した．図3.12 は，野口工業（株）におけ\nる実験手順のタイムテーブルである．\n図3.12: 野口工業（株）における実験手順のタイムテーブル\n被験者は30 代から50 代の男性5 名の被験者を対象に構成された．被験者のうち3 名は\n27\n過去に熱中症を経験しており，このことからも本実験が行われた環境が特に暑い環境であ\nることが示唆される．\nまた，収集したデータのラベルにおいては，図3.13 に示すように「very hot」と「hot」\nと評価されるデータのみであり，この環境の特性を反映したものとなっている．\n図3.13: 熱中症経験者のいる現場実験における拡張したPMV を用いた温熱感覚のデータ\nセットの量\n28\n第4章\n熱的快適性の予測\n4.1\n実験室から得られたデータの検証\n4.1.1\n元データを活用した分類性能の検証\n表4.1 に，実験室におけるデータセット（サンプル数6623）を用いたExtra Tree，Random\nForest，およびGradient Boosting の評価結果を示す．\n機械学習において，汎化性能を評価するための方法として，グループ5 分割交差検証を\n用いた．5 分割交差検証とは，データセットを5 個に分割して，そのうち1 つをテストデー\nタに，残りを学習データとして評価を行うものである．最後に分割した回数で割ること\nで，平均を算出する．さらに，今回は訓練データとテストデータの両方に同じ被験者の\nデータが含まれることを避けている．\n表4.1: 実験室における分類モデルの比較\nModel\nRecall[%]\nPrecision[%]\nF1[%]\nExtra Tree\n47.24\n41.36\n39.56\nRandom Forest\n47.68\n41.74\n40.20\nGradient Boosting\n47.12\n41.64\n40.99\n学習機としてExtra Tree，Random Forest，Gradient Boosting で推定したうち，最もF1 値\nの精度が高かったGradient Boosting での各温熱感覚の評価指標を表4.2 に示す．\nまた，実験室において収集されたデータをもとに，Gradient Boosting を用いて熱的快適\n性を予測した結果の混同行列を図4.1 に示す．\n表4.2: 実験室におけるGradient Boosting による各温熱感覚の評価指標\nThermal Sensation\nRecall[%]\nPrecision[%]\nF1[%]\nneutral\n5.91\n18.52\n8.96\nSlightly warm\n17.29\n34.78\n23.10\nwarm\n79.60\n50.89\n62.09\nhot\n16.50\n42.80\n23.81\n29\n図4.1: 実験室におけるGradient Boosting による熱的快適性の予測（単位：%）\nこれらの結果から，図3.7 に示したデータセットのラベル分布における不均衡がモデル\nの性能に影響を与えていると考えられる．特に，温熱感覚の「warm」のサンプル数が他の\nラベルに比べて非常に多いことが，表4.2 で示されるように，このラベルに対するRecall や\nPrecision およびF1 値が他のラベルよりも高くなる原因と考えられる．一方で，「neutral」\nや「hot」のようにサンプル数が少ないラベルでは，これらの指標が低い結果となっている．\n図4.1 の混同行列を見ると，モデルは「warm」ラベルを他のラベルと比較して高い割合\nで予測しており，逆に「neutral」や「hot」ラベルのサンプルは「warm」に誤分類される\n傾向が確認できる．これは，ラベル数の不均衡がモデルの学習バイアスを引き起こし，多\n数派クラスに対して高い予測精度を示す一方，少数派クラスに対しては性能が低下するこ\nとを示している．\n4.1.2\nオーバーサンプリング適用後の分類性能の検証\nラベル分布の不均衡を対処するために，データセットに含まれるラベル数の不均衡を解\n消するオーバーサンプリング手法の1 つであるBorderlineSMOTE を使用し4 種類のラベ\nル数を等しくした．\n表4.3 には，実験室において収集されたデータに対し，オーバーサンプリングを適用し\nたデータセット（サンプル数13336）を用いたExtra Tree，Random Forest，およびGradient\nBoosting の評価結果を示す．\n30\n表4.3: 実験室における分類モデル性能の比較（オーバーサンプリングの適用後）\nModel\nRecall[%]\nPrecision[%]\nF1[%]\nExtra Tree\n67.05\n65.20\n64.63\nRandom Forest\n66.02\n64.15\n63.90\nGradient Boosting\n57.32\n56.14\n56.05\n表4.3 より，オーバーサンプリング適用後，Recall，Precision，F1 値が全体的に向上し\nている．特に，Extra Tree ではF1 値が約25%上昇し，Random Forest やGradient Boosting\nにおいても同様の傾向が見られる．\n学習機としてExtra Tree，Random Forest，Gradient Boosting で推定したうち，最もF1 値\nの精度が高かったExtra Tree での各温熱感覚の評価指標を表4.4 に示す．\nまた，実験室においてオーバーサンプリングを実施したデータをもとに，Extra Tree を\n用いて熱的快適性を予測した結果の混同行列を図4.2 に示す．\n表4.4: 実験室におけるExtra Tree による各温熱感覚の評価指標（オーバーサンプリング\nの適用後）\nThermal Sensation\nRecall[%]\nPrecision[%]\nF1[%]\nneutral\n82.39\n69.72\n75.53\nSlightly warm\n67.13\n61.59\n64.24\nwarm\n27.89\n55.29\n37.08\nhot\n90.79\n74.19\n81.66\n31\n図4.2: 実験室におけるExtra Tree による熱的快適性の予測（オーバーサンプリングの適\n用後，単位：%）\n表4.4 をオーバーサンプリング適用前（表4.2）と比較すると，F1 値に以下のような変\n化が見られた．\nまず，「neutral」クラスにおいては，適用前のF1 値が8.96%であったのに対し，適用後\nは75.53%へと大幅に改善している．同様に，「slightly warm」クラスのF1 値も，適用前\nの23.10%から64.24%へと大きく向上した．また，「hot」クラスに関しても，適用前のF1\n値23.81%から適用後は81.66%へと著しい改善が確認された．\n一方，「warm」クラスに関しては，適用前のF1 値62.09%から適用後は37.08%へと減少\nしている．これは，少数派クラスである他の温熱感覚を区別する性能が向上する一方で，\n多数派クラスである「warm」の優位性が相対的に低下した結果と考えられる．\nこのことから，オーバーサンプリングの適用により，少数派クラス（neutral, slightly warm,\nhot）の予測性能が大幅に向上し，データセット全体のクラス間バランスが改善されたこ\nとが示された．\n図4.2 の混同行列から，「hot」および「neutral」のクラスにおいては，真のラベルと予測\nラベルが一致する割合がそれぞれ90.79%および82.39%と高く，極端な温熱状態の分類精\n度が優れていることが確認された．特に，熱中症の予防に最も重要である「hot」の分類\n精度が90.79%と非常に高い点は，本研究で構築したモデルが熱的危険状態を適切に検出\nできる可能性を示している．一方，「warm」と「slightly warm」のクラスでは，誤分類の\n割合が相対的に高く，特に「warm」の30.50%が「slightly warm」と混同されるなど，中\n間的な温熱感覚の区別が困難であることが示唆された．\n32\n4.2\n現場から得られたデータの検証\n4.2.1\n元データを活用した分類性能の検証\n表4.5 に，現場におけるデータセット（サンプル数3171）を用いたExtra Tree，Random\nForest，およびGradient Boosting の評価結果を示す．\n表4.5: 現場における分類モデルの比較\nModel\nRecall[%]\nPrecision[%]\nF1[%]\nExtra Tree\n47.59\n39.01\n42.72\nRandom Forest\n50.65\n40.46\n44.47\nGradient Boosting\n39.55\n39.72\n39.63\n学習機としてExtra Tree，Random Forest，Gradient Boosting で推定したうち，最もF1 値\nの精度が高かったRandom Forest での各温熱感覚の評価指標を表4.6 に示す．\nまた，現場において収集されたデータをもとに，Random Forest を用いて熱的快適性を\n予測した結果の混同行列を図4.3 に示す．\n表4.6: 現場におけるRandom Forest による各温熱感覚の評価指標\nThermal Sensation\nRecall[%]\nPrecision[%]\nF1[%]\nwarm\n79.91\n60.67\n68.97\nhot\n0.47\n0.96\n0.63\nvery hot\n6.13\n12.28\n8.17\n図4.3: 現場におけるRandom Forest による熱的快適性の予測（単位：%）\n33\nこれらの結果から，図3.10 に示したデータセットのラベル分布における不均衡がモデ\nルの性能に影響を与えていると考えられる．4.1.1 項と同様に，温熱感覚の「warm」のサ\nンプル数が他のラベルに比べて非常に多いことが，表4.6 で示されるように，このラベル\nに対するRecall やPrecision およびF1 値が他のラベルよりも高くなる原因と考えられる．\n一方で，「hot」や「very hot」のようにサンプル数が少ないラベルでは，これらの指標が\n低い結果となっている．\nまた，図4.3 の混同行列を見ると，モデルは「warm」ラベルを他のラベルと比較して高\nい割合で予測しており，逆に「hot」や「very hot」ラベルのサンプルは「warm」に誤分類\nされる傾向が確認できる．\n4.2.2\nオーバーサンプリング適用後の分類性能の検証\n表4.7 には，現場において収集されたデータに対し，オーバーサンプリングを適用した\nデータセット（サンプル数5838）を用いたExtra Tree，Random Forest，およびGradient\nBoosting の評価結果を示す．\n表4.7: 現場における分類モデル性能の比較（オーバーサンプリングの適用後）\nModel\nRecall[%]\nPrecision[%]\nF1[%]\nExtra Tree\n68.60\n68.96\n67.87\nRandom Forest\n67.39\n67.70\n66.93\nGradient Boosting\n60.95\n61.58\n60.91\n表4.7 より，オーバーサンプリング適用後，Recall，Precision，F1 値が全体的に向上し\nている．特に，Extra Tree ではF1 値が約25%上昇し，Random Forest やGradient Boosting\nにおいても同様の傾向が見られる．\n学習機としてExtra Tree，Random Forest，Gradient Boosting で推定したうち，最もF1 値\nの精度が高かったExtra Tree での各温熱感覚の評価指標を表4.8 に示す．\nまた，現場においてオーバーサンプリングを実施したデータをもとに，Extra Tree を用\nいて熱的快適性を予測した結果の混同行列を図4.4 に示す．\n表4.8: 現場におけるExtra Tree による各温熱感覚の評価指標（オーバーサンプリングの\n適用後）\nThermal Sensation\nRecall[%]\nPrecision[%]\nF1[%]\nwarm\n48.46\n68.63\n56.81\nhot\n76.62\n74.33\n75.46\nvery hot\n80.73\n63.91\n71.34\n34\n図4.4: 現場におけるExtra Tree による熱的快適性の予測（オーバーサンプリングの適用\n後，単位：%）\n表4.8 をオーバーサンプリング適用前（表4.6）と比較すると，F1 値に以下のような変\n化が見られた．\nまず，「hot」クラスにおいては，適用前のF1 値が0.63%であったのに対し，適用後は\n75.46%へと大幅に改善している．同様に，「very hot」クラスのF1 値も，適用前の8.17%\nから71.34%へと大きく向上した．\n一方，「warm」クラスに関しては，適用前のF1 値68.97%から適用後は56.81%へと減少\nしている．これは，少数派クラスである他の温熱感覚を区別する性能が向上する一方で，\n多数派クラスである「warm」の優位性が相対的に低下した結果と考えられる．\nこのことから，オーバーサンプリングの適用により，少数派クラス（hot, very hot）の\n予測性能が大幅に向上し，データセット全体のクラス間バランスが改善されたことが示さ\nれた．\n図4.4 の混同行列から，「very hot」および「hot」のクラスにおいては，真のラベルと予\n測ラベルが一致する割合がそれぞれ80.73%および76.62%と高く，極端な温熱状態の分類\n精度が優れていることが確認された．一方，「warm」の32.94%が「very hot」として分類\nされるなど，中間的な温熱感覚における誤分類が目立つ結果となった．現場では環境因子\nの統制が難しいことにより，実験室と比較してデータのばらつきが大きくなり，特に中間\n的な温熱状態（「warm」）の分類に影響を及ぼしている可能性が考えられる．それにもか\nかわらず，「very hot」および「hot」の分類精度が高い点は，熱中症のリスクが高い状態\nを適切に検出できる可能性を示しており，本モデルの実用性を支持する結果といえる．\n現場実験で収集したデータのうち，頚部冷却を行わない条件下で得られたデータに対し\nてオーバーサンプリングを適用し，これをExtra Tree モデルの学習に使用した．その結果，\n頚部冷却を実施した条件下における熱的快適性を予測した結果を図4.5 に示す．\n35\n混同行列は図4.5 に示すように全体的に右寄りの傾向を示した．具体的には，本来「very\nhot」や「hot」に分類されるデータが，機械学習を用いて「warm」と分類される割合が増\n加している．この右寄りの傾向は，頚部冷却により生体反応の熱的リスクが低下した可能\n性を示している．\nまた，頚部冷却を行わないデータで学習したモデルは，その条件下で高い分類精度を示\nしていることから，今回の混同行列に示される右寄りの分類結果の信頼性は高いと考えら\nれる．すなわち，頚部冷却により被験者の生体反応が「very hot」や「hot」から「warm」\nへと軽減される傾向が明確に示されており，熱中症リスクの低減に寄与する可能性が強く\n示唆される．\n図4.5: 現場における頚部冷却ありの熱的快適性の予測（単位：%）\n4.3\n熱中症経験者のいる現場から得られたデータの検証\n現場実験で収集したデータのうち，頚部冷却を行わない条件下で得られたデータと実験\n室で収集したデータに対してオーバーサンプリングを適用し，これをExtra Tree モデルの\n学習に使用した．その結果，熱中症経験者のいる現場実験において収集された頚部冷却を\n実施した条件下における熱的快適性を予測した結果を図4.6 に示す．\n混同行列は全体的に右寄りの傾向を示しており，具体的には，真値が「very hot」や「hot」\nであるデータの一部が「warm」や「slightly warm」と予測される割合が増加している．こ\nの右寄りの傾向は，頸部冷却によって被験者の生理的負担が軽減し，熱中症リスクが低下\nした可能性を示唆している．\n一方で，真値が「hot」であるにもかかわらず「very hot」と予測されるケースも一部観\n察された．この結果は，モデルが頸部冷却の影響を十分に反映できていないことや，個体\n差やデータのばらつきが影響している可能性が考えられる．\n36\nまた，頸部冷却が十分に効果を発揮しない状況や外部環境の要因も誤分類の原因として\n挙げられる．\nそれにもかかわらず，今回の結果は頸部冷却が「very hot」や「hot」といった極端な熱\n的状態を軽減し，「warm」や「slightly warm」へと熱的快適性を改善する傾向を示してお\nり，熱中症リスクの低減に寄与する可能性を示唆するものといえる．\n図4.6: 熱中症経験者のいる現場における熱的快適性の予測（単位：%）\nまた，データセットを熱中症経験者と非経験者に分け，それぞれ評価に用いた混同行列\nを図4.7 および図4.8 に示す．混同行列を見ると，全体的な分類の傾向として，熱中症経\n験者においては，真値が「very hot」や「hot」であるデータが「warm」や「slightly warm」，\nさらには「neutral」へと右側に分類される割合が一定数確認された．一方，非経験者の場\n合，「very hot」や「hot」と分類される割合が経験者より高く，「warm」への移動が特に顕\n著であった．しかし，それより右側である「slightly warm」や「neutral」への移動は少な\nく，右寄りの分類傾向は限定的であった．\n具体的には，図4.7（熱中症経験者）においては，真値が「very hot」の場合に「slightly\nwarm」への分類割合が23.10%，「neutral」への分類割合が4.84%と，非経験者（図4.8）に\nおける「slightly warm」への分類割合が9.02%，「neutral」への分類割合が1.28%と比べ，\n高い結果が得られた．\nまた，真値が「hot」の場合も，経験者では「slightly warm」や「neutral」への分類が見\nられたが，非経験者では「warm」への分類が集中していた．\nこれらの結果から，頚部冷却による全体的な右寄りの分類傾向は熱中症経験者のほうが\n強く示されていることが分かる．これは，熱中症経験者が過去の経験により生理的適応が\n異なるため，頚部冷却の効果がより顕著に現れる可能性を示唆している．\nまた，非経験者の場合は「warm」への分類が集中しており，冷却効果は一定程度確認で\nきるものの，分類が「slightly warm」や「neutral」に至る割合は低いことが示された．\n37\n以上の結果より，頚部冷却は特に熱中症経験者に対して顕著な効果を発揮し，生体反応\nの熱的負荷を低減させる可能性が高いことが示唆される．\n図4.7: 熱中症経験者における熱的快適性の予測（単位：%）\n図4.8: 熱中症非経験者における熱的快適性の予測（単位：%）\n38\n第5章\n自律型リアルタイム推定システムの検討\n本章では，スマートウォッチを用いた自律型リアルタイム推定システムの開発を行う．\nこのシステムは，取得したデータをクラウドサーバに送信し，クラウド側で推定を行った\n結果を受信する方式ではなく，デバイス単体で完結するリアルタイムなデータ処理および\nフィードバックを実現するものである．現場においては，インターネット環境が整ってい\nない場合が多く，クラウドサーバを利用したデータ処理が困難であるという課題が存在\nする．\nまた，Empatica 社製E4 リストバンドは，スマートフォンを携帯しながら作業を行う必\n要があるが，携帯電話の持ち運びが難しい環境や作業の妨げとなる状況が想定される．こ\nれらの課題を解決するために，スマートウォッチを用いた自律型システムの構築は現場実\n用性の向上に寄与すると考えられる．特に，リアルタイムなフィードバックが可能となる\nことで，使用者が即時に対応を取ることができ，安全性や作業効率の向上が期待される．\n5.1\nE4 リストバンドとスマートウォッチから得られるデータの比較\nEmpatica E4 リストバンドとスマートウォッチの心拍間隔データを比較することは，推\n定精度を確保する上で重要である．特に，スマートウォッチから取得できる心拍間隔の情\n報を，Empatica E4 リストバンドから得られる心拍間隔データに可能な限り近づけること\nが必要不可欠である．これは，両デバイスから得られるデータが近づけば，心拍間隔に関\n連した特徴量として用いる推定モデルの性能を維持し，正確なリアルタイム推定を可能に\nするためである．\n5.1.1\n使用するスマートウォッチ\n推定をするために使用したスマートウォッチは，図5.1 に示すPolar 社製の「M600」\n（Wear\nOS by Google）である[47]．このスマートウォッチは，フィットネスおよびスポーツ用途\nを主目的として設計されており，音楽再生，健康管理，ライフスタイルの追跡，コミュニ\nティ機能など，多様なニーズに対応可能な機能を有する．搭載センサは，心拍センサ，加\n速度センサ，周辺光センサ，ジャイロスコープ，バイブレーションモータ，およびマイク\nで構成されている．特に心拍センサには光学式心拍測定技術が採用されており，精度の高\nい測定が可能である．\nPolar M600 スマートウォッチでは，心拍に関連したデータを取得することが可能であ\nり，これをもとに心拍間隔を算出することで，Empatica E4 リストバンドを用いた際に推\n定された指標と同等のデータを得ることができる．\n39\n図5.1: Polar 社製M600 Wear OS by Google\n5.1.2\n使用するデータ\n本比較においては，平均温度約28◦C，平均湿度約60%の室内環境で1 時間タイピングを\n行った際のデータを用いた．Empatica E4 リストバンドにより取得された心拍間隔（RRI）\nと，Polar M600 スマートウォッチから取得された心拍情報をもとに計算された心拍間隔\nの分布を図5.2 および図5.3 に示す．E4 リストバンドのデータ（図5.2）は，平均が約800\nms 付近で正規分布に近い形状を示しており，全体的に分布が滑らかである．一方，Polar\nM600 のデータ（図5.3）は，800 ms 付近ではE4 リストバンドと同様にピークが見られる\nものの，1000 ms から1500 ms 付近にかけてもう一つのピークが観測されており，心拍間\n隔の分布に明らかな特徴の違いがある．特に，1500 ms 付近の突出は異常値が含まれてい\nる可能性を示唆している．\nまた，それぞれの心拍情報に基づき6 つの特徴量を算出し，これを用いて熱的快適性を\n予測した結果を図5.4 および図5.5 に示す．\n図5.2: E4 リストバンドによる心拍間隔の\n分布\n図5.3: Polar M600 スマートウォッチによる\n心拍間隔の分布\n40\n図5.4: E4 リストバンドによるデータに基\nづく推定結果\n図5.5: Polar M600 スマートウォッチによる\nデータに基づく推定結果\n5.1.3\nフィルターの効果検証\n心拍変動指標を用いた解析においては，データの正確性を確保するために異常値を適切\nに除去するフィルタリング処理が不可欠である．本検証では，2 種類のフィルタリング手\n法を用いて効果を検証した．\nまず，1 つ目の手法として心拍間隔の値が250 ms 以上1200 ms 以下の範囲に収まるデー\nタのみを選別する．この範囲は，通常の人間の心拍数（約50～240 拍/分）に対応してお\nり，生理学的に異常とされるデータを除外する基準として用いられる．具体的には，250\nms 未満の心拍間隔は頻脈や測定誤差を示す可能性があり，1200 ms を超える心拍間隔は\n徐脈やノイズによる異常を含む可能性がある．この基準を適用することで，測定データの\n妥当性を担保することができる．\n次に，2 つ目の手法として心拍間隔データの分布特性に基づき，平均値±3σ の範囲内に\n収まるデータのみを選別する．ここで，σ は標準偏差を表し，データ分布の広がりを示す\n指標である．心拍間隔データが正規分布に近いと仮定した場合，この範囲には約99.7%の\nデータが収まるため，平均値から3σ を超えるデータは測定誤差や異常値である可能性が\n高い．これを除外することで，データの品質向上を図ることができる．\n以上の2 手法は，異なる基準に基づいてデータをフィルタリングするものである．統計\n的基準に基づく手法は，データ分布の特性を活用して異常値を排除することを目的として\nおり，一方で生理学的基準に基づく手法は，心拍数に基づいて異常なデータを排除するこ\nとを目的としている．これらの2 手法を併せて適用することでフィルタリングを行い，得\nられたデータをもとにその効果を検証する．\n図5.6 は，フィルタリング後のPolar M600 スマートウォッチによる心拍間隔の分布を示\nしている．\nまた，図5.7 は，フィルタリング後のPolar M600 スマートウォッチのデータを用いて推\n定された熱的快適性の分布を示している．\n図5.6 では，フィルタリングを適用した結果，Polar M600 スマートウォッチの心拍間隔\nの分布における1500 ms 付近の突出が排除され，800 ms 付近を中心とした分布形状がE4\nリストバンドのデータ（図5.2）に近づいていることが確認できる．このことは，統計的\n41\nおよび生理学的基準に基づくフィルタリング手法が，データ分布の補正に有効であったこ\nとを示している．\nさらに，図5.7 では，フィルタリング後のPolar M600 スマートウォッチのデータを用い\nた推定結果が，「warm」のみを示すE4 リストバンドの推定結果（図5.4）により近づいて\nいることが示された．これにより，フィルタリングを施すことで心拍間隔分布のみならず\n熱的快適性の推定結果においても，E4 リストバンドと一貫性のある結果が得られること\nが確認された．\nこれらの結果は，フィルタリング手法の適用によって，Polar M600 スマートウォッチの\nデータのばらつきや異常値を効果的に補正し，E4 リストバンドとのデータ一致性を向上\nさせることが可能であることを示している．\n図5.6: フィルタリング後のPolar M600 スマートウォッチによる心拍間隔の分布\n図5.7: フィルタリング後のPolar M600 スマートウォッチによるデータに基づく推定結果\n42\n5.2\nPolar M600 スマートウォッチでの推定\n5.2.1\nPolar M600 スマートウォッチでの推定に用いる特徴量\nPolar M600 スマートウォッチを用いたリアルタイム推定に使用する特徴として，6 つを\n選定した．6 つの特徴量は，4.2 節で使用したExtra Tree を用いた推定結果際の特徴量の\nうち，5 分割交差検証における5 通りの重要度で1 度でも上位5 つに含まれていたもので\nあった．表5.1 に，選定された特徴量6 つと5 分割交差検証における重要度の上位5 つに\n出現した回数を示す．\nまた，図5.8 に，5 分割交差検証における1 つの分割結果の特徴量重要度を示す．\n表5.1: 各作業の詳細\n特徴量\n出現回数\nHRV MEDIAN NNI\n5 回\nHRV MEAN hr\n5 回\nHRV PCT 5\n5 回\nHRV STD HR\n5 回\nHRV MEAN\n3 回\nHRV MEAN NNI\n2 回\n43\n図5.8: 5 分割交差検証における特徴量重要度（分割1 の結果）\n5.2.2\n6 つの特徴量のみを使用した場合の推定精度\n特徴量を選定した6 つを使用し，現場実験において収集された頚部冷却なしのデータに\n基づく機械学習をした熱的快適性予測の結果を図5.9 に示す．まず，真値が「very hot」の\n場合，再現率は56.37%に留まっており，全体の約30.94%が「warm」に誤分類されてい\nる．この結果は，「very hot」と「warm」が特徴量の削減により識別が困難になったこと\nを示している．一方で，「hot」との誤分類（12.69%）は相対的に少なく，特定の中間状態\nにおける誤分類が抑えられている可能性が考えられる．\n次に，真値が「hot」の場合，再現率は59.87%であり，特徴量を52個使用した場合（76.62%）\nと比較すると大幅な精度低下が確認できる．\nまた，「very hot」（19.53%）および「warm」（20.61%）への誤分類が均等に発生してお\nり，「hot」を特徴付ける要素が十分に抽出されていないことが示唆される．\nさらに，真値が「warm」の場合，再現率は55.81%であり，30.01%が「very hot」，14.18%\nが「hot」に誤分類されている．この結果から，「warm」は他の状態と比較して最も広範囲\nな誤分類を受けており，6 つの特徴量では「warm」の特性を十分に表現できていない可能\n性が高い．\n全体として，特徴量を6 つに限定した場合には，分類性能が全体的に低下し，特に「very\nhot」と「warm」の識別が困難であることが示された．一方で，リアルタイム処理を想定\nしたモデル軽量化の観点からは，許容可能な範囲での性能維持が確認されたといえる．こ\n44\nの結果は，推定モデルにおける特徴量選択の重要性を示唆しており，精度と効率のバラン\nスを考慮した最適な特徴量数の選定が求められる．\n図5.9: 6 つの特徴量を使用した現場における熱的快適性の予測（単位：%）\n5.2.3\nリアルタイム推定システムと画面出力\n分類モデルの構築には，ニュージーランドのワイカト大学により開発された，Java 言語を\n基盤としたオープンソースのデータマイニングツールであるWEKA（Waikato Environment\nfor Knowledge Analysis）[48] を使用した．WEKA は，無料で利用可能なソフトウェアで\nあり，各種の機械学習アルゴリズムやデータ前処理機能を備え，データ分析やモデル構築\nを効率的に行うための環境を提供する．\n本開発では，WEKA を用いてPolar M600 スマートウォッチ内でリアルタイムに熱的快\n適性を推定するシステムを構築した．推定はその時点での結果に加え，直前の4 つの推定\n結果を用いた多数決によって行われ，これにより安定した推定結果を得ることを目的と\nした．\n推定された熱的快適性に応じて，Polar M600 スマートウォッチの画面に適切な画像を表\n示し，作業者が現在の温熱状態を直感的に把握できるようにする．具体的には，熱的快適\n性が「neutral」と推定された場合は通常の状態を示す画像が表示され，作業者に特別な注\n意を促す必要がないことを示す．一方で，「slightly warm」と推定された場合には注意が\n必要な状態を表す画像が表示され，作業者に対して周囲の環境に意識を向けるよう促す．\nさらに，「warm」と推定された場合には警戒が必要であることを伝える画像が表示され，\n作業者に対してさらなる注意を喚起する．\nこれが「hot」と推定された場合には，厳重な警戒が求められる状態であることを示す\n画像が表示され，作業者に対して速やかな対応を促す．最も危険な状態である「very hot」\n45\nと推定された場合には，危険を知らせる画像が表示されるとともに，Polar M600 スマー\nトウォッチが振動して作業者に強い注意を喚起する．\n図5.10 に，Polar M600 スマートウォッチの画面に出力を示す．\n図5.10: 推定結果に対応する画像の種類\n46\n第6章\n結論\n6.1\nまとめ\n本研究では，熱中症リスクを評価するために，実験室環境および実運用環境における熱\n的快適性の推定モデルを構築し評価した．結果として，データ収集環境や頸部冷却の有無\nによる影響を詳細に検討し，モデルの有効性と課題を明らかにした．\n実験室環境では温度や湿度を制御し，データを収集し分析した結果，「hot」と「neutral」\nの分類精度が高く，特に「hot」の分類精度の高さは熱中症リスク検出の信頼性を示した．\n一方，現場環境では日常的作業を行う被験者からデータを収集し，頸部冷却の有無を比\n較した．頸部冷却を実施しない場合，「very hot」と「hot」の分類精度は比較的良好であっ\nたが，「warm」クラスの分類精度は低下し，データのばらつきが影響している可能性が示\n唆された．頸部冷却を実施した場合，「very hot」や「hot」の状態が「warm」や「slightly\nwarm」と分類される傾向が見られ，頸部冷却が熱的快適性の向上と熱中症リスク軽減に\n寄与することが確認された．\nさらに，過去に熱中症経験者が発生した現場においてデータを収集し分析した結果にお\nいても，頸部冷却により被験者の生理的負担が軽減されることが確認された．特に，熱中\n症経験者は非経験者に比べ，頸部冷却による熱中症リスク低減効果がより顕著であった．\n一方，個体差や外部要因により頸部冷却の効果が発揮されない状況が一部観察された．\nさらに，自律型リアルタイム推定システムの開発を行い，特徴量を6 つに削減したモデ\nルをPolar M600 スマートウォッチに搭載して実装した．このシステムではインターネッ\nト接続を必要とせず，推定された温熱状態をデバイス画面に表示し，最も危険な状態にな\nると振動で警告を発する機能を備えている．推定精度は特徴量52 個を使用したモデルに\n劣るものの，検出精度は他の温熱状態と比べ高い結果を示した．\nこれら成果は，熱中症予防技術の基盤を提供し，労働環境や高齢者支援の改善に寄与す\nるものである．\n6.2\n今後の展望\n今後の展望として，Polar M600 スマートウォッチで推定された温熱快適性に基づき，頸\n部冷却を自動的に実施するなどのフィードバック手法を検討する．\nまた，リアルタイム推定の精度向上を目指し，モデルの軽量化と使用する特徴量の増加\nに取り組む．さらに，Polar M600 スマートウォッチ単体での振動フィードバックのタイ\nミングや手法を改善し，より効果的なアラートシステムの構築を目指す．\n47\n謝辞\n本研究はセコム科学技術振興財団研究助成金の支援を受けて実施した．本研究を進め\nるにあたり，御指導を賜りました青山学院大学理工学部情報テクノロジー学科Guillaume\nLopez 教授に心より感謝申し上げます．また，研究を進めるにあたり，多大なるご協力を\nいただきました株式会社富士通ゼネラルの皆様に深く感謝申し上げます．さらに，3 年間\nにわたり実験を支えてくださった大熊研究補佐員に厚く御礼申し上げます．加えて，実験\nをともに実施してくださった佐藤さん，段さん，タへラさん，川﨑さん，安藤さんに感謝\nの意を表します．また，研究会や日々の生活を通して多くの助言をいただいたロペズ研究\n室の同期や後輩，OBOG の皆様にも深く感謝いたします．最後に，本研究を支えてくだ\nさったすべての方々に心より感謝申し上げます．\n2025 年1 月31 日\n本多　一騎\n48\n参考文献\n[1] 厚生労働省. 年齢（5 歳階級）別にみた熱中症による死亡数の年次推移（平成7 年～令和\n5 年）～　人口動態統計（確定数）より. https://www.mhlw.go.jp/toukei/\nsaikin/hw/jinkou/tokusyu/necchusho23/dl/nenrei.pdf, 9 2024. (参\n照日2024/9/24).\n[2] 環境省. 環境省熱中症予防情報サイト: 環境省マニュアル2-1. (参照日2024/09/25).\n[3] 労働安全衛生総合研究所. 熱中症予防のための暑熱環境と作業負荷の総合評価. (参照\n日2024/10/4).\n[4] IPCC. 図spm.8 - 各ssp シナリオにおける1850 年～1900 年基準の地表気温変化. (参\n照日2024/09/24).\n[5] ASHRAE 55-2020: Thermal Environmental Conditions for Human Occupancy. ANSI\nApproved. 2021.\n[6] ISO 7730:2005(E): Ergonomics of the Thermal Environment-Assessment of the Inﬂuence\nof the Thermal Environment Using Subjective Judgment Scales. 2005.\n[7] Stefano Corgnati, Marco Filippi, and Sara Viazzo. Perception of the thermal environment\nin high school and university classrooms: Subjective preferences and thermal comfort.\nBuilding and Environment - BLDG ENVIRON, Vol. 42, pp. 951–959, 02 2007.\n[8] Edward Arens, Michael Humphreys, Richard de Dear, and Hui Zhang. Are ‘class a’\ntemperature requirements realistic or desirable? Building and Environment - BLDG ENV-\nIRON, Vol. 45, pp. 4–10, 01 2010.\n[9] Muhammad Khairil, A. Senin, and Azree Othuman Mydin. Signiﬁcance of thermal com-\nfort in buildings and its relation to the building occupants. European Journal of Sustain-\nable Development, 2013.\n[10] N. Seong and D. Yoon. An approach of indoor thermal environment control and energy\nsaving using the pmv index. LHI Journal, 2010.\n[11] T. Kramer, V. Garcia-Hansen, S. Omrani, J. Zhou, and D. Chen. Personal differences in\nthermal comfort perception: Observations from a ﬁeld study in brisbane, australia. Build-\ning and Environment, 2023.\n[12] Wei Luo, R. Kramer, Y. D. de Kort, and W. D. van Marken Lichtenbelt. Effectiveness of\npersonal comfort systems on whole-body thermal comfort – a systematic review on which\nbody segments to target. Energy and Buildings, 2021.\n49\n[13] Lin Lu, Jiayao Zhang, Yi Xie, F. Gao, Song Xu, Xinghuo Wu, and Z. Ye. Wearable health\ndevices in health care: Narrative systematic review. JMIR mHealth and uHealth, 2020.\n[14] M. Bez and F. Simini. Wearable devices and medical monitoring robot software to re-\nduce costs and increase quality of care. IEEE Conference on Advances in Computing,\nCommunications and Informatics, 2018.\n[15] Sam McDevitt, Haley Hernandez, Jamison S Hicks, Russell Lowell, Hamza Bentahaikt,\nReuben F. Burch, J. Ball, H. Chander, Charles E. Freeman, Courtney Taylor, and Brock\nAnderson. Wearables for biomechanical performance optimization and risk assessment in\nindustrial and sports applications. Bioengineering, 2022.\n[16] キヤノンIT ソリューションズ. ウェアラブルデバイスのセキュリティとプライバシー\nの問題, 2020. (参照日2024/09/25).\n[17] Fortune\nBusiness\nInsights.\nWearable\ntechnology\nmarket\nsize,\nshare,\nvalue\n—\ngrowth,\n2032.\nhttps://www.fortunebusinessinsights.com/\nwearable-technology-market-106000, 2024. (参照日2024/09/25).\n[18] Nikhil Singh, K. Moneghetti, J. Christle, D. Hadley, V. Froelicher, and D. Plews. Heart\nrate variability: An old metric with new meaning in the era of using mhealth technologies\nfor health and exercise training guidance. Arrhythmia I& Electrophysiology Review, 2018.\n[19] Hidehiko Ikura, Yoshinori Katsumata, Y. Seki, Toshinobu Ryuzaki, Y. Shiraishi, Kotaro\nMiura, Kazuki Sato, and K. Fukuda. Real-time analysis of heart rate variability during aer-\nobic exercise in patients with cardiovascular disease. International Journal of Cardiology\nHeart I& Vasculature, 2022.\n[20] 鈴木伊織, 佐藤文明ほか. ウェアラブル端末により検知した心拍変動に基づくストレ\nス推定. 研究報告コンピュータセキュリティ(CSEC), Vol. 2020, No. 30, pp. 1–7, 2020.\n[21] Kizito Nkurikiyeyezu, Yuta Suzuki, and Guillaume Lopez.\nHeart rate variability as a\npredictive biomarker of thermal comfort. Journal of Ambient Intelligence and Humanized\nComputing, Vol. 9, , 10 2018.\n[22] 早野順一郎, 山田眞己, 藤浪隆夫, 横山清子, 渡辺與作, 高田和之. 心拍変動と自律神経\n機能. 生物物理, Vol. 28, No. 4, pp. 198–202, 1988.\n[23] F. Canini, E. Sagui, and F. Zagnoli. Syst`eme nerveux, stress et coup de chaleur. EAC\nRevue, Vol. 36, No. 2, pp. 102–108, 2012.\n[24] Takashi Hamatani, A. Uchiyama, and T. Higashino. Estimating core body temperature\nbased on human thermal model using wearable sensors. Proceedings of the ACM Confer-\nence, 2015.\n[25] K. Tokizawa, Toru Shimuta, and Hirofumi Tsuchimoto. Wearable technologies for real-\ntime monitoring of body core temperature under heat stress conditions. Medicine I& Sci-\nence in Sports I& Exercise, 2020.\n50\n[26] 日本気象協会. 学びの部屋「熱中症予防の基礎知識」. https://www.netsuzero.\njp/learning/le17. (参照日2024/10/02).\n[27] Mayo\nClinic\nHealth\nSystem.\nWhen\ntemps\nrise,\nremember\nthese\nheat-\nstroke\nprevention\ntips.\nhttps://www.mayoclinichealthsystem.\norg/hometown-health/speaking-of-health/\nwhen-temps-rise-remember-these-heatstroke-prevention-tips,\n2023. (参照日2024/10/02).\n[28] 環境省. 熱中症環境保健マニュアル, 2022. (参照日2024/10/02).\n[29] Cleveland\nClinic.\nHyperthermia\n(heat-related\nillnesses).\nhttps://my.\nclevelandclinic.org/health/diseases/22111-hyperthermia.\n(参照\n日2024/10/02).\n[30] Jai Kyoung Sim, S. Yoon, and Young-Ho Cho. Wearable sweat rate sensors for human\nthermal comfort monitoring. Scientiﬁc Reports, Vol. 8, pp. 1–10, 2018.\n[31] Jintu Fan and Humble W. K. Tsang. Effect of clothing thermal properties on the thermal\ncomfort sensation during active sports. Journal of Industrial Textiles, Vol. 37, No. 4, pp.\n319–335, 2008.\n[32] Naoto Fujii, Kion Hatam, G. Mcgarr, R. Meade, P. Boulay, T. Nishiyasu, and G. Kenny.\nExogenous activation of protease-activated receptor 2 attenuates cutaneous vasodilatation\nand sweating in older men exercising in the heat. Acta Physiologica, Vol. 226, No. 4, p.\ne13369, 2019.\n[33] Chee Chong Shawn Tan, Li Chin, and I. C. C. Low. Thermoregulation in the aging pop-\nulation and practical strategies to overcome a warmer tomorrow.\nProteomics Clinical\nApplications, Vol. 14, No. 3, p. 1800468, 2020.\n[34] Su-Young Son. Research trends on prevention of heat stroke using clothing: Focusing\non practical research in japan. Fashion and Ergonomics Research, Vol. 56, pp. 473–484,\n2018.\n[35] Zijun Li, Mengsheng Zhang, Tian Yuan, Qiaoli Wang, Pengyu Hu, and Yu Xu. New\nwearable thermoelectric cooling garment for relieving the thermal stress of body in high\ntemperature environments. Energy and Buildings, Vol. 112, pp. 1–10, 2022.\n[36] Wanwan Wang and Mengmeng Zhao. Design of liquid–air hybrid cooling garment and its\neffect on local thermal comfort. Applied Sciences, Vol. 13, p. 9414, 2023.\n[37] D. Leyk, J. Hoitz, C. Becker, K. Glitz, Kai Nestler, and C. Piekarski. Health risks and\ninterventions in exertional heat stress. Arzteblatt International, Vol. 116, pp. 537–544,\n2019.\n[38] Christian K. Garcia, Liliana I. Renter´ıa, Gabriel Leite-Santos, Lisa R. Leon, and O. Lai-\ntano. Exertional heat stroke: pathophysiology and risk factors. BMJ Medicine, Oct 2022.\n51\n[39] A. Costrini, H. Pitt, A. Gustafson, and D. E. Uddin. Cardiovascular and metabolic mani-\nfestations of heat stroke and severe heat exhaustion. American Journal of Medicine, Feb\n1979.\n[40] 千葉友樹, 高橋幹雄, 黒木友裕, 和田一樹, 天野健太郎, 桑山絹子. 局所冷却行為による\n暑熱ストレス低減効果の予測手法に関する研究(その1) 頸部冷却時の生理反応の検\n討. 空気調和・衛生工学会大会学術講演論文集令和元年度大会(札幌) 学術講演論文\n集第6 巻温熱環境評価編, pp. 37–40. 公益社団法人空気調和・衛生工学会, 2019.\n[41] Povl Ole Fanger. Assessment of man’s thermal comfort in practice. British Journal of\nIndustrial Medicine, Vol. 30, pp. 313 – 324, 1973.\n[42] E. Halawa and J. van Hoof. The adaptive approach to thermal comfort: A critical overview.\nEnergy and Buildings, Vol. 51, pp. 101–110, 2012.\n[43] empatica. E4 wristband — real-time physiological signals — wearable ppg, eda, temper-\nature, motion sensors. https://www.empatica.com/research/e4/. (参照日\n2024/10/15).\n[44] Luca Menghini, Evelyn Gianfranchi, Nicola Cellini, Elisabetta Patron, Mariaelena Tagli-\nabue, and Michela Sarlo. Stressing the accuracy: Wrist-worn wearable sensor validation\nover different conditions. Psychophysiology, Vol. 56, , 07 2019.\n[45] 工場向け暑さ対策— コモドギア- 富士通ゼネラル. (参照日2024/10/15).\n[46] Fred Shaffer and J. P. Ginsberg. An overview of heart rate variability metrics and norms.\nFrontiers in Public Health, Vol. 5, , 2017.\n[47] M600\nユーザーマニュアル\n—\npolar\nm600\nユーザーマニュアル.\nhttps://support.polar.com/e_manuals/M600/wear-os/\npolar-m600-user-manual-japanese/Content/introduction.htm.\n(参照日2025/01/12).\n[48] Machine learning project at the university of waikato in new zealand. https://ml.\ncms.waikato.ac.nz/index.html. (参照日2025/01/12).\n52\n質疑応答\n工藤　聖人　情報テクノロジー学科　助手\nQ\n研究背景に高齢者の熱中症死亡者数増加傾向を挙げられていましたが，実験では現\n場などの高齢者とは言えない年齢層だったのはなぜでしょうか．\nA\nご質問ありがとうございます．研究背景での言及は，運動や労働などによる若年層\nや中年層の熱中症だけでなく，高齢者の屋内での熱中症なども多くあり，全年代に\n対して熱中症の危機感を持つべきだという意図のもと高齢者の熱中症死亡者数増加\n傾向を挙げさせていただきました．また，高温多湿な環境において高齢者のデータ\nを収集することは健康面に対して非常に配慮して行う必要があるため，今回は現場\nで働いている方のデータ収集や，高齢者の方には制御された実験室のもと涼しい格\n好でデータを収集させていただきました．\n大原　剛三　情報テクノロジー学科　教授\nQ\nコメントになりますが，高齢者と若年層では感じ方など異なると思います．\nA\nコメントありがとうございます．先行研究でも年齢差で熱に対する快適性や熱中症\nの重症度などの違いには言及されており，本実験で収集されたデータにおいても，学\n習用データセットを50 歳以上と50 歳未満で分けた際に精度の向上がみられました．\n高齢者の健康に配慮してより多くのデータを収集し，高齢者専用の熱的快適性モデ\nルを作成することも視野に入れたいと思います．\n浦垣　啓志郎　情報テクノロジー学科　助手\nQ\n暑さを測る指標であるPMV は連続値で出ていると思うのですが，分類問題にした\n理由はなぜでしょうか．\nA\nご質問ありがとうございます．PMV の値は連続値で取得できますが，基礎実験で\nある実験室での実験は，温度や湿度が一定に制御された環境でのデータ収集であっ\nたため，算出されるPMV の値も離散的な傾向にありました．そのため，このデータ\nを訓練データとして用いて熱中症経験者のいる現場で得たデータなどの評価するた\nめに，今回は分類問題とさせていただきました．今後は，制御されていない環境で\nのデータ収集を増やし，より多様な条件下でPMV の値を取得することで，回帰分析\nを用いた細かい粒度での熱中症リスク評価を目指していきたいと考えています．\n53\n",
        "chunks": [
            "M2024_Kazuki_Honda. M2024_Kazuki_Honda. M2024_Kazuki_Honda",
            " \n \n \n \n \n \n \n \n青 \n山 \n学 \n院 \n大 \n学 \n理 \n工 \n学 \n研 \n究 \n科 \n \n \n \n \n理工学専攻 \n知能情報 \nコース \n \n \n \n修 \n士 \n論 \n文 \n \n \n学 生 番 号 \n35623244 \n \n \n氏 \n名 \n本多 一騎 \n \n \n研究指導教員 \nGuillaume Lopez \n \n多様な環境における熱中症リスク評価と予防策の検討\n本多一騎\n2025/01/31\n目次\n第1 章\n序論\n3\n1.1\n研究背景. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n3\n1.1.1\n熱中症による被害\n. . . . . . . . . . . . . . . . . . . . . . . . . . .\n3\n1.1.2\n熱中症のメカニズム\n. . . . . . . . . . . . . . . . . . . . . . . . . .\n4\n1.1.3\n地表気温変化と影響\n. . . . . . . . . . . . . . . . . . . ",
            "3\n地表気温変化と影響\n. . . . . . . . . . . . . . . . . . . . . . . . . .\n5\n1.1.4\n現在の熱的快適性提供技術の問題点\n. . . . . . . . . . . . . . . . .\n5\n1.1.5\n熱的快適性の役割と影響. . . . . . . . . . . . . . . . . . . . . . . .\n6\n1.1.6\nウェアラブルデバイスの普及\n. . . . . . . . . . . . . . . . . . . . .\n6\n1.2\n研究目的. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n7\n1.3\n本論文の構成. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n8\n第2 章\n関連研究\n9\n2.1\n心拍変動指標に基づく生理的評価. . . . . . . . . . . . . . . . . . . . . . .\n9\n2",
            "価. . . . . . . . . . . . . . . . . . . . . . .\n9\n2.1.1\n心拍変動指標の健康および運動指導への応用. . . . . . . . . . . . .\n9\n2.1.2\nウェアラブル端末を用いたストレス推定. . . . . . . . . . . . . . .\n10\n2.1.3\n気温の変化による心拍変動指標への影響. . . . . . . . . . . . . . .\n10\n2.1.4\n自律神経機能の低下と熱中症のリスク\n. . . . . . . . . . . . . . . .\n11\n2.2\nウェアラブルセンサ技術を用いた熱中症リスク推定. . . . . . . . . . . . .\n12\n2.2.1\nウェアラブルセンサによる深部体温の推定. . . . . . . . . . . . . .\n12\n2.2.2\n発汗と熱中症リスクの関係\n. . . . . . . . . . . . . . . . . . . . . .\n13\n2.3\n熱中症予防対策に関する研究\n. . . . . . . . . . . . . . ",
            "\n13\n2.3\n熱中症予防対策に関する研究\n. . . . . . . . . . . . . . . . . . . . . . . . .\n15\n2.3.1\n水冷服および空調服による熱中症予防\n. . . . . . . . . . . . . . . .\n15\n2.3.2\n水分補給による熱中症予防\n. . . . . . . . . . . . . . . . . . . . . .\n15\n2.3.3\n頸部冷却による熱中症予防\n. . . . . . . . . . . . . . . . . . . . . .\n16\n第3 章\nデータ収集\n17\n3.1\n熱的快適性モデル. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n17\n3.2\n実験に使用されたデバイス. . . . . . . . . . . . . . . . . . . . . . . . . . .\n17\n3.3\n熱的快適性予測のための特徴量とデータ前処理\n. . . . . . . . . . . . . . .\n19\n3.3.1\n時間領",
            "とデータ前処理\n. . . . . . . . . . . . . . .\n19\n3.3.1\n時間領域解析. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n19\n3.3.2\n周波数領域解析. . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n19\n3.4\n多様な環境での実験\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n22\n3.4.1\n実験室における実験\n. . . . . . . . . . . . . . . . . . . . . . . . . .\n22\n3.4.2\n現場における実験\n. . . . . . . . . . . . . . . . . . . . . . . . . . .\n24\n3.4.3\n熱中症経験者のいる現場での実験. . . . . . . . . . . . . . . . . . .\n26\n1\n第4 章\n熱的快適性の予測\n29\n4.1\n実験室から",
            " . . . . . . . . .\n26\n1\n第4 章\n熱的快適性の予測\n29\n4.1\n実験室から得られたデータの検証. . . . . . . . . . . . . . . . . . . . . . .\n29\n4.1.1\n元データを活用した分類性能の検証\n. . . . . . . . . . . . . . . . .\n29\n4.1.2\nオーバーサンプリング適用後の分類性能の検証\n. . . . . . . . . . .\n30\n4.2\n現場から得られたデータの検証. . . . . . . . . . . . . . . . . . . . . . . .\n33\n4.2.1\n元データを活用した分類性能の検証\n. . . . . . . . . . . . . . . . .\n33\n4.2.2\nオーバーサンプリング適用後の分類性能の検証\n. . . . . . . . . . .\n34\n4.3\n熱中症経験者のいる現場から得られたデータの検証. . . . . . . . . . . . .\n36\n第5 章\n自律型リアルタイム推定システムの検討\n39\n5.1\nE4 リストバンド",
            " . . .\n36\n第5 章\n自律型リアルタイム推定システムの検討\n39\n5.1\nE4 リストバンドとスマートウォッチから得られるデータの比較\n. . . . . .\n39\n5.1.1\n使用するスマートウォッチ\n. . . . . . . . . . . . . . . . . . . . . .\n39\n5.1.2\n使用するデータ. . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n40\n5.1.3\nフィルターの効果検証. . . . . . . . . . . . . . . . . . . . . . . . .\n41\n5.2\nPolar M600 スマートウォッチでの推定. . . . . . . . . . . . . . . . . . . .\n43\n5.2.1\nPolar M600 スマートウォッチでの推定に用いる特徴量\n. . . . . . .\n43\n5.2.2\n6 つの特徴量のみを使用した場合の推定精度. . . . . . . . . . . . .\n44\n5.2.3\nリアルタイム推定システムと画面出力\n",
            " . . . . . . . . . . .\n44\n5.2.3\nリアルタイム推定システムと画面出力\n. . . . . . . . . . . . . . . .\n45\n第6 章\n結論\n47\n6.1\nまとめ. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n47\n6.2\n今後の展望\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n47\n謝辞\n48\n参考文献\n49\n2\n第1章\n序論\n本章では，本研究における背景および研究目的，本論文の構成について述べる．\n1.1\n研究背景\n1.1.1\n熱中症による被害\n厚生労働省によると，熱中症による死者数は年々増加傾向にあり，2023 年は1600 を超\nえる人が熱中症で命を落としている[1]．図1.1 より，熱中症の死者数の中でも特に高齢\n者の割合が大きく，2010 年以降熱中症による死者数の約80%が高齢者であった[1]．\n図1.1: 熱中症死者のうち高齢者の",
            "0 年以降熱中症による死者数の約80%が高齢者であった[1]．\n図1.1: 熱中症死者のうち高齢者の割合（[1] より作成）\n熱中症は，環境条件や活動状況によってさまざまなレベルで発生する．環境省の指針に\nよれば，熱中症の危険性は気温や湿度などの環境条件に基づいて分類され，危険レベルが高\nいほど重篤な症状が引き起こされるリスクが増加する[2]．特に高齢者や子供は熱中症の\n影響を受けやすい．注意すべき点として，暑さ指数（WBGT: Wet Bulb Globe Temperature）\nに基づく警戒レベルがあり，この指数が28◦C を超えると，熱中症の発生リスクが急激に\n高まる[2]．\n3\n1.1.2\n熱中症のメカニズム\n人間は，外気温が高くなると体温が上昇し，体温調節機能が働く．体温が37◦C 程度に\n保たれるように，皮膚の血流が増加し，発汗によって体熱を放散しようとする．しかし，\n過度の暑さや脱水が進むと，血流の変化や発汗の低下により，体温がさらに上昇し，熱中\n症のリスクが増す．特に，環境温度が高いと，発汗による体熱放散が妨げられ，体温が急\n激に上昇する可能性がある．例えば，体重70",
            "環境温度が高いと，発汗による体熱放散が妨げられ，体温が急\n激に上昇する可能性がある．例えば，体重70kg の人間は発汗により体温を10◦C 低下さ\nせることが可能であるが，大量の汗をかいたとき，水分補給が不十分だと体温調節が困難\nになる．これにより，体内の水分バランスが崩れ，最終的に熱中症を引き起こす[3]．\n熱中症はその症状に応じて「熱失神（熱虚脱）」「熱痙攣」「熱疲労（熱疲弊）」「熱射病」\nの4 つに分類される．\n熱失神は，暑熱環境下で脳への血流が一時的に減少し，立ちくらみや倦怠感が生じる状\n態である．血圧の低下も見られるが，体温上昇はほとんどない．熱痙攣は，大量の発汗で\n塩分が不足し，筋肉が痙攣することである．熱疲労は，脱水による全身のだるさや吐き気，\n頭痛などの症状を特徴とし，頻脈や体温の上昇を伴うこともある．熱射病は，体温が急激\nに上昇し，意識障害や全身の痙攣が生じる重篤な状態であり，緊急の治療が必要である．\nこれらの状態は，重症度に基づいてI 度からIII 度に分類され，III 度は最も危険な状態を\n示す．\n図1.2 は，熱中症の発生メカニズムおよび症状の重症度を示している",
            "I 度は最も危険な状態を\n示す．\n図1.2 は，熱中症の発生メカニズムおよび症状の重症度を示している．\n図1.2: 暑熱ばく露時の体温調節反応と熱中症の発生メカニズム（[3] より引用）\n4\n1.1.3\n地表気温変化と影響\n図1.3 は，産業革命前（1850 年～1900 年）を基準とした地表気温の変化を示している．\nこれまでの気温上昇は主に人間活動による温室効果ガスの排出が原因であることが分かっ\nている．気温変化の将来的な予測は，採用される社会経済パスウェイ（SSP）によって大\nきく異なり，2100 年までの予測気温上昇は約1◦C から5◦C の範囲にわたる．\nSSP5-8.5 は，温室効果ガスの排出が最も多いシナリオであり，2100 年までに地表気温\nが最大5◦C 上昇する可能性がある．一方，SSP1-1.9 やSSP1-2.6 のシナリオは，より積極\n的な排出削減を前提としており，気温上昇を1◦C から2◦C 程度に抑えることができると\n予測されている．これらの予測は，気温上昇を抑制するために迅速かつ持続的な対策が必\n要であることを示している．\n最大約5◦C 気温の上昇は，熱波の",
            "制するために迅速かつ持続的な対策が必\n要であることを示している．\n最大約5◦C 気温の上昇は，熱波の頻発や強度の増加，生態系への悪影響，さらには人間\nの健康への重大なリスクをもたらす．\n図1.3: 1850 年～1900 年を基準とした各SSP の地表気温の変化（[4] より引用）\n1.1.4\n現在の熱的快適性提供技術の問題点\n現在，ほとんどの建物や機器は，多くの人が許容できる温熱環境条件の範囲を明確にし\nた規格に基づいて作られている．しかし，環境条件の変化や室内での活動により，身体の\n温熱感覚や快適性は大きく変化することが頻繁にある．\n最近の研究では，ASHRAE 55[5] やISO 7730[6] といった熱的快適性の基準は，室内環\n境における不満を持つ人数を過小評価していることが示されている[7]．\nまた，快適に感じる温度は人によって異なることが知られている．しかし，ほとんどの\n熱的快適性を提供する技術（空調装置など）は，建物内の全員に中立的な熱環境を設定す\nるよう設計されている．\nこの熱的快適性の設定方法は，エネルギーを大量に消費し[8]，人体の中で熱的快適性\nに最も影響を与",
            "．\nこの熱的快適性の設定方法は，エネルギーを大量に消費し[8]，人体の中で熱的快適性\nに最も影響を与える部位（手首，足，頭など）を冷却または加熱することがほとんどでき\nない．さらに，室内温度を常に中立的に保つのではなく，人が熱的に不快と感じたときに\nだけ調整することで，熱的快適性に必要なエネルギーを大幅に削減できる可能性がある．\n5\nこのような観点から，快適で健康的な室内環境を実現するためには，熱的快適性を評価す\nることが重要であると考えられる．\n1.1.5\n熱的快適性の役割と影響\n熱的快適性は，人間の健康と心理的な快適さに大きな影響を与える．適切な温熱環境は，\n身体的な健康だけでなく，心理的な満足感や生産性にも寄与する．特に，熱的快適性が損\nなわれた環境では，居住者の士気や作業意欲が低下し，長期的には健康被害を引き起こす\n可能性がある[9]．\n熱的快適性を評価するために使用されるPMV（予測平均温冷感）指数は，特にオフィス\n環境において，快適性とエネルギー節約の両面で効果的であることが示されている[10]．\nしかし，PMV 指数は個々の感覚に基づくものではないため，個人差を考慮する必",
            "示されている[10]．\nしかし，PMV 指数は個々の感覚に基づくものではないため，個人差を考慮する必要があ\nり，Kramer らの研究ではPMV 指数と個別の快適性の間に大きな差が見られることが報\n告されている[11]．この報告から，より個別化された熱的快適性の管理が推奨されるよう\nになっている．\nまた，個別の快適性システム（PCS）は，局所的な温熱不快感を緩和しながら，熱的快\n適性を向上させ，健康にも好影響を与える可能性がある．これにより，特にオフィス環境\nにおいて，作業効率と健康状態の改善が期待できる[12]．\n図1.4 は，Luo らが提案している頭，手，足をターゲットとするPCS である．\n図1.4: 局所的な不快感を取り除くための提案されているPCS（[12] より引用）\n1.1.6\nウェアラブルデバイスの普及\n近年，Apple Watch をはじめとしたウェアラブルデバイスが急速に普及し，健康管理，ス\nポーツ，医療分野における重要なツールとしての地位を確立している．ウェアラブルデバ\nイスは，心拍数や活動量，睡眠データのモニタリングを通じて，個人の健康状態を常に監\n視すること",
            "ルデバ\nイスは，心拍数や活動量，睡眠データのモニタリングを通じて，個人の健康状態を常に監\n視することが可能であり，これにより健康管理や病気予防の新たなアプローチが生まれて\nいる．\n医療分野において，ウェアラブルデバイスは，患者の生理データをリアルタイムで監視\nし，疾病の早期発見や治療に役立てられている[13]．特に，高齢者や慢性疾患を抱える患\n6\n者にとって，ウェアラブルデバイスは医療費の削減や医療の質向上に貢献する可能性が\n高い．\nまた，これらのデバイスは遠隔医療の普及にも寄与しており，患者が病院を訪れること\nなく，日常的な健康データを医師と共有することができる[14]．\nスポーツ分野においては，ウェアラブルデバイスを用いて，アスリートのパフォーマン\nス向上やリスク管理が行われている[15]．デバイスによる生体データのモニタリングは，\nトレーニングの効率を最適化し，ケガの予防に役立つと同時に，競技中の健康状態を監視\nするための手段としても有効である．\nウェアラブルデバイスは，ユーザーの健康状態や行動に関する多くのデータを収集し，\nリアルタイムでの分析を可能にする．しかし，このようなデ",
            "健康状態や行動に関する多くのデータを収集し，\nリアルタイムでの分析を可能にする．しかし，このようなデバイスが収集するデータは非\n常にセンシティブであり，セキュリティやプライバシーに関する問題が懸念される．\nまず，ウェアラブルデバイスから得られるデータは，個人の健康情報や位置情報を含む\nことが多く，これらの情報が不正にアクセスされると，個人のプライバシーが侵害される\n可能性がある．特に，悪意のある攻撃者によってデータが盗まれると，個人情報が悪用\nされるリスクが高まる[16]．このような観点から，ウェアラブルデバイスの利用において\nは，セキュリティとプライバシーの保護が不可欠である．それでも，これらの技術は今後\nさらに進化し，健康管理，スポーツ，医療分野において重要な役割を担い，普及していく\nと考えられる．\n図1.4 は，北米におけるウェアラブル技術の市場規模拡大を予測したものである[17]．\n図1.5: 北米におけるウェアラブル技術の市場規模予測（単位：10 億米ドル）（[17] より引\n用）\n1.2\n研究目的\n1.1.1 項で述べたように，近年，熱中症による死者数は増加傾向にあり，近年",
            "用）\n1.2\n研究目的\n1.1.1 項で述べたように，近年，熱中症による死者数は増加傾向にあり，近年の死者数の\nうち高齢者の割合が80%を超えてきている．\nそこで本研究の目的は，細かい粒度で熱中症のリスクを評価するとともに，普及しつつ\nあるウェアラブル技術を活用して，一人暮らしなども増えている高齢者の安心と安全およ\n7\nび，労働者の健康と安全を守る仕組みの開発である．そのため，熱中症の発生する可能性\nのある作業現場において，スマートウォッチを用いて計測できる脈拍を始めとした生理指\n標などから，熱的快適性の推定手法や頸部冷却効果の検証，またリアルタイム推定システ\nムの開発を目標とする．\n1.3\n本論文の構成\n第1 章：本論文の研究背景，研究目的および論文の構成について述べる．\n第2 章：関連研究について述べる．\n第3 章：本研究のデータ収集について述べる．\n第4 章：解析結果を述べるとともに，その結果について考察を述べる．\n第5 章：自律型リアルタイム推定システムの開発について述べる．\n第6 章：本論文のまとめと今後の展望について述べる．\n8\n第2章\n関連研究\n2.1\n心拍変動指標に基づ",
            "6 章：本論文のまとめと今後の展望について述べる．\n8\n第2章\n関連研究\n2.1\n心拍変動指標に基づく生理的評価\n2.1.1\n心拍変動指標の健康および運動指導への応用\n心拍変動（HRV）は，従来から心血管系の健康指標として使用されてきたが，Singh ら\nは，モバイルヘルス（mHealth）技術の普及に伴い，心拍変動が健康状態の評価や運動ト\nレーニングの指導において重要な役割を果たすことを示している[18] ．この研究では，心\n拍変動がリスク層別化や運動プログラムの最適化に利用できることが述べられており，モ\nバイルデバイスを通じた日常的なフィードバックの可能性が強調されている．\n伊倉らは，心血管疾患患者において有酸素運動中にリアルタイムで心拍変動を解析する\n手法を提案している．この研究では，心拍変動を使用して換気閾値での運動強度を連続的\nかつ非侵襲的に測定することにより，より安全かつ効果的な運動戦略を提供できることが\n示されている[19]．この手法は，心拍変動のリアルタイム分析が運動中の健康管理に役立\nつことが明らかにされている．\n図2.1: 実験手順心拍変動は継続的に記録され，運動負",
            "健康管理に役立\nつことが明らかにされている．\n図2.1: 実験手順心拍変動は継続的に記録され，運動負荷は運動中の高周波（HF）成分に\n基づいて調整される（[19] より引用）\n9\n2.1.2\nウェアラブル端末を用いたストレス推定\n鈴木らの研究では，スマートウォッチによって取得された心拍数から導出される複数の\n評価指標を用いて，ストレス検出の精度が評価されている．心拍数は，利き手でない手に\n装着されたAndroid Wear OS 搭載端末から取得された．正規化されたサポートベクターマ\nシン（SVM）を用いた場合，検出精度は73.24%，適合率は77.57%，再現率は74.92%，特\n異率は72.72%という結果が得られた．\nまた，SDNN はリラックス状態において高く，ストレス負荷状態では低くなる傾向が示\nされており，RMSSD についても同様に，リラックス時には高く，ストレス負荷時には低\nい値を示す傾向が確認された[20]．\n図2.2: 実験参加者につけられたウェアラブル端末（[20] より引用）\n2.1.3\n気温の変化による心拍変動指標への影響\n熱的快適性は主観的な心理的感覚である",
            " より引用）\n2.1.3\n気温の変化による心拍変動指標への影響\n熱的快適性は主観的な心理的感覚であるため，人の生理的信号の変化をもとに熱的快適\n性を提供することは，非常に効果的であると考えられる．Nkurikiyeyezu らの研究によれ\nば，心拍変動は自律神経系のバランスおよびその機能を評価する指標となり，気温の変化\nが心拍変動に測定可能な変化をもたらすことが示されている[21]．例えば，図2.3 に示す\nように，Mean RR，VLF，サンプルエントロピーなどの指標は寒冷な環境で最も高く，暑\n熱環境では最も低い値を示すことが分かっている．\nまた，Mean RR，RMSSD，SDSD，pNN25，VLF，およびサンプルエントロピーの6 つ\nの心拍変動指標を用いた機械学習モデルを構築することで，人々の熱的快適性（暑さによ\nる不快感，寒さによる不快感，快適さ）を最大93.7%の精度で予測可能であることが明ら\nかとなった[21]．このことから，暑さによる不快感の度合いを推定できることで，熱中症\n10\nのリスクが高まっているかどうかを把握し，早期に適切な対策を講じることが可能である\nと考えら",
            "症\n10\nのリスクが高まっているかどうかを把握し，早期に適切な対策を講じることが可能である\nと考えられる．\n図2.3: 各環境における心拍変動指標の正規化された平均（[21] より引用）\n2.1.4\n自律神経機能の低下と熱中症のリスク\n一般的に，心拍変動は自律神経機能を評価する重要な指標として広く採用されている．\n自律神経系は交感神経と副交感神経から構成され，これらのバランスが心拍変動に反映さ\nれる[22]．高い心拍変動は副交感神経の優位を示し，ストレスが少なくリラックスした状\n態であることを意味する．一方，低い心拍変動は交感神経が優位で，ストレスや身体的負\n荷がかかっていることを示す．\n図2.4a は健康な青年男子の呼吸性心拍変動（RSA）と心拍数の関係を示し，薬物投与前\n後での変化を比較している．心拍数が副交感神経のみで制御されるとき，RSA のCCV 値\nは心拍数と直線的関係にある．\n図2.4b はMayer 波に関連した心拍変動と，動脈血圧の収縮期血圧におけるMayer 波の\n大きさ（CCV 値）の関係を示している．\n自律神経機能が低下すると，体温調節などの生理的な調整機能が劣",
            "きさ（CCV 値）の関係を示している．\n自律神経機能が低下すると，体温調節などの生理的な調整機能が劣化し，熱中症の発症\nリスクが高まることが示されている．Canini らの研究では，自律神経機能の低下が，スト\nレスに対する保護メカニズムの不全を引き起こし，熱中症に対する感受性を増加させる可\n能性が指摘されている[23]．\n11\n図2.4: (a) 健康な青年男子の呼吸性心拍変動（RSA）と心拍数の関係．(b) 心拍変動と，\n動脈血圧の収縮期血圧におけるMayer 波の大きさ（CCV 値）の関係（[22] より引用）\n2.2\nウェアラブルセンサ技術を用いた熱中症リスク推定\n2.2.1\nウェアラブルセンサによる深部体温の推定\n釜谷らは，ウェアラブルセンサとヒト熱モデルを用いて深部体温を推定する手法を提案\nしている．この研究では，二重ノードのヒト熱モデルを利用し，歩行活動中に0.07◦C の\n誤差で深部体温を推定することに成功している[24]．これにより，熱中症予防における深\n部体温の連続的なモニタリングが可能となり，特に高温環境下での熱ストレス管理に有効\nであることが示されている．\n時澤ら",
            "モニタリングが可能となり，特に高温環境下での熱ストレス管理に有効\nであることが示されている．\n時澤らは，熱ストレス条件下における運動中に体幹温度をリアルタイムでモニタリング\nするためのウェアラブルパッチ型センサシステムを提案している．この研究では，胸部か\nらの熱フラックスデータを利用し，体幹温度の予測精度が高いことが示されている[25]．\n予測された体幹温度は実測値とよく一致しており，このシステムは熱中症予防や高温環境\n下での健康管理に有効であることが確認されている．\nしかし，深部体温は熱中症と密接に関連しているものの，深部体温の予測自体が熱中症\nの予防に直接結びつくとは限らない．\n図2.5 が示すように，通常，発汗や血液の皮膚表面への移動を通じて体温を調整するが，\n高温環境下では熱放散が困難になり，体内に熱が蓄積される．この状態が進行すると体内\nの血液の流れが低下し，体に熱がたまり，深部体温が上昇する．この時点で既に「異常時」\nとなり，熱中症発症が近づき手遅れとなる可能性がある[26][27][28]．したがって，深部\n体温の上昇を検知する前に予防的なアラートを出すことが肝要である[",
            "[27][28]．したがって，深部\n体温の上昇を検知する前に予防的なアラートを出すことが肝要である[29]．具体的には，\n環境条件（気温や湿度）や個人の活動レベルに基づき，早期に頸部冷却や水分補給を促す\n予防策が効果的であると考えられる．\n12\n図2.5: 熱中症の起こり方（[28] より引用）\n2.2.2\n発汗と熱中症リスクの関係\nSim らの研究では，異なる熱環境下での人間の熱的快適性のモニタリングを目的とした\nウェアラブル発汗速度センサの使用が提案されている．このセンサは発汗量を測定感度の\n変化を10%未満で測定可能であった．「快適」，「やや暖かい」，「暖かい」，「暑い」の4 段階\nの温熱状態の範囲において，各温熱状態における発汗量の差は平均（32.06 ± 27.19）g/m2h\nであった．この機能により，身体の過剰な熱ストレスを迅速に検出し，熱中症リスクを軽\n減するための迅速な対応が可能である．発汗のパターンや発汗速度の変動をリアルタイム\nで把握することで，熱中症の予防や早期対応に役立つ可能性が示唆されている[30]．\nFan らの研究では，発汗がアクティブなスポーツ時の熱的",
            "応に役立つ可能性が示唆されている[30]．\nFan らの研究では，発汗がアクティブなスポーツ時の熱的快適感に与える影響に着目し\nている．特に，衣服内の水分抵抗と湿気の蓄積が発汗に直接関係し，熱的快適性に大きな\n影響を与えることが示されている．発汗は体内の余分な熱を放散する役割を持っており，\n衣服の熱特性（通気性，吸湿性）が十分でない場合，発汗による冷却効果が減少し，熱的\n快適性が損なわれるとされている．したがって，適切な衣服の選択により，発汗を促進\nし，熱中症のリスクを軽減することが重要であると結論づけている[31]．\n13\n図2.6: (a) 手首に装着する発汗率センサー．(b)3 つの異なる条件を用いた温度状態評価に\n使用されたアンケート．(c) 温度状態制御中に被験者1 から得られた湿度センサーによる\n容量の時間変化．(d–f)3 名の被験者における温度状態による発汗率（[30] より引用）\n藤井らの研究では，プロテアーゼ活性化受容体2（PAR2）の外因性活性化が，高齢者に\nおける皮膚血管拡張および発汗の低下を引き起こすことが示されている．この研究は，高\n齢男性を対象に運動による",
            "皮膚血管拡張および発汗の低下を引き起こすことが示されている．この研究は，高\n齢男性を対象に運動による熱ストレス時の発汗と血管反応を調査しており，特に高齢者で\nはPAR2 の活性化が発汗機能を抑制することが明らかとなった．この発見は，高齢者にお\nける自律神経機能の低下が，発汗による熱放散メカニズムに影響を与える可能性を示唆し\nている[32]．\nTan らの研究では，高齢者の発汗応答の低下が発汗腺のコリン作動性受容体の感受性の\n低下およびシグナル伝達の変化に起因することが指摘されている．これにより，高齢者は\n熱関連の障害に対して脆弱性が増し，発汗による体温調節が困難になることが報告されて\nいる．さらに，熱ストレス時に高齢者が熱的負荷に対してどのように対応するかに関する\n実践的な戦略も提案されている[33]．\nこのように，高齢者は加齢に伴う自律神経機能などの衰えにより，発汗機能の低下が顕\n著であることが報告されている．つまり，発汗センサによる熱中症予防対策は，若年層や\n十分な発汗が期待できる人々に対しては有効であるが，本研究の目的である高齢者も含め\nた熱中症予防において，発汗だけでは熱中症リ",
            "々に対しては有効であるが，本研究の目的である高齢者も含め\nた熱中症予防において，発汗だけでは熱中症リスクを十分に評価できない可能性がある．\n14\n2.3\n熱中症予防対策に関する研究\n2.3.1\n水冷服および空調服による熱中症予防\n水冷服や空調服は，熱中症の予防や熱ストレスの軽減に効果的であることが多くの研究\nで示されている．Son の研究では，水冷服や空調服を使用することで熱ストレスが軽減さ\nれ，運動能力の向上が期待できることが報告されている[34]．特に，皮膚の露出や衣服の\n通気性が重要な要素であり，適切な設計により熱中症のリスクを効果的に低減できること\nが示されている．\nLi らの研究では，空調服が高温環境下での熱ストレスを効果的に軽減することが明らか\nにされている[35]．この研究では，空調服が運動強度に応じた性能を発揮し，熱を効率的\nに放散できることが確認された．特に，高温環境で働く人々にとって，このような空調服\nが快適さと安全性を提供する新しい手段として期待されている．\nさらに，Wang らは，液体と空気を利用したハイブリッド冷却服が局所的な熱ストレス\nの軽減に効果的であるこ",
            "，Wang らは，液体と空気を利用したハイブリッド冷却服が局所的な熱ストレス\nの軽減に効果的であることを示している[36]．この研究では，コンベクションと熱伝導の\nメカニズムを組み合わせた冷却が，体表温度を効果的に下げることが確認されている．\nこれらの研究は，水冷服や空調服が熱中症予防および熱ストレス軽減に重要な役割を果\nたすことを示しており，今後の研究や実用化に向けた重要な基盤となっている．\nしかし，空調服や水冷服はにはいくつかのデメリットが存在する．Leyk によると，服\nの断熱性が原因で，汗の蒸発が妨げられ，体温を効果的に下げる蒸発冷却の作用が減少す\nることが指摘されている[37]．これは特に湿度の高い環境で顕著であり，体温調節が困難\nになり，結果として熱ストレスが増加する危険性がある．\nまた，装置が故障した場合には，冷却効果が失われるだけでなく，逆に断熱効果が体温\nを保持し，熱ストレスを悪化させるリスクがある．\nこのように，空調服や水冷服はその利便性に優れている一方で，使用環境や使用方法に\nよっては逆効果をもたらす可能性がある．特に，高温多湿な環境や長時間の使用では，こ\nれらの",
            "使用方法に\nよっては逆効果をもたらす可能性がある．特に，高温多湿な環境や長時間の使用では，こ\nれらのデメリットを十分に考慮し，適切な対策を講じる必要がある．\n図2.7: シリコンチューブ付き液空冷却衣服（[36] より引用）\n2.3.2\n水分補給による熱中症予防\n脱水症状は熱中症のリスク要因として重要な役割を果たしている．Garcia らの研究では，\n労作性熱中症の病態生理学において，脱水症がリスクを高めることが示されている[38]．\n特に，脱水により体温調節機能が低下し，熱中症の発症リスクが高まる可能性がある．\n15\n図2.8: 発汗量の実験値と潜熱損失量の総和の計算値（[40] より引用）\nまた，Costrini らによると，熱中症患者は熱疲労患者に比べて初期の脱水がより進行し\nており，血糖値が有意に低いことが確認されている[39]．さらに，熱中症患者は血清カリ\nウム濃度の低下も見られ，これが代謝反応の変化を引き起こしていることが示唆されて\nいる．\nGarcia らの研究では，脱水症による体温調節障害が熱中症の重症度を増すことが強調さ\nれており，運動時の適切な水分補給の重要性が示さ",
            "による体温調節障害が熱中症の重症度を増すことが強調さ\nれており，運動時の適切な水分補給の重要性が示されている．一方，Costrini らの研究で\nは，脱水による代謝的な影響が熱中症の進行を助長することが明らかにされている．し\nたがって，脱水症は熱中症の予防および治療において，最も重要な要因の一つであると言\nえる．\n2.3.3\n頸部冷却による熱中症予防\n千葉らの研究では，暑熱環境下における頸部冷却の生理的反応に関する実験が行われ，\nその結果が詳細に報告されている．実験では，温度32◦C ，湿度60%の条件で，8 名の健\n康な男性を対象にデスクワークを行わせ，ネッククーラーを使用した条件（Case 1）と，\n使用しない条件（Case 2）を比較した．\nまず，頸部皮膚温度は，ネッククーラーを装着したCase 1 では約30.8◦C に低下し，装\n着しなかったCase 2 では約34.7◦C であったことが確認された[40]．これにより，頸部冷\n却による皮膚温の顕著な低下が生じ，発汗量が減少する傾向が見られた．図2.8 が示すよ\nうに，発汗量の実験結果では，Case 1 では発汗量が少なく，発",
            "傾向が見られた．図2.8 が示すよ\nうに，発汗量の実験結果では，Case 1 では発汗量が少なく，発汗による潜熱損失量もCase\n2 と比較して少ないことが確認されている．これにより，局所冷却が身体の熱的負荷を軽\n減する効果が示唆される．\nさらに，血圧に関する測定では，頸部冷却を行ったCase 1 の方が，最高血圧が有意に高\nくなった．これは，頸部冷却によって血管拡張が抑制され，血管抵抗が増加したためであ\nると考えられる[40]．結果として，暑熱環境下における循環系の負担軽減や熱中症リスク\nの低減が期待される．\n16\n第3章\nデータ収集\n3.1\n熱的快適性モデル\nPMV（Predicted Mean Vote）モデルは，様々な温度条件下で長時間にわたる大規模な実\n験室実験に基づき，熱的快適性を予測するために開発された[41]．このモデルは，その公\n平性と精度が認められ，ISO 7730 やASHRAE 55 などの国際規格に採用されている[42]．\nPMV を算出する際には，周囲の空気温度，平均放射温度，気流速度，相対湿度，代謝率，\n衣服の断熱性といった6 つの要因を考慮する必要がある",
            "度，平均放射温度，気流速度，相対湿度，代謝率，\n衣服の断熱性といった6 つの要因を考慮する必要がある[41]．\nPMV による評価は，「寒い」，「涼しい」，「少し涼しい」，「普通」，「少し暖かい」，「暖か\nい」，「暑い」の7 段階に分類される．\n本研究では，通常PMV の値が2.5 を超えると「暑い(hot)」と分類されるが，その中で\nも3.5 を超えるものを図3.1 に示すように「とても暑い(very hot)」としてラベルの拡張を\n行った．\n図3.1: 拡張されたPMV の8 段階評価指標\n3.2\n実験に使用されたデバイス\n被験者には図3.2 に示すE4 リストバンドを装着させた．E4 リストバンドは，腕時計型\nのウェアラブルデバイスであり，皮膚電気活動（Electrodermal Activity, EDA）センサ，光\n電式容積脈波（Photoplethysmography, PPG）センサ，3 軸加速度計，光温度計など，多数\nのセンサを搭載している[43]．EDA は4Hz のサンプリングレートで皮膚の電気的特性の\n変動を捉え，発汗量の増加に伴い皮膚の電気伝導度も上昇することが",
            "ンプリングレートで皮膚の電気的特性の\n変動を捉え，発汗量の増加に伴い皮膚の電気伝導度も上昇することが知られている．\n特に，PPG センサは64Hz で容積脈波（Blood Volume Pulse, BVP）を計測し，これに基づ\nいて心拍間隔（Interbeat Interval, IBI）および心拍変動（Heart Rate Variability, HRV）を算\n出することが可能である．近年の研究では，E4 リストバンドが座位安静時や一定のペー\nスでの呼吸条件下において，心拍変動を高精度に記録できることが報告されている[44]．\nこのように，E4 リストバンドは，高品質なデータ収集を目的とした精度の高いセンサを\n備えている．\n17\n図3.3 に示すC´omodo gear i3 は，富士通ゼネラルが開発したウェアラブル冷却装置であ\nる[45]．このデバイスは，主に工場などの暑熱環境下での使用を目的としており，首に装\n着して皮膚表面を冷却することで体感温度を低下させる．軽量かつコードレス設計で，作\n業の妨げにならないように工夫されている．また，バッテリー駆動により，持続的に冷却\nが可",
            "ス設計で，作\n業の妨げにならないように工夫されている．また，バッテリー駆動により，持続的に冷却\nが可能であり，長時間の使用に適している．\n図3.2: Empatica E4 リストバンド（[43] より引用）\n図3.3: C´omodo gear i3（[45] より引用）\n18\n3.3\n熱的快適性予測のための特徴量とデータ前処理\n各実験終了後，図3.4 に示すようにに示すように，E4 リストバンドからスマートフォ\nンに同期された生体情報は，E4 コネクトというクラウドにCSV 形式でアップロードされ\nた．その後，PPG センサのノイズを除去したのち，52 個の特徴量を抽出した．\n本研究では，熱的快適性予測のための特徴量として，心拍変動指標の時間領域解析と周\n波数領域解析を選択した．また，心拍変動指標は全て300 秒の窓サイズのセグメント，30\n秒のシフトサイズで計算された．\n図3.4: 実験における生体情報の処理\n3.3.1\n時間領域解析\n時間領域の心拍変動指標は，心拍間の時間（心拍間隔）を元に算出されるものであり，計算\nも理解も容易である．具体的には，平均心拍間隔（Mean R-R",
            "隔）を元に算出されるものであり，計算\nも理解も容易である．具体的には，平均心拍間隔（Mean R-R interval），標準偏差（Standard\nDeviation of NN intervals, SDNN），および隣接する心拍間隔の差の二乗平均平方根（Root\nMean Square of Successive Differences, RMSSD）などが代表的な指標である．これらの指\n標は心拍間隔の変動を直接表しており，特にSDNN は全体的な変動の大きさを，RMSSD\nは短期的な変動の大きさを示す．時間領域解析はシンプルでありながら，交感神経と副交\n感神経の活動バランスを推測する上で有用である．\n本研究で使用した時間領域の心拍変動指標の一覧の一部を表3.1 に示す．\n3.3.2\n周波数領域解析\n周波数領域解析は，心拍間隔の変動を周波数成分に分解して解析する手法である．R-R\n間隔の時系列データに対して高速フーリエ変換（FFT），自己回帰（AR）モデリングによる\n19\nアプローチが広く採用されており[46]，低周波成分（Low Frequency, LF: 0.04～0.15",
            "チが広く採用されており[46]，低周波成分（Low Frequency, LF: 0.04～0.15 Hz）\nや高周波成分（High Frequency, HF: 0.15～0.40 Hz）を解析するものである．LF 成分は交\n感神経と副交感神経の両方に関連するとされ，HF 成分は主に副交感神経の活動に関連す\nると考えられている．また，LF/HF 比は自律神経のバランスを示す指標として用いられる\nことが多い．周波数領域解析により，時間領域では捉えきれない自律神経の周期的な活動\nをより詳細に分析することができる．\n本研究で使用した周波数領域の心拍変動指標の一覧の一部を表3.2 に示す．\n20\n表3.1: 選択した時間領域の特徴の説明\n時間領域の指標\n説明\nNUM IBIS\nNNI の合計値\nHRV MEAN NNI\n全NNI の平均値\nHRV MEDIAN NNI\n全NNI の中央値\nRANGE NNI\nNNI の最大値と最小値の差\nSDSD\n隣接する心拍間隔の差の標準偏差\nRMSSD\n隣接する心拍間隔の差の2 乗の平均値の平方根\nHRV NNI 50\n50 ミリ秒以上離れたNNI の数",
            "接する心拍間隔の差の2 乗の平均値の平方根\nHRV NNI 50\n50 ミリ秒以上離れたNNI の数\nHRV NNI 20\n20 ミリ秒以上離れたNNI の数\nHRV pNNI 50\n50 ミリ秒以上離れたNNI の割合\nHRV pNNI 20\n20 ミリ秒以上離れたNNI の割合\nSDNN\n各心拍間隔の標準偏差\nHRV SD1\nプロット散布図における縦軸方向の標準偏差\nHRV SD2\nプロット散布図における横軸方向の標準偏差\nHR MEAN\n平均心拍数（1 分間の心拍数で測定）\nHR MIN\n心拍数の最小値（1 分間の心拍数で測定）\nHR MAX\n心拍数の最大値（1 分間の心拍数で測定）\nHR STD\n心拍数の標準偏差\nHRV MEAN\nIBI の平均値\nHRV STD\nIBI の標準偏差\nHRV MIN\nIBI の最小値\nHRV MAX\nIBI の最大値\nHRV SKEWNESS\n全IBI の歪度\nHRV KURTOSIS\n全IBI の尖度\nHRV PEAKS\nIBI のピーク値\nHRV Energy\nIBI から算出されるエネルギー\nHRV CVSD\n連続した心拍間隔の差の変動係",
            "RV Energy\nIBI から算出されるエネルギー\nHRV CVSD\n連続した心拍間隔の差の変動係数\nHRV n Above Mean\n平均値以上のIBI の数\nHRV n Below Mean\n平均値以下のIBI の数\nHRV IQR\nIBI の25%から75%までの四分位範囲\nHRV Entropy\nIBI のエントロピー\nHRV RMS\n隣接するNNI の差の2 乗和の平均の平方根\n21\n表3.2: 選択した周波数領域の特徴の説明\n周波数領域の指標\n説明\nHRV VLF\n0.0033～0.04Hz の周波数帯のパワースペクトル\nHRV LF\n0.04～0.15Hz の周波数帯のパワースペクトル\nHRV HF\n0.15～0.4Hz の周波帯のパワースペクトル\nHRV LF HF RATIO\nLF（低周波）とHF（高周波）のパワーの比率\nTP\n周波数0～0.4Hz のパワースペクトルのトータルパワー\nHRV LFnu\n低周波数領域(LF) のHRV の正規化\nHRV HFnu\n高周波数領域(HF) のHRV 正規化\n3.4\n多様な環境での実験\n本研究では，3 つの異なる実験環境にお",
            "数領域(HF) のHRV 正規化\n3.4\n多様な環境での実験\n本研究では，3 つの異なる実験環境において段階的に実験を行った．これらの実験は，\n「実験室における実験」から「現場における実験」，さらに「熱中症経験者のいる現場での\n実験」へと進展し，各実験環境における熱的快適性の評価を行った．以下に，各実験環境\nにおける具体的な内容について詳述する．\n本研究で収集したデータは，川崎市環境局環境対策部　地域環境共創課および（株）富\n士通ゼネラルの立会いの下入手した．また，実験担当者は，臨床研究に携わる人のe ラー\nニングサイト「ICR 臨床研究入門」にて，「研究倫理と被験者保護」および「人を対象と\nする医学系研究に関する倫理指針」を履修している．また，本実験は，青山学院大学理工\n学部ライフサイエンス委員会の「人に係る研究」に関する審査・承認を受け実施され（承\n認番号H21-009-1），被験者は実験説明を受け，実験に対する同意書による同意をもって，\n実験に参加頂いている．\n3.4.1\n実験室における実験\n実験室内での実験では，温度や湿度といった環境因子を制御できる実験室を用い，熱的\n快適性に",
            "おける実験\n実験室内での実験では，温度や湿度といった環境因子を制御できる実験室を用い，熱的\n快適性に関する基礎データを収集した．実験条件は，読書，転写，ラジオ体操という3 つ\nの活動に基づき，主に高温環境に焦点を当てたさまざまな条件を設定した．例えば，ラジ\nオ体操では，高温状態（温度32◦C，湿度80%）および温暖状態（温度25◦C，湿度60%）\nの条件でデータを収集した．各条件は，図3.1 に示す温熱感覚の尺度「普通(neutral)」「少\nし暖かい(slightly warm)」「暖かい(warm)」「暑い(hot)」に従って調整された．\n各活動は，日常生活と関連付けて設定されたものである．例えば，読書やテレビ鑑賞は\n読書活動に，仕事におけるデスクワークや座学は転写活動に，工場や屋外での力作業はラ\nジオ体操活動にそれぞれ対応している．実験一例としてラジオ体操の様子を図3.5 に示す．\nまた，各実験条件の詳細を表3.3 に示す．\n22\n図3.5: 実験室における実験の様子（ラジオ体操）\n表3.3: データ収集条件\n実験番号\n活動\n温度\n湿度\n期間\n1\nラジオ体操\n32◦C\n80%\n1",
            "\n表3.3: データ収集条件\n実験番号\n活動\n温度\n湿度\n期間\n1\nラジオ体操\n32◦C\n80%\n10 分\n2\nラジオ体操\n25◦C\n60%\n10 分\n3\n読書\n25◦C\n60%\n15 分\n4\n読書\n32◦C\n80%\n15 分\n5\n読書\n27◦C\n60%\n15 分\n6\n読書\n32◦C\n80%\n15 分\n7\n転写\n32◦C\n80%\n15 分\n8\n転写\n27◦C\n60%\n15 分\n実験は午前と午後にそれぞれ1 日2 グループに対して実施し，1 回の実験でのデータ収\n集は最大3 名までとした．図3.6 に年齢と性別の分布を示す成人男女44 名を対象に，4 つ\nの温湿度環境および3 つの作業条件下で，E4 リストバンド[43] を装着させ，連続的な脈\n拍間隔を測定した．\n図3.7 は，データセットに含まれる4 つの温度状態を示しており，\n「warm」および「slightly\nwarm」における記録数が他の温度状態と比較して非常に多かった．\n23\n図3.6: 被験者の年齢と性別の分布\n図3.7: 実験室実験におけるPMV を用いた温熱感覚のデータセットの量\n3.4.2\n現場における実験\n3.4.",
            "実験室実験におけるPMV を用いた温熱感覚のデータセットの量\n3.4.2\n現場における実験\n3.4.1 項の結果は統制された環境で得られたものであり，そのまま実際の現場環境に適\n用するには限界があるため，実験室を離れた実運用下での分類精度の妥当性と実用性を評\n価する必要がある．作業現場では，実験室のように環境因子を厳密に制御することが困難\nであるが，より現実的な条件下でデータを取得することが可能である．作業現場での実験\n24\nでは，製造工場や建設現場など温熱環境が異なる8 つの作業現場を選定しデータを収集し\nた．実験一例として入江崎クリーンセンターにおける様子を図3.8 に示す．\nまた，各現場の詳細を表3.4 に示す．\n図3.8: 入江崎クリーンセンターにおける実験の様子（作業場点検）\n表3.4: 各実験場所の詳細\n実験場所\n作業内容\n平均温度\n平均湿度\n実験時間\n入江崎クリーンセンター\n屋内・外での作業場点検\n34.9◦C\n44.7%\n3 時間\n川崎市環境総合研究所　多摩川イベント\n屋外での誘導および受付\n36.9◦C\n47.5%\n6 時間\nセントラル硝子（株）\n屋内での粉溶解および",
            "外での誘導および受付\n36.9◦C\n47.5%\n6 時間\nセントラル硝子（株）\n屋内での粉溶解および充填作業\n29.4◦C\n64.2%\n3 時間\n（株）レゾナック\n屋内での清掃\n33.7◦C\n69.7%\n3 時間\n富士通ゼネラルサマーフェスティバル\n屋外での会場設営および誘導\n30.4◦C\n72.8%\n6 時間\n浮島処理センター資源化処理施設\n屋内での機器点検\n33.8◦C\n57.7%\n3 時間\n久地小学校給食調理場\n屋内での清掃\n33.1◦C\n56.6%\n3 時間\n入江崎クリーンセンター\n屋外での草刈りおよび清掃\n31.0◦C\n68.2%\n3 時間\n作業者には，日常的な作業を実施してもらい，その際に脈拍間隔と熱的快適性の評価を\n行った．実験はフィードバック手法の検討として頸部冷却ありの状態と頸部冷却なしの状\n態でそれぞれ同じ作業を実施した．図3.9 は，入江崎クリーンセンターにおける実験手順\nのタイムテーブルである．\n25\n図3.9: 入江崎クリーンセンターにおける実験手順のタイムテーブル例\n被験者は20 代から60 代までの幅広い年齢層から選定し，合計51 名（男性48 名，女性\n",
            "ブル例\n被験者は20 代から60 代までの幅広い年齢層から選定し，合計51 名（男性48 名，女性\n3 名）で構成された．図3.10 は，データセットに含まれる3 つの温度状態を示しており，\n「warm」における記録数が他の温度状態と比較して非常に多かった．\n図3.10: 現場実験における拡張したPMV を用いた温熱感覚のデータセットの量\n3.4.3\n熱中症経験者のいる現場での実験\n過去に熱中症経験者が発生した作業現場を対象に，さらに実用的な実験を実施した．こ\nの実験では，特にPMV の値が2.5 を超え，多くの状態が「very hot」や「hot」と評価され\nる厳しい温熱環境下での作業を対象とした．\n熱中症経験者のいる現場での実験では，野口工業（株）において３つの異なる作業に対\nしてデータを収集した．実験一例として，プレス加工を行っている様子を図3.11 に示す．\nまた，各作業の詳細を表3.5 に示す．\n26\n図3.11: プレス加工を行っている様子\n表3.5: 各作業の詳細\n作業内容\n平均温度\n平均湿度\n実験時間\nプレス加工\n32.6◦C\n63.4%\n6 時間\n溶接\n35.3◦C\n",
            "\n平均温度\n平均湿度\n実験時間\nプレス加工\n32.6◦C\n63.4%\n6 時間\n溶接\n35.3◦C\n55.2%\n6 時間\nフォークリフト\n34.7◦C\n59.1%\n6 時間\n作業者には，日常的な作業を実施してもらい，その際に脈拍間隔と熱的快適性の評価を\n行った．対象とした野口工業（株）の現場は，暑い環境での作業が常態化している．この\nため，頸部冷却を実施しないデータを取得することは安全性の観点から危険であると判断\nし，実験は頸部冷却を実施した状態でのみ実施した．図3.12 は，野口工業（株）におけ\nる実験手順のタイムテーブルである．\n図3.12: 野口工業（株）における実験手順のタイムテーブル\n被験者は30 代から50 代の男性5 名の被験者を対象に構成された．被験者のうち3 名は\n27\n過去に熱中症を経験しており，このことからも本実験が行われた環境が特に暑い環境であ\nることが示唆される．\nまた，収集したデータのラベルにおいては，図3.13 に示すように「very hot」と「hot」\nと評価されるデータのみであり，この環境の特性を反映したものとなっている．\n図3.13: 熱中症経験者",
            "と評価されるデータのみであり，この環境の特性を反映したものとなっている．\n図3.13: 熱中症経験者のいる現場実験における拡張したPMV を用いた温熱感覚のデータ\nセットの量\n28\n第4章\n熱的快適性の予測\n4.1\n実験室から得られたデータの検証\n4.1.1\n元データを活用した分類性能の検証\n表4.1 に，実験室におけるデータセット（サンプル数6623）を用いたExtra Tree，Random\nForest，およびGradient Boosting の評価結果を示す．\n機械学習において，汎化性能を評価するための方法として，グループ5 分割交差検証を\n用いた．5 分割交差検証とは，データセットを5 個に分割して，そのうち1 つをテストデー\nタに，残りを学習データとして評価を行うものである．最後に分割した回数で割ること\nで，平均を算出する．さらに，今回は訓練データとテストデータの両方に同じ被験者の\nデータが含まれることを避けている．\n表4.1: 実験室における分類モデルの比較\nModel\nRecall[%]\nPrecision[%]\nF1[%]\nExtra Tree\n47.24\n41.3",
            "Recall[%]\nPrecision[%]\nF1[%]\nExtra Tree\n47.24\n41.36\n39.56\nRandom Forest\n47.68\n41.74\n40.20\nGradient Boosting\n47.12\n41.64\n40.99\n学習機としてExtra Tree，Random Forest，Gradient Boosting で推定したうち，最もF1 値\nの精度が高かったGradient Boosting での各温熱感覚の評価指標を表4.2 に示す．\nまた，実験室において収集されたデータをもとに，Gradient Boosting を用いて熱的快適\n性を予測した結果の混同行列を図4.1 に示す．\n表4.2: 実験室におけるGradient Boosting による各温熱感覚の評価指標\nThermal Sensation\nRecall[%]\nPrecision[%]\nF1[%]\nneutral\n5.91\n18.52\n8.96\nSlightly warm\n17.29\n34.78\n23.10\nwarm\n79.60\n50.89\n62.09\nhot\n16.50\n42.80\n",
            "4.78\n23.10\nwarm\n79.60\n50.89\n62.09\nhot\n16.50\n42.80\n23.81\n29\n図4.1: 実験室におけるGradient Boosting による熱的快適性の予測（単位：%）\nこれらの結果から，図3.7 に示したデータセットのラベル分布における不均衡がモデル\nの性能に影響を与えていると考えられる．特に，温熱感覚の「warm」のサンプル数が他の\nラベルに比べて非常に多いことが，表4.2 で示されるように，このラベルに対するRecall や\nPrecision およびF1 値が他のラベルよりも高くなる原因と考えられる．一方で，「neutral」\nや「hot」のようにサンプル数が少ないラベルでは，これらの指標が低い結果となっている．\n図4.1 の混同行列を見ると，モデルは「warm」ラベルを他のラベルと比較して高い割合\nで予測しており，逆に「neutral」や「hot」ラベルのサンプルは「warm」に誤分類される\n傾向が確認できる．これは，ラベル数の不均衡がモデルの学習バイアスを引き起こし，多\n数派クラスに対して高い予測精度を示す一方，少数派クラスに対",
            "衡がモデルの学習バイアスを引き起こし，多\n数派クラスに対して高い予測精度を示す一方，少数派クラスに対しては性能が低下するこ\nとを示している．\n4.1.2\nオーバーサンプリング適用後の分類性能の検証\nラベル分布の不均衡を対処するために，データセットに含まれるラベル数の不均衡を解\n消するオーバーサンプリング手法の1 つであるBorderlineSMOTE を使用し4 種類のラベ\nル数を等しくした．\n表4.3 には，実験室において収集されたデータに対し，オーバーサンプリングを適用し\nたデータセット（サンプル数13336）を用いたExtra Tree，Random Forest，およびGradient\nBoosting の評価結果を示す．\n30\n表4.3: 実験室における分類モデル性能の比較（オーバーサンプリングの適用後）\nModel\nRecall[%]\nPrecision[%]\nF1[%]\nExtra Tree\n67.05\n65.20\n64.63\nRandom Forest\n66.02\n64.15\n63.90\nGradient Boosting\n57.32\n56.14\n56.05\n表4.3 ",
            "15\n63.90\nGradient Boosting\n57.32\n56.14\n56.05\n表4.3 より，オーバーサンプリング適用後，Recall，Precision，F1 値が全体的に向上し\nている．特に，Extra Tree ではF1 値が約25%上昇し，Random Forest やGradient Boosting\nにおいても同様の傾向が見られる．\n学習機としてExtra Tree，Random Forest，Gradient Boosting で推定したうち，最もF1 値\nの精度が高かったExtra Tree での各温熱感覚の評価指標を表4.4 に示す．\nまた，実験室においてオーバーサンプリングを実施したデータをもとに，Extra Tree を\n用いて熱的快適性を予測した結果の混同行列を図4.2 に示す．\n表4.4: 実験室におけるExtra Tree による各温熱感覚の評価指標（オーバーサンプリング\nの適用後）\nThermal Sensation\nRecall[%]\nPrecision[%]\nF1[%]\nneutral\n82.39\n69.72\n75.53\nSlightly ",
            "ision[%]\nF1[%]\nneutral\n82.39\n69.72\n75.53\nSlightly warm\n67.13\n61.59\n64.24\nwarm\n27.89\n55.29\n37.08\nhot\n90.79\n74.19\n81.66\n31\n図4.2: 実験室におけるExtra Tree による熱的快適性の予測（オーバーサンプリングの適\n用後，単位：%）\n表4.4 をオーバーサンプリング適用前（表4.2）と比較すると，F1 値に以下のような変\n化が見られた．\nまず，「neutral」クラスにおいては，適用前のF1 値が8.96%であったのに対し，適用後\nは75.53%へと大幅に改善している．同様に，「slightly warm」クラスのF1 値も，適用前\nの23.10%から64.24%へと大きく向上した．また，「hot」クラスに関しても，適用前のF1\n値23.81%から適用後は81.66%へと著しい改善が確認された．\n一方，「warm」クラスに関しては，適用前のF1 値62.09%から適用後は37.08%へと減少\nしている．これは，少数派クラスである他の温熱感覚を区別する性能が向上する",
            "用後は37.08%へと減少\nしている．これは，少数派クラスである他の温熱感覚を区別する性能が向上する一方で，\n多数派クラスである「warm」の優位性が相対的に低下した結果と考えられる．\nこのことから，オーバーサンプリングの適用により，少数派クラス（neutral, slightly warm,\nhot）の予測性能が大幅に向上し，データセット全体のクラス間バランスが改善されたこ\nとが示された．\n図4.2 の混同行列から，「hot」および「neutral」のクラスにおいては，真のラベルと予測\nラベルが一致する割合がそれぞれ90.79%および82.39%と高く，極端な温熱状態の分類精\n度が優れていることが確認された．特に，熱中症の予防に最も重要である「hot」の分類\n精度が90.79%と非常に高い点は，本研究で構築したモデルが熱的危険状態を適切に検出\nできる可能性を示している．一方，「warm」と「slightly warm」のクラスでは，誤分類の\n割合が相対的に高く，特に「warm」の30.50%が「slightly warm」と混同されるなど，中\n間的な温熱感覚の区別が困難であることが示",
            "50%が「slightly warm」と混同されるなど，中\n間的な温熱感覚の区別が困難であることが示唆された．\n32\n4.2\n現場から得られたデータの検証\n4.2.1\n元データを活用した分類性能の検証\n表4.5 に，現場におけるデータセット（サンプル数3171）を用いたExtra Tree，Random\nForest，およびGradient Boosting の評価結果を示す．\n表4.5: 現場における分類モデルの比較\nModel\nRecall[%]\nPrecision[%]\nF1[%]\nExtra Tree\n47.59\n39.01\n42.72\nRandom Forest\n50.65\n40.46\n44.47\nGradient Boosting\n39.55\n39.72\n39.63\n学習機としてExtra Tree，Random Forest，Gradient Boosting で推定したうち，最もF1 値\nの精度が高かったRandom Forest での各温熱感覚の評価指標を表4.6 に示す．\nまた，現場において収集されたデータをもとに，Random Forest を用いて熱的快適性を\n",
            "す．\nまた，現場において収集されたデータをもとに，Random Forest を用いて熱的快適性を\n予測した結果の混同行列を図4.3 に示す．\n表4.6: 現場におけるRandom Forest による各温熱感覚の評価指標\nThermal Sensation\nRecall[%]\nPrecision[%]\nF1[%]\nwarm\n79.91\n60.67\n68.97\nhot\n0.47\n0.96\n0.63\nvery hot\n6.13\n12.28\n8.17\n図4.3: 現場におけるRandom Forest による熱的快適性の予測（単位：%）\n33\nこれらの結果から，図3.10 に示したデータセットのラベル分布における不均衡がモデ\nルの性能に影響を与えていると考えられる．4.1.1 項と同様に，温熱感覚の「warm」のサ\nンプル数が他のラベルに比べて非常に多いことが，表4.6 で示されるように，このラベル\nに対するRecall やPrecision およびF1 値が他のラベルよりも高くなる原因と考えられる．\n一方で，「hot」や「very hot」のようにサンプル数が少ないラベルでは，これらの指",
            "えられる．\n一方で，「hot」や「very hot」のようにサンプル数が少ないラベルでは，これらの指標が\n低い結果となっている．\nまた，図4.3 の混同行列を見ると，モデルは「warm」ラベルを他のラベルと比較して高\nい割合で予測しており，逆に「hot」や「very hot」ラベルのサンプルは「warm」に誤分類\nされる傾向が確認できる．\n4.2.2\nオーバーサンプリング適用後の分類性能の検証\n表4.7 には，現場において収集されたデータに対し，オーバーサンプリングを適用した\nデータセット（サンプル数5838）を用いたExtra Tree，Random Forest，およびGradient\nBoosting の評価結果を示す．\n表4.7: 現場における分類モデル性能の比較（オーバーサンプリングの適用後）\nModel\nRecall[%]\nPrecision[%]\nF1[%]\nExtra Tree\n68.60\n68.96\n67.87\nRandom Forest\n67.39\n67.70\n66.93\nGradient Boosting\n60.95\n61.58\n60.91\n表4.7 より，オーバ",
            "93\nGradient Boosting\n60.95\n61.58\n60.91\n表4.7 より，オーバーサンプリング適用後，Recall，Precision，F1 値が全体的に向上し\nている．特に，Extra Tree ではF1 値が約25%上昇し，Random Forest やGradient Boosting\nにおいても同様の傾向が見られる．\n学習機としてExtra Tree，Random Forest，Gradient Boosting で推定したうち，最もF1 値\nの精度が高かったExtra Tree での各温熱感覚の評価指標を表4.8 に示す．\nまた，現場においてオーバーサンプリングを実施したデータをもとに，Extra Tree を用\nいて熱的快適性を予測した結果の混同行列を図4.4 に示す．\n表4.8: 現場におけるExtra Tree による各温熱感覚の評価指標（オーバーサンプリングの\n適用後）\nThermal Sensation\nRecall[%]\nPrecision[%]\nF1[%]\nwarm\n48.46\n68.63\n56.81\nhot\n76.62\n74.33\n75.4",
            "\nF1[%]\nwarm\n48.46\n68.63\n56.81\nhot\n76.62\n74.33\n75.46\nvery hot\n80.73\n63.91\n71.34\n34\n図4.4: 現場におけるExtra Tree による熱的快適性の予測（オーバーサンプリングの適用\n後，単位：%）\n表4.8 をオーバーサンプリング適用前（表4.6）と比較すると，F1 値に以下のような変\n化が見られた．\nまず，「hot」クラスにおいては，適用前のF1 値が0.63%であったのに対し，適用後は\n75.46%へと大幅に改善している．同様に，「very hot」クラスのF1 値も，適用前の8.17%\nから71.34%へと大きく向上した．\n一方，「warm」クラスに関しては，適用前のF1 値68.97%から適用後は56.81%へと減少\nしている．これは，少数派クラスである他の温熱感覚を区別する性能が向上する一方で，\n多数派クラスである「warm」の優位性が相対的に低下した結果と考えられる．\nこのことから，オーバーサンプリングの適用により，少数派クラス（hot, very hot）の\n予測性能が大幅に向上し，データセッ",
            "リングの適用により，少数派クラス（hot, very hot）の\n予測性能が大幅に向上し，データセット全体のクラス間バランスが改善されたことが示さ\nれた．\n図4.4 の混同行列から，「very hot」および「hot」のクラスにおいては，真のラベルと予\n測ラベルが一致する割合がそれぞれ80.73%および76.62%と高く，極端な温熱状態の分類\n精度が優れていることが確認された．一方，「warm」の32.94%が「very hot」として分類\nされるなど，中間的な温熱感覚における誤分類が目立つ結果となった．現場では環境因子\nの統制が難しいことにより，実験室と比較してデータのばらつきが大きくなり，特に中間\n的な温熱状態（「warm」）の分類に影響を及ぼしている可能性が考えられる．それにもか\nかわらず，「very hot」および「hot」の分類精度が高い点は，熱中症のリスクが高い状態\nを適切に検出できる可能性を示しており，本モデルの実用性を支持する結果といえる．\n現場実験で収集したデータのうち，頚部冷却を行わない条件下で得られたデータに対し\nてオーバーサンプリングを適用し，これをExtra ",
            "，頚部冷却を行わない条件下で得られたデータに対し\nてオーバーサンプリングを適用し，これをExtra Tree モデルの学習に使用した．その結果，\n頚部冷却を実施した条件下における熱的快適性を予測した結果を図4.5 に示す．\n35\n混同行列は図4.5 に示すように全体的に右寄りの傾向を示した．具体的には，本来「very\nhot」や「hot」に分類されるデータが，機械学習を用いて「warm」と分類される割合が増\n加している．この右寄りの傾向は，頚部冷却により生体反応の熱的リスクが低下した可能\n性を示している．\nまた，頚部冷却を行わないデータで学習したモデルは，その条件下で高い分類精度を示\nしていることから，今回の混同行列に示される右寄りの分類結果の信頼性は高いと考えら\nれる．すなわち，頚部冷却により被験者の生体反応が「very hot」や「hot」から「warm」\nへと軽減される傾向が明確に示されており，熱中症リスクの低減に寄与する可能性が強く\n示唆される．\n図4.5: 現場における頚部冷却ありの熱的快適性の予測（単位：%）\n4.3\n熱中症経験者のいる現場から得られたデータの検証\n現場実験",
            "ありの熱的快適性の予測（単位：%）\n4.3\n熱中症経験者のいる現場から得られたデータの検証\n現場実験で収集したデータのうち，頚部冷却を行わない条件下で得られたデータと実験\n室で収集したデータに対してオーバーサンプリングを適用し，これをExtra Tree モデルの\n学習に使用した．その結果，熱中症経験者のいる現場実験において収集された頚部冷却を\n実施した条件下における熱的快適性を予測した結果を図4.6 に示す．\n混同行列は全体的に右寄りの傾向を示しており，具体的には，真値が「very hot」や「hot」\nであるデータの一部が「warm」や「slightly warm」と予測される割合が増加している．こ\nの右寄りの傾向は，頸部冷却によって被験者の生理的負担が軽減し，熱中症リスクが低下\nした可能性を示唆している．\n一方で，真値が「hot」であるにもかかわらず「very hot」と予測されるケースも一部観\n察された．この結果は，モデルが頸部冷却の影響を十分に反映できていないことや，個体\n差やデータのばらつきが影響している可能性が考えられる．\n36\nまた，頸部冷却が十分に効果を発揮しない状況",
            "データのばらつきが影響している可能性が考えられる．\n36\nまた，頸部冷却が十分に効果を発揮しない状況や外部環境の要因も誤分類の原因として\n挙げられる．\nそれにもかかわらず，今回の結果は頸部冷却が「very hot」や「hot」といった極端な熱\n的状態を軽減し，「warm」や「slightly warm」へと熱的快適性を改善する傾向を示してお\nり，熱中症リスクの低減に寄与する可能性を示唆するものといえる．\n図4.6: 熱中症経験者のいる現場における熱的快適性の予測（単位：%）\nまた，データセットを熱中症経験者と非経験者に分け，それぞれ評価に用いた混同行列\nを図4.7 および図4.8 に示す．混同行列を見ると，全体的な分類の傾向として，熱中症経\n験者においては，真値が「very hot」や「hot」であるデータが「warm」や「slightly warm」，\nさらには「neutral」へと右側に分類される割合が一定数確認された．一方，非経験者の場\n合，「very hot」や「hot」と分類される割合が経験者より高く，「warm」への移動が特に顕\n著であった．しかし，それより右側である「sl",
            "れる割合が経験者より高く，「warm」への移動が特に顕\n著であった．しかし，それより右側である「slightly warm」や「neutral」への移動は少な\nく，右寄りの分類傾向は限定的であった．\n具体的には，図4.7（熱中症経験者）においては，真値が「very hot」の場合に「slightly\nwarm」への分類割合が23.10%，「neutral」への分類割合が4.84%と，非経験者（図4.8）に\nおける「slightly warm」への分類割合が9.02%，「neutral」への分類割合が1.28%と比べ，\n高い結果が得られた．\nまた，真値が「hot」の場合も，経験者では「slightly warm」や「neutral」への分類が見\nられたが，非経験者では「warm」への分類が集中していた．\nこれらの結果から，頚部冷却による全体的な右寄りの分類傾向は熱中症経験者のほうが\n強く示されていることが分かる．これは，熱中症経験者が過去の経験により生理的適応が\n異なるため，頚部冷却の効果がより顕著に現れる可能性を示唆している．\nまた，非経験者の場合は「warm」への分類が集中しており，",
            "がより顕著に現れる可能性を示唆している．\nまた，非経験者の場合は「warm」への分類が集中しており，冷却効果は一定程度確認で\nきるものの，分類が「slightly warm」や「neutral」に至る割合は低いことが示された．\n37\n以上の結果より，頚部冷却は特に熱中症経験者に対して顕著な効果を発揮し，生体反応\nの熱的負荷を低減させる可能性が高いことが示唆される．\n図4.7: 熱中症経験者における熱的快適性の予測（単位：%）\n図4.8: 熱中症非経験者における熱的快適性の予測（単位：%）\n38\n第5章\n自律型リアルタイム推定システムの検討\n本章では，スマートウォッチを用いた自律型リアルタイム推定システムの開発を行う．\nこのシステムは，取得したデータをクラウドサーバに送信し，クラウド側で推定を行った\n結果を受信する方式ではなく，デバイス単体で完結するリアルタイムなデータ処理および\nフィードバックを実現するものである．現場においては，インターネット環境が整ってい\nない場合が多く，クラウドサーバを利用したデータ処理が困難であるという課題が存在\nする．\nまた，Empatica 社製E4 リスト",
            "バを利用したデータ処理が困難であるという課題が存在\nする．\nまた，Empatica 社製E4 リストバンドは，スマートフォンを携帯しながら作業を行う必\n要があるが，携帯電話の持ち運びが難しい環境や作業の妨げとなる状況が想定される．こ\nれらの課題を解決するために，スマートウォッチを用いた自律型システムの構築は現場実\n用性の向上に寄与すると考えられる．特に，リアルタイムなフィードバックが可能となる\nことで，使用者が即時に対応を取ることができ，安全性や作業効率の向上が期待される．\n5.1\nE4 リストバンドとスマートウォッチから得られるデータの比較\nEmpatica E4 リストバンドとスマートウォッチの心拍間隔データを比較することは，推\n定精度を確保する上で重要である．特に，スマートウォッチから取得できる心拍間隔の情\n報を，Empatica E4 リストバンドから得られる心拍間隔データに可能な限り近づけること\nが必要不可欠である．これは，両デバイスから得られるデータが近づけば，心拍間隔に関\n連した特徴量として用いる推定モデルの性能を維持し，正確なリアルタイム推定を可能に\nするためである．\n",
            "連した特徴量として用いる推定モデルの性能を維持し，正確なリアルタイム推定を可能に\nするためである．\n5.1.1\n使用するスマートウォッチ\n推定をするために使用したスマートウォッチは，図5.1 に示すPolar 社製の「M600」\n（Wear\nOS by Google）である[47]．このスマートウォッチは，フィットネスおよびスポーツ用途\nを主目的として設計されており，音楽再生，健康管理，ライフスタイルの追跡，コミュニ\nティ機能など，多様なニーズに対応可能な機能を有する．搭載センサは，心拍センサ，加\n速度センサ，周辺光センサ，ジャイロスコープ，バイブレーションモータ，およびマイク\nで構成されている．特に心拍センサには光学式心拍測定技術が採用されており，精度の高\nい測定が可能である．\nPolar M600 スマートウォッチでは，心拍に関連したデータを取得することが可能であ\nり，これをもとに心拍間隔を算出することで，Empatica E4 リストバンドを用いた際に推\n定された指標と同等のデータを得ることができる．\n39\n図5.1: Polar 社製M600 Wear OS by Google",
            "を得ることができる．\n39\n図5.1: Polar 社製M600 Wear OS by Google\n5.1.2\n使用するデータ\n本比較においては，平均温度約28◦C，平均湿度約60%の室内環境で1 時間タイピングを\n行った際のデータを用いた．Empatica E4 リストバンドにより取得された心拍間隔（RRI）\nと，Polar M600 スマートウォッチから取得された心拍情報をもとに計算された心拍間隔\nの分布を図5.2 および図5.3 に示す．E4 リストバンドのデータ（図5.2）は，平均が約800\nms 付近で正規分布に近い形状を示しており，全体的に分布が滑らかである．一方，Polar\nM600 のデータ（図5.3）は，800 ms 付近ではE4 リストバンドと同様にピークが見られる\nものの，1000 ms から1500 ms 付近にかけてもう一つのピークが観測されており，心拍間\n隔の分布に明らかな特徴の違いがある．特に，1500 ms 付近の突出は異常値が含まれてい\nる可能性を示唆している．\nまた，それぞれの心拍情報に基づき6 つの特徴量を算出し，これを用いて熱的快適性を\n予測し",
            "している．\nまた，それぞれの心拍情報に基づき6 つの特徴量を算出し，これを用いて熱的快適性を\n予測した結果を図5.4 および図5.5 に示す．\n図5.2: E4 リストバンドによる心拍間隔の\n分布\n図5.3: Polar M600 スマートウォッチによる\n心拍間隔の分布\n40\n図5.4: E4 リストバンドによるデータに基\nづく推定結果\n図5.5: Polar M600 スマートウォッチによる\nデータに基づく推定結果\n5.1.3\nフィルターの効果検証\n心拍変動指標を用いた解析においては，データの正確性を確保するために異常値を適切\nに除去するフィルタリング処理が不可欠である．本検証では，2 種類のフィルタリング手\n法を用いて効果を検証した．\nまず，1 つ目の手法として心拍間隔の値が250 ms 以上1200 ms 以下の範囲に収まるデー\nタのみを選別する．この範囲は，通常の人間の心拍数（約50～240 拍/分）に対応してお\nり，生理学的に異常とされるデータを除外する基準として用いられる．具体的には，250\nms 未満の心拍間隔は頻脈や測定誤差を示す可能性があり，1200 ms を超える心",
            "体的には，250\nms 未満の心拍間隔は頻脈や測定誤差を示す可能性があり，1200 ms を超える心拍間隔は\n徐脈やノイズによる異常を含む可能性がある．この基準を適用することで，測定データの\n妥当性を担保することができる．\n次に，2 つ目の手法として心拍間隔データの分布特性に基づき，平均値±3σ の範囲内に\n収まるデータのみを選別する．ここで，σ は標準偏差を表し，データ分布の広がりを示す\n指標である．心拍間隔データが正規分布に近いと仮定した場合，この範囲には約99.7%の\nデータが収まるため，平均値から3σ を超えるデータは測定誤差や異常値である可能性が\n高い．これを除外することで，データの品質向上を図ることができる．\n以上の2 手法は，異なる基準に基づいてデータをフィルタリングするものである．統計\n的基準に基づく手法は，データ分布の特性を活用して異常値を排除することを目的として\nおり，一方で生理学的基準に基づく手法は，心拍数に基づいて異常なデータを排除するこ\nとを目的としている．これらの2 手法を併せて適用することでフィルタリングを行い，得\nられたデータをもとにその効果を検証する．",
            "らの2 手法を併せて適用することでフィルタリングを行い，得\nられたデータをもとにその効果を検証する．\n図5.6 は，フィルタリング後のPolar M600 スマートウォッチによる心拍間隔の分布を示\nしている．\nまた，図5.7 は，フィルタリング後のPolar M600 スマートウォッチのデータを用いて推\n定された熱的快適性の分布を示している．\n図5.6 では，フィルタリングを適用した結果，Polar M600 スマートウォッチの心拍間隔\nの分布における1500 ms 付近の突出が排除され，800 ms 付近を中心とした分布形状がE4\nリストバンドのデータ（図5.2）に近づいていることが確認できる．このことは，統計的\n41\nおよび生理学的基準に基づくフィルタリング手法が，データ分布の補正に有効であったこ\nとを示している．\nさらに，図5.7 では，フィルタリング後のPolar M600 スマートウォッチのデータを用い\nた推定結果が，「warm」のみを示すE4 リストバンドの推定結果（図5.4）により近づいて\nいることが示された．これにより，フィルタリングを施すことで心拍間隔分布のみならず\n",
            "）により近づいて\nいることが示された．これにより，フィルタリングを施すことで心拍間隔分布のみならず\n熱的快適性の推定結果においても，E4 リストバンドと一貫性のある結果が得られること\nが確認された．\nこれらの結果は，フィルタリング手法の適用によって，Polar M600 スマートウォッチの\nデータのばらつきや異常値を効果的に補正し，E4 リストバンドとのデータ一致性を向上\nさせることが可能であることを示している．\n図5.6: フィルタリング後のPolar M600 スマートウォッチによる心拍間隔の分布\n図5.7: フィルタリング後のPolar M600 スマートウォッチによるデータに基づく推定結果\n42\n5.2\nPolar M600 スマートウォッチでの推定\n5.2.1\nPolar M600 スマートウォッチでの推定に用いる特徴量\nPolar M600 スマートウォッチを用いたリアルタイム推定に使用する特徴として，6 つを\n選定した．6 つの特徴量は，4.2 節で使用したExtra Tree を用いた推定結果際の特徴量の\nうち，5 分割交差検証における5 通りの重要度で1 度でも上位5",
            "ee を用いた推定結果際の特徴量の\nうち，5 分割交差検証における5 通りの重要度で1 度でも上位5 つに含まれていたもので\nあった．表5.1 に，選定された特徴量6 つと5 分割交差検証における重要度の上位5 つに\n出現した回数を示す．\nまた，図5.8 に，5 分割交差検証における1 つの分割結果の特徴量重要度を示す．\n表5.1: 各作業の詳細\n特徴量\n出現回数\nHRV MEDIAN NNI\n5 回\nHRV MEAN hr\n5 回\nHRV PCT 5\n5 回\nHRV STD HR\n5 回\nHRV MEAN\n3 回\nHRV MEAN NNI\n2 回\n43\n図5.8: 5 分割交差検証における特徴量重要度（分割1 の結果）\n5.2.2\n6 つの特徴量のみを使用した場合の推定精度\n特徴量を選定した6 つを使用し，現場実験において収集された頚部冷却なしのデータに\n基づく機械学習をした熱的快適性予測の結果を図5.9 に示す．まず，真値が「very hot」の\n場合，再現率は56.37%に留まっており，全体の約30.94%が「warm」に誤分類されてい\nる．この結果は，「very hot」と「w",
            "おり，全体の約30.94%が「warm」に誤分類されてい\nる．この結果は，「very hot」と「warm」が特徴量の削減により識別が困難になったこと\nを示している．一方で，「hot」との誤分類（12.69%）は相対的に少なく，特定の中間状態\nにおける誤分類が抑えられている可能性が考えられる．\n次に，真値が「hot」の場合，再現率は59.87%であり，特徴量を52個使用した場合（76.62%）\nと比較すると大幅な精度低下が確認できる．\nまた，「very hot」（19.53%）および「warm」（20.61%）への誤分類が均等に発生してお\nり，「hot」を特徴付ける要素が十分に抽出されていないことが示唆される．\nさらに，真値が「warm」の場合，再現率は55.81%であり，30.01%が「very hot」，14.18%\nが「hot」に誤分類されている．この結果から，「warm」は他の状態と比較して最も広範囲\nな誤分類を受けており，6 つの特徴量では「warm」の特性を十分に表現できていない可能\n性が高い．\n全体として，特徴量を6 つに限定した場合には，分類性能が全体的に低下し，特に「",
            "ない可能\n性が高い．\n全体として，特徴量を6 つに限定した場合には，分類性能が全体的に低下し，特に「very\nhot」と「warm」の識別が困難であることが示された．一方で，リアルタイム処理を想定\nしたモデル軽量化の観点からは，許容可能な範囲での性能維持が確認されたといえる．こ\n44\nの結果は，推定モデルにおける特徴量選択の重要性を示唆しており，精度と効率のバラン\nスを考慮した最適な特徴量数の選定が求められる．\n図5.9: 6 つの特徴量を使用した現場における熱的快適性の予測（単位：%）\n5.2.3\nリアルタイム推定システムと画面出力\n分類モデルの構築には，ニュージーランドのワイカト大学により開発された，Java 言語を\n基盤としたオープンソースのデータマイニングツールであるWEKA（Waikato Environment\nfor Knowledge Analysis）[48] を使用した．WEKA は，無料で利用可能なソフトウェアで\nあり，各種の機械学習アルゴリズムやデータ前処理機能を備え，データ分析やモデル構築\nを効率的に行うための環境を提供する．\n本開発では，WEKA を用いてP",
            "備え，データ分析やモデル構築\nを効率的に行うための環境を提供する．\n本開発では，WEKA を用いてPolar M600 スマートウォッチ内でリアルタイムに熱的快\n適性を推定するシステムを構築した．推定はその時点での結果に加え，直前の4 つの推定\n結果を用いた多数決によって行われ，これにより安定した推定結果を得ることを目的と\nした．\n推定された熱的快適性に応じて，Polar M600 スマートウォッチの画面に適切な画像を表\n示し，作業者が現在の温熱状態を直感的に把握できるようにする．具体的には，熱的快適\n性が「neutral」と推定された場合は通常の状態を示す画像が表示され，作業者に特別な注\n意を促す必要がないことを示す．一方で，「slightly warm」と推定された場合には注意が\n必要な状態を表す画像が表示され，作業者に対して周囲の環境に意識を向けるよう促す．\nさらに，「warm」と推定された場合には警戒が必要であることを伝える画像が表示され，\n作業者に対してさらなる注意を喚起する．\nこれが「hot」と推定された場合には，厳重な警戒が求められる状態であることを示す\n画像が表示され，",
            "\nこれが「hot」と推定された場合には，厳重な警戒が求められる状態であることを示す\n画像が表示され，作業者に対して速やかな対応を促す．最も危険な状態である「very hot」\n45\nと推定された場合には，危険を知らせる画像が表示されるとともに，Polar M600 スマー\nトウォッチが振動して作業者に強い注意を喚起する．\n図5.10 に，Polar M600 スマートウォッチの画面に出力を示す．\n図5.10: 推定結果に対応する画像の種類\n46\n第6章\n結論\n6.1\nまとめ\n本研究では，熱中症リスクを評価するために，実験室環境および実運用環境における熱\n的快適性の推定モデルを構築し評価した．結果として，データ収集環境や頸部冷却の有無\nによる影響を詳細に検討し，モデルの有効性と課題を明らかにした．\n実験室環境では温度や湿度を制御し，データを収集し分析した結果，「hot」と「neutral」\nの分類精度が高く，特に「hot」の分類精度の高さは熱中症リスク検出の信頼性を示した．\n一方，現場環境では日常的作業を行う被験者からデータを収集し，頸部冷却の有無を比\n較した．頸部冷却を実施しない場合，",
            "では日常的作業を行う被験者からデータを収集し，頸部冷却の有無を比\n較した．頸部冷却を実施しない場合，「very hot」と「hot」の分類精度は比較的良好であっ\nたが，「warm」クラスの分類精度は低下し，データのばらつきが影響している可能性が示\n唆された．頸部冷却を実施した場合，「very hot」や「hot」の状態が「warm」や「slightly\nwarm」と分類される傾向が見られ，頸部冷却が熱的快適性の向上と熱中症リスク軽減に\n寄与することが確認された．\nさらに，過去に熱中症経験者が発生した現場においてデータを収集し分析した結果にお\nいても，頸部冷却により被験者の生理的負担が軽減されることが確認された．特に，熱中\n症経験者は非経験者に比べ，頸部冷却による熱中症リスク低減効果がより顕著であった．\n一方，個体差や外部要因により頸部冷却の効果が発揮されない状況が一部観察された．\nさらに，自律型リアルタイム推定システムの開発を行い，特徴量を6 つに削減したモデ\nルをPolar M600 スマートウォッチに搭載して実装した．このシステムではインターネッ\nト接続を必要とせず，推定された温熱",
            "スマートウォッチに搭載して実装した．このシステムではインターネッ\nト接続を必要とせず，推定された温熱状態をデバイス画面に表示し，最も危険な状態にな\nると振動で警告を発する機能を備えている．推定精度は特徴量52 個を使用したモデルに\n劣るものの，検出精度は他の温熱状態と比べ高い結果を示した．\nこれら成果は，熱中症予防技術の基盤を提供し，労働環境や高齢者支援の改善に寄与す\nるものである．\n6.2\n今後の展望\n今後の展望として，Polar M600 スマートウォッチで推定された温熱快適性に基づき，頸\n部冷却を自動的に実施するなどのフィードバック手法を検討する．\nまた，リアルタイム推定の精度向上を目指し，モデルの軽量化と使用する特徴量の増加\nに取り組む．さらに，Polar M600 スマートウォッチ単体での振動フィードバックのタイ\nミングや手法を改善し，より効果的なアラートシステムの構築を目指す．\n47\n謝辞\n本研究はセコム科学技術振興財団研究助成金の支援を受けて実施した．本研究を進め\nるにあたり，御指導を賜りました青山学院大学理工学部情報テクノロジー学科Guillaume\nLopez 教授に",
            "り，御指導を賜りました青山学院大学理工学部情報テクノロジー学科Guillaume\nLopez 教授に心より感謝申し上げます．また，研究を進めるにあたり，多大なるご協力を\nいただきました株式会社富士通ゼネラルの皆様に深く感謝申し上げます．さらに，3 年間\nにわたり実験を支えてくださった大熊研究補佐員に厚く御礼申し上げます．加えて，実験\nをともに実施してくださった佐藤さん，段さん，タへラさん，川﨑さん，安藤さんに感謝\nの意を表します．また，研究会や日々の生活を通して多くの助言をいただいたロペズ研究\n室の同期や後輩，OBOG の皆様にも深く感謝いたします．最後に，本研究を支えてくだ\nさったすべての方々に心より感謝申し上げます．\n2025 年1 月31 日\n本多　一騎\n48\n参考文献\n[1] 厚生労働省. 年齢（5 歳階級）別にみた熱中症による死亡数の年次推移（平成7 年～令和\n5 年）～　人口動態統計（確定数）より. https://www.mhlw.go.jp/toukei/\nsaikin/hw/jinkou/tokusyu/necchusho23/dl/nenrei.pdf, 9 202",
            "hw/jinkou/tokusyu/necchusho23/dl/nenrei.pdf, 9 2024. (参\n照日2024/9/24).\n[2] 環境省. 環境省熱中症予防情報サイト: 環境省マニュアル2-1. (参照日2024/09/25).\n[3] 労働安全衛生総合研究所. 熱中症予防のための暑熱環境と作業負荷の総合評価. (参照\n日2024/10/4).\n[4] IPCC. 図spm.8 - 各ssp シナリオにおける1850 年～1900 年基準の地表気温変化. (参\n照日2024/09/24).\n[5] ASHRAE 55-2020: Thermal Environmental Conditions for Human Occupancy. ANSI\nApproved. 2021.\n[6] ISO 7730:2005(E): Ergonomics of the Thermal Environment-Assessment of the Inﬂuence\nof the Thermal Environment Using Subjective Judgment Scales. ",
            "mal Environment Using Subjective Judgment Scales. 2005.\n[7] Stefano Corgnati, Marco Filippi, and Sara Viazzo. Perception of the thermal environment\nin high school and university classrooms: Subjective preferences and thermal comfort.\nBuilding and Environment - BLDG ENVIRON, Vol. 42, pp. 951–959, 02 2007.\n[8] Edward Arens, Michael Humphreys, Richard de Dear, and Hui Zhang. Are ‘class a’\ntemperature requirements realistic or desirable? Building and Environment - BLDG ENV-\nIRON, Vol. 45, pp. 4–10, ",
            " Environment - BLDG ENV-\nIRON, Vol. 45, pp. 4–10, 01 2010.\n[9] Muhammad Khairil, A. Senin, and Azree Othuman Mydin. Signiﬁcance of thermal com-\nfort in buildings and its relation to the building occupants. European Journal of Sustain-\nable Development, 2013.\n[10] N. Seong and D. Yoon. An approach of indoor thermal environment control and energy\nsaving using the pmv index. LHI Journal, 2010.\n[11] T. Kramer, V. Garcia-Hansen, S. Omrani, J. Zhou, and D. Chen. Personal differences in\nthermal comfort",
            "d D. Chen. Personal differences in\nthermal comfort perception: Observations from a ﬁeld study in brisbane, australia. Build-\ning and Environment, 2023.\n[12] Wei Luo, R. Kramer, Y. D. de Kort, and W. D. van Marken Lichtenbelt. Effectiveness of\npersonal comfort systems on whole-body thermal comfort – a systematic review on which\nbody segments to target. Energy and Buildings, 2021.\n49\n[13] Lin Lu, Jiayao Zhang, Yi Xie, F. Gao, Song Xu, Xinghuo Wu, and Z. Ye. Wearable health\ndevices in health care: ",
            "nd Z. Ye. Wearable health\ndevices in health care: Narrative systematic review. JMIR mHealth and uHealth, 2020.\n[14] M. Bez and F. Simini. Wearable devices and medical monitoring robot software to re-\nduce costs and increase quality of care. IEEE Conference on Advances in Computing,\nCommunications and Informatics, 2018.\n[15] Sam McDevitt, Haley Hernandez, Jamison S Hicks, Russell Lowell, Hamza Bentahaikt,\nReuben F. Burch, J. Ball, H. Chander, Charles E. Freeman, Courtney Taylor, and Brock\nAnderso",
            "les E. Freeman, Courtney Taylor, and Brock\nAnderson. Wearables for biomechanical performance optimization and risk assessment in\nindustrial and sports applications. Bioengineering, 2022.\n[16] キヤノンIT ソリューションズ. ウェアラブルデバイスのセキュリティとプライバシー\nの問題, 2020. (参照日2024/09/25).\n[17] Fortune\nBusiness\nInsights.\nWearable\ntechnology\nmarket\nsize,\nshare,\nvalue\n—\ngrowth,\n2032.\nhttps://www.fortunebusinessinsights.com/\nwearable-technology-market-106000, 2024. (参照日2024/09/25).\n[18] Nikhil Singh, K. Moneghetti, J. Christle",
            "25).\n[18] Nikhil Singh, K. Moneghetti, J. Christle, D. Hadley, V. Froelicher, and D. Plews. Heart\nrate variability: An old metric with new meaning in the era of using mhealth technologies\nfor health and exercise training guidance. Arrhythmia I& Electrophysiology Review, 2018.\n[19] Hidehiko Ikura, Yoshinori Katsumata, Y. Seki, Toshinobu Ryuzaki, Y. Shiraishi, Kotaro\nMiura, Kazuki Sato, and K. Fukuda. Real-time analysis of heart rate variability during aer-\nobic exercise in patients with cardiovas",
            "ring aer-\nobic exercise in patients with cardiovascular disease. International Journal of Cardiology\nHeart I& Vasculature, 2022.\n[20] 鈴木伊織, 佐藤文明ほか. ウェアラブル端末により検知した心拍変動に基づくストレ\nス推定. 研究報告コンピュータセキュリティ(CSEC), Vol. 2020, No. 30, pp. 1–7, 2020.\n[21] Kizito Nkurikiyeyezu, Yuta Suzuki, and Guillaume Lopez.\nHeart rate variability as a\npredictive biomarker of thermal comfort. Journal of Ambient Intelligence and Humanized\nComputing, Vol. 9, , 10 2018.\n[22] 早野順一郎, 山田眞己, 藤浪隆夫, 横山清子, 渡辺與作, 高田和之. 心拍変動と自律神経\n機能. ",
            "野順一郎, 山田眞己, 藤浪隆夫, 横山清子, 渡辺與作, 高田和之. 心拍変動と自律神経\n機能. 生物物理, Vol. 28, No. 4, pp. 198–202, 1988.\n[23] F. Canini, E. Sagui, and F. Zagnoli. Syst`eme nerveux, stress et coup de chaleur. EAC\nRevue, Vol. 36, No. 2, pp. 102–108, 2012.\n[24] Takashi Hamatani, A. Uchiyama, and T. Higashino. Estimating core body temperature\nbased on human thermal model using wearable sensors. Proceedings of the ACM Confer-\nence, 2015.\n[25] K. Tokizawa, Toru Shimuta, and Hirofumi Tsuchimoto. Wearable technologies for real-\ntime",
            "i Tsuchimoto. Wearable technologies for real-\ntime monitoring of body core temperature under heat stress conditions. Medicine I& Sci-\nence in Sports I& Exercise, 2020.\n50\n[26] 日本気象協会. 学びの部屋「熱中症予防の基礎知識」. https://www.netsuzero.\njp/learning/le17. (参照日2024/10/02).\n[27] Mayo\nClinic\nHealth\nSystem.\nWhen\ntemps\nrise,\nremember\nthese\nheat-\nstroke\nprevention\ntips.\nhttps://www.mayoclinichealthsystem.\norg/hometown-health/speaking-of-health/\nwhen-temps-rise-remember-these-heatstroke-prevention-tips,\n2023. (参照日",
            "ember-these-heatstroke-prevention-tips,\n2023. (参照日2024/10/02).\n[28] 環境省. 熱中症環境保健マニュアル, 2022. (参照日2024/10/02).\n[29] Cleveland\nClinic.\nHyperthermia\n(heat-related\nillnesses).\nhttps://my.\nclevelandclinic.org/health/diseases/22111-hyperthermia.\n(参照\n日2024/10/02).\n[30] Jai Kyoung Sim, S. Yoon, and Young-Ho Cho. Wearable sweat rate sensors for human\nthermal comfort monitoring. Scientiﬁc Reports, Vol. 8, pp. 1–10, 2018.\n[31] Jintu Fan and Humble W. K. Tsang. Effect of clothing thermal properties on the t",
            "ng. Effect of clothing thermal properties on the thermal\ncomfort sensation during active sports. Journal of Industrial Textiles, Vol. 37, No. 4, pp.\n319–335, 2008.\n[32] Naoto Fujii, Kion Hatam, G. Mcgarr, R. Meade, P. Boulay, T. Nishiyasu, and G. Kenny.\nExogenous activation of protease-activated receptor 2 attenuates cutaneous vasodilatation\nand sweating in older men exercising in the heat. Acta Physiologica, Vol. 226, No. 4, p.\ne13369, 2019.\n[33] Chee Chong Shawn Tan, Li Chin, and I. C. C. Low.",
            "] Chee Chong Shawn Tan, Li Chin, and I. C. C. Low. Thermoregulation in the aging pop-\nulation and practical strategies to overcome a warmer tomorrow.\nProteomics Clinical\nApplications, Vol. 14, No. 3, p. 1800468, 2020.\n[34] Su-Young Son. Research trends on prevention of heat stroke using clothing: Focusing\non practical research in japan. Fashion and Ergonomics Research, Vol. 56, pp. 473–484,\n2018.\n[35] Zijun Li, Mengsheng Zhang, Tian Yuan, Qiaoli Wang, Pengyu Hu, and Yu Xu. New\nwearable thermoele",
            "Wang, Pengyu Hu, and Yu Xu. New\nwearable thermoelectric cooling garment for relieving the thermal stress of body in high\ntemperature environments. Energy and Buildings, Vol. 112, pp. 1–10, 2022.\n[36] Wanwan Wang and Mengmeng Zhao. Design of liquid–air hybrid cooling garment and its\neffect on local thermal comfort. Applied Sciences, Vol. 13, p. 9414, 2023.\n[37] D. Leyk, J. Hoitz, C. Becker, K. Glitz, Kai Nestler, and C. Piekarski. Health risks and\ninterventions in exertional heat stress. Arztebla",
            "\ninterventions in exertional heat stress. Arzteblatt International, Vol. 116, pp. 537–544,\n2019.\n[38] Christian K. Garcia, Liliana I. Renter´ıa, Gabriel Leite-Santos, Lisa R. Leon, and O. Lai-\ntano. Exertional heat stroke: pathophysiology and risk factors. BMJ Medicine, Oct 2022.\n51\n[39] A. Costrini, H. Pitt, A. Gustafson, and D. E. Uddin. Cardiovascular and metabolic mani-\nfestations of heat stroke and severe heat exhaustion. American Journal of Medicine, Feb\n1979.\n[40] 千葉友樹, 高橋幹雄, 黒木友裕, 和田一樹, ",
            " Medicine, Feb\n1979.\n[40] 千葉友樹, 高橋幹雄, 黒木友裕, 和田一樹, 天野健太郎, 桑山絹子. 局所冷却行為による\n暑熱ストレス低減効果の予測手法に関する研究(その1) 頸部冷却時の生理反応の検\n討. 空気調和・衛生工学会大会学術講演論文集令和元年度大会(札幌) 学術講演論文\n集第6 巻温熱環境評価編, pp. 37–40. 公益社団法人空気調和・衛生工学会, 2019.\n[41] Povl Ole Fanger. Assessment of man’s thermal comfort in practice. British Journal of\nIndustrial Medicine, Vol. 30, pp. 313 – 324, 1973.\n[42] E. Halawa and J. van Hoof. The adaptive approach to thermal comfort: A critical overview.\nEnergy and Buildings, Vol. 51, pp. 101–110, 2012.\n[43] empati",
            "Buildings, Vol. 51, pp. 101–110, 2012.\n[43] empatica. E4 wristband — real-time physiological signals — wearable ppg, eda, temper-\nature, motion sensors. https://www.empatica.com/research/e4/. (参照日\n2024/10/15).\n[44] Luca Menghini, Evelyn Gianfranchi, Nicola Cellini, Elisabetta Patron, Mariaelena Tagli-\nabue, and Michela Sarlo. Stressing the accuracy: Wrist-worn wearable sensor validation\nover different conditions. Psychophysiology, Vol. 56, , 07 2019.\n[45] 工場向け暑さ対策— コモドギア- 富士通ゼネラル. (参照日2024/10/15",
            "019.\n[45] 工場向け暑さ対策— コモドギア- 富士通ゼネラル. (参照日2024/10/15).\n[46] Fred Shaffer and J. P. Ginsberg. An overview of heart rate variability metrics and norms.\nFrontiers in Public Health, Vol. 5, , 2017.\n[47] M600\nユーザーマニュアル\n—\npolar\nm600\nユーザーマニュアル.\nhttps://support.polar.com/e_manuals/M600/wear-os/\npolar-m600-user-manual-japanese/Content/introduction.htm.\n(参照日2025/01/12).\n[48] Machine learning project at the university of waikato in new zealand. https://ml.\ncms.waikato.ac.nz/index.html. (参照日2025/01/12).\n52\n質疑",
            "s.waikato.ac.nz/index.html. (参照日2025/01/12).\n52\n質疑応答\n工藤　聖人　情報テクノロジー学科　助手\nQ\n研究背景に高齢者の熱中症死亡者数増加傾向を挙げられていましたが，実験では現\n場などの高齢者とは言えない年齢層だったのはなぜでしょうか．\nA\nご質問ありがとうございます．研究背景での言及は，運動や労働などによる若年層\nや中年層の熱中症だけでなく，高齢者の屋内での熱中症なども多くあり，全年代に\n対して熱中症の危機感を持つべきだという意図のもと高齢者の熱中症死亡者数増加\n傾向を挙げさせていただきました．また，高温多湿な環境において高齢者のデータ\nを収集することは健康面に対して非常に配慮して行う必要があるため，今回は現場\nで働いている方のデータ収集や，高齢者の方には制御された実験室のもと涼しい格\n好でデータを収集させていただきました．\n大原　剛三　情報テクノロジー学科　教授\nQ\nコメントになりますが，高齢者と若年層では感じ方など異なると思います．\nA\nコメントありがとうございます．先行研究でも年齢差で熱に対する快適性や熱中症\nの重症度などの違いに",
            "A\nコメントありがとうございます．先行研究でも年齢差で熱に対する快適性や熱中症\nの重症度などの違いには言及されており，本実験で収集されたデータにおいても，学\n習用データセットを50 歳以上と50 歳未満で分けた際に精度の向上がみられました．\n高齢者の健康に配慮してより多くのデータを収集し，高齢者専用の熱的快適性モデ\nルを作成することも視野に入れたいと思います．\n浦垣　啓志郎　情報テクノロジー学科　助手\nQ\n暑さを測る指標であるPMV は連続値で出ていると思うのですが，分類問題にした\n理由はなぜでしょうか．\nA\nご質問ありがとうございます．PMV の値は連続値で取得できますが，基礎実験で\nある実験室での実験は，温度や湿度が一定に制御された環境でのデータ収集であっ\nたため，算出されるPMV の値も離散的な傾向にありました．そのため，このデータ\nを訓練データとして用いて熱中症経験者のいる現場で得たデータなどの評価するた\nめに，今回は分類問題とさせていただきました．今後は，制御されていない環境で\nのデータ収集を増やし，より多様な条件下でPMV の値を取得することで，回帰分析\nを用いた細かい粒度",
            "\nのデータ収集を増やし，より多様な条件下でPMV の値を取得することで，回帰分析\nを用いた細かい粒度での熱中症リスク評価を目指していきたいと考えています．\n53\n"
        ]
    },
    {
        "id": "paper_11",
        "filename": "M2024_Keisuke_Sato.pdf",
        "title": "M2024_Keisuke_Sato",
        "fulltext": " \n \n \n \n \n青  山  学  院  大  学 \n \n理  工  学  研  究  科 \n \n \n \n理工学専攻    知能情報    コース \n \n \n \n \n修  士  論  文 \n \n \n \n       学 生 番 号    ３５６２３２３３      \n \n \n       氏     名      佐 藤  圭 翼        \n \n \n研究指導教員    ロペズ・ギヨーム       \n \nW.I.L.-CoreMoni\n短期的および長期的な複合支援による体幹トレーニングの\n姿勢向上とモチベーション維持効果の検証\n佐藤圭翼\n2025/01/31\nThe Academic Year of 2024, Submitted on January 31st, 2025 \n \nGraduate School of Science and Engineering, Aoyama Gakuin University \n \nTitle: W.I.L.-CoreMoni \nVerification of The Effects of Short-Term and Long-Term Combined Support for \nImproving Posture and Maintaining Motivation during Core Training \n \nStudent Name: Keisuke Sato  \nID Number: 35623233   \nDegree: Master of Engineering \nCourse: Intelligence and Information \nThesis Advisor: Professor Guillaume Lopez \n \nAbstract  \nDue to the COVID-19 pandemic, lack of exercise has become a concern. We focused on \ncore training, which can be done alone anytime, anywhere. However, maintaining \nproper posture during training is challenging, and low motivation often leads to \ninconsistency. \nTo address these issues, we developed the W.I.L.-CoreMoni system to support posture \ncorrection and motivation. The system consists of a coin-sized wearable accelerometer \nand a smartphone. Users attach the sensor to their waist and train while checking the \nsmartphone screen. The system collects individual baseline values, converts \nacceleration data into angles, and compares the posture in real-time against predefined \nthresholds, providing immediate feedback for correction. \nAdditionally, three long-term feedback features were implemented: \n \n1. Training History: Allows users to review past sessions. \n2. Ranking System: Enables competition with others online. \n3. Reminder Notifications: Alerts users when they miss training for a certain period. \n \nTo evaluate the system, we conducted a one-month experiment with eight participants \n(ages 20–50) performing front plank exercises. Participants trained at their preferred \ntime and location. They were divided into two groups: Group A received notifications in \nthe first two weeks, while Group B received them in the latter two weeks. Usability \n(SUS) and motivation surveys were conducted. \nResults showed that long-term feedback increased training frequency and consistency \nwhile maintaining motivation. The effectiveness of the history, ranking, and notification \nfeatures was confirmed, demonstrating their role in improving training frequency, \nstability, and motivation. \nFor future improvements, we plan to explore alternative sensors for smoother \nsmartphone connectivity. Additionally, in response to user requests, we aim to \nimplement real-time ranking notifications and voice-based feedback to enhance \nmotivation. \n \n理工学専攻修士論文要旨 \n \n \n提出年度\n      ： 2024 年度 \n提\n出\n日\n      ： 2025 年 1 月 31 日 \n専修コース： 知能情報コース \n学生番号\n      ： 35623233 \n学生氏名\n      ： 佐藤 圭翼 \n研究指導教員： ロペズ ギヨーム 教授 \n \n（論文題目） \nW.I.L.-CoreMoni： \n短期的および長期的な複合支援による体幹トレーニングの姿勢向上とモチベーション維持効果の検証 \n \n（内容の要旨） \n新型コロナウイルスの影響により，運動不足の問題を指摘し，一人で手軽に取り組むことのできる体\n幹トレーニングに注目した．体幹トレーニングは場所を選ばず，好きな時間や場所で取り組むことがで\nきる一方，トレーニング中の姿勢が正しいかどうかの判定は難しい．また，モチベーションが維持でき\nないことでトレーニングを継続できず，結果として３日坊主になってしまうなど様々な問題点があげら\nれる． \nこれらの課題を解決すべく，トレーニング中の姿勢支援およびモチベーションの維持向上を目的とし\nて，体幹トレーニング支援システム「W.I.L.-CoreMoni」を構築した．本システムは，加速度を取得する\nことができる500 円玉くらいの大きさのウェアラブルデバイスとスマートフォンで構成されている．ユ\nーザは加速度センサを腰に装着し，スマートフォンの画面を見ながらトレーニングを行う．その際，本\nシステムがユーザによって異なる基準値（初期値）を取得したのち，独自のアルゴリズムによって，取\n得した加速度を角度に変換し，トレーニング中の暫定値と比較後，あらかじめ定義した閾値との判定結\n果によってユーザにリアルタイムにフィードバックを与え，姿勢改善を促すというものである． \nまた，モチベーション維持を目的とした長期的なフィードバック機能を３つ実装した． \n \n① 「トレーニング履歴閲覧機能」：これまでのトレーニングデータを閲覧する仕組みを提供 \n② 「ランキング機能」：同じトレーニングに取り組む人とオンライン上で競争することを提供 \n③ 「３日坊主防止通知機能」：一定期間トレーニングに取り組んでいない際に，自動的に通知 \n \n本システムの有効性を評価するため実験を行った．20~50 代の男女８名を被験者とし，１か月の間，\n体幹トレーニングの種目のひとつである「フロントプランク」の姿勢でトレーニングに取り組んでもら\nった．実験の実施時間と場所は各被験者の任意とした．被験者には内密に，２つのグループに分割し，\nGroup A は最初の２週間，通知機能を有効にし，Group B は後半の２週間，通知機能を有効にした．\n各被験者には，システムの使いやすさを評価する SUS アンケートと，継続性・モチベーションに関す\nるアンケートを用意した． \n実験の結果，長期的なフィードバックによって継続頻度が向上し，安定した頻度でトレーニングに取\nり組めていたことが分かった．同時に，被験者のモチベーションが高かったという結果を得ることがで\nきた．したがって，長期的なフィードバックにおいて期待通りの結果を得ることができたと結論付ける\nことができる．特に長期的なフィードバックの主要機能である「履歴閲覧機能」「競争機能」「通知機能」\nの有効性が実証された．３要素間に機能の優劣はあるものの，結果として「継続頻度の向上」「安定した\nトレーニング継続回数」「モチベーションの維持・向上」の３点すべての有効性を実証することができ\nた． \n今後の展望として，加速度センサとスマートフォンの接続がスムーズになるよう，センサの種類を変\n更することを検討していきたい．また，「リアルタイムで順位の変動を知らせてほしい」という被験者か\nらの意見を反映させるため，ランキングが変動した際に通知が発動するような仕組みや音声によるマル\nチフィードバックについても検討し，実現に向けて「W.I.L.-CoreMoni」の更改をしたい． \n \n \n青山学院大学大学院理工学研究科 \n目次\n第1 章\n序論\n3\n1.1\n研究背景. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n3\n1.1.1\n新型コロナウイルスが人々の生活へ与えた影響. . . . . . . . . . . . . . . . . . . . .\n3\n1.1.2\n体幹トレーニングの重要性. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n3\n1.1.3\n体幹トレーニングの認知度. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n4\n1.1.4\nモチベーション維持における心理的側面\n. . . . . . . . . . . . . . . . . . . . . . . .\n6\n1.2\n研究目的. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n7\n1.3\n本論文の構成. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n8\n第2 章\n先行研究とその課題および本研究の優位性\n9\n2.1\n先行研究. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n9\n2.1.1\nカメラ画像を用いたトレーニング支援手法. . . . . . . . . . . . . . . . . . . . . . .\n9\n2.1.2\nウェアラブルデバイスを用いた体幹トレーニングの種目識別手法. . . . . . . . . . .\n10\n2.1.3\n習慣化するための支援手法. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n12\n2.1.4\nモチベーションの維持・制御手法. . . . . . . . . . . . . . . . . . . . . . . . . . . .\n13\n2.2\n先行研究の課題と本研究の優位性. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n13\n第3 章\nW.I.L.-CoreMoni の全体像，概要および使用方法\n14\n3.1\nW.I.L-CoreMoni の全体像. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n14\n3.2\nW.I.L-CoreMoni の概要\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n15\n3.2.1\nセンシング機能-短期的フィードバック- . . . . . . . . . . . . . . . . . . . . . . . .\n15\n3.2.2\n骨格画像等表示機能-短期的フィードバック- . . . . . . . . . . . . . . . . . . . . . .\n28\n3.2.3\nトレーニングスタッツ閲覧機能-長期的フィードバック- . . . . . . . . . . . . . . . .\n30\n3.2.4\n他者とのランキング機能-長期的フィードバック-\n. . . . . . . . . . . . . . . . . . .\n30\n3.2.5\n３日坊主防止リマインダ機能-長期的フィードバック- . . . . . . . . . . . . . . . . .\n31\n3.3\nW.I.L.-CoreMoni におけるデータの流れ\n. . . . . . . . . . . . . . . . . . . . . . . . . . . .\n32\n3.4\nW.I.L.-CoreMoni の使い方. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n33\n第4 章\nスコアリングによるモチベーション維持の検証（予備実験）\n40\n4.1\n予備実験の目的. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n40\n4.2\n予備実験の方法. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n40\n4.3\n予備実験の手順. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n40\n4.4\n予備実験の分析方法\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n41\n4.4.1\nトレーニングスタッツ. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n41\n4.4.2\nSUS アンケート. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n41\n4.5\n実験結果. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n42\n4.5.1\n実験前と実験後での正しい姿勢を維持できた時間の比較結果. . . . . . . . . . . . .\n42\n4.5.2\nSUS スコア. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n43\n4.5.3\n体幹トレーニングをおこなった頻度・継続性. . . . . . . . . . . . . . . . . . . . . .\n45\n4.6\n考察・課題・今後の展望. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n49\n1\n第5 章\nスコアリング並びにリマインドによるモチベーション維持の検証（本実験）\n50\n5.1\n本実験の目的. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n50\n5.2\n本実験の方法. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n50\n5.3\n本実験の手順. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n50\n5.4\n本実験の分析方法. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n51\n5.4.1\nトレーニングの継続性. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n51\n5.4.2\nSUS アンケート. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n51\n5.4.3\nモチベーションに関する主観評価アンケート. . . . . . . . . . . . . . . . . . . . . .\n51\n5.4.4\n道具性期待理論によるモチベーション評価. . . . . . . . . . . . . . . . . . . . . . .\n52\n5.5\n本実験の結果と考察\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n53\n5.5.1\nトレーニングの継続頻度. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n53\n5.5.2\n短期的および長期的フィードバックにおけるSUS スコア. . . . . . . . . . . . . . .\n55\n5.5.3\nモチベーション維持に関する主観アンケート結果\n. . . . . . . . . . . . . . . . . . .\n56\n5.5.4\n道具性期待理論に基づくモチベーション状態の評価. . . . . . . . . . . . . . . . . .\n58\n第6 章\n本研究の結論および今後の展望\n59\n謝辞\n60\n参考文献\n61\n付録\n64\n付録A . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n64\n付録B . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n66\n付録C . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n81\n2\n第1章\n序論\n本章では序論として，研究背景および研究目的について論じる．第1.1 節では研究背景について述べ，第\n1.2 節では研究目的について述べる．第1.3 節では本論文の構成について述べる．\n1.1\n研究背景\n本節では研究背景として，第1.1.1 項で新型コロナウイルスが人々の生活に与えた影響について，第1.1.2\n項で体幹トレーニングの重要性について，第1.1.3 項で体幹トレーニングの認知度について，第1.1.4 項で\nモチベーション維持における心理的側面について論じる．\n1.1.1\n新型コロナウイルスが人々の生活へ与えた影響\n2019 年末に流行し始めた新型コロナウイルス（以下COVID-19）の影響は3 年たった今でも爪痕を残して\nいる[1]．スポーツ庁は「感染症対策による活動制限・運動不足の長期化による影響」として「体力の低下」\n「腰痛・肩こり」「生活習慣病の発症・悪化」を事例に挙げている[2]．また，明治安田生命保険相互会社が\n2021 年に5640 人の男女を対象に実施した健康に関するアンケート調査[3] の結果，3 人に2 人がCOVID-19\nの影響でストレスを感じていると回答し，4 人に1 人の体重が増加していることが分かった．さらに，コロ\nナ禍による健康意識の変化についてのアンケートの結果，40%以上の人々が「健康意識が高まった」と回答\nした．以上のことから，COVID-19 の流行を機に人々は健康に意識を持ち始めたといえる．\n健康な身体を維持するためには，ランニングや筋力トレーニングといった日常的な運動が有効であると\n考えられている[4]．フィットネスクラブの動向報告[5] によると，2022 年4 月の利用者数合計は1700 万人\nを超えており，多くの人々が定期的に運動をしていることが分かる．\n1.1.2\n体幹トレーニングの重要性\n自宅で過ごす時間が増えたことから，屋内で一人で簡単に始められる体幹トレーニングに注目が集まっ\nている[6]．体幹トレーニングはスポーツ動作に求められる能力向上だけでなく[7]，日常生活においても重\n要な役割を果たしている．\n「体幹」とは図1.1 に示すように身体の四股と頭部を除いた部分で，身体重量の\n約48 ％を占めており，体幹に含まれる筋肉群は「体幹筋」と総称されている[8]．体幹は運動について四股\n間の運動連結やバランスに関して重要な役割を果たしている．そのため体幹は動作の要であり，全ての生活\n動作において最も重要な身体の部位である．体幹の筋力が低下すれば起き上がることが困難になり，体幹に\n異常運動を呈すれば座位などの姿勢保持が著しく困難になるなど，体幹強度は身体の健康にとても重要で\nある．体幹トレーニングはスポーツ選手を筆頭に一般の人々にも浸透し始め，注目されている．\n3\n図1.1: 体幹の部位\n1.1.3\n体幹トレーニングの認知度\n近年，体幹トレーニングは注目を集めているが，認知度を調査するケーススタディはまだ行われていな\nい．そこで，体幹トレーニングがどの程度認知されているか調査を行った．\n「体幹トレーニングに関するア\nンケート」と題した調査を実施した．図1.2 は調査に使用した質問項目のスクリーンショットである．質問\nは「体幹トレーニングをご存知ですか？」と「ご存じの体幹トレーニングの種目にチェックを入れてくださ\nい．」という簡単な2 つの質問である．候補となった種目[9] は，体幹トレーニングの主要エクササイズで\nある「フロントプランク[10]」，\n「サイドプランク[11]」，\n「ニー・トゥ・エルボー[12]」である．20 代から40\n代の男女82 名が回答した．\n調査結果によると，\n「体幹トレーニングをご存知ですか？」という質問に対して，回答者の97.6%が「は\nい」と回答した．知っている種目の回答率は，\n「フロントプランク」が100 ％，\n「サイドプランク」が93.8 ％，\n「ニー・トゥ・エルボー」が85.2 ％でした．図1.3 と図1.4 にそれぞれの詳細を示す．\n4\n図1.2: 体幹トレーニングの認知度アンケートの質問項目\n図1.3: 体幹トレーニングの認知度アンケート結果\n5\n図1.4: 種目の認知度アンケート結果\nこれらの結果から，体幹トレーニングの認知度は十分であると結論付けることができる．\n1.1.4\nモチベーション維持における心理的側面\nなにかを継続する際，モチベーションや目標がないと頑張れないと感じるのは私たちだけではないはず\nだ．人間が行動を継続するとき，\n「動機づけ」という概念が重要となる．動機づけとは，行動を始発させ，目\n標に向かって維持・調整する過程や機能のことである[13]．\n動機づけには外発的動機付けと内発的動機付けの２種類がある[14]．外発的動機付けとは，外部からの評\n価や報酬，また賞罰などが要因となって行動を起こす動機付けである．外部から得られるポジティブな要因\nや評価や罰といった恐れの気持ちも要因となることが特徴である一方，内発的動機付けとは，物事に対する\n興味や関心によって行動を起こし，達成感や満足感を得たいという，人の内面に沸き起こった意欲から起こ\nる動機づけである．好奇心や探知心が根本にあり，損得への関係がない欲求が特徴である．\n内発的動機付けからの行動には「承認」が重要であり，人間の欲求は５段階のピラミッドのように構成さ\nれている（図1.5）．低層階の欲求が満たされると，より高次の階層の欲求を求めるようになる．上層階で\nある第４，第５階層が内発的なものであり，下層階の第１，第２，第３階層が外発的なものである．第１階\n層は生理的欲求と呼ばれ，生きていくための必要な基本的な本能的な欲求である．第２階層は安全欲求と呼\nばれ，危機を回避したい，安全安心に生活がしたいという欲求である．第３階層は社会的欲求と呼ばれ，集\n団やグループに属したい，仲間が欲しいという欲求である．第４階層は承認欲求と呼ばれ，認められたいと\n感じたり，尊敬されたいと感じる欲求である．最後の第５階層は自己実現欲求と呼ばれ，自分自身の力を発\n揮し，あるべき姿の自分になりたいと感じる欲求である．これらはマズローの欲求段階説と呼ばれている．\n6\n図1.5: マズローの欲求段階説\n1.2\n研究目的\n本研究の目的は，一人で行うトレーニング（体幹トレーニング）を支援するシステムを構築し，トレーニ\nングを通して人々の健康維持に貢献し，ウェルビーイング実現に近づけることである．体幹トレーニングを\n行うにあたって，いくつか課題がある．体幹トレーニングは一人で気軽に始められるものの，自分の姿勢を\n客観的に俯瞰し，正しい姿勢を維持することは容易ではない．また，監視の目がないことからトレーニング\nを継続して行うことを途中でやめてしまう可能性も考えられる．\n実際，日本におけるフィットネス継続率は低迷している．スポーツジムを利用する人々の継続率に関する\nデータは，利用者のモチベーションや生活スタイルを反映しており，日本フィットネス産業協会によると，\n国内のジムの月間退会率は約4～5 ％であり，年間を通して見るとほぼ半数の会員が入れ替わるそうだ[15]．\nまた，アメリカの研究では，フィットネスジム利用者の継続率は，開始から3ヶ月後で37%，1 年後には\nわずか4%未満に減少すると報告されている．100 人がジムに入会しても，1 年後には4 人しか継続してい\nない結果となる[16]．忙しくて時間が取れない，成果が感じられないといった理由が多いが，\n「エクササイ\nズが単調で飽きてしまうこともある」と考えられている．会員の歩留まりが上がれば，ロスは減ると考え\nられる．\n「国内市場の大部分は（運動器具やプール，スタジオをそろえた）総合型ジムが支えているものの，\nそこで応えきれていないニーズを（娯楽型が）ひろっている」と指摘する．\nこのような課題を解決するため，本研究では加速度センサを活用し，短期的フィードバックと長期的フィー\nドバックを兼ね備えた，体幹トレーニング支援システムである「W.I.L.-CoreMoni」を提案する．トレーニ\nングを楽しみながら継続できるよう，時間がない人でも手軽に利用でき，自身のトレーニング成果を可視化\nするなど，いくつかの仕掛けを実装した．本システムの開発を通して，システムの有効性の検証およびシス\nテムがトレーニングの継続にどのくらい貢献できるのかを評価することを目標とし，本研究に取り組んだ．\n7\nまた，モチベーション評価を行うにあたって２つのことに留意する．１点目はトレーニング種目である．\nフロントプランクやサイドプランクなど，様々な種目を利用できるようシステムの開発に尽力したが，シ\nステム上の挙動が安定しているフロントプランクに着目した．２点目は動機づけについてである．前項で\n動機づけには外発的動機付けと内発的動機付けがあると述べたが，今回は内発的動機付けに着目する．な\nぜなら，アンダーマイニング効果が存在するからだ[17]．アンダーマイニング効果とは，内発的動機付けに\nよる行動に対して，外発的動機付けである「外的報酬」を与えた場合，かえってその人の意欲を低下させ\nてしまう現象のことである．もともとは内発的動機付けによる行動していたはずなのに，報酬を得た結果，\n報酬や評価そのものが目的となってしまう状態をさす．アンダーマイニング効果を防ぐためには，相手の\n努力や行動を褒め，\n「やらされている」と感じさせない言動を心がけることが大切である．内発的動機付け\nは，興味・関心や達成感・満足感を得たい気持ちが原動力となる．そういった原動力から成る行動は，高い\n集中力や質を保った業務を続けることができ，やりがいを感じやすいメリットが期待できる．\nさらに，内発的動機付けは外発的動機付けに比べ，より個人の特性やライフスタイルに適応させることが\nできるため，有効性をはかることができるのではないかと仮定した．そのため，内発的動機付けに焦点を置\nき，本研究に取り組んだ．\n本研究の目的は大きく分けると以下の通り：\n1. 短期的フィードバックの有効性を検証する．\n2. 長期的フィードバックの有効性を検証する．\n1.3\n本論文の構成\n本論文の構成は以下の通りである．\n• 第１章序論（研究背景や研究目的，本論文の構成）\n• 第２章関連研究および先行研究との差異\n• 第３章W.I.L.-CoreMoni の全体像，概要および使用方法\n• 第４章スコアリングによるモチベーション維持の検証（予備実験）\n• 第５章スコアリング並びにリマインドによるモチベーション維持の検証（本実験）\n• 第６章本研究の結論および今後の展望\n• 謝辞\n• 参考文献\n• 付録A～C\n8\n第2章\n先行研究とその課題および本研究の優位性\n本章ではいくつかの先行研究と本研究の優位性について論じる. 第2.1 節では先行研究について，第2.2\n項では先行研究の課題と本研究の優位性について論じる.\n2.1\n先行研究\n2.1.1\nカメラ画像を用いたトレーニング支援手法\n綿谷らはカメラの画像を用いた体幹トレーニングの姿勢支援手法を提案した[18]．従来のトレーニング支\n援手法は，姿勢推定を行ったのちにユーザへフィードバックを与え，正しい姿勢でのトレーニングを促すと\nいうものであった[19][20]．しかしながら，それらの姿勢推定には深度カメラや複数台のカメラを必要とす\nるため，コストがかかるという問題点があげられた．また，ユーザへの視覚的フィードバックが１視点およ\nび骨格情報のみを示している２次元骨格画像であるため，トレーニング時の姿勢把握が難しいという問題\nがあった．\nそこで彼らは，画像から姿勢推定を行い，トレーニングの目標姿勢と現在の姿勢の３次元モデルを生成し，\n重畳表示した．さらに，目標姿勢と現在の姿勢の違いを把握しやすくするために，身体の各部位１０箇所に\nマーカを表示し，誤差に応じて４段階に色変化させた．これらの情報を２視点でユーザへ視覚的フィード\nバックをすることで，姿勢補正の支援を行った．提案手法としては，単一のRGB カメラのみを用いて，カ\nメラ画像から姿勢推定を行い，推定結果に基づいて３次元モデルを生成し，２視点でユーザへ視覚的フィー\nドバックを行うというものである．\n結果として，アンケートによる有効性評価を行ったところ，３次元モデルを用いてフィードバックを行う\nことは姿勢の把握しやすさを向上させるうえで有効な手法であると考えられた．\nしかしこの研究では，視覚的フィードバックの更新速度が遅く，目標姿勢に対して現在の姿勢がどのくら\nい異なっているかを認識するのは困難であった．また，トレーニング中に視線を変えて画面を見なければな\nらないという問題点もあった．今後の展望として、Head Mounted Display（HMD）の利用などが考えられ\nている．\n一方，村田らは安価な装置を開発することを目的とし，深度カメラを有するKinect[21] を利用し，運動を\n支援するシステムを構築した[22]．少子高齢化が進むに従い，リハビリテーションを必要とする人が増加す\nる可能性があり，運動を客観的に評価することが推奨されている．長期間にわたってリハビリテーションを\n続けるためには，当事者である患者のやる気を維持し，医療従事者が現状について正しく認識できる必要が\nある．腕や足の関節の角度の測定は分度器や定規を当てるなどして計測可能であるが，身体が傾いた状態，\nさらにそれにねじれが加わった状態を分度器や定規で測定するのは高度なノウハウが必要といわれている．\nリハビリテーションやスポーツの場で患者や選手の身体の動きを詳細に計測できる機器にVICON[23] が\nある．VICON は身体の関節運動を動的な情報として記録可能である一方で，非常に高価であることから，\n導入可能な施設は限られ，自宅での自主訓練には不向きであると考えられる．この問題を解決するため，村\n田らはKinect を用いて前屈，身体の傾き，身体のねじれ具合を計測する３種類のアプリケーションを開発\nした．\n結果として，数度の誤差範囲で計測することができ，身体のゆがみを比較的安価で，高度なノウハウを必\n要としない装置を開発することができた．今後の展望としては，性能と利用勝手を向上させていくとある．\n9\n2.1.2\nウェアラブルデバイスを用いた体幹トレーニングの種目識別手法\n高田らは，体幹トレーニング支援に向けたウェアラブルデバイスによる種目認識手法を提案している[24]．\n日本は高齢化社会から高齢社会へと転換し，今後は事態が深刻化する恐れがある．副次的な被害としては，\n経済成長の弱体化・社会保障の負担増大などがあげられる．これらの問題を解決するためには，日常的なト\nレーニングが有効であると考えられている．体力がつくことで自立した生活や健康寿命の延び，労働者と\nして社会に貢献できるなどの利点がある．これらのことから，健康寿命を延伸させ，要支援・要介護状態に\nならないための取り組みを推進させることは非常に重要であると考えられている．\n個人で行うことのできる体幹トレーニングは，パーソナルトレーナーの下で行うトレーニングに比べ，効\n果的なトレーニングを行うことができないという問題がある．そこで高田らは，身体にウェアラブルデバイ\nス（図2.1）を装着し，ウェアラブルデバイス内に搭載された慣性センサを用いてトレーニング中の姿勢情\n報を取得し，得られる加速度やジャイロデータをもとに，機械学習によって体幹トレーニング種目を自動認\n識できるようにした．提案手法として，Step0 からStep3 までの構成（図2.2）が紹介されている．Step0 で\n身体に取り付けられた少数のウェアラブルデバイス内に搭載されたセンサから体幹トレーニング中の姿勢情\n報を取得し，Step1 でセンサから得られるデータをもとに機械学習を用いて学習器を構築し，その学習器に\nよって体幹トレーニング種目の自動認識を行う．Step2 で認識された種目に対してQuality of Training 評\n価を行い，Step3 で評価結果から個々にあった運動支援をデバイスを介して行い，人間のパーソナルトレー\nナーを人工知能的なエージェントに置き換えるというものである．\n結果として，機械学習手法としてRandom Forest(RF) を用いた場合で，F 値：99.7%と高精度に認識す\nることに成功した．さらに，片方の手首およびベルト位置にデバイスを装着するだけでもF 値：94.1%の精\n度で認識できることを確認した．したがって，本システムの有効性を確認することができた．\n今後の展望として，装着部位として足首などを考慮した追加デバイスによる認識精度の向上，トレーニン\nグ中か否かのセグメンテーション化の検討があげられる．\n図2.1: ウェアラブルデバイスを使用した種目識別手法\n10\n図2.2: 高田らの実験における装置操作手順の説明\nDavid Barbado らは，図2.3 に示すような様々な体幹トレーニングの強度を定量化するために，スマホ\n内の加速度センサの信頼性を分析し，骨盤につけた加速度データが体幹構造の安定性や全身の姿勢制御を\nどの程度表しているかを分析した[25]．体幹トレーニングについて，これまで運動パフォーマンスの向上や\n筋骨格系損傷の予防に大きく利用されているものの，トレーニングの強度を定量化する方法はない．David\nらはこれらの問題を解決するため，トレーニングの強度を定量化した．スマートフォンの加速度計と2 つ\nのプラットフォームを使用し，骨盤の平均直線加速度と圧力中心の変位の平均速度を測定した．そこから\n得られた結果として，クラス内相関関係，測定標準誤差により評価した．実験の結果，ほとんどの体幹ト\nレーニング種目において骨盤加速度は中程度から高い信頼性スコアが得られ，圧心変位は低から中程度で\nあることが示された．スマートフォンの加速度計は体幹トレーニング強度を定量化するために信頼できる\nデバイスであると認識できた．今後の展望として，体幹トレーニングにおける安定性の状態を特定したり，\nトレーニングの改善に直接役立てることなどがあげられる．\n11\n図2.3: David Barbado らの実験\n森田らは加速度センサを用いた体幹トレーニング支援システムを開発した[26]．新型コロナウイルスの\n影響により，多くの人が自宅で過ごすようになった．そんな中，一人で気軽に始めることのできる「体幹\nトレーニング」に注目が集まっている．しかし，スポーツジムなどにおいてパーソナルトレーナーの指導\nのもとで行うトレーニングと比較して，個人で行う体幹トレーニングではその効果が著しく低下すること\nが考えられる．この問題を解決するため，森田らは加速度センサを用いて体幹トレーニングを支援するシ\nステムを実装した．提案手法はセンサを身体に装着し，センサから得られたデータをもとにスマートフォ\nンを介してフィードバックを行うというものである．また，フィードバックは画像の切り替えによって行っ\nている．評価実験の結果，アプリケーションの使用感と画像の切り替えによるフィードバックのアンケー\nトにおいて，78 ％の被験者が適切であったと回答した．そのため，本システムは非常に優れたユーザビリ\nティであることが示された．しかしながら，フィードバックが画像であるがゆえに，ユーザが下を向いてし\nまうことで姿勢が悪くなる場面があった．そのため，画像の切り替えに加え，新たなフィードバック方法を\n検討しなければならない．\n2.1.3\n習慣化するための支援手法\n濱谷らは，ソーシャルネットワーキングサービスでの繋がりを通じて，仲間との関わりを通じた習慣化支\n援技術について検討を行った[27]．具体的には，健康的な行動の目標を立てて，仲間から応援を受けること\nにより目標達成が支援されること，さらに，応援を受ける仲間との親密さに応じて，同じ応援１回でも目\n標達成後押しに対する効果が異なるという仮説を検証した．実際に大学生504 人の約3ヶ月半にわたる歩数\nデータ，歩数目標宣言データを取得し評価を行った結果，目標宣言を行うこと自体に歩数を増加させる効果\nがあること，目標宣言に対して応援を受けることで歩数が増加すること，および応援を受ける相手との過\n去のコミュニケーション履歴に応じて，歩数の増加効果の大きさに差異があることが示唆された．しかし，\n応援する機能なしによるユーザの長期的なトレーニング支援や他者との競争機能は用意されていない．ま\nた，個人のデータを閲覧するといった過去の個人データ振り返る機能には焦点を置いていない．\n12\n2.1.4\nモチベーションの維持・制御手法\n大手通信キャリアNTT ドコモ[28] が提供するd ヘルスケアは，毎日の歩数と体重の記録がポイントに\n変換される健康促進システムである[29]．このシステムは，ユーザーの健康維持に対するモチベーションを\n高めるための手法として，外発的な報酬を提供する．歩数や体重の記録により得られるポイントは，商品や\nサービスと交換でき，健康的なライフスタイルを維持するための動機付けとなる．しかし，一部のユーザー\nからは，外発的な報酬だけではなく，内発的な動機づけも重要との意見が出ている．内発的な動機づけと\nは，自己達成感や自己満足など，個人の内面からくる動機づけのことを指す．この考え方に基づくと，健康\n維持のための行動は，自分自身が健康でいたいという欲求から自然と起こるものであり，外部からの報酬だ\nけに頼るのではなく，自己の内面からの動機づけを高める支援も重要になる．この観点から，今後の健康促\n進システムの開発においては，ユーザーの内発的な動機づけを高める要素を取り入れることが求められる\nと考える．具体的には，自己達成感を得るための目標設定機能や，自己満足感を得るためのフィードバック\n機能などが考えられる．これらの機能を取り入れることで，ユーザー自身が健康維持のための行動を自然\nととるようになり，より持続的な健康促進が期待できる．\n双見らは，心理的影響を考慮した競争情報を用いたモチベーション制御手法を提案した[30]．まず日常の\n運動モチベーション向上を対象とし，競争においてモチベーションに影響する要因である，努力量に対する\n競争結果，競争相手との成績差，競争参加人数の3 点による心理的影響への配慮をシステム設計に内包さ\nせた競争システムを開発した．提案システムでは活動量計から得た歩数を基にして，モチベーションに良い\n効果を与えるように補正された競争結果がフィードバックされるというものである．プロトタイプシステム\nを用いた評価実験では，合計82 名の6 週間にわたる3 種類の実験を通して提示情報による歩数への効果を\n測定し，提案手法の有効性を確認した．\n2.2\n先行研究の課題と本研究の優位性\n先行研究として第2.1 節で述べたようなものがあげられる．それらに共通してみられる課題としてひとつ\nあげられるのが，トレーニングの支援として効果的なものであるのかどうかということである．特に長期\n的なフィードバック方法についてはもう少し検討しなければならない．\n本研究では加速度センサを用いて姿勢判定を行うことを前提として，姿勢判定方法およびフィードバック\n方法に着目し，システムの新規作成・有効性の検証を行った．画像の切り替えによるフィードバックだけで\nなく，テキスト表示によるフィードバックも追加した．さらに，長期的なトレーニング支援につなげる機能\nとして、これまでの自分のトレーニングデータを閲覧できる機能や遠隔地にいる他者との競争機能，push\n通知によるリマインド機能などを実装し，\n「W.I.L.-CoreMoni」を開発した．さらに，複数種目のトレーニン\nグに対応できるよう，システムの機能拡張にも努めた．\n本研究の優位性は，短期性と長期性の両方を兼ね備えたフィードバック機能である．これにより，短期\n間・長期間、一気通貫して体幹トレーニングに取り組むことができるだろう．\n長期的なトレーニング支援においては，金銭やポイントの付与といった外発的な要因による動機づけで\nはなく，本人のやる気やモチベーション維持などの内発的動機付けに着目した．エーテンラボ株式会社がリ\nリースした「みんチャレ[31]」は，読書の習慣化や体重の減少など同じ目標を目指すユーザが匿名で5 人集\nまり，チームで報告を行ったり，挑戦が途切れる日が続くとチームを脱退させられるなどの仕掛けにより習\n慣化を高める支援を行っている．しかし，個人間での競争や個人のトレーニングスコアを動機づけの種とし\nてモチベーションを維持・向上させる研究は未だ行われていない．\n本研究では，個人のトレーニングデータを閲覧する機能や他者との競争，リマインド機能を実装し，内発\n的動機付けに着目し，長期的なトレーニング支援の実現に努めた．本論文では，システムの有効性検証およ\nび本システムがトレーニングのモチベーション維持・向上にどのように貢献したかを論じる．\n13\n第3章\nW.I.L.-CoreMoniの全体像，概要および\n使用方法\n本章では，提案手法として本研究で開発したシステム「W.I.L.-CoreMoni」について詳しく論じる．第3.1\n節でW.I.L-CoreMoni の全体図，第3.2 節でW.I.L.-CoreMoni の概要（DB、機能、閾値値などについて）\nを，第3.3 節でW.I.L.-CoreMoni におけるデータの流れについて，第3.4 節でW.I.L.-CoreMoni の使い方\nについて述べる．\n3.1\nW.I.L-CoreMoni の全体像\n提案システムの全体図を説明すると共に本研究の立ち位置を俯瞰する．図3.1 に本研究で提案予定の体幹\nトレーニング支援システム「W.I.L.-CoreMoni」の全体概要図を示す。本システムの概要を大枠と細部に分\nけて見ていこう．\n図3.1: W.I.L.-CoreMoni の全体概要\n図3.2 に機能の大枠を示す．「W.I.L.-CoreMoni」は体幹トレーニング時のユーザの姿勢情報を取得する\n「センシング機能」とユーザに行動支援を提供する「フィードバック」の２つに分けて考えることができる．\n本研究においてはフィードバックの手法に焦点を置いているため，これに関して説明する．\n以前，短期性に焦点を置いた研究を行った（黄色枠線）．今回は長期性に焦点を置き研究を行った（赤色\n枠線）．この背景として，ユーザのトレーニング後の支援不足の解消があげられる．短期性のフィードバッ\nク機能を備えたシステムは，トレーニング時には有効であったものの，トレーニングを継続する動機づけに\nはつながらなかった．\n今回，長期性に重視したと述べたが，システムの機能としては短期的フィードバックと長期的フィード\nバックの両方を備えている．長期的フィードバックのフィードバック手法を考える材料として，外発的動機\n付けと内発的動機付けの２つが存在する[14]．第2.2 節でも先述したように，本研究においては内発的動機\n付けに焦点を当てて研究した．\n14\n図3.2: W.I.L.-CoreMoni の機能の大枠\n図3.3 に細部を示す．今回の研究においては内発的動機付けに焦点を置いているため，内発的動機付けの\nコンテンツを紹介する．第1.1.4 項で論じた内発的動機付けであるが，本動機付けを促進する機能として，\nトレーニングの振り返り機能（以下、トレーニングスタッツ）やオンライン上でのほかのユーザとの競争\n（以下、ランキング），通知機能などがあげられると考え，これらの機能を実装した（緑色枠線）．詳細に\nついては次章以降に論じる．\n図3.3: W.I.L.-CoreMoni の機能の細部\n3.2\nW.I.L-CoreMoni の概要\n本節ではシステムの概要について論じる．第3.2.1 項で短期的フィードバックであるセンシング機能につ\nいて，第3.2.2 項で骨格画像等表示機能について，第3.2.3 項で長期的フィードバック機能であるトレーニ\nングスタッツ閲覧機能について，第3.2.4 項で他者とのランキング機能について，第3.2.5 項で３日坊主防\n止リマインダ機能について論じる．\n3.2.1\nセンシング機能-短期的フィードバック-\n本項では，提案システムにおける短期的フィードバックであるセンシング機能について述べる．W.I.L.-\nCoreMoni は体幹トレーニングを自律的に行う上で重要となる姿勢監督の役割を担い，ユーザの体幹トレー\nニングを支援するものである．本システムは500 円玉くらいの大きさのウェアラブルデバイス（図3.4）と\nスマートフォン（図3.5）を使用したものである．９軸IMU による加速度データ，ジャイロデータ，磁力\nデータ，そして心拍数の取得が可能である「movesense（SUUNTO 社製）[32]」というデバイスを用いてい\n15\nる．movesense はエクササイズ用に最適化されたウェアラブルセンサである．重さは9.4g と小型軽量であ\nり違和感なく装着することが可能である．耐久性にも優れているため，スポーツなどのシーンで利用でき\nる．プロスポーツで使用されるウェアラブルセンサと比較して安価であるため，私たちのような一般ユーザ\nにも購入しやすい．\n本システムは，movesense から１秒間に13 個の加速度データを取得し，その一つ一つをあらかじめ定義\nした閾値と比較し，姿勢の良し悪しを判断している．ウェアラブルデバイスとスマートフォンはBluetooth\n通信で接続している．\n図3.4: ウェアラブルIMU “Movesense”（[32] より引用）\n図3.5: スマートフォン“ASUS X01AD”\nまた，体幹トレーニング中の「姿勢」を支援対象とし，より効果的な支援につながるよう搭載する機能に\n留意した．メインメニューを作成し，そこからトレーニング種目を選べるようにした．デザインや使いやす\nさにも工夫を施し，従来型システム「CoreMoni[26]」との差別化を図った．姿勢判定においては，より精\n度の高い判定ができるアルゴリズムを実装し，フィードバックにおいては，骨格画像による姿勢の画像切り\n替えによるものとその画像と連動して「HIGH」「GOOD」「LOW」の３種類のテキストをリアルタイムに\n表示するという２種類のフィードバックを用意した．\nさらに，上級者向けにX 軸，Y 軸，Z 軸方向の加速度の値も表示できるようにした．トレーニングを行\nう画面においては，トレーニング種目ごとにトレーニング方法と本システムの使い方，アドバイス等を明\n記した．\n図3.6 にシステムの構成図を示す．ユーザは腰に加速度センサを装着する．ユーザはスマートフォンの画\n面に表示された自分の現在の姿勢を俯瞰して見ることで，姿勢を正すことができるだろう(図3.7)．\n16\n図3.6: W.I.L.-CoreMoni の構成図\n図3.7: トレーニング中のデバイスの使用方法\n17\n加速度センサの装着位置に関してだが，森田らの実験[26] を参考にした．加速度センサを背中，腰，足\n首の３点に装着し，０秒～15 秒を正しい姿勢，15 秒～30 秒を腰が低い姿勢，30 秒～45 秒を腰が高い姿勢，\n45 秒～60 秒を連続的に変化のある姿勢として，１分間の体幹トレーニング（フロントプランク）を行って\nもらった．\nその結果，背中と足首に装着したセンサでは，加速度の値があまり変化しなかった（図3.8，図3.9）．し\nかし，腰に装着したセンサでは加速度の変化が見られた（図3.10）．特にY 軸に大きな変化があることが\n分かる．以上の結果から，加速度センサの装着位置は腰に選定した．\n図3.8: 背中の加速度の変化\n18\n図3.9: 足首の加速度の変化\n図3.10: 腰の加速度の変化\n19\n続いて，姿勢判定の原理となる閾値について論じる．まずはじめに，movesense における加速度センサの\n仕組みについて説明する．図3.11 に示すように加速度はX 軸，Y 軸，Z 軸の３軸に分けて考えることがで\nきる．実験および調査の結果，正面向かって左方向がX 軸（赤色矢印），下方向がY 軸方向（黄色矢印），\n円盤の裏側方向がZ 軸（緑色矢印）となることが分かった．\n図3.11: movesense における加速度の方向\n次に，腰の高さによって加速度の値がどのように変化するのかを説明する．腰の位置が高くなればなるほ\nど，Y 軸方向の加速度の値は小さくなり，Z 軸方向の加速度の値は緩やかに小さくなる．また，腰の位置が\n低くなればなるほど，Y 軸方向の加速度の値は大きくなり，Z 軸方向の加速度の値は緩やかに小さくなる．\n腰の位置が良いとされるときは腰の位置が高いとき・低い時のX 軸方向の加速度の値と同様，特に大きな\n変化はない．整理したものを図3.12 に示す．\n図3.12: ３軸加速度の変化の様子\n20\nさて，閾値の決定方法に関して説明する．\n「Azure Kinnect DK（Microsoft 社製）[21]」（図3.13）を用い\nて，インストラクター指導の下，腰の位置が高い時・良い時・低い時の姿勢を保ち，その時の骨格画像（順\nに図3.14，図3.15，図3.16）と床と腰のなす角をもとに閾値を決定した．調査の結果，床と腰のなす角は\nそれぞれ図3.17 のようになった．グラフ（図3.17）を見ると，腰の位置が高いとされるとき，13.5 °より\nも小さい値をとっていることが分かる．\nまた，腰の位置が低いとされるとき，20 °よりも大きい値をとっている．以上のことから，13.5 °以上20\n°以下を良い姿勢と定義した．良い姿勢の許容角度を表した模式図を図3.18 に記す．\n図3.13: Azure Kinect DK\n図3.14: 腰の位置が高い時のKinect 骨格画像\n21\n図3.15: 腰の位置が良い時のKinect 骨格画像\n図3.16: 腰の位置が低い時のKinect 骨格画像\n22\n図3.17: 腰の位置と角度の関係性\n図3.18: 模式図\n本システムでは，床に対して垂直方向に直立した状態でキャリブレーションを行うことを前提としてい\nる．そのため，キャリブレーション時の角度をa °，トレーニング中の角度をb °としたとき，閾値は次の\nようになる．\n＜HIGH ＞\nb◦−a◦< 13.5◦−90◦i.e. b◦−a◦< −76.5◦\n(3.1)\n＜GOOD ＞\n13.5◦−90◦≤b◦−a◦≤20◦−90◦i.e. −76.5◦≤b◦−a◦≤−70◦\n(3.2)\n＜LOW ＞\n20◦−90◦< b◦−a◦i.e. −70◦< b◦−a◦\n(3.3)\n23\n腰の位置が高い時，低い時，良い時の３姿勢それぞれにおいて具体的な数値を用いて図で説明する．\n• 腰の位置が高い時\nキャリブレーション時とトレーニング中のX 軸方向，Y 軸方向，Z 軸方向の加速度の値が表3.1 のよう\nになるとき，角度は表3.2 に記した通りになる．\n表3.1: x,y,z 軸の加速度の値\nx-axis acceleration\ny-axis acceleration\nz-axis acceleration\nCalibration Value(a)\n0\n9.52\n0.10\nCurrent Value(b)\n0\n-2.40\n9.63\n表3.2: 角度\nArctan(y/z)\ndegree\nCalibration Value(a)\n95.2\n89 °\nCurrent Value(b)\n-0.25\n-14 °\nこのとき，キャリブレーション時とトレーニング中の角度を図で表すと，図3.19 のようになる．数値を\n閾値判定の式に当てはめると，図中左下のようになり，判定は「HIGH」となる．\n図3.19: 加速度から算出された角度のグラフ画像\n24\n• 腰の位置が低い時\nキャリブレーション時とトレーニング中のX 軸方向，Y 軸方向，Z 軸方向の加速度の値が表3.3 のよう\nになるとき，角度は表3.4 に記した通りになる．\n表3.3: x,y,z 軸の加速度の値\nx-axis acceleration\ny-axis acceleration\nz-axis acceleration\nCalibration Value(a)\n0\n9.52\n0.10\nCurrent Value(b)\n0\n4.04\n9.25\n表3.4: 角度\nArctan(y/z)\ndegree\nCalibration Value(a)\n95.2\n89 °\nCurrent Value(b)\n0.44\n24 °\nこのとき，キャリブレーション時とトレーニング中の角度を図で表すと，図3.20 のようになる．数値を\n閾値判定の式に当てはめると，図中左下のようになり，判定は「LOW」となる．\n図3.20: 加速度から算出された角度のグラフ画像\n25\n• 腰の位置が良い時\nキャリブレーション時とトレーニング中のX 軸方向，Y 軸方向，Z 軸方向の加速度の値が表3.5 のよう\nになるとき，角度は表3.6 に記した通りになる．\n表3.5: x,y,z 軸の加速度の値\nx-axis acceleration\ny-axis acceleration\nz-axis acceleration\nCalibration Value(a)\n0\n9.52\n0.10\nCurrent Value(b)\n0\n3.36\n9.79\n表3.6: 角度\nArctan(y/z)\ndegree\nCalibration Value(a)\n95.2\n89 °\nCurrent Value(b)\n0.34\n19 °\nこのとき，キャリブレーション時とトレーニング中の角度を図で表すと，図3.21 のようになる．数値を\n閾値判定の式に当てはめると，図中左下のようになり，判定は「GOOD」となる．\n図3.21: 加速度から算出された角度のグラフ画像\n26\nなお，フロントプランクの姿勢において意識すべきことは以下のとおりである．\n1. 体全体を足から首筋まで，まっすぐ伸ばす．\n2. 腰を落とさない．\n3. 腰を上げすぎない．\n4. 肩を丸めない．\n5. 顔を下げない，上げない．\n6. 両肘は，両肩の真下に来るようにする．\n7. 両腕は，前方にまっすぐ伸ばす．\n上記の番号に対応したものを図3.22 に示す．\n図3.22: フロントプランクの姿勢において意識すべきこと\nサイドプランクにおいても同様の手順を踏み，実装を行った．注意すべき点としては，フロントプラン\nクが１つのセンサを装着するのに対し，サイドプランクでは２つのセンサを装着することである．しかし，\n本研究の実験においてはフロントプランクでの評価としたいため，サイドプランクにおける詳細の論述は\n省略する．図3.23 にサイドプランクの正しい姿勢時の骨格を掲載し，説明完了とする．\n図3.23: サイドプランク姿勢におけるKinect 骨格画像\n27\n3.2.2\n骨格画像等表示機能-短期的フィードバック-\n本項では，提案システムにおける短期的フィードバックである骨格画像表示機能について論じる．まず，\n姿勢判定の手法であるが，大きく３段階に分かれている．\n第１段階目は「キャリブレーション」である．キャリブレーションを行うことにより，各ユーザに応じた\n初期値を生成することが可能であるため，ユーザに依存する可能性を低減させることができるだろう．絶対\n的な基準を設けず相対的な基準を設けることは，ユーザを限定することなく，汎用性の観点から有効となる\nだろう．加速度センサのサンプリング数を13Hz に設定しているため，１秒間に13 個のデータが取得可能\nである．\nまた，キャリブレーションの実行時間を５秒に設定している．そのため，キャリブレーションを行うこと\nで65 個のサンプリングデータを取得することが可能である．初期値の選定においては外れ値が存在するこ\nとを考慮して，中央値を用いている．すなわち，昇順に並べ変えたデータの33 個目の値を用いている(式\n3.4)．その加速度を角度に変換（変換方法は前述）し，初期値に設定している．\nmedian in calibration = (65 sampled data sorted ÷ 2) + 1\n(3.4)\n第２段階目は「トレーニング中の角度の取得」である．Y 軸方向の加速度とZ 軸方向の加速度の値のアー\nクタンジェントを求め，求まったラジアンを度に変換し，角度を算出している(式3.5)．0.077 秒に１回の\n更新が行われるため，トレーニング中の角度をほぼリアルタイムに算出することが可能である．\nangle during training = arctan(Y axis acceleration value ÷ Z axis acceleration value)\n(3.5)\n第３段階目は「ずれの算出」である．第１段階で基準値，第２段階で暫定値を求める方法を説明した．姿\n勢判定を行う際は式3.5 と式3.4 の差を求めることで実現可能である．トレーニング中の角度がキャリブ\nレーション時の角度に対して5 °以上15 °以下の範囲（相対的な角度）に収まるとき，正しい姿勢と判定\nする．しかし，キャリブレーションは床に対して垂直方向に直立して行うことを前提としているため，π/2\nラジアンを考慮しなければならない．そのため，それぞれ90 °を引いて下記に示される式3.6，式3.7，式\n3.8 のようになる．\nhigh waist position : (angle during training −median in calibration) < −76.5◦\n(3.6)\ngood waist position : −76.5◦≤(angle during training −median in calibration) ≤−70.0◦\n(3.7)\nlow waist position : −70.0◦< (angle during training −median in calibration)\n(3.8)\n以上のようなアルゴリズムを用いて，体幹トレーニング中の姿勢を判定し，トレーニングの支援につなげ\nている．\n28\nここからは，具体的なフィードバック方法について紹介する．フィードバック要素としては，骨格画像を\nリアルタイムに表示するものと文字によって姿勢の状態変化を表示するものの２種類を作成した．\n従来型システムにおいて，イヤホンから音楽を流し，腰の高さによって音楽の周波数を変化させるフィー\nドバック方法があった[26]．しかしながら，今回この機能は排除した．音楽を聴きながらトレーニングを行\nうことは，集中力が高まる一方で筋肉の合成を阻害する可能性がある[33]．男性においては，音楽を聴くこ\nとでテストステロン[34] の分泌が抑えられるという研究結果が出ている．テストステロンは筋肉の合成に\nは欠かせない男性ホルモンである．しかしながら，女性の場合は逆に，音楽を聴くことでテストステロン\n値が上がるという結果が出ている．老若男女問わず誰でも使いやすいシステムを目指すため，音楽による\nフィードバックについては見直しが必要であると考え，音楽によるフィードバック機能を排除し，システム\nを作成し直した．\nまず，画像によるフィードバック方法について説明する．腰の位置が高い・良い・低いの３種類の画像を\nリアルタイムに切り替える仕組みになっている．使用している画像は骨格画像となっており，腰の位置が高\nいとき，低いときの代表例と良い姿勢の３つを「e-skin MEVA[35]」で撮影したものを使用している．その\nため，従来型システム[26] のように腰が高い・低いを伝えるだけでなく，どのように腰が高いのかを視覚\n的に認識することが可能である．\n次に，文字による姿勢の状態表示について説明する．トレーニング中の腰の位置に応じて「HIGH」「GOOD」\n「LOW」の文字を表示するというものである．一見シンプルなシステムに見えるかもしれないが，五感の\nうちの一つである視覚は人間の情報判断において87%の割合を占めている[36]．また，数値的に加速度の\n値を見たい上級者向けに，X 軸，Y 軸，Z 軸方向の加速度の値をリアルタイムに表示できるようにした．こ\nれにより，姿勢の良し悪しだけを見たい一般ユーザだけでなく，数値的なデータを客観的に見たい専門家ま\nで幅広いカテゴリーの人々に使っていただけるだろう．\n最後に，腰の位置（姿勢の良し悪し）に応じたスマートフォン上のフィードバック画面の例を図3.24，図\n3.25，図3.26 に示す．\n図3.24: 腰の位置が高い時\n図3.25: 腰の位置が良い時\n図3.26: 腰の位置が低い時\n29\n3.2.3\nトレーニングスタッツ閲覧機能-長期的フィードバック-\n本項では，長期的フィードバック機能の一つである「トレーニングスタッツ閲覧機能」について論じる．\n本機能は自身のトレーニング時の姿勢の良し悪し判定結果の割合を閲覧できる機能である．\n（図3.27 中央右）\n本機能を実装した目的は，ユーザのモチベーション維持を促進するためである．自身のトレーニングスタッ\nツを振り返ることのできるこの機能だが，加速度センサから得られた腰の角度の値をトレーニングセッショ\nンごとにFirebase（[37]）に送信し，アプリケーション上からFirebase に格納された情報を参照することで\n本機能を実現している．\nまた，データの保存方法だが，トレーニングを実施する画面に「データベースへ保存する」専用ボタンが\nあり，それを押下することでFirebase にデータを送信することができる. そのボタンの詳細は3.4 節で詳し\nく述べる．\n3.2.4\n他者とのランキング機能-長期的フィードバック-\n本項では，長期的フィードバック機能の一つである「他者とのランキング機能」について論じる．本機能\nは，同じアプリケーションを使用して体幹トレーニングを行っている人たちとオンライン上で対戦できる\nというものである．\n（図3.27 左下）本機能を実装した目的は，ユーザの競争心を刺激し，モチベーション向\n上を促進するためである．同じ体幹トレーニングを行っている他のユーザと自分のスコアを比較できるこ\nの機能だが，Firebase に送信された個人データをトレーニングセッションごとにFirebase 上でソートを行\nい、順位を表示することで本機能を実現している.\n図3.27: 長期的フィードバック（個人データ&ランキング）の概要図\n30\n3.2.5\n３日坊主防止リマインダ機能-長期的フィードバック-\n本項では，長期的フィードバック機能の一つである「３日坊主防止リマインダ機能」について論じる．本\n機能は，体幹トレーニングを３日間怠けた場合、そのユーザに対して「そろそろ体幹トレーニングに取り組\nみましょう！」という通知を発行するというものである．３日間トレーニングを怠った場合に通知する仕組\nみを考案したが，これはフィットネスジムを利用している人の多くが，週２回の頻度で通っているからであ\nる[38]．参照したデータによると，通っている頻度は「週2 回程度」「週1 回程度」「週3～4 回程度」の順\nに多いそうだ．\n図3.28: 長期的フィードバック（通知機能）の概要図\n31\n3.3\nW.I.L.-CoreMoni におけるデータの流れ\n本節では，提案システム「W.I.L.-CoreMoni」のデータの流れについて図3.29 に沿って論じる．ユーザは\n加速度センサであるmovesense を装着し，トレーニングを行う．movesense より，X,Y,Z 軸方向の加速度の\n値を取得する．取得された加速度の値はBluetooth で接続されているスマートフォンに送信され，スマート\nフォンに搭載されている自作アプリケーション内で角度に変換処理される．処理された角度のデータは，短\n期的フィードバックとして，姿勢判定処理されたのちに，ユーザに直接フィードバックとして提供される．\n同時に，Firebase へもデータが送信される．Firebase ではトレーニング種目やトレーニングセッション，\nユーザ情報などが格納されている. オンライン上で管理されているこれらの情報も，ランキング機能や自身\nのトレーニングスタッツ閲覧機能，通知機能の要素として，長期的フィードバックに活用されている. 小さ\nな加速度センサから得られた情報はマルチフィードバックとして，形を変えてユーザに還元されている構図\nとなる．\n図3.29: W.I.L.-CoreMoni におけるデータフロー\n32\n3.4\nW.I.L.-CoreMoni の使い方\n本節では，W.I.L.-CoreMoni の使い方について論じる．先にトレーニング時の利用手順について，次に\nトレーニング後の利用手順について論じる．\nトレーニング時のアプリケーションの利用手順は以下の通りである．\n1. W.I.L.-CoreMoni のアプリケーションを押下（図3.30）\n2. アプリケーションが起動する（図3.31）\n3. ログイン可能なユーザが一覧表示される（図3.32）\n4. 自身の名前を選択し，スタートボタンを押下（図3.33）\n5. ログインが完了する（図3.34）\n6. トレーニングメニューを選択する（図3.35）\n7. 位置情報へのアクセスを許可する（図3.36）\n8. デバイス検出・接続を許可する（図3.37）\n9. 再度，位置情報へのアクセスを許可する（図3.38）\n10. Connect ボタンを押下し，デバイスを接続する（図3.39）\n11. スキャン開始（図3.40）\n12. 接続試行（図3.41）\n13. センサの特定（図3.42）\n14. 接続完了（図3.43）\n15. キャリブレーションボタン押下（図3.44）\n16. キャリブレーションの開始（図3.45）\n17. ５秒後，キャリブレーション終了（図3.46）\n18. スタートボタン押下（図3.47）\n19. トレーニング&計測開始（図3.48）\n20. ストップボタン押下（図3.49）\n21. トレーニング&計測終了（図3.50）\n22. 画面下部のボタンを押下し，トレーニングデータをデータベースへアップロードする（図3.51）\nまた，図3.30～図3.51 に前述した手順ごとのアプリケーションの画面を示す．\n33\n図3.30: アプリケーション選択図3.31: アプリケーション起動\n図3.32: ユーザの一覧表示\n図3.33: ログインユーザの選択\n図3.34: ログイン完了\n図3.35: トレーニングメニュー\n34\n図3.36: 位置情報の許可\n図3.37: デバイス接続の許可\n図3.38: 位置情報の再許可\n図3.39: デバイスの接続\n図3.40: スキャン開始\n図3.41: 接続試行\n35\n図3.42: センサの特定\n図3.43: 接続完了\n図3.44: キャリブレーション\n図3.45: キャリブレーション開始図3.46: キャリブレーション終了\n図3.47: スタートボタン押下\n36\n図3.48: 計測開始\n図3.49: ストップボタン押下\n図3.50: 計測終了\n図3.51: データベースへ格納\n37\n次にトレーニング後のアプリケーションの利用手順について論じる．トレーニング後のアプリケーション\nの利用手順は以下の通りである．\n1. Activity Record ボタンを押下（図3.52）\n2. 閲覧したいコンテンツを選択（図3.53）\n3. 個人データの表示（図3.54）\n4. ランキングの表示（図3.55）\n5. ３日間トレーニングを怠けた際のロック画面に表示された通知（図3.56）\n6. ３日間トレーニングを怠けた際のコントロールセンターに表示された通知（図3.57）\n7. ３日間トレーニングを怠けた際のアプリケーションアイコンに表示された通知（図3.58）\nまた，図3.52～図3.58 に手順ごとのアプリケーションの画面を示す．\n図3.52: Activity Record\n図3.53: コンテンツ選択\n図3.54: 個人データ表示\n38\n図3.55: ランキング表示\n図3.56: 通知（ロック画面）\n図3.57: 通知\n（コントロールセンター）\n図3.58: 通知\n（アプリケーションアイコン）\n39\n第4章\nスコアリングによるモチベーション維持の\n検証（予備実験）\n本章では，自身のトレーニングスタッツ閲覧機能およびランキング機能を搭載したシステム（以下，ス\nコアリングと呼ぶ）を利用した場合とシステムを利用しなかった場合を比較した予備実験について論じる．\n第4.1 節では予備実験の目的について，第4.2 節では予備実験の方法について，第4.3 節では予備実験の手\n順について，第4.4 節では予備実験の分析方法について，第4.5 節では予備実験の結果について，第4.6 節\nでは考察や課題および今後の展望について述べる．\n4.1\n予備実験の目的\n本実験の目的は，スコアリング機能の有効性検証である．大きくまとめると以下の４つとなる．\n1. スコアリング機能の有無により，体幹トレーニングに及ぼす影響を調査し，スコアリング機能の有効\n性を検証すること．\n2. 本システムを使用することでトレーニングの継続を促すことができるのかを検証すること．\n3. システムなしとありを比較し、2 カ月後の姿勢変化を観察すること．\n4. システムのユーザビリティについて評価すること．\n4.2\n予備実験の方法\n本実験の条件について論じる．被験者は20 代-50 代の男女19 人（男性14 人，女性5 人）で行った．うち，\n現在も運動経験があるものが5 人，過去に習慣的にあったものが12 人，まったく運動したことのない人が\n2 人である．トレーニングの種目は予備調査で一番認知度の高かった「フロントプランク」とした．実験期\n間は２カ月間とし，実験の実施時間と場所は各被験者の任意とした．2 つのグループに分割した．GroupA\nはシステムを使用する群であり，GroupB はシステムを使用しない群である．各被験者には，実験が開始さ\nれる前と後に，２か月後の成果を評価するための参考値としてトレーニング時の腰の角度を計測した．ま\nた，システムの使いやすさを評価するためのSUS アンケートや継続に関するアンケートなどを用意した．\nなお，本実験にあたっては謝礼の存在を明らかにしないものとした．\n4.3\n予備実験の手順\n実験手順は以下のとおりである．\n＜A グループ＞\n1. 被験者に対する実験の説明．\n2. 同意書の記入（運動経験などの個人データ収集）．\n3. 実験キットの送付．\n40\n4. 実験前データの取得（実験監督者同伴）．\n5. 実験開始（２か月間）\n6. 実験後データの取得（実験監督者同伴）\n7. アンケート記入\n8. 実験キットの返送\n——————————————————————————————————————————————\n＜B グループ＞\n1. 被験者に対する実験の説明．\n2. 同意書の記入（運動経験などの個人データ収集）．\n3. 実験前データの取得（実験監督者同伴）．\n4. 実験開始（２か月間）\n5. 実験後データの取得（実験監督者同伴）\n6. アンケート記入\n4.4\n予備実験の分析方法\n4.4.1\nトレーニングスタッツ\n実験前と実験後に取得したスコアを比較し，２か月間の「体幹トレーニングにおける正しい姿勢を保持で\nきた割合」の変化を観察する．また，2 か月間を通して体幹トレーニングを何セッション継続することがで\nきたのかを分析する．\n4.4.2\nSUS アンケート\nSUS アンケートはSystem Usability Scale の略で，ジョン・ブルック（John Brooke）により1986 年に\n開発され，システムのユーザビリティの受け止められ方について測定するために最も広く利用されている\n質問票である[39][40]．このスケールは，1（まったくそう思わない）から5（まったくそう思う）の10 の\n記述から成り立っている．奇数項目の設問は肯定的な質問であり，偶数番号の設問は否定的な質問である．\n集計方法は，奇数番号の設問に対しては回答番号から１を引く．偶数番号の設問に対しては，５から回答番\n号を引く．そして，合計スコアに2.5 をかけて０から100 までのスケールに変換する．各スコアに対する評\n価の指標を図4.1 に示す．\nモチベーションに関する主観評価アンケート\nトレーニングを継続できた理由や継続できなかった理由を問う設問を用意した．今後もトレーニングを\n継続するためにどのようなサポートが必要であるかということも尋ねた．また，システムを使用せずに２\nか月間トレーニングをしたグループB の被験者に対しては，支援システムを使用してみたいかどうかを尋\nねた．このように，被験者の主観評価を問うアンケートを複数個用意した．\n41\n図4.1: SUS スコア指標（[39][40] から引用）\n4.5\n実験結果\n4.5.1\n実験前と実験後での正しい姿勢を維持できた時間の比較結果\n本節では，2 か月間のトレーニング成果を検証するために，システムを使用したグループと使用しなかっ\nたグループそれぞれの，正しい姿勢を維持できた割合を比較する．また，システムの姿勢判定における”\nGood ”の割合で算出した．本計測は実験前と2 か月後である実験後の計2 回おこなった．なお，システムの\n有無によるバイアスを無くすために，本計測においては，両グループともシステムを使用せずに計測した．\n表4.1 は2 か月間，体幹トレーニング支援システムを使用したグループの実験前と実験後のGood の割合\nである．9 人中5 人の割合が増加していることが分かる．Good のカウント回数が少なく，割合が高いスコ\nアが出ていることは，ブレずに正しい姿勢でトレーニングをすることができているということが言えるだ\nろう．一方で，表4.2 は体幹トレーニング支援システムを使用しなかったグループの実験前後のGood の割\n合であるが，10 人中8 人の割合が増加していることが分かる．センサの装着位置によって判定は異なって\nしまうため，一概には言えないが，本システムは2 か月間のトレーニングをするにあたっては，体幹トレー\nニング支援システムの有無によって，その後のユーザのトレーニング時の姿勢に影響を及ぼすとは考えに\nくいと結論付ける. なお，カッコ内の数値は姿勢判定においてGood の判定がなされた回数を示している.\n42\n表4.1: GroupA の実験前後データ\nUserID\n実験前データ\n実験後データ\n1\n3.95% (16)\n5.26% (20)\n2\n2.3% (9)\n0.26% (1)\n3\n0.26% (1)\n96.72% (383)\n4\n22.51% (86)\n24.55% (110)\n5\n75.13% (287)\n3.17% (12)\n6\n90.16% (0)\n0% (348)\n7\n0.26% (1)\n86.2% (331)\n8\n23.6% (93)\n39.1% (156)\n9\n84.95% (333)\n47.47% (188)\n表4.2: GroupB の実験前後データ\nUserID\n実験前データ\n実験後データ\n1\n1.31% (5)\n53.79% (213)\n2\n13.7% (53)\n97.4% (374)\n3\n0% (0)\n0.26% (1)\n4\n0.26% (1)\n1.04% (4)\n5\n0% (0)\n100% (1)\n6\n19.35% (83)\n1.51% (6)\n7\n0.26% (1)\n0% (0)\n8\n0.52% (2)\n3.05% (12)\n9\n0.25% (1)\n0.76% (3)\n10\n0% (0)\n79.76% (331)\n4.5.2\nSUS スコア\n本節ではSUS スコアの結果について考察する．スコアは表4.3 のとおりであり，スコア指標は図4.1 の\nとおりである．\n平均スコアは67.5 ポイントとなり，C スコアであった．あまり期待していた結果ではないものの，Good\nの評価となったため，本システムのユーザビリティは有効であると結論付けることができる．\n43\n表4.3: 得点データ\nUserID\nScore\n1\n52.5\n2\n70\n3\n80\n4\n67.5\n5\n57.5\n6\n77.5\n7\n80\n8\n57.5\n9\n65\n44\n4.5.3\n体幹トレーニングをおこなった頻度・継続性\n本節では継続性の観点からシステムの有効性を評価した結果を述べる．本実験はシステムを使用する\nGroupA とシステムを使用しないGroupB の２つのグループで行った．GroupA とGroupB の継続性を見\nる．図4.2 と図4.3 は２か月間の間に行った体幹トレーニングの継続頻度を示している．\nまた，週あたりの取り組み日数が３日以上を示す，赤系色の割合が多ければ多いほど期待通りの結果であ\nることを事前に提示しておく．\n図4.2: 体幹トレーニングの継続頻度(GroupA)\n図4.3: 体幹トレーニングの継続頻度(GroupB)\nこれらの円グラフを見ていこう．まずはGroupA について論じる．図4.2 は継続回数を継続日数で換算し\nた割合を示している. 週3.4 日以上取り組んだ割合は56%，週に1 日より少ない割合は33%となった．この\nことから，GroupA の被験者の半数以上が週3,4 日継続できたことがわかった（赤系色）．一方，図4.3 は\nGroupB の結果を示している．GroupB では，週3.4 日以上取り組んだ割合は0%であった．また，継続頻\n度が週に1 日より少ない割合は70%となっている．このことから，理想とする継続頻度である週3,4 日の割\n合が半数以上となったGroupA の有効性が検証された．GroupA はシステムを使用したグループであるた\nめ，本システムはモチベーションや継続の動機づけにポジティブな結果をもたらしていることが分かった．\n45\n次に，トレーニングを継続する際に，システム上のどのような機能が動機づけに起因したかについて調査\nしたアンケート結果を見ていこう．図4.4 のアンケート結果によると，\n「自身のトレーニング結果を閲覧でき\nる」「オンラインによる対戦機能」と回答された割合がそれぞれ55.6%となった．そのため，システムによ\nる継続の有効性が検証されたと考えることができる．しかし，\n「トレーニングを忘れないためのリマインダ\n機能が欲しい」「ランキングの変動がなかった」という声も上がった．今後，これらの要素を検討しなけれ\nばならないと感じた．\n図4.4: どのような機能が動機づけに起因したか\n最後に，そのほかに実施したアンケート結果を掲載する．今後も体幹トレーニングを継続したい感じる\nと回答したのは，GroupA が77.8%，GroupB が30%となった（図4.5，4.6）．この２カ月で健康的な体に\nなった・スタイルが良くなったと感じると回答したのは，GroupA が44.5%，GroupB が0%となった（図\n4.7，4.8）．\n図4.5: 今後も体幹トレーニングを継続したいか(GroupA)\n46\n図4.6: 今後も体幹トレーニングを継続したいか(GroupB)\n図4.7: この２カ月で健康的な体になった・スタイルが良くなったと感じるか(GroupA)\n図4.8: この２カ月で健康的な体になった・スタイルが良くなったと感じるか(GroupB)\n47\nシステムを使用しなかった被験者らに「体幹トレーニング支援システム」を使用してみたいか尋ねたとこ\nろ，70%が「使ってみたい」と回答した（図4.9）．彼らが本システムを使用した際にどのような結果が得\nられるか興味がある．\n図4.9: 本システムを使用してみたいか(GroupB)\n48\n4.6\n考察・課題・今後の展望\n本予備実験では，スコアリング機能を搭載した体幹トレーニング支援システムの開発および効果検証を\n行った．本システムは，トレーニング中の姿勢を視覚的にフィードバックすることで，適切な姿勢の維持を\nサポートする．また，競争心を掻き立てるランキング機能や個人の成果を確認できるデータ閲覧機能を実\n装し，ユーザのモチベーション向上に寄与することを目指した．実験には19 名の被験者を対象に，本シス\nテムを使用したトレーニングと，システムを使用しない通常のトレーニングを行った．その結果，本システ\nムを使用したトレーニングの方が，体幹の安定性と筋力が向上したことが確認された．また，被験者の自\n己評価によれば，システムの使用はトレーニングのモチベーション向上に寄与したという結果が得られた．\n以上の結果から，スコアリング機能を搭載した体幹トレーニング支援システムは，体幹トレーニングの効\n果向上とモチベーション維持に寄与する可能性が示された．\nしかし，今回の予備実験で課題が３つほど見つかった．１つ目は，デバイス装着位置のより詳細な選定で\nある．正しい姿勢でトレーニングを行えていたとしても，センサの装着位置によって若干のずれが生じてし\nまう．しかしながら，へその位置にベルトを装着することで問題は解消された．そのため，次回の実験では\n装着位置の説明を、実演を通して行いたい．\n２つ目はモチベーション維持のためのコンテンツ拡張である．今回実装した，ランキング機能とトレーニ\nング振り返り機能だけでは完全であるとは言えない．第4.5.3 節でも述べたが，トレーニングを忘れないよ\nうなリマインド機能があるとより良いと感じた．\n３つ目は被験者の選定である．今回の実験で募集した被験者は無作為に選んだ．そのため，属性もばらば\nらであり，正しい評価実験が行えていない．そのため，そもそもエクササイズに関心がないがゆえに，継続\nできないことも考えられる．\n今後の展望として，２か月の期間におけるリタイアのタイミングと被験者の属性などの解析を詳細に行\nい，モチベーショングラフの作成を行いたい．今後は，さらなる機能の追加やシステムの改善を行い，より\n効果的な体幹トレーニング支援を目指す．具体的には，より効果的なモチベーション維持のため，通知機\n能を実装することも考えている．さらに，今回募集した被験者は，無作為であるため，体幹トレーニング\nをしたいと考えている人ではない．トレーニングをしているがなかなか続かない人たちをターゲットにし，\nより詳細な研究を行いたい．そのため，被験者の選出も慎重に行いたいと考えている．\n49\n第5章\nスコアリング並びにリマインドによるモチ\nベーション維持の検証（本実験）\n本章ではスコアリング並びにリマインドによるモチベーション維持の検証について論じる．4 章でも述べ\nた通りだが、予備実験では自身のトレーニングスタッツとランキング機能のみだった。予備実験の結果を受\nけ，トレーニングを忘れないようなリマインド機能を実装し，本機能の有効性を検証した. 第5.1 節では本\n実験の目的について，第5.2 節では本実験の方法について，第5.3 節では本実験の手順について，第5.4 節\nでは本実験の分析方法について，第5.5 節では本実験の結果および考察について述べる．\n5.1\n本実験の目的\n本実験の目的は，リマインド機能の有効性検証である．大きくまとめると以下の３つとなる．\n1. リマインド機能の有無により，体幹トレーニングに及ぼす影響を調査し，リマインド機能の有効性を\n検証すること．\n2. 本システムを使用することでトレーニングの継続を促すことができるのかを検証すること．\n3. システムのユーザビリティについて評価すること．\n5.2\n本実験の方法\n本実験の条件について論じる．本実験は20 代から50 代の被験者８名で実施した．トレーニングの種目\nは予備調査で一番認知度の高かった「フロントプランク」とした．実験期間は2024 年11 月1 日から2024\n年11 月30 日の１か月間とし，実験の実施時間と場所は各被験者の任意とした．被験者には内密に２つのグ\nループに分割した．GroupA は最初の２週間通知がある群であり，GroupB は後半の２週間に通知がある群\nである．各被験者には，システムの使いやすさを評価するためのSUS アンケートや継続性・モチベーショ\nンに関するアンケートなどを用意した．\n5.3\n本実験の手順\n実験手順は以下のとおりである．\n＜A グループ＞\n1. 被験者に対する実験の説明．\n2. 同意書の記入（運動経験などの個人データ収集）．\n3. 実験キットの送付．\n4. 実験開始（１か月間：前半通知あり，後半通知なし）\n5. アンケート記入\n6. 実験キットの返送\n50\n——————————————————————————————————————————————\n＜B グループ＞\n1. 被験者に対する実験の説明．\n2. 同意書の記入（運動経験などの個人データ収集）．\n3. 実験キットの送付．\n4. 実験開始（１か月間：前半通知なし，後半通知あり）\n5. アンケート記入\n6. 実験キットの返送\n5.4\n本実験の分析方法\n5.4.1\nトレーニングの継続性\n１か月間にトレーニングをどのくらい継続できたのかをFirebase[37] のﬁrestore[41] を参照することで解\n析する．１か月間に取り組んだ日数と安定した継続頻度になっているかを検証する．\n5.4.2\nSUS アンケート\n前節で述べた通りの方法で解析を行う．また，SUS アンケートの質問文の例を掲示する．\n＜質問文＞\n1. このシステムをもっと頻繁に使用したい．\n2. このシステムは必要以上に複雑である．\n3. このシステムはシンプルで使いやすい．\n4. このシステムを使用するには技術的なサポートが必要.\n5. システムがスムーズに機能し，うまく統合されている.\n6. イレギュラーなことも多い.\n7. このシステムはほとんどの人がすぐに習得できる.\n8. このシステムは手間がかかる．\n9. このシステムの操作に自身がある．\n10. このシステムを使い始めるまでは学ぶことがたくさんある．\n5.4.3\nモチベーションに関する主観評価アンケート\nトレーニングを継続できた理由や継続できなかった理由を問う設問を用意した．提案システムに実装し\nた機能である３要素について，トレーニングを継続できた要因になっているかを問うこととした．１つ目は\n自身のトレーニングスコア，２つ目はランキング，３つ目は３日坊主防止プッシュ通知である．また，今後\nもトレーニングを継続するためにどのようなサポートが必要であるかということも尋ねた．\n51\n5.4.4\n道具性期待理論によるモチベーション評価\nユーザのトレーニング中のモチベーションを定量化するために，道具性期待理論[42] を用いてモチベー\nションを数値化する．道具性期待理論（Expectancy Theory）とは心理学や経営学において，動機付けを説\n明するための理論である．主にビクター・ブルームが提唱したもので，特に仕事や職場における人間の行動\nを理解する際に用いられる．この理論は，人が目標に向かって行動する動機を，次の３つの要因の掛け合わ\nせとして説明できる．\n１つ目は「期待（Expectancy）」である．努力をすれば成果が得られるという信念や確度の程度が定義と\nなる．例えば，\n「一生懸命勉強すれば試験に合格できる」と思えるかどうかなどがあげられる．影響を受け\nる要因としては，技術や知識，過去の成功体験などである．\n２つ目は「道具性（Instrumentality）」である．その成果が望む報酬や結果に結びつくと信じる度合いが\n定義である．例えば，\n「試験に合格すればよい仕事に就ける」という認識などがあげられる．影響を与える\n要因としては，報酬体系の透明性，上司や組織の公平性などである．\n３つ目は「誘意性（Valence）」である．得られる報酬や結果の価値や魅力が定義である．例えば，\n「良い\n仕事に就くことに価値を感じるかどうか」などがあげられる．影響を与える要因としては，個人の価値観や\n目標，欲求などである．\nこれら３つの要素を用いることで，動機づけは次の理論数式5.1 で定量化することが可能である．\n各要因のパラメータは0.0（設問に対して否定）から1.0（設問に対して肯定）までの間とし，算出した．\nMotivation = Expectancy × Instrumentality × V alence\n(5.1)\n52\n5.5\n本実験の結果と考察\n5.5.1\nトレーニングの継続頻度\n本項では１か月間で体幹トレーニングに取り組んだ頻度について論じる．表5.1 は通知機能が有効だった\n期間（半月）におけるユーザごとの平均インターバル日数・分散および標準偏差を示している．平均イン\nターバル日数というのは，トレーニング実施後，次にもう一度体幹トレーニングに取り組むまでの所要日\n数を意味している．いわゆる休息期間と認識していただければ幸いだ．\n被験者は次のトレーニングに取り組むまでに平均して３日ほどかかっている．すなわち，週に３～４日ほ\nど体幹トレーニングに取り組んだことがわかる．また，標準偏差に注目すると値が小さく，安定した頻度で\nトレーニングに取組めていたと推測できる．\n表5.1: 通知機能有効期間におけるユーザごとの平均インターバル日数・分散および標準偏差\nUserID\nAverage\nVariance\nStandard deviation\n1\n3.5\n2.3\n1.5\n2\n2.0\n0.0\n0.0\n3\n2.2\n0.1\n0.4\n4\n2.0\n—\n—\n5\n2.5\n0.3\n0.5\n6\n2.3\n0.2\n0.5\n7\n7.5\n6.3\n2.5\n8\n2.3\n0.6\n0.7\nAverage\n3.0\n—\n—\n一方で，表5.2 は通知機能が無効だった期間（半月）におけるユーザごとの平均インターバル日数・分散\nおよび標準偏差を示している．\n被験者は次のトレーニングに取り組むまでに平均して８日ほどかかっている．すなわち，週に１日も体幹\nトレーニングに取り組まなかった割合が高かったことがわかる．また，被験者３，７，８に注目してもらい\nたい．彼らは次のトレーニングに取り組むまでに約16 日間の休息期間を設けていたことがわかる．すなわ\nち，安定した頻度でトレーニングに取組むことができておらず，低頻度かつ不安定な継続頻度であったと推\n測できる．\n表5.2: 通知機能無効期間におけるユーザごとの平均インターバル日数・分散および標準偏差\nUserID\nAverage\nVariance\nStandard deviation\n1\n5.0\n13\n3.6\n2\n2.5\n0.3\n0.5\n3\n16\n—\n—\n4\n2.4\n0.2\n0.5\n5\n3.8\n1.2\n1.1\n6\n4.7\n1.6\n1.3\n7\n16\n—\n—\n8\n16\n—\n—\nAverage\n8.3\n—\n—\n53\n表5.3 は通知機能が有効時と無効時の両者における，被験者が次のトレーニングに取り組むまでの平均イ\nンターバル日数を比較した表である．\n全体的に，通知機能が有効であった期間のインターバル日数は少ない印象である．その一方で通知機能が\n無効であった期間のインターバル日数は比較的多い印象である．\nまた，被験者７においては両期間とも継続頻度が低い．これは被験者がたまたま繁忙期であったことが要\n因である．しかしながら，通知機能が有効な期間の方が無効な期間に比べて継続頻度が高くなっていたた\nめ，良い結果を得ることができたと考察できる．\n表5.3: 通知機能有効・無効別の次回トレーニングまでの平均インターバル日数\nUserID\nThe notiﬁcation enabled\nThe notiﬁcation disabled\n1\n3.5\n5.0\n2\n2.0\n2.5\n3\n2.2\n16\n4\n2.0\n2.4\n5\n2.5\n3.8\n6\n2.3\n4.7\n7\n7.5\n16\n8\n2.3\n16\nAverage\n3.0\n8.3\n表5.4 は通知機能が有効時・無効時の標準偏差を比較した表である．また，カッコ内の数字はトレーニン\nグの継続回数を表している．\n通知機能が有効であるときの標準偏差を見ると，0 に近い値が散見される．一般的に，標準偏差は値が０\nに近ければ近いほど平均値との差が小さく，データのばらつきが非常に小さいと判断できる．先ほども述べ\nたが，これは被験者が安定した継続頻度でトレーニングに取り組むことができた結果であると推測できる．\nまた，継続回数（体幹トレーニングに取り組んだ回数）が多ければ多いほど，同時に標準偏差の値も０に\n近くなっていることから，通知機能によって安定した継続頻度・回数で体幹トレーニングに取り組めていた\nことがわかる．\n一方で通知機能が無効であるときの標準偏差を見ると3.6 という大きな値が見られる．これはデータのば\nらつきが比較的大きいと判断できる．このことから，通知機能が無効の時，被験者の体幹トレーニングの継\n続頻度は低頻度かつ不安定であると結論付けることができる．\n表5.4: 通知機能有効・無効ごとの標準偏差比較による頻度安定性評価\nUserID\nThe notiﬁcation enabled\nThe notiﬁcation disabled\n1\n1.5(4)\n3.6(3)\n2\n0.0(3)\n0.5(4)\n3\n0.4(6)\n—(1)\n4\n—(1)\n0.5(5)\n5\n0.5(4)\n1.1(4)\n6\n0.5(6)\n1.3(3)\n7\n2.5(2)\n—(1)\n8\n0.7(6)\n—(1)\n結論として，通知機能が無効であった期間に比べて通知機能が有効であった期間の方が被験者の体幹ト\nレーニングの継続頻度が高く，安定した頻度であったため，期待していた「安定した継続頻度の実現」およ\nび「本システムの有効性」を検証することができた．\n54\n5.5.2\n短期的および長期的フィードバックにおけるSUS スコア\n本項では，本実験のSUS スコアの結果について論じる．表5.5 は短期的フィードバック機能に対するSUS\nスコアの結果である．８名の被験者のうち，６名の被験者がグレードC 以上となった．平均スコアは，74.1\nポイントであった．\nまた，表5.6 は短期的フィードバック機能に対するSUS スコアの結果である．８名の被験者のうち，６\n名の被験者がグレードC 以上となった．平均スコアは，76.0 ポイントであった．\n以上のことから，本システムにおける短期的，長期的の両フィードバックユーザビリティは有効であるこ\nとが分かった．しかし，一部の被験者においては，極度に低いユーザビリティであることも事実である．\n被験者１，３，５，６，７，８は短期的フィードバックおよび長期的フィードバックの両方に対し，高い\nスコアを提示した．一方で，被験者２，４は両フィードバックのユーザビリティに対し，D やF といった\n低めのスコアを提示した．彼らはシステムを使ってトレーニングすることが煩わしいと感想を残していた\nため，システムを使用してトレーニングを行うこと自体に抵抗があったと考える．\n全体として，良い結果を得ることができたと結論付ける．\n表5.5: 短期的フィードバックにおけるSUS スコア\nUserID\nScore\nGrade\n1\n95.0\nA+\n2\n12.5\nF\n3\n95.0\nA+\n4\n47.5\nF\n5\n82.5\nA\n6\n75.0\nB\n7\n90.0\nA+\n8\n95.0\nA+\nAverage\n74.1\nB\n表5.6: 長期的フィードバックにおけるSUS スコア\nUserID\nScore\nGrade\n1\n95.0\nA+\n2\n12.5\nF\n3\n95.0\nA+\n4\n52.5\nD\n5\n94.0\nA+\n6\n70.0\nC\n7\n92.5\nA+\n8\n95.0\nA+\nAverage\n75.8\nB+\n55\n5.5.3\nモチベーション維持に関する主観アンケート結果\n本項ではモチベーション維持に関する主観アンケート結果について論じる．図5.1 は，今回の実験にて使\n用したアプリケーションの機能について効果的であったものはどの機能であったかを尋ねたアンケート結果\nである．本アンケートでは，システムの使いやすさなどではなく，モチベーション維持に関連する機能につ\nいて，その機能がモチベーションを維持する上で効果的であったか・有効であったかを調査した．\n調査の結果，他者との競争（ランキング）機能が87.5%と高く，次いで通知（３日坊主防止）機能が62.5%\nとなり最後に自身のトレーニングスコア閲覧機能が25%となった．他者との競争（ランキング）機能はラ\nンキングがリアルタイムに変動するため，ほかの人に順位を抜かされないように，ランキングを日々チェッ\nクすると同時にトレーニングを続けるよう習慣づけることが可能であったためこのような結果になったと\n考えられる．通知（３日坊主防止）機能はユーザの意志に関係なく３日間トレーニングを行っていなかった\n場合，自動的に通知が送信される仕組みであるため，受動的なフィードバックとなり，ユーザにとって有効\n的なフィードバックとなったと考える．自身のトレーニングスコア閲覧機能に関して，本機能が最下位と\nなったのは他の２機能と異なり，自発的な意思がないと受けることのできないフィードバックであるからだ\nと考える．自身のトレーニングスコアは，自分から確認しようという意思がなければ閲覧できない．そのた\nめ，このような結果になったと考えられる．\n図5.1: どの機能が特に効果的だったかを尋ねたアンケート結果\n次に本実験の焦点である通知機能がどのくらい有効であったかを調査した結果について論じる．図5.2 は\n通知機能が有効であったか否かを尋ねたアンケートの結果である．アンケート調査の結果，被験者の75%\nが「有効である」と回答した．一方で，被験者の25%は「有効でない」と回答した．トレーニングの継続\n性が見られなかったユーザが含まれていたため，前提としてモチベーションが向上しなかったがゆえにシス\nテムは有効ではないと結論付けたと考える．\n最後に，トレーニング実施中の身体的コンディションについて調査した結果を掲載する．図5.3 はトレー\nニング中のフィジカルコンディションについて尋ねた結果である．被験者全員が「良い」または「普通」と\n回答したため，本実験に身体的な悪影響はなかったものと考えられる．\n56\n図5.2: 通知機能が効果的だったかを尋ねたアンケート結果\n図5.3: トレーニング中のフィジカルコンディションを尋ねたアンケート結果\n57\n5.5.4\n道具性期待理論に基づくモチベーション状態の評価\n道具性期待理論を検証するためのアンケートを集計し，期待値，道具性，誘意性について数値を算出し，\nモチベーション状態を数値化した．本項ではこれらの結果について論じる．\nトレーニングの実施に関係なく，普段の運動（体幹トレーニング）に対するモチベーションを数値化し\nた．その結果を表5.7 に示す．次にトレーニング時における体幹トレーニングに対するモチベーションを数\n値化した．その結果を表5.8 に示す．\nまず，表5.7 から見ていこう．数値が1 に近ければ近いほどモチベーションが高くなるのだが，0.5 未満\nの数値が目立つ．平均値は0.378 であり，お世辞にもモチベーションが高いとは言えない．しかし，表5.8\nをみると，0.5 や１といった１に近いまたは等しい数値が散見された．また，平均値も0.561 となっており，\n本システムを活用したことでモチベーションが相対的に向上したといえるだろう．\nその一方で，一部のユーザにおいてはモチベーションが下がってしまった．被験者４は継続性が低かった\nユーザである．本実験において，当該被験者のモチベーションが著しく低かったことが原因として考えるこ\nとができる．\n表5.7: 日常生活におけるユーザの体幹トレーニングに対するモチベーション\nUserID\nValue\n1\n0.252\n2\n0.648\n3\n0.420\n4\n0.500\n5\n0.288\n6\n0.126\n7\n0.648\n8\n0.140\nAverage\n0.378\n表5.8: トレーニング実施時におけるユーザの体幹トレーニングに対するモチベーション\nUserID\nValue\n1\n0.392\n2\n0.648\n3\n1.000\n4\n0.024\n5\n0.576\n6\n0.196\n7\n0.648\n8\n1.000\nAverage\n0.561\n58\n第6章\n本研究の結論および今後の展望\n本章では本研究の結論および今後の展望について論じる．新型コロナウイルスの影響による健康被害に\n着目し，運動不足や生活習慣病について議論した．健康な身体を維持するためには日常的な運動が必要で\nあり，人々が自主的に運動を継続することを心掛けることが重要である．\n一人で簡単に行うことのできるトレーニングに，体幹トレーニングというインナーマッスルを鍛えるト\nレーニング方法がある．このトレーニングは，スポーツ動作に求められる能力向上だけでなく，立つ・座\nる・歩く動作など，日常生活においても重要な役割を果たしている筋力を鍛えることができる．\nしかしながら，指導者なしでは正しい姿勢でトレーニングが行えていなかったり，監督者がいないことで\n怠けてしまうなどの懸念点がある．これらの懸念点を解消するため，私は体幹トレーニングにおけるユー\nザ向け支援システムを提案した．本システムはウェアラブルデバイスとスマートフォンの２つのデバイスで\n構成されており，この２つがあれば誰でも簡単に使用することが可能である．今回は，フロントプランクと\nいう体幹トレーニングの種目を実験対象とした．\n本システムは，加速度を取得することができる500 円玉くらいの大きさのウェアラブルデバイスを腰に\n装着し，スマートフォンの画面を見ながらトレーニングを行う．その際，システムがユーザによって異なる\n基準値を取得したのち，独自のアルゴリズムによって，取得した加速度を角度に変換し，トレーニング中の\n暫定値と比較後，あらかじめ定義した閾値との判定結果によってユーザにリアルタイムにフィードバックを\n与え，姿勢改善を促すというものである．また，モチベーション維持を目的とした長期的フィードバックも\n実装し，自身のトレーニング履歴閲覧機能をはじめ，ランキング機能による競争や３日坊主防止のための\nリマインド通知機能などを組み込み，本研究の対象機能とした．\n本実験では，20 代から50 代の男女８名で実施した，トレーニングの種目は予備実験の時と同様，\n「フロ\nントプランク」とした．実験期間は2024 年11 月1 日から2024 年11 月30 日の１か月間で行い，実験の実\n施時間と場所は各被験者の任意とした．被験者には内密に２つのグループに分割し，GroupA は最初の２週\n間，通知が有効でなる群であり，GroupB は後半の２週間に通知が有効でになる群である．各被験者には，\nシステムの使いやすさを評価するためのSUS アンケートや継続性・モチベーションに関するアンケートな\nどを用意した．\n本実験の結果，前章でも述べた通り，長期的フィードバックにおいて期待通りの結果を得ることができ\nた．特に長期的フィードバックの主要機能である「通知機能」「競争機能」「履歴閲覧機能」の有効性が検\n証された．３要素間に優劣の差はあるものの，結果として「継続頻度の向上」「安定したトレーニング継続\n回数」「モチベーションの維持・向上」の３点すべてにおいて期待通りもしくはそれ以上の結果を得ること\nができた．\n本研究の目的に対する結論は以下の通り：\n1. 短期的フィードバックの有効性を検証することができた．\n2. 長期的フィードバックの有効性を検証することができた．\n最後に，今後の展望について述べる．被験者に対し，トレーニングに取り組むうえで困難だったことはな\nにかを尋ねたところ，\n「加速度センサとスマートフォンの接続がうまくできない」という回答が散見された．\n本課題を解決すべく，別のセンサを用いてシステムを実装していくことも視野に，今後検討していきたい．\nまた，将来的にどのような機能があったらよいかを尋ねた結果，\n「ランキング変動時に通知がくるようにし\nてほしい」「目標の継続時間を達成したらポジティブなフィードバックを返してほしい」「音声によるフィー\nドバックがあればさらにいい」といった声があがった．本課題を解決すべく，さまざまなフィードバックの\n組み合わせを試行し，より良いシステムを構築していけたらと感じている.\n59\n謝辞\n本研究はJSPS 科研費JP22K11998 の助成を受けたものです．本研究を進めるにあたって，大学３年次\nから現在にかけて約４年間ご指導頂いた，青山学院大学理工学部情報テクノロジー学科教授Guillaume\nLopez 先生に深く感謝申し上げます．研究の方針や問題解決にあたってご指導いただいたこと，学業面と私\n生活両面でのアドバイスをしてくださったこと，心から感謝しております．\nさらに，事務手続きや研究室整備，展示会等のアシスタントを行ってくださった研究補助員の大熊ちひろ\nさまにも深く感謝申し上げます．\n最後に，日々お互いに意見し合った同期の皆さま，頼ってくれた後輩の大学院1 年生・大学4 年生，ラ\nボワーク参加の３年生の皆さまに感謝いたします．特に同期の平井氏にはシステムの開発面で多くのアドバ\nイスを頂きました．感謝いたします．\n2025 年1 月31 日\n佐藤圭翼\n60\n参考文献\n[1] 新型コロナウイルス感染症対策全国の感染者数内閣官房. https://www.caicm.go.jp/index.html.\n(Accessed on 06/28/2022).\n[2] 新型コロナウイルス感染対策スポーツ・運動の留意点と、運動事例について：スポーツ庁. https://www.\nmext.go.jp/sports/b_menu/sports/mcatetop05/jsa_00010.html. (Accessed on 06/28/2022).\n[3] 明治安田生命「健康」に関するアンケート調査を実施！https://www.meijiyasuda.co.jp/profile/\nnews/release/2021/pdf/20210906_01.pdf. (Accessed on 06/28/2022).\n[4] 次期国民健康づくり運動プラン策定専門委員会厚生科学審議会地域保健健康増進栄養部会. 健康日本２１\n（第２次）の推進に関する参考資料. https://www.mhlw.go.jp/bunya/kenkou/dl/kenkounippon21_\n02.pdf. (Accessed on 06/28/2022).\n[5] 経済産業省. フィットネスクラブの動向. https://www.meti.go.jp/statistics/tyo/tokusabido/\nsanko/pdf/hv58_02j.pdf. (Accessed on 06/28/2022).\n[6] 谷本道哉. 体幹トレーニングの流行の背景と効果に関する考察. 理学療法-臨床・研究・教育, Vol. 27,\nNo. 1, pp. 3–9, 2020.\n[7] 鈴木雄貴, 桜井伸二. 体幹トレーニングが体幹の安定性とジャンプパフォーマンスに与える影響の検\n討. 中京大学体育研究所紀要= Bulletin of Research Institute of Health and Sport Sciences, Chukyo\nUniversity, No. 32, pp. 31–36, 2018.\n[8] 藤本鎮也, 吉田一也, 佐藤慎一郎, 秋山純和. 体幹と理学療法. 理学療法-臨床・研究・教育, Vol. 20,\nNo. 1, pp. 7–14, 2013.\n[9] 体幹を鍛えるための10 種のトレーニングメニュー【プロが教える筋トレ】— oricon news. https:\n//www.oricon.co.jp/special/58258/. (Accessed on 06/12/2024).\n[10] 木場克己. Dvd で鍛えるプロトレーナー木場克己の体幹パフォーマンスアップメソッド. pp. 72–73, 4\n2012.\n[11] 木場克己. Dvd で鍛えるプロトレーナー木場克己の体幹パフォーマンスアップメソッド. pp. 74–75, 4\n2012.\n[12] 木場克己. Dvd で鍛えるプロトレーナー木場克己の体幹パフォーマンスアップメソッド. pp. 92–93, 4\n2012.\n[13] 鈴木未紗. やる気を高めるには「承認」～内発的動機付け・マズローの欲求段階説より考える～—\nhabi*do（ハビドゥ）. https://habi-do.com/blog/intrinsic-motivation-approval/. (Accessed\non 11/30/2023).\n[14] 株式会社LAFOOL.\nビジネスにおいてやる気を引き出す動機付けとは？効果的な方法を紹介-\nwell-being workers. https://survey.lafool.jp/mindfulness/column/0028.html. (Accessed on\n11/30/2023).\n61\n[15] 産経新聞.\n【今週の注目記事】長続きしないフィットネスジム、楽しければ…まるでディ\nスコ、娯楽型が急増（3/3 ページ）\n-\n産経ニュース.\nhttps://www.sankei.com/article/\n20180929-SIISHCV7ARKYBIYOXLXKPEMDAI/3/. (Accessed on 06/12/2024).\n[16] 24 時間フィットネスジムVERUS. スポーツジムの継続率ってどれくらい？続けるためのコツも紹介—\nverus-ヴェルス— 栃木県宇都宮市24 時間365 日営業フィットネスジム. https://verus-gym.com/\ncolumn/retention-rate/. (Accessed on 06/12/2024).\n[17] 株式会社カオナビ. アンダーマイニング効果とは？例、エンハンシング効果- カオナビ人事用語集.\nhttps://www.kaonavi.jp/dictionary/undermining_koka/. (Accessed on 06/12/2024).\n[18] 綿谷惇史. カメラ画像を用いた体幹トレーニングの姿勢支援手法の提案. https://dspace.jaist.\nac.jp/dspace/bitstream/10119/15832/5/paper.pdf, 03 2019. (Accessed on 07/10/2024).\n[19] 高久大輔中島克人. Kinect を用いた筋力トレーニング支援システム. https://ipsj.ixsq.nii.ac.\njp/ej/?action=pages_view_main&active_action=repository_view_main_item_detail&item_\nid=164408&item_no=1&page_id=13&block_id=8, 03 2015. (Accessed on 07/10/2024).\n[20] 岡本勝礒村智将松原行宏.\n姿勢推定手法を活用したリアルタイム運動訓練支援環境.\nhttps:\n//www.jstage.jst.go.jp/article/pjsai/JSAI2016/0/JSAI2016_1C4OS13a1/_pdf/-char/ja,\n2016. (Accessed on 07/10/2024).\n[21] Microsoft.\nAzure\nkinect.\nhttps://www.microsoft.com/ja-jp/d/azure-kinect-dk/\n8pp5vxmd9nhq?activetab=pivot:%E6%A6%82%E8%A6%81tab. (Accessed on 07/10/2024).\n[22] 村田嘉利\n永澤修平鈴木彰真.\nKinect を用いた体幹のリハビリテーション支援システム.\nhttps://ipsj.ixsq.nii.ac.jp/ej/?action=pages_view_main&active_action=repository_\nview_main_item_detail&item_id=104949&item_no=1&page_id=13&block_id=8, 07 2014.\n(Ac-\ncessed on 07/10/2024).\n[23] Inter Reha. Vicon — モーションキャプチャ— 三次元動作分析システム. http://www.vicon.jp/.\n(Accessed on 07/10/2024).\n[24] 高田将志中村優吾藤本まなと荒川豊安本慶一. 体幹トレーニング支援に向けたウェアラブルデバ\nイスによる種目認識手法の提案. https://ipsj.ixsq.nii.ac.jp/ej/?action=pages_view_main&\nactive_action=repository_view_main_item_detail&item_id=186775&item_no=1&page_id=\n13&block_id=8, 03 2018. (Accessed on 07/10/2024).\n[25] Amaya Prat-Luri Mar´ıa Pilar Garc´ıa-Vaquero Francisco J. Vera-Garcia David Barbado, Belen Irles-\nVidal. Training intensity quantiﬁcation of core stability exercises based on a smartphone accelerom-\neter — plos one.\nhttps://journals.plos.org/plosone/article?id=10.1371/journal.pone.\n0208262, 12 2018. (Accessed on 07/10/2024).\n[26] 森田大喜. 加速度センサを用いた体幹トレーニング支援システム. http://www.wil.it.aoyama.ac.\njp/abstract/DaikiMORITA_a.pdf, 01 2021. (Accessed on 07/10/2024).\n[27] 濱谷尚志落合桂一山田渉檜山聡白井拓也荒川豊. 目標宣言共有型プラットフォームを用いたソーシャ\nルナッジの量的質的効果の評価. https://ipsj-bti.github.io/proceedings/202303/pdf/bti03_\n05.pdf, 03 2023. (Accessed on 07/10/2024).\n[28] エヌ・ティ・ティ・ドコモ. https://www.docomo.ne.jp/. (Accessed on 07/10/2024).\n[29] d ヘルスケア｜毎日の歩数がd ポイントに！https://health.docomo.ne.jp/.\n(Accessed on\n07/10/2024).\n62\n[30] 双見京介寺田努塚本昌彦.\n心理的影響を考慮した競争情報フィードバックによるモチベーシ\nョン制御手法.\nhttps://ipsj.ixsq.nii.ac.jp/ej/?action=pages_view_main&active_action=\nrepository_view_main_item_detail&item_id=190072&item_no=1&page_id=13&block_id=8, 06\n2017. (Accessed on 07/10/2024).\n[31] みんチャレ- 三日坊主防止アプリ— みんチャレは専門家監修のもとに作成された、5 人1 組で続ける\n「習慣化アプリ」です。https://minchalle.com/. (Accessed on 07/10/2024).\n[32] Wearable sensor ― movesense. https://www.movesense.com/. (Accessed on 09/29/2022).\n[33] Is background music during training counterproductive?!\nhow music aﬀects muscle training —\ncompare recommended gyms! sports gym fan club（fanclub）(in japanese). https://sportsgym-fc.\ncom/music/. (Accessed on 07/20/2022).\n[34] About testosterone｜daito pharmaceutical industry co., ltd. (in japanese). https://www.daito-p.\nco.jp/reference/testosterone.html. (Accessed on 07/20/2022).\n[35] motion capture suit「e-skin meva」— imu sensor welfare equipment creact of manufacturing. https:\n//www.creact.co.jp/item/measure/mocap/meva/meva-top. (Accessed on 10/02/2022).\n[36] red cross sendai (in japanese). http://www.sendai.jrc.or.jp/info/sendai/no85/04.html. (Ac-\ncessed on 10/02/2022).\n[37] Firebase. https://firebase.google.com/?hl=ja. (Accessed on 11/02/2024).\n[38] スポーツジムの継続率ってどれくらい？続けるためのコツも紹介. https://verus-gym.com/column/\nretention-rate/. (Accessed on 11/11/2024).\n[39] System usability scale - wikipedia.\nhttps://en.wikipedia.org/wiki/System\\_usability\\\n_scale. (Accessed on 11/18/2022).\n[40] The system usability scale:\nPast,\npresent,\nand future.\nhttps://www.researchgate.net/\npublication/324116412_The_System_Usability_Scale_Past_Present_and_Future.\n(Accessed\non 01/14/2025).\n[41] ﬁrestore. https://firebase.google.com/docs/firestore?hl=ja. (Accessed on 12/12/2024).\n[42] 職務モテイベーションに関する期待理論. https://www.jstage.jst.go.jp/article/jjesp1971/\n14/2/14_2_147/_pdf. (Accessed on 12/12/2024).\n63\n付録\n付録A 本研究に関する論文誌投稿および学会発表の実績\n• 国際論文誌・国際ジャーナル\nMay 27th, 2024\nKeisuke Sato, Guillaume Lopez\n”Eﬀect of Real-Time Feedback on Posture Improvement during Core Training”\nInternational Journal of Activity and Behavior Computing\nURL https://www.jstage.jst.go.jp/article/ijabc/2024/1/2024 15/ article/-char/en\nJune 16th, 2024\nKeisuke Sato, Guillaume Lopez\nCoreMoni-α: Consideration of Long-Term Feedback Methods in Core Training\nInternational Journal of Activity and Behavior Computing\nURL https://www.jstage.jst.go.jp/article/ijabc/2024/2/2024 28/ article/-char/en\n• 査読有り\n2022 年10 月\nAmi Jinno, Keisuke Sato, Anna Yokokubo, Guillaume Lopez\n“ Real-Time Feedback System for Eﬃcient Core Training ”\nThe International Conference on Activity and Behavior computing 2022 @University of East London\n2023 年9 月\nKeisuke Sato, Guillaume Lopez\n“ Eﬀect of Real-Time Feedback on Posture Improvement during Core Training ”\nThe International Conference on Activity and Behavior computing 2023 @Deutsches Forschungszentrum\nf¨ur K¨unstliche Intelligenz Kaiserslautern\n2023 年10 月\nKeisuke Sato, Guillaume Lopez\n“ Inﬂuence of Feedback Modality in Core Training Support System ”\nThe International Conference on Informatics, Electronics ＆Vision 2023 @University of East London\n2024 年5 月\nKeisuke Sato, Guillaume Lopez\n“ CoreMoni-α: Consideration of Long-Term Feedback Methods in Core Training ”\nThe International Conference on Activity and Behavior Computing 2024 @ Kitakyusyu ＆Nakatsu\n64\n• 査読無し\n2022 年7 月\n神野亜美，佐藤圭翼，横窪安奈，ロペズギヨーム\n“ CoreMoni：体幹トレーニングにおける効果的な姿勢促進システム”\n一般社団法人情報処理学会マルチメディア，分散，協調とモバイルシンポジウム2022 @Online\n2023 年3 月\n佐藤圭翼, ロペズギヨーム\n“ CoreMoni-α：効果的な体幹トレーニングのための短期的フィードバックシステム”\n一般社団法人情報処理学会行動変容学研究G 研究会2023 @九州大学\n2023 年7 月\n佐藤圭翼，ロペズギヨーム\n“ CoreMoni-α：効果的な体幹トレーニングのための短期的フィードバックシステム”\n情報処理学会マルチメディア、分散、協調とモバイルシンポジウム2023 @富山国際会議場\n2024 年6 月\n佐藤圭翼，ロペズギヨーム\n“ CoreMoni-α: Consideration of Long-Term Feedback Methods in Core Training ”\n一般社団法人情報処理学会マルチメディア、分散、協調とモバイルシンポジウム2024 @花巻温泉\n65\n付録B 本研究の実験に使用した研究同意書\n図6.5 から図6.10 までは予備実験の，図6.11 から図6.14 までは本実験の研究同意書である．\n図6.1: 予備実験の同意書（1/10）\n66\n図6.2: 予備実験の同意書（2/10）\n67\n図6.3: 予備実験の同意書（3/10）\n68\n図6.4: 予備実験の同意書（4/10）\n69\n図6.5: 予備実験の同意書（5/10）\n70\n図6.6: 予備実験の同意書（6/10）\n71\n図6.7: 予備実験の同意書（7/10）\n72\n図6.8: 予備実験の同意書（8/10）\n73\n図6.9: 予備実験の同意書（9/10）\n74\n図6.10: 予備実験の同意書（10/10）\n75\n図6.11: 本実験の同意書（1/5）\n76\n図6.12: 本実験の同意書（2/5）\n77\n図6.13: 本実験の同意書（3/5）\n78\n図6.14: 本実験の同意書（4/5）\n79\n図6.15: 本実験の同意書（5/5）\n80\n付録C 質疑応答内容\nQ.（工藤）本実験において，想定では毎日続けるのが良いということなのか．\nA.（佐藤）いいえ．本研究においては，文献調査のもと，３日に１回行えていれば可としている．\nQ.（工藤）三日坊主の防止ではなく，24 時間やっていなかったら通知するようなシステムの方が良いの\nではないか．\nA.（佐藤）健康の観点から，毎日続けることが必ずしも良いとは断定できない．疲労骨折などの副次的\nな悪影響が考えられる．また，将来的にシステムを使わずにトレーニングを続けるようになってもらうこと\nが目標であるため，強制的に頻繁にトレーニング催促を行うことで，かえってモチベーションが低下してし\nまい，本末転倒になってしまう可能性が懸念される．\nQ.（工藤）結果として，続くようになっているのか．\nA.（佐藤）はい．しかしながら，一部の被験者においては続かなかった．この被験者は最後のアンケー\nト記述で「そもそもシステムを使ってトレーニングを続けることが煩雑である」と述べたため，そもそもシ\nステムを使用すること自体に抵抗があったと考えられる．\nQ.（工藤）「姿勢推定+3 日坊主防止機能を備えたトレーニングアプリケーションを使って被験者実験を\nした」という研究だと捉えているが，その認識で合っているか？その場合，技術的な新規性はどこにあたる\nのか？姿勢推定を使ったトレーニングアプリケーション研究は結構ありそうだが，紹介されていた関連研究\n以外を踏まえて，研究自体の新規性を改めて論じてほしい．\nA.（佐藤）本研究に取り組むまでは，世の中にたくさんあると感じていた．しかし，調査していく中で，\n何かの要素（姿勢判定）が完璧であっても，別の要素（フィードバック）になんらかの課題が生じている\n関連研究が散見された．本研究の新規性は主に４つの観点から考えることができる．１点目はリアルタイ\nムの姿勢判定およびリアルタイムフィードバックである．体幹トレーニングに限らず，トレーニングの姿\n勢の良し悪し判定をリアルタイムに行い，即時にユーザにフィードバックを与えるシステムは存在しない．\n２点目は通知のタイミングである．24 時間に１回のタイミングやランキング変動時にユーザに通知を送信\nする機能はすでに存在しているが，72 時間のタイミングで通知を送る体幹トレーニング支援システムはな\nいと認識している．３つ目は短期的・長期的フィードバックの両方を搭載している点である．短期的フィー\nドバックや長期的フィードバックの単体システムは存在するものの複合的なシステムは散見されない．４つ\n目は特殊なアルゴリズムにより，加速度センサひとつで角度を算出し，姿勢判定につなげている点である．\nQ.(D¨urst)Do people learn the best posture for your training after some time, or is it necessary to use\nyour system for years because it is easily possible to fall back into a bad posture? For a front plank, did\nyou only check the position of the hip? I ’d assume even if the hip is positioned correctly, the back could\nbe in a bad position and should be corrected.\nA.(Sato)The former is correct. The goal of this research is to be able to continue training in the correct\nposture without using the system in a few years. You’re right. In the future, I would like to equip multiple\nsensors to make the system more accurate.\n81\n",
        "chunks": [
            "M2024_Keisuke_Sato. M2024_Keisuke_Sato. M2024_Keisuke_Sato",
            " \n \n \n \n \n青  山  学  院  大  学 \n \n理  工  学  研  究  科 \n \n \n \n理工学専攻    知能情報    コース \n \n \n \n \n修  士  論  文 \n \n \n \n       学 生 番 号    ３５６２３２３３      \n \n \n       氏     名      佐 藤  圭 翼        \n \n \n研究指導教員    ロペズ・ギヨーム       \n \nW.I.L.-CoreMoni\n短期的および長期的な複合支援による体幹トレーニングの\n姿勢向上とモチベーション維持効果の検証\n佐藤圭翼\n2025/01/31\nThe Academic Year of 2024, Submitted on January 31st, 2025 \n \nGraduate School of Science and Engineering, Aoyama Gakuin University \n \nTitle: W.I.L.-CoreMoni \nVerification of The Effects of Short-Term and Long-Term",
            "ication of The Effects of Short-Term and Long-Term Combined Support for \nImproving Posture and Maintaining Motivation during Core Training \n \nStudent Name: Keisuke Sato  \nID Number: 35623233   \nDegree: Master of Engineering \nCourse: Intelligence and Information \nThesis Advisor: Professor Guillaume Lopez \n \nAbstract  \nDue to the COVID-19 pandemic, lack of exercise has become a concern. We focused on \ncore training, which can be done alone anytime, anywhere. However, maintaining \nproper posture du",
            " anywhere. However, maintaining \nproper posture during training is challenging, and low motivation often leads to \ninconsistency. \nTo address these issues, we developed the W.I.L.-CoreMoni system to support posture \ncorrection and motivation. The system consists of a coin-sized wearable accelerometer \nand a smartphone. Users attach the sensor to their waist and train while checking the \nsmartphone screen. The system collects individual baseline values, converts \nacceleration data into angles, an",
            "alues, converts \nacceleration data into angles, and compares the posture in real-time against predefined \nthresholds, providing immediate feedback for correction. \nAdditionally, three long-term feedback features were implemented: \n \n1. Training History: Allows users to review past sessions. \n2. Ranking System: Enables competition with others online. \n3. Reminder Notifications: Alerts users when they miss training for a certain period. \n \nTo evaluate the system, we conducted a one-month experimen",
            "ate the system, we conducted a one-month experiment with eight participants \n(ages 20–50) performing front plank exercises. Participants trained at their preferred \ntime and location. They were divided into two groups: Group A received notifications in \nthe first two weeks, while Group B received them in the latter two weeks. Usability \n(SUS) and motivation surveys were conducted. \nResults showed that long-term feedback increased training frequency and consistency \nwhile maintaining motivation. ",
            "cy and consistency \nwhile maintaining motivation. The effectiveness of the history, ranking, and notification \nfeatures was confirmed, demonstrating their role in improving training frequency, \nstability, and motivation. \nFor future improvements, we plan to explore alternative sensors for smoother \nsmartphone connectivity. Additionally, in response to user requests, we aim to \nimplement real-time ranking notifications and voice-based feedback to enhance \nmotivation. \n \n理工学専攻修士論文要旨 \n \n \n提出年度\n    ",
            "enhance \nmotivation. \n \n理工学専攻修士論文要旨 \n \n \n提出年度\n      ： 2024 年度 \n提\n出\n日\n      ： 2025 年 1 月 31 日 \n専修コース： 知能情報コース \n学生番号\n      ： 35623233 \n学生氏名\n      ： 佐藤 圭翼 \n研究指導教員： ロペズ ギヨーム 教授 \n \n（論文題目） \nW.I.L.-CoreMoni： \n短期的および長期的な複合支援による体幹トレーニングの姿勢向上とモチベーション維持効果の検証 \n \n（内容の要旨） \n新型コロナウイルスの影響により，運動不足の問題を指摘し，一人で手軽に取り組むことのできる体\n幹トレーニングに注目した．体幹トレーニングは場所を選ばず，好きな時間や場所で取り組むことがで\nきる一方，トレーニング中の姿勢が正しいかどうかの判定は難しい．また，モチベーションが維持でき\nないことでトレーニングを継続できず，結果として３日坊主になってしまうなど様々な問題点があげら\nれる． \nこれらの課題を解決すべく，トレーニング中の姿勢支援およびモチベーションの維持向上を目的とし\nて，",
            " \nこれらの課題を解決すべく，トレーニング中の姿勢支援およびモチベーションの維持向上を目的とし\nて，体幹トレーニング支援システム「W.I.L.-CoreMoni」を構築した．本システムは，加速度を取得する\nことができる500 円玉くらいの大きさのウェアラブルデバイスとスマートフォンで構成されている．ユ\nーザは加速度センサを腰に装着し，スマートフォンの画面を見ながらトレーニングを行う．その際，本\nシステムがユーザによって異なる基準値（初期値）を取得したのち，独自のアルゴリズムによって，取\n得した加速度を角度に変換し，トレーニング中の暫定値と比較後，あらかじめ定義した閾値との判定結\n果によってユーザにリアルタイムにフィードバックを与え，姿勢改善を促すというものである． \nまた，モチベーション維持を目的とした長期的なフィードバック機能を３つ実装した． \n \n① 「トレーニング履歴閲覧機能」：これまでのトレーニングデータを閲覧する仕組みを提供 \n② 「ランキング機能」：同じトレーニングに取り組む人とオンライン上で競争することを提供 \n③ 「３日坊主防止通知機能」：一定期間トレーニングに取り組ん",
            "人とオンライン上で競争することを提供 \n③ 「３日坊主防止通知機能」：一定期間トレーニングに取り組んでいない際に，自動的に通知 \n \n本システムの有効性を評価するため実験を行った．20~50 代の男女８名を被験者とし，１か月の間，\n体幹トレーニングの種目のひとつである「フロントプランク」の姿勢でトレーニングに取り組んでもら\nった．実験の実施時間と場所は各被験者の任意とした．被験者には内密に，２つのグループに分割し，\nGroup A は最初の２週間，通知機能を有効にし，Group B は後半の２週間，通知機能を有効にした．\n各被験者には，システムの使いやすさを評価する SUS アンケートと，継続性・モチベーションに関す\nるアンケートを用意した． \n実験の結果，長期的なフィードバックによって継続頻度が向上し，安定した頻度でトレーニングに取\nり組めていたことが分かった．同時に，被験者のモチベーションが高かったという結果を得ることがで\nきた．したがって，長期的なフィードバックにおいて期待通りの結果を得ることができたと結論付ける\nことができる．特に長期的なフィードバックの主要機能である「履歴閲覧",
            "果を得ることができたと結論付ける\nことができる．特に長期的なフィードバックの主要機能である「履歴閲覧機能」「競争機能」「通知機能」\nの有効性が実証された．３要素間に機能の優劣はあるものの，結果として「継続頻度の向上」「安定した\nトレーニング継続回数」「モチベーションの維持・向上」の３点すべての有効性を実証することができ\nた． \n今後の展望として，加速度センサとスマートフォンの接続がスムーズになるよう，センサの種類を変\n更することを検討していきたい．また，「リアルタイムで順位の変動を知らせてほしい」という被験者か\nらの意見を反映させるため，ランキングが変動した際に通知が発動するような仕組みや音声によるマル\nチフィードバックについても検討し，実現に向けて「W.I.L.-CoreMoni」の更改をしたい． \n \n \n青山学院大学大学院理工学研究科 \n目次\n第1 章\n序論\n3\n1.1\n研究背景. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n3\n1.1.1\n新型",
            ". . . . . . . . . . . . . . . . . . . .\n3\n1.1.1\n新型コロナウイルスが人々の生活へ与えた影響. . . . . . . . . . . . . . . . . . . . .\n3\n1.1.2\n体幹トレーニングの重要性. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n3\n1.1.3\n体幹トレーニングの認知度. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n4\n1.1.4\nモチベーション維持における心理的側面\n. . . . . . . . . . . . . . . . . . . . . . . .\n6\n1.2\n研究目的. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n7\n1.3\n本論文の構成. . . . . . . . . . . . . . . . ",
            ". . .\n7\n1.3\n本論文の構成. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n8\n第2 章\n先行研究とその課題および本研究の優位性\n9\n2.1\n先行研究. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n9\n2.1.1\nカメラ画像を用いたトレーニング支援手法. . . . . . . . . . . . . . . . . . . . . . .\n9\n2.1.2\nウェアラブルデバイスを用いた体幹トレーニングの種目識別手法. . . . . . . . . . .\n10\n2.1.3\n習慣化するための支援手法. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n12\n2.1.4\nモチベーションの維持・制御手法. . . . . . . . . . . . . ",
            "12\n2.1.4\nモチベーションの維持・制御手法. . . . . . . . . . . . . . . . . . . . . . . . . . . .\n13\n2.2\n先行研究の課題と本研究の優位性. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n13\n第3 章\nW.I.L.-CoreMoni の全体像，概要および使用方法\n14\n3.1\nW.I.L-CoreMoni の全体像. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n14\n3.2\nW.I.L-CoreMoni の概要\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n15\n3.2.1\nセンシング機能-短期的フィードバック- . . . . . . . . . . . . . . . . . . . . . . . .\n15\n3.2.2\n骨格画像等表示機能-短",
            ". . . . . . . . . . . . . . .\n15\n3.2.2\n骨格画像等表示機能-短期的フィードバック- . . . . . . . . . . . . . . . . . . . . . .\n28\n3.2.3\nトレーニングスタッツ閲覧機能-長期的フィードバック- . . . . . . . . . . . . . . . .\n30\n3.2.4\n他者とのランキング機能-長期的フィードバック-\n. . . . . . . . . . . . . . . . . . .\n30\n3.2.5\n３日坊主防止リマインダ機能-長期的フィードバック- . . . . . . . . . . . . . . . . .\n31\n3.3\nW.I.L.-CoreMoni におけるデータの流れ\n. . . . . . . . . . . . . . . . . . . . . . . . . . . .\n32\n3.4\nW.I.L.-CoreMoni の使い方. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ",
            ". . . . . . . . . . . . . . . . . . . . . . . . . .\n33\n第4 章\nスコアリングによるモチベーション維持の検証（予備実験）\n40\n4.1\n予備実験の目的. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n40\n4.2\n予備実験の方法. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n40\n4.3\n予備実験の手順. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n40\n4.4\n予備実験の分析方法\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n41\n4.4.1\nトレーニングスタッツ. . ",
            " . . . . . . . . . . . . .\n41\n4.4.1\nトレーニングスタッツ. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n41\n4.4.2\nSUS アンケート. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n41\n4.5\n実験結果. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n42\n4.5.1\n実験前と実験後での正しい姿勢を維持できた時間の比較結果. . . . . . . . . . . . .\n42\n4.5.2\nSUS スコア. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n43\n4.5.3\n体幹トレーニングをおこなった頻度・継続性. ",
            " . . . . . . . . .\n43\n4.5.3\n体幹トレーニングをおこなった頻度・継続性. . . . . . . . . . . . . . . . . . . . . .\n45\n4.6\n考察・課題・今後の展望. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n49\n1\n第5 章\nスコアリング並びにリマインドによるモチベーション維持の検証（本実験）\n50\n5.1\n本実験の目的. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n50\n5.2\n本実験の方法. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n50\n5.3\n本実験の手順. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ",
            ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n50\n5.4\n本実験の分析方法. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n51\n5.4.1\nトレーニングの継続性. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n51\n5.4.2\nSUS アンケート. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n51\n5.4.3\nモチベーションに関する主観評価アンケート. . . . . . . . . . . . . . . . . . . . . .\n51\n5.4.4\n道具性期待理論によるモチベーション評価. . . . . . . . . . . . . . . . . . . . . . .",
            "ション評価. . . . . . . . . . . . . . . . . . . . . . .\n52\n5.5\n本実験の結果と考察\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n53\n5.5.1\nトレーニングの継続頻度. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n53\n5.5.2\n短期的および長期的フィードバックにおけるSUS スコア. . . . . . . . . . . . . . .\n55\n5.5.3\nモチベーション維持に関する主観アンケート結果\n. . . . . . . . . . . . . . . . . . .\n56\n5.5.4\n道具性期待理論に基づくモチベーション状態の評価. . . . . . . . . . . . . . . . . .\n58\n第6 章\n本研究の結論および今後の展望\n59\n謝辞\n60\n参考文献\n61\n付録\n64\n付録A . . . . . . . ",
            "および今後の展望\n59\n謝辞\n60\n参考文献\n61\n付録\n64\n付録A . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n64\n付録B . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n66\n付録C . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n81\n2\n第1章\n序論\n本章では序論として，研究背景および研究目的について論じる．第1.1 節では研究背景について述べ，第\n1.2 節では研究目的について述べる．第1.3 節では本論文の構成について述べる．\n1.1\n研究背景\n本節では研究背景として，第1.1.1 項で新型コロナウイルスが人々の生活に",
            "べる．\n1.1\n研究背景\n本節では研究背景として，第1.1.1 項で新型コロナウイルスが人々の生活に与えた影響について，第1.1.2\n項で体幹トレーニングの重要性について，第1.1.3 項で体幹トレーニングの認知度について，第1.1.4 項で\nモチベーション維持における心理的側面について論じる．\n1.1.1\n新型コロナウイルスが人々の生活へ与えた影響\n2019 年末に流行し始めた新型コロナウイルス（以下COVID-19）の影響は3 年たった今でも爪痕を残して\nいる[1]．スポーツ庁は「感染症対策による活動制限・運動不足の長期化による影響」として「体力の低下」\n「腰痛・肩こり」「生活習慣病の発症・悪化」を事例に挙げている[2]．また，明治安田生命保険相互会社が\n2021 年に5640 人の男女を対象に実施した健康に関するアンケート調査[3] の結果，3 人に2 人がCOVID-19\nの影響でストレスを感じていると回答し，4 人に1 人の体重が増加していることが分かった．さらに，コロ\nナ禍による健康意識の変化についてのアンケートの結果，40%以上の人々が「健康意識が高まった」と回答\nした．",
            "よる健康意識の変化についてのアンケートの結果，40%以上の人々が「健康意識が高まった」と回答\nした．以上のことから，COVID-19 の流行を機に人々は健康に意識を持ち始めたといえる．\n健康な身体を維持するためには，ランニングや筋力トレーニングといった日常的な運動が有効であると\n考えられている[4]．フィットネスクラブの動向報告[5] によると，2022 年4 月の利用者数合計は1700 万人\nを超えており，多くの人々が定期的に運動をしていることが分かる．\n1.1.2\n体幹トレーニングの重要性\n自宅で過ごす時間が増えたことから，屋内で一人で簡単に始められる体幹トレーニングに注目が集まっ\nている[6]．体幹トレーニングはスポーツ動作に求められる能力向上だけでなく[7]，日常生活においても重\n要な役割を果たしている．\n「体幹」とは図1.1 に示すように身体の四股と頭部を除いた部分で，身体重量の\n約48 ％を占めており，体幹に含まれる筋肉群は「体幹筋」と総称されている[8]．体幹は運動について四股\n間の運動連結やバランスに関して重要な役割を果たしている．そのため体幹は動作の要であり，全ての生",
            "四股\n間の運動連結やバランスに関して重要な役割を果たしている．そのため体幹は動作の要であり，全ての生活\n動作において最も重要な身体の部位である．体幹の筋力が低下すれば起き上がることが困難になり，体幹に\n異常運動を呈すれば座位などの姿勢保持が著しく困難になるなど，体幹強度は身体の健康にとても重要で\nある．体幹トレーニングはスポーツ選手を筆頭に一般の人々にも浸透し始め，注目されている．\n3\n図1.1: 体幹の部位\n1.1.3\n体幹トレーニングの認知度\n近年，体幹トレーニングは注目を集めているが，認知度を調査するケーススタディはまだ行われていな\nい．そこで，体幹トレーニングがどの程度認知されているか調査を行った．\n「体幹トレーニングに関するア\nンケート」と題した調査を実施した．図1.2 は調査に使用した質問項目のスクリーンショットである．質問\nは「体幹トレーニングをご存知ですか？」と「ご存じの体幹トレーニングの種目にチェックを入れてくださ\nい．」という簡単な2 つの質問である．候補となった種目[9] は，体幹トレーニングの主要エクササイズで\nある「フロントプランク[10]」，\n「サイドプラン",
            "[9] は，体幹トレーニングの主要エクササイズで\nある「フロントプランク[10]」，\n「サイドプランク[11]」，\n「ニー・トゥ・エルボー[12]」である．20 代から40\n代の男女82 名が回答した．\n調査結果によると，\n「体幹トレーニングをご存知ですか？」という質問に対して，回答者の97.6%が「は\nい」と回答した．知っている種目の回答率は，\n「フロントプランク」が100 ％，\n「サイドプランク」が93.8 ％，\n「ニー・トゥ・エルボー」が85.2 ％でした．図1.3 と図1.4 にそれぞれの詳細を示す．\n4\n図1.2: 体幹トレーニングの認知度アンケートの質問項目\n図1.3: 体幹トレーニングの認知度アンケート結果\n5\n図1.4: 種目の認知度アンケート結果\nこれらの結果から，体幹トレーニングの認知度は十分であると結論付けることができる．\n1.1.4\nモチベーション維持における心理的側面\nなにかを継続する際，モチベーションや目標がないと頑張れないと感じるのは私たちだけではないはず\nだ．人間が行動を継続するとき，\n「動機づけ」という概念が重要となる．動機づけとは，行動を始発させ，目",
            "だ．人間が行動を継続するとき，\n「動機づけ」という概念が重要となる．動機づけとは，行動を始発させ，目\n標に向かって維持・調整する過程や機能のことである[13]．\n動機づけには外発的動機付けと内発的動機付けの２種類がある[14]．外発的動機付けとは，外部からの評\n価や報酬，また賞罰などが要因となって行動を起こす動機付けである．外部から得られるポジティブな要因\nや評価や罰といった恐れの気持ちも要因となることが特徴である一方，内発的動機付けとは，物事に対する\n興味や関心によって行動を起こし，達成感や満足感を得たいという，人の内面に沸き起こった意欲から起こ\nる動機づけである．好奇心や探知心が根本にあり，損得への関係がない欲求が特徴である．\n内発的動機付けからの行動には「承認」が重要であり，人間の欲求は５段階のピラミッドのように構成さ\nれている（図1.5）．低層階の欲求が満たされると，より高次の階層の欲求を求めるようになる．上層階で\nある第４，第５階層が内発的なものであり，下層階の第１，第２，第３階層が外発的なものである．第１階\n層は生理的欲求と呼ばれ，生きていくための必要な基本的な本能的な欲求",
            "階層が外発的なものである．第１階\n層は生理的欲求と呼ばれ，生きていくための必要な基本的な本能的な欲求である．第２階層は安全欲求と呼\nばれ，危機を回避したい，安全安心に生活がしたいという欲求である．第３階層は社会的欲求と呼ばれ，集\n団やグループに属したい，仲間が欲しいという欲求である．第４階層は承認欲求と呼ばれ，認められたいと\n感じたり，尊敬されたいと感じる欲求である．最後の第５階層は自己実現欲求と呼ばれ，自分自身の力を発\n揮し，あるべき姿の自分になりたいと感じる欲求である．これらはマズローの欲求段階説と呼ばれている．\n6\n図1.5: マズローの欲求段階説\n1.2\n研究目的\n本研究の目的は，一人で行うトレーニング（体幹トレーニング）を支援するシステムを構築し，トレーニ\nングを通して人々の健康維持に貢献し，ウェルビーイング実現に近づけることである．体幹トレーニングを\n行うにあたって，いくつか課題がある．体幹トレーニングは一人で気軽に始められるものの，自分の姿勢を\n客観的に俯瞰し，正しい姿勢を維持することは容易ではない．また，監視の目がないことからトレーニング\nを継続して行うことを途中でやめ",
            "維持することは容易ではない．また，監視の目がないことからトレーニング\nを継続して行うことを途中でやめてしまう可能性も考えられる．\n実際，日本におけるフィットネス継続率は低迷している．スポーツジムを利用する人々の継続率に関する\nデータは，利用者のモチベーションや生活スタイルを反映しており，日本フィットネス産業協会によると，\n国内のジムの月間退会率は約4～5 ％であり，年間を通して見るとほぼ半数の会員が入れ替わるそうだ[15]．\nまた，アメリカの研究では，フィットネスジム利用者の継続率は，開始から3ヶ月後で37%，1 年後には\nわずか4%未満に減少すると報告されている．100 人がジムに入会しても，1 年後には4 人しか継続してい\nない結果となる[16]．忙しくて時間が取れない，成果が感じられないといった理由が多いが，\n「エクササイ\nズが単調で飽きてしまうこともある」と考えられている．会員の歩留まりが上がれば，ロスは減ると考え\nられる．\n「国内市場の大部分は（運動器具やプール，スタジオをそろえた）総合型ジムが支えているものの，\nそこで応えきれていないニーズを（娯楽型が）ひろっている」と指摘",
            "えた）総合型ジムが支えているものの，\nそこで応えきれていないニーズを（娯楽型が）ひろっている」と指摘する．\nこのような課題を解決するため，本研究では加速度センサを活用し，短期的フィードバックと長期的フィー\nドバックを兼ね備えた，体幹トレーニング支援システムである「W.I.L.-CoreMoni」を提案する．トレーニ\nングを楽しみながら継続できるよう，時間がない人でも手軽に利用でき，自身のトレーニング成果を可視化\nするなど，いくつかの仕掛けを実装した．本システムの開発を通して，システムの有効性の検証およびシス\nテムがトレーニングの継続にどのくらい貢献できるのかを評価することを目標とし，本研究に取り組んだ．\n7\nまた，モチベーション評価を行うにあたって２つのことに留意する．１点目はトレーニング種目である．\nフロントプランクやサイドプランクなど，様々な種目を利用できるようシステムの開発に尽力したが，シ\nステム上の挙動が安定しているフロントプランクに着目した．２点目は動機づけについてである．前項で\n動機づけには外発的動機付けと内発的動機付けがあると述べたが，今回は内発的動機付けに着目する．な\n",
            "で\n動機づけには外発的動機付けと内発的動機付けがあると述べたが，今回は内発的動機付けに着目する．な\nぜなら，アンダーマイニング効果が存在するからだ[17]．アンダーマイニング効果とは，内発的動機付けに\nよる行動に対して，外発的動機付けである「外的報酬」を与えた場合，かえってその人の意欲を低下させ\nてしまう現象のことである．もともとは内発的動機付けによる行動していたはずなのに，報酬を得た結果，\n報酬や評価そのものが目的となってしまう状態をさす．アンダーマイニング効果を防ぐためには，相手の\n努力や行動を褒め，\n「やらされている」と感じさせない言動を心がけることが大切である．内発的動機付け\nは，興味・関心や達成感・満足感を得たい気持ちが原動力となる．そういった原動力から成る行動は，高い\n集中力や質を保った業務を続けることができ，やりがいを感じやすいメリットが期待できる．\nさらに，内発的動機付けは外発的動機付けに比べ，より個人の特性やライフスタイルに適応させることが\nできるため，有効性をはかることができるのではないかと仮定した．そのため，内発的動機付けに焦点を置\nき，本研究に取り組んだ．\n本研",
            "とができるのではないかと仮定した．そのため，内発的動機付けに焦点を置\nき，本研究に取り組んだ．\n本研究の目的は大きく分けると以下の通り：\n1. 短期的フィードバックの有効性を検証する．\n2. 長期的フィードバックの有効性を検証する．\n1.3\n本論文の構成\n本論文の構成は以下の通りである．\n• 第１章序論（研究背景や研究目的，本論文の構成）\n• 第２章関連研究および先行研究との差異\n• 第３章W.I.L.-CoreMoni の全体像，概要および使用方法\n• 第４章スコアリングによるモチベーション維持の検証（予備実験）\n• 第５章スコアリング並びにリマインドによるモチベーション維持の検証（本実験）\n• 第６章本研究の結論および今後の展望\n• 謝辞\n• 参考文献\n• 付録A～C\n8\n第2章\n先行研究とその課題および本研究の優位性\n本章ではいくつかの先行研究と本研究の優位性について論じる. 第2.1 節では先行研究について，第2.2\n項では先行研究の課題と本研究の優位性について論じる.\n2.1\n先行研究\n2.1.1\nカメラ画像を用いたトレーニング支援手法\n綿谷らはカメラの画像を用いた体幹トレー",
            "先行研究\n2.1.1\nカメラ画像を用いたトレーニング支援手法\n綿谷らはカメラの画像を用いた体幹トレーニングの姿勢支援手法を提案した[18]．従来のトレーニング支\n援手法は，姿勢推定を行ったのちにユーザへフィードバックを与え，正しい姿勢でのトレーニングを促すと\nいうものであった[19][20]．しかしながら，それらの姿勢推定には深度カメラや複数台のカメラを必要とす\nるため，コストがかかるという問題点があげられた．また，ユーザへの視覚的フィードバックが１視点およ\nび骨格情報のみを示している２次元骨格画像であるため，トレーニング時の姿勢把握が難しいという問題\nがあった．\nそこで彼らは，画像から姿勢推定を行い，トレーニングの目標姿勢と現在の姿勢の３次元モデルを生成し，\n重畳表示した．さらに，目標姿勢と現在の姿勢の違いを把握しやすくするために，身体の各部位１０箇所に\nマーカを表示し，誤差に応じて４段階に色変化させた．これらの情報を２視点でユーザへ視覚的フィード\nバックをすることで，姿勢補正の支援を行った．提案手法としては，単一のRGB カメラのみを用いて，カ\nメラ画像から姿勢推定を行い，推定結果",
            "行った．提案手法としては，単一のRGB カメラのみを用いて，カ\nメラ画像から姿勢推定を行い，推定結果に基づいて３次元モデルを生成し，２視点でユーザへ視覚的フィー\nドバックを行うというものである．\n結果として，アンケートによる有効性評価を行ったところ，３次元モデルを用いてフィードバックを行う\nことは姿勢の把握しやすさを向上させるうえで有効な手法であると考えられた．\nしかしこの研究では，視覚的フィードバックの更新速度が遅く，目標姿勢に対して現在の姿勢がどのくら\nい異なっているかを認識するのは困難であった．また，トレーニング中に視線を変えて画面を見なければな\nらないという問題点もあった．今後の展望として、Head Mounted Display（HMD）の利用などが考えられ\nている．\n一方，村田らは安価な装置を開発することを目的とし，深度カメラを有するKinect[21] を利用し，運動を\n支援するシステムを構築した[22]．少子高齢化が進むに従い，リハビリテーションを必要とする人が増加す\nる可能性があり，運動を客観的に評価することが推奨されている．長期間にわたってリハビリテーションを\n続け",
            "可能性があり，運動を客観的に評価することが推奨されている．長期間にわたってリハビリテーションを\n続けるためには，当事者である患者のやる気を維持し，医療従事者が現状について正しく認識できる必要が\nある．腕や足の関節の角度の測定は分度器や定規を当てるなどして計測可能であるが，身体が傾いた状態，\nさらにそれにねじれが加わった状態を分度器や定規で測定するのは高度なノウハウが必要といわれている．\nリハビリテーションやスポーツの場で患者や選手の身体の動きを詳細に計測できる機器にVICON[23] が\nある．VICON は身体の関節運動を動的な情報として記録可能である一方で，非常に高価であることから，\n導入可能な施設は限られ，自宅での自主訓練には不向きであると考えられる．この問題を解決するため，村\n田らはKinect を用いて前屈，身体の傾き，身体のねじれ具合を計測する３種類のアプリケーションを開発\nした．\n結果として，数度の誤差範囲で計測することができ，身体のゆがみを比較的安価で，高度なノウハウを必\n要としない装置を開発することができた．今後の展望としては，性能と利用勝手を向上させていくとある．\n",
            "\n要としない装置を開発することができた．今後の展望としては，性能と利用勝手を向上させていくとある．\n9\n2.1.2\nウェアラブルデバイスを用いた体幹トレーニングの種目識別手法\n高田らは，体幹トレーニング支援に向けたウェアラブルデバイスによる種目認識手法を提案している[24]．\n日本は高齢化社会から高齢社会へと転換し，今後は事態が深刻化する恐れがある．副次的な被害としては，\n経済成長の弱体化・社会保障の負担増大などがあげられる．これらの問題を解決するためには，日常的なト\nレーニングが有効であると考えられている．体力がつくことで自立した生活や健康寿命の延び，労働者と\nして社会に貢献できるなどの利点がある．これらのことから，健康寿命を延伸させ，要支援・要介護状態に\nならないための取り組みを推進させることは非常に重要であると考えられている．\n個人で行うことのできる体幹トレーニングは，パーソナルトレーナーの下で行うトレーニングに比べ，効\n果的なトレーニングを行うことができないという問題がある．そこで高田らは，身体にウェアラブルデバイ\nス（図2.1）を装着し，ウェアラブルデバイス内に搭載された慣性",
            "で高田らは，身体にウェアラブルデバイ\nス（図2.1）を装着し，ウェアラブルデバイス内に搭載された慣性センサを用いてトレーニング中の姿勢情\n報を取得し，得られる加速度やジャイロデータをもとに，機械学習によって体幹トレーニング種目を自動認\n識できるようにした．提案手法として，Step0 からStep3 までの構成（図2.2）が紹介されている．Step0 で\n身体に取り付けられた少数のウェアラブルデバイス内に搭載されたセンサから体幹トレーニング中の姿勢情\n報を取得し，Step1 でセンサから得られるデータをもとに機械学習を用いて学習器を構築し，その学習器に\nよって体幹トレーニング種目の自動認識を行う．Step2 で認識された種目に対してQuality of Training 評\n価を行い，Step3 で評価結果から個々にあった運動支援をデバイスを介して行い，人間のパーソナルトレー\nナーを人工知能的なエージェントに置き換えるというものである．\n結果として，機械学習手法としてRandom Forest(RF) を用いた場合で，F 値：99.7%と高精度に認識す\nることに成功した．さらに，片方の手",
            "st(RF) を用いた場合で，F 値：99.7%と高精度に認識す\nることに成功した．さらに，片方の手首およびベルト位置にデバイスを装着するだけでもF 値：94.1%の精\n度で認識できることを確認した．したがって，本システムの有効性を確認することができた．\n今後の展望として，装着部位として足首などを考慮した追加デバイスによる認識精度の向上，トレーニン\nグ中か否かのセグメンテーション化の検討があげられる．\n図2.1: ウェアラブルデバイスを使用した種目識別手法\n10\n図2.2: 高田らの実験における装置操作手順の説明\nDavid Barbado らは，図2.3 に示すような様々な体幹トレーニングの強度を定量化するために，スマホ\n内の加速度センサの信頼性を分析し，骨盤につけた加速度データが体幹構造の安定性や全身の姿勢制御を\nどの程度表しているかを分析した[25]．体幹トレーニングについて，これまで運動パフォーマンスの向上や\n筋骨格系損傷の予防に大きく利用されているものの，トレーニングの強度を定量化する方法はない．David\nらはこれらの問題を解決するため，トレーニングの強度を定量化した．スマ",
            "量化する方法はない．David\nらはこれらの問題を解決するため，トレーニングの強度を定量化した．スマートフォンの加速度計と2 つ\nのプラットフォームを使用し，骨盤の平均直線加速度と圧力中心の変位の平均速度を測定した．そこから\n得られた結果として，クラス内相関関係，測定標準誤差により評価した．実験の結果，ほとんどの体幹ト\nレーニング種目において骨盤加速度は中程度から高い信頼性スコアが得られ，圧心変位は低から中程度で\nあることが示された．スマートフォンの加速度計は体幹トレーニング強度を定量化するために信頼できる\nデバイスであると認識できた．今後の展望として，体幹トレーニングにおける安定性の状態を特定したり，\nトレーニングの改善に直接役立てることなどがあげられる．\n11\n図2.3: David Barbado らの実験\n森田らは加速度センサを用いた体幹トレーニング支援システムを開発した[26]．新型コロナウイルスの\n影響により，多くの人が自宅で過ごすようになった．そんな中，一人で気軽に始めることのできる「体幹\nトレーニング」に注目が集まっている．しかし，スポーツジムなどにおいてパーソナルトレ",
            "とのできる「体幹\nトレーニング」に注目が集まっている．しかし，スポーツジムなどにおいてパーソナルトレーナーの指導\nのもとで行うトレーニングと比較して，個人で行う体幹トレーニングではその効果が著しく低下すること\nが考えられる．この問題を解決するため，森田らは加速度センサを用いて体幹トレーニングを支援するシ\nステムを実装した．提案手法はセンサを身体に装着し，センサから得られたデータをもとにスマートフォ\nンを介してフィードバックを行うというものである．また，フィードバックは画像の切り替えによって行っ\nている．評価実験の結果，アプリケーションの使用感と画像の切り替えによるフィードバックのアンケー\nトにおいて，78 ％の被験者が適切であったと回答した．そのため，本システムは非常に優れたユーザビリ\nティであることが示された．しかしながら，フィードバックが画像であるがゆえに，ユーザが下を向いてし\nまうことで姿勢が悪くなる場面があった．そのため，画像の切り替えに加え，新たなフィードバック方法を\n検討しなければならない．\n2.1.3\n習慣化するための支援手法\n濱谷らは，ソーシャルネットワーキングサービス",
            "ければならない．\n2.1.3\n習慣化するための支援手法\n濱谷らは，ソーシャルネットワーキングサービスでの繋がりを通じて，仲間との関わりを通じた習慣化支\n援技術について検討を行った[27]．具体的には，健康的な行動の目標を立てて，仲間から応援を受けること\nにより目標達成が支援されること，さらに，応援を受ける仲間との親密さに応じて，同じ応援１回でも目\n標達成後押しに対する効果が異なるという仮説を検証した．実際に大学生504 人の約3ヶ月半にわたる歩数\nデータ，歩数目標宣言データを取得し評価を行った結果，目標宣言を行うこと自体に歩数を増加させる効果\nがあること，目標宣言に対して応援を受けることで歩数が増加すること，および応援を受ける相手との過\n去のコミュニケーション履歴に応じて，歩数の増加効果の大きさに差異があることが示唆された．しかし，\n応援する機能なしによるユーザの長期的なトレーニング支援や他者との競争機能は用意されていない．ま\nた，個人のデータを閲覧するといった過去の個人データ振り返る機能には焦点を置いていない．\n12\n2.1.4\nモチベーションの維持・制御手法\n大手通信キャリアNTT",
            "能には焦点を置いていない．\n12\n2.1.4\nモチベーションの維持・制御手法\n大手通信キャリアNTT ドコモ[28] が提供するd ヘルスケアは，毎日の歩数と体重の記録がポイントに\n変換される健康促進システムである[29]．このシステムは，ユーザーの健康維持に対するモチベーションを\n高めるための手法として，外発的な報酬を提供する．歩数や体重の記録により得られるポイントは，商品や\nサービスと交換でき，健康的なライフスタイルを維持するための動機付けとなる．しかし，一部のユーザー\nからは，外発的な報酬だけではなく，内発的な動機づけも重要との意見が出ている．内発的な動機づけと\nは，自己達成感や自己満足など，個人の内面からくる動機づけのことを指す．この考え方に基づくと，健康\n維持のための行動は，自分自身が健康でいたいという欲求から自然と起こるものであり，外部からの報酬だ\nけに頼るのではなく，自己の内面からの動機づけを高める支援も重要になる．この観点から，今後の健康促\n進システムの開発においては，ユーザーの内発的な動機づけを高める要素を取り入れることが求められる\nと考える．具体的には，自己達成感を",
            "ーザーの内発的な動機づけを高める要素を取り入れることが求められる\nと考える．具体的には，自己達成感を得るための目標設定機能や，自己満足感を得るためのフィードバック\n機能などが考えられる．これらの機能を取り入れることで，ユーザー自身が健康維持のための行動を自然\nととるようになり，より持続的な健康促進が期待できる．\n双見らは，心理的影響を考慮した競争情報を用いたモチベーション制御手法を提案した[30]．まず日常の\n運動モチベーション向上を対象とし，競争においてモチベーションに影響する要因である，努力量に対する\n競争結果，競争相手との成績差，競争参加人数の3 点による心理的影響への配慮をシステム設計に内包さ\nせた競争システムを開発した．提案システムでは活動量計から得た歩数を基にして，モチベーションに良い\n効果を与えるように補正された競争結果がフィードバックされるというものである．プロトタイプシステム\nを用いた評価実験では，合計82 名の6 週間にわたる3 種類の実験を通して提示情報による歩数への効果を\n測定し，提案手法の有効性を確認した．\n2.2\n先行研究の課題と本研究の優位性\n先行研究とし",
            "の効果を\n測定し，提案手法の有効性を確認した．\n2.2\n先行研究の課題と本研究の優位性\n先行研究として第2.1 節で述べたようなものがあげられる．それらに共通してみられる課題としてひとつ\nあげられるのが，トレーニングの支援として効果的なものであるのかどうかということである．特に長期\n的なフィードバック方法についてはもう少し検討しなければならない．\n本研究では加速度センサを用いて姿勢判定を行うことを前提として，姿勢判定方法およびフィードバック\n方法に着目し，システムの新規作成・有効性の検証を行った．画像の切り替えによるフィードバックだけで\nなく，テキスト表示によるフィードバックも追加した．さらに，長期的なトレーニング支援につなげる機能\nとして、これまでの自分のトレーニングデータを閲覧できる機能や遠隔地にいる他者との競争機能，push\n通知によるリマインド機能などを実装し，\n「W.I.L.-CoreMoni」を開発した．さらに，複数種目のトレーニン\nグに対応できるよう，システムの機能拡張にも努めた．\n本研究の優位性は，短期性と長期性の両方を兼ね備えたフィードバック機能である．これにより，短",
            "努めた．\n本研究の優位性は，短期性と長期性の両方を兼ね備えたフィードバック機能である．これにより，短期\n間・長期間、一気通貫して体幹トレーニングに取り組むことができるだろう．\n長期的なトレーニング支援においては，金銭やポイントの付与といった外発的な要因による動機づけで\nはなく，本人のやる気やモチベーション維持などの内発的動機付けに着目した．エーテンラボ株式会社がリ\nリースした「みんチャレ[31]」は，読書の習慣化や体重の減少など同じ目標を目指すユーザが匿名で5 人集\nまり，チームで報告を行ったり，挑戦が途切れる日が続くとチームを脱退させられるなどの仕掛けにより習\n慣化を高める支援を行っている．しかし，個人間での競争や個人のトレーニングスコアを動機づけの種とし\nてモチベーションを維持・向上させる研究は未だ行われていない．\n本研究では，個人のトレーニングデータを閲覧する機能や他者との競争，リマインド機能を実装し，内発\n的動機付けに着目し，長期的なトレーニング支援の実現に努めた．本論文では，システムの有効性検証およ\nび本システムがトレーニングのモチベーション維持・向上にどのように貢献したかを",
            "ステムの有効性検証およ\nび本システムがトレーニングのモチベーション維持・向上にどのように貢献したかを論じる．\n13\n第3章\nW.I.L.-CoreMoniの全体像，概要および\n使用方法\n本章では，提案手法として本研究で開発したシステム「W.I.L.-CoreMoni」について詳しく論じる．第3.1\n節でW.I.L-CoreMoni の全体図，第3.2 節でW.I.L.-CoreMoni の概要（DB、機能、閾値値などについて）\nを，第3.3 節でW.I.L.-CoreMoni におけるデータの流れについて，第3.4 節でW.I.L.-CoreMoni の使い方\nについて述べる．\n3.1\nW.I.L-CoreMoni の全体像\n提案システムの全体図を説明すると共に本研究の立ち位置を俯瞰する．図3.1 に本研究で提案予定の体幹\nトレーニング支援システム「W.I.L.-CoreMoni」の全体概要図を示す。本システムの概要を大枠と細部に分\nけて見ていこう．\n図3.1: W.I.L.-CoreMoni の全体概要\n図3.2 に機能の大枠を示す．「W.I.L.-CoreMoni」は体幹トレーニン",
            "oni の全体概要\n図3.2 に機能の大枠を示す．「W.I.L.-CoreMoni」は体幹トレーニング時のユーザの姿勢情報を取得する\n「センシング機能」とユーザに行動支援を提供する「フィードバック」の２つに分けて考えることができる．\n本研究においてはフィードバックの手法に焦点を置いているため，これに関して説明する．\n以前，短期性に焦点を置いた研究を行った（黄色枠線）．今回は長期性に焦点を置き研究を行った（赤色\n枠線）．この背景として，ユーザのトレーニング後の支援不足の解消があげられる．短期性のフィードバッ\nク機能を備えたシステムは，トレーニング時には有効であったものの，トレーニングを継続する動機づけに\nはつながらなかった．\n今回，長期性に重視したと述べたが，システムの機能としては短期的フィードバックと長期的フィード\nバックの両方を備えている．長期的フィードバックのフィードバック手法を考える材料として，外発的動機\n付けと内発的動機付けの２つが存在する[14]．第2.2 節でも先述したように，本研究においては内発的動機\n付けに焦点を当てて研究した．\n14\n図3.2: W.I.L.-Core",
            "，本研究においては内発的動機\n付けに焦点を当てて研究した．\n14\n図3.2: W.I.L.-CoreMoni の機能の大枠\n図3.3 に細部を示す．今回の研究においては内発的動機付けに焦点を置いているため，内発的動機付けの\nコンテンツを紹介する．第1.1.4 項で論じた内発的動機付けであるが，本動機付けを促進する機能として，\nトレーニングの振り返り機能（以下、トレーニングスタッツ）やオンライン上でのほかのユーザとの競争\n（以下、ランキング），通知機能などがあげられると考え，これらの機能を実装した（緑色枠線）．詳細に\nついては次章以降に論じる．\n図3.3: W.I.L.-CoreMoni の機能の細部\n3.2\nW.I.L-CoreMoni の概要\n本節ではシステムの概要について論じる．第3.2.1 項で短期的フィードバックであるセンシング機能につ\nいて，第3.2.2 項で骨格画像等表示機能について，第3.2.3 項で長期的フィードバック機能であるトレーニ\nングスタッツ閲覧機能について，第3.2.4 項で他者とのランキング機能について，第3.2.5 項で３日坊主防\n止リマインダ機能について",
            ".2.4 項で他者とのランキング機能について，第3.2.5 項で３日坊主防\n止リマインダ機能について論じる．\n3.2.1\nセンシング機能-短期的フィードバック-\n本項では，提案システムにおける短期的フィードバックであるセンシング機能について述べる．W.I.L.-\nCoreMoni は体幹トレーニングを自律的に行う上で重要となる姿勢監督の役割を担い，ユーザの体幹トレー\nニングを支援するものである．本システムは500 円玉くらいの大きさのウェアラブルデバイス（図3.4）と\nスマートフォン（図3.5）を使用したものである．９軸IMU による加速度データ，ジャイロデータ，磁力\nデータ，そして心拍数の取得が可能である「movesense（SUUNTO 社製）[32]」というデバイスを用いてい\n15\nる．movesense はエクササイズ用に最適化されたウェアラブルセンサである．重さは9.4g と小型軽量であ\nり違和感なく装着することが可能である．耐久性にも優れているため，スポーツなどのシーンで利用でき\nる．プロスポーツで使用されるウェアラブルセンサと比較して安価であるため，私たちのような一般ユー",
            "でき\nる．プロスポーツで使用されるウェアラブルセンサと比較して安価であるため，私たちのような一般ユーザ\nにも購入しやすい．\n本システムは，movesense から１秒間に13 個の加速度データを取得し，その一つ一つをあらかじめ定義\nした閾値と比較し，姿勢の良し悪しを判断している．ウェアラブルデバイスとスマートフォンはBluetooth\n通信で接続している．\n図3.4: ウェアラブルIMU “Movesense”（[32] より引用）\n図3.5: スマートフォン“ASUS X01AD”\nまた，体幹トレーニング中の「姿勢」を支援対象とし，より効果的な支援につながるよう搭載する機能に\n留意した．メインメニューを作成し，そこからトレーニング種目を選べるようにした．デザインや使いやす\nさにも工夫を施し，従来型システム「CoreMoni[26]」との差別化を図った．姿勢判定においては，より精\n度の高い判定ができるアルゴリズムを実装し，フィードバックにおいては，骨格画像による姿勢の画像切り\n替えによるものとその画像と連動して「HIGH」「GOOD」「LOW」の３種類のテキストをリアルタイムに\n表示す",
            "ものとその画像と連動して「HIGH」「GOOD」「LOW」の３種類のテキストをリアルタイムに\n表示するという２種類のフィードバックを用意した．\nさらに，上級者向けにX 軸，Y 軸，Z 軸方向の加速度の値も表示できるようにした．トレーニングを行\nう画面においては，トレーニング種目ごとにトレーニング方法と本システムの使い方，アドバイス等を明\n記した．\n図3.6 にシステムの構成図を示す．ユーザは腰に加速度センサを装着する．ユーザはスマートフォンの画\n面に表示された自分の現在の姿勢を俯瞰して見ることで，姿勢を正すことができるだろう(図3.7)．\n16\n図3.6: W.I.L.-CoreMoni の構成図\n図3.7: トレーニング中のデバイスの使用方法\n17\n加速度センサの装着位置に関してだが，森田らの実験[26] を参考にした．加速度センサを背中，腰，足\n首の３点に装着し，０秒～15 秒を正しい姿勢，15 秒～30 秒を腰が低い姿勢，30 秒～45 秒を腰が高い姿勢，\n45 秒～60 秒を連続的に変化のある姿勢として，１分間の体幹トレーニング（フロントプランク）を行って\nもらった．\nその結果",
            "的に変化のある姿勢として，１分間の体幹トレーニング（フロントプランク）を行って\nもらった．\nその結果，背中と足首に装着したセンサでは，加速度の値があまり変化しなかった（図3.8，図3.9）．し\nかし，腰に装着したセンサでは加速度の変化が見られた（図3.10）．特にY 軸に大きな変化があることが\n分かる．以上の結果から，加速度センサの装着位置は腰に選定した．\n図3.8: 背中の加速度の変化\n18\n図3.9: 足首の加速度の変化\n図3.10: 腰の加速度の変化\n19\n続いて，姿勢判定の原理となる閾値について論じる．まずはじめに，movesense における加速度センサの\n仕組みについて説明する．図3.11 に示すように加速度はX 軸，Y 軸，Z 軸の３軸に分けて考えることがで\nきる．実験および調査の結果，正面向かって左方向がX 軸（赤色矢印），下方向がY 軸方向（黄色矢印），\n円盤の裏側方向がZ 軸（緑色矢印）となることが分かった．\n図3.11: movesense における加速度の方向\n次に，腰の高さによって加速度の値がどのように変化するのかを説明する．腰の位置が高くなればなるほ\nど，Y",
            "に，腰の高さによって加速度の値がどのように変化するのかを説明する．腰の位置が高くなればなるほ\nど，Y 軸方向の加速度の値は小さくなり，Z 軸方向の加速度の値は緩やかに小さくなる．また，腰の位置が\n低くなればなるほど，Y 軸方向の加速度の値は大きくなり，Z 軸方向の加速度の値は緩やかに小さくなる．\n腰の位置が良いとされるときは腰の位置が高いとき・低い時のX 軸方向の加速度の値と同様，特に大きな\n変化はない．整理したものを図3.12 に示す．\n図3.12: ３軸加速度の変化の様子\n20\nさて，閾値の決定方法に関して説明する．\n「Azure Kinnect DK（Microsoft 社製）[21]」（図3.13）を用い\nて，インストラクター指導の下，腰の位置が高い時・良い時・低い時の姿勢を保ち，その時の骨格画像（順\nに図3.14，図3.15，図3.16）と床と腰のなす角をもとに閾値を決定した．調査の結果，床と腰のなす角は\nそれぞれ図3.17 のようになった．グラフ（図3.17）を見ると，腰の位置が高いとされるとき，13.5 °より\nも小さい値をとっていることが分かる．\nまた，腰の位置が低いと",
            "置が高いとされるとき，13.5 °より\nも小さい値をとっていることが分かる．\nまた，腰の位置が低いとされるとき，20 °よりも大きい値をとっている．以上のことから，13.5 °以上20\n°以下を良い姿勢と定義した．良い姿勢の許容角度を表した模式図を図3.18 に記す．\n図3.13: Azure Kinect DK\n図3.14: 腰の位置が高い時のKinect 骨格画像\n21\n図3.15: 腰の位置が良い時のKinect 骨格画像\n図3.16: 腰の位置が低い時のKinect 骨格画像\n22\n図3.17: 腰の位置と角度の関係性\n図3.18: 模式図\n本システムでは，床に対して垂直方向に直立した状態でキャリブレーションを行うことを前提としてい\nる．そのため，キャリブレーション時の角度をa °，トレーニング中の角度をb °としたとき，閾値は次の\nようになる．\n＜HIGH ＞\nb◦−a◦< 13.5◦−90◦i.e. b◦−a◦< −76.5◦\n(3.1)\n＜GOOD ＞\n13.5◦−90◦≤b◦−a◦≤20◦−90◦i.e. −76.5◦≤b◦−a◦≤−70◦\n(3.2)\n＜LOW ＞\n2",
            "b◦−a◦≤20◦−90◦i.e. −76.5◦≤b◦−a◦≤−70◦\n(3.2)\n＜LOW ＞\n20◦−90◦< b◦−a◦i.e. −70◦< b◦−a◦\n(3.3)\n23\n腰の位置が高い時，低い時，良い時の３姿勢それぞれにおいて具体的な数値を用いて図で説明する．\n• 腰の位置が高い時\nキャリブレーション時とトレーニング中のX 軸方向，Y 軸方向，Z 軸方向の加速度の値が表3.1 のよう\nになるとき，角度は表3.2 に記した通りになる．\n表3.1: x,y,z 軸の加速度の値\nx-axis acceleration\ny-axis acceleration\nz-axis acceleration\nCalibration Value(a)\n0\n9.52\n0.10\nCurrent Value(b)\n0\n-2.40\n9.63\n表3.2: 角度\nArctan(y/z)\ndegree\nCalibration Value(a)\n95.2\n89 °\nCurrent Value(b)\n-0.25\n-14 °\nこのとき，キャリブレーション時とトレーニング中の角度を図で表すと，図3.19 のようになる．",
            "4 °\nこのとき，キャリブレーション時とトレーニング中の角度を図で表すと，図3.19 のようになる．数値を\n閾値判定の式に当てはめると，図中左下のようになり，判定は「HIGH」となる．\n図3.19: 加速度から算出された角度のグラフ画像\n24\n• 腰の位置が低い時\nキャリブレーション時とトレーニング中のX 軸方向，Y 軸方向，Z 軸方向の加速度の値が表3.3 のよう\nになるとき，角度は表3.4 に記した通りになる．\n表3.3: x,y,z 軸の加速度の値\nx-axis acceleration\ny-axis acceleration\nz-axis acceleration\nCalibration Value(a)\n0\n9.52\n0.10\nCurrent Value(b)\n0\n4.04\n9.25\n表3.4: 角度\nArctan(y/z)\ndegree\nCalibration Value(a)\n95.2\n89 °\nCurrent Value(b)\n0.44\n24 °\nこのとき，キャリブレーション時とトレーニング中の角度を図で表すと，図3.20 のようになる．数値を\n閾値判定の式に当てはめる",
            "ョン時とトレーニング中の角度を図で表すと，図3.20 のようになる．数値を\n閾値判定の式に当てはめると，図中左下のようになり，判定は「LOW」となる．\n図3.20: 加速度から算出された角度のグラフ画像\n25\n• 腰の位置が良い時\nキャリブレーション時とトレーニング中のX 軸方向，Y 軸方向，Z 軸方向の加速度の値が表3.5 のよう\nになるとき，角度は表3.6 に記した通りになる．\n表3.5: x,y,z 軸の加速度の値\nx-axis acceleration\ny-axis acceleration\nz-axis acceleration\nCalibration Value(a)\n0\n9.52\n0.10\nCurrent Value(b)\n0\n3.36\n9.79\n表3.6: 角度\nArctan(y/z)\ndegree\nCalibration Value(a)\n95.2\n89 °\nCurrent Value(b)\n0.34\n19 °\nこのとき，キャリブレーション時とトレーニング中の角度を図で表すと，図3.21 のようになる．数値を\n閾値判定の式に当てはめると，図中左下のようになり，判定は「",
            "表すと，図3.21 のようになる．数値を\n閾値判定の式に当てはめると，図中左下のようになり，判定は「GOOD」となる．\n図3.21: 加速度から算出された角度のグラフ画像\n26\nなお，フロントプランクの姿勢において意識すべきことは以下のとおりである．\n1. 体全体を足から首筋まで，まっすぐ伸ばす．\n2. 腰を落とさない．\n3. 腰を上げすぎない．\n4. 肩を丸めない．\n5. 顔を下げない，上げない．\n6. 両肘は，両肩の真下に来るようにする．\n7. 両腕は，前方にまっすぐ伸ばす．\n上記の番号に対応したものを図3.22 に示す．\n図3.22: フロントプランクの姿勢において意識すべきこと\nサイドプランクにおいても同様の手順を踏み，実装を行った．注意すべき点としては，フロントプラン\nクが１つのセンサを装着するのに対し，サイドプランクでは２つのセンサを装着することである．しかし，\n本研究の実験においてはフロントプランクでの評価としたいため，サイドプランクにおける詳細の論述は\n省略する．図3.23 にサイドプランクの正しい姿勢時の骨格を掲載し，説明完了とする．\n図3.23: サイドプランク姿勢",
            "3 にサイドプランクの正しい姿勢時の骨格を掲載し，説明完了とする．\n図3.23: サイドプランク姿勢におけるKinect 骨格画像\n27\n3.2.2\n骨格画像等表示機能-短期的フィードバック-\n本項では，提案システムにおける短期的フィードバックである骨格画像表示機能について論じる．まず，\n姿勢判定の手法であるが，大きく３段階に分かれている．\n第１段階目は「キャリブレーション」である．キャリブレーションを行うことにより，各ユーザに応じた\n初期値を生成することが可能であるため，ユーザに依存する可能性を低減させることができるだろう．絶対\n的な基準を設けず相対的な基準を設けることは，ユーザを限定することなく，汎用性の観点から有効となる\nだろう．加速度センサのサンプリング数を13Hz に設定しているため，１秒間に13 個のデータが取得可能\nである．\nまた，キャリブレーションの実行時間を５秒に設定している．そのため，キャリブレーションを行うこと\nで65 個のサンプリングデータを取得することが可能である．初期値の選定においては外れ値が存在するこ\nとを考慮して，中央値を用いている．すなわち，昇順に並べ",
            "る．初期値の選定においては外れ値が存在するこ\nとを考慮して，中央値を用いている．すなわち，昇順に並べ変えたデータの33 個目の値を用いている(式\n3.4)．その加速度を角度に変換（変換方法は前述）し，初期値に設定している．\nmedian in calibration = (65 sampled data sorted ÷ 2) + 1\n(3.4)\n第２段階目は「トレーニング中の角度の取得」である．Y 軸方向の加速度とZ 軸方向の加速度の値のアー\nクタンジェントを求め，求まったラジアンを度に変換し，角度を算出している(式3.5)．0.077 秒に１回の\n更新が行われるため，トレーニング中の角度をほぼリアルタイムに算出することが可能である．\nangle during training = arctan(Y axis acceleration value ÷ Z axis acceleration value)\n(3.5)\n第３段階目は「ずれの算出」である．第１段階で基準値，第２段階で暫定値を求める方法を説明した．姿\n勢判定を行う際は式3.5 と式3.4 の差を求めることで実現可能である．ト",
            "求める方法を説明した．姿\n勢判定を行う際は式3.5 と式3.4 の差を求めることで実現可能である．トレーニング中の角度がキャリブ\nレーション時の角度に対して5 °以上15 °以下の範囲（相対的な角度）に収まるとき，正しい姿勢と判定\nする．しかし，キャリブレーションは床に対して垂直方向に直立して行うことを前提としているため，π/2\nラジアンを考慮しなければならない．そのため，それぞれ90 °を引いて下記に示される式3.6，式3.7，式\n3.8 のようになる．\nhigh waist position : (angle during training −median in calibration) < −76.5◦\n(3.6)\ngood waist position : −76.5◦≤(angle during training −median in calibration) ≤−70.0◦\n(3.7)\nlow waist position : −70.0◦< (angle during training −median in calibration)\n(3.8)\n以上のようなアルゴリズムを",
            "aining −median in calibration)\n(3.8)\n以上のようなアルゴリズムを用いて，体幹トレーニング中の姿勢を判定し，トレーニングの支援につなげ\nている．\n28\nここからは，具体的なフィードバック方法について紹介する．フィードバック要素としては，骨格画像を\nリアルタイムに表示するものと文字によって姿勢の状態変化を表示するものの２種類を作成した．\n従来型システムにおいて，イヤホンから音楽を流し，腰の高さによって音楽の周波数を変化させるフィー\nドバック方法があった[26]．しかしながら，今回この機能は排除した．音楽を聴きながらトレーニングを行\nうことは，集中力が高まる一方で筋肉の合成を阻害する可能性がある[33]．男性においては，音楽を聴くこ\nとでテストステロン[34] の分泌が抑えられるという研究結果が出ている．テストステロンは筋肉の合成に\nは欠かせない男性ホルモンである．しかしながら，女性の場合は逆に，音楽を聴くことでテストステロン\n値が上がるという結果が出ている．老若男女問わず誰でも使いやすいシステムを目指すため，音楽による\nフィードバックについては見直しが必",
            "．老若男女問わず誰でも使いやすいシステムを目指すため，音楽による\nフィードバックについては見直しが必要であると考え，音楽によるフィードバック機能を排除し，システム\nを作成し直した．\nまず，画像によるフィードバック方法について説明する．腰の位置が高い・良い・低いの３種類の画像を\nリアルタイムに切り替える仕組みになっている．使用している画像は骨格画像となっており，腰の位置が高\nいとき，低いときの代表例と良い姿勢の３つを「e-skin MEVA[35]」で撮影したものを使用している．その\nため，従来型システム[26] のように腰が高い・低いを伝えるだけでなく，どのように腰が高いのかを視覚\n的に認識することが可能である．\n次に，文字による姿勢の状態表示について説明する．トレーニング中の腰の位置に応じて「HIGH」「GOOD」\n「LOW」の文字を表示するというものである．一見シンプルなシステムに見えるかもしれないが，五感の\nうちの一つである視覚は人間の情報判断において87%の割合を占めている[36]．また，数値的に加速度の\n値を見たい上級者向けに，X 軸，Y 軸，Z 軸方向の加速度の値をリアルタ",
            "]．また，数値的に加速度の\n値を見たい上級者向けに，X 軸，Y 軸，Z 軸方向の加速度の値をリアルタイムに表示できるようにした．こ\nれにより，姿勢の良し悪しだけを見たい一般ユーザだけでなく，数値的なデータを客観的に見たい専門家ま\nで幅広いカテゴリーの人々に使っていただけるだろう．\n最後に，腰の位置（姿勢の良し悪し）に応じたスマートフォン上のフィードバック画面の例を図3.24，図\n3.25，図3.26 に示す．\n図3.24: 腰の位置が高い時\n図3.25: 腰の位置が良い時\n図3.26: 腰の位置が低い時\n29\n3.2.3\nトレーニングスタッツ閲覧機能-長期的フィードバック-\n本項では，長期的フィードバック機能の一つである「トレーニングスタッツ閲覧機能」について論じる．\n本機能は自身のトレーニング時の姿勢の良し悪し判定結果の割合を閲覧できる機能である．\n（図3.27 中央右）\n本機能を実装した目的は，ユーザのモチベーション維持を促進するためである．自身のトレーニングスタッ\nツを振り返ることのできるこの機能だが，加速度センサから得られた腰の角度の値をトレーニングセッショ\nンごとにFireb",
            "のできるこの機能だが，加速度センサから得られた腰の角度の値をトレーニングセッショ\nンごとにFirebase（[37]）に送信し，アプリケーション上からFirebase に格納された情報を参照することで\n本機能を実現している．\nまた，データの保存方法だが，トレーニングを実施する画面に「データベースへ保存する」専用ボタンが\nあり，それを押下することでFirebase にデータを送信することができる. そのボタンの詳細は3.4 節で詳し\nく述べる．\n3.2.4\n他者とのランキング機能-長期的フィードバック-\n本項では，長期的フィードバック機能の一つである「他者とのランキング機能」について論じる．本機能\nは，同じアプリケーションを使用して体幹トレーニングを行っている人たちとオンライン上で対戦できる\nというものである．\n（図3.27 左下）本機能を実装した目的は，ユーザの競争心を刺激し，モチベーション向\n上を促進するためである．同じ体幹トレーニングを行っている他のユーザと自分のスコアを比較できるこ\nの機能だが，Firebase に送信された個人データをトレーニングセッションごとにFirebase",
            "\nの機能だが，Firebase に送信された個人データをトレーニングセッションごとにFirebase 上でソートを行\nい、順位を表示することで本機能を実現している.\n図3.27: 長期的フィードバック（個人データ&ランキング）の概要図\n30\n3.2.5\n３日坊主防止リマインダ機能-長期的フィードバック-\n本項では，長期的フィードバック機能の一つである「３日坊主防止リマインダ機能」について論じる．本\n機能は，体幹トレーニングを３日間怠けた場合、そのユーザに対して「そろそろ体幹トレーニングに取り組\nみましょう！」という通知を発行するというものである．３日間トレーニングを怠った場合に通知する仕組\nみを考案したが，これはフィットネスジムを利用している人の多くが，週２回の頻度で通っているからであ\nる[38]．参照したデータによると，通っている頻度は「週2 回程度」「週1 回程度」「週3～4 回程度」の順\nに多いそうだ．\n図3.28: 長期的フィードバック（通知機能）の概要図\n31\n3.3\nW.I.L.-CoreMoni におけるデータの流れ\n本節では，提案システム「W.I.L.-CoreMoni",
            "L.-CoreMoni におけるデータの流れ\n本節では，提案システム「W.I.L.-CoreMoni」のデータの流れについて図3.29 に沿って論じる．ユーザは\n加速度センサであるmovesense を装着し，トレーニングを行う．movesense より，X,Y,Z 軸方向の加速度の\n値を取得する．取得された加速度の値はBluetooth で接続されているスマートフォンに送信され，スマート\nフォンに搭載されている自作アプリケーション内で角度に変換処理される．処理された角度のデータは，短\n期的フィードバックとして，姿勢判定処理されたのちに，ユーザに直接フィードバックとして提供される．\n同時に，Firebase へもデータが送信される．Firebase ではトレーニング種目やトレーニングセッション，\nユーザ情報などが格納されている. オンライン上で管理されているこれらの情報も，ランキング機能や自身\nのトレーニングスタッツ閲覧機能，通知機能の要素として，長期的フィードバックに活用されている. 小さ\nな加速度センサから得られた情報はマルチフィードバックとして，形を変えてユーザに還元されている構",
            "小さ\nな加速度センサから得られた情報はマルチフィードバックとして，形を変えてユーザに還元されている構図\nとなる．\n図3.29: W.I.L.-CoreMoni におけるデータフロー\n32\n3.4\nW.I.L.-CoreMoni の使い方\n本節では，W.I.L.-CoreMoni の使い方について論じる．先にトレーニング時の利用手順について，次に\nトレーニング後の利用手順について論じる．\nトレーニング時のアプリケーションの利用手順は以下の通りである．\n1. W.I.L.-CoreMoni のアプリケーションを押下（図3.30）\n2. アプリケーションが起動する（図3.31）\n3. ログイン可能なユーザが一覧表示される（図3.32）\n4. 自身の名前を選択し，スタートボタンを押下（図3.33）\n5. ログインが完了する（図3.34）\n6. トレーニングメニューを選択する（図3.35）\n7. 位置情報へのアクセスを許可する（図3.36）\n8. デバイス検出・接続を許可する（図3.37）\n9. 再度，位置情報へのアクセスを許可する（図3.38）\n10. Connect ボタンを押下し，デバイス",
            "再度，位置情報へのアクセスを許可する（図3.38）\n10. Connect ボタンを押下し，デバイスを接続する（図3.39）\n11. スキャン開始（図3.40）\n12. 接続試行（図3.41）\n13. センサの特定（図3.42）\n14. 接続完了（図3.43）\n15. キャリブレーションボタン押下（図3.44）\n16. キャリブレーションの開始（図3.45）\n17. ５秒後，キャリブレーション終了（図3.46）\n18. スタートボタン押下（図3.47）\n19. トレーニング&計測開始（図3.48）\n20. ストップボタン押下（図3.49）\n21. トレーニング&計測終了（図3.50）\n22. 画面下部のボタンを押下し，トレーニングデータをデータベースへアップロードする（図3.51）\nまた，図3.30～図3.51 に前述した手順ごとのアプリケーションの画面を示す．\n33\n図3.30: アプリケーション選択図3.31: アプリケーション起動\n図3.32: ユーザの一覧表示\n図3.33: ログインユーザの選択\n図3.34: ログイン完了\n図3.35: トレーニングメニュー\n34\n図3.36:",
            "インユーザの選択\n図3.34: ログイン完了\n図3.35: トレーニングメニュー\n34\n図3.36: 位置情報の許可\n図3.37: デバイス接続の許可\n図3.38: 位置情報の再許可\n図3.39: デバイスの接続\n図3.40: スキャン開始\n図3.41: 接続試行\n35\n図3.42: センサの特定\n図3.43: 接続完了\n図3.44: キャリブレーション\n図3.45: キャリブレーション開始図3.46: キャリブレーション終了\n図3.47: スタートボタン押下\n36\n図3.48: 計測開始\n図3.49: ストップボタン押下\n図3.50: 計測終了\n図3.51: データベースへ格納\n37\n次にトレーニング後のアプリケーションの利用手順について論じる．トレーニング後のアプリケーション\nの利用手順は以下の通りである．\n1. Activity Record ボタンを押下（図3.52）\n2. 閲覧したいコンテンツを選択（図3.53）\n3. 個人データの表示（図3.54）\n4. ランキングの表示（図3.55）\n5. ３日間トレーニングを怠けた際のロック画面に表示された通知（図3.56）\n6. ３日",
            "3.55）\n5. ３日間トレーニングを怠けた際のロック画面に表示された通知（図3.56）\n6. ３日間トレーニングを怠けた際のコントロールセンターに表示された通知（図3.57）\n7. ３日間トレーニングを怠けた際のアプリケーションアイコンに表示された通知（図3.58）\nまた，図3.52～図3.58 に手順ごとのアプリケーションの画面を示す．\n図3.52: Activity Record\n図3.53: コンテンツ選択\n図3.54: 個人データ表示\n38\n図3.55: ランキング表示\n図3.56: 通知（ロック画面）\n図3.57: 通知\n（コントロールセンター）\n図3.58: 通知\n（アプリケーションアイコン）\n39\n第4章\nスコアリングによるモチベーション維持の\n検証（予備実験）\n本章では，自身のトレーニングスタッツ閲覧機能およびランキング機能を搭載したシステム（以下，ス\nコアリングと呼ぶ）を利用した場合とシステムを利用しなかった場合を比較した予備実験について論じる．\n第4.1 節では予備実験の目的について，第4.2 節では予備実験の方法について，第4.3 節では予備実験の手\n順について",
            "実験の目的について，第4.2 節では予備実験の方法について，第4.3 節では予備実験の手\n順について，第4.4 節では予備実験の分析方法について，第4.5 節では予備実験の結果について，第4.6 節\nでは考察や課題および今後の展望について述べる．\n4.1\n予備実験の目的\n本実験の目的は，スコアリング機能の有効性検証である．大きくまとめると以下の４つとなる．\n1. スコアリング機能の有無により，体幹トレーニングに及ぼす影響を調査し，スコアリング機能の有効\n性を検証すること．\n2. 本システムを使用することでトレーニングの継続を促すことができるのかを検証すること．\n3. システムなしとありを比較し、2 カ月後の姿勢変化を観察すること．\n4. システムのユーザビリティについて評価すること．\n4.2\n予備実験の方法\n本実験の条件について論じる．被験者は20 代-50 代の男女19 人（男性14 人，女性5 人）で行った．うち，\n現在も運動経験があるものが5 人，過去に習慣的にあったものが12 人，まったく運動したことのない人が\n2 人である．トレーニングの種目は予備調査で一番認知度の高かった「",
            "，まったく運動したことのない人が\n2 人である．トレーニングの種目は予備調査で一番認知度の高かった「フロントプランク」とした．実験期\n間は２カ月間とし，実験の実施時間と場所は各被験者の任意とした．2 つのグループに分割した．GroupA\nはシステムを使用する群であり，GroupB はシステムを使用しない群である．各被験者には，実験が開始さ\nれる前と後に，２か月後の成果を評価するための参考値としてトレーニング時の腰の角度を計測した．ま\nた，システムの使いやすさを評価するためのSUS アンケートや継続に関するアンケートなどを用意した．\nなお，本実験にあたっては謝礼の存在を明らかにしないものとした．\n4.3\n予備実験の手順\n実験手順は以下のとおりである．\n＜A グループ＞\n1. 被験者に対する実験の説明．\n2. 同意書の記入（運動経験などの個人データ収集）．\n3. 実験キットの送付．\n40\n4. 実験前データの取得（実験監督者同伴）．\n5. 実験開始（２か月間）\n6. 実験後データの取得（実験監督者同伴）\n7. アンケート記入\n8. 実験キットの返送\n————————————————————",
            "監督者同伴）\n7. アンケート記入\n8. 実験キットの返送\n——————————————————————————————————————————————\n＜B グループ＞\n1. 被験者に対する実験の説明．\n2. 同意書の記入（運動経験などの個人データ収集）．\n3. 実験前データの取得（実験監督者同伴）．\n4. 実験開始（２か月間）\n5. 実験後データの取得（実験監督者同伴）\n6. アンケート記入\n4.4\n予備実験の分析方法\n4.4.1\nトレーニングスタッツ\n実験前と実験後に取得したスコアを比較し，２か月間の「体幹トレーニングにおける正しい姿勢を保持で\nきた割合」の変化を観察する．また，2 か月間を通して体幹トレーニングを何セッション継続することがで\nきたのかを分析する．\n4.4.2\nSUS アンケート\nSUS アンケートはSystem Usability Scale の略で，ジョン・ブルック（John Brooke）により1986 年に\n開発され，システムのユーザビリティの受け止められ方について測定するために最も広く利用されている\n質問票である[39][40]．このスケールは，1（まっ",
            "について測定するために最も広く利用されている\n質問票である[39][40]．このスケールは，1（まったくそう思わない）から5（まったくそう思う）の10 の\n記述から成り立っている．奇数項目の設問は肯定的な質問であり，偶数番号の設問は否定的な質問である．\n集計方法は，奇数番号の設問に対しては回答番号から１を引く．偶数番号の設問に対しては，５から回答番\n号を引く．そして，合計スコアに2.5 をかけて０から100 までのスケールに変換する．各スコアに対する評\n価の指標を図4.1 に示す．\nモチベーションに関する主観評価アンケート\nトレーニングを継続できた理由や継続できなかった理由を問う設問を用意した．今後もトレーニングを\n継続するためにどのようなサポートが必要であるかということも尋ねた．また，システムを使用せずに２\nか月間トレーニングをしたグループB の被験者に対しては，支援システムを使用してみたいかどうかを尋\nねた．このように，被験者の主観評価を問うアンケートを複数個用意した．\n41\n図4.1: SUS スコア指標（[39][40] から引用）\n4.5\n実験結果\n4.5.1\n実験前と実験後",
            "1: SUS スコア指標（[39][40] から引用）\n4.5\n実験結果\n4.5.1\n実験前と実験後での正しい姿勢を維持できた時間の比較結果\n本節では，2 か月間のトレーニング成果を検証するために，システムを使用したグループと使用しなかっ\nたグループそれぞれの，正しい姿勢を維持できた割合を比較する．また，システムの姿勢判定における”\nGood ”の割合で算出した．本計測は実験前と2 か月後である実験後の計2 回おこなった．なお，システムの\n有無によるバイアスを無くすために，本計測においては，両グループともシステムを使用せずに計測した．\n表4.1 は2 か月間，体幹トレーニング支援システムを使用したグループの実験前と実験後のGood の割合\nである．9 人中5 人の割合が増加していることが分かる．Good のカウント回数が少なく，割合が高いスコ\nアが出ていることは，ブレずに正しい姿勢でトレーニングをすることができているということが言えるだ\nろう．一方で，表4.2 は体幹トレーニング支援システムを使用しなかったグループの実験前後のGood の割\n合であるが，10 人中8 人の割合が増加して",
            "テムを使用しなかったグループの実験前後のGood の割\n合であるが，10 人中8 人の割合が増加していることが分かる．センサの装着位置によって判定は異なって\nしまうため，一概には言えないが，本システムは2 か月間のトレーニングをするにあたっては，体幹トレー\nニング支援システムの有無によって，その後のユーザのトレーニング時の姿勢に影響を及ぼすとは考えに\nくいと結論付ける. なお，カッコ内の数値は姿勢判定においてGood の判定がなされた回数を示している.\n42\n表4.1: GroupA の実験前後データ\nUserID\n実験前データ\n実験後データ\n1\n3.95% (16)\n5.26% (20)\n2\n2.3% (9)\n0.26% (1)\n3\n0.26% (1)\n96.72% (383)\n4\n22.51% (86)\n24.55% (110)\n5\n75.13% (287)\n3.17% (12)\n6\n90.16% (0)\n0% (348)\n7\n0.26% (1)\n86.2% (331)\n8\n23.6% (93)\n39.1% (156)\n9\n84.95% (333)\n47.47% (188)\n表4.",
            "% (93)\n39.1% (156)\n9\n84.95% (333)\n47.47% (188)\n表4.2: GroupB の実験前後データ\nUserID\n実験前データ\n実験後データ\n1\n1.31% (5)\n53.79% (213)\n2\n13.7% (53)\n97.4% (374)\n3\n0% (0)\n0.26% (1)\n4\n0.26% (1)\n1.04% (4)\n5\n0% (0)\n100% (1)\n6\n19.35% (83)\n1.51% (6)\n7\n0.26% (1)\n0% (0)\n8\n0.52% (2)\n3.05% (12)\n9\n0.25% (1)\n0.76% (3)\n10\n0% (0)\n79.76% (331)\n4.5.2\nSUS スコア\n本節ではSUS スコアの結果について考察する．スコアは表4.3 のとおりであり，スコア指標は図4.1 の\nとおりである．\n平均スコアは67.5 ポイントとなり，C スコアであった．あまり期待していた結果ではないものの，Good\nの評価となったため，本システムのユーザビリティは有効であると結論付けることができる．\n43\n表4.3: 得点データ\nUser",
            "ステムのユーザビリティは有効であると結論付けることができる．\n43\n表4.3: 得点データ\nUserID\nScore\n1\n52.5\n2\n70\n3\n80\n4\n67.5\n5\n57.5\n6\n77.5\n7\n80\n8\n57.5\n9\n65\n44\n4.5.3\n体幹トレーニングをおこなった頻度・継続性\n本節では継続性の観点からシステムの有効性を評価した結果を述べる．本実験はシステムを使用する\nGroupA とシステムを使用しないGroupB の２つのグループで行った．GroupA とGroupB の継続性を見\nる．図4.2 と図4.3 は２か月間の間に行った体幹トレーニングの継続頻度を示している．\nまた，週あたりの取り組み日数が３日以上を示す，赤系色の割合が多ければ多いほど期待通りの結果であ\nることを事前に提示しておく．\n図4.2: 体幹トレーニングの継続頻度(GroupA)\n図4.3: 体幹トレーニングの継続頻度(GroupB)\nこれらの円グラフを見ていこう．まずはGroupA について論じる．図4.2 は継続回数を継続日数で換算し\nた割合を示している. 週3.4 日以上取り組んだ割合は56%，週に",
            "2 は継続回数を継続日数で換算し\nた割合を示している. 週3.4 日以上取り組んだ割合は56%，週に1 日より少ない割合は33%となった．この\nことから，GroupA の被験者の半数以上が週3,4 日継続できたことがわかった（赤系色）．一方，図4.3 は\nGroupB の結果を示している．GroupB では，週3.4 日以上取り組んだ割合は0%であった．また，継続頻\n度が週に1 日より少ない割合は70%となっている．このことから，理想とする継続頻度である週3,4 日の割\n合が半数以上となったGroupA の有効性が検証された．GroupA はシステムを使用したグループであるた\nめ，本システムはモチベーションや継続の動機づけにポジティブな結果をもたらしていることが分かった．\n45\n次に，トレーニングを継続する際に，システム上のどのような機能が動機づけに起因したかについて調査\nしたアンケート結果を見ていこう．図4.4 のアンケート結果によると，\n「自身のトレーニング結果を閲覧でき\nる」「オンラインによる対戦機能」と回答された割合がそれぞれ55.6%となった．そのため，システムによ\nる継続の",
            "ラインによる対戦機能」と回答された割合がそれぞれ55.6%となった．そのため，システムによ\nる継続の有効性が検証されたと考えることができる．しかし，\n「トレーニングを忘れないためのリマインダ\n機能が欲しい」「ランキングの変動がなかった」という声も上がった．今後，これらの要素を検討しなけれ\nばならないと感じた．\n図4.4: どのような機能が動機づけに起因したか\n最後に，そのほかに実施したアンケート結果を掲載する．今後も体幹トレーニングを継続したい感じる\nと回答したのは，GroupA が77.8%，GroupB が30%となった（図4.5，4.6）．この２カ月で健康的な体に\nなった・スタイルが良くなったと感じると回答したのは，GroupA が44.5%，GroupB が0%となった（図\n4.7，4.8）．\n図4.5: 今後も体幹トレーニングを継続したいか(GroupA)\n46\n図4.6: 今後も体幹トレーニングを継続したいか(GroupB)\n図4.7: この２カ月で健康的な体になった・スタイルが良くなったと感じるか(GroupA)\n図4.8: この２カ月で健康的な体になった・スタイルが良く",
            "ルが良くなったと感じるか(GroupA)\n図4.8: この２カ月で健康的な体になった・スタイルが良くなったと感じるか(GroupB)\n47\nシステムを使用しなかった被験者らに「体幹トレーニング支援システム」を使用してみたいか尋ねたとこ\nろ，70%が「使ってみたい」と回答した（図4.9）．彼らが本システムを使用した際にどのような結果が得\nられるか興味がある．\n図4.9: 本システムを使用してみたいか(GroupB)\n48\n4.6\n考察・課題・今後の展望\n本予備実験では，スコアリング機能を搭載した体幹トレーニング支援システムの開発および効果検証を\n行った．本システムは，トレーニング中の姿勢を視覚的にフィードバックすることで，適切な姿勢の維持を\nサポートする．また，競争心を掻き立てるランキング機能や個人の成果を確認できるデータ閲覧機能を実\n装し，ユーザのモチベーション向上に寄与することを目指した．実験には19 名の被験者を対象に，本シス\nテムを使用したトレーニングと，システムを使用しない通常のトレーニングを行った．その結果，本システ\nムを使用したトレーニングの方が，体幹の安定性と筋力が向上し",
            "トレーニングを行った．その結果，本システ\nムを使用したトレーニングの方が，体幹の安定性と筋力が向上したことが確認された．また，被験者の自\n己評価によれば，システムの使用はトレーニングのモチベーション向上に寄与したという結果が得られた．\n以上の結果から，スコアリング機能を搭載した体幹トレーニング支援システムは，体幹トレーニングの効\n果向上とモチベーション維持に寄与する可能性が示された．\nしかし，今回の予備実験で課題が３つほど見つかった．１つ目は，デバイス装着位置のより詳細な選定で\nある．正しい姿勢でトレーニングを行えていたとしても，センサの装着位置によって若干のずれが生じてし\nまう．しかしながら，へその位置にベルトを装着することで問題は解消された．そのため，次回の実験では\n装着位置の説明を、実演を通して行いたい．\n２つ目はモチベーション維持のためのコンテンツ拡張である．今回実装した，ランキング機能とトレーニ\nング振り返り機能だけでは完全であるとは言えない．第4.5.3 節でも述べたが，トレーニングを忘れないよ\nうなリマインド機能があるとより良いと感じた．\n３つ目は被験者の選定である．今回",
            "ーニングを忘れないよ\nうなリマインド機能があるとより良いと感じた．\n３つ目は被験者の選定である．今回の実験で募集した被験者は無作為に選んだ．そのため，属性もばらば\nらであり，正しい評価実験が行えていない．そのため，そもそもエクササイズに関心がないがゆえに，継続\nできないことも考えられる．\n今後の展望として，２か月の期間におけるリタイアのタイミングと被験者の属性などの解析を詳細に行\nい，モチベーショングラフの作成を行いたい．今後は，さらなる機能の追加やシステムの改善を行い，より\n効果的な体幹トレーニング支援を目指す．具体的には，より効果的なモチベーション維持のため，通知機\n能を実装することも考えている．さらに，今回募集した被験者は，無作為であるため，体幹トレーニング\nをしたいと考えている人ではない．トレーニングをしているがなかなか続かない人たちをターゲットにし，\nより詳細な研究を行いたい．そのため，被験者の選出も慎重に行いたいと考えている．\n49\n第5章\nスコアリング並びにリマインドによるモチ\nベーション維持の検証（本実験）\n本章ではスコアリング並びにリマインドによるモチベーション維持の",
            "モチ\nベーション維持の検証（本実験）\n本章ではスコアリング並びにリマインドによるモチベーション維持の検証について論じる．4 章でも述べ\nた通りだが、予備実験では自身のトレーニングスタッツとランキング機能のみだった。予備実験の結果を受\nけ，トレーニングを忘れないようなリマインド機能を実装し，本機能の有効性を検証した. 第5.1 節では本\n実験の目的について，第5.2 節では本実験の方法について，第5.3 節では本実験の手順について，第5.4 節\nでは本実験の分析方法について，第5.5 節では本実験の結果および考察について述べる．\n5.1\n本実験の目的\n本実験の目的は，リマインド機能の有効性検証である．大きくまとめると以下の３つとなる．\n1. リマインド機能の有無により，体幹トレーニングに及ぼす影響を調査し，リマインド機能の有効性を\n検証すること．\n2. 本システムを使用することでトレーニングの継続を促すことができるのかを検証すること．\n3. システムのユーザビリティについて評価すること．\n5.2\n本実験の方法\n本実験の条件について論じる．本実験は20 代から50 代の被験者８名で実施した",
            "5.2\n本実験の方法\n本実験の条件について論じる．本実験は20 代から50 代の被験者８名で実施した．トレーニングの種目\nは予備調査で一番認知度の高かった「フロントプランク」とした．実験期間は2024 年11 月1 日から2024\n年11 月30 日の１か月間とし，実験の実施時間と場所は各被験者の任意とした．被験者には内密に２つのグ\nループに分割した．GroupA は最初の２週間通知がある群であり，GroupB は後半の２週間に通知がある群\nである．各被験者には，システムの使いやすさを評価するためのSUS アンケートや継続性・モチベーショ\nンに関するアンケートなどを用意した．\n5.3\n本実験の手順\n実験手順は以下のとおりである．\n＜A グループ＞\n1. 被験者に対する実験の説明．\n2. 同意書の記入（運動経験などの個人データ収集）．\n3. 実験キットの送付．\n4. 実験開始（１か月間：前半通知あり，後半通知なし）\n5. アンケート記入\n6. 実験キットの返送\n50\n——————————————————————————————————————————————\n＜B グループ＞\n1. 被験",
            "———————————————————————————————————\n＜B グループ＞\n1. 被験者に対する実験の説明．\n2. 同意書の記入（運動経験などの個人データ収集）．\n3. 実験キットの送付．\n4. 実験開始（１か月間：前半通知なし，後半通知あり）\n5. アンケート記入\n6. 実験キットの返送\n5.4\n本実験の分析方法\n5.4.1\nトレーニングの継続性\n１か月間にトレーニングをどのくらい継続できたのかをFirebase[37] のﬁrestore[41] を参照することで解\n析する．１か月間に取り組んだ日数と安定した継続頻度になっているかを検証する．\n5.4.2\nSUS アンケート\n前節で述べた通りの方法で解析を行う．また，SUS アンケートの質問文の例を掲示する．\n＜質問文＞\n1. このシステムをもっと頻繁に使用したい．\n2. このシステムは必要以上に複雑である．\n3. このシステムはシンプルで使いやすい．\n4. このシステムを使用するには技術的なサポートが必要.\n5. システムがスムーズに機能し，うまく統合されている.\n6. イレギュラーなことも多い.\n7. このシステム",
            "テムがスムーズに機能し，うまく統合されている.\n6. イレギュラーなことも多い.\n7. このシステムはほとんどの人がすぐに習得できる.\n8. このシステムは手間がかかる．\n9. このシステムの操作に自身がある．\n10. このシステムを使い始めるまでは学ぶことがたくさんある．\n5.4.3\nモチベーションに関する主観評価アンケート\nトレーニングを継続できた理由や継続できなかった理由を問う設問を用意した．提案システムに実装し\nた機能である３要素について，トレーニングを継続できた要因になっているかを問うこととした．１つ目は\n自身のトレーニングスコア，２つ目はランキング，３つ目は３日坊主防止プッシュ通知である．また，今後\nもトレーニングを継続するためにどのようなサポートが必要であるかということも尋ねた．\n51\n5.4.4\n道具性期待理論によるモチベーション評価\nユーザのトレーニング中のモチベーションを定量化するために，道具性期待理論[42] を用いてモチベー\nションを数値化する．道具性期待理論（Expectancy Theory）とは心理学や経営学において，動機付けを説\n明するための理論である．",
            "xpectancy Theory）とは心理学や経営学において，動機付けを説\n明するための理論である．主にビクター・ブルームが提唱したもので，特に仕事や職場における人間の行動\nを理解する際に用いられる．この理論は，人が目標に向かって行動する動機を，次の３つの要因の掛け合わ\nせとして説明できる．\n１つ目は「期待（Expectancy）」である．努力をすれば成果が得られるという信念や確度の程度が定義と\nなる．例えば，\n「一生懸命勉強すれば試験に合格できる」と思えるかどうかなどがあげられる．影響を受け\nる要因としては，技術や知識，過去の成功体験などである．\n２つ目は「道具性（Instrumentality）」である．その成果が望む報酬や結果に結びつくと信じる度合いが\n定義である．例えば，\n「試験に合格すればよい仕事に就ける」という認識などがあげられる．影響を与える\n要因としては，報酬体系の透明性，上司や組織の公平性などである．\n３つ目は「誘意性（Valence）」である．得られる報酬や結果の価値や魅力が定義である．例えば，\n「良い\n仕事に就くことに価値を感じるかどうか」などがあげられる．影響を",
            "や魅力が定義である．例えば，\n「良い\n仕事に就くことに価値を感じるかどうか」などがあげられる．影響を与える要因としては，個人の価値観や\n目標，欲求などである．\nこれら３つの要素を用いることで，動機づけは次の理論数式5.1 で定量化することが可能である．\n各要因のパラメータは0.0（設問に対して否定）から1.0（設問に対して肯定）までの間とし，算出した．\nMotivation = Expectancy × Instrumentality × V alence\n(5.1)\n52\n5.5\n本実験の結果と考察\n5.5.1\nトレーニングの継続頻度\n本項では１か月間で体幹トレーニングに取り組んだ頻度について論じる．表5.1 は通知機能が有効だった\n期間（半月）におけるユーザごとの平均インターバル日数・分散および標準偏差を示している．平均イン\nターバル日数というのは，トレーニング実施後，次にもう一度体幹トレーニングに取り組むまでの所要日\n数を意味している．いわゆる休息期間と認識していただければ幸いだ．\n被験者は次のトレーニングに取り組むまでに平均して３日ほどかかっている．すなわち，週に３～４日ほ\nど",
            "\n被験者は次のトレーニングに取り組むまでに平均して３日ほどかかっている．すなわち，週に３～４日ほ\nど体幹トレーニングに取り組んだことがわかる．また，標準偏差に注目すると値が小さく，安定した頻度で\nトレーニングに取組めていたと推測できる．\n表5.1: 通知機能有効期間におけるユーザごとの平均インターバル日数・分散および標準偏差\nUserID\nAverage\nVariance\nStandard deviation\n1\n3.5\n2.3\n1.5\n2\n2.0\n0.0\n0.0\n3\n2.2\n0.1\n0.4\n4\n2.0\n—\n—\n5\n2.5\n0.3\n0.5\n6\n2.3\n0.2\n0.5\n7\n7.5\n6.3\n2.5\n8\n2.3\n0.6\n0.7\nAverage\n3.0\n—\n—\n一方で，表5.2 は通知機能が無効だった期間（半月）におけるユーザごとの平均インターバル日数・分散\nおよび標準偏差を示している．\n被験者は次のトレーニングに取り組むまでに平均して８日ほどかかっている．すなわち，週に１日も体幹\nトレーニングに取り組まなかった割合が高かったことがわかる．また，被験者３，７，８に注目してもらい\nたい．彼らは次",
            "に取り組まなかった割合が高かったことがわかる．また，被験者３，７，８に注目してもらい\nたい．彼らは次のトレーニングに取り組むまでに約16 日間の休息期間を設けていたことがわかる．すなわ\nち，安定した頻度でトレーニングに取組むことができておらず，低頻度かつ不安定な継続頻度であったと推\n測できる．\n表5.2: 通知機能無効期間におけるユーザごとの平均インターバル日数・分散および標準偏差\nUserID\nAverage\nVariance\nStandard deviation\n1\n5.0\n13\n3.6\n2\n2.5\n0.3\n0.5\n3\n16\n—\n—\n4\n2.4\n0.2\n0.5\n5\n3.8\n1.2\n1.1\n6\n4.7\n1.6\n1.3\n7\n16\n—\n—\n8\n16\n—\n—\nAverage\n8.3\n—\n—\n53\n表5.3 は通知機能が有効時と無効時の両者における，被験者が次のトレーニングに取り組むまでの平均イ\nンターバル日数を比較した表である．\n全体的に，通知機能が有効であった期間のインターバル日数は少ない印象である．その一方で通知機能が\n無効であった期間のインターバル日数は比較的多い印象である．\nまた，",
            "印象である．その一方で通知機能が\n無効であった期間のインターバル日数は比較的多い印象である．\nまた，被験者７においては両期間とも継続頻度が低い．これは被験者がたまたま繁忙期であったことが要\n因である．しかしながら，通知機能が有効な期間の方が無効な期間に比べて継続頻度が高くなっていたた\nめ，良い結果を得ることができたと考察できる．\n表5.3: 通知機能有効・無効別の次回トレーニングまでの平均インターバル日数\nUserID\nThe notiﬁcation enabled\nThe notiﬁcation disabled\n1\n3.5\n5.0\n2\n2.0\n2.5\n3\n2.2\n16\n4\n2.0\n2.4\n5\n2.5\n3.8\n6\n2.3\n4.7\n7\n7.5\n16\n8\n2.3\n16\nAverage\n3.0\n8.3\n表5.4 は通知機能が有効時・無効時の標準偏差を比較した表である．また，カッコ内の数字はトレーニン\nグの継続回数を表している．\n通知機能が有効であるときの標準偏差を見ると，0 に近い値が散見される．一般的に，標準偏差は値が０\nに近ければ近いほど平均値との差が小さく，データのばらつきが非常に小",
            "れる．一般的に，標準偏差は値が０\nに近ければ近いほど平均値との差が小さく，データのばらつきが非常に小さいと判断できる．先ほども述べ\nたが，これは被験者が安定した継続頻度でトレーニングに取り組むことができた結果であると推測できる．\nまた，継続回数（体幹トレーニングに取り組んだ回数）が多ければ多いほど，同時に標準偏差の値も０に\n近くなっていることから，通知機能によって安定した継続頻度・回数で体幹トレーニングに取り組めていた\nことがわかる．\n一方で通知機能が無効であるときの標準偏差を見ると3.6 という大きな値が見られる．これはデータのば\nらつきが比較的大きいと判断できる．このことから，通知機能が無効の時，被験者の体幹トレーニングの継\n続頻度は低頻度かつ不安定であると結論付けることができる．\n表5.4: 通知機能有効・無効ごとの標準偏差比較による頻度安定性評価\nUserID\nThe notiﬁcation enabled\nThe notiﬁcation disabled\n1\n1.5(4)\n3.6(3)\n2\n0.0(3)\n0.5(4)\n3\n0.4(6)\n—(1)\n4\n—(1)\n0.5(5)\n5",
            "6(3)\n2\n0.0(3)\n0.5(4)\n3\n0.4(6)\n—(1)\n4\n—(1)\n0.5(5)\n5\n0.5(4)\n1.1(4)\n6\n0.5(6)\n1.3(3)\n7\n2.5(2)\n—(1)\n8\n0.7(6)\n—(1)\n結論として，通知機能が無効であった期間に比べて通知機能が有効であった期間の方が被験者の体幹ト\nレーニングの継続頻度が高く，安定した頻度であったため，期待していた「安定した継続頻度の実現」およ\nび「本システムの有効性」を検証することができた．\n54\n5.5.2\n短期的および長期的フィードバックにおけるSUS スコア\n本項では，本実験のSUS スコアの結果について論じる．表5.5 は短期的フィードバック機能に対するSUS\nスコアの結果である．８名の被験者のうち，６名の被験者がグレードC 以上となった．平均スコアは，74.1\nポイントであった．\nまた，表5.6 は短期的フィードバック機能に対するSUS スコアの結果である．８名の被験者のうち，６\n名の被験者がグレードC 以上となった．平均スコアは，76.0 ポイントであった．\n以上のことから，本システムにおける短期的，長期的の両",
            "た．平均スコアは，76.0 ポイントであった．\n以上のことから，本システムにおける短期的，長期的の両フィードバックユーザビリティは有効であるこ\nとが分かった．しかし，一部の被験者においては，極度に低いユーザビリティであることも事実である．\n被験者１，３，５，６，７，８は短期的フィードバックおよび長期的フィードバックの両方に対し，高い\nスコアを提示した．一方で，被験者２，４は両フィードバックのユーザビリティに対し，D やF といった\n低めのスコアを提示した．彼らはシステムを使ってトレーニングすることが煩わしいと感想を残していた\nため，システムを使用してトレーニングを行うこと自体に抵抗があったと考える．\n全体として，良い結果を得ることができたと結論付ける．\n表5.5: 短期的フィードバックにおけるSUS スコア\nUserID\nScore\nGrade\n1\n95.0\nA+\n2\n12.5\nF\n3\n95.0\nA+\n4\n47.5\nF\n5\n82.5\nA\n6\n75.0\nB\n7\n90.0\nA+\n8\n95.0\nA+\nAverage\n74.1\nB\n表5.6: 長期的フィードバックにおけるSUS スコア\nUse",
            "\nA+\nAverage\n74.1\nB\n表5.6: 長期的フィードバックにおけるSUS スコア\nUserID\nScore\nGrade\n1\n95.0\nA+\n2\n12.5\nF\n3\n95.0\nA+\n4\n52.5\nD\n5\n94.0\nA+\n6\n70.0\nC\n7\n92.5\nA+\n8\n95.0\nA+\nAverage\n75.8\nB+\n55\n5.5.3\nモチベーション維持に関する主観アンケート結果\n本項ではモチベーション維持に関する主観アンケート結果について論じる．図5.1 は，今回の実験にて使\n用したアプリケーションの機能について効果的であったものはどの機能であったかを尋ねたアンケート結果\nである．本アンケートでは，システムの使いやすさなどではなく，モチベーション維持に関連する機能につ\nいて，その機能がモチベーションを維持する上で効果的であったか・有効であったかを調査した．\n調査の結果，他者との競争（ランキング）機能が87.5%と高く，次いで通知（３日坊主防止）機能が62.5%\nとなり最後に自身のトレーニングスコア閲覧機能が25%となった．他者との競争（ランキング）機能はラ\nンキングがリアルタイムに変動",
            "ングスコア閲覧機能が25%となった．他者との競争（ランキング）機能はラ\nンキングがリアルタイムに変動するため，ほかの人に順位を抜かされないように，ランキングを日々チェッ\nクすると同時にトレーニングを続けるよう習慣づけることが可能であったためこのような結果になったと\n考えられる．通知（３日坊主防止）機能はユーザの意志に関係なく３日間トレーニングを行っていなかった\n場合，自動的に通知が送信される仕組みであるため，受動的なフィードバックとなり，ユーザにとって有効\n的なフィードバックとなったと考える．自身のトレーニングスコア閲覧機能に関して，本機能が最下位と\nなったのは他の２機能と異なり，自発的な意思がないと受けることのできないフィードバックであるからだ\nと考える．自身のトレーニングスコアは，自分から確認しようという意思がなければ閲覧できない．そのた\nめ，このような結果になったと考えられる．\n図5.1: どの機能が特に効果的だったかを尋ねたアンケート結果\n次に本実験の焦点である通知機能がどのくらい有効であったかを調査した結果について論じる．図5.2 は\n通知機能が有効であったか否かを尋ねたアン",
            "い有効であったかを調査した結果について論じる．図5.2 は\n通知機能が有効であったか否かを尋ねたアンケートの結果である．アンケート調査の結果，被験者の75%\nが「有効である」と回答した．一方で，被験者の25%は「有効でない」と回答した．トレーニングの継続\n性が見られなかったユーザが含まれていたため，前提としてモチベーションが向上しなかったがゆえにシス\nテムは有効ではないと結論付けたと考える．\n最後に，トレーニング実施中の身体的コンディションについて調査した結果を掲載する．図5.3 はトレー\nニング中のフィジカルコンディションについて尋ねた結果である．被験者全員が「良い」または「普通」と\n回答したため，本実験に身体的な悪影響はなかったものと考えられる．\n56\n図5.2: 通知機能が効果的だったかを尋ねたアンケート結果\n図5.3: トレーニング中のフィジカルコンディションを尋ねたアンケート結果\n57\n5.5.4\n道具性期待理論に基づくモチベーション状態の評価\n道具性期待理論を検証するためのアンケートを集計し，期待値，道具性，誘意性について数値を算出し，\nモチベーション状態を数値化した．本項",
            "ンケートを集計し，期待値，道具性，誘意性について数値を算出し，\nモチベーション状態を数値化した．本項ではこれらの結果について論じる．\nトレーニングの実施に関係なく，普段の運動（体幹トレーニング）に対するモチベーションを数値化し\nた．その結果を表5.7 に示す．次にトレーニング時における体幹トレーニングに対するモチベーションを数\n値化した．その結果を表5.8 に示す．\nまず，表5.7 から見ていこう．数値が1 に近ければ近いほどモチベーションが高くなるのだが，0.5 未満\nの数値が目立つ．平均値は0.378 であり，お世辞にもモチベーションが高いとは言えない．しかし，表5.8\nをみると，0.5 や１といった１に近いまたは等しい数値が散見された．また，平均値も0.561 となっており，\n本システムを活用したことでモチベーションが相対的に向上したといえるだろう．\nその一方で，一部のユーザにおいてはモチベーションが下がってしまった．被験者４は継続性が低かった\nユーザである．本実験において，当該被験者のモチベーションが著しく低かったことが原因として考えるこ\nとができる．\n表5.7: 日常生活にお",
            "験者のモチベーションが著しく低かったことが原因として考えるこ\nとができる．\n表5.7: 日常生活におけるユーザの体幹トレーニングに対するモチベーション\nUserID\nValue\n1\n0.252\n2\n0.648\n3\n0.420\n4\n0.500\n5\n0.288\n6\n0.126\n7\n0.648\n8\n0.140\nAverage\n0.378\n表5.8: トレーニング実施時におけるユーザの体幹トレーニングに対するモチベーション\nUserID\nValue\n1\n0.392\n2\n0.648\n3\n1.000\n4\n0.024\n5\n0.576\n6\n0.196\n7\n0.648\n8\n1.000\nAverage\n0.561\n58\n第6章\n本研究の結論および今後の展望\n本章では本研究の結論および今後の展望について論じる．新型コロナウイルスの影響による健康被害に\n着目し，運動不足や生活習慣病について議論した．健康な身体を維持するためには日常的な運動が必要で\nあり，人々が自主的に運動を継続することを心掛けることが重要である．\n一人で簡単に行うことのできるトレーニングに，体幹トレーニングというインナーマッスルを鍛えるト\nレ",
            "．\n一人で簡単に行うことのできるトレーニングに，体幹トレーニングというインナーマッスルを鍛えるト\nレーニング方法がある．このトレーニングは，スポーツ動作に求められる能力向上だけでなく，立つ・座\nる・歩く動作など，日常生活においても重要な役割を果たしている筋力を鍛えることができる．\nしかしながら，指導者なしでは正しい姿勢でトレーニングが行えていなかったり，監督者がいないことで\n怠けてしまうなどの懸念点がある．これらの懸念点を解消するため，私は体幹トレーニングにおけるユー\nザ向け支援システムを提案した．本システムはウェアラブルデバイスとスマートフォンの２つのデバイスで\n構成されており，この２つがあれば誰でも簡単に使用することが可能である．今回は，フロントプランクと\nいう体幹トレーニングの種目を実験対象とした．\n本システムは，加速度を取得することができる500 円玉くらいの大きさのウェアラブルデバイスを腰に\n装着し，スマートフォンの画面を見ながらトレーニングを行う．その際，システムがユーザによって異なる\n基準値を取得したのち，独自のアルゴリズムによって，取得した加速度を角度に変換し，トレーニ",
            "って異なる\n基準値を取得したのち，独自のアルゴリズムによって，取得した加速度を角度に変換し，トレーニング中の\n暫定値と比較後，あらかじめ定義した閾値との判定結果によってユーザにリアルタイムにフィードバックを\n与え，姿勢改善を促すというものである．また，モチベーション維持を目的とした長期的フィードバックも\n実装し，自身のトレーニング履歴閲覧機能をはじめ，ランキング機能による競争や３日坊主防止のための\nリマインド通知機能などを組み込み，本研究の対象機能とした．\n本実験では，20 代から50 代の男女８名で実施した，トレーニングの種目は予備実験の時と同様，\n「フロ\nントプランク」とした．実験期間は2024 年11 月1 日から2024 年11 月30 日の１か月間で行い，実験の実\n施時間と場所は各被験者の任意とした．被験者には内密に２つのグループに分割し，GroupA は最初の２週\n間，通知が有効でなる群であり，GroupB は後半の２週間に通知が有効でになる群である．各被験者には，\nシステムの使いやすさを評価するためのSUS アンケートや継続性・モチベーションに関するアンケートな\nどを用意",
            "の使いやすさを評価するためのSUS アンケートや継続性・モチベーションに関するアンケートな\nどを用意した．\n本実験の結果，前章でも述べた通り，長期的フィードバックにおいて期待通りの結果を得ることができ\nた．特に長期的フィードバックの主要機能である「通知機能」「競争機能」「履歴閲覧機能」の有効性が検\n証された．３要素間に優劣の差はあるものの，結果として「継続頻度の向上」「安定したトレーニング継続\n回数」「モチベーションの維持・向上」の３点すべてにおいて期待通りもしくはそれ以上の結果を得ること\nができた．\n本研究の目的に対する結論は以下の通り：\n1. 短期的フィードバックの有効性を検証することができた．\n2. 長期的フィードバックの有効性を検証することができた．\n最後に，今後の展望について述べる．被験者に対し，トレーニングに取り組むうえで困難だったことはな\nにかを尋ねたところ，\n「加速度センサとスマートフォンの接続がうまくできない」という回答が散見された．\n本課題を解決すべく，別のセンサを用いてシステムを実装していくことも視野に，今後検討していきたい．\nまた，将来的にどのような機能があった",
            "いてシステムを実装していくことも視野に，今後検討していきたい．\nまた，将来的にどのような機能があったらよいかを尋ねた結果，\n「ランキング変動時に通知がくるようにし\nてほしい」「目標の継続時間を達成したらポジティブなフィードバックを返してほしい」「音声によるフィー\nドバックがあればさらにいい」といった声があがった．本課題を解決すべく，さまざまなフィードバックの\n組み合わせを試行し，より良いシステムを構築していけたらと感じている.\n59\n謝辞\n本研究はJSPS 科研費JP22K11998 の助成を受けたものです．本研究を進めるにあたって，大学３年次\nから現在にかけて約４年間ご指導頂いた，青山学院大学理工学部情報テクノロジー学科教授Guillaume\nLopez 先生に深く感謝申し上げます．研究の方針や問題解決にあたってご指導いただいたこと，学業面と私\n生活両面でのアドバイスをしてくださったこと，心から感謝しております．\nさらに，事務手続きや研究室整備，展示会等のアシスタントを行ってくださった研究補助員の大熊ちひろ\nさまにも深く感謝申し上げます．\n最後に，日々お互いに意見し合った同期の皆さま",
            "研究補助員の大熊ちひろ\nさまにも深く感謝申し上げます．\n最後に，日々お互いに意見し合った同期の皆さま，頼ってくれた後輩の大学院1 年生・大学4 年生，ラ\nボワーク参加の３年生の皆さまに感謝いたします．特に同期の平井氏にはシステムの開発面で多くのアドバ\nイスを頂きました．感謝いたします．\n2025 年1 月31 日\n佐藤圭翼\n60\n参考文献\n[1] 新型コロナウイルス感染症対策全国の感染者数内閣官房. https://www.caicm.go.jp/index.html.\n(Accessed on 06/28/2022).\n[2] 新型コロナウイルス感染対策スポーツ・運動の留意点と、運動事例について：スポーツ庁. https://www.\nmext.go.jp/sports/b_menu/sports/mcatetop05/jsa_00010.html. (Accessed on 06/28/2022).\n[3] 明治安田生命「健康」に関するアンケート調査を実施！https://www.meijiyasuda.co.jp/profile/\nnews/release/2021/pdf/20",
            "eijiyasuda.co.jp/profile/\nnews/release/2021/pdf/20210906_01.pdf. (Accessed on 06/28/2022).\n[4] 次期国民健康づくり運動プラン策定専門委員会厚生科学審議会地域保健健康増進栄養部会. 健康日本２１\n（第２次）の推進に関する参考資料. https://www.mhlw.go.jp/bunya/kenkou/dl/kenkounippon21_\n02.pdf. (Accessed on 06/28/2022).\n[5] 経済産業省. フィットネスクラブの動向. https://www.meti.go.jp/statistics/tyo/tokusabido/\nsanko/pdf/hv58_02j.pdf. (Accessed on 06/28/2022).\n[6] 谷本道哉. 体幹トレーニングの流行の背景と効果に関する考察. 理学療法-臨床・研究・教育, Vol. 27,\nNo. 1, pp. 3–9, 2020.\n[7] 鈴木雄貴, 桜井伸二. 体幹トレーニングが体幹の安定性とジャンプパフォーマンス",
            " 2020.\n[7] 鈴木雄貴, 桜井伸二. 体幹トレーニングが体幹の安定性とジャンプパフォーマンスに与える影響の検\n討. 中京大学体育研究所紀要= Bulletin of Research Institute of Health and Sport Sciences, Chukyo\nUniversity, No. 32, pp. 31–36, 2018.\n[8] 藤本鎮也, 吉田一也, 佐藤慎一郎, 秋山純和. 体幹と理学療法. 理学療法-臨床・研究・教育, Vol. 20,\nNo. 1, pp. 7–14, 2013.\n[9] 体幹を鍛えるための10 種のトレーニングメニュー【プロが教える筋トレ】— oricon news. https:\n//www.oricon.co.jp/special/58258/. (Accessed on 06/12/2024).\n[10] 木場克己. Dvd で鍛えるプロトレーナー木場克己の体幹パフォーマンスアップメソッド. pp. 72–73, 4\n2012.\n[11] 木場克己. Dvd で鍛えるプロトレーナー木場克己の体幹パフォーマンスアップメソ",
            "012.\n[11] 木場克己. Dvd で鍛えるプロトレーナー木場克己の体幹パフォーマンスアップメソッド. pp. 74–75, 4\n2012.\n[12] 木場克己. Dvd で鍛えるプロトレーナー木場克己の体幹パフォーマンスアップメソッド. pp. 92–93, 4\n2012.\n[13] 鈴木未紗. やる気を高めるには「承認」～内発的動機付け・マズローの欲求段階説より考える～—\nhabi*do（ハビドゥ）. https://habi-do.com/blog/intrinsic-motivation-approval/. (Accessed\non 11/30/2023).\n[14] 株式会社LAFOOL.\nビジネスにおいてやる気を引き出す動機付けとは？効果的な方法を紹介-\nwell-being workers. https://survey.lafool.jp/mindfulness/column/0028.html. (Accessed on\n11/30/2023).\n61\n[15] 産経新聞.\n【今週の注目記事】長続きしないフィットネスジム、楽しければ…まるでディ\nスコ、娯楽型が急",
            "産経新聞.\n【今週の注目記事】長続きしないフィットネスジム、楽しければ…まるでディ\nスコ、娯楽型が急増（3/3 ページ）\n-\n産経ニュース.\nhttps://www.sankei.com/article/\n20180929-SIISHCV7ARKYBIYOXLXKPEMDAI/3/. (Accessed on 06/12/2024).\n[16] 24 時間フィットネスジムVERUS. スポーツジムの継続率ってどれくらい？続けるためのコツも紹介—\nverus-ヴェルス— 栃木県宇都宮市24 時間365 日営業フィットネスジム. https://verus-gym.com/\ncolumn/retention-rate/. (Accessed on 06/12/2024).\n[17] 株式会社カオナビ. アンダーマイニング効果とは？例、エンハンシング効果- カオナビ人事用語集.\nhttps://www.kaonavi.jp/dictionary/undermining_koka/. (Accessed on 06/12/2024).\n[18] 綿谷惇史. カメラ画像を用いた体幹トレーニングの",
            "ssed on 06/12/2024).\n[18] 綿谷惇史. カメラ画像を用いた体幹トレーニングの姿勢支援手法の提案. https://dspace.jaist.\nac.jp/dspace/bitstream/10119/15832/5/paper.pdf, 03 2019. (Accessed on 07/10/2024).\n[19] 高久大輔中島克人. Kinect を用いた筋力トレーニング支援システム. https://ipsj.ixsq.nii.ac.\njp/ej/?action=pages_view_main&active_action=repository_view_main_item_detail&item_\nid=164408&item_no=1&page_id=13&block_id=8, 03 2015. (Accessed on 07/10/2024).\n[20] 岡本勝礒村智将松原行宏.\n姿勢推定手法を活用したリアルタイム運動訓練支援環境.\nhttps:\n//www.jstage.jst.go.jp/article/pjsai/JSAI2016/0/JSAI2",
            "ww.jstage.jst.go.jp/article/pjsai/JSAI2016/0/JSAI2016_1C4OS13a1/_pdf/-char/ja,\n2016. (Accessed on 07/10/2024).\n[21] Microsoft.\nAzure\nkinect.\nhttps://www.microsoft.com/ja-jp/d/azure-kinect-dk/\n8pp5vxmd9nhq?activetab=pivot:%E6%A6%82%E8%A6%81tab. (Accessed on 07/10/2024).\n[22] 村田嘉利\n永澤修平鈴木彰真.\nKinect を用いた体幹のリハビリテーション支援システム.\nhttps://ipsj.ixsq.nii.ac.jp/ej/?action=pages_view_main&active_action=repository_\nview_main_item_detail&item_id=104949&item_no=1&page_id=13&block_id=8, 07 2014.\n(Ac-\ncessed on 07/1",
            "age_id=13&block_id=8, 07 2014.\n(Ac-\ncessed on 07/10/2024).\n[23] Inter Reha. Vicon — モーションキャプチャ— 三次元動作分析システム. http://www.vicon.jp/.\n(Accessed on 07/10/2024).\n[24] 高田将志中村優吾藤本まなと荒川豊安本慶一. 体幹トレーニング支援に向けたウェアラブルデバ\nイスによる種目認識手法の提案. https://ipsj.ixsq.nii.ac.jp/ej/?action=pages_view_main&\nactive_action=repository_view_main_item_detail&item_id=186775&item_no=1&page_id=\n13&block_id=8, 03 2018. (Accessed on 07/10/2024).\n[25] Amaya Prat-Luri Mar´ıa Pilar Garc´ıa-Vaquero Francisco J. Vera-Garcia David Barbado, ",
            "a-Vaquero Francisco J. Vera-Garcia David Barbado, Belen Irles-\nVidal. Training intensity quantiﬁcation of core stability exercises based on a smartphone accelerom-\neter — plos one.\nhttps://journals.plos.org/plosone/article?id=10.1371/journal.pone.\n0208262, 12 2018. (Accessed on 07/10/2024).\n[26] 森田大喜. 加速度センサを用いた体幹トレーニング支援システム. http://www.wil.it.aoyama.ac.\njp/abstract/DaikiMORITA_a.pdf, 01 2021. (Accessed on 07/10/2024).\n[27] 濱谷尚志落合桂一山田渉檜山聡白井拓也荒川豊. 目標宣言共有型プラットフォームを用いたソーシャ\nルナッジの量的質的効果の評価. https://",
            ". 目標宣言共有型プラットフォームを用いたソーシャ\nルナッジの量的質的効果の評価. https://ipsj-bti.github.io/proceedings/202303/pdf/bti03_\n05.pdf, 03 2023. (Accessed on 07/10/2024).\n[28] エヌ・ティ・ティ・ドコモ. https://www.docomo.ne.jp/. (Accessed on 07/10/2024).\n[29] d ヘルスケア｜毎日の歩数がd ポイントに！https://health.docomo.ne.jp/.\n(Accessed on\n07/10/2024).\n62\n[30] 双見京介寺田努塚本昌彦.\n心理的影響を考慮した競争情報フィードバックによるモチベーシ\nョン制御手法.\nhttps://ipsj.ixsq.nii.ac.jp/ej/?action=pages_view_main&active_action=\nrepository_view_main_item_detail&item_id=190072&item_no=1&page_id=13&block",
            "m_detail&item_id=190072&item_no=1&page_id=13&block_id=8, 06\n2017. (Accessed on 07/10/2024).\n[31] みんチャレ- 三日坊主防止アプリ— みんチャレは専門家監修のもとに作成された、5 人1 組で続ける\n「習慣化アプリ」です。https://minchalle.com/. (Accessed on 07/10/2024).\n[32] Wearable sensor ― movesense. https://www.movesense.com/. (Accessed on 09/29/2022).\n[33] Is background music during training counterproductive?!\nhow music aﬀects muscle training —\ncompare recommended gyms! sports gym fan club（fanclub）(in japanese). https://sportsgym-fc.\ncom/music/. (Acce",
            "japanese). https://sportsgym-fc.\ncom/music/. (Accessed on 07/20/2022).\n[34] About testosterone｜daito pharmaceutical industry co., ltd. (in japanese). https://www.daito-p.\nco.jp/reference/testosterone.html. (Accessed on 07/20/2022).\n[35] motion capture suit「e-skin meva」— imu sensor welfare equipment creact of manufacturing. https:\n//www.creact.co.jp/item/measure/mocap/meva/meva-top. (Accessed on 10/02/2022).\n[36] red cross sendai (in japanese). http://www.sendai.jrc.or.jp/info/sendai/no85/04.html",
            "tp://www.sendai.jrc.or.jp/info/sendai/no85/04.html. (Ac-\ncessed on 10/02/2022).\n[37] Firebase. https://firebase.google.com/?hl=ja. (Accessed on 11/02/2024).\n[38] スポーツジムの継続率ってどれくらい？続けるためのコツも紹介. https://verus-gym.com/column/\nretention-rate/. (Accessed on 11/11/2024).\n[39] System usability scale - wikipedia.\nhttps://en.wikipedia.org/wiki/System\\_usability\\\n_scale. (Accessed on 11/18/2022).\n[40] The system usability scale:\nPast,\npresent,\nand future.\nhttps://www.researchgate.net/\npublication/32411641",
            "https://www.researchgate.net/\npublication/324116412_The_System_Usability_Scale_Past_Present_and_Future.\n(Accessed\non 01/14/2025).\n[41] ﬁrestore. https://firebase.google.com/docs/firestore?hl=ja. (Accessed on 12/12/2024).\n[42] 職務モテイベーションに関する期待理論. https://www.jstage.jst.go.jp/article/jjesp1971/\n14/2/14_2_147/_pdf. (Accessed on 12/12/2024).\n63\n付録\n付録A 本研究に関する論文誌投稿および学会発表の実績\n• 国際論文誌・国際ジャーナル\nMay 27th, 2024\nKeisuke Sato, Guillaume Lopez\n”Eﬀect of Real-Time Feedback on Posture Improvement during Core Tr",
            "ime Feedback on Posture Improvement during Core Training”\nInternational Journal of Activity and Behavior Computing\nURL https://www.jstage.jst.go.jp/article/ijabc/2024/1/2024 15/ article/-char/en\nJune 16th, 2024\nKeisuke Sato, Guillaume Lopez\nCoreMoni-α: Consideration of Long-Term Feedback Methods in Core Training\nInternational Journal of Activity and Behavior Computing\nURL https://www.jstage.jst.go.jp/article/ijabc/2024/2/2024 28/ article/-char/en\n• 査読有り\n2022 年10 月\nAmi Jinno, Keisuke Sato, Anna Y",
            "\n• 査読有り\n2022 年10 月\nAmi Jinno, Keisuke Sato, Anna Yokokubo, Guillaume Lopez\n“ Real-Time Feedback System for Eﬃcient Core Training ”\nThe International Conference on Activity and Behavior computing 2022 @University of East London\n2023 年9 月\nKeisuke Sato, Guillaume Lopez\n“ Eﬀect of Real-Time Feedback on Posture Improvement during Core Training ”\nThe International Conference on Activity and Behavior computing 2023 @Deutsches Forschungszentrum\nf¨ur K¨unstliche Intelligenz Kaiserslautern\n2023 年10 月\nKeis",
            "stliche Intelligenz Kaiserslautern\n2023 年10 月\nKeisuke Sato, Guillaume Lopez\n“ Inﬂuence of Feedback Modality in Core Training Support System ”\nThe International Conference on Informatics, Electronics ＆Vision 2023 @University of East London\n2024 年5 月\nKeisuke Sato, Guillaume Lopez\n“ CoreMoni-α: Consideration of Long-Term Feedback Methods in Core Training ”\nThe International Conference on Activity and Behavior Computing 2024 @ Kitakyusyu ＆Nakatsu\n64\n• 査読無し\n2022 年7 月\n神野亜美，佐藤圭翼，横窪安奈，ロペズギヨーム\n“ CoreMoni",
            "• 査読無し\n2022 年7 月\n神野亜美，佐藤圭翼，横窪安奈，ロペズギヨーム\n“ CoreMoni：体幹トレーニングにおける効果的な姿勢促進システム”\n一般社団法人情報処理学会マルチメディア，分散，協調とモバイルシンポジウム2022 @Online\n2023 年3 月\n佐藤圭翼, ロペズギヨーム\n“ CoreMoni-α：効果的な体幹トレーニングのための短期的フィードバックシステム”\n一般社団法人情報処理学会行動変容学研究G 研究会2023 @九州大学\n2023 年7 月\n佐藤圭翼，ロペズギヨーム\n“ CoreMoni-α：効果的な体幹トレーニングのための短期的フィードバックシステム”\n情報処理学会マルチメディア、分散、協調とモバイルシンポジウム2023 @富山国際会議場\n2024 年6 月\n佐藤圭翼，ロペズギヨーム\n“ CoreMoni-α: Consideration of Long-Term Feedback Methods in Core Training ”\n一般社団法人情報処理学会マルチメディア、分散、協調とモバイルシンポジウム2024 @花巻温泉\n65\n付録B 本研究の",
            "処理学会マルチメディア、分散、協調とモバイルシンポジウム2024 @花巻温泉\n65\n付録B 本研究の実験に使用した研究同意書\n図6.5 から図6.10 までは予備実験の，図6.11 から図6.14 までは本実験の研究同意書である．\n図6.1: 予備実験の同意書（1/10）\n66\n図6.2: 予備実験の同意書（2/10）\n67\n図6.3: 予備実験の同意書（3/10）\n68\n図6.4: 予備実験の同意書（4/10）\n69\n図6.5: 予備実験の同意書（5/10）\n70\n図6.6: 予備実験の同意書（6/10）\n71\n図6.7: 予備実験の同意書（7/10）\n72\n図6.8: 予備実験の同意書（8/10）\n73\n図6.9: 予備実験の同意書（9/10）\n74\n図6.10: 予備実験の同意書（10/10）\n75\n図6.11: 本実験の同意書（1/5）\n76\n図6.12: 本実験の同意書（2/5）\n77\n図6.13: 本実験の同意書（3/5）\n78\n図6.14: 本実験の同意書（4/5）\n79\n図6.15: 本実験の同意書（5/5）\n80\n付録C 質疑応答内容\nQ.（工藤）本実験において，想定",
            "図6.15: 本実験の同意書（5/5）\n80\n付録C 質疑応答内容\nQ.（工藤）本実験において，想定では毎日続けるのが良いということなのか．\nA.（佐藤）いいえ．本研究においては，文献調査のもと，３日に１回行えていれば可としている．\nQ.（工藤）三日坊主の防止ではなく，24 時間やっていなかったら通知するようなシステムの方が良いの\nではないか．\nA.（佐藤）健康の観点から，毎日続けることが必ずしも良いとは断定できない．疲労骨折などの副次的\nな悪影響が考えられる．また，将来的にシステムを使わずにトレーニングを続けるようになってもらうこと\nが目標であるため，強制的に頻繁にトレーニング催促を行うことで，かえってモチベーションが低下してし\nまい，本末転倒になってしまう可能性が懸念される．\nQ.（工藤）結果として，続くようになっているのか．\nA.（佐藤）はい．しかしながら，一部の被験者においては続かなかった．この被験者は最後のアンケー\nト記述で「そもそもシステムを使ってトレーニングを続けることが煩雑である」と述べたため，そもそもシ\nステムを使用すること自体に抵抗があったと考えられる．\nQ.（工藤",
            "雑である」と述べたため，そもそもシ\nステムを使用すること自体に抵抗があったと考えられる．\nQ.（工藤）「姿勢推定+3 日坊主防止機能を備えたトレーニングアプリケーションを使って被験者実験を\nした」という研究だと捉えているが，その認識で合っているか？その場合，技術的な新規性はどこにあたる\nのか？姿勢推定を使ったトレーニングアプリケーション研究は結構ありそうだが，紹介されていた関連研究\n以外を踏まえて，研究自体の新規性を改めて論じてほしい．\nA.（佐藤）本研究に取り組むまでは，世の中にたくさんあると感じていた．しかし，調査していく中で，\n何かの要素（姿勢判定）が完璧であっても，別の要素（フィードバック）になんらかの課題が生じている\n関連研究が散見された．本研究の新規性は主に４つの観点から考えることができる．１点目はリアルタイ\nムの姿勢判定およびリアルタイムフィードバックである．体幹トレーニングに限らず，トレーニングの姿\n勢の良し悪し判定をリアルタイムに行い，即時にユーザにフィードバックを与えるシステムは存在しない．\n２点目は通知のタイミングである．24 時間に１回のタイミングやランキング変",
            "るシステムは存在しない．\n２点目は通知のタイミングである．24 時間に１回のタイミングやランキング変動時にユーザに通知を送信\nする機能はすでに存在しているが，72 時間のタイミングで通知を送る体幹トレーニング支援システムはな\nいと認識している．３つ目は短期的・長期的フィードバックの両方を搭載している点である．短期的フィー\nドバックや長期的フィードバックの単体システムは存在するものの複合的なシステムは散見されない．４つ\n目は特殊なアルゴリズムにより，加速度センサひとつで角度を算出し，姿勢判定につなげている点である．\nQ.(D¨urst)Do people learn the best posture for your training after some time, or is it necessary to use\nyour system for years because it is easily possible to fall back into a bad posture? For a front plank, did\nyou only check the position ",
            "or a front plank, did\nyou only check the position of the hip? I ’d assume even if the hip is positioned correctly, the back could\nbe in a bad position and should be corrected.\nA.(Sato)The former is correct. The goal of this research is to be able to continue training in the correct\nposture without using the system in a few years. You’re right. In the future, I would like to equip multiple\nsensors to make the system more accurate.\n81\n"
        ]
    },
    {
        "id": "paper_12",
        "filename": "M2024_LiuZeyu.pdf",
        "title": "M2024_LiuZeyu",
        "fulltext": " \n \n \n \n \n \n \n \n \n青 \n山 \n学 \n院 \n大 \n学 \n \n理 \n工 \n学 \n研 \n究 \n科 \n \n \n \n \n理工学専攻 \n \n \n \n \n \n修 \n士 \n論 \n文 \n \n \n \n学 生 番 号 \n \n35623252\n \n \n \nLIU ZEYU \n \n \n \n研究指導教員 \nGuillaume \nLOPEZ \n \n知能情報\nコース \n氏 \n名 \nSmartWT: Fitness activity monitoring using\nwearable devices\nLiu Zeyu\nJanuary 2025\n理工学専攻修士論文要旨 \n \n \n提出年度 \n： 2024 年度 \n提出日  \n： 2025 年1 月31 日 \n専修コース \n： 知能情報 コース \n学生番号 \n： 35623252 \n学生指名 \n： LIU ZEYU \n研究指導教員 ： ロペズ・ギヨーム 教授 \n \n（論文題目） \nSmartWT: Fitness activity monitoring using wearable devices \n \n（内容の要旨） \n近年，ウェアラブルデバイスは急速に進化し，心拍数測定，歩数計測，睡眠分析など多様な健康管\n理機能を提供するようになった．特にスマートウォッチは，加速度センサーやジャイロスコープを搭\n載し，運動データのリアルタイム収集が可能となっている．しかし，現在のフィットネス活動追跡ア\nプリケーションソフトウェア（以降アプリ）は，有酸素運動の記録には優れているものの，ウェイト\nトレーニングなどの無酸素運動においては，ユーザーが回数や負荷を手動で入力する必要があり，ト\nレーニングの集中力を妨げる要因となっている． \nこれを解決するため，本研究では，スマートウォッチとスマートフォンを活用したリアルタイムフ\nィットネスモニタリングシステム「SmartWT」を開発し，既存のフィットネスアプリが無酸素運動の\n自動記録に対応できていない課題を解決することを目的としている． \n本研究では，スマートウォッチで加速度データを収集し，スマートフォンに転送したのち，スマー\nトフォン上でリアルタイム処理を行うTLSW（三層スライディングウィンドウ）アルゴリズムを考案\nし，運動状態の自動識別，運動種別の分類，および回数の自動カウントを実現することで，手動入力\nの必要性を排除する．TLSW アルゴリズムは，状態認識，ピーク検出，運動分類の3 つの主要ステッ\nプで構成される．まず，状態分類モデルを用いてユーザーが運動状態にあるかを判定し，運動中であ\nると判断された場合，合成加速度を計算してピークを検出する．ピークがウィンドウの中心に位置す\nる場合，それを1 回の運動としてカウントし，機械学習モデルで運動種別を分類する．精度向上のた\nめ，最大値，最小値，スペクトルセントロイド，スペクトルフラットネス，ゼロ交差率などの時間領\n域・周波数領域の特徴量を抽出し，ランダムフォレストを用いた分類モデルを訓練した． \nパソコンを用いたオフライン環境において，分類精度96.7%，カウント精度96.6%を達成したが，高\n性能なプログラミング環境と処理能力のないモバイル端末において，データ転送や計算環境の違いに\nより，それぞれ95%，88%に若干低下した．さらに，9 名の被験者を対象とした実証実験では，8 種類\nの運動において分類精度86.1%，カウント精度81.4%を記録した．特定の動作において精度が低下した\n主な原因は，個人の運動幅の違いや疲労による動作速度の低下である．モバイル端末の開発では，シ\nステムのリアルタイム性と安定性を確保するために，Data Layer API を使用してスマートウォッチと\nスマートフォン間のデータ転送を実装し，スライディングウィンドウのデータ管理を最適化するため\nにリングバッファを採用し，データコピーによる負荷を軽減した．また，パソコンを用いたオフライ\nン環境と特性計算の精度を統一するため，モバイル端末にChaquopy を統合し，フーリエ変換や周波\n数領域の特徴抽出をオフライン処理環境と同じスクリプトで実行できるようにした． \n実験結果から，本システムは高精度な運動種別識別および回数カウントを実現し，フィットネスデ\nータの記録を効率化できることが確認された．加えて，Android 端末の最適化により，データ処理の効\n率と計算の安定性が確保された． \n \n \n青山学院大学大学院理工学研究科 \n1\nThe Academic Year of 2024, Submitted on January 31st, 2025 \n \nGraduate School of Science and Engineering, Aoyama Gakuin University \n \nTitle: SmartWT: Fitness activity monitoring using wearable devices \nStudent Name: LIU ZEYU  \nID Number: 35623252 \nDegree: Master of Engineering \nCourse: Intelligence and Information \nThesis Advisor: Professor Guillaume Lopez \n \nAbstract  \n In recent years, wearable devices have rapidly evolved, offering various health management \nfunctions such as heart rate monitoring, step counting, and sleep analysis. Smartwatches, in \nparticular, are equipped with accelerometers and gyroscopes, enabling real-time movement data \ncollection. However, while current fitness tracking applications effectively record aerobic \nexercises, they still require users to manually input repetitions and weights for anaerobic \nexercises like weight training, which disrupts workout focus. \nThis study developed SmartWT, a real-time fitness monitoring system utilizing smartwatches \nand smartphones, to address the limitations of existing fitness applications in automatically \ntracking anaerobic exercises. It proposes the Three-Layer Sliding Window (TLSW) algorithm, \nwhich collects acceleration data via a smartwatch and processes it in real-time on a smartphone \nto automatically recognize exercise states, classify exercise types, and count repetitions, \neliminating the need for manual input. The algorithm consists of three key steps: state \nrecognition, peak detection, and exercise classification & counting. First, the system uses a state \nclassification model to determine whether the user is actively exercising. Once an exercise state \nis detected, composite acceleration is calculated, and peaks are identified. If a peak is located at \nthe center of the window, it is counted as a valid repetition, and a machine learning model \nclassifies the exercise type. To improve accuracy, this study extracted various time-domain and \nfrequency-domain features, including maximum and minimum values, spectral centroid, \nspectral flatness, and zero-crossing rate, and trained a classification model using a Random \nForest algorithm. \nIn offline experiments conducted in a PC environment using Python programming language, \nthe algorithm achieved 96.7% classification accuracy and 96.6% counting accuracy. However, in \noffline tests on Android devices, accuracy slightly decreased to 95% and 88%, respectively, due \nto differences in data transmission and computational environments. Furthermore, a user study \nwith nine participants performing eight different exercises recorded a classification accuracy of \n86.1% and a counting accuracy of 81.4%. Lower accuracy in some exercises was mainly \nattributed to variations in individual movement ranges and reduced motion speed caused by \nfatigue. \nFor the mobile device implementation, the system's real-time performance and stability were \nensured by utilizing the Data Layer API to transmit data between the smartwatch and \nsmartphone. A ring buffer was employed to optimize sliding window data management, \nreducing computational overhead caused by continuous data copying. Additionally, to maintain \nconsistency with the Python environment in feature calculations, Chaquopy library was \nintegrated into the mobile device system, allowing Fourier Transform and frequency-domain \nfeature extraction to be executed using Python scripts directly on the mobile device. \nThe experimental results confirm that SmartWT can accurately recognize exercise types and \ncount repetitions, significantly improving the efficiency and accuracy of fitness data recording. \nFurthermore, optimizations in the mobile device implementation ensure efficient data \nprocessing and computational stability, making the system a promising solution for automated \nfitness tracking. \n2\nContents\n1\nIntroduction\n5\n1.1\nBackground . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n5\n1.2\nResearch problem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n7\n1.2.1\nQuestionnaire for ﬁtness enthusiasts on automated monitoring of ﬁtness\ndata . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n8\n1.3\nOutline of the thesis\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n16\n2\nRelated work\n17\n2.1\nImpact of Mobile Fitness Applications . . . . . . . . . . . . . . . . . . . . . . . . . . .\n17\n2.2\nMotion Recognition Methods . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n20\n2.3\nContribution of this research . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n23\n3\nIntroduction to Research Methods\n24\n3.1\nProposal of Research Methods\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n24\n3.2\nOverview of TLSW: A method for monitoring ﬁtness exercise in real time . . . . . .\n26\n3.3\nMethod for separating and extracting the ﬁtness state\n. . . . . . . . . . . . . . . . .\n27\n3.4\nMethod of counting and recognizing ﬁtness movements . . . . . . . . . . . . . . . .\n30\n3.5\nState Recognition Model and Fitness Movement Recognition Model using Machine\nLearning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n36\n3.5.1\nData collection\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n36\n3.5.2\nData preprocessing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n38\n3.5.3\nData set segmentation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n39\n3.5.4\nFeature Selection . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n39\n3.5.5\nState Classiﬁcation Model Training and Feature Reduction\n. . . . . . . . . .\n48\n3.5.6\nType Classiﬁcation Model Training and Feature Reduction\n. . . . . . . . . .\n51\n4\nAlgorithm ofﬂine experiments and results\n54\n4.1\nExperimental data collection . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n54\n4.2\nDLSW Algorithm Experiment . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n55\n4.3\nTLSW Algorithm Experiment . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n56\n5\nSmartWT : An Android ﬁtness monitoring app that uses TLSW methods\n59\n5.1\nRelated work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n59\n5.2\nOverview of System Architecture . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n60\n5.3\nAndroid application for smartphone . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n61\n5.3.1\nData transmission\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n63\n5.3.2\nData structure of the sliding window\n. . . . . . . . . . . . . . . . . . . . . . .\n65\n3\n5.3.3\nFeature Value Calculation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n65\n5.3.4\nInterface of Smartphone Application\n. . . . . . . . . . . . . . . . . . . . . . .\n66\n5.4\nAndroid application for smartwatch . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n66\n5.4.1\nInterface of Smartphone Application\n. . . . . . . . . . . . . . . . . . . . . . .\n69\n6\nExperiments and Results\n71\n6.1\nAndroid device ofﬂine experiments and results\n. . . . . . . . . . . . . . . . . . . . .\n71\n6.1.1\nDescription of the experiment . . . . . . . . . . . . . . . . . . . . . . . . . . .\n71\n6.1.2\nResurts . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n71\n6.2\nAndroid devices actual experiments and results . . . . . . . . . . . . . . . . . . . . .\n72\n6.2.1\nDescription of the experiment . . . . . . . . . . . . . . . . . . . . . . . . . . .\n72\n6.2.2\nResurts . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n74\n6.3\nSummary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n78\n7\nFuture work\n80\nAcknowledgments\n82\nReferences\n83\n4\nChapter 1\nIntroduction\n1.1\nBackground\nIn recent years, wearable devices have gained widespread popularity due to their powerful\nfunctionalities in monitoring health and ﬁtness activities. These devices not only help individ-\nuals track their physical condition in real time but also provide personalized recommendations\nfor ﬁtness enthusiasts, promoting more scientiﬁc and efﬁcient workout methods. A 2023 survey\nrevealed that wearable devices consistently attract signiﬁcant attention among ﬁtness enthu-\nsiasts, especially smartwatches equipped with sensors such as accelerometers and gyroscopes,\nwhich have become essential tools for tracking physical activity.\nScientiﬁc research has demonstrated that regular exercise has signiﬁcant positive effects on\nphysical health. Exercise not only strengthens muscles and improves cardiovascular function\nbut also effectively reduces the risk of chronic diseases such as cardiovascular diseases, dia-\nbetes, and obesity. Additionally, ﬁtness activities can enhance mood, relieve stress, and improve\noverall quality of life. However, unstructured or unscientiﬁc exercise may lead to suboptimal\noutcomes or even increase the risk of injury. Therefore, planned ﬁtness routines are particularly\nimportant. A well-structured ﬁtness plan helps individuals select appropriate exercise intensity\nand volume based on their physical condition and goals, thereby improving workout efﬁciency\nand minimizing the likelihood of injuries.\nWith the rapid advancement of technology, wearable devices continue to improve in both\nhardware and software functionalities. Early wearable devices had relatively simple features,\nsuch as step counting and heart rate measurement. In contrast, today ’s smartwatches and\nﬁtness bands offer much more comprehensive monitoring capabilities, including sleep quality\n5\nWearable devices receive attention [1].\ntracking, real-time three-axis acceleration data recording, blood oxygen monitoring, and per-\nsonalized ﬁtness plan recommendations.\nThese devices not only raise users’awareness of their health but also generate detailed health\nreports based on collected data, helping users adjust their ﬁtness strategies more scientiﬁcally.\nFor example, real-time heart rate monitoring enables users to control exercise intensity to re-\nmain in the optimal range for fat burning or cardiovascular improvement. Additionally, motion\nrecognition features help users correct improper movements and prevent injuries. For ﬁtness\nenthusiasts, these functions signiﬁcantly enhance the safety and scientiﬁc accuracy of their\nworkouts. At the same time, ﬁtness tracking applications are ﬂourishing, serving as essential\ncompanions to wearable devices. These applications seamlessly connect with smart devices,\nallowing users to synchronize workout data in real time and providing detailed ﬁtness analyses\nand plan customization. Many ﬁtness apps now include social elements, such as online rank-\nings, challenges, and badge rewards. These features not only enable users to track their ﬁtness\nprogress and long-term achievements but also increase engagement and motivation through\nsocial interactions and competitive incentives. In the future, with the further development of\nartiﬁcial intelligence and big data technologies, ﬁtness tracking apps will be able to identify\nusers’ workout states more accurately, provide highly personalized ﬁtness advice, and predict\npotential health risks, further advancing data-driven ﬁtness applications.\nIn summary, the rapid development of wearable devices and the growing prevalence of ﬁt-\n6\nFigure 1.2: Monitoring heart rate with a smartwatch\nness tracking apps are profoundly transforming people’s approach to ﬁtness, offering new pos-\nsibilities for healthier lifestyles. These tools not only help ﬁtness enthusiasts achieve their goals\nmore efﬁciently but also promote health management and the establishment of ﬁtness habits\nthrough technological innovations. In the future, as technology continues to evolve, this ﬁeld\nwill further develop, bringing greater convenience and health beneﬁts to a broader audience.\n1.2\nResearch problem\nCurrently, many ﬁtness tracking apps are highly effective in monitoring aerobic exercises. For\nexample, Apple Fitness and Google Fit provide comprehensive tracking for long-duration aero-\nbic activities like running and cycling. However, their support for anaerobic exercises remains\ninadequate. To address this issue, ﬁtness apps such as RepCount and Strong Workout Tracker\nGym Log, which focus on anaerobic exercises, have gained popularity. These apps assist users\nin creating detailed training plans and tracking long-term ﬁtness achievements. However, users\nare still required to manually input data such as repetitions and weights after completing each\nset of exercises. This frequent input not only disrupts user focus but also diminishes the overall\nworkout experience. If user actions could be recognized in real time and recorded automatically,\nit would signiﬁcantly enhance workout efﬁciency and user experience.\nCurrent research on human action recognition can be broadly divided into two approaches:\nimage-based recognition and sensor-based recognition. Image recognition uses cameras to\ncapture images of users during exercise and applies deep learning techniques to identify move-\nments, enabling precise capture of complex motion details. However, this approach requires\n7\nhigh device performance and network reliability and may raise privacy concerns. Sensor-based\nresearch, on the other hand, leverages built-in sensors like accelerometers and gyroscopes to\ncollect user movement data and applies methods such as template matching or machine learn-\ning to recognize actions. This approach offers better real-time performance and portability.\nNonetheless, it faces challenges such as the potential inconvenience caused by wearing multi-\nple sensors or the reliance on stable network connections for data transmission.\nAlthough wearable devices have made signiﬁcant progress in the ﬁeld of human action recog-\nnition, existing research still has limitations. On the one hand, many developed algorithms\nremain conﬁned to theoretical models or simulated environments and lack deployment and\ntesting on actual devices, leaving their performance in real-world scenarios insufﬁciently val-\nidated. On the other hand, many models used in research are computationally intensive and\nrequire high hardware performance, making it impossible for them to operate independently\non wearable devices. Instead, they rely on server-based computation. Furthermore, this depen-\ndence on server computation necessitates a stable network connection between the device and\nserver. When the network is unstable or ofﬂine, system performance and user experience are\nsigniﬁcantly impacted.\nIn this study, we developed an algorithm capable of long-term tracking of user ﬁtness activ-\nities, automatically recognizing and counting exercise actions. The algorithm replaces manual\noperations at the start and end of each action with automatic segmentation and improves upon\nthe traditional ﬁxed-step sliding window algorithm, reducing computational overhead while en-\nhancing recognition accuracy. Testing results show that the algorithm achieves an accuracy of\n94.31% in long-term tracking of ﬁtness data, correctly identifying exercise types and counting\nsets.\n1.2.1\nQuestionnaire for ﬁtness enthusiasts on automated monitoring of ﬁtness data\nTo understand the use of wearable devices by ﬁtness enthusiasts and their perspectives on\nﬁtness tracking software, we designed a questionnaire survey. The following are the results of\nthe survey.\nRespondents Fitness Situation Statistics\nWe conducted an anonymous questionnaire survey with 71 participants. The distribution of\ntheir years of ﬁtness experience and regular workout frequency is shown in the chart Figure 1.3\nbelow.\n8\nFigure 1.3: Participants’ number of years and frequency of ﬁtness\nThe Current State of Planned Fitness\nWe analyzed respondents’ views on ﬁtness plans, their habits of creating ﬁtness plans, and\nthe implementation of these plans. The results are presented in Figure 1.4.\nFigure 1.4: Participants’ number of years and frequency of ﬁtness\nMost respondents believe that ﬁtness plans can enhance workout effectiveness. Among them,\n52% stated that plans \"somewhat improve effectiveness,\" 37% believed that plans \"greatly en-\nhance effectiveness,\" and only 11% indicated that plans have no effect. Of the respondents, 48%\nreported having the habit of creating ﬁtness plans, while 52% stated they did not have such a\nhabit. Based on whether respondents have the habit of creating ﬁtness plans, we designed cor-\nresponding questions and analyzed the responses. Below are the most representative results\n9\nfrom the analysis.\nFitness enthusiasts with a habit of creating plans\nFigure 1.5: Views on ﬁtness plans from people who have plans to work out\nFrom the Figure 1.5 above, it can be observed that most respondents who create ﬁtness plans\ntend to design their plans independently, while the proportion using ﬁtness apps or software\nis relatively low. When recording ﬁtness plans, they prefer simpler methods or even rely on\nmemory. Additionally, more than half of the respondents have tried using ﬁtness apps or tools\nto assist in creating their plans.\n10\nFitness enthusiasts without a habit of creating plans\nFigure 1.6: Views on ﬁtness plans from people who have no plan to work out\nFor users who do not create ﬁtness plans, as shown in Figure 1.6, the main reasons include\nunpredictable schedules, a preference for unrestricted workouts, and unfamiliarity with plan\ncreation. Opinions on the impact of not having a plan on workout effectiveness are divided.\nSome users believe the impact is minimal and prefer the freedom of unstructured exercise. Oth-\ners, while aware of the potential drawbacks, have not taken action due to uncertainty about how\nto start or a lack of willingness to change.\n11\nRespondent perceptions of tracking apps\nFigure 1.7: The willingness of different ﬁtness enthusiasts to use ﬁtness tracking apps\nBefore analyzing ﬁtness enthusiasts’ opinions on ﬁtness tracking apps, we ﬁrst examined\ntheir willingness to use such applications. As shown in Figure 1.7, 76.1% of respondents ex-\npressed a willingness to use ﬁtness tracking apps. Among them, individuals with planned work-\nout routines demonstrated a signiﬁcantly higher inclination toward using these applications.\nFigure 1.8: Views of ﬁtness enthusiasts on recording data\nFigure 1.8 shows that most respondents preferred automatic recording of ﬁtness data, while\nonly a small number chose manual recording or a combination of automatic and manual ad-\njustments for data recording.\n12\nFigure 1.9: Views of ﬁtness enthusiasts on automatically recording ﬁtness data\nAs shown in Figure 1.9, respondents value accuracy and convenience the most when record-\ning ﬁtness data. The primary advantages of automatic recording applications include reducing\nmanual input, improving management efﬁciency, and helping users focus more on their work-\nouts. However, these applications also face challenges such as recognition inaccuracies, high\ndependency on devices, limited ﬂexibility, and concerns about data privacy.\n13\nFigure 1.10: Views of ﬁtness enthusiasts on automatically recording ﬁtness data\nAs shown in the results of Figure 1.10, ﬁtness apps that rely on manual data recording of-\nfer certain advantages, such as ﬂexibility in data adjustments, more accurate detail recording,\nand the ability to make adjustments based on real-time progress. However, users also face nu-\nmerous challenges, including the tedious and forgettable nature of the recording process, its\ntime-consuming and user-unfriendly aspects, frequent operations that disrupt focus, and the\ncomplexity of data organization and analysis. This indicates that while manual recording excels\nin precise control, the user experience requires further optimization.\n14\nExpectations for automated ﬁtness tracking app\nFigure 1.11: Expectations of ﬁtness enthusiasts for automated ﬁtness tracking app\n15\nFigure 1.11 illustrates that users ’demands for automated ﬁtness data recording systems fo-\ncus on accurately recognizing ﬁtness actions, real-time tracking of plan completion, and mon-\nitoring health metrics such as heart rate. Additionally, they consider the accuracy of automatic\nrecognition and system usability as the most critical aspects. Users also expressed a desire for\nfeatures such as automatically generated ﬁtness reports, synchronized plan adjustments, and\npersonalized ﬁtness recommendations. This indicates a preference for systems that are precise,\nefﬁcient, and capable of providing in-depth analysis.\nSummary of questionnaire results\nThe survey results indicate that most respondents believe ﬁtness plans can enhance workout\neffectiveness and show a strong willingness to use automatic ﬁtness tracking applications. Com-\npared to manual recording, automatic tracking is favored for its efﬁciency and convenience.\nUsers hope to reduce manual input through automatic tracking while achieving precise action\nrecognition, real-time plan tracking, and comprehensive monitoring of health metrics. This\nhighlights a clear demand for ﬁtness tracking applications with intelligent and automated fea-\ntures.\n1.3\nOutline of the thesis\nThis thesis is divided into seven chapters, covering the research background, related work,\nmethodology, experimental validation, system implementation, experimental results analysis,\nand future prospects. Chapter 1 introduces the research background, highlighting the limita-\ntions of existing ﬁtness tracking applications in recording anaerobic exercises and presenting\nthe objectives of this study. Chapter 2 reviews mobile ﬁtness applications and motion recog-\nnition methods, analyzing their advantages and limitations. Chapter 3 details the Triple-Layer\nSliding Window (TLSW) algorithm, including exercise state recognition, movement classiﬁca-\ntion, counting, and machine learning-based feature extraction. Chapter 4 presents ofﬂine ex-\nperiments conducted in a Python environment to evaluate the algorithm’s performance. Chap-\nter 5 describes the implementation of the Android application, focusing on data interaction be-\ntween the smartwatch and smartphone, data transmission, and feature computation. Chapter\n6 evaluates the system through ofﬂine and real-world experiments on Android devices, compar-\ning performance across different environments. Chapter 7 discusses potential improvements,\nincluding enhanced data processing and personalized ﬁtness feedback.\n16\nChapter 2\nRelated work\n2.1\nImpact of Mobile Fitness Applications\nAccording to a 2023 survey, wearable devices have been a popular topic of discussion among\nﬁtness enthusiasts since 2016 [1]. Mobile health applications integrated into wearable devices\nhave also become increasingly prevalent. These technological advancements not only enhance\nindividuals’ health awareness but also create opportunities for research in automatic activity\nrecognition and data-driven ﬁtness applications. Meanwhile, ﬁtness tracking apps are highly\npopular among ﬁtness enthusiasts. By monitoring ﬁtness data, these apps not only help users\nrecord workout completion and long-term ﬁtness achievements but also boost their motiva-\ntion through features such as badge collection and online competitions [2][3][4].[5]introduces\ngamiﬁed ﬁtness tracking applications that incorporate step count data into gameplay. By map-\nping existing currency-based taxonomies to step-based games and providing different types of\nexamples, it demonstrates the value of treating steps as currency.\n17\nScreenshot from the Fitness RPG app showing canonical game elements found in traditional\nRPG games. [5].\nThe widespread adoption and advancement of this technology are closely related to the nu-\nmerous health beneﬁts of physical activity. Studies have shown that regular exercise can sig-\nniﬁcantly reduce resting heart rate (RHR), particularly through endurance training and yoga.\nThis not only lowers all-cause mortality but is also correlated with pre-intervention RHR and\nparticipant age [6]. Additionally, physical exercise enhances cognitive function and extends its\npositive effects by maintaining good cardiovascular health [7]. During special periods, such as\nthe COVID-19 pandemic, digital ﬁtness apps provided convenient solutions for home workouts,\nenabling individuals to stay active during lockdowns, although their beneﬁts were primarily ob-\nserved in speciﬁc social groups [8].\n18\nThese ﬁtness applications make it easier for users to track their workout progress, challenge\nthemselves, and compete with others, further motivating them to maintain their exercise habits\n[7][9][10][11]. Studies on physical activity and wearable devices suggest that the reminder func-\ntions and continuous notiﬁcation mechanisms provided by these devices effectively encourage\nadults to engage in physical exercise, with particularly signiﬁcant results for sedentary individu-\nals [8]. Additionally, participating in online competitions or sharing ﬁtness achievements within\ncommunities can effectively boost users ’ﬁtness motivation. This interactive approach allows\nusers to experience social support and the joy of competition, inspiring them to engage more\nactively in exercise [7].\nHowever, research shows that compared to sharing ﬁtness achievements, more users prefer\nto focus on setting personal goals and tracking their progress. When users achieve their goals\nand receive rewards, they often feel“good about themselves”and“more motivated,”which fur-\nther promotes the sustainability of their workouts [12]. Moreover, ﬁtness tracking applications\nenhance physical activity levels through data feedback and goal management, strengthening\nusers’ self-monitoring and ﬁtness motivation [11].\nFigure 2.2: Capabilities in Google Fit\nCurrently, widely used ﬁtness tracking software, such as Apple Fitness and Google Fit, can\ntrack daily walking, running, and cycling data. Apps like RepCount [13] and Strong Workout\nTracker Gym Log [14], designed speciﬁcally for ﬁtness enthusiasts, help users create workout\nplans and record completion progress. These apps support long-term ﬁtness tracking, enabling\nusers to monitor their progress over time. However, most of these apps require users to manu-\nally record repetitions after completing each set, which not only causes inconvenience but also\ndisrupts workout focus.\n19\n2.2\nMotion Recognition Methods\nIn the rapid development of mobile health applications, the implementation of automatic ﬁt-\nness tracking relies on motion recognition technology. By converting users’movement patterns\ninto quantiﬁable data, this technology not only helps users track their workout progress in real-\ntime but also automatically identiﬁes exercise types and calculates activity levels. To achieve\nlong-term automatic tracking of various ﬁtness activities, along with counting and recording\nthem, three main objectives must typically be accomplished: (1) segmenting the user’s active\nand inactive states, (2) recognizing the user’s ﬁtness activities, and (3) counting the ﬁtness ac-\ntivities.\nIn research on user state and motion recognition, two primary approaches are visual-based\nand sensor-based methods. In visual-based research, Xie et al. [15] introduced an interactive\ncore training system called CoreUI. This system utilizes monocular camera input and 3D human\nshape estimation technology to provide users with visual feedback for posture correction. How-\never, due to a processing time of approximately 2 seconds per frame, the system has high latency,\nmaking it unsuitable for high-speed activities requiring real-time feedback, such as gymnastics\nor ball sports. M. Pasula et al. [16] proposed a hybrid model combining X3D and SlowFast net-\nworks for exercise classiﬁcation and muscle group activation prediction in videos. The results\ndemonstrated improved accuracy and efﬁciency compared to single models, but limitations re-\nmain in real-world generalization, real-time performance, and small muscle group prediction\naccuracy.\n[17] developed a hybrid model combining a Convolutional Neural Network (CNN) and a\nLong Short-Term Memory (LSTM) network for activity recognition. The CNN extracts spatial\nfeatures, while the LSTM captures temporal information. Additionally, a new dataset contain-\ning 12 types of human activities was created, collected from 20 participants using a Kinect V2\nsensor. Through an ablation study on various traditional machine learning and deep learning\nmodels, the CNN-LSTM approach achieved an accuracy of 90.89%, demonstrating its strong\nperformance in human activity recognition (HAR) applications.\nOther visual-based studies have also achieved promising recognition results. However, due\nto the need to set up devices like smartphones for real-time video capture, these methods are\nnot suitable for public spaces such as gyms. Sensor-based methods, on the other hand, are more\nsuitable for public settings because they offer higher privacy and do not require additional space\nfor data collection.Chaurasia et al. [18] provided a comprehensive review covering various as-\npects of Activity Recognition and Classiﬁcation (ARC) research using smartphones and wearable\n20\nActivity recognition through different Machine learning algorithms.[17]\nsensors. The review included data collection, feature extraction, classiﬁcation modeling, and\nkey factors inﬂuencing performance. Additionally, it summarized the strengths and limitations\nof existing methods, offering clear directions for future research.\nChung et al. [19] built a testing platform consisting of eight wearable inertial measurement\nunit (IMU) sensors and an Android mobile device for activity data collection. They also devel-\noped a Long Short-Term Memory (LSTM) framework to train a deep learning model. The results\nshowed that activity data from four sensors located on the wrist, right ankle, and both sides of\nthe waist, sampled at a rate as low as 10 Hz, was sufﬁcient to recognize daily activities (ADL),\nincluding eating and driving.\nTestbed conﬁguration.[19]\n21\nHighly relevant to this study are the works of [20][21] [22][23]and [24], all of which have\nachieved long-term automatic recognition of various exercises and completed repetition count-\ning. Dan et al. [20] introduced the RecoFit system, which uses inertial sensors in a smartphone\nworn on the arm to automatically track repetitive exercises such as weightlifting and aerobics.\nThe system achieved segmentation, recognition, and counting of ﬁtness data, with segmenta-\ntion precision and recall exceeding 95%. Recognition rates for different numbers of repetitions\nwere 99%, 98%, and 96%, respectively, with a counting accuracy of ± 1. However, RecoFit has\nlimitations, such as requiring 5 seconds for segmentation and recognition, performing poorly\nwith a small number of repetitions, and relying on specialized devices attached to the forearm,\nwhich increases user inconvenience and cost.\nData collection and evaluation hardware.[20]\nShen et al. [21] proposed the MiLift system, which combines a two-stage classiﬁcation model\nwith a lightweight weightlifting detection algorithm to autonomously and efﬁciently track aero-\nbic and weightlifting exercises. The system achieved an average precision and recall of over 90%\nfor aerobic activity classiﬁcation, weightlifting detection, and weightlifting type classiﬁcation.\nMiLift also calculated weightlifting repetitions with an average error of 1.12 repetitions (mean\nof 9.65 repetitions). However, it relied solely on gravity data for recognition, which reduced ac-\ncuracy when movements lacked signiﬁcant changes in the gravity direction.\nSoro et al. [22] used deep learning methods for recognizing and counting complex full-body\nmovements, achieving a recognition accuracy of 99.96% on constrained movement datasets.\nHowever, their approach required a CNN+RNN architecture to process multi-sensor data, pos-\ning challenges for real-time recognition on devices.\nSkawinski et al. [23] proposed a machine learning approach using convolutional neural net-\nworks to count repetitions of recognized exercise types with a single 3D accelerometer worn on\nthe chest. The method achieved an average recognition accuracy of 89.9%, with an average rep-\netition counting accuracy of 97.9% across all exercise types. However, the method was limited\n22\nto four types of exercises with signiﬁcant differences, potentially restricting its applicability to\nother exercise types.\nIshii et al. [24] developed ExerSense, which uses correlation-based methods and Dynamic\nTime Warping (DTW) for exercise segmentation, classiﬁcation, and counting. The authors also\ntested different device positions to optimize performance. When data was limited, this ap-\nproach outperformed machine learning methods in accuracy. However, template-based algo-\nrithms are highly dependent on template quality, posing challenges for generalization across\ndifferent populations and exercise scenarios.\n2.3\nContribution of this research\nTo enable real-time human motion recognition on Android devices, our study has made the\nfollowing contributions compared to the aforementioned research:\n1. Lower Sampling Rate: Unlike the algorithms requiring 50 Hz or 100 Hz sampling rates in\nprior studies, our algorithm achieves recognition and counting using only a 12.5 Hz sampling\nrate, signiﬁcantly reducing battery consumption [25].\n2. Reduced Feature Set: Our algorithm utilizes fewer features. After feature selection, the two\nRandom Forest (RF) models employed in our study use only 24 and 26 features, respectively.\n3. Double Layer Sliding Window Method: We implemented a Double Layer Sliding Win-\ndow approach, which, compared to traditional sliding window methods [18][25], reduces the\nnumber of computations required by the model while maintaining accuracy, thereby lowering\ncomputational overhead.\n23\nChapter 3\nIntroduction to Research Methods\n3.1\nProposal of Research Methods\nThis study aims to develop an algorithm and design an Android application based on it to\ntrack ﬁtness activities in real time and record data for eight categories of exercises. The sys-\ntem collects acceleration data in real time through a smartwatch and processes it on the smart-\nphone. With this application, users do not need to manually select exercise types or record the\nnumber of repetitions during their workouts. The application automatically handles the record-\ning and classiﬁcation of ﬁtness data.\nFigure 3.1 illustrates the eight target ﬁtness activities in our study, all of which are upper-body\nresistance exercises performed using gym machines. Resistance exercises provide numerous\nbeneﬁts for individuals across different populations and conditions, such as reducing arterial\nblood pressure [26], increasing muscle strength, and serving as a treatment for various muscu-\nloskeletal disorders [27].\nBefore detailing the components of our algorithm, we ﬁrst present Figure 3.2, which illus-\ntrates how the entire algorithm operates in a real-time environment.\nThe algorithm employs a triple-layer sliding window structure to process acceleration data\ncollected during user activities in real time. The detailed workﬂow is as follows: 1. State Detec-\ntion: The algorithm ﬁrst uses three-axis acceleration data to determine whether the user is in\nan active state. 2. Composite Acceleration Calculation: Once the user is identiﬁed as being in\nan active state, compcosite acceleration is computed. 3. Repetition Counting: By detecting the\npeaks of the composite acceleration, the algorithm counts the user ’s repetitive actions. 4. Ac-\ntion Recognition: Finally, based on the three-axis acceleration data, the algorithm identiﬁes the\n24\nFigure 3.1: 8 Types of ﬁtness activities\nFigure 3.2: Algorithm working schematic\n25\ntype of activity and outputs the results. Through these steps, the algorithm achieves real-time\nautomatic tracking and recording of the user ’s ﬁtness activities.\n3.2\nOverview of TLSW: A method for monitoring ﬁtness exercise in real time\nFigure 3.3: Structure of the TLSW algorithm\nFigure 3.3 illustrates the algorithm’s structure in this study, which utilizes a Triple-layer slid-\ning window data structure with a total length of approximately 5.6 seconds. The structure slides\none data point at a time, performing computations with each slide, and moves to the right (with\nnew data entering the state classiﬁcation window ﬁrst). The state recognition window contin-\nuously classiﬁes the activity state in real time, determining whether the user is engaged in a\nﬁtness activity. Once a ﬁtness state is identiﬁed, the double-layer window is activated, where:\nLayer[1]: This layer identiﬁes the peak positions within the window and determines whether the\n26\npeaks are centered. Layer[2]: This layer classiﬁes the data within the window using a machine\nlearning model for activity type classiﬁcation.\nThis structure ensures efﬁcient real-time state recognition, repetition counting, and activity\nclassiﬁcation.\nFigure 3.4 presents the ﬂowchart of the algorithm, with details of each component explained\nin the next section. The algorithm consists of two main parts:\n1. State Classiﬁcation:\nWhen the user presses the \"Start Workout\" button, the collected three-axis acceleration\ndata enters the window for real-time state classiﬁcation. The purpose of this step is to\ndetermine whether the user is exercising. A machine learning model trained to recognize\nstates is used for classiﬁcation:\n• If the classiﬁcation result is \"non-exercise,\" the accumulator - 1.\n• If the classiﬁcation result is \"exercise,\" the accumulator + 1.\n2. Type Classiﬁcation and Counting:\nWhen the state classiﬁcation determines the user is exercising, this part is activated. First,\npeak detection is performed within the window to locate the positions of peaks. The algo-\nrithm then checks whether the peak position lies at the center of the window:\n• If the peak is not at the center, it is skipped.\n• If the peak is at the center, it is counted as a valid exercise repetition. Centered around\nthe peak, the data within the window is classiﬁed using a machine learning model to\nidentify the exercise type, which is recorded as one completed action of that type.\nThis dual-step process ensures accurate recognition of the user’s activity state, repetition count-\ning, and exercise type classiﬁcation in real time.\n3.3\nMethod for separating and extracting the ﬁtness state\nIn this section, we will detail the working principle of the state classiﬁcation window, as il-\nlustrated in the structural diagram. To eliminate the cumbersome process of manually starting\nand stopping between each set of exercises, we introduced a real-time state recognition feature.\nFirst, the system continuously detects the user’s motion state in real time, automatically distin-\nguishing between active (exercise) and inactive (non-exercise) states. Once the system identi-\nﬁes an active state, it proceeds to recognize the user’s speciﬁc actions during exercise. Based\n27\nFigure 3.4: Flowchart of the TLSW algorithm\n28\non data collection and analysis, we categorized the user’s state during workouts into four dis-\ntinct types. Figure 3.5 shows the corresponding three-axis acceleration data for these four types.\nThis approach ensures efﬁcient and seamless transitions between exercise detection and action\nrecognition, signiﬁcantly enhancing user convenience and workout tracking accuracy.\nFigure 3.5: Triaxial acceleration diagrams for 4 states\nThe four states include exercise, walking, resting while seated, and other activities (e.g., drink-\ning water, sanitizing gym equipment). Since this study focuses solely on processing the exercise\nstate, all states other than exercise are deﬁned as \"non-exercise,\" while all target ﬁtness activities\nare classiﬁed as \"exercise.\"\nTo recognize motion states, the action recognition window is designed such that three-axis\nacceleration data enters the window, and every 5 data points (approximately 0.4 seconds), a ma-\nchine learning model performs classiﬁcation to determine the state. The window length is 70\ndata points, equivalent to approximately 5.6 seconds. Since activities like walking or repetitive\nnon-exercise motions can often be misclassiﬁed as exercise, relying on a single classiﬁcation\nresult to determine the exercise state could lead to numerous errors. To address this, an accu-\nmulator system with a threshold is incorporated to optimize the decision process:\n- When the classiﬁcation result is \"exercise,\" the accumulator increases by 1.\n- When the result is \"non-exercise,\" the accumulator decreases by 1.\nThe accumulator has a threshold value and a maximum limit. Once the accumulator value\nexceeds the threshold, the system transitions to the exercise state and activates the next pro-\ncessing stage. When the accumulator reaches its maximum limit, it will no longer increase.\nAdjusting the threshold affects the ease of classifying the user as being in the exercise state.\n29\nFor example, lowering the threshold allows quicker transitions to the exercise state but increases\nthe risk of misclassifying other states as exercise. Similarly, modifying the difference between the\nmaximum limit and the threshold adjusts the transition difﬁculty from exercise to non-exercise:\nA small difference results in a quick reversion to the non-exercise state after completing the\nlast action in a set, potentially losing the count of the ﬁnal action due to the delay. Conversely, a\nlarge difference may lead to non-exercise data being passed to the next stage, causing redundant\ncounts.\nIn summary, adjusting the threshold and maximum limit inﬂuences the weights for transi-\ntions between [non-exercise] →[exercise] and [exercise] →[non-exercise] states. After multi-\nple tests in this experiment, the delay is approximately 1.6 seconds. Under ideal conditions, the\nsystem determines the user has entered the exercise state 1.6 seconds after starting the workout.\n3.4\nMethod of counting and recognizing ﬁtness movements\nThis section details the workﬂow of the Double-Layer Sliding Window illustrated in the struc-\ntural diagram. This component consists of an inner window and an outer window, both centered\nat the same position.\nOuter Window (Peak Detection Window): The outer window is responsible for peak detec-\ntion. It has a size of 60 data points, equivalent to approximately 4.8 seconds.\nInner Window (Action Recognition Window): The inner window handles action recognition.\nIts size is 50 data points, equivalent to approximately 4 seconds.\nFigure 3.6: Schematic of the working of DLSW algorithm\nFigure 3.6 shows the four steps of data processing in the Double-Layer Sliding Window algo-\nrithm:\n30\n1. Composite Acceleration Calculation Compute the Composite acceleration from the three-\naxis acceleration data entering the window.\n2. Peak Detection Detect the peaks of the composite acceleration within the outer window.\nAs the window slides, calculate the position of each peak.\n3. Repetition Recording and Classiﬁcation When a peak is located at the center of the outer\nwindow, record one repetition. Simultaneously, classify the ﬁtness activity type using the\nthree-axis acceleration data within the inner window.\n4. Result Aggregation and Output Temporarily store each recorded repetition. When a transi-\ntion out of the exercise state occurs, aggregate the classiﬁcation results within the current\nset, select the majority result as the activity type for the set, and output the classiﬁcation\nresult along with the count.\nIn studies [20] and [22], repetition counting is performed by selecting a speciﬁc axis from the\nthree-axis acceleration data for peak detection. However, in our research, we observed that for\ncertain exercises, such as the Lat Pull Down(Figure 3.7), variations in the smartwatch’s angle and\nposition on the left wrist during data collection, along with differences in the motion angles of\nthe exercises themselves, result in the most representative axis differing across actions.\nTo address this issue, we opted to compute the composite acceleration, allowing us to per-\nform peak detection on a uniﬁed dimension for all exercises. This approach enhances the algo-\nrithm’s adaptability and consistency across various ﬁtness activities.\nDuring the sliding of the window, the composite acceleration peaks for each action pass se-\nquentially through the center of the window. The center point is used as a marker, and when\na peak aligns with the center, it is recorded as one repetition. This method offers the following\nadvantages:\n• Reduction in Duplicate Counting\nBy aligning peak positions with the center point, the method ensures that the same peak\nappearing in adjacent windows is not counted twice. This effectively reduces the likelihood\nof duplicate counts for the same action.\n• Improved Action Classiﬁcation Accuracy\nTo enhance classiﬁcation accuracy, special preprocessing was applied to the training data.\nSpeciﬁcally, composite acceleration peaks were used as markers to segment each action\ninto windows centered around the peaks. This approach minimizes errors caused by vari-\nations in user movement speed and ensures that the window data covers the primary or\n31\nFigure 3.7: Composite acceleration and triaxial acceleration of Lat Put Down\n32\ncomplete segment of each ﬁtness action. Even when the rhythm of the actions changes,\ndata integrity is preserved, signiﬁcantly improving model classiﬁcation accuracy.\n• Reduced Computational Overhead\nThe algorithm mandates that composite acceleration peaks must pass through the window\ncenter. Ideally, the number of feature extractions and model classiﬁcations matches the\nactual number of ﬁtness actions. Compared to ﬁxed-step sliding window methods, this\napproach effectively reduces unnecessary computational costs.\nAnalysis revealed that the duration of a single user action typically ranges from 2.7 to 5 sec-\nonds. To maximize coverage of a single action ’s data while avoiding the inclusion of two com-\nplete actions in one window, we set the inner window size to 4 seconds. Additionally, we opti-\nmized the size of the outer window to reduce counting errors:\n• Issues with an Oversized Window\nWhen users complete the last few repetitions in a set, their movements tend to slow down\ndue to fatigue, resulting in lower acceleration peaks. An oversized window may include\nthe peak from the previous action, which can interfere with detecting the next action ’s\nacceleration peak, ultimately reducing the count.\n• Issues with an Undersized Window\nIf the outer window is too small, secondary peaks between two consecutive actions may\nbe mistaken for the synthetic acceleration peak of a full action. This can lead to over-\nsegmentation of a single action and result in overcounting.\nIn some actions, a single motion may produce two closely spaced positive peaks of similar\nmagnitude, along with a distinct negative peak in the opposite direction that can serve as a\nmarker. Relying solely on peak-to-peak distance to ﬁlter out duplicate peaks may affect fast-\npaced actions or those with close peak spacing within a single motion.\nTo address this, we incorporated synthetic acceleration inversion into the peak detection\nprocess shows in Figure 3.8: Using gravity acceleration (9.8 m/s2) as the reference value, if the\ndifference between the minimum value and the reference exceeds the difference between the\nmaximum value and the reference signiﬁcantly, the synthetic acceleration data within the cur-\nrent window is inverted.The inverted data is then used for subsequent peak detection.\n33\nFigure 3.8: Reverse acceleration optimized for counting\nFigure 3.9 illustrates the workﬂow for determining whether a peak position lies at the center:\nHere are the detailed steps for calculating peak positions:\n1. Smooth Data\nTo eliminate noise interference in the acceleration data, a Simple Moving Average (SMA) is\napplied to the three-axis acceleration data (X, Y, Z). A window size of 3 is used to calculate\nthe average of each data point and its neighboring points.\n2. Calculate the Composite Acceleration\nComposite acceleration is computed from the smoothed three-axis acceleration data and\nserves as the foundation for subsequent processing.\n3. Calculate Whether to Reverse the Signal\nTo distinguish different phases of an action, the signal’s direction is evaluated for potential\ninversion:\nCalculate the deviation of the maximum and minimum acceleration values from the stan-\ndard gravitational acceleration (9.8 m/s2).If the minimum value’s deviation signiﬁcantly\nexceeds the maximum value’s deviation, the signal is inverted.The inversion ensures con-\nsistent peak orientation, facilitating more accurate peak detection.\n4. Calculate Relative Height\nThe relative height of peaks is calculated based on the maximum and minimum accelera-\ntion values within the window. A relative height threshold of 40% of the acceleration range\nis used to ﬁlter out minor ﬂuctuations.The prominence of a peak is determined using the\n34\nFigure 3.9: Process for ﬁnding peak locations\n35\nprominence parameter from Python’s [scipy.signal.ﬁnd_peaks] method.Prominence is de-\nﬁned as:\nProminence = Peak Height−max(Left Base,Right Base)\n(3.1)\nThe left and right bases represent the lowest points on either side of the peak.After testing,\nsetting the prominence threshold to 40% of the acceleration range(Prominence=(max_acc\n－min_acc) * 0.4)yielded the best results.\n5. Calculate Absolute Height\nValues below the gravitational acceleration (9.8 m/s2) are adjusted to 9.8 to mitigate the\nimpact of low values on calculations.The adjusted signal ’s mean is calculated as the base-\nline.A peak’s absolute height threshold is set to 101.5% of the baseline (a 1.5% increment),\nﬁltering signiﬁcant peaks related to actions while reducing false detections caused by gen-\neral ﬂuctuations.\n6. Find the Peak Location\nUsing the [scipy.signal.ﬁnd_peaks] method in Python, peaks are ﬁltered based on relative\nheight, absolute height, and a minimum distance of 22 data points between peaks. This\nprocess identiﬁes valid peaks in the window and calculates their positions.\n3.5\nState Recognition Model and Fitness Movement Recognition Model us-\ning Machine Learning\nTo support the above algorithm in classifying users’ states and ﬁtness activity types, we trained\ntwo machine learning models using common Python libraries such as NumPy and scikit-learn.\nBelow are the details of the model training process.\n3.5.1\nData collection\nThis study utilized the Google Pixel Watch 2 running Android OS 4.0 (API 34) to collect three-\naxis acceleration data, as shown in Figure 3.10. The device was worn on the left wrist of 10\nvolunteers. Data collection was conducted in the gymnasium of Aoyama Gakuin University’s\nSagamihara Campus, recorded at a sampling rate of 12.5 Hz.\nIn total, data for eight types of ﬁtness activities were collected, including 1,701 ﬁtness actions\nand approximately 120 minutes of non-exercise state data during the ﬁtness sessions, as shown\n36\nFigure 3.10: Devices and wear positions\nFigure 3.11: Distribution in data sets\n37\nin Figure 3.11. Figure 3.12 illustrates the three-axis acceleration corresponding to each activity\ntype.\nFigure 3.12: 3-axis acceleration for 8 types of movements\nDuring data collection, volunteers performed various predeﬁned ﬁtness activities using des-\nignated gym machines. However, no strict requirements were imposed on speed, weight load,\nor repetitions per set. This ensured that the data closely resembled real-world ﬁtness scenarios,\nproviding valuable support for model training.\n3.5.2\nData preprocessing\nIn this study, the collected acceleration data was smoothed to reduce the impact of potential\noutliers during data collection on subsequent analysis. To enhance computational efﬁciency,\nwe applied a sliding window averaging method for smoothing. Speciﬁcally, the sliding window\nsize was set to 3, and the value of each data point was calculated as the average of that point and\nits two adjacent points (one before and one after).\n38\nThis method effectively smooths short-term ﬂuctuations while preserving the primary trends\nand characteristics of the data, providing a more stable and reliable input for subsequent data\nsegmentation and feature extraction.\n3.5.3\nData set segmentation\nAfter smoothing the data, it was segmented based on the requirements of different models:\n1. Segmentation for the State Classiﬁcation Model\n• Manual Separating:\nThe data was manually cleaned to separate exercise states from non-exercise states\nwithin the same dataset. Exercise state data was saved as independent datasets for\neach set of actions, while non-exercise state data was saved in segments, ensuring con-\ntinuity within each dataset and avoiding concatenation from different segments.\n• Window:\nThe window size was set to match real-time recognition parameters, 70 data points\nwith a stride of 5, to maintain consistency across data processing standards.\n2. Segmentation for the Type Classiﬁcation Model\nFollowing the approach of the Double-Layer Sliding Window (DLSW) algorithm, segmen-\ntation points were determined based on the positions of synthetic acceleration peaks:\n• Synthetic Acceleration Calculation:\nComposite acceleration was calculated from three-axis acceleration data.\n• Peak Detection:\nPeaks were detected using the ﬁnd_peaks method in Python ’s scipy.signal library.\n• Windowing Around Peaks:\nFor each peak position, a window of 50 data points centered around the peak was ex-\ntracted, providing the input data for subsequent feature extraction.\n3.5.4\nFeature Selection\nAfter splitting the dataset for each model, we ﬁrst performed feature extraction in Python.\nFeature extraction is crucial, as the selected features directly affect classiﬁcation accuracy. Choos-\ning the right features means identifying key attributes that best represent the original data. In\n39\nother studies, researchers select different types of features based on the classiﬁcation model\nthey are building. These features are mainly divided into time-domain and frequency-domain\nfeatures. Compared to time-domain features, frequency-domain features have a higher compu-\ntational cost [18].\nWe referred to other studies and selected commonly used features such as maximum, min-\nimum, median, kurtosis, skewness, zero-crossing rates, correlation coefﬁcient, peak-to-peak\nvalue, and correlation between axes [28]. Below are the features used in this study for the state\nrecognition model and the category recognition model. Some feature calculations were based\non [28][29][30][31] and were implemented using the NumPy and SciPy libraries in Python.\nTable 3.1: Feature Descriptions\nFeature Name\nExplanation\nmax\nMaximum value in the window\nmin\nMinimum value in the window\nmdn\nMedian value\nkts\nKurtosis\npeak_value\nMaximum absolute value in the window\npeak_to_peak_value\nDifference between maximum and minimum values\nskewness\nMeasures the degree of skewness of the data distribution relative to a\nsymmetric distribution\nsma\nSignal Magnitude Area [32]\nnum_prominent_peaks_3\nNumber of peaks with prominence > 0.3\nnum_prominent_peaks_5\nNumber of peaks with prominence > 0.5\nnum_prominent_peaks_7\nNumber of peaks with prominence > 0.7\nmax_peak_value\nPeak value with prominence > 0.7\nspectral_centroid\nWeighted average of signal frequency distribution\nspectral_ﬂatness\nIndicator of the uniformity of the signal’s spectral distribution\ncor_xy\nCorrelation coefﬁcient of x-axis and y-axis\nzcr\nZero-Crossing Rate\ntotal_energy\nThe power spectral density of the signal is calculated and integrated\nto obtain the total energy of the signal.\nbandpass_energy_0_2_0_3\nTotal energy in the frequency range 0.2 Hz to 0.3 Hz\nbandpass_energy_0_4_0_6\nTotal energy in the frequency range 0.4 Hz to 0.6 Hz\nbandpass_energy_0_7_0_8\nTotal energy in the frequency range 0.7 Hz to 0.8 Hz\nThe calculation methods for commonly selected features such as maximum and minimum\nare omitted here. Instead, we will focus on explaining the calculation methods for other features\nspeciﬁcally deﬁned in this study.\n40\n• Signal Magnitude Area\nThe normalized Signal Magnitude Area (SMA) reﬂects the overall average absolute magni-\ntude of a signal and is used to quantify its intensity or energy characteristics in a speciﬁc\ndimension. In time series analysis, it helps compare the average magnitude of different\nsignals, such as the acceleration characteristics in various directions during ﬁtness move-\nments.\nxsma =\nPN\ni=1 |x[i]|\nN\n– |x[i]|: The absolute value of the i-th sample of the signal;\n– N: The total number of samples in the signal;\n– P|x[i]|: The sum of the absolute values of the signal amplitude.\n• num_prominent_peaks\nWe found that the number of prominent peaks exceeding a certain threshold differs be-\ntween ﬁtness and non-ﬁtness states. Therefore, we included the number of peaks with\nprominence greater than 0.3, 0.5, and 0.7 as features. Using the ‘ﬁnd_peaks‘ method with a\nspeciﬁed prominence parameter, we detected signiﬁcant peaks in the signal and recorded\ntheir count as feature values.\n41\nFigure 3.13: The number of peak points exceeding the threshold in three-axis acceleration: (left)\nﬁtness state, (right) non-ﬁtness state.\n• max peak value\nThe algorithm detects peaks in the signal based on the speciﬁed prominence parameter\n(prominence > 0.7) and returns the maximum value among these peaks. If no peaks are\nfound, it returns 0.\n• Power Spectral Density\nNext, to compute frequency features, we analyzed the peak frequency distribution of three-\naxis acceleration within each segmented data window. First, we calculated the power spec-\ntral density (PSD) for each window using the ‘welch‘ method from the ‘scipy.signal‘ library.\nThis method analyzes the energy distribution of the signal in the frequency domain by seg-\nmenting the signal, computing the spectrum for each segment, and averaging the results.\n42\nTo accommodate the characteristics of the signal and the limitations of data length, we set\nthe segment size for Welch ’s method to 50 data points. Additionally, adjacent segments\nhad an overlap of 10 points (20% overlap) to further smooth the PSD curve and reduce\nestimation variance. With this conﬁguration, each window of the signal was ﬁrst processed\nwith a Hanning window to minimize edge effects, followed by a Fast Fourier Transform\n(FFT) to compute its spectrum. The squared values of all windowed spectra were then\naveraged to generate the ﬁnal PSD curve.\nSxx(f ) = 1\nL\nLX\nk=1\n1\nnperseg\n¯¯¯¯¯\nnperseg−1\nX\nn=0\nxk[n]w[n]e−i2πf n∆t\n¯¯¯¯¯\n2\n• spectral centroid\nIn the analysis of acceleration signals during ﬁtness activities, the spectral centroid repre-\nsents the weighted average of the signal’s frequency spectrum, reﬂecting the primary fre-\nquency characteristics of the movement. A lower spectral centroid value indicates that\nlow-frequency components dominate the signal, which is typically associated with slower\nor more controlled movements. In contrast, a higher spectral centroid suggests that high-\nfrequency components are dominant, often corresponding to faster and more dynamic\nmovements [30]. We calculate the spectral centroid based on the previously computed\nPSD, using the following formula:\nFor a given frequency array f [i] and PSD values S[i], the spectral centroid C is deﬁned as:\nC =\nP\ni f [i]·S[i]\nP\ni S[i]\n– f [i]: The i-th frequency point;\n– S[i]: The PSD value corresponding to the i-th frequency point;\n– The numerator is the weighted sum of frequencies by their corresponding power;\n– The denominator is the total power, used for normalization.\n• spectral ﬂatness\nSpectral Flatness is calculated as the ratio of the geometric mean to the arithmetic mean of\nthe spectrum and is used to measure the uniformity of the spectral distribution.\nFirst, the magnitude spectrum is obtained by applying the Fast Fourier Transform (FFT)\nto the input signal. Then, the geometric mean and arithmetic mean of the spectrum are\n43\ncomputed. The geometric mean is derived by taking the logarithm of the magnitude val-\nues, averaging them, and then applying the exponential function. The arithmetic mean is\nsimply the average of the spectral magnitudes.\nFinally, spectral ﬂatness is obtained by dividing the geometric mean by the arithmetic\nmean. This metric reﬂects the frequency distribution characteristics of the signal: higher\nspectral ﬂatness indicates a more uniform energy distribution across frequencies (e.g., white\nnoise), while lower spectral ﬂatness suggests that energy is concentrated at a few speciﬁc\nfrequencies.\nThe Spectral Flatness is deﬁned as:\nSpectral Flatness =\n¡QN\ni=1\n¡\nSx(fi)+ϵ\n¢¢ 1\nN\n1\nN\nPN\ni=1\n¡\nSx(fi)+ϵ\n¢\n– Sx(fi): The power spectral density (PSD) corresponding to the i-th frequency point;\n– N: The total number of frequency points;\n– ϵ = 1×10−10: A small constant added to avoid division by zero or taking logarithms of\nzero.\n• Total energy\nBy computing the total energy of the Power Spectral Density (PSD), the overall energy dis-\ntribution across the entire frequency domain can be quantiﬁed. This reﬂects the overall\nintensity characteristics of the signal, providing a measure of movement intensity or activ-\nity level.\nThe total energy is calculated by summing the PSD values across all frequency points and\nmultiplying by the frequency resolution ∆f = freqs[1]−freqs[0]. The formula is as follows:\nEtotal =\nX\ni\nSx(fi)·∆f\nwhere Sx(fi) represents the power spectral density value at the ith frequency point.\n• bandpass_energy\nTo analyze the energy distribution of the signal within speciﬁc frequency ranges, we com-\nputed the Bandpass Energy within each window. First, we determined the dominant fre-\nquency range by calculating the signal’s frequency distribution using Power Spectral Den-\nsity (PSD). Then, we integrated the PSD within this frequency band to obtain the total en-\nergy in that range.\n44\nAfter extracting the peak frequency from the PSD in each window, we used Kernel Den-\nsity Estimation (KDE) to visualize the distribution of dominant frequencies. KDE is a non-\nparametric method that smooths discrete frequency distributions into a continuous prob-\nability density function, revealing the concentration and overall trend of frequency com-\nponents.\nFor implementation, we used the kdeplot function from the Seaborn library to generate\nKDE visualizations. The results are shown in the ﬁgure.\nFigure 3.14: Main Frequency Distribution in Exercise State\n45\nFigure 3.15: Main Frequency Distribution in Non-Exercise State\nFrom the ﬁgure, it can be observed that in the exercise state, the dominant frequencies\nare concentrated in the ranges of 0.2–0.3 Hz, 0.4–0.6 Hz, and 0.7–0.8 Hz, whereas in the\nnon-exercise state, the frequency distribution is more dispersed.\nWe then used the following formula to compute the total energy within each of these three\nfrequency ranges.\nEbandpass =\nX\ni∈band\nSx(fi)∆f\n– Sx(fi): The PSD value at the frequency point fi;\n– ∆f = freqs[1]−freqs[0]: The frequency resolution;\n– band: The set of frequency points within the bandpass range.\nThe ﬁgure shows the differences in total energy across different frequency ranges between\nthe exercise and non-exercise states. Therefore, we deﬁned the total energy in each of the three\nfrequency ranges as separate feature values.\n46\nFigure 3.16: Comparison of Energy in Three Frequency Ranges for Different States: (Top) Exer-\ncise State (Bottom) Non-Exercise State\n• Zero Crossing Rate\nZero Crossing Rate (ZCR) is a frequency-domain feature that measures the rate of signal\nchanges by calculating the proportion of zero crossings within a unit time. It is determined\nby detecting sign changes between adjacent sampling points, counting the total number of\nzero-crossings, and dividing this count by the signal length.\nZCR = 1\n2\nN\nX\nn=2\n¯¯sign(xn)−sign(xn−1)\n¯¯\n• Correlation Coefﬁcient\nBy computing the correlation coefﬁcients between the X, Y, and Z axes of the acceleration\nsignal, the relationship between different directional movements is quantiﬁed. Speciﬁcally,\nthe X, Y, and Z components of the signal are ﬁrst extracted, and then the Pearson correlation\ncoefﬁcients for X-Y, X-Z, and Y-Z are calculated using np.corrcoef.\n47\ncor(X ,Y ) = cov(X ,Y )\nσX σY\n3.5.5\nState Classiﬁcation Model Training and Feature Reduction\nWe referred to previous studies [30][33] that summarized commonly used machine learning\nmethods for state recognition and selected Random Forest, Decision Tree, SVM, K-Means, and\nNaïve Bayes for comparison. The models were ﬁrst trained in Python, and their performance\nwas evaluated using accuracy and F1-score. The results are shown in the table below.\nTable 3.2: Comparison of State Classiﬁcation Model Performance\nModel\nF1-Score\nAccuracy\nRandom Forest\n0.972\n0.974\nDecision Tree\n0.927\n0.922\nSVM\n0.919\n0.915\nK-MEANS\n0.968\n0.967\nNaive Bayes\n0.762\n0.776\nSimilar to ﬁndings in other studies, the Random Forest algorithm demonstrated strong per-\nformance, making it the chosen method for training the state recognition model.\nSince the model is intended to run on an ofﬂine device, dimensionality reduction was nec-\nessary to lower computational complexity. To achieve this, we combined Gini-based feature\nselection [34][35][36] and SHAP (Shapley Additive Explanations) [37][38] to evaluate feature im-\nportance.\nIn Random Forest, the Gini Impurity is a key metric for measuring node purity and assess-\ning each feature ’s contribution to classiﬁcation decisions. By analyzing feature importance,\nwe performed feature selection and dimensionality reduction, retaining only the most valuable\nfeatures for classiﬁcation. This approach helps reduce computational complexity and mitigates\nthe risk of overﬁtting.\nThe Gini Impurity quantiﬁes classiﬁcation impurity and is calculated using the following for-\nmula:\nG = 1−\nKX\nk=1\np2\nk\n• K : The number of classes;\n48\n• pk: The proportion of samples belonging to the k-th class in the current node.\nThe smaller the Gini Index, the purer the samples in the current node, and the better the\nclassiﬁcation effect. During the training process of a Random Forest, the Gini Index is used to\nmeasure the change in purity before and after the split.\nSHAP (SHapley Additive exPlanations) is based on Shapley values from game theory, which\nprovide a method for fairly distributing rewards. In machine learning, Shapley values quantify\neach feature’s average marginal contribution to the overall prediction, ensuring fairness, consis-\ntency, and efﬁciency in explanations.\nWithin the SHAP framework, this method is used to assess each feature ’s contribution to\nmodel predictions. The core idea is to evaluate all possible subsets of features, compute the im-\npact of adding a speciﬁc feature to each subset, and assign contribution values using a weighted\naverage. This approach provides an interpretable explanation of the model’s decision-making\nprocess.\nSpeciﬁcally, we set the number of trees (n_estimators) between 50 and 150, increasing by 5\neach time, and evaluated model accuracy using 5-fold cross-validation. The results showed that\nmodel performance stabilized when the number of trees ranged between 75 and 125. Next, we\nreﬁned the search within this range, increasing by 1 each time and performing another 5-fold\ncross-validation, ultimately determining the optimal number of trees to be 100.\nBased on this, we further tuned the tree depth (max_depth) from 1 to 11, again using 5-fold\ncross-validation, to determine the best depth parameter. Using the optimized model, we then\ncalculated the contribution of each feature to the prediction results.\nFinally, by combining the results from Gini-based selection and SHAP analysis, we selected\nthe top 25 most important features. The ﬁnal selected features are shown in the table below.\nNext, we extracted data for these selected features and split it into a training set and test set\nwith an 80:20 ratio. We trained the model using 10-fold cross-validation with the GridSearchCV\nmethod to ﬁne-tune hyperparameters. The model’s performance was evaluated using accuracy\nand F1-score, and a confusion matrix was generated to visualize the classiﬁcation results.\nThe ﬁnal results are shown in the ﬁgure below.\n49\nTable 3.3: Feature Names in State Classiﬁcation Model\nFeature Names\nx_zcr\nx_spectral_ﬂatness\nx_num_prominent_peaks_7\ny_num_prominent_peaks_3\nx_spectral_centroid\nx_bandpass_0_4_0_6\ny_spectral_centroid\nz_zcr\nx_bandpass_0_7_0_8\ny_zcr\ny_peak_value\ny_bandpass_0_2_0_3\nx_total_energy\nx_max_peak\ny_kts\ny_bandpass_0_4_0_6\ny_total_energy\nz_spectral_ﬂatness\ny_spectral_ﬂatness\ncor_yz\nx_skewness\nx_sma\nx_peak_to_peak_value\ny_peak_to_peak_value\ny_sma\nFigure 3.17: Confusion Matrix for State Classiﬁcation Models\nThe results showed an accuracy of 92.1% and an F1-score of 0.917. The recognition accuracy\nfor the ﬁtness state was particularly high, likely because the selected features were more distinc-\n50\ntive in ﬁtness-related movements. This aligns with our objective of assigning higher weight to\nthe ﬁtness state for improved classiﬁcation performance.\n3.5.6\nType Classiﬁcation Model Training and Feature Reduction\nSimilar to the state classiﬁcation model, we ﬁrst created a dataset using all features. Then,\nwe trained multiple machine learning classiﬁcation models for comparison. The results are as\nfollows:\nTable 3.4: Comparison of Type Classiﬁcation Performance\nModel\nF1-Score\nAccuracy\nRandom Forest\n0.948\n0.943\nDecision Tree\n0.871\n0.868\nSVM\n0.941\n0.940\nK-MEANS\n0.940\n0.936\nNaive Bayes\n0.894\n0.887\nFollowing the same approach as in the state classiﬁcation model, we ﬁrst trained a random\nforest model using all features and ﬁne-tuned its key parameters to assess feature importance.\nIn the initial tuning phase, we performed cross-validation to evaluate the impact of different\nparameter combinations on model accuracy, identifying a stable parameter range. We then re-\nﬁned the tuning process within this range to determine the optimal combination of parameters,\nincluding the number and depth of trees.\nBased on the optimized random forest model, we computed the contribution of each feature\nto classiﬁcation performance. From the feature importance analysis, we selected the most sig-\nniﬁcant features and split them into training and test sets. As shown in the table, most of the\nhigh-contribution features are related to acceleration along the X-axis, which aligns with the\ncharacteristics of our target movements―most actions exhibit signiﬁcant variations along the\nsmartwatch ’s X-axis direction.\nFor further model training, we used grid search and cross-validation to optimize perfor-\nmance, ensuring stability and generalization. Finally, we evaluated the model using accuracy\nand F1-score, and visualized the classiﬁcation results through a confusion matrix, leading to the\nselection of the best-performing model.\n51\nTable 3.5: Feature Names in Type Classiﬁcation Model\nFeature Names\ncor_xy\ncor_xz\ncor_yz\nx_bandpass_energy\nx_kts\nx_max\nx_max_peak_value\nx_min\nx_peak_to_peak_value\nx_peak_value\nx_skewness\nx_spectral_centroid\ny_max\ny_mdn\ny_min\ny_num_prominent_peaks\ny_peak_to_peak_value\ny_peak_value\ny_skewness\ny_spectral_centroid\nz_bandpass_energy\nz_skewness\nz_spectral_centroid\nz_zcr\nFigure 3.18: Confusion Matrix for Type Classiﬁcation Models\nThe category classiﬁcation model achieved an accuracy of 97.1% ± 2.1 and an F1-score of\n0.97 ± 0.022. Among the classiﬁcations, Lat Pull Down (Class 5) and Shoulder Press_1 (Class 7)\nwere more prone to misclassiﬁcation. We speculate that this is due to the similarity in movement\n52\npatterns between the two exercises. After standardization, the range of variation in three-axis\nacceleration was reduced, making it harder to distinguish between them.\n53\nChapter 4\nAlgorithm ofﬂine experiments and results\nBefore developing the Android application incorporating this algorithm, we ﬁrst conducted\nofﬂine experiments to verify its performance and applicability. The experiments were divided\ninto two main parts: DLSW algorithm validation for category classiﬁcation and TLSW algorithm\nvalidation for overall performance. All ofﬂine experiments were conducted in a Python environ-\nment on Google Colaboratory.\n4.1\nExperimental data collection\nWe ﬁrst collected the necessary experimental data with the assistance of seven male volun-\nteers aged 21 to 26, all with prior ﬁtness experience. Before data collection, volunteers were\ninformed of the available ﬁtness activities and created personal workout plans based on their\npreferences. Each participant selected 2–3 types of exercises, performing at least two sets per\nexercise.\nBefore starting the workout, volunteers engaged in light physical activity as a warm-up, dur-\ning which data collection began. Volunteers then followed their planned workout routines, and\ndata collection ended when they either completed their workout or could no longer continue.\nIn total, we collected approximately 3.3 hours of data, including 892 recorded ﬁtness move-\nments and around 2.4 hours of non-exercise data.\n54\n4.2\nDLSW Algorithm Experiment\nIn the Double-Layer Sliding Window (DLSW) algorithm test, we segmented and separately\nsaved each set of ﬁtness activity data. We then conducted comparative testing in a Python envi-\nronment, using a traditional ﬁxed-step sliding window approach with step sizes set to 25%, 50%,\nand 75% of the window size.\nFollowing the same classiﬁcation method as in the algorithm, we recorded the prediction\nresults for each set of data. To evaluate the performance, we used two key metrics:\n1. Probability of Correct Single Classiﬁcation – Measures the classiﬁcation accuracy for each\nindividual sliding window.\n2. Probability of Correct Classiﬁcation in the Result – Evaluates the proportion of correctly\nclassiﬁed target labels within a set of actions.\nSince the algorithm determines the ﬁnal classiﬁcation based on the most frequently pre-\ndicted label within a set of movements, minor misclassiﬁcations do not signiﬁcantly affect the\noverall result. These two metrics effectively reﬂect the algorithm’s classiﬁcation performance.\nFigure 4.1: Optimized results for Double-Layer Sliding Window\n55\nThe results showed that, compared to the ﬁxed-step sliding window, this method reduces the\nnumber of computations, lowering computational overhead while maintaining better accuracy\nin both single classiﬁcation and correct label proportion within a set of movements.\nDuring testing, we observed that when movements were slower, the sliding window often\nincluded a higher proportion of transition data between two actions, leading to a decrease in\nclassiﬁcation accuracy. In such cases, using the peak point within the window as the center for\nclassiﬁcation proved to be a more effective approach.\n4.3\nTLSW Algorithm Experiment\nFor the TLSW algorithm experiment, we ﬁrst simulated a real-time environment that closely\nresembles actual usage conditions. In this test, we used the collected experimental dataset and\nstrictly followed the sliding window size and step length deﬁned in the TLSW algorithm to en-\nsure consistency between the experiment and real-world execution.\nSpeciﬁcally, we applied the sliding window technique to incrementally segment and process\nthe data, simulating the characteristics of a real-time data stream. At each step, feature values\nwere computed and fed into the classiﬁcation model for evaluation.\nFigure 4.2: Optimized results for Double-Layer Sliding Window\n56\nWe compared the single classiﬁcation accuracy of different exercise categories with the cor-\nrected classiﬁcation accuracy for a full set of movements. As shown in the ﬁgure, although Ma-\nchine Row and Shoulder Press_2 had relatively low single classiﬁcation accuracy, at around 75%,\nthe majority of movements within each set were correctly classiﬁed. After applying the cor-\nrection strategy, the overall classiﬁcation accuracy for these exercises signiﬁcantly improved,\ndemonstrating the effectiveness of the correction method in enhancing overall classiﬁcation\nperformance.\nFigure 4.3: Performance in recognizing actions of varying durations\nIn addition to classifying different exercise categories, we also calculated the average dura-\ntion per movement and divided it into four time ranges, from less than 3 seconds to more than\n5 seconds. We then conducted a detailed analysis for each range.\nThe results showed that the algorithm performed well when movement durations were be-\ntween 3 and 5 seconds. However, when movements lasted less than 3 seconds, the accuracy of\nthe three evaluation metrics dropped to approximately 90\nTo investigate these issues, we conducted further analysis. For movements shorter than 3\nseconds, since the window size for action classiﬁcation was set to 4 seconds, each window may\n57\nhave contained parts of the previous or next movement, leading to mixed data that affected fea-\nture calculations and classiﬁcation performance. For movements longer than 5 seconds, since\nthe peak detection window was 4.8 seconds, when the window moved between two movement\npeaks, some secondary peaks might have been mistakenly identiﬁed as primary peaks, causing\novercounting. Although we introduced restrictions in the peak detection algorithm, they did not\nfully eliminate the impact of secondary peaks.\nBeyond the effect of movement duration on algorithm performance, we also observed other\npotential sources of error. For instance, short pauses between repetitions and changes in grip\nposition (e.g., incorrect posture) during exercises sometimes led to misclassiﬁcation in state\nrecognition or movement type recognition.\nDespite these challenges, the overall results of the TLSW experiment demonstrated strong\nperformance. The algorithm achieved: 92.84% accuracy for ﬁtness state recognition,97.83% ac-\ncuracy for ﬁtness type classiﬁcation,96.33% accuracy for movement counting.\n58\nChapter 5\nSmartWT : An Android ﬁtness monitoring\napp that uses TLSW methods\nAfter validating the TLSW algorithm through ofﬂine experiments, we conﬁrmed that its per-\nformance meets the expected goals. It demonstrated strong results in ﬁtness state recognition,\nexercise classiﬁcation, and movement counting, providing a solid foundation for the next phase\nof our work.\nNext, we plan to integrate the TLSW algorithm and the optimized machine learning model\ninto an Android application. Based on feedback from the questionnaire survey, we aim to de-\nvelop a smart ﬁtness assistant capable of real-time ﬁtness state and movement recognition.\nThis application will collect acceleration data via a smartwatch and transmit it to a smart-\nphone for real-time processing. The smartphone will utilize the TLSW algorithm for sliding\nwindow processing, extract feature values, and classify movements using a pre-trained machine\nlearning model.\n5.1\nRelated work\nIn the current mobile device market, Android and iOS are the two dominant operating sys-\ntems. As an open-source system, Android not only holds a signiﬁcant share in the smartphone\nmarket but is also widely used in tablets, in-car systems, and IoT devices [39].\nIn human activity recognition research, researchers have not only developed innovative al-\ngorithms but also implemented them as Android applications, enabling functions such as fall\ndetection [41][44], gait symmetry analysis [40], and activity recognition [42][43]. Some stud-\n59\nies have leveraged machine learning or deep learning, deploying trained models on Android\ndevices using frameworks like TensorFlow, Keras, and ONNX, achieving efﬁcient real-time ap-\nplications on mobile platforms [45][46][47].\n5.2\nOverview of System Architecture\nFigure 5.1: System Composition Diagram\nFigure 5.1 illustrates the overall system architecture, which consists of a smartwatch, smart-\nphone, and cloud database. The devices used in this study include a Motorola g52j 5G smart-\nphone and a Google Pixel 2 smartwatch, with Google Firebase serving as the cloud database.\nBoth the smartwatch and smartphone run on the Android operating system, with the smart-\nphone using Android 14 and the smartwatch running Android Wear OS 4.0. The software devel-\nopment was conducted on Windows 11 using Android Studio Giraffe | 2022.3.1 Patch 2.\nFigure 5.2 illustrates the system workﬂow. The process begins with the user logging into their\naccount, which is authenticated through Firebase. Upon successful authentication, the system\nautomatically checks the connection status of the smartwatch.\n60\nTable 5.1: Functions of Each Component\nComponent\nFunctionality\nSmartphone\nTransmission of acceleration data, Show ﬁtness plan, Vibration feed-\nback\nSmartwatch\nUser login, Operate the watch, View historical data & ﬁtness move-\nment descriptions, Real-time recognition\nFirebase\nStore user accounts, Stores historical user data\nAfter logging in, users can view historical data and ﬁtness tutorials on the smartphone, re-\ngardless of the smartwatch ’s connection status. However, the automatic tracking function is\nonly available when the smartwatch app is open and online.\nBefore starting a workout, users input their ﬁtness plan on the smartphone, which is then\nsynchronized to the smartwatch and displayed on its screen. When the Start button is pressed,\nthe SmartWT system begins operating. The smartwatch starts collecting three-axis acceleration\ndata during the workout and transmits it in real time to the smartphone.\nThe smartphone processes the received data in real time, recognizing ﬁtness movements\nand counting repetitions. It updates the progress according to the predeﬁned workout plan and\nsends updates back to the smartwatch, dynamically displaying the remaining exercises. When\na set is completed, the smartwatch vibrates to notify the user of their progress.\nDuring the workout, users can check the remaining repetitions at any time via the smart-\nwatch or smartphone. When the workout plan is completed, or if the user chooses to stop early,\npressing the Stop button on the smartphone halts the SmartWT system. The system then up-\nloads the workout plan and completion progress to the cloud database, allowing users to review\ntheir workout history on the smartphone.\n5.3\nAndroid application for smartphone\nIn this study, the Android application on the smartphone is responsible for data processing,\ndevice management, and model inference, enabling automated ﬁtness tracking and user inter-\naction.\nData transmission is handled using Data Layer API [48], an Android synchronization mecha-\nnism designed for efﬁcient data transfer between smartphones and smartwatches. Additionally,\nﬁtness data is synchronized to the cloud via Firebase. Upon user login, the application auto-\nmatically checks the smartwatch ’s connection status, and the automatic tracking function is\n61\nFigure 5.2: System Operation Flowchart\n62\nonly enabled when the smartwatch is online and the app is running.\nFor model inference, the application utilizes ONNX Runtime, a cross-platform deep learning\ninference engine that efﬁciently runs pretrained machine learning models on Android devices\n[49]. This enables ﬁtness activity recognition and repetition counting.\nIn this chapter, we focus on the development details of the automatic recognition system,\nwhich is directly relevant to this study. Explanations of device connection status, data upload,\nand database retrieval are omitted.\nThe ﬁgure illustrates the workﬂow of the automatic recognition function, which follows the\nsame process as the TLSW algorithm described in Chapter 3. The system consists of four core\ncomponents: data reception, ﬁtness state recognition, movement classiﬁcation, and corrected\nresult output.\nThe entire process is governed by three key decision points, which determine when each\ncomputation step is triggered to ensure the algorithm operates correctly. However, due to dif-\nferences in computing environments and the fact that ofﬂine Python code does not involve data\ntransmission, adjustments were made on the Android side to accommodate data transmission,\nsliding window data structures, and feature computation.\n5.3.1\nData transmission\nWe used Google’s Data Layer API to enable real-time transmission of three-axis acceleration\ndata between the smartphone and smartwatch. This method is highly convenient as it does not\nrely on an internet connection, allowing communication even when both devices are ofﬂine.\nAdditionally, communication is restricted to paired devices, ensuring data security.\nIn our algorithm, one system computation is performed for each received batch of three-axis\nacceleration data. Ideally, data transmission should follow this sequence: smartwatch sends\ndata →smartphone receives data →computation is completed →smartwatch sends the next\nbatch.\nInitially, we designed the system so that the smartwatch would send data immediately after\ncollecting each batch. However, testing showed that frequent API calls at high transmission\nrates caused signiﬁcant data loss due to system-level asynchronous operations, with a loss rate\nof approximately 10\nTo address this issue, we modiﬁed the data transmission logic so that the smartwatch now\ncollects and transmits data in batches of ﬁve. On the smartphone side, data is received and\n63\nFigure 5.3: Flowchart of smartphone app auto-recognition function\n64\ninserted into the sliding window structure at 80ms intervals, followed by a computation cycle.\nTesting showed that this approach increased data transmission success to 98.3%, though a small\ndegree of data loss still remained.\n5.3.2\nData structure of the sliding window\nIn the ofﬂine Python experiments, while testing the TLSW algorithm, we simulated sliding\nwindows by reading data points from the dataset at predeﬁned positions. Speciﬁcally, we cre-\nated a new data structure, populated it with data from the original dataset, and then applied the\nalgorithm for computation.\nHowever, in real-time execution, to improve efﬁciency and reduce computational overhead\ncaused by continuous data copying, we implemented the sliding window using a circular queue.\nBy maintaining queue indices (start_index and end_index), we dynamically tracked the head\nand tail positions of the data queue. This ensured that extracted data preserved its original time\nsequence, allowing the system to accurately retrieve data from different positions within the\nwindow for state recognition and movement classiﬁcation.\n5.3.3\nFeature Value Calculation\nDuring model training and testing in the Python environment, we used various libraries to\ncompute feature values. However, in the Android environment, when computing Fourier Trans-\nform and other feature values using Java libraries, we observed signiﬁcant discrepancies in the\nresults.\nWe attempted to manually adjust all parameters to minimize errors, but the discrepancies re-\nmained substantial. To resolve this, we integrated Chaquopy (version 15.0.1) to execute Python\nscripts directly on Android. This allowed us to use the same Python code for feature computa-\ntion as in the ofﬂine experiments.\nFor complex feature calculations or peak detection algorithms, the application calls a Python\nscript, processes the computation, and returns the results to the Android environment. Testing\nconﬁrmed that this method successfully reduced errors, although minor precision differences\nremained due to variations in computing environments. Nevertheless, the error margin was\nsigniﬁcantly lower compared to using Java-based computations.\n65\n5.3.4\nInterface of Smartphone Application\nThe Figure 5.4 presents the user interface of the smartphone application developed in this\nstudy.\nThe upper section of the ﬁgure displays the login screen, menu screen, and history screen,\nwhile the lower section includes the automatic workout tracking interface, workout plan cre-\nation screen, and real-time progress tracking screen during workouts.\nIn the automatic workout tracking interface, users ﬁrst press the \"Create a Plan\" button to\nset up a personalized workout plan, specifying the number of sets and repetitions per exercise.\nOnce the plan is created, users can start the automatic tracking feature by pressing \"Start Work\nOut\".\nDuring the workout, as users complete each set, the system updates the remaining repeti-\ntions in the plan. When an exercise is fully completed, the system displays \"Fin\", indicating that\nthe movement is ﬁnished. Users can follow the plan sequentially or choose to end the workout\nearly.\nTo prevent accidental interruptions, stopping the workout requires a double-tap on the \"Stop\nWork Out\" button.\n5.4\nAndroid application for smartwatch\nIn this study, the smartwatch serves three main functions:\nCollecting acceleration data from the user and transmitting it to the smartphone.\nDisplaying the user ’s workout plan and updating progress in real time.\nProviding vibration feedback when a set is completed.\nData transmission is handled via Data Layer API, as explained in the previous section. There-\nfore, this section focuses on interface design and user interaction workﬂow.\nThe Figure5.5 shows the operational ﬂow of the smartwatch in the automatic workout track-\ning function. The process starts with the following steps:\n1. Checking device connection.\n2. Receiving the user ’s workout plan.\n66\nFigure 5.4: user interface of the smartphone application\n67\nFigure 5.5: Flowchart of smartwatch app auto-recognition function\n68\n3. Collecting three-axis acceleration data.\n4. Transmitting the data to the smartphone via Data Layer API.\nAfter the smartphone processes the data, it updates the workout plan progress on the smart-\nwatch. When the user completes a set, the smartwatch provides vibration feedback to notify\nthe user. The process concludes when the user either completes all sets or manually stops the\nprogram.\n5.4.1\nInterface of Smartphone Application\nAs shown in the ﬁgure5.6, when the smartwatch app is opened, the initial screen displays the\nconnection status with the smartphone (top left). After receiving the connection information\nfrom the smartphone, the screen transitions to the waiting for ﬁtness data screen (top right).\nOnce the user inputs their workout plan on the smartphone and starts the workout, the\nsmartwatch receives the user ’s plan and displays the remaining repetitions for each exercise.\nAfter completing a movement, the screen shows \"Fin\", and the smartwatch provides vibration\nfeedback to notify the user.\n69\nFigure 5.6: Interface of Smartphone Application\n70\nChapter 6\nExperiments and Results\n6.1\nAndroid device ofﬂine experiments and results\n6.1.1\nDescription of the experiment\nAfter completing the system development for both the smartwatch and smartphone, we con-\nducted ofﬂine experiments to verify the system’s performance before real-world use and testing.\nWe used the same dataset that was used in the Python environment for algorithm testing to con-\nduct the SmartWT system tests.\nIn the ofﬂine experiments, we stored the pre-prepared dataset on the smartwatch and sim-\nulated the data transmission process as it would occur in an actual experiment. Speciﬁcally,\nthe smartwatch sent test data to the smartphone in groups at the same time intervals as in real\nusage. Upon receiving the data, the smartphone processed and recognized it according to the\nactual operating logic.\nThis approach allowed us to test the smartphone system’s recognition performance with-\nout relying on actual user interaction. We were able to assess the algorithm ’s performance\nwithin the SmartWT system, verify whether the data transmission and recognition processes\nwere functioning properly, and evaluate whether the system demonstrated good stability and\naccuracy.\n6.1.2\nResurts\nFigure 6.1 shows the real-time recognition performance of the SmartWT system on Android\ndevices. Compared to the results from the Python environment shown in Figure 3.1, it can be ob-\n71\nFigure 6.1: Real-time recognition results of the SmartWT system on Android devices\nserved that, although the same algorithm and dataset were used, the recognition performance\non the Android side has slightly decreased. This is especially evident in the recognition of Ma-\nchine Row and Shoulder Press_2 movements. The accuracy of single recognition on Android\ndropped by approximately 10% compared to the Python environment.\nSimilarly, we analyzed the classiﬁcation accuracy corresponding to different movement du-\nrations. Compared to the results in Figure 3.2, there was a noticeable decline in accuracy for fast\nmovements with an average period of less than 3 seconds. For slower movements, there was\nalso a slight decrease in both state recognition and repetition count accuracy. This indicates\nthat movement duration does have a certain impact on the system’s recognition performance.\n6.2\nAndroid devices actual experiments and results\n6.2.1\nDescription of the experiment\nWe then designed and conducted real-world experiments, using the same smartphone and\nsmartwatch as in the ofﬂine experiments. The experimental process was as follows:\nVolunteers were asked to complete all exercises, with each exercise consisting of 3 sets, each\n72\nFigure 6.2: Recognition of different simultaneous movements by SmartWT system in an experi-\nment on Android devices\n73\nset containing 8 repetitions, for a total of 192 movements. To avoid excessive strain and reduce\nthe risk of injury, the experiment was divided into two sessions for each volunteer. In the ﬁrst\nsession, volunteers could freely choose 4 exercises from the 8 available exercises, and in the\nsecond session, they completed the remaining 4 exercises.\nDuring the experiment, volunteers were required to complete the speciﬁed number of repe-\ntitions regardless of the remaining repetitions displayed. However, if the volunteers felt fatigued\nor unable to complete a set, they could reduce the number of repetitions or discontinue the ex-\nperiment as they saw ﬁt. The experiment was conducted under the supervision and guidance\nof the researcher, who explained the equipment usage and exercise form to the volunteers be-\nforehand, recorded the number of repetitions during the experiment, and provided necessary\nassistance.\nA total of 9 participants took part in the experiment, including 8 males and 1 female, aged\nbetween 21 and 25 years. The participants had 1 to 3 years of ﬁtness experience and had no re-\ncent injuries or illnesses. The experiment was conducted in the ﬁtness room at Aoyama Gakuin\nUniversity. To protect the privacy of the participants and other gym users, no images of the\nparticipants were taken; only images of the researcher were used to illustrate the experimental\nprocess.\n6.2.2\nResurts\nAfter analyzing the experimental results of the 9 volunteers, we statistically divided the classi-\nﬁcation accuracy and counting accuracy based on different volunteers and exercise categories.\nThe ﬁnal results are shown in the ﬁgure below.\n74\nFigure 6.3: Experimental schematic\n75\nFigure 6.4: Results of the experiment for each volunteer\nFrom Figure 6.4, it can be seen that there are certain variations in classiﬁcation accuracy\nand counting accuracy among the different volunteers. Overall, the classiﬁcation accuracy is\ngenerally high, with most volunteers achieving over 90% accuracy. Notably, User7 and User8\nreached 100% classiﬁcation accuracy.\nIn contrast, the counting accuracy shows more ﬂuctuation. Some volunteers, such as User2\nand User6, had relatively low counting accuracy, with values of 63.55% and 63.33%, respectively.\nOn the other hand, User8 achieved the highest counting accuracy at 98.00%.\nThis indicates that, while the system performs relatively consistently in movement classi-\nﬁcation, there is still room for improvement in movement counting, especially in optimizing\nperformance for certain individuals.\n76\nFigure 6.5: Results of the experiment for each volunteer\nFrom Figure 6.5, it is evident that there are signiﬁcant differences in both classiﬁcation ac-\ncuracy and counting accuracy across different exercises. The classiﬁcation accuracy is generally\nhigh, with most exercises achieving over 88% accuracy. For instance, Machine Bicep Curl and\nMachine Lateral Raise had classiﬁcation accuracies of 92.59% and 92.50%, respectively. How-\never, some exercises, such as Machine Row, had lower classiﬁcation accuracy, with a perfor-\nmance of only 66.67%, the lowest among all exercises.\nThe counting accuracy shows even more variation. Some exercises performed well, such as\nPec Deck Fly and Lat Pull Down, with counting accuracies of 97.50% and 97.96%, respectively.\nHowever, other exercises, such as Machine Row and Shoulder Press_2, had relatively low count-\ning accuracies of 58.33% and 75.00%, which were noticeably lower compared to other exercises.\nOverall, the system performs well in classiﬁcation and counting for most exercises, but fur-\nther optimization is needed for movements like Machine Row and Shoulder Press_2, especially\nin terms of accuracy. This could involve adjusting feature extraction methods or algorithm pa-\nrameters to improve performance for these exercises.\nBy observing the volunteers’ movements during the experiment, we identiﬁed several fac-\ntors that could contribute to the decrease in performance, aside from data transmission and\ncomputation accuracy:\n77\n1. Large movement intervals: Due to fatigue, volunteers sometimes took longer breaks be-\ntween exercises, which may have impacted state recognition accuracy.\n2. Insufﬁcient movement range: Volunteers with less ﬁtness experience often performed ex-\nercises with a smaller range of motion, not fully completing the standard movements. This\ncould negatively affect classiﬁcation performance.\n3. Heavy load: When volunteers selected heavier weights, the slower movement speed and\nless noticeable acceleration made it harder for the system to detect peaks, reducing the\neffectiveness of peak detection and affecting both classiﬁcation and counting accuracy.\nThese factors suggest that the variability of users’ movement characteristics in real-world sce-\nnarios could impact the system’s performance. This should be taken into account when opti-\nmizing the algorithm.\n6.3\nSummary\n1. In the ofﬂine Python experiments, the system demonstrated excellent performance in both\nalgorithm recognition accuracy and counting performance. Since the ofﬂine experiments di-\nrectly read the dataset and calculated feature values without considering data transmission, the\nresults were highly stable. The classiﬁcation accuracy and counting accuracy reached 96.66%\nand 96.64%, respectively, representing the theoretical maximum performance of the system.\n2. In the ofﬂine experiments on Android devices, we used the same dataset and algorithm but\nsimulated the real data transmission process using the smartwatch. The experimental results\nshowed a slight decrease in both classiﬁcation accuracy and counting accuracy compared to\nthe Python ofﬂine experiments, mainly due to: a) Precision loss during the data transmission\nprocess. b) Subtle differences in ﬂoating-point calculations between the Android and Python\nenvironments.\nDespite these challenges, by optimizing the transmission logic and using Python scripts for\nfeature computation, the system performance remained at a high level, with classiﬁcation ac-\ncuracy and counting accuracy reaching 95.03% and 88%, respectively, which is still close to the\nPython experiment results.\n3. In the real-world Android experiment, where volunteers performed actual ﬁtness move-\nments, the results showed a further decrease in classiﬁcation and counting accuracy compared\nto the ofﬂine experiments. The main issues were: a) Some exercises (e.g., Machine Row and\n78\nShoulder Press_2) exhibited lower classiﬁcation and counting accuracy. b) Movements with\nshorter durations or smaller changes in acceleration were more prone to misclassiﬁcation.\nThese declines in performance were not only due to data transmission and computational\nenvironment differences but were also inﬂuenced by practical factors: i. Volunteers experienced\nfatigue, leading to longer movement intervals, which affected state recognition. ii. Less expe-\nrienced volunteers did not fully complete standard movements, resulting in reduced classiﬁca-\ntion performance. iii. When volunteers selected heavier weights, movements became slower,\nand acceleration became less noticeable, which impacted the peak detection algorithm.\nThe ﬁnal results showed a classiﬁcation accuracy of 86.11% and counting accuracy of 81.42%.\n79\nChapter 7\nFuture work\nTo further enhance the performance and applicability of the SmartWT system, future re-\nsearch will focus on the following improvements and expansions:\n1. Increasing Data Types\nThe current system primarily uses three-axis acceleration data for activity state recognition\nand classiﬁcation. However, to improve the algorithm’s robustness and ability to recognize\ncomplex movements, we plan to incorporate additional data types, such as angular veloc-\nity. During practical testing, we also measured the system’s runtime and found that there is\nstill considerable computation time available. Therefore, expanding the types of data used\nwill enhance the system ’s ability to capture posture changes and improve classiﬁcation\nand counting performance for various ﬁtness activities.\n2. Using Dynamic Length Sliding Windows\nCurrently, the system uses ﬁxed-length sliding windows to process the data, which may\nnot be well-suited to the rhythm differences in movements among different users. In the\nfuture, we plan to explore methods for dynamic length sliding windows that will adap-\ntively adjust the window length based on the user ’s actual movement characteristics. This\napproach will better capture personalized movement patterns, enhancing the system ’s\napplicability to a wider range of users.\n3. Improving Long-Term Feedback Mechanisms\nThe current system design focuses on real-time activity recognition and counting. How-\never, the impact of long-term ﬁtness behavior on users has not been thoroughly explored.\nFuture work will improve the long-term feedback system by analyzing users ’historical\n80\nﬁtness data to provide personalized suggestions and motivational incentives. Additionally,\nwe will integrate gamiﬁcation features, such as achievement systems and ranking mecha-\nnisms, to further investigate the role of long-term feedback in promoting user engagement\nand cultivating ﬁtness habits.\n81\nAcknowledgments\nThis thesis would not have been possible without the support of many people, and I would\nlike to express my deepest gratitude.\nFirst, I sincerely thank my supervisor, Prof. G. Lopez, for his tremendous support and for\ngiving me the opportunity to study and research here. His guidance went beyond academic\nmatters, providing me with encouragement in university life and career development after grad-\nuation. I have learned a lot from him―not only in research but also about food, culture, leader-\nship, and kindness. I have decided to continue my studies in the Lopez Laboratory as a doctoral\nstudent and hope to contribute even more in the future.\nI would also like to express my gratitude to Prof. Y. Tobe, who guided me in interacting with\nother researchers during conferences and presentations, and who provided valuable insights for\nmy research. Additionally, I am very grateful to Okuma-san from the Lopez Laboratory. She has\nnot only helped me with research but also supported me in daily life, which has been especially\nmeaningful as an international student.\nI feel proud to be part of the Lopez Laboratory. Since joining, I have received great support\nfrom everyone. They have helped me with research, daily life, and even improving my Japanese,\nallowing me to gradually feel at home and contribute to the lab. I would also like to acknowl-\nedge the rapid development of artiﬁcial intelligence, which has greatly improved my research\nefﬁciency and allowed me to explore even more knowledge.\nLastly, none of this would have been possible without the support and encouragement of my\nparents and family.\nThank you all!\nJanuary 30th, 2025\nLiu Zeyu\n82\nReferences\n[1] W. R. Thompson, “Worldwide Survey of Fitness Trends for 2023,” ACSM’s Health & Fitness\nJournal, vol. 27, no. 1, pp. 9–18, Dec. 2023, doi: 10.1249/ﬁt.0000000000000834.\n[2] G. Di Martino et al., “Enhancing Behavioural Changes: A Narrative Review on the Effective-\nness of a Multifactorial APP-Based Intervention Integrating Physical Activity,” International\nJournal of Environmental Research and Public Health, vol. 21, no. 2, Art. no. 2, Feb. 2024,\ndoi: 10.3390/ijerph21020233.\n[3] F. Ozdamli and F. Milrich, “Positive and Negative Impacts of Gamiﬁcation on the Fitness\nIndustry,” European Journal of Investigation in Health, Psychology and Education, vol. 13,\nno. 8, Art. no. 8, Aug. 2023, doi: 10.3390/ejihpe13080103.\n[4] I. Cho, K. Kaplanidou, and S. Sato, “Gamiﬁed Wearable Fitness Tracker for Physical Activity:\nA Comprehensive Literature Review,” Sustainability, vol. 13, no. 13, Art. no. 13, Jan. 2021,\ndoi: 10.3390/su13137017.\n[5] “The Role of Steps and Game Elements in Gamiﬁed Fitness Tracker Apps: A Systematic Re-\nview,” Accessed: Jan. 31, 2025. [Online]. Available: https://www.mdpi.com/2414-4088/\n5/2/5.\n[6] H. Xie, A. Watatani, and K. Miyata, “CoreUI: Interactive Core Training System with 3D Hu-\nman Shape,” arXiv preprint arXiv:2106.09196, 2021. [Online]. Available: https://arxiv.\norg/abs/2106.09196\n[7] Y. Wu, A. Kankanhalli, and K. Huang, “Gamiﬁcation in Fitness Apps: How Do Leaderboards\nInﬂuence Exercise?,” in ICIS 2015 Proceedings, 2015, no. 14. [Online]. Available: https:\n//aisel.aisnet.org/icis2015/proceedings/IShealth/14\n[8] R. Gal, A. M. May, E. J. van Overmeeren, M. Simons, and E. M. Monninkhof, “The Effect\nof Physical Activity Interventions Comprising Wearables and Smartphone Applications on\nPhysical Activity: A Systematic Review and Meta-analysis,” Sports Medicine – Open, vol. 4,\nno. 1, p. 42, 2018. doi: https://doi.org/10.1186/s40798-018-0157-9\n83\n[9] E. Southcott and J. Jooste, “Unveiling the Impact of Mobile Fitness Applications on Motiva-\ntional Orientation in Sustaining Exercise Behaviors: A Qualitative Investigation,” Physical\nCulture and Sport. Studies and Research, vol. 103, 2023. doi: 10.2478/pcssr-2024-0008.\n[10] D. Jin, H. Halvari, N. Maehle, and A. H. Olafsen, “Self-tracking behaviour in physical ac-\ntivity: a systematic review of drivers and outcomes of ﬁtness tracking,” Behaviour & In-\nformation Technology, vol. 41, no. 2, pp. 242–261, 2020. doi: https://doi.org/10.1080/\n0144929X.2020.1801840.\n[11] B. Soulé, G. Marchant, and R. Verchère, “Sport and ﬁtness app uses: a review of humanities\nand social science perspectives,” European Journal for Sport and Society, vol. 19, no. 2, pp.\n170–189, 2021. doi: https://doi.org/10.1080/16138171.2021.1918896.\n[12] A. Schneider and R. Arnold, “Wearables from head to toe: Are they friend or foe? An empiri-\ncal landscaping of health and ﬁtness wearables and apps in six countries to identify emerg-\ning policy challenges,” Jul. 31, 2022. [Online]. Available: https://ssrn.com/abstract=\n4177215 or http://dx.doi.org/10.2139/ssrn.4177215.\n[13] “RepCount,” [Online]. Available: https://www.repcountapp.com/. Accessed: 2024.\n[14] “Strong Workout Tracker Gym Log,” [Online]. Available: https://www.strong.app/. Ac-\ncessed: 2024.\n[15] H. Xie, A. Watatani, and K. Miyata, “CoreUI: Interactive Core Training System with 3D Hu-\nman Shape,” arXiv preprint arXiv:2106.09196, 2021. [Online]. Available: https://arxiv.\norg/abs/2106.09196.\n[16] M. Pasula and P. Saha, “Video-based exercise classiﬁcation and muscle group activa-\ntion prediction using hybrid X3D-SlowFast network,” arXiv preprint arXiv:2406.06703, Jun.\n2024. [Online]. Available: https://arxiv.org/abs/2406.06703.\n[17] I. U. Khan, S. Afzal, and J. W. Lee, “Human activity recognition via hybrid deep learning\nbased model,” Sensors, vol. 22, no. 1, Art. no. 1, Jan. 2022. doi: https://doi.org/10.3390/\ns22010323.\n[18] S. K. Chaurasia and S. R. N. Reddy, “State-of-the-art survey on activity recognition and clas-\nsiﬁcation using smartphones and wearable sensors,” Multimedia Tools and Applications,\nvol. 81, pp. 1077–1108, 2022. doi: https://doi.org/10.1007/s11042-021-11410-0.\n[19] S. Chung, J. Lim, K. J. Noh, G. Kim, and H. Jeong, “Sensor data acquisition and multimodal\nsensor fusion for human activity recognition using deep learning,” Sensors, vol. 19, no. 7,\nArt. no. 7, Jan. 2019. doi: https://doi.org/10.3390/s19071716.\n84\n[20] D. Morris, T. S. Saponas, A. Guillory, and I. Kelner, “RecoFit: using a wearable sensor to\nﬁnd, recognize, and count repetitive exercises,” in Proceedings of the SIGCHI Conference\non Human Factors in Computing Systems (CHI ’14), New York, NY, USA: Association for\nComputing Machinery, 2014, pp. 3225–3234. doi: https://doi.org/10.1145/2556288.\n2557116.\n[21] C. Shen, B. -J. Ho, and M. Srivastava, “MiLift: Efﬁcient smartwatch-based workout tracking\nusing automatic segmentation,” IEEE Transactions on Mobile Computing, vol. 17, no. 7, pp.\n1609–1622, Jul. 2018. doi: https://doi.org/10.1109/TMC.2017.2775641.\n[22] A. Soro, G. Brunner, S. Tanner, and R. Wattenhofer, “Recognition and repetition count-\ning for complex physical exercises with deep learning,” Sensors, vol. 19, p. 714, 2019. doi:\nhttps://doi.org/10.3390/s19030714.\n[23] K. Skawinski, F. Montraveta Roca, R. D. Findling, and S. Sigg, “Workout type recognition\nand repetition counting with CNNs from 3D acceleration sensed on the chest,” in Advances\nin Computational Intelligence. IWANN 2019, I. Rojas, G. Joya, and A. Catala, Eds. Cham:\nSpringer, 2019, vol. 11506, Lecture Notes in Computer Science. doi: https://doi.org/10.\n1007/978-3-030-20521-8_29.\n[24] S. Ishii, A. Yokokubo, M. Luimula, and G. Lopez, “ExerSense: Physical exercise recognition\nand counting algorithm from wearables robust to positioning,” Sensors, vol. 21, p. 91, 2021.\ndoi: https://doi.org/10.3390/s21010091.\n[25] A. Dehghani, O. Sarbishei, T. Glatard, and E. Shihab, “A quantitative comparison of overlap-\nping and non-overlapping sliding windows for human activity recognition using inertial\nsensors,” Sensors, vol. 19, p. 5026, 2019. doi: https://doi.org/10.3390/s19225026.\n[26] V. A. Cornelissen, R. H. Fagard, E. Coeckelberghs, and L. Vanhees, “Impact of resistance\ntraining on blood pressure and other cardiovascular risk factors,” Hypertension, vol. 58,\nno. 5, pp. 950–958, Nov. 2011. doi: https://doi.org/10.1161/HYPERTENSIONAHA.111.\n177071.\n[27] J. Kristensen and A. Franklyn-Miller, “Resistance training in musculoskeletal rehabilitation:\na systematic review,” British Journal of Sports Medicine, vol. 46, no. 10, pp. 719–726, Aug.\n2012. doi: https://doi.org/10.1136/bjsm.2010.079376.\n[28] A. H. E. Akpa, M. Fujiwara, H. Suwa, Y. Arakawa, and K. Yasumoto, “A smart glove to track\nﬁtness exercises by reading hand palm,” Journal of Sensors, vol. 2019, no. 1, p. 9320145,\n2019. doi: https://doi.org/10.1155/2019/9320145.\n85\n[29] W.-Y. Chung, A. Purwar, and A. Sharma, “Frequency domain approach for activity classi-\nﬁcation using accelerometer,” in 2008 30th Annual International Conference of the IEEE\nEngineering in Medicine and Biology Society, Aug. 2008, pp. 1120–1123. doi: https://doi.\norg/10.1109/IEMBS.2008.4649357.\n[30] D. Jayakumar, M. Krishnaiah, S. Kollem, S. Peddakrishna, N. Chandrasekhar, and M. Thiru-\npathi, “Emergency vehicle classiﬁcation using combined temporal and spectral audio fea-\ntures with machine learning algorithms,” Electronics, vol. 13, no. 19, Art. no. 19, Jan. 2024.\ndoi: https://doi.org/10.3390/electronics13193873.\n[31] K. Bhangale and M. Kothandaraman, “Speech emotion recognition based on multiple\nacoustic features and deep convolutional neural network,” Electronics, vol. 12, no. 4, Art.\nno. 4, Jan. 2023. doi: https://doi.org/10.3390/electronics12040839.\n[32] W.-Y. Chung, A. Purwar, and A. Sharma, “Frequency domain approach for activity classi-\nﬁcation using accelerometer,” in 2008 30th Annual International Conference of the IEEE\nEngineering in Medicine and Biology Society, Aug. 2008, pp. 1120–1123. doi: https://doi.\norg/10.1109/IEMBS.2008.4649357.\n[33] O. D. Lara and M. A. Labrador, “A Survey on Human Activity Recognition using Wearable\nSensors,” IEEE Communications Surveys & Tutorials, vol. 15, no. 3, pp. 1192–1209, 2013.\ndoi: https://doi.org/10.1109/SURV.2012.110112.00192.\n[34] M. Wang et al., “A comprehensive evaluation of dual-polarimetric Sentinel-1 SAR data for\nmonitoring key phenological stages of winter wheat,” Remote Sensing, vol. 16, no. 10, Art.\nno. 10, Jan. 2024. doi: https://doi.org/10.3390/rs16101659.\n[35] E. C. Ketola, M. Barankovich, S. Schuckers, A. Ray-Dowling, D. Hou, and M. H. Imtiaz,\n“Channel reduction for an EEG-based authentication system while performing motor\nmovements,” Sensors, vol. 22, no. 23, Art. no. 23, Jan. 2022. doi: https://doi.org/10.\n3390/s22239156.\n[36] W.-Y. Chung, A. Purwar, and A. Sharma, “Frequency domain approach for activity classi-\nﬁcation using accelerometer,” in 2008 30th Annual International Conference of the IEEE\nEngineering in Medicine and Biology Society, Aug. 2008, pp. 1120–1123. doi: https://doi.\norg/10.1109/IEMBS.2008.4649357.\n[37] Y. Meng, N. Yang, Z. Qian, and G. Zhang, “What makes an online review more help-\nful: An interpretation framework using XGBoost and SHAP values,” Journal of Theoret-\nical and Applied Electronic Commerce Research, vol. 16, no. 3, Art. no. 3, Jun. 2021. doi:\nhttps://doi.org/10.3390/jtaer16030029.\n86\n[38] S. Knapiˇc, A. Malhi, R. Saluja, and K. Främling, “Explainable artiﬁcial intelligence for hu-\nman decision support system in the medical domain,” Machine Learning and Knowl-\nedge Extraction, vol. 3, no. 3, Art. no. 3, Sep. 2021. doi: https://doi.org/10.3390/\nmake3030037.\n[39] M. A. Khan et al., “Smart Android Based Home Automation System Using Internet of Things\n(IoT),” Sustainability, vol. 14, no. 17, Art. no. 17, Jan. 2022. doi: https://doi.org/10.\n3390/su141710717.\n[40] R. Luque, E. Casilari, M.-J. Morón, and G. Redondo, “Comparison and characterization of\nAndroid-based fall detection systems,” Sensors, vol. 14, no. 10, Art. no. 10, Oct. 2014. doi:\nhttps://doi.org/10.3390/s141018543.\n[41] A. R. Anwary, H. Yu, and M. Vassallo, “An automatic gait feature extraction method for iden-\ntifying gait asymmetry using wearable sensors,” Sensors, vol. 18, no. 2, Art. no. 2, Feb. 2018.\ndoi: https://doi.org/10.3390/s18020676.\n[42] R.-A. Voicu, C. Dobre, L. Bajenaru, and R.-I. Ciobanu, “Human physical activity recognition\nusing smartphone sensors,” Sensors, vol. 19, no. 3, Art. no. 3, Jan. 2019. doi: https://doi.\norg/10.3390/s19030458.\n[43] T. R. Mauldin, M. E. Canby, V. Metsis, A. H. H. Ngu, and C. C. Rivera, “SmartFall: A\nsmartwatch-based fall detection system using deep learning,” Sensors, vol. 18, no. 10, Art.\nno. 10, Oct. 2018. doi: https://doi.org/10.3390/s18103363.\n[44] S. Chung, J. Lim, K. J. Noh, G. Kim, and H. Jeong, “Sensor data acquisition and multimodal\nsensor fusion for human activity recognition using deep learning,” Sensors, vol. 19, no. 7,\nArt. no. 7, Jan. 2019. doi: https://doi.org/10.3390/s19071716.\n[45] R. Szabo, “Implementing computer vision in Android apps and presenting the background\ntechnology with mathematical demonstrations,” Technologies, vol. 13, no. 1, Art. no. 1, Jan.\n2025. doi: https://doi.org/10.3390/technologies13010027.\n[46] A. Sehgal and N. Kehtarnavaz, “Guidelines and benchmarks for deployment of deep learn-\ning models on smartphones as real-time apps,” Machine Learning and Knowledge Extrac-\ntion, vol. 1, no. 1, Art. no. 1, Mar. 2019. doi: https://doi.org/10.3390/make1010027.\n[47] A. Ghaffari and Y. Savaria, “CNN2Gate: An implementation of convolutional neural net-\nworks inference on FPGAs with automated design space exploration,” Electronics, vol. 9,\nno. 12, Art. no. 12, Dec. 2020. doi: https://doi.org/10.3390/electronics9122200.\n87\n[48] Google, “Data Layer API Overview,” Android Developers. Available: https://developer.\nandroid.com/training/wearables/data/overview. [Accessed: 08-Jan-2025].\n[49] ONNX Runtime Developers, ONNX Runtime, 2021. [Online]. Available:\nhttps://\nonnxruntime.ai/. [Accessed: Jan. 29, 2025].\n88\n質疑応答\n戸辺　義人　情報テクノロジー学科　教授\nQ\nリアルタイムというのがあいまいですが，本研究におけるリアルタイムとは？\nA\nご質問ありがとうございます．本研究における「リアルタイム」とは、スマートウォッ\nチで収集した加速度データをスマートフォンに送信し、TLSW（三層スライディング\nウィンドウ）アルゴリズムを用いて即時に処理し、運動状態の識別、運動種別の分\n類、および回数のカウントを行うことを指します。\n浦垣　啓志郎　情報テクノロジー学科　助手\nQ\nPython とAndroid の誤差は利用しているライブラリなどの影響を確認しましたか？\nA\nご質問ありがとうございます．本研究ではPython 環境とAndroid 環境の違いによ\nる誤差を確認し、特にフーリエ変換や特徴量計算の精度統一のためにChaquopy を\n導入し、Python スクリプトを直接実行することで誤差を最小限に抑えました。\n89\n",
        "chunks": [
            "M2024_LiuZeyu. M2024_LiuZeyu. M2024_LiuZeyu",
            " \n \n \n \n \n \n \n \n \n青 \n山 \n学 \n院 \n大 \n学 \n \n理 \n工 \n学 \n研 \n究 \n科 \n \n \n \n \n理工学専攻 \n \n \n \n \n \n修 \n士 \n論 \n文 \n \n \n \n学 生 番 号 \n \n35623252\n \n \n \nLIU ZEYU \n \n \n \n研究指導教員 \nGuillaume \nLOPEZ \n \n知能情報\nコース \n氏 \n名 \nSmartWT: Fitness activity monitoring using\nwearable devices\nLiu Zeyu\nJanuary 2025\n理工学専攻修士論文要旨 \n \n \n提出年度 \n： 2024 年度 \n提出日  \n： 2025 年1 月31 日 \n専修コース \n： 知能情報 コース \n学生番号 \n： 35623252 \n学生指名 \n： LIU ZEYU \n研究指導教員 ： ロペズ・ギヨーム 教授 \n \n（論文題目） \nSmartWT: Fitness activity monitoring using wearable devices \n \n（内容の要旨） \n近年，ウェアラブルデバイスは急速に",
            "ing wearable devices \n \n（内容の要旨） \n近年，ウェアラブルデバイスは急速に進化し，心拍数測定，歩数計測，睡眠分析など多様な健康管\n理機能を提供するようになった．特にスマートウォッチは，加速度センサーやジャイロスコープを搭\n載し，運動データのリアルタイム収集が可能となっている．しかし，現在のフィットネス活動追跡ア\nプリケーションソフトウェア（以降アプリ）は，有酸素運動の記録には優れているものの，ウェイト\nトレーニングなどの無酸素運動においては，ユーザーが回数や負荷を手動で入力する必要があり，ト\nレーニングの集中力を妨げる要因となっている． \nこれを解決するため，本研究では，スマートウォッチとスマートフォンを活用したリアルタイムフ\nィットネスモニタリングシステム「SmartWT」を開発し，既存のフィットネスアプリが無酸素運動の\n自動記録に対応できていない課題を解決することを目的としている． \n本研究では，スマートウォッチで加速度データを収集し，スマートフォンに転送したのち，スマー\nトフォン上でリアルタイム処理を行うTLSW（三層スライディングウィンドウ）アルゴリズ",
            "たのち，スマー\nトフォン上でリアルタイム処理を行うTLSW（三層スライディングウィンドウ）アルゴリズムを考案\nし，運動状態の自動識別，運動種別の分類，および回数の自動カウントを実現することで，手動入力\nの必要性を排除する．TLSW アルゴリズムは，状態認識，ピーク検出，運動分類の3 つの主要ステッ\nプで構成される．まず，状態分類モデルを用いてユーザーが運動状態にあるかを判定し，運動中であ\nると判断された場合，合成加速度を計算してピークを検出する．ピークがウィンドウの中心に位置す\nる場合，それを1 回の運動としてカウントし，機械学習モデルで運動種別を分類する．精度向上のた\nめ，最大値，最小値，スペクトルセントロイド，スペクトルフラットネス，ゼロ交差率などの時間領\n域・周波数領域の特徴量を抽出し，ランダムフォレストを用いた分類モデルを訓練した． \nパソコンを用いたオフライン環境において，分類精度96.7%，カウント精度96.6%を達成したが，高\n性能なプログラミング環境と処理能力のないモバイル端末において，データ転送や計算環境の違いに\nより，それぞれ95%，88%に若干低下した．さらに，9",
            "ル端末において，データ転送や計算環境の違いに\nより，それぞれ95%，88%に若干低下した．さらに，9 名の被験者を対象とした実証実験では，8 種類\nの運動において分類精度86.1%，カウント精度81.4%を記録した．特定の動作において精度が低下した\n主な原因は，個人の運動幅の違いや疲労による動作速度の低下である．モバイル端末の開発では，シ\nステムのリアルタイム性と安定性を確保するために，Data Layer API を使用してスマートウォッチと\nスマートフォン間のデータ転送を実装し，スライディングウィンドウのデータ管理を最適化するため\nにリングバッファを採用し，データコピーによる負荷を軽減した．また，パソコンを用いたオフライ\nン環境と特性計算の精度を統一するため，モバイル端末にChaquopy を統合し，フーリエ変換や周波\n数領域の特徴抽出をオフライン処理環境と同じスクリプトで実行できるようにした． \n実験結果から，本システムは高精度な運動種別識別および回数カウントを実現し，フィットネスデ\nータの記録を効率化できることが確認された．加えて，Android 端末の最適化により，データ処理",
            "デ\nータの記録を効率化できることが確認された．加えて，Android 端末の最適化により，データ処理の効\n率と計算の安定性が確保された． \n \n \n青山学院大学大学院理工学研究科 \n1\nThe Academic Year of 2024, Submitted on January 31st, 2025 \n \nGraduate School of Science and Engineering, Aoyama Gakuin University \n \nTitle: SmartWT: Fitness activity monitoring using wearable devices \nStudent Name: LIU ZEYU  \nID Number: 35623252 \nDegree: Master of Engineering \nCourse: Intelligence and Information \nThesis Advisor: Professor Guillaume Lopez \n \nAbstract  \n In recent years, wearable devices",
            "z \n \nAbstract  \n In recent years, wearable devices have rapidly evolved, offering various health management \nfunctions such as heart rate monitoring, step counting, and sleep analysis. Smartwatches, in \nparticular, are equipped with accelerometers and gyroscopes, enabling real-time movement data \ncollection. However, while current fitness tracking applications effectively record aerobic \nexercises, they still require users to manually input repetitions and weights for anaerobic \nexercises like w",
            "itions and weights for anaerobic \nexercises like weight training, which disrupts workout focus. \nThis study developed SmartWT, a real-time fitness monitoring system utilizing smartwatches \nand smartphones, to address the limitations of existing fitness applications in automatically \ntracking anaerobic exercises. It proposes the Three-Layer Sliding Window (TLSW) algorithm, \nwhich collects acceleration data via a smartwatch and processes it in real-time on a smartphone \nto automatically recognize ",
            "-time on a smartphone \nto automatically recognize exercise states, classify exercise types, and count repetitions, \neliminating the need for manual input. The algorithm consists of three key steps: state \nrecognition, peak detection, and exercise classification & counting. First, the system uses a state \nclassification model to determine whether the user is actively exercising. Once an exercise state \nis detected, composite acceleration is calculated, and peaks are identified. If a peak is locat",
            "ated, and peaks are identified. If a peak is located at \nthe center of the window, it is counted as a valid repetition, and a machine learning model \nclassifies the exercise type. To improve accuracy, this study extracted various time-domain and \nfrequency-domain features, including maximum and minimum values, spectral centroid, \nspectral flatness, and zero-crossing rate, and trained a classification model using a Random \nForest algorithm. \nIn offline experiments conducted in a PC environment us",
            "fline experiments conducted in a PC environment using Python programming language, \nthe algorithm achieved 96.7% classification accuracy and 96.6% counting accuracy. However, in \noffline tests on Android devices, accuracy slightly decreased to 95% and 88%, respectively, due \nto differences in data transmission and computational environments. Furthermore, a user study \nwith nine participants performing eight different exercises recorded a classification accuracy of \n86.1% and a counting accuracy ",
            "cation accuracy of \n86.1% and a counting accuracy of 81.4%. Lower accuracy in some exercises was mainly \nattributed to variations in individual movement ranges and reduced motion speed caused by \nfatigue. \nFor the mobile device implementation, the system's real-time performance and stability were \nensured by utilizing the Data Layer API to transmit data between the smartwatch and \nsmartphone. A ring buffer was employed to optimize sliding window data management, \nreducing computational overhead ",
            "data management, \nreducing computational overhead caused by continuous data copying. Additionally, to maintain \nconsistency with the Python environment in feature calculations, Chaquopy library was \nintegrated into the mobile device system, allowing Fourier Transform and frequency-domain \nfeature extraction to be executed using Python scripts directly on the mobile device. \nThe experimental results confirm that SmartWT can accurately recognize exercise types and \ncount repetitions, significantly",
            "ercise types and \ncount repetitions, significantly improving the efficiency and accuracy of fitness data recording. \nFurthermore, optimizations in the mobile device implementation ensure efficient data \nprocessing and computational stability, making the system a promising solution for automated \nfitness tracking. \n2\nContents\n1\nIntroduction\n5\n1.1\nBackground . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n5\n1.2\nResearch problem . . . . . . . . . . . . . . . . . ",
            "esearch problem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n7\n1.2.1\nQuestionnaire for ﬁtness enthusiasts on automated monitoring of ﬁtness\ndata . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n8\n1.3\nOutline of the thesis\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n16\n2\nRelated work\n17\n2.1\nImpact of Mobile Fitness Applications . . . . . . . . . . . . . . . . . . . . . . . . . . .\n17\n2.2\nMotion Rec",
            " . . . . . . . . . . . . . . . .\n17\n2.2\nMotion Recognition Methods . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n20\n2.3\nContribution of this research . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n23\n3\nIntroduction to Research Methods\n24\n3.1\nProposal of Research Methods\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n24\n3.2\nOverview of TLSW: A method for monitoring ﬁtness exercise in real time . . . . . .\n26\n3.3\nMethod for separating and extractin",
            ". . . .\n26\n3.3\nMethod for separating and extracting the ﬁtness state\n. . . . . . . . . . . . . . . . .\n27\n3.4\nMethod of counting and recognizing ﬁtness movements . . . . . . . . . . . . . . . .\n30\n3.5\nState Recognition Model and Fitness Movement Recognition Model using Machine\nLearning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n36\n3.5.1\nData collection\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n36\n3.5.2\nData preprocessing ",
            ". . . . . . . . . . .\n36\n3.5.2\nData preprocessing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n38\n3.5.3\nData set segmentation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n39\n3.5.4\nFeature Selection . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n39\n3.5.5\nState Classiﬁcation Model Training and Feature Reduction\n. . . . . . . . . .\n48\n3.5.6\nType Classiﬁcation Model Training and Feature Reduction\n. . . . . . . . . .\n51\n4\nAlgorithm ofﬂi",
            " Reduction\n. . . . . . . . . .\n51\n4\nAlgorithm ofﬂine experiments and results\n54\n4.1\nExperimental data collection . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n54\n4.2\nDLSW Algorithm Experiment . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n55\n4.3\nTLSW Algorithm Experiment . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n56\n5\nSmartWT : An Android ﬁtness monitoring app that uses TLSW methods\n59\n5.1\nRelated work . . . . . . . . . . . . . . . . . . . ",
            "elated work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n59\n5.2\nOverview of System Architecture . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n60\n5.3\nAndroid application for smartphone . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n61\n5.3.1\nData transmission\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n63\n5.3.2\nData structure of the sliding window\n. . . . . . . . . . . . . . . . . . . . . . .\n65\n3\n5.3.3\nFeature V",
            ". . . . . . . . . . . . . . .\n65\n3\n5.3.3\nFeature Value Calculation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n65\n5.3.4\nInterface of Smartphone Application\n. . . . . . . . . . . . . . . . . . . . . . .\n66\n5.4\nAndroid application for smartwatch . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n66\n5.4.1\nInterface of Smartphone Application\n. . . . . . . . . . . . . . . . . . . . . . .\n69\n6\nExperiments and Results\n71\n6.1\nAndroid device ofﬂine experiments and results\n. . . . . .",
            " device ofﬂine experiments and results\n. . . . . . . . . . . . . . . . . . . . .\n71\n6.1.1\nDescription of the experiment . . . . . . . . . . . . . . . . . . . . . . . . . . .\n71\n6.1.2\nResurts . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n71\n6.2\nAndroid devices actual experiments and results . . . . . . . . . . . . . . . . . . . . .\n72\n6.2.1\nDescription of the experiment . . . . . . . . . . . . . . . . . . . . . . . . . . .\n72\n6.2.2\nResurts . . . . . . . . . . .",
            ". . . . . .\n72\n6.2.2\nResurts . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n74\n6.3\nSummary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n78\n7\nFuture work\n80\nAcknowledgments\n82\nReferences\n83\n4\nChapter 1\nIntroduction\n1.1\nBackground\nIn recent years, wearable devices have gained widespread popularity due to their powerful\nfunctionalities in monitoring health and ﬁtness activities. These devices not only help individ-\nuals t",
            "ities. These devices not only help individ-\nuals track their physical condition in real time but also provide personalized recommendations\nfor ﬁtness enthusiasts, promoting more scientiﬁc and efﬁcient workout methods. A 2023 survey\nrevealed that wearable devices consistently attract signiﬁcant attention among ﬁtness enthu-\nsiasts, especially smartwatches equipped with sensors such as accelerometers and gyroscopes,\nwhich have become essential tools for tracking physical activity.\nScientiﬁc resear",
            "s for tracking physical activity.\nScientiﬁc research has demonstrated that regular exercise has signiﬁcant positive effects on\nphysical health. Exercise not only strengthens muscles and improves cardiovascular function\nbut also effectively reduces the risk of chronic diseases such as cardiovascular diseases, dia-\nbetes, and obesity. Additionally, ﬁtness activities can enhance mood, relieve stress, and improve\noverall quality of life. However, unstructured or unscientiﬁc exercise may lead to subo",
            "tructured or unscientiﬁc exercise may lead to suboptimal\noutcomes or even increase the risk of injury. Therefore, planned ﬁtness routines are particularly\nimportant. A well-structured ﬁtness plan helps individuals select appropriate exercise intensity\nand volume based on their physical condition and goals, thereby improving workout efﬁciency\nand minimizing the likelihood of injuries.\nWith the rapid advancement of technology, wearable devices continue to improve in both\nhardware and software func",
            "inue to improve in both\nhardware and software functionalities. Early wearable devices had relatively simple features,\nsuch as step counting and heart rate measurement. In contrast, today ’s smartwatches and\nﬁtness bands offer much more comprehensive monitoring capabilities, including sleep quality\n5\nWearable devices receive attention [1].\ntracking, real-time three-axis acceleration data recording, blood oxygen monitoring, and per-\nsonalized ﬁtness plan recommendations.\nThese devices not only rai",
            "s plan recommendations.\nThese devices not only raise users’awareness of their health but also generate detailed health\nreports based on collected data, helping users adjust their ﬁtness strategies more scientiﬁcally.\nFor example, real-time heart rate monitoring enables users to control exercise intensity to re-\nmain in the optimal range for fat burning or cardiovascular improvement. Additionally, motion\nrecognition features help users correct improper movements and prevent injuries. For ﬁtness\ne",
            "roper movements and prevent injuries. For ﬁtness\nenthusiasts, these functions signiﬁcantly enhance the safety and scientiﬁc accuracy of their\nworkouts. At the same time, ﬁtness tracking applications are ﬂourishing, serving as essential\ncompanions to wearable devices. These applications seamlessly connect with smart devices,\nallowing users to synchronize workout data in real time and providing detailed ﬁtness analyses\nand plan customization. Many ﬁtness apps now include social elements, such as o",
            "ﬁtness apps now include social elements, such as online rank-\nings, challenges, and badge rewards. These features not only enable users to track their ﬁtness\nprogress and long-term achievements but also increase engagement and motivation through\nsocial interactions and competitive incentives. In the future, with the further development of\nartiﬁcial intelligence and big data technologies, ﬁtness tracking apps will be able to identify\nusers’ workout states more accurately, provide highly personali",
            "t states more accurately, provide highly personalized ﬁtness advice, and predict\npotential health risks, further advancing data-driven ﬁtness applications.\nIn summary, the rapid development of wearable devices and the growing prevalence of ﬁt-\n6\nFigure 1.2: Monitoring heart rate with a smartwatch\nness tracking apps are profoundly transforming people’s approach to ﬁtness, offering new pos-\nsibilities for healthier lifestyles. These tools not only help ﬁtness enthusiasts achieve their goals\nmore e",
            "help ﬁtness enthusiasts achieve their goals\nmore efﬁciently but also promote health management and the establishment of ﬁtness habits\nthrough technological innovations. In the future, as technology continues to evolve, this ﬁeld\nwill further develop, bringing greater convenience and health beneﬁts to a broader audience.\n1.2\nResearch problem\nCurrently, many ﬁtness tracking apps are highly effective in monitoring aerobic exercises. For\nexample, Apple Fitness and Google Fit provide comprehensive tr",
            "le Fitness and Google Fit provide comprehensive tracking for long-duration aero-\nbic activities like running and cycling. However, their support for anaerobic exercises remains\ninadequate. To address this issue, ﬁtness apps such as RepCount and Strong Workout Tracker\nGym Log, which focus on anaerobic exercises, have gained popularity. These apps assist users\nin creating detailed training plans and tracking long-term ﬁtness achievements. However, users\nare still required to manually input data su",
            "users\nare still required to manually input data such as repetitions and weights after completing each\nset of exercises. This frequent input not only disrupts user focus but also diminishes the overall\nworkout experience. If user actions could be recognized in real time and recorded automatically,\nit would signiﬁcantly enhance workout efﬁciency and user experience.\nCurrent research on human action recognition can be broadly divided into two approaches:\nimage-based recognition and sensor-based rec",
            "ches:\nimage-based recognition and sensor-based recognition. Image recognition uses cameras to\ncapture images of users during exercise and applies deep learning techniques to identify move-\nments, enabling precise capture of complex motion details. However, this approach requires\n7\nhigh device performance and network reliability and may raise privacy concerns. Sensor-based\nresearch, on the other hand, leverages built-in sensors like accelerometers and gyroscopes to\ncollect user movement data and ",
            " and gyroscopes to\ncollect user movement data and applies methods such as template matching or machine learn-\ning to recognize actions. This approach offers better real-time performance and portability.\nNonetheless, it faces challenges such as the potential inconvenience caused by wearing multi-\nple sensors or the reliance on stable network connections for data transmission.\nAlthough wearable devices have made signiﬁcant progress in the ﬁeld of human action recog-\nnition, existing research still",
            "uman action recog-\nnition, existing research still has limitations. On the one hand, many developed algorithms\nremain conﬁned to theoretical models or simulated environments and lack deployment and\ntesting on actual devices, leaving their performance in real-world scenarios insufﬁciently val-\nidated. On the other hand, many models used in research are computationally intensive and\nrequire high hardware performance, making it impossible for them to operate independently\non wearable devices. Inste",
            "o operate independently\non wearable devices. Instead, they rely on server-based computation. Furthermore, this depen-\ndence on server computation necessitates a stable network connection between the device and\nserver. When the network is unstable or ofﬂine, system performance and user experience are\nsigniﬁcantly impacted.\nIn this study, we developed an algorithm capable of long-term tracking of user ﬁtness activ-\nities, automatically recognizing and counting exercise actions. The algorithm repla",
            "and counting exercise actions. The algorithm replaces manual\noperations at the start and end of each action with automatic segmentation and improves upon\nthe traditional ﬁxed-step sliding window algorithm, reducing computational overhead while en-\nhancing recognition accuracy. Testing results show that the algorithm achieves an accuracy of\n94.31% in long-term tracking of ﬁtness data, correctly identifying exercise types and counting\nsets.\n1.2.1\nQuestionnaire for ﬁtness enthusiasts on automated m",
            "uestionnaire for ﬁtness enthusiasts on automated monitoring of ﬁtness data\nTo understand the use of wearable devices by ﬁtness enthusiasts and their perspectives on\nﬁtness tracking software, we designed a questionnaire survey. The following are the results of\nthe survey.\nRespondents Fitness Situation Statistics\nWe conducted an anonymous questionnaire survey with 71 participants. The distribution of\ntheir years of ﬁtness experience and regular workout frequency is shown in the chart Figure 1.3\nbe",
            "kout frequency is shown in the chart Figure 1.3\nbelow.\n8\nFigure 1.3: Participants’ number of years and frequency of ﬁtness\nThe Current State of Planned Fitness\nWe analyzed respondents’ views on ﬁtness plans, their habits of creating ﬁtness plans, and\nthe implementation of these plans. The results are presented in Figure 1.4.\nFigure 1.4: Participants’ number of years and frequency of ﬁtness\nMost respondents believe that ﬁtness plans can enhance workout effectiveness. Among them,\n52% stated that p",
            "rkout effectiveness. Among them,\n52% stated that plans \"somewhat improve effectiveness,\" 37% believed that plans \"greatly en-\nhance effectiveness,\" and only 11% indicated that plans have no effect. Of the respondents, 48%\nreported having the habit of creating ﬁtness plans, while 52% stated they did not have such a\nhabit. Based on whether respondents have the habit of creating ﬁtness plans, we designed cor-\nresponding questions and analyzed the responses. Below are the most representative results",
            "sponses. Below are the most representative results\n9\nfrom the analysis.\nFitness enthusiasts with a habit of creating plans\nFigure 1.5: Views on ﬁtness plans from people who have plans to work out\nFrom the Figure 1.5 above, it can be observed that most respondents who create ﬁtness plans\ntend to design their plans independently, while the proportion using ﬁtness apps or software\nis relatively low. When recording ﬁtness plans, they prefer simpler methods or even rely on\nmemory. Additionally, more ",
            "ethods or even rely on\nmemory. Additionally, more than half of the respondents have tried using ﬁtness apps or tools\nto assist in creating their plans.\n10\nFitness enthusiasts without a habit of creating plans\nFigure 1.6: Views on ﬁtness plans from people who have no plan to work out\nFor users who do not create ﬁtness plans, as shown in Figure 1.6, the main reasons include\nunpredictable schedules, a preference for unrestricted workouts, and unfamiliarity with plan\ncreation. Opinions on the impact",
            "liarity with plan\ncreation. Opinions on the impact of not having a plan on workout effectiveness are divided.\nSome users believe the impact is minimal and prefer the freedom of unstructured exercise. Oth-\ners, while aware of the potential drawbacks, have not taken action due to uncertainty about how\nto start or a lack of willingness to change.\n11\nRespondent perceptions of tracking apps\nFigure 1.7: The willingness of different ﬁtness enthusiasts to use ﬁtness tracking apps\nBefore analyzing ﬁtness",
            "o use ﬁtness tracking apps\nBefore analyzing ﬁtness enthusiasts’ opinions on ﬁtness tracking apps, we ﬁrst examined\ntheir willingness to use such applications. As shown in Figure 1.7, 76.1% of respondents ex-\npressed a willingness to use ﬁtness tracking apps. Among them, individuals with planned work-\nout routines demonstrated a signiﬁcantly higher inclination toward using these applications.\nFigure 1.8: Views of ﬁtness enthusiasts on recording data\nFigure 1.8 shows that most respondents preferre",
            "ta\nFigure 1.8 shows that most respondents preferred automatic recording of ﬁtness data, while\nonly a small number chose manual recording or a combination of automatic and manual ad-\njustments for data recording.\n12\nFigure 1.9: Views of ﬁtness enthusiasts on automatically recording ﬁtness data\nAs shown in Figure 1.9, respondents value accuracy and convenience the most when record-\ning ﬁtness data. The primary advantages of automatic recording applications include reducing\nmanual input, improving ",
            "ications include reducing\nmanual input, improving management efﬁciency, and helping users focus more on their work-\nouts. However, these applications also face challenges such as recognition inaccuracies, high\ndependency on devices, limited ﬂexibility, and concerns about data privacy.\n13\nFigure 1.10: Views of ﬁtness enthusiasts on automatically recording ﬁtness data\nAs shown in the results of Figure 1.10, ﬁtness apps that rely on manual data recording of-\nfer certain advantages, such as ﬂexibili",
            "rding of-\nfer certain advantages, such as ﬂexibility in data adjustments, more accurate detail recording,\nand the ability to make adjustments based on real-time progress. However, users also face nu-\nmerous challenges, including the tedious and forgettable nature of the recording process, its\ntime-consuming and user-unfriendly aspects, frequent operations that disrupt focus, and the\ncomplexity of data organization and analysis. This indicates that while manual recording excels\nin precise control",
            "t while manual recording excels\nin precise control, the user experience requires further optimization.\n14\nExpectations for automated ﬁtness tracking app\nFigure 1.11: Expectations of ﬁtness enthusiasts for automated ﬁtness tracking app\n15\nFigure 1.11 illustrates that users ’demands for automated ﬁtness data recording systems fo-\ncus on accurately recognizing ﬁtness actions, real-time tracking of plan completion, and mon-\nitoring health metrics such as heart rate. Additionally, they consider the a",
            "h as heart rate. Additionally, they consider the accuracy of automatic\nrecognition and system usability as the most critical aspects. Users also expressed a desire for\nfeatures such as automatically generated ﬁtness reports, synchronized plan adjustments, and\npersonalized ﬁtness recommendations. This indicates a preference for systems that are precise,\nefﬁcient, and capable of providing in-depth analysis.\nSummary of questionnaire results\nThe survey results indicate that most respondents believe ",
            "ey results indicate that most respondents believe ﬁtness plans can enhance workout\neffectiveness and show a strong willingness to use automatic ﬁtness tracking applications. Com-\npared to manual recording, automatic tracking is favored for its efﬁciency and convenience.\nUsers hope to reduce manual input through automatic tracking while achieving precise action\nrecognition, real-time plan tracking, and comprehensive monitoring of health metrics. This\nhighlights a clear demand for ﬁtness tracking ",
            "his\nhighlights a clear demand for ﬁtness tracking applications with intelligent and automated fea-\ntures.\n1.3\nOutline of the thesis\nThis thesis is divided into seven chapters, covering the research background, related work,\nmethodology, experimental validation, system implementation, experimental results analysis,\nand future prospects. Chapter 1 introduces the research background, highlighting the limita-\ntions of existing ﬁtness tracking applications in recording anaerobic exercises and present",
            "tions in recording anaerobic exercises and presenting\nthe objectives of this study. Chapter 2 reviews mobile ﬁtness applications and motion recog-\nnition methods, analyzing their advantages and limitations. Chapter 3 details the Triple-Layer\nSliding Window (TLSW) algorithm, including exercise state recognition, movement classiﬁca-\ntion, counting, and machine learning-based feature extraction. Chapter 4 presents ofﬂine ex-\nperiments conducted in a Python environment to evaluate the algorithm’s pe",
            " Python environment to evaluate the algorithm’s performance. Chap-\nter 5 describes the implementation of the Android application, focusing on data interaction be-\ntween the smartwatch and smartphone, data transmission, and feature computation. Chapter\n6 evaluates the system through ofﬂine and real-world experiments on Android devices, compar-\ning performance across different environments. Chapter 7 discusses potential improvements,\nincluding enhanced data processing and personalized ﬁtness feedb",
            "nced data processing and personalized ﬁtness feedback.\n16\nChapter 2\nRelated work\n2.1\nImpact of Mobile Fitness Applications\nAccording to a 2023 survey, wearable devices have been a popular topic of discussion among\nﬁtness enthusiasts since 2016 [1]. Mobile health applications integrated into wearable devices\nhave also become increasingly prevalent. These technological advancements not only enhance\nindividuals’ health awareness but also create opportunities for research in automatic activity\nrecog",
            "rtunities for research in automatic activity\nrecognition and data-driven ﬁtness applications. Meanwhile, ﬁtness tracking apps are highly\npopular among ﬁtness enthusiasts. By monitoring ﬁtness data, these apps not only help users\nrecord workout completion and long-term ﬁtness achievements but also boost their motiva-\ntion through features such as badge collection and online competitions [2][3][4].[5]introduces\ngamiﬁed ﬁtness tracking applications that incorporate step count data into gameplay. By",
            "that incorporate step count data into gameplay. By map-\nping existing currency-based taxonomies to step-based games and providing different types of\nexamples, it demonstrates the value of treating steps as currency.\n17\nScreenshot from the Fitness RPG app showing canonical game elements found in traditional\nRPG games. [5].\nThe widespread adoption and advancement of this technology are closely related to the nu-\nmerous health beneﬁts of physical activity. Studies have shown that regular exercise c",
            "tivity. Studies have shown that regular exercise can sig-\nniﬁcantly reduce resting heart rate (RHR), particularly through endurance training and yoga.\nThis not only lowers all-cause mortality but is also correlated with pre-intervention RHR and\nparticipant age [6]. Additionally, physical exercise enhances cognitive function and extends its\npositive effects by maintaining good cardiovascular health [7]. During special periods, such as\nthe COVID-19 pandemic, digital ﬁtness apps provided convenient",
            " pandemic, digital ﬁtness apps provided convenient solutions for home workouts,\nenabling individuals to stay active during lockdowns, although their beneﬁts were primarily ob-\nserved in speciﬁc social groups [8].\n18\nThese ﬁtness applications make it easier for users to track their workout progress, challenge\nthemselves, and compete with others, further motivating them to maintain their exercise habits\n[7][9][10][11]. Studies on physical activity and wearable devices suggest that the reminder fun",
            "and wearable devices suggest that the reminder func-\ntions and continuous notiﬁcation mechanisms provided by these devices effectively encourage\nadults to engage in physical exercise, with particularly signiﬁcant results for sedentary individu-\nals [8]. Additionally, participating in online competitions or sharing ﬁtness achievements within\ncommunities can effectively boost users ’ﬁtness motivation. This interactive approach allows\nusers to experience social support and the joy of competition, i",
            "ience social support and the joy of competition, inspiring them to engage more\nactively in exercise [7].\nHowever, research shows that compared to sharing ﬁtness achievements, more users prefer\nto focus on setting personal goals and tracking their progress. When users achieve their goals\nand receive rewards, they often feel“good about themselves”and“more motivated,”which fur-\nther promotes the sustainability of their workouts [12]. Moreover, ﬁtness tracking applications\nenhance physical activity ",
            "s tracking applications\nenhance physical activity levels through data feedback and goal management, strengthening\nusers’ self-monitoring and ﬁtness motivation [11].\nFigure 2.2: Capabilities in Google Fit\nCurrently, widely used ﬁtness tracking software, such as Apple Fitness and Google Fit, can\ntrack daily walking, running, and cycling data. Apps like RepCount [13] and Strong Workout\nTracker Gym Log [14], designed speciﬁcally for ﬁtness enthusiasts, help users create workout\nplans and record comp",
            "s, help users create workout\nplans and record completion progress. These apps support long-term ﬁtness tracking, enabling\nusers to monitor their progress over time. However, most of these apps require users to manu-\nally record repetitions after completing each set, which not only causes inconvenience but also\ndisrupts workout focus.\n19\n2.2\nMotion Recognition Methods\nIn the rapid development of mobile health applications, the implementation of automatic ﬁt-\nness tracking relies on motion recogni",
            "tomatic ﬁt-\nness tracking relies on motion recognition technology. By converting users’movement patterns\ninto quantiﬁable data, this technology not only helps users track their workout progress in real-\ntime but also automatically identiﬁes exercise types and calculates activity levels. To achieve\nlong-term automatic tracking of various ﬁtness activities, along with counting and recording\nthem, three main objectives must typically be accomplished: (1) segmenting the user’s active\nand inactive st",
            ": (1) segmenting the user’s active\nand inactive states, (2) recognizing the user’s ﬁtness activities, and (3) counting the ﬁtness ac-\ntivities.\nIn research on user state and motion recognition, two primary approaches are visual-based\nand sensor-based methods. In visual-based research, Xie et al. [15] introduced an interactive\ncore training system called CoreUI. This system utilizes monocular camera input and 3D human\nshape estimation technology to provide users with visual feedback for posture c",
            "o provide users with visual feedback for posture correction. How-\never, due to a processing time of approximately 2 seconds per frame, the system has high latency,\nmaking it unsuitable for high-speed activities requiring real-time feedback, such as gymnastics\nor ball sports. M. Pasula et al. [16] proposed a hybrid model combining X3D and SlowFast net-\nworks for exercise classiﬁcation and muscle group activation prediction in videos. The results\ndemonstrated improved accuracy and efﬁciency compar",
            "emonstrated improved accuracy and efﬁciency compared to single models, but limitations re-\nmain in real-world generalization, real-time performance, and small muscle group prediction\naccuracy.\n[17] developed a hybrid model combining a Convolutional Neural Network (CNN) and a\nLong Short-Term Memory (LSTM) network for activity recognition. The CNN extracts spatial\nfeatures, while the LSTM captures temporal information. Additionally, a new dataset contain-\ning 12 types of human activities was creat",
            "ontain-\ning 12 types of human activities was created, collected from 20 participants using a Kinect V2\nsensor. Through an ablation study on various traditional machine learning and deep learning\nmodels, the CNN-LSTM approach achieved an accuracy of 90.89%, demonstrating its strong\nperformance in human activity recognition (HAR) applications.\nOther visual-based studies have also achieved promising recognition results. However, due\nto the need to set up devices like smartphones for real-time video",
            "et up devices like smartphones for real-time video capture, these methods are\nnot suitable for public spaces such as gyms. Sensor-based methods, on the other hand, are more\nsuitable for public settings because they offer higher privacy and do not require additional space\nfor data collection.Chaurasia et al. [18] provided a comprehensive review covering various as-\npects of Activity Recognition and Classiﬁcation (ARC) research using smartphones and wearable\n20\nActivity recognition through differe",
            "d wearable\n20\nActivity recognition through different Machine learning algorithms.[17]\nsensors. The review included data collection, feature extraction, classiﬁcation modeling, and\nkey factors inﬂuencing performance. Additionally, it summarized the strengths and limitations\nof existing methods, offering clear directions for future research.\nChung et al. [19] built a testing platform consisting of eight wearable inertial measurement\nunit (IMU) sensors and an Android mobile device for activity data",
            "ors and an Android mobile device for activity data collection. They also devel-\noped a Long Short-Term Memory (LSTM) framework to train a deep learning model. The results\nshowed that activity data from four sensors located on the wrist, right ankle, and both sides of\nthe waist, sampled at a rate as low as 10 Hz, was sufﬁcient to recognize daily activities (ADL),\nincluding eating and driving.\nTestbed conﬁguration.[19]\n21\nHighly relevant to this study are the works of [20][21] [22][23]and [24], al",
            "udy are the works of [20][21] [22][23]and [24], all of which have\nachieved long-term automatic recognition of various exercises and completed repetition count-\ning. Dan et al. [20] introduced the RecoFit system, which uses inertial sensors in a smartphone\nworn on the arm to automatically track repetitive exercises such as weightlifting and aerobics.\nThe system achieved segmentation, recognition, and counting of ﬁtness data, with segmenta-\ntion precision and recall exceeding 95%. Recognition rate",
            "ecision and recall exceeding 95%. Recognition rates for different numbers of repetitions\nwere 99%, 98%, and 96%, respectively, with a counting accuracy of ± 1. However, RecoFit has\nlimitations, such as requiring 5 seconds for segmentation and recognition, performing poorly\nwith a small number of repetitions, and relying on specialized devices attached to the forearm,\nwhich increases user inconvenience and cost.\nData collection and evaluation hardware.[20]\nShen et al. [21] proposed the MiLift sys",
            "ware.[20]\nShen et al. [21] proposed the MiLift system, which combines a two-stage classiﬁcation model\nwith a lightweight weightlifting detection algorithm to autonomously and efﬁciently track aero-\nbic and weightlifting exercises. The system achieved an average precision and recall of over 90%\nfor aerobic activity classiﬁcation, weightlifting detection, and weightlifting type classiﬁcation.\nMiLift also calculated weightlifting repetitions with an average error of 1.12 repetitions (mean\nof 9.65 r",
            " average error of 1.12 repetitions (mean\nof 9.65 repetitions). However, it relied solely on gravity data for recognition, which reduced ac-\ncuracy when movements lacked signiﬁcant changes in the gravity direction.\nSoro et al. [22] used deep learning methods for recognizing and counting complex full-body\nmovements, achieving a recognition accuracy of 99.96% on constrained movement datasets.\nHowever, their approach required a CNN+RNN architecture to process multi-sensor data, pos-\ning challenges f",
            "o process multi-sensor data, pos-\ning challenges for real-time recognition on devices.\nSkawinski et al. [23] proposed a machine learning approach using convolutional neural net-\nworks to count repetitions of recognized exercise types with a single 3D accelerometer worn on\nthe chest. The method achieved an average recognition accuracy of 89.9%, with an average rep-\netition counting accuracy of 97.9% across all exercise types. However, the method was limited\n22\nto four types of exercises with sign",
            "as limited\n22\nto four types of exercises with signiﬁcant differences, potentially restricting its applicability to\nother exercise types.\nIshii et al. [24] developed ExerSense, which uses correlation-based methods and Dynamic\nTime Warping (DTW) for exercise segmentation, classiﬁcation, and counting. The authors also\ntested different device positions to optimize performance. When data was limited, this ap-\nproach outperformed machine learning methods in accuracy. However, template-based algo-\nrith",
            "ds in accuracy. However, template-based algo-\nrithms are highly dependent on template quality, posing challenges for generalization across\ndifferent populations and exercise scenarios.\n2.3\nContribution of this research\nTo enable real-time human motion recognition on Android devices, our study has made the\nfollowing contributions compared to the aforementioned research:\n1. Lower Sampling Rate: Unlike the algorithms requiring 50 Hz or 100 Hz sampling rates in\nprior studies, our algorithm achieves ",
            "ng rates in\nprior studies, our algorithm achieves recognition and counting using only a 12.5 Hz sampling\nrate, signiﬁcantly reducing battery consumption [25].\n2. Reduced Feature Set: Our algorithm utilizes fewer features. After feature selection, the two\nRandom Forest (RF) models employed in our study use only 24 and 26 features, respectively.\n3. Double Layer Sliding Window Method: We implemented a Double Layer Sliding Win-\ndow approach, which, compared to traditional sliding window methods [18]",
            "ompared to traditional sliding window methods [18][25], reduces the\nnumber of computations required by the model while maintaining accuracy, thereby lowering\ncomputational overhead.\n23\nChapter 3\nIntroduction to Research Methods\n3.1\nProposal of Research Methods\nThis study aims to develop an algorithm and design an Android application based on it to\ntrack ﬁtness activities in real time and record data for eight categories of exercises. The sys-\ntem collects acceleration data in real time through a",
            " collects acceleration data in real time through a smartwatch and processes it on the smart-\nphone. With this application, users do not need to manually select exercise types or record the\nnumber of repetitions during their workouts. The application automatically handles the record-\ning and classiﬁcation of ﬁtness data.\nFigure 3.1 illustrates the eight target ﬁtness activities in our study, all of which are upper-body\nresistance exercises performed using gym machines. Resistance exercises provid",
            "ed using gym machines. Resistance exercises provide numerous\nbeneﬁts for individuals across different populations and conditions, such as reducing arterial\nblood pressure [26], increasing muscle strength, and serving as a treatment for various muscu-\nloskeletal disorders [27].\nBefore detailing the components of our algorithm, we ﬁrst present Figure 3.2, which illus-\ntrates how the entire algorithm operates in a real-time environment.\nThe algorithm employs a triple-layer sliding window structure ",
            "m employs a triple-layer sliding window structure to process acceleration data\ncollected during user activities in real time. The detailed workﬂow is as follows: 1. State Detec-\ntion: The algorithm ﬁrst uses three-axis acceleration data to determine whether the user is in\nan active state. 2. Composite Acceleration Calculation: Once the user is identiﬁed as being in\nan active state, compcosite acceleration is computed. 3. Repetition Counting: By detecting the\npeaks of the composite acceleration, ",
            "etecting the\npeaks of the composite acceleration, the algorithm counts the user ’s repetitive actions. 4. Ac-\ntion Recognition: Finally, based on the three-axis acceleration data, the algorithm identiﬁes the\n24\nFigure 3.1: 8 Types of ﬁtness activities\nFigure 3.2: Algorithm working schematic\n25\ntype of activity and outputs the results. Through these steps, the algorithm achieves real-time\nautomatic tracking and recording of the user ’s ﬁtness activities.\n3.2\nOverview of TLSW: A method for monitor",
            "vities.\n3.2\nOverview of TLSW: A method for monitoring ﬁtness exercise in real time\nFigure 3.3: Structure of the TLSW algorithm\nFigure 3.3 illustrates the algorithm’s structure in this study, which utilizes a Triple-layer slid-\ning window data structure with a total length of approximately 5.6 seconds. The structure slides\none data point at a time, performing computations with each slide, and moves to the right (with\nnew data entering the state classiﬁcation window ﬁrst). The state recognition wi",
            "assiﬁcation window ﬁrst). The state recognition window contin-\nuously classiﬁes the activity state in real time, determining whether the user is engaged in a\nﬁtness activity. Once a ﬁtness state is identiﬁed, the double-layer window is activated, where:\nLayer[1]: This layer identiﬁes the peak positions within the window and determines whether the\n26\npeaks are centered. Layer[2]: This layer classiﬁes the data within the window using a machine\nlearning model for activity type classiﬁcation.\nThis s",
            "ning model for activity type classiﬁcation.\nThis structure ensures efﬁcient real-time state recognition, repetition counting, and activity\nclassiﬁcation.\nFigure 3.4 presents the ﬂowchart of the algorithm, with details of each component explained\nin the next section. The algorithm consists of two main parts:\n1. State Classiﬁcation:\nWhen the user presses the \"Start Workout\" button, the collected three-axis acceleration\ndata enters the window for real-time state classiﬁcation. The purpose of this s",
            "al-time state classiﬁcation. The purpose of this step is to\ndetermine whether the user is exercising. A machine learning model trained to recognize\nstates is used for classiﬁcation:\n• If the classiﬁcation result is \"non-exercise,\" the accumulator - 1.\n• If the classiﬁcation result is \"exercise,\" the accumulator + 1.\n2. Type Classiﬁcation and Counting:\nWhen the state classiﬁcation determines the user is exercising, this part is activated. First,\npeak detection is performed within the window to lo",
            "eak detection is performed within the window to locate the positions of peaks. The algo-\nrithm then checks whether the peak position lies at the center of the window:\n• If the peak is not at the center, it is skipped.\n• If the peak is at the center, it is counted as a valid exercise repetition. Centered around\nthe peak, the data within the window is classiﬁed using a machine learning model to\nidentify the exercise type, which is recorded as one completed action of that type.\nThis dual-step proce",
            "ompleted action of that type.\nThis dual-step process ensures accurate recognition of the user’s activity state, repetition count-\ning, and exercise type classiﬁcation in real time.\n3.3\nMethod for separating and extracting the ﬁtness state\nIn this section, we will detail the working principle of the state classiﬁcation window, as il-\nlustrated in the structural diagram. To eliminate the cumbersome process of manually starting\nand stopping between each set of exercises, we introduced a real-time s",
            "each set of exercises, we introduced a real-time state recognition feature.\nFirst, the system continuously detects the user’s motion state in real time, automatically distin-\nguishing between active (exercise) and inactive (non-exercise) states. Once the system identi-\nﬁes an active state, it proceeds to recognize the user’s speciﬁc actions during exercise. Based\n27\nFigure 3.4: Flowchart of the TLSW algorithm\n28\non data collection and analysis, we categorized the user’s state during workouts int",
            "e categorized the user’s state during workouts into four dis-\ntinct types. Figure 3.5 shows the corresponding three-axis acceleration data for these four types.\nThis approach ensures efﬁcient and seamless transitions between exercise detection and action\nrecognition, signiﬁcantly enhancing user convenience and workout tracking accuracy.\nFigure 3.5: Triaxial acceleration diagrams for 4 states\nThe four states include exercise, walking, resting while seated, and other activities (e.g., drink-\ning w",
            "e seated, and other activities (e.g., drink-\ning water, sanitizing gym equipment). Since this study focuses solely on processing the exercise\nstate, all states other than exercise are deﬁned as \"non-exercise,\" while all target ﬁtness activities\nare classiﬁed as \"exercise.\"\nTo recognize motion states, the action recognition window is designed such that three-axis\nacceleration data enters the window, and every 5 data points (approximately 0.4 seconds), a ma-\nchine learning model performs classiﬁca",
            "ds), a ma-\nchine learning model performs classiﬁcation to determine the state. The window length is 70\ndata points, equivalent to approximately 5.6 seconds. Since activities like walking or repetitive\nnon-exercise motions can often be misclassiﬁed as exercise, relying on a single classiﬁcation\nresult to determine the exercise state could lead to numerous errors. To address this, an accu-\nmulator system with a threshold is incorporated to optimize the decision process:\n- When the classiﬁcation re",
            " the decision process:\n- When the classiﬁcation result is \"exercise,\" the accumulator increases by 1.\n- When the result is \"non-exercise,\" the accumulator decreases by 1.\nThe accumulator has a threshold value and a maximum limit. Once the accumulator value\nexceeds the threshold, the system transitions to the exercise state and activates the next pro-\ncessing stage. When the accumulator reaches its maximum limit, it will no longer increase.\nAdjusting the threshold affects the ease of classifying ",
            "ing the threshold affects the ease of classifying the user as being in the exercise state.\n29\nFor example, lowering the threshold allows quicker transitions to the exercise state but increases\nthe risk of misclassifying other states as exercise. Similarly, modifying the difference between the\nmaximum limit and the threshold adjusts the transition difﬁculty from exercise to non-exercise:\nA small difference results in a quick reversion to the non-exercise state after completing the\nlast action in ",
            "xercise state after completing the\nlast action in a set, potentially losing the count of the ﬁnal action due to the delay. Conversely, a\nlarge difference may lead to non-exercise data being passed to the next stage, causing redundant\ncounts.\nIn summary, adjusting the threshold and maximum limit inﬂuences the weights for transi-\ntions between [non-exercise] →[exercise] and [exercise] →[non-exercise] states. After multi-\nple tests in this experiment, the delay is approximately 1.6 seconds. Under i",
            "t, the delay is approximately 1.6 seconds. Under ideal conditions, the\nsystem determines the user has entered the exercise state 1.6 seconds after starting the workout.\n3.4\nMethod of counting and recognizing ﬁtness movements\nThis section details the workﬂow of the Double-Layer Sliding Window illustrated in the struc-\ntural diagram. This component consists of an inner window and an outer window, both centered\nat the same position.\nOuter Window (Peak Detection Window): The outer window is responsi",
            "ak Detection Window): The outer window is responsible for peak detec-\ntion. It has a size of 60 data points, equivalent to approximately 4.8 seconds.\nInner Window (Action Recognition Window): The inner window handles action recognition.\nIts size is 50 data points, equivalent to approximately 4 seconds.\nFigure 3.6: Schematic of the working of DLSW algorithm\nFigure 3.6 shows the four steps of data processing in the Double-Layer Sliding Window algo-\nrithm:\n30\n1. Composite Acceleration Calculation C",
            "\nrithm:\n30\n1. Composite Acceleration Calculation Compute the Composite acceleration from the three-\naxis acceleration data entering the window.\n2. Peak Detection Detect the peaks of the composite acceleration within the outer window.\nAs the window slides, calculate the position of each peak.\n3. Repetition Recording and Classiﬁcation When a peak is located at the center of the outer\nwindow, record one repetition. Simultaneously, classify the ﬁtness activity type using the\nthree-axis acceleration ",
            "s activity type using the\nthree-axis acceleration data within the inner window.\n4. Result Aggregation and Output Temporarily store each recorded repetition. When a transi-\ntion out of the exercise state occurs, aggregate the classiﬁcation results within the current\nset, select the majority result as the activity type for the set, and output the classiﬁcation\nresult along with the count.\nIn studies [20] and [22], repetition counting is performed by selecting a speciﬁc axis from the\nthree-axis acc",
            "y selecting a speciﬁc axis from the\nthree-axis acceleration data for peak detection. However, in our research, we observed that for\ncertain exercises, such as the Lat Pull Down(Figure 3.7), variations in the smartwatch’s angle and\nposition on the left wrist during data collection, along with differences in the motion angles of\nthe exercises themselves, result in the most representative axis differing across actions.\nTo address this issue, we opted to compute the composite acceleration, allowing ",
            "d to compute the composite acceleration, allowing us to per-\nform peak detection on a uniﬁed dimension for all exercises. This approach enhances the algo-\nrithm’s adaptability and consistency across various ﬁtness activities.\nDuring the sliding of the window, the composite acceleration peaks for each action pass se-\nquentially through the center of the window. The center point is used as a marker, and when\na peak aligns with the center, it is recorded as one repetition. This method offers the fo",
            "orded as one repetition. This method offers the following\nadvantages:\n• Reduction in Duplicate Counting\nBy aligning peak positions with the center point, the method ensures that the same peak\nappearing in adjacent windows is not counted twice. This effectively reduces the likelihood\nof duplicate counts for the same action.\n• Improved Action Classiﬁcation Accuracy\nTo enhance classiﬁcation accuracy, special preprocessing was applied to the training data.\nSpeciﬁcally, composite acceleration peaks w",
            " data.\nSpeciﬁcally, composite acceleration peaks were used as markers to segment each action\ninto windows centered around the peaks. This approach minimizes errors caused by vari-\nations in user movement speed and ensures that the window data covers the primary or\n31\nFigure 3.7: Composite acceleration and triaxial acceleration of Lat Put Down\n32\ncomplete segment of each ﬁtness action. Even when the rhythm of the actions changes,\ndata integrity is preserved, signiﬁcantly improving model classiﬁca",
            " preserved, signiﬁcantly improving model classiﬁcation accuracy.\n• Reduced Computational Overhead\nThe algorithm mandates that composite acceleration peaks must pass through the window\ncenter. Ideally, the number of feature extractions and model classiﬁcations matches the\nactual number of ﬁtness actions. Compared to ﬁxed-step sliding window methods, this\napproach effectively reduces unnecessary computational costs.\nAnalysis revealed that the duration of a single user action typically ranges from ",
            "ion of a single user action typically ranges from 2.7 to 5 sec-\nonds. To maximize coverage of a single action ’s data while avoiding the inclusion of two com-\nplete actions in one window, we set the inner window size to 4 seconds. Additionally, we opti-\nmized the size of the outer window to reduce counting errors:\n• Issues with an Oversized Window\nWhen users complete the last few repetitions in a set, their movements tend to slow down\ndue to fatigue, resulting in lower acceleration peaks. An ove",
            "gue, resulting in lower acceleration peaks. An oversized window may include\nthe peak from the previous action, which can interfere with detecting the next action ’s\nacceleration peak, ultimately reducing the count.\n• Issues with an Undersized Window\nIf the outer window is too small, secondary peaks between two consecutive actions may\nbe mistaken for the synthetic acceleration peak of a full action. This can lead to over-\nsegmentation of a single action and result in overcounting.\nIn some actions",
            "action and result in overcounting.\nIn some actions, a single motion may produce two closely spaced positive peaks of similar\nmagnitude, along with a distinct negative peak in the opposite direction that can serve as a\nmarker. Relying solely on peak-to-peak distance to ﬁlter out duplicate peaks may affect fast-\npaced actions or those with close peak spacing within a single motion.\nTo address this, we incorporated synthetic acceleration inversion into the peak detection\nprocess shows in Figure 3.8",
            "nto the peak detection\nprocess shows in Figure 3.8: Using gravity acceleration (9.8 m/s2) as the reference value, if the\ndifference between the minimum value and the reference exceeds the difference between the\nmaximum value and the reference signiﬁcantly, the synthetic acceleration data within the cur-\nrent window is inverted.The inverted data is then used for subsequent peak detection.\n33\nFigure 3.8: Reverse acceleration optimized for counting\nFigure 3.9 illustrates the workﬂow for determining",
            "Figure 3.9 illustrates the workﬂow for determining whether a peak position lies at the center:\nHere are the detailed steps for calculating peak positions:\n1. Smooth Data\nTo eliminate noise interference in the acceleration data, a Simple Moving Average (SMA) is\napplied to the three-axis acceleration data (X, Y, Z). A window size of 3 is used to calculate\nthe average of each data point and its neighboring points.\n2. Calculate the Composite Acceleration\nComposite acceleration is computed from the s",
            "tion\nComposite acceleration is computed from the smoothed three-axis acceleration data and\nserves as the foundation for subsequent processing.\n3. Calculate Whether to Reverse the Signal\nTo distinguish different phases of an action, the signal’s direction is evaluated for potential\ninversion:\nCalculate the deviation of the maximum and minimum acceleration values from the stan-\ndard gravitational acceleration (9.8 m/s2).If the minimum value’s deviation signiﬁcantly\nexceeds the maximum value’s devi",
            "tion signiﬁcantly\nexceeds the maximum value’s deviation, the signal is inverted.The inversion ensures con-\nsistent peak orientation, facilitating more accurate peak detection.\n4. Calculate Relative Height\nThe relative height of peaks is calculated based on the maximum and minimum accelera-\ntion values within the window. A relative height threshold of 40% of the acceleration range\nis used to ﬁlter out minor ﬂuctuations.The prominence of a peak is determined using the\n34\nFigure 3.9: Process for ﬁn",
            "determined using the\n34\nFigure 3.9: Process for ﬁnding peak locations\n35\nprominence parameter from Python’s [scipy.signal.ﬁnd_peaks] method.Prominence is de-\nﬁned as:\nProminence = Peak Height−max(Left Base,Right Base)\n(3.1)\nThe left and right bases represent the lowest points on either side of the peak.After testing,\nsetting the prominence threshold to 40% of the acceleration range(Prominence=(max_acc\n－min_acc) * 0.4)yielded the best results.\n5. Calculate Absolute Height\nValues below the gravita",
            "Calculate Absolute Height\nValues below the gravitational acceleration (9.8 m/s2) are adjusted to 9.8 to mitigate the\nimpact of low values on calculations.The adjusted signal ’s mean is calculated as the base-\nline.A peak’s absolute height threshold is set to 101.5% of the baseline (a 1.5% increment),\nﬁltering signiﬁcant peaks related to actions while reducing false detections caused by gen-\neral ﬂuctuations.\n6. Find the Peak Location\nUsing the [scipy.signal.ﬁnd_peaks] method in Python, peaks are",
            "cipy.signal.ﬁnd_peaks] method in Python, peaks are ﬁltered based on relative\nheight, absolute height, and a minimum distance of 22 data points between peaks. This\nprocess identiﬁes valid peaks in the window and calculates their positions.\n3.5\nState Recognition Model and Fitness Movement Recognition Model us-\ning Machine Learning\nTo support the above algorithm in classifying users’ states and ﬁtness activity types, we trained\ntwo machine learning models using common Python libraries such as NumPy",
            "models using common Python libraries such as NumPy and scikit-learn.\nBelow are the details of the model training process.\n3.5.1\nData collection\nThis study utilized the Google Pixel Watch 2 running Android OS 4.0 (API 34) to collect three-\naxis acceleration data, as shown in Figure 3.10. The device was worn on the left wrist of 10\nvolunteers. Data collection was conducted in the gymnasium of Aoyama Gakuin University’s\nSagamihara Campus, recorded at a sampling rate of 12.5 Hz.\nIn total, data for e",
            "t a sampling rate of 12.5 Hz.\nIn total, data for eight types of ﬁtness activities were collected, including 1,701 ﬁtness actions\nand approximately 120 minutes of non-exercise state data during the ﬁtness sessions, as shown\n36\nFigure 3.10: Devices and wear positions\nFigure 3.11: Distribution in data sets\n37\nin Figure 3.11. Figure 3.12 illustrates the three-axis acceleration corresponding to each activity\ntype.\nFigure 3.12: 3-axis acceleration for 8 types of movements\nDuring data collection, volun",
            "8 types of movements\nDuring data collection, volunteers performed various predeﬁned ﬁtness activities using des-\nignated gym machines. However, no strict requirements were imposed on speed, weight load,\nor repetitions per set. This ensured that the data closely resembled real-world ﬁtness scenarios,\nproviding valuable support for model training.\n3.5.2\nData preprocessing\nIn this study, the collected acceleration data was smoothed to reduce the impact of potential\noutliers during data collection o",
            "act of potential\noutliers during data collection on subsequent analysis. To enhance computational efﬁciency,\nwe applied a sliding window averaging method for smoothing. Speciﬁcally, the sliding window\nsize was set to 3, and the value of each data point was calculated as the average of that point and\nits two adjacent points (one before and one after).\n38\nThis method effectively smooths short-term ﬂuctuations while preserving the primary trends\nand characteristics of the data, providing a more sta",
            " characteristics of the data, providing a more stable and reliable input for subsequent data\nsegmentation and feature extraction.\n3.5.3\nData set segmentation\nAfter smoothing the data, it was segmented based on the requirements of different models:\n1. Segmentation for the State Classiﬁcation Model\n• Manual Separating:\nThe data was manually cleaned to separate exercise states from non-exercise states\nwithin the same dataset. Exercise state data was saved as independent datasets for\neach set of act",
            " saved as independent datasets for\neach set of actions, while non-exercise state data was saved in segments, ensuring con-\ntinuity within each dataset and avoiding concatenation from different segments.\n• Window:\nThe window size was set to match real-time recognition parameters, 70 data points\nwith a stride of 5, to maintain consistency across data processing standards.\n2. Segmentation for the Type Classiﬁcation Model\nFollowing the approach of the Double-Layer Sliding Window (DLSW) algorithm, se",
            "e Double-Layer Sliding Window (DLSW) algorithm, segmen-\ntation points were determined based on the positions of synthetic acceleration peaks:\n• Synthetic Acceleration Calculation:\nComposite acceleration was calculated from three-axis acceleration data.\n• Peak Detection:\nPeaks were detected using the ﬁnd_peaks method in Python ’s scipy.signal library.\n• Windowing Around Peaks:\nFor each peak position, a window of 50 data points centered around the peak was ex-\ntracted, providing the input data for",
            "peak was ex-\ntracted, providing the input data for subsequent feature extraction.\n3.5.4\nFeature Selection\nAfter splitting the dataset for each model, we ﬁrst performed feature extraction in Python.\nFeature extraction is crucial, as the selected features directly affect classiﬁcation accuracy. Choos-\ning the right features means identifying key attributes that best represent the original data. In\n39\nother studies, researchers select different types of features based on the classiﬁcation model\nthe",
            "s of features based on the classiﬁcation model\nthey are building. These features are mainly divided into time-domain and frequency-domain\nfeatures. Compared to time-domain features, frequency-domain features have a higher compu-\ntational cost [18].\nWe referred to other studies and selected commonly used features such as maximum, min-\nimum, median, kurtosis, skewness, zero-crossing rates, correlation coefﬁcient, peak-to-peak\nvalue, and correlation between axes [28]. Below are the features used in",
            " between axes [28]. Below are the features used in this study for the state\nrecognition model and the category recognition model. Some feature calculations were based\non [28][29][30][31] and were implemented using the NumPy and SciPy libraries in Python.\nTable 3.1: Feature Descriptions\nFeature Name\nExplanation\nmax\nMaximum value in the window\nmin\nMinimum value in the window\nmdn\nMedian value\nkts\nKurtosis\npeak_value\nMaximum absolute value in the window\npeak_to_peak_value\nDifference between maximum ",
            "dow\npeak_to_peak_value\nDifference between maximum and minimum values\nskewness\nMeasures the degree of skewness of the data distribution relative to a\nsymmetric distribution\nsma\nSignal Magnitude Area [32]\nnum_prominent_peaks_3\nNumber of peaks with prominence > 0.3\nnum_prominent_peaks_5\nNumber of peaks with prominence > 0.5\nnum_prominent_peaks_7\nNumber of peaks with prominence > 0.7\nmax_peak_value\nPeak value with prominence > 0.7\nspectral_centroid\nWeighted average of signal frequency distribution\ns",
            "eighted average of signal frequency distribution\nspectral_ﬂatness\nIndicator of the uniformity of the signal’s spectral distribution\ncor_xy\nCorrelation coefﬁcient of x-axis and y-axis\nzcr\nZero-Crossing Rate\ntotal_energy\nThe power spectral density of the signal is calculated and integrated\nto obtain the total energy of the signal.\nbandpass_energy_0_2_0_3\nTotal energy in the frequency range 0.2 Hz to 0.3 Hz\nbandpass_energy_0_4_0_6\nTotal energy in the frequency range 0.4 Hz to 0.6 Hz\nbandpass_energy",
            "e frequency range 0.4 Hz to 0.6 Hz\nbandpass_energy_0_7_0_8\nTotal energy in the frequency range 0.7 Hz to 0.8 Hz\nThe calculation methods for commonly selected features such as maximum and minimum\nare omitted here. Instead, we will focus on explaining the calculation methods for other features\nspeciﬁcally deﬁned in this study.\n40\n• Signal Magnitude Area\nThe normalized Signal Magnitude Area (SMA) reﬂects the overall average absolute magni-\ntude of a signal and is used to quantify its intensity or e",
            " signal and is used to quantify its intensity or energy characteristics in a speciﬁc\ndimension. In time series analysis, it helps compare the average magnitude of different\nsignals, such as the acceleration characteristics in various directions during ﬁtness move-\nments.\nxsma =\nPN\ni=1 |x[i]|\nN\n– |x[i]|: The absolute value of the i-th sample of the signal;\n– N: The total number of samples in the signal;\n– P|x[i]|: The sum of the absolute values of the signal amplitude.\n• num_prominent_peaks\nWe fo",
            " the signal amplitude.\n• num_prominent_peaks\nWe found that the number of prominent peaks exceeding a certain threshold differs be-\ntween ﬁtness and non-ﬁtness states. Therefore, we included the number of peaks with\nprominence greater than 0.3, 0.5, and 0.7 as features. Using the ‘ﬁnd_peaks‘ method with a\nspeciﬁed prominence parameter, we detected signiﬁcant peaks in the signal and recorded\ntheir count as feature values.\n41\nFigure 3.13: The number of peak points exceeding the threshold in three-a",
            " of peak points exceeding the threshold in three-axis acceleration: (left)\nﬁtness state, (right) non-ﬁtness state.\n• max peak value\nThe algorithm detects peaks in the signal based on the speciﬁed prominence parameter\n(prominence > 0.7) and returns the maximum value among these peaks. If no peaks are\nfound, it returns 0.\n• Power Spectral Density\nNext, to compute frequency features, we analyzed the peak frequency distribution of three-\naxis acceleration within each segmented data window. First, we",
            "ation within each segmented data window. First, we calculated the power spec-\ntral density (PSD) for each window using the ‘welch‘ method from the ‘scipy.signal‘ library.\nThis method analyzes the energy distribution of the signal in the frequency domain by seg-\nmenting the signal, computing the spectrum for each segment, and averaging the results.\n42\nTo accommodate the characteristics of the signal and the limitations of data length, we set\nthe segment size for Welch ’s method to 50 data points.",
            "egment size for Welch ’s method to 50 data points. Additionally, adjacent segments\nhad an overlap of 10 points (20% overlap) to further smooth the PSD curve and reduce\nestimation variance. With this conﬁguration, each window of the signal was ﬁrst processed\nwith a Hanning window to minimize edge effects, followed by a Fast Fourier Transform\n(FFT) to compute its spectrum. The squared values of all windowed spectra were then\naveraged to generate the ﬁnal PSD curve.\nSxx(f ) = 1\nL\nLX\nk=1\n1\nnperseg\n¯",
            "e ﬁnal PSD curve.\nSxx(f ) = 1\nL\nLX\nk=1\n1\nnperseg\n¯¯¯¯¯\nnperseg−1\nX\nn=0\nxk[n]w[n]e−i2πf n∆t\n¯¯¯¯¯\n2\n• spectral centroid\nIn the analysis of acceleration signals during ﬁtness activities, the spectral centroid repre-\nsents the weighted average of the signal’s frequency spectrum, reﬂecting the primary fre-\nquency characteristics of the movement. A lower spectral centroid value indicates that\nlow-frequency components dominate the signal, which is typically associated with slower\nor more controlled mo",
            "cally associated with slower\nor more controlled movements. In contrast, a higher spectral centroid suggests that high-\nfrequency components are dominant, often corresponding to faster and more dynamic\nmovements [30]. We calculate the spectral centroid based on the previously computed\nPSD, using the following formula:\nFor a given frequency array f [i] and PSD values S[i], the spectral centroid C is deﬁned as:\nC =\nP\ni f [i]·S[i]\nP\ni S[i]\n– f [i]: The i-th frequency point;\n– S[i]: The PSD value cor",
            "he i-th frequency point;\n– S[i]: The PSD value corresponding to the i-th frequency point;\n– The numerator is the weighted sum of frequencies by their corresponding power;\n– The denominator is the total power, used for normalization.\n• spectral ﬂatness\nSpectral Flatness is calculated as the ratio of the geometric mean to the arithmetic mean of\nthe spectrum and is used to measure the uniformity of the spectral distribution.\nFirst, the magnitude spectrum is obtained by applying the Fast Fourier Tra",
            "ctrum is obtained by applying the Fast Fourier Transform (FFT)\nto the input signal. Then, the geometric mean and arithmetic mean of the spectrum are\n43\ncomputed. The geometric mean is derived by taking the logarithm of the magnitude val-\nues, averaging them, and then applying the exponential function. The arithmetic mean is\nsimply the average of the spectral magnitudes.\nFinally, spectral ﬂatness is obtained by dividing the geometric mean by the arithmetic\nmean. This metric reﬂects the frequency ",
            "rithmetic\nmean. This metric reﬂects the frequency distribution characteristics of the signal: higher\nspectral ﬂatness indicates a more uniform energy distribution across frequencies (e.g., white\nnoise), while lower spectral ﬂatness suggests that energy is concentrated at a few speciﬁc\nfrequencies.\nThe Spectral Flatness is deﬁned as:\nSpectral Flatness =\n¡QN\ni=1\n¡\nSx(fi)+ϵ\n¢¢ 1\nN\n1\nN\nPN\ni=1\n¡\nSx(fi)+ϵ\n¢\n– Sx(fi): The power spectral density (PSD) corresponding to the i-th frequency point;\n– N: The ",
            "rresponding to the i-th frequency point;\n– N: The total number of frequency points;\n– ϵ = 1×10−10: A small constant added to avoid division by zero or taking logarithms of\nzero.\n• Total energy\nBy computing the total energy of the Power Spectral Density (PSD), the overall energy dis-\ntribution across the entire frequency domain can be quantiﬁed. This reﬂects the overall\nintensity characteristics of the signal, providing a measure of movement intensity or activ-\nity level.\nThe total energy is calc",
            "sity or activ-\nity level.\nThe total energy is calculated by summing the PSD values across all frequency points and\nmultiplying by the frequency resolution ∆f = freqs[1]−freqs[0]. The formula is as follows:\nEtotal =\nX\ni\nSx(fi)·∆f\nwhere Sx(fi) represents the power spectral density value at the ith frequency point.\n• bandpass_energy\nTo analyze the energy distribution of the signal within speciﬁc frequency ranges, we com-\nputed the Bandpass Energy within each window. First, we determined the dominan",
            "thin each window. First, we determined the dominant fre-\nquency range by calculating the signal’s frequency distribution using Power Spectral Den-\nsity (PSD). Then, we integrated the PSD within this frequency band to obtain the total en-\nergy in that range.\n44\nAfter extracting the peak frequency from the PSD in each window, we used Kernel Den-\nsity Estimation (KDE) to visualize the distribution of dominant frequencies. KDE is a non-\nparametric method that smooths discrete frequency distributions",
            "thod that smooths discrete frequency distributions into a continuous prob-\nability density function, revealing the concentration and overall trend of frequency com-\nponents.\nFor implementation, we used the kdeplot function from the Seaborn library to generate\nKDE visualizations. The results are shown in the ﬁgure.\nFigure 3.14: Main Frequency Distribution in Exercise State\n45\nFigure 3.15: Main Frequency Distribution in Non-Exercise State\nFrom the ﬁgure, it can be observed that in the exercise sta",
            "ﬁgure, it can be observed that in the exercise state, the dominant frequencies\nare concentrated in the ranges of 0.2–0.3 Hz, 0.4–0.6 Hz, and 0.7–0.8 Hz, whereas in the\nnon-exercise state, the frequency distribution is more dispersed.\nWe then used the following formula to compute the total energy within each of these three\nfrequency ranges.\nEbandpass =\nX\ni∈band\nSx(fi)∆f\n– Sx(fi): The PSD value at the frequency point fi;\n– ∆f = freqs[1]−freqs[0]: The frequency resolution;\n– band: The set of freque",
            "he frequency resolution;\n– band: The set of frequency points within the bandpass range.\nThe ﬁgure shows the differences in total energy across different frequency ranges between\nthe exercise and non-exercise states. Therefore, we deﬁned the total energy in each of the three\nfrequency ranges as separate feature values.\n46\nFigure 3.16: Comparison of Energy in Three Frequency Ranges for Different States: (Top) Exer-\ncise State (Bottom) Non-Exercise State\n• Zero Crossing Rate\nZero Crossing Rate (ZCR",
            "State\n• Zero Crossing Rate\nZero Crossing Rate (ZCR) is a frequency-domain feature that measures the rate of signal\nchanges by calculating the proportion of zero crossings within a unit time. It is determined\nby detecting sign changes between adjacent sampling points, counting the total number of\nzero-crossings, and dividing this count by the signal length.\nZCR = 1\n2\nN\nX\nn=2\n¯¯sign(xn)−sign(xn−1)\n¯¯\n• Correlation Coefﬁcient\nBy computing the correlation coefﬁcients between the X, Y, and Z axes of ",
            "ation coefﬁcients between the X, Y, and Z axes of the acceleration\nsignal, the relationship between different directional movements is quantiﬁed. Speciﬁcally,\nthe X, Y, and Z components of the signal are ﬁrst extracted, and then the Pearson correlation\ncoefﬁcients for X-Y, X-Z, and Y-Z are calculated using np.corrcoef.\n47\ncor(X ,Y ) = cov(X ,Y )\nσX σY\n3.5.5\nState Classiﬁcation Model Training and Feature Reduction\nWe referred to previous studies [30][33] that summarized commonly used machine lear",
            "30][33] that summarized commonly used machine learning\nmethods for state recognition and selected Random Forest, Decision Tree, SVM, K-Means, and\nNaïve Bayes for comparison. The models were ﬁrst trained in Python, and their performance\nwas evaluated using accuracy and F1-score. The results are shown in the table below.\nTable 3.2: Comparison of State Classiﬁcation Model Performance\nModel\nF1-Score\nAccuracy\nRandom Forest\n0.972\n0.974\nDecision Tree\n0.927\n0.922\nSVM\n0.919\n0.915\nK-MEANS\n0.968\n0.967\nNaiv",
            "927\n0.922\nSVM\n0.919\n0.915\nK-MEANS\n0.968\n0.967\nNaive Bayes\n0.762\n0.776\nSimilar to ﬁndings in other studies, the Random Forest algorithm demonstrated strong per-\nformance, making it the chosen method for training the state recognition model.\nSince the model is intended to run on an ofﬂine device, dimensionality reduction was nec-\nessary to lower computational complexity. To achieve this, we combined Gini-based feature\nselection [34][35][36] and SHAP (Shapley Additive Explanations) [37][38] to eval",
            "P (Shapley Additive Explanations) [37][38] to evaluate feature im-\nportance.\nIn Random Forest, the Gini Impurity is a key metric for measuring node purity and assess-\ning each feature ’s contribution to classiﬁcation decisions. By analyzing feature importance,\nwe performed feature selection and dimensionality reduction, retaining only the most valuable\nfeatures for classiﬁcation. This approach helps reduce computational complexity and mitigates\nthe risk of overﬁtting.\nThe Gini Impurity quantiﬁes",
            "he risk of overﬁtting.\nThe Gini Impurity quantiﬁes classiﬁcation impurity and is calculated using the following for-\nmula:\nG = 1−\nKX\nk=1\np2\nk\n• K : The number of classes;\n48\n• pk: The proportion of samples belonging to the k-th class in the current node.\nThe smaller the Gini Index, the purer the samples in the current node, and the better the\nclassiﬁcation effect. During the training process of a Random Forest, the Gini Index is used to\nmeasure the change in purity before and after the split.\nSH",
            "he change in purity before and after the split.\nSHAP (SHapley Additive exPlanations) is based on Shapley values from game theory, which\nprovide a method for fairly distributing rewards. In machine learning, Shapley values quantify\neach feature’s average marginal contribution to the overall prediction, ensuring fairness, consis-\ntency, and efﬁciency in explanations.\nWithin the SHAP framework, this method is used to assess each feature ’s contribution to\nmodel predictions. The core idea is to eval",
            "ion to\nmodel predictions. The core idea is to evaluate all possible subsets of features, compute the im-\npact of adding a speciﬁc feature to each subset, and assign contribution values using a weighted\naverage. This approach provides an interpretable explanation of the model’s decision-making\nprocess.\nSpeciﬁcally, we set the number of trees (n_estimators) between 50 and 150, increasing by 5\neach time, and evaluated model accuracy using 5-fold cross-validation. The results showed that\nmodel perfo",
            "ss-validation. The results showed that\nmodel performance stabilized when the number of trees ranged between 75 and 125. Next, we\nreﬁned the search within this range, increasing by 1 each time and performing another 5-fold\ncross-validation, ultimately determining the optimal number of trees to be 100.\nBased on this, we further tuned the tree depth (max_depth) from 1 to 11, again using 5-fold\ncross-validation, to determine the best depth parameter. Using the optimized model, we then\ncalculated the",
            " Using the optimized model, we then\ncalculated the contribution of each feature to the prediction results.\nFinally, by combining the results from Gini-based selection and SHAP analysis, we selected\nthe top 25 most important features. The ﬁnal selected features are shown in the table below.\nNext, we extracted data for these selected features and split it into a training set and test set\nwith an 80:20 ratio. We trained the model using 10-fold cross-validation with the GridSearchCV\nmethod to ﬁne-tu",
            "-validation with the GridSearchCV\nmethod to ﬁne-tune hyperparameters. The model’s performance was evaluated using accuracy\nand F1-score, and a confusion matrix was generated to visualize the classiﬁcation results.\nThe ﬁnal results are shown in the ﬁgure below.\n49\nTable 3.3: Feature Names in State Classiﬁcation Model\nFeature Names\nx_zcr\nx_spectral_ﬂatness\nx_num_prominent_peaks_7\ny_num_prominent_peaks_3\nx_spectral_centroid\nx_bandpass_0_4_0_6\ny_spectral_centroid\nz_zcr\nx_bandpass_0_7_0_8\ny_zcr\ny_pea",
            "tral_centroid\nz_zcr\nx_bandpass_0_7_0_8\ny_zcr\ny_peak_value\ny_bandpass_0_2_0_3\nx_total_energy\nx_max_peak\ny_kts\ny_bandpass_0_4_0_6\ny_total_energy\nz_spectral_ﬂatness\ny_spectral_ﬂatness\ncor_yz\nx_skewness\nx_sma\nx_peak_to_peak_value\ny_peak_to_peak_value\ny_sma\nFigure 3.17: Confusion Matrix for State Classiﬁcation Models\nThe results showed an accuracy of 92.1% and an F1-score of 0.917. The recognition accuracy\nfor the ﬁtness state was particularly high, likely because the selected features were more dist",
            "ikely because the selected features were more distinc-\n50\ntive in ﬁtness-related movements. This aligns with our objective of assigning higher weight to\nthe ﬁtness state for improved classiﬁcation performance.\n3.5.6\nType Classiﬁcation Model Training and Feature Reduction\nSimilar to the state classiﬁcation model, we ﬁrst created a dataset using all features. Then,\nwe trained multiple machine learning classiﬁcation models for comparison. The results are as\nfollows:\nTable 3.4: Comparison of Type Cl",
            "s are as\nfollows:\nTable 3.4: Comparison of Type Classiﬁcation Performance\nModel\nF1-Score\nAccuracy\nRandom Forest\n0.948\n0.943\nDecision Tree\n0.871\n0.868\nSVM\n0.941\n0.940\nK-MEANS\n0.940\n0.936\nNaive Bayes\n0.894\n0.887\nFollowing the same approach as in the state classiﬁcation model, we ﬁrst trained a random\nforest model using all features and ﬁne-tuned its key parameters to assess feature importance.\nIn the initial tuning phase, we performed cross-validation to evaluate the impact of different\nparameter ",
            "ion to evaluate the impact of different\nparameter combinations on model accuracy, identifying a stable parameter range. We then re-\nﬁned the tuning process within this range to determine the optimal combination of parameters,\nincluding the number and depth of trees.\nBased on the optimized random forest model, we computed the contribution of each feature\nto classiﬁcation performance. From the feature importance analysis, we selected the most sig-\nniﬁcant features and split them into training and ",
            "niﬁcant features and split them into training and test sets. As shown in the table, most of the\nhigh-contribution features are related to acceleration along the X-axis, which aligns with the\ncharacteristics of our target movements―most actions exhibit signiﬁcant variations along the\nsmartwatch ’s X-axis direction.\nFor further model training, we used grid search and cross-validation to optimize perfor-\nmance, ensuring stability and generalization. Finally, we evaluated the model using accuracy\nan",
            " Finally, we evaluated the model using accuracy\nand F1-score, and visualized the classiﬁcation results through a confusion matrix, leading to the\nselection of the best-performing model.\n51\nTable 3.5: Feature Names in Type Classiﬁcation Model\nFeature Names\ncor_xy\ncor_xz\ncor_yz\nx_bandpass_energy\nx_kts\nx_max\nx_max_peak_value\nx_min\nx_peak_to_peak_value\nx_peak_value\nx_skewness\nx_spectral_centroid\ny_max\ny_mdn\ny_min\ny_num_prominent_peaks\ny_peak_to_peak_value\ny_peak_value\ny_skewness\ny_spectral_centroid\n",
            "value\ny_peak_value\ny_skewness\ny_spectral_centroid\nz_bandpass_energy\nz_skewness\nz_spectral_centroid\nz_zcr\nFigure 3.18: Confusion Matrix for Type Classiﬁcation Models\nThe category classiﬁcation model achieved an accuracy of 97.1% ± 2.1 and an F1-score of\n0.97 ± 0.022. Among the classiﬁcations, Lat Pull Down (Class 5) and Shoulder Press_1 (Class 7)\nwere more prone to misclassiﬁcation. We speculate that this is due to the similarity in movement\n52\npatterns between the two exercises. After standardiz",
            "tterns between the two exercises. After standardization, the range of variation in three-axis\nacceleration was reduced, making it harder to distinguish between them.\n53\nChapter 4\nAlgorithm ofﬂine experiments and results\nBefore developing the Android application incorporating this algorithm, we ﬁrst conducted\nofﬂine experiments to verify its performance and applicability. The experiments were divided\ninto two main parts: DLSW algorithm validation for category classiﬁcation and TLSW algorithm\nvali",
            "for category classiﬁcation and TLSW algorithm\nvalidation for overall performance. All ofﬂine experiments were conducted in a Python environ-\nment on Google Colaboratory.\n4.1\nExperimental data collection\nWe ﬁrst collected the necessary experimental data with the assistance of seven male volun-\nteers aged 21 to 26, all with prior ﬁtness experience. Before data collection, volunteers were\ninformed of the available ﬁtness activities and created personal workout plans based on their\npreferences. Each",
            "nal workout plans based on their\npreferences. Each participant selected 2–3 types of exercises, performing at least two sets per\nexercise.\nBefore starting the workout, volunteers engaged in light physical activity as a warm-up, dur-\ning which data collection began. Volunteers then followed their planned workout routines, and\ndata collection ended when they either completed their workout or could no longer continue.\nIn total, we collected approximately 3.3 hours of data, including 892 recorded ﬁt",
            "ately 3.3 hours of data, including 892 recorded ﬁtness move-\nments and around 2.4 hours of non-exercise data.\n54\n4.2\nDLSW Algorithm Experiment\nIn the Double-Layer Sliding Window (DLSW) algorithm test, we segmented and separately\nsaved each set of ﬁtness activity data. We then conducted comparative testing in a Python envi-\nronment, using a traditional ﬁxed-step sliding window approach with step sizes set to 25%, 50%,\nand 75% of the window size.\nFollowing the same classiﬁcation method as in the a",
            "ollowing the same classiﬁcation method as in the algorithm, we recorded the prediction\nresults for each set of data. To evaluate the performance, we used two key metrics:\n1. Probability of Correct Single Classiﬁcation – Measures the classiﬁcation accuracy for each\nindividual sliding window.\n2. Probability of Correct Classiﬁcation in the Result – Evaluates the proportion of correctly\nclassiﬁed target labels within a set of actions.\nSince the algorithm determines the ﬁnal classiﬁcation based on th",
            "ithm determines the ﬁnal classiﬁcation based on the most frequently pre-\ndicted label within a set of movements, minor misclassiﬁcations do not signiﬁcantly affect the\noverall result. These two metrics effectively reﬂect the algorithm’s classiﬁcation performance.\nFigure 4.1: Optimized results for Double-Layer Sliding Window\n55\nThe results showed that, compared to the ﬁxed-step sliding window, this method reduces the\nnumber of computations, lowering computational overhead while maintaining better",
            "ng computational overhead while maintaining better accuracy\nin both single classiﬁcation and correct label proportion within a set of movements.\nDuring testing, we observed that when movements were slower, the sliding window often\nincluded a higher proportion of transition data between two actions, leading to a decrease in\nclassiﬁcation accuracy. In such cases, using the peak point within the window as the center for\nclassiﬁcation proved to be a more effective approach.\n4.3\nTLSW Algorithm Experi",
            "more effective approach.\n4.3\nTLSW Algorithm Experiment\nFor the TLSW algorithm experiment, we ﬁrst simulated a real-time environment that closely\nresembles actual usage conditions. In this test, we used the collected experimental dataset and\nstrictly followed the sliding window size and step length deﬁned in the TLSW algorithm to en-\nsure consistency between the experiment and real-world execution.\nSpeciﬁcally, we applied the sliding window technique to incrementally segment and process\nthe data,",
            "que to incrementally segment and process\nthe data, simulating the characteristics of a real-time data stream. At each step, feature values\nwere computed and fed into the classiﬁcation model for evaluation.\nFigure 4.2: Optimized results for Double-Layer Sliding Window\n56\nWe compared the single classiﬁcation accuracy of different exercise categories with the cor-\nrected classiﬁcation accuracy for a full set of movements. As shown in the ﬁgure, although Ma-\nchine Row and Shoulder Press_2 had relati",
            "ough Ma-\nchine Row and Shoulder Press_2 had relatively low single classiﬁcation accuracy, at around 75%,\nthe majority of movements within each set were correctly classiﬁed. After applying the cor-\nrection strategy, the overall classiﬁcation accuracy for these exercises signiﬁcantly improved,\ndemonstrating the effectiveness of the correction method in enhancing overall classiﬁcation\nperformance.\nFigure 4.3: Performance in recognizing actions of varying durations\nIn addition to classifying differe",
            "rying durations\nIn addition to classifying different exercise categories, we also calculated the average dura-\ntion per movement and divided it into four time ranges, from less than 3 seconds to more than\n5 seconds. We then conducted a detailed analysis for each range.\nThe results showed that the algorithm performed well when movement durations were be-\ntween 3 and 5 seconds. However, when movements lasted less than 3 seconds, the accuracy of\nthe three evaluation metrics dropped to approximately",
            " three evaluation metrics dropped to approximately 90\nTo investigate these issues, we conducted further analysis. For movements shorter than 3\nseconds, since the window size for action classiﬁcation was set to 4 seconds, each window may\n57\nhave contained parts of the previous or next movement, leading to mixed data that affected fea-\nture calculations and classiﬁcation performance. For movements longer than 5 seconds, since\nthe peak detection window was 4.8 seconds, when the window moved between",
            "dow was 4.8 seconds, when the window moved between two movement\npeaks, some secondary peaks might have been mistakenly identiﬁed as primary peaks, causing\novercounting. Although we introduced restrictions in the peak detection algorithm, they did not\nfully eliminate the impact of secondary peaks.\nBeyond the effect of movement duration on algorithm performance, we also observed other\npotential sources of error. For instance, short pauses between repetitions and changes in grip\nposition (e.g., inc",
            "epetitions and changes in grip\nposition (e.g., incorrect posture) during exercises sometimes led to misclassiﬁcation in state\nrecognition or movement type recognition.\nDespite these challenges, the overall results of the TLSW experiment demonstrated strong\nperformance. The algorithm achieved: 92.84% accuracy for ﬁtness state recognition,97.83% ac-\ncuracy for ﬁtness type classiﬁcation,96.33% accuracy for movement counting.\n58\nChapter 5\nSmartWT : An Android ﬁtness monitoring\napp that uses TLSW met",
            "n Android ﬁtness monitoring\napp that uses TLSW methods\nAfter validating the TLSW algorithm through ofﬂine experiments, we conﬁrmed that its per-\nformance meets the expected goals. It demonstrated strong results in ﬁtness state recognition,\nexercise classiﬁcation, and movement counting, providing a solid foundation for the next phase\nof our work.\nNext, we plan to integrate the TLSW algorithm and the optimized machine learning model\ninto an Android application. Based on feedback from the questionn",
            " application. Based on feedback from the questionnaire survey, we aim to de-\nvelop a smart ﬁtness assistant capable of real-time ﬁtness state and movement recognition.\nThis application will collect acceleration data via a smartwatch and transmit it to a smart-\nphone for real-time processing. The smartphone will utilize the TLSW algorithm for sliding\nwindow processing, extract feature values, and classify movements using a pre-trained machine\nlearning model.\n5.1\nRelated work\nIn the current mobile",
            "ning model.\n5.1\nRelated work\nIn the current mobile device market, Android and iOS are the two dominant operating sys-\ntems. As an open-source system, Android not only holds a signiﬁcant share in the smartphone\nmarket but is also widely used in tablets, in-car systems, and IoT devices [39].\nIn human activity recognition research, researchers have not only developed innovative al-\ngorithms but also implemented them as Android applications, enabling functions such as fall\ndetection [41][44], gait s",
            " functions such as fall\ndetection [41][44], gait symmetry analysis [40], and activity recognition [42][43]. Some stud-\n59\nies have leveraged machine learning or deep learning, deploying trained models on Android\ndevices using frameworks like TensorFlow, Keras, and ONNX, achieving efﬁcient real-time ap-\nplications on mobile platforms [45][46][47].\n5.2\nOverview of System Architecture\nFigure 5.1: System Composition Diagram\nFigure 5.1 illustrates the overall system architecture, which consists of a ",
            " overall system architecture, which consists of a smartwatch, smart-\nphone, and cloud database. The devices used in this study include a Motorola g52j 5G smart-\nphone and a Google Pixel 2 smartwatch, with Google Firebase serving as the cloud database.\nBoth the smartwatch and smartphone run on the Android operating system, with the smart-\nphone using Android 14 and the smartwatch running Android Wear OS 4.0. The software devel-\nopment was conducted on Windows 11 using Android Studio Giraffe | 202",
            "d on Windows 11 using Android Studio Giraffe | 2022.3.1 Patch 2.\nFigure 5.2 illustrates the system workﬂow. The process begins with the user logging into their\naccount, which is authenticated through Firebase. Upon successful authentication, the system\nautomatically checks the connection status of the smartwatch.\n60\nTable 5.1: Functions of Each Component\nComponent\nFunctionality\nSmartphone\nTransmission of acceleration data, Show ﬁtness plan, Vibration feed-\nback\nSmartwatch\nUser login, Operate the",
            "tion feed-\nback\nSmartwatch\nUser login, Operate the watch, View historical data & ﬁtness move-\nment descriptions, Real-time recognition\nFirebase\nStore user accounts, Stores historical user data\nAfter logging in, users can view historical data and ﬁtness tutorials on the smartphone, re-\ngardless of the smartwatch ’s connection status. However, the automatic tracking function is\nonly available when the smartwatch app is open and online.\nBefore starting a workout, users input their ﬁtness plan on th",
            "ing a workout, users input their ﬁtness plan on the smartphone, which is then\nsynchronized to the smartwatch and displayed on its screen. When the Start button is pressed,\nthe SmartWT system begins operating. The smartwatch starts collecting three-axis acceleration\ndata during the workout and transmits it in real time to the smartphone.\nThe smartphone processes the received data in real time, recognizing ﬁtness movements\nand counting repetitions. It updates the progress according to the predeﬁne",
            " It updates the progress according to the predeﬁned workout plan and\nsends updates back to the smartwatch, dynamically displaying the remaining exercises. When\na set is completed, the smartwatch vibrates to notify the user of their progress.\nDuring the workout, users can check the remaining repetitions at any time via the smart-\nwatch or smartphone. When the workout plan is completed, or if the user chooses to stop early,\npressing the Stop button on the smartphone halts the SmartWT system. The s",
            " on the smartphone halts the SmartWT system. The system then up-\nloads the workout plan and completion progress to the cloud database, allowing users to review\ntheir workout history on the smartphone.\n5.3\nAndroid application for smartphone\nIn this study, the Android application on the smartphone is responsible for data processing,\ndevice management, and model inference, enabling automated ﬁtness tracking and user inter-\naction.\nData transmission is handled using Data Layer API [48], an Android s",
            "is handled using Data Layer API [48], an Android synchronization mecha-\nnism designed for efﬁcient data transfer between smartphones and smartwatches. Additionally,\nﬁtness data is synchronized to the cloud via Firebase. Upon user login, the application auto-\nmatically checks the smartwatch ’s connection status, and the automatic tracking function is\n61\nFigure 5.2: System Operation Flowchart\n62\nonly enabled when the smartwatch is online and the app is running.\nFor model inference, the application",
            "p is running.\nFor model inference, the application utilizes ONNX Runtime, a cross-platform deep learning\ninference engine that efﬁciently runs pretrained machine learning models on Android devices\n[49]. This enables ﬁtness activity recognition and repetition counting.\nIn this chapter, we focus on the development details of the automatic recognition system,\nwhich is directly relevant to this study. Explanations of device connection status, data upload,\nand database retrieval are omitted.\nThe ﬁgur",
            "load,\nand database retrieval are omitted.\nThe ﬁgure illustrates the workﬂow of the automatic recognition function, which follows the\nsame process as the TLSW algorithm described in Chapter 3. The system consists of four core\ncomponents: data reception, ﬁtness state recognition, movement classiﬁcation, and corrected\nresult output.\nThe entire process is governed by three key decision points, which determine when each\ncomputation step is triggered to ensure the algorithm operates correctly. However",
            "o ensure the algorithm operates correctly. However, due to dif-\nferences in computing environments and the fact that ofﬂine Python code does not involve data\ntransmission, adjustments were made on the Android side to accommodate data transmission,\nsliding window data structures, and feature computation.\n5.3.1\nData transmission\nWe used Google’s Data Layer API to enable real-time transmission of three-axis acceleration\ndata between the smartphone and smartwatch. This method is highly convenient as",
            "nd smartwatch. This method is highly convenient as it does not\nrely on an internet connection, allowing communication even when both devices are ofﬂine.\nAdditionally, communication is restricted to paired devices, ensuring data security.\nIn our algorithm, one system computation is performed for each received batch of three-axis\nacceleration data. Ideally, data transmission should follow this sequence: smartwatch sends\ndata →smartphone receives data →computation is completed →smartwatch sends the",
            "ta →computation is completed →smartwatch sends the next\nbatch.\nInitially, we designed the system so that the smartwatch would send data immediately after\ncollecting each batch. However, testing showed that frequent API calls at high transmission\nrates caused signiﬁcant data loss due to system-level asynchronous operations, with a loss rate\nof approximately 10\nTo address this issue, we modiﬁed the data transmission logic so that the smartwatch now\ncollects and transmits data in batches of ﬁve. On",
            "\ncollects and transmits data in batches of ﬁve. On the smartphone side, data is received and\n63\nFigure 5.3: Flowchart of smartphone app auto-recognition function\n64\ninserted into the sliding window structure at 80ms intervals, followed by a computation cycle.\nTesting showed that this approach increased data transmission success to 98.3%, though a small\ndegree of data loss still remained.\n5.3.2\nData structure of the sliding window\nIn the ofﬂine Python experiments, while testing the TLSW algorithm",
            "thon experiments, while testing the TLSW algorithm, we simulated sliding\nwindows by reading data points from the dataset at predeﬁned positions. Speciﬁcally, we cre-\nated a new data structure, populated it with data from the original dataset, and then applied the\nalgorithm for computation.\nHowever, in real-time execution, to improve efﬁciency and reduce computational overhead\ncaused by continuous data copying, we implemented the sliding window using a circular queue.\nBy maintaining queue indices",
            "ing a circular queue.\nBy maintaining queue indices (start_index and end_index), we dynamically tracked the head\nand tail positions of the data queue. This ensured that extracted data preserved its original time\nsequence, allowing the system to accurately retrieve data from different positions within the\nwindow for state recognition and movement classiﬁcation.\n5.3.3\nFeature Value Calculation\nDuring model training and testing in the Python environment, we used various libraries to\ncompute feature ",
            "ent, we used various libraries to\ncompute feature values. However, in the Android environment, when computing Fourier Trans-\nform and other feature values using Java libraries, we observed signiﬁcant discrepancies in the\nresults.\nWe attempted to manually adjust all parameters to minimize errors, but the discrepancies re-\nmained substantial. To resolve this, we integrated Chaquopy (version 15.0.1) to execute Python\nscripts directly on Android. This allowed us to use the same Python code for featu",
            "s allowed us to use the same Python code for feature computa-\ntion as in the ofﬂine experiments.\nFor complex feature calculations or peak detection algorithms, the application calls a Python\nscript, processes the computation, and returns the results to the Android environment. Testing\nconﬁrmed that this method successfully reduced errors, although minor precision differences\nremained due to variations in computing environments. Nevertheless, the error margin was\nsigniﬁcantly lower compared to us",
            "error margin was\nsigniﬁcantly lower compared to using Java-based computations.\n65\n5.3.4\nInterface of Smartphone Application\nThe Figure 5.4 presents the user interface of the smartphone application developed in this\nstudy.\nThe upper section of the ﬁgure displays the login screen, menu screen, and history screen,\nwhile the lower section includes the automatic workout tracking interface, workout plan cre-\nation screen, and real-time progress tracking screen during workouts.\nIn the automatic workout",
            "g screen during workouts.\nIn the automatic workout tracking interface, users ﬁrst press the \"Create a Plan\" button to\nset up a personalized workout plan, specifying the number of sets and repetitions per exercise.\nOnce the plan is created, users can start the automatic tracking feature by pressing \"Start Work\nOut\".\nDuring the workout, as users complete each set, the system updates the remaining repeti-\ntions in the plan. When an exercise is fully completed, the system displays \"Fin\", indicating ",
            " completed, the system displays \"Fin\", indicating that\nthe movement is ﬁnished. Users can follow the plan sequentially or choose to end the workout\nearly.\nTo prevent accidental interruptions, stopping the workout requires a double-tap on the \"Stop\nWork Out\" button.\n5.4\nAndroid application for smartwatch\nIn this study, the smartwatch serves three main functions:\nCollecting acceleration data from the user and transmitting it to the smartphone.\nDisplaying the user ’s workout plan and updating progr",
            "laying the user ’s workout plan and updating progress in real time.\nProviding vibration feedback when a set is completed.\nData transmission is handled via Data Layer API, as explained in the previous section. There-\nfore, this section focuses on interface design and user interaction workﬂow.\nThe Figure5.5 shows the operational ﬂow of the smartwatch in the automatic workout track-\ning function. The process starts with the following steps:\n1. Checking device connection.\n2. Receiving the user ’s wo",
            "ing device connection.\n2. Receiving the user ’s workout plan.\n66\nFigure 5.4: user interface of the smartphone application\n67\nFigure 5.5: Flowchart of smartwatch app auto-recognition function\n68\n3. Collecting three-axis acceleration data.\n4. Transmitting the data to the smartphone via Data Layer API.\nAfter the smartphone processes the data, it updates the workout plan progress on the smart-\nwatch. When the user completes a set, the smartwatch provides vibration feedback to notify\nthe user. The pr",
            "ides vibration feedback to notify\nthe user. The process concludes when the user either completes all sets or manually stops the\nprogram.\n5.4.1\nInterface of Smartphone Application\nAs shown in the ﬁgure5.6, when the smartwatch app is opened, the initial screen displays the\nconnection status with the smartphone (top left). After receiving the connection information\nfrom the smartphone, the screen transitions to the waiting for ﬁtness data screen (top right).\nOnce the user inputs their workout plan ",
            "p right).\nOnce the user inputs their workout plan on the smartphone and starts the workout, the\nsmartwatch receives the user ’s plan and displays the remaining repetitions for each exercise.\nAfter completing a movement, the screen shows \"Fin\", and the smartwatch provides vibration\nfeedback to notify the user.\n69\nFigure 5.6: Interface of Smartphone Application\n70\nChapter 6\nExperiments and Results\n6.1\nAndroid device ofﬂine experiments and results\n6.1.1\nDescription of the experiment\nAfter completin",
            ".1.1\nDescription of the experiment\nAfter completing the system development for both the smartwatch and smartphone, we con-\nducted ofﬂine experiments to verify the system’s performance before real-world use and testing.\nWe used the same dataset that was used in the Python environment for algorithm testing to con-\nduct the SmartWT system tests.\nIn the ofﬂine experiments, we stored the pre-prepared dataset on the smartwatch and sim-\nulated the data transmission process as it would occur in an actua",
            "transmission process as it would occur in an actual experiment. Speciﬁcally,\nthe smartwatch sent test data to the smartphone in groups at the same time intervals as in real\nusage. Upon receiving the data, the smartphone processed and recognized it according to the\nactual operating logic.\nThis approach allowed us to test the smartphone system’s recognition performance with-\nout relying on actual user interaction. We were able to assess the algorithm ’s performance\nwithin the SmartWT system, verif",
            "hm ’s performance\nwithin the SmartWT system, verify whether the data transmission and recognition processes\nwere functioning properly, and evaluate whether the system demonstrated good stability and\naccuracy.\n6.1.2\nResurts\nFigure 6.1 shows the real-time recognition performance of the SmartWT system on Android\ndevices. Compared to the results from the Python environment shown in Figure 3.1, it can be ob-\n71\nFigure 6.1: Real-time recognition results of the SmartWT system on Android devices\nserved ",
            "s of the SmartWT system on Android devices\nserved that, although the same algorithm and dataset were used, the recognition performance\non the Android side has slightly decreased. This is especially evident in the recognition of Ma-\nchine Row and Shoulder Press_2 movements. The accuracy of single recognition on Android\ndropped by approximately 10% compared to the Python environment.\nSimilarly, we analyzed the classiﬁcation accuracy corresponding to different movement du-\nrations. Compared to the ",
            "o different movement du-\nrations. Compared to the results in Figure 3.2, there was a noticeable decline in accuracy for fast\nmovements with an average period of less than 3 seconds. For slower movements, there was\nalso a slight decrease in both state recognition and repetition count accuracy. This indicates\nthat movement duration does have a certain impact on the system’s recognition performance.\n6.2\nAndroid devices actual experiments and results\n6.2.1\nDescription of the experiment\nWe then desig",
            "\n6.2.1\nDescription of the experiment\nWe then designed and conducted real-world experiments, using the same smartphone and\nsmartwatch as in the ofﬂine experiments. The experimental process was as follows:\nVolunteers were asked to complete all exercises, with each exercise consisting of 3 sets, each\n72\nFigure 6.2: Recognition of different simultaneous movements by SmartWT system in an experi-\nment on Android devices\n73\nset containing 8 repetitions, for a total of 192 movements. To avoid excessive ",
            " for a total of 192 movements. To avoid excessive strain and reduce\nthe risk of injury, the experiment was divided into two sessions for each volunteer. In the ﬁrst\nsession, volunteers could freely choose 4 exercises from the 8 available exercises, and in the\nsecond session, they completed the remaining 4 exercises.\nDuring the experiment, volunteers were required to complete the speciﬁed number of repe-\ntitions regardless of the remaining repetitions displayed. However, if the volunteers felt fa",
            "ions displayed. However, if the volunteers felt fatigued\nor unable to complete a set, they could reduce the number of repetitions or discontinue the ex-\nperiment as they saw ﬁt. The experiment was conducted under the supervision and guidance\nof the researcher, who explained the equipment usage and exercise form to the volunteers be-\nforehand, recorded the number of repetitions during the experiment, and provided necessary\nassistance.\nA total of 9 participants took part in the experiment, includi",
            " participants took part in the experiment, including 8 males and 1 female, aged\nbetween 21 and 25 years. The participants had 1 to 3 years of ﬁtness experience and had no re-\ncent injuries or illnesses. The experiment was conducted in the ﬁtness room at Aoyama Gakuin\nUniversity. To protect the privacy of the participants and other gym users, no images of the\nparticipants were taken; only images of the researcher were used to illustrate the experimental\nprocess.\n6.2.2\nResurts\nAfter analyzing the ",
            "mental\nprocess.\n6.2.2\nResurts\nAfter analyzing the experimental results of the 9 volunteers, we statistically divided the classi-\nﬁcation accuracy and counting accuracy based on different volunteers and exercise categories.\nThe ﬁnal results are shown in the ﬁgure below.\n74\nFigure 6.3: Experimental schematic\n75\nFigure 6.4: Results of the experiment for each volunteer\nFrom Figure 6.4, it can be seen that there are certain variations in classiﬁcation accuracy\nand counting accuracy among the differen",
            " accuracy\nand counting accuracy among the different volunteers. Overall, the classiﬁcation accuracy is\ngenerally high, with most volunteers achieving over 90% accuracy. Notably, User7 and User8\nreached 100% classiﬁcation accuracy.\nIn contrast, the counting accuracy shows more ﬂuctuation. Some volunteers, such as User2\nand User6, had relatively low counting accuracy, with values of 63.55% and 63.33%, respectively.\nOn the other hand, User8 achieved the highest counting accuracy at 98.00%.\nThis ind",
            " the highest counting accuracy at 98.00%.\nThis indicates that, while the system performs relatively consistently in movement classi-\nﬁcation, there is still room for improvement in movement counting, especially in optimizing\nperformance for certain individuals.\n76\nFigure 6.5: Results of the experiment for each volunteer\nFrom Figure 6.5, it is evident that there are signiﬁcant differences in both classiﬁcation ac-\ncuracy and counting accuracy across different exercises. The classiﬁcation accuracy",
            "ss different exercises. The classiﬁcation accuracy is generally\nhigh, with most exercises achieving over 88% accuracy. For instance, Machine Bicep Curl and\nMachine Lateral Raise had classiﬁcation accuracies of 92.59% and 92.50%, respectively. How-\never, some exercises, such as Machine Row, had lower classiﬁcation accuracy, with a perfor-\nmance of only 66.67%, the lowest among all exercises.\nThe counting accuracy shows even more variation. Some exercises performed well, such as\nPec Deck Fly and L",
            "ercises performed well, such as\nPec Deck Fly and Lat Pull Down, with counting accuracies of 97.50% and 97.96%, respectively.\nHowever, other exercises, such as Machine Row and Shoulder Press_2, had relatively low count-\ning accuracies of 58.33% and 75.00%, which were noticeably lower compared to other exercises.\nOverall, the system performs well in classiﬁcation and counting for most exercises, but fur-\nther optimization is needed for movements like Machine Row and Shoulder Press_2, especially\nin",
            "ke Machine Row and Shoulder Press_2, especially\nin terms of accuracy. This could involve adjusting feature extraction methods or algorithm pa-\nrameters to improve performance for these exercises.\nBy observing the volunteers’ movements during the experiment, we identiﬁed several fac-\ntors that could contribute to the decrease in performance, aside from data transmission and\ncomputation accuracy:\n77\n1. Large movement intervals: Due to fatigue, volunteers sometimes took longer breaks be-\ntween exer",
            "nteers sometimes took longer breaks be-\ntween exercises, which may have impacted state recognition accuracy.\n2. Insufﬁcient movement range: Volunteers with less ﬁtness experience often performed ex-\nercises with a smaller range of motion, not fully completing the standard movements. This\ncould negatively affect classiﬁcation performance.\n3. Heavy load: When volunteers selected heavier weights, the slower movement speed and\nless noticeable acceleration made it harder for the system to detect peak",
            "ation made it harder for the system to detect peaks, reducing the\neffectiveness of peak detection and affecting both classiﬁcation and counting accuracy.\nThese factors suggest that the variability of users’ movement characteristics in real-world sce-\nnarios could impact the system’s performance. This should be taken into account when opti-\nmizing the algorithm.\n6.3\nSummary\n1. In the ofﬂine Python experiments, the system demonstrated excellent performance in both\nalgorithm recognition accuracy an",
            "formance in both\nalgorithm recognition accuracy and counting performance. Since the ofﬂine experiments di-\nrectly read the dataset and calculated feature values without considering data transmission, the\nresults were highly stable. The classiﬁcation accuracy and counting accuracy reached 96.66%\nand 96.64%, respectively, representing the theoretical maximum performance of the system.\n2. In the ofﬂine experiments on Android devices, we used the same dataset and algorithm but\nsimulated the real dat",
            "e dataset and algorithm but\nsimulated the real data transmission process using the smartwatch. The experimental results\nshowed a slight decrease in both classiﬁcation accuracy and counting accuracy compared to\nthe Python ofﬂine experiments, mainly due to: a) Precision loss during the data transmission\nprocess. b) Subtle differences in ﬂoating-point calculations between the Android and Python\nenvironments.\nDespite these challenges, by optimizing the transmission logic and using Python scripts for",
            "he transmission logic and using Python scripts for\nfeature computation, the system performance remained at a high level, with classiﬁcation ac-\ncuracy and counting accuracy reaching 95.03% and 88%, respectively, which is still close to the\nPython experiment results.\n3. In the real-world Android experiment, where volunteers performed actual ﬁtness move-\nments, the results showed a further decrease in classiﬁcation and counting accuracy compared\nto the ofﬂine experiments. The main issues were: a) ",
            " the ofﬂine experiments. The main issues were: a) Some exercises (e.g., Machine Row and\n78\nShoulder Press_2) exhibited lower classiﬁcation and counting accuracy. b) Movements with\nshorter durations or smaller changes in acceleration were more prone to misclassiﬁcation.\nThese declines in performance were not only due to data transmission and computational\nenvironment differences but were also inﬂuenced by practical factors: i. Volunteers experienced\nfatigue, leading to longer movement intervals, ",
            "ed\nfatigue, leading to longer movement intervals, which affected state recognition. ii. Less expe-\nrienced volunteers did not fully complete standard movements, resulting in reduced classiﬁca-\ntion performance. iii. When volunteers selected heavier weights, movements became slower,\nand acceleration became less noticeable, which impacted the peak detection algorithm.\nThe ﬁnal results showed a classiﬁcation accuracy of 86.11% and counting accuracy of 81.42%.\n79\nChapter 7\nFuture work\nTo further enh",
            "of 81.42%.\n79\nChapter 7\nFuture work\nTo further enhance the performance and applicability of the SmartWT system, future re-\nsearch will focus on the following improvements and expansions:\n1. Increasing Data Types\nThe current system primarily uses three-axis acceleration data for activity state recognition\nand classiﬁcation. However, to improve the algorithm’s robustness and ability to recognize\ncomplex movements, we plan to incorporate additional data types, such as angular veloc-\nity. During pra",
            "data types, such as angular veloc-\nity. During practical testing, we also measured the system’s runtime and found that there is\nstill considerable computation time available. Therefore, expanding the types of data used\nwill enhance the system ’s ability to capture posture changes and improve classiﬁcation\nand counting performance for various ﬁtness activities.\n2. Using Dynamic Length Sliding Windows\nCurrently, the system uses ﬁxed-length sliding windows to process the data, which may\nnot be well",
            "windows to process the data, which may\nnot be well-suited to the rhythm differences in movements among different users. In the\nfuture, we plan to explore methods for dynamic length sliding windows that will adap-\ntively adjust the window length based on the user ’s actual movement characteristics. This\napproach will better capture personalized movement patterns, enhancing the system ’s\napplicability to a wider range of users.\n3. Improving Long-Term Feedback Mechanisms\nThe current system design f",
            "rm Feedback Mechanisms\nThe current system design focuses on real-time activity recognition and counting. How-\never, the impact of long-term ﬁtness behavior on users has not been thoroughly explored.\nFuture work will improve the long-term feedback system by analyzing users ’historical\n80\nﬁtness data to provide personalized suggestions and motivational incentives. Additionally,\nwe will integrate gamiﬁcation features, such as achievement systems and ranking mecha-\nnisms, to further investigate the ",
            " ranking mecha-\nnisms, to further investigate the role of long-term feedback in promoting user engagement\nand cultivating ﬁtness habits.\n81\nAcknowledgments\nThis thesis would not have been possible without the support of many people, and I would\nlike to express my deepest gratitude.\nFirst, I sincerely thank my supervisor, Prof. G. Lopez, for his tremendous support and for\ngiving me the opportunity to study and research here. His guidance went beyond academic\nmatters, providing me with encourageme",
            "nd academic\nmatters, providing me with encouragement in university life and career development after grad-\nuation. I have learned a lot from him―not only in research but also about food, culture, leader-\nship, and kindness. I have decided to continue my studies in the Lopez Laboratory as a doctoral\nstudent and hope to contribute even more in the future.\nI would also like to express my gratitude to Prof. Y. Tobe, who guided me in interacting with\nother researchers during conferences and presentat",
            "other researchers during conferences and presentations, and who provided valuable insights for\nmy research. Additionally, I am very grateful to Okuma-san from the Lopez Laboratory. She has\nnot only helped me with research but also supported me in daily life, which has been especially\nmeaningful as an international student.\nI feel proud to be part of the Lopez Laboratory. Since joining, I have received great support\nfrom everyone. They have helped me with research, daily life, and even improving ",
            " me with research, daily life, and even improving my Japanese,\nallowing me to gradually feel at home and contribute to the lab. I would also like to acknowl-\nedge the rapid development of artiﬁcial intelligence, which has greatly improved my research\nefﬁciency and allowed me to explore even more knowledge.\nLastly, none of this would have been possible without the support and encouragement of my\nparents and family.\nThank you all!\nJanuary 30th, 2025\nLiu Zeyu\n82\nReferences\n[1] W. R. Thompson, “Worl",
            "5\nLiu Zeyu\n82\nReferences\n[1] W. R. Thompson, “Worldwide Survey of Fitness Trends for 2023,” ACSM’s Health & Fitness\nJournal, vol. 27, no. 1, pp. 9–18, Dec. 2023, doi: 10.1249/ﬁt.0000000000000834.\n[2] G. Di Martino et al., “Enhancing Behavioural Changes: A Narrative Review on the Effective-\nness of a Multifactorial APP-Based Intervention Integrating Physical Activity,” International\nJournal of Environmental Research and Public Health, vol. 21, no. 2, Art. no. 2, Feb. 2024,\ndoi: 10.3390/ijerph2102",
            " 2, Art. no. 2, Feb. 2024,\ndoi: 10.3390/ijerph21020233.\n[3] F. Ozdamli and F. Milrich, “Positive and Negative Impacts of Gamiﬁcation on the Fitness\nIndustry,” European Journal of Investigation in Health, Psychology and Education, vol. 13,\nno. 8, Art. no. 8, Aug. 2023, doi: 10.3390/ejihpe13080103.\n[4] I. Cho, K. Kaplanidou, and S. Sato, “Gamiﬁed Wearable Fitness Tracker for Physical Activity:\nA Comprehensive Literature Review,” Sustainability, vol. 13, no. 13, Art. no. 13, Jan. 2021,\ndoi: 10.3390",
            ". 13, no. 13, Art. no. 13, Jan. 2021,\ndoi: 10.3390/su13137017.\n[5] “The Role of Steps and Game Elements in Gamiﬁed Fitness Tracker Apps: A Systematic Re-\nview,” Accessed: Jan. 31, 2025. [Online]. Available: https://www.mdpi.com/2414-4088/\n5/2/5.\n[6] H. Xie, A. Watatani, and K. Miyata, “CoreUI: Interactive Core Training System with 3D Hu-\nman Shape,” arXiv preprint arXiv:2106.09196, 2021. [Online]. Available: https://arxiv.\norg/abs/2106.09196\n[7] Y. Wu, A. Kankanhalli, and K. Huang, “Gamiﬁcation ",
            "Y. Wu, A. Kankanhalli, and K. Huang, “Gamiﬁcation in Fitness Apps: How Do Leaderboards\nInﬂuence Exercise?,” in ICIS 2015 Proceedings, 2015, no. 14. [Online]. Available: https:\n//aisel.aisnet.org/icis2015/proceedings/IShealth/14\n[8] R. Gal, A. M. May, E. J. van Overmeeren, M. Simons, and E. M. Monninkhof, “The Effect\nof Physical Activity Interventions Comprising Wearables and Smartphone Applications on\nPhysical Activity: A Systematic Review and Meta-analysis,” Sports Medicine – Open, vol. 4,\nno. ",
            "ta-analysis,” Sports Medicine – Open, vol. 4,\nno. 1, p. 42, 2018. doi: https://doi.org/10.1186/s40798-018-0157-9\n83\n[9] E. Southcott and J. Jooste, “Unveiling the Impact of Mobile Fitness Applications on Motiva-\ntional Orientation in Sustaining Exercise Behaviors: A Qualitative Investigation,” Physical\nCulture and Sport. Studies and Research, vol. 103, 2023. doi: 10.2478/pcssr-2024-0008.\n[10] D. Jin, H. Halvari, N. Maehle, and A. H. Olafsen, “Self-tracking behaviour in physical ac-\ntivity: a sys",
            "f-tracking behaviour in physical ac-\ntivity: a systematic review of drivers and outcomes of ﬁtness tracking,” Behaviour & In-\nformation Technology, vol. 41, no. 2, pp. 242–261, 2020. doi: https://doi.org/10.1080/\n0144929X.2020.1801840.\n[11] B. Soulé, G. Marchant, and R. Verchère, “Sport and ﬁtness app uses: a review of humanities\nand social science perspectives,” European Journal for Sport and Society, vol. 19, no. 2, pp.\n170–189, 2021. doi: https://doi.org/10.1080/16138171.2021.1918896.\n[12] A.",
            "s://doi.org/10.1080/16138171.2021.1918896.\n[12] A. Schneider and R. Arnold, “Wearables from head to toe: Are they friend or foe? An empiri-\ncal landscaping of health and ﬁtness wearables and apps in six countries to identify emerg-\ning policy challenges,” Jul. 31, 2022. [Online]. Available: https://ssrn.com/abstract=\n4177215 or http://dx.doi.org/10.2139/ssrn.4177215.\n[13] “RepCount,” [Online]. Available: https://www.repcountapp.com/. Accessed: 2024.\n[14] “Strong Workout Tracker Gym Log,” [Online",
            "24.\n[14] “Strong Workout Tracker Gym Log,” [Online]. Available: https://www.strong.app/. Ac-\ncessed: 2024.\n[15] H. Xie, A. Watatani, and K. Miyata, “CoreUI: Interactive Core Training System with 3D Hu-\nman Shape,” arXiv preprint arXiv:2106.09196, 2021. [Online]. Available: https://arxiv.\norg/abs/2106.09196.\n[16] M. Pasula and P. Saha, “Video-based exercise classiﬁcation and muscle group activa-\ntion prediction using hybrid X3D-SlowFast network,” arXiv preprint arXiv:2406.06703, Jun.\n2024. [Onlin",
            "arXiv preprint arXiv:2406.06703, Jun.\n2024. [Online]. Available: https://arxiv.org/abs/2406.06703.\n[17] I. U. Khan, S. Afzal, and J. W. Lee, “Human activity recognition via hybrid deep learning\nbased model,” Sensors, vol. 22, no. 1, Art. no. 1, Jan. 2022. doi: https://doi.org/10.3390/\ns22010323.\n[18] S. K. Chaurasia and S. R. N. Reddy, “State-of-the-art survey on activity recognition and clas-\nsiﬁcation using smartphones and wearable sensors,” Multimedia Tools and Applications,\nvol. 81, pp. 1077",
            "ltimedia Tools and Applications,\nvol. 81, pp. 1077–1108, 2022. doi: https://doi.org/10.1007/s11042-021-11410-0.\n[19] S. Chung, J. Lim, K. J. Noh, G. Kim, and H. Jeong, “Sensor data acquisition and multimodal\nsensor fusion for human activity recognition using deep learning,” Sensors, vol. 19, no. 7,\nArt. no. 7, Jan. 2019. doi: https://doi.org/10.3390/s19071716.\n84\n[20] D. Morris, T. S. Saponas, A. Guillory, and I. Kelner, “RecoFit: using a wearable sensor to\nﬁnd, recognize, and count repetitive e",
            "e sensor to\nﬁnd, recognize, and count repetitive exercises,” in Proceedings of the SIGCHI Conference\non Human Factors in Computing Systems (CHI ’14), New York, NY, USA: Association for\nComputing Machinery, 2014, pp. 3225–3234. doi: https://doi.org/10.1145/2556288.\n2557116.\n[21] C. Shen, B. -J. Ho, and M. Srivastava, “MiLift: Efﬁcient smartwatch-based workout tracking\nusing automatic segmentation,” IEEE Transactions on Mobile Computing, vol. 17, no. 7, pp.\n1609–1622, Jul. 2018. doi: https://doi.o",
            "o. 7, pp.\n1609–1622, Jul. 2018. doi: https://doi.org/10.1109/TMC.2017.2775641.\n[22] A. Soro, G. Brunner, S. Tanner, and R. Wattenhofer, “Recognition and repetition count-\ning for complex physical exercises with deep learning,” Sensors, vol. 19, p. 714, 2019. doi:\nhttps://doi.org/10.3390/s19030714.\n[23] K. Skawinski, F. Montraveta Roca, R. D. Findling, and S. Sigg, “Workout type recognition\nand repetition counting with CNNs from 3D acceleration sensed on the chest,” in Advances\nin Computational I",
            "nsed on the chest,” in Advances\nin Computational Intelligence. IWANN 2019, I. Rojas, G. Joya, and A. Catala, Eds. Cham:\nSpringer, 2019, vol. 11506, Lecture Notes in Computer Science. doi: https://doi.org/10.\n1007/978-3-030-20521-8_29.\n[24] S. Ishii, A. Yokokubo, M. Luimula, and G. Lopez, “ExerSense: Physical exercise recognition\nand counting algorithm from wearables robust to positioning,” Sensors, vol. 21, p. 91, 2021.\ndoi: https://doi.org/10.3390/s21010091.\n[25] A. Dehghani, O. Sarbishei, T. G",
            "90/s21010091.\n[25] A. Dehghani, O. Sarbishei, T. Glatard, and E. Shihab, “A quantitative comparison of overlap-\nping and non-overlapping sliding windows for human activity recognition using inertial\nsensors,” Sensors, vol. 19, p. 5026, 2019. doi: https://doi.org/10.3390/s19225026.\n[26] V. A. Cornelissen, R. H. Fagard, E. Coeckelberghs, and L. Vanhees, “Impact of resistance\ntraining on blood pressure and other cardiovascular risk factors,” Hypertension, vol. 58,\nno. 5, pp. 950–958, Nov. 2011. doi",
            "nsion, vol. 58,\nno. 5, pp. 950–958, Nov. 2011. doi: https://doi.org/10.1161/HYPERTENSIONAHA.111.\n177071.\n[27] J. Kristensen and A. Franklyn-Miller, “Resistance training in musculoskeletal rehabilitation:\na systematic review,” British Journal of Sports Medicine, vol. 46, no. 10, pp. 719–726, Aug.\n2012. doi: https://doi.org/10.1136/bjsm.2010.079376.\n[28] A. H. E. Akpa, M. Fujiwara, H. Suwa, Y. Arakawa, and K. Yasumoto, “A smart glove to track\nﬁtness exercises by reading hand palm,” Journal of Sens",
            "s exercises by reading hand palm,” Journal of Sensors, vol. 2019, no. 1, p. 9320145,\n2019. doi: https://doi.org/10.1155/2019/9320145.\n85\n[29] W.-Y. Chung, A. Purwar, and A. Sharma, “Frequency domain approach for activity classi-\nﬁcation using accelerometer,” in 2008 30th Annual International Conference of the IEEE\nEngineering in Medicine and Biology Society, Aug. 2008, pp. 1120–1123. doi: https://doi.\norg/10.1109/IEMBS.2008.4649357.\n[30] D. Jayakumar, M. Krishnaiah, S. Kollem, S. Peddakrishna, N",
            "umar, M. Krishnaiah, S. Kollem, S. Peddakrishna, N. Chandrasekhar, and M. Thiru-\npathi, “Emergency vehicle classiﬁcation using combined temporal and spectral audio fea-\ntures with machine learning algorithms,” Electronics, vol. 13, no. 19, Art. no. 19, Jan. 2024.\ndoi: https://doi.org/10.3390/electronics13193873.\n[31] K. Bhangale and M. Kothandaraman, “Speech emotion recognition based on multiple\nacoustic features and deep convolutional neural network,” Electronics, vol. 12, no. 4, Art.\nno. 4, Ja",
            "work,” Electronics, vol. 12, no. 4, Art.\nno. 4, Jan. 2023. doi: https://doi.org/10.3390/electronics12040839.\n[32] W.-Y. Chung, A. Purwar, and A. Sharma, “Frequency domain approach for activity classi-\nﬁcation using accelerometer,” in 2008 30th Annual International Conference of the IEEE\nEngineering in Medicine and Biology Society, Aug. 2008, pp. 1120–1123. doi: https://doi.\norg/10.1109/IEMBS.2008.4649357.\n[33] O. D. Lara and M. A. Labrador, “A Survey on Human Activity Recognition using Wearable\n",
            "rvey on Human Activity Recognition using Wearable\nSensors,” IEEE Communications Surveys & Tutorials, vol. 15, no. 3, pp. 1192–1209, 2013.\ndoi: https://doi.org/10.1109/SURV.2012.110112.00192.\n[34] M. Wang et al., “A comprehensive evaluation of dual-polarimetric Sentinel-1 SAR data for\nmonitoring key phenological stages of winter wheat,” Remote Sensing, vol. 16, no. 10, Art.\nno. 10, Jan. 2024. doi: https://doi.org/10.3390/rs16101659.\n[35] E. C. Ketola, M. Barankovich, S. Schuckers, A. Ray-Dowling,",
            "ola, M. Barankovich, S. Schuckers, A. Ray-Dowling, D. Hou, and M. H. Imtiaz,\n“Channel reduction for an EEG-based authentication system while performing motor\nmovements,” Sensors, vol. 22, no. 23, Art. no. 23, Jan. 2022. doi: https://doi.org/10.\n3390/s22239156.\n[36] W.-Y. Chung, A. Purwar, and A. Sharma, “Frequency domain approach for activity classi-\nﬁcation using accelerometer,” in 2008 30th Annual International Conference of the IEEE\nEngineering in Medicine and Biology Society, Aug. 2008, pp. ",
            "g in Medicine and Biology Society, Aug. 2008, pp. 1120–1123. doi: https://doi.\norg/10.1109/IEMBS.2008.4649357.\n[37] Y. Meng, N. Yang, Z. Qian, and G. Zhang, “What makes an online review more help-\nful: An interpretation framework using XGBoost and SHAP values,” Journal of Theoret-\nical and Applied Electronic Commerce Research, vol. 16, no. 3, Art. no. 3, Jun. 2021. doi:\nhttps://doi.org/10.3390/jtaer16030029.\n86\n[38] S. Knapiˇc, A. Malhi, R. Saluja, and K. Främling, “Explainable artiﬁcial intelli",
            "a, and K. Främling, “Explainable artiﬁcial intelligence for hu-\nman decision support system in the medical domain,” Machine Learning and Knowl-\nedge Extraction, vol. 3, no. 3, Art. no. 3, Sep. 2021. doi: https://doi.org/10.3390/\nmake3030037.\n[39] M. A. Khan et al., “Smart Android Based Home Automation System Using Internet of Things\n(IoT),” Sustainability, vol. 14, no. 17, Art. no. 17, Jan. 2022. doi: https://doi.org/10.\n3390/su141710717.\n[40] R. Luque, E. Casilari, M.-J. Morón, and G. Redondo, ",
            " Luque, E. Casilari, M.-J. Morón, and G. Redondo, “Comparison and characterization of\nAndroid-based fall detection systems,” Sensors, vol. 14, no. 10, Art. no. 10, Oct. 2014. doi:\nhttps://doi.org/10.3390/s141018543.\n[41] A. R. Anwary, H. Yu, and M. Vassallo, “An automatic gait feature extraction method for iden-\ntifying gait asymmetry using wearable sensors,” Sensors, vol. 18, no. 2, Art. no. 2, Feb. 2018.\ndoi: https://doi.org/10.3390/s18020676.\n[42] R.-A. Voicu, C. Dobre, L. Bajenaru, and R.-I.",
            "[42] R.-A. Voicu, C. Dobre, L. Bajenaru, and R.-I. Ciobanu, “Human physical activity recognition\nusing smartphone sensors,” Sensors, vol. 19, no. 3, Art. no. 3, Jan. 2019. doi: https://doi.\norg/10.3390/s19030458.\n[43] T. R. Mauldin, M. E. Canby, V. Metsis, A. H. H. Ngu, and C. C. Rivera, “SmartFall: A\nsmartwatch-based fall detection system using deep learning,” Sensors, vol. 18, no. 10, Art.\nno. 10, Oct. 2018. doi: https://doi.org/10.3390/s18103363.\n[44] S. Chung, J. Lim, K. J. Noh, G. Kim, and ",
            "63.\n[44] S. Chung, J. Lim, K. J. Noh, G. Kim, and H. Jeong, “Sensor data acquisition and multimodal\nsensor fusion for human activity recognition using deep learning,” Sensors, vol. 19, no. 7,\nArt. no. 7, Jan. 2019. doi: https://doi.org/10.3390/s19071716.\n[45] R. Szabo, “Implementing computer vision in Android apps and presenting the background\ntechnology with mathematical demonstrations,” Technologies, vol. 13, no. 1, Art. no. 1, Jan.\n2025. doi: https://doi.org/10.3390/technologies13010027.\n[46]",
            "https://doi.org/10.3390/technologies13010027.\n[46] A. Sehgal and N. Kehtarnavaz, “Guidelines and benchmarks for deployment of deep learn-\ning models on smartphones as real-time apps,” Machine Learning and Knowledge Extrac-\ntion, vol. 1, no. 1, Art. no. 1, Mar. 2019. doi: https://doi.org/10.3390/make1010027.\n[47] A. Ghaffari and Y. Savaria, “CNN2Gate: An implementation of convolutional neural net-\nworks inference on FPGAs with automated design space exploration,” Electronics, vol. 9,\nno. 12, Art.",
            "ce exploration,” Electronics, vol. 9,\nno. 12, Art. no. 12, Dec. 2020. doi: https://doi.org/10.3390/electronics9122200.\n87\n[48] Google, “Data Layer API Overview,” Android Developers. Available: https://developer.\nandroid.com/training/wearables/data/overview. [Accessed: 08-Jan-2025].\n[49] ONNX Runtime Developers, ONNX Runtime, 2021. [Online]. Available:\nhttps://\nonnxruntime.ai/. [Accessed: Jan. 29, 2025].\n88\n質疑応答\n戸辺　義人　情報テクノロジー学科　教授\nQ\nリアルタイムというのがあいまいですが，本研究におけるリアルタイムとは？\nA\nご質問ありがとうございます．本研究における「リアル",
            "まいですが，本研究におけるリアルタイムとは？\nA\nご質問ありがとうございます．本研究における「リアルタイム」とは、スマートウォッ\nチで収集した加速度データをスマートフォンに送信し、TLSW（三層スライディング\nウィンドウ）アルゴリズムを用いて即時に処理し、運動状態の識別、運動種別の分\n類、および回数のカウントを行うことを指します。\n浦垣　啓志郎　情報テクノロジー学科　助手\nQ\nPython とAndroid の誤差は利用しているライブラリなどの影響を確認しましたか？\nA\nご質問ありがとうございます．本研究ではPython 環境とAndroid 環境の違いによ\nる誤差を確認し、特にフーリエ変換や特徴量計算の精度統一のためにChaquopy を\n導入し、Python スクリプトを直接実行することで誤差を最小限に抑えました。\n89\n"
        ]
    },
    {
        "id": "paper_13",
        "filename": "M2024_Sae_Ohkubo.pdf",
        "title": "M2024_Sae_Ohkubo",
        "fulltext": "青  山  学  院  大  学 \n理  工  学  研  究  科 \n理工学専攻 \n知能情報 \nコース\n修  士  論  文 \n学 生 番 号\n35623218\n氏 \n名\n大久保　紗恵\n研究指導教員\nロペズ ギヨーム\nChewker\nネックレス型デバイスを用いた\n食習慣改善システム\n大久保紗恵\n2025/01/31\nAcademic Year of 2024, Submitted on January 31st, 2025 \n \nGraduate School of Science and Engineering, Aoyama Gakuin University \n \nTitle: Chewker: Eating Habit Improvement System using Necklace-type Device \n \nStudent Name: Sae Ohkubo \nID Number: 35623218   \nDegree: Master of Engineering \nCourse: Intelligence and Information \nThesis Advisor: Professor Guillaume Lopez \n \nAbstract  \n Obesity may lead to lifestyle diseases such as diabetes and high blood pressure. Eating \nslowly and chewing well is essential to prevent obesity. Past studies revealed that \nconversation during the meal is related to health. So, increasing conversation during \nthe meal is desirable. On the other hand, presenting information to eaters, such as \nchewing count in real-time, prevents them from eating too fast and improves their \nconsciousness of eating activity. \nThis study developed Chewker, a system that detects eating behaviors in real time and \nprovides feedback. Chewker combines two parts: a necklace-type device equipped with \nan IMU sensor, a piezo film sensor, an ultrasonic sensor to detect feeding, chewing, and \nswallowing, and a smartphone application that uses the microphone to detect talking \nand provide feedback. Since slow music has been shown to promote slower eating and \nincrease chewing count, Chewker dynamically adjusts music playback speed in real-\ntime based on chewing count and interval, slowing to 0.5x when these values fall below \na threshold and returning to normal speed when they meet the criteria. After meals, the \nsystem provides feedback on various metrics, including total chewing count, chewing \ninterval, and meal duration, storing data for long-term behavior tracking.  \nEvaluation of Chewker accuracy with 15 subjects showed high F1-scores of 0.84 for \nchewing and 0.83 for feeding detection but a lower F1-score of 0.64 for swallowing, \nhighlighting the challenge of distinguishing swallowing from chewing remains. \nAn evaluation with 11 subjects showed that real-time feedback increased total meal \nduration for all subjects, total chewing count and chewing count per swallowing for 10 \nsubjects, and chewing interval for eight subjects. Seven subjects showed a decrease in \nchewing count per feeding, but their feeding count increased, suggesting smaller bites \nand more frequent food intake. However, talking time decreased for many subjects, \nlikely due to increased focus on chewing. The pre-experiment survey indicated that 10 \nsubjects did not usually pay attention to chewing, but all reported greater awareness \nafter using the system. \nFuture work includes long-term evaluation of real-time feedback effects, improvements \nin swallowing detection through enhanced calibration and design, and modifications to \nimprove ease of use and comfort. Adding feedback to promote conversation will also be \nconsidered. \n理工学専攻修士論文要旨 \n \n \n提出年度\n      ： 2024 年度 \n提\n出\n日\n      ： 2025 年 1 月 31 日 \n専修コース： 知能情報 コース \n学生番号\n      ： 35623218 \n学生氏名\n      ： 大久保 紗恵 \n研究指導教員： ロペズ ギヨーム 教授 \n \n（論文題目） \n \nChewker ネックレス型デバイスを用いた食習慣改善システム \n \n（内容の要旨） \n肥満は生活習慣病を引き起こす恐れがある．早食いの人ほどBMI が高い傾向があり，ゆっくりよく\n噛んで食べることが肥満を予防するために重要である．また食事中の会話は健康に関連があることが分\nかっており，食事中の会話を増やすことが望ましい．さらに，リアルタイムで咀嚼回数などの食事に関\nする情報を食事者に提示することにより，早食いを防ぎ，食事行動に対する意識の改善を促すことが期\n待できる． \n以上より本研究の目的は，食事行動の定量化によって食習慣に基づく食事中の行動への意識改善を行\nうことである．研究目的の達成のために，自然な食事環境下でリアルタイムに食事行動を検出し，検出\nされた食事行動に基づいたフィードバックを行うシステム (Chewker) を提案する．Chewker は慣性セ\nンサ，ピエゾフィルム，超音波センサが搭載されたネックレス型デバイス，およびスマートフォンのマ\nイクの4 つを用いてリアルタイムに食事行動を検出する．検出する食事行動は摂食・咀嚼・嚥下・発話\nの4 種類である．ゆっくりとした音楽は咀嚼のペースを下げて，咀嚼回数，食事時間を増加させること\nから，リアルタイムでのフィードバックは音楽を利用する．嚥下のタイミングで，前回の嚥下からの咀\n嚼回数と咀嚼ペースの平均を算出し，どちらか一方，もしくは両者とも基準値に満たない場合，音楽が\n0.5 倍速になり，両条件が満たされた場合は1.0 倍速に戻る．食事終了後には，摂食・咀嚼・嚥下の回\n数，および，摂食間・嚥下間の咀嚼回数の平均，咀嚼ペースの平均，総食事時間，総食事時間に対する\n会話時間の割合をもとに食事全体に対するフィードバックを表示する．食事データは保存され，いつで\nも振り返りを可能にし，可視化した過去の推移を確認できる． \nまず，Chewker の食事行動検出精度を評価した．被験者15 名に，ピーナッツを口に運び，20 回咀嚼\nして1 回嚥下するという一連の動作を3 回計測した．咀嚼のF1 値は0.84 と高い精度を示し，摂食も\n0.83 と安定した精度で検出できることが確認された．一方で，嚥下のF1 値は0.64 と他の行動に比べて\n精度が低く，咀嚼との誤検出が課題として挙げられた． \n次に，Chewker の有用性をリアルタイムフィードバックの側面から検証するために，被験者11 人に\n対し評価実験を行った．Chewker のリアルタイムフィードバック機能ありとなしのそれぞれの状態で\n同じお弁当を，日にちを変えて合計2 回食べ，総食事時間・総咀嚼回数・摂食間・嚥下間の咀嚼回数，\n咀嚼ペース，会話時間の6 項目の数値の変化を評価した．結果，Chewker の利用により，総食事時間に\nおいて全員が，総咀嚼回数・嚥下間の咀嚼回数において10 名，咀嚼ペースにおいて8 名の数値が上昇\nした．摂食間の咀嚼回数においては7 名の被験者で減少が見られたが，この7 名は摂食回数が増加して\nいるため，一口あたりの食べ物の量が減少し，口に運ぶ回数が増えたことが考えられるため，良い変化\nと言える．会話時間の割合は減少している被験者が多く，リアルタイムフィードバックにより，会話よ\nりも咀嚼に意識していると考える．事前アンケートでは「普段の食事で噛むことを意識していない」と\n回答した被験者が10 名いたが，実験後には全員が「噛むことを意識した」と回答し，食事行動への意\n識の改善が明らかになった． \n今後は，長期間の使用によるフィードバック効果検証を実施したい．また嚥下の検出精度に課題が残\nるため，キャリブレーションの改良や，デバイスの設計の見直しを検討したい．アンケートで「デバイ\nスの装着が難しい」，「首が苦しい」という意見が寄せられたため，より簡単に装着でき，快適に使用で\nきるよう改善する．さらに発話を促すリアルタイムフィードバックの追加を検討したい． \n \n \n青山学院大学大学院理工学研究科 \n目次\n第1 章\n序論\n3\n1.1\n研究背景. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n3\n1.1.1\n肥満者の増加. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n3\n1.1.2\n肥満と咀嚼の関係. . . . . . . . . . . . . . . . . . . . . . . . . . . .\n4\n1.1.3\n食事行動と食事中の音楽の関係. . . . . . . . . . . . . . . . . . . .\n5\n1.1.4\n肥満と食事中の会話の関係. . . . . . . . . . . . . . . . . . . . . . .\n6\n1.1.5\n食事行動認識の必要性. . . . . . . . . . . . . . . . . . . . . . . . .\n6\n1.2\n研究目的. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n7\n1.3\n本論文の構成. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n7\n第2 章\n食事行動検出についての関連研究\n8\n2.1\n食事行動検出・分類手法に関する研究\n. . . . . . . . . . . . . . . . . . . .\n8\n2.2\n食事行動に関するフィードバックを用いた研究. . . . . . . . . . . . . . . .\n13\n2.3\n関連研究についてのまとめ. . . . . . . . . . . . . . . . . . . . . . . . . . .\n16\n第3 章\nChewker: 食習慣改善システム\n19\n3.1\nシステムの概要. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n19\n3.2\nネックレス型デバイスとスマートフォンの連携. . . . . . . . . . . . . . . .\n22\n3.3\nChewker の利用手順\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n24\n3.4\n食事行動検出のアルゴリズム\n. . . . . . . . . . . . . . . . . . . . . . . . .\n31\n3.4.1\n発話検出. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n33\n3.4.2\n摂食検出. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n34\n3.4.3\n咀嚼と嚥下の検出. . . . . . . . . . . . . . . . . . . . . . . . . . . .\n36\n3.5\n咀嚼と嚥下の検出. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n36\n3.6\nフィードバックシステムの概要\n. . . . . . . . . . . . . . . . . . . . . . . .\n38\n3.6.1\nフィードバック内容\n. . . . . . . . . . . . . . . . . . . . . . . . . .\n38\n3.6.2\n音楽を用いたリアルタイムフィードバック. . . . . . . . . . . . . .\n40\n3.6.3\n食事直後の視覚的フィードバック. . . . . . . . . . . . . . . . . . .\n44\n3.6.4\n過去のデータ参照の視覚的フィードバック. . . . . . . . . . . . . .\n53\n第4 章\nChewker の食事行動検出精度評価実験\n57\n4.1\n食事行動検出精度実験概要. . . . . . . . . . . . . . . . . . . . . . . . . . .\n57\n4.2\n食事行動検出精度実験手順. . . . . . . . . . . . . . . . . . . . . . . . . . .\n57\n4.3\n食事行動検出精度実験結果. . . . . . . . . . . . . . . . . . . . . . . . . . .\n57\n4.3.1\n摂食の検出精度. . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n60\n4.3.2\n咀嚼の検出精度. . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n61\n1\n4.3.3\n嚥下の検出精度. . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n62\n第5 章\nChewker のフィードバック効果検証\n63\n5.1\nフィードバック効果検証概要\n. . . . . . . . . . . . . . . . . . . . . . . . .\n63\n5.2\nフィードバック効果検証手順\n. . . . . . . . . . . . . . . . . . . . . . . . .\n63\n5.2.1\n事前アンケート. . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n65\n5.2.2\nSUS アンケート. . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n67\n5.2.3\nChewker についてのアンケート. . . . . . . . . . . . . . . . . . . .\n67\n5.3\nフィードバック効果検証結果\n. . . . . . . . . . . . . . . . . . . . . . . . .\n70\n5.3.1\n全体の食事時間の結果. . . . . . . . . . . . . . . . . . . . . . . . .\n70\n5.3.2\n全体の咀嚼回数の結果. . . . . . . . . . . . . . . . . . . . . . . . .\n71\n5.3.3\n摂食間の咀嚼回数の結果. . . . . . . . . . . . . . . . . . . . . . . .\n73\n5.3.4\n嚥下間の咀嚼回数の結果. . . . . . . . . . . . . . . . . . . . . . . .\n76\n5.3.5\n咀嚼ペースの結果. . . . . . . . . . . . . . . . . . . . . . . . . . . .\n78\n5.3.6\n会話時間の結果. . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n79\n5.3.7\nSUS スコア結果. . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n81\n5.3.8\n実験前後のアンケート結果. . . . . . . . . . . . . . . . . . . . . . .\n82\n第6 章\n結論\n87\n6.1\nまとめ. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n87\n6.2\n今後の展望\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n88\n謝辞\n89\n参考文献\n90\n付録\n95\n付録A . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n95\n付録B . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n96\n付録C . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n99\n2\n第1章\n序論\n序論では，本研究を実施するに至った背景と研究の目的，本論文の構成について述べる．\n本研究にかかわる社会的背景や技術的背景を述べ，研究の意義について論述する．そのう\nえで本研究で提案する自然な環境下での様々なセンサを用いた食事行動分類によるフィー\nドバックシステムの必要性と利点について述べ，広範囲な研究範囲の中で，本研究がどの\nような位置づけであるかについて説明する．\n1.1\n研究背景\n1.1.1\n肥満者の増加\n世界保健機関ではBMI が25 以上を過体重，30 以上を肥満と定めている．2016 年には\n18 歳以上の39 ％が過体重、13 ％が肥満であったことが分かっており，さらに1975 年以\n降，世界的な肥満の数は約3 倍となっている[1]．また、世界的に見ると低体重でなくな\nるよりも過体重、肥満でなくなっている人の方が多い。肥満は、ほとんどの体のシステム\nに影響を与える病気であり、糖尿病や高血圧などの生活習慣病を引き起こす恐れがある．\n世界的に肥満が増え問題となっている中，日本でも厚生労働省によって対策が講じられて\nきた．日本においてはBMI が25 以上の場合に肥満であると判定されるのだが，肥満の患\n者数は10 年前から減少していないことが示唆されている[2]．図1.1 から肥満者の割合は\n年数に対して大きな変動がないことが分かり，これは肥満者の割合が減少していないこと\nを意味する．\n　\n3\n図1.1: 日本の肥満率の年次推移（[2] をもとに作成）\n1.1.2\n肥満と咀嚼の関係\n咀嚼とは口に取り込んだ食べ物を噛み砕くことである．また，日常生活においては食物\nを飲み込むのに適した性状に噛み砕き，唾液と混ぜる口の働きと定義されている[3]．よ\nく噛むことで唾液が多く分泌され血糖値が早く上がり，その結果，満腹中枢に働くため空\n腹感が満たされる．そのため，肥満の予防にもなる[4]．また，図1.2 より，食べる速さが\n早い人ほどBMI が高い傾向にあることが示されている[5]．これにより，早食いと肥満は\n強い関係にあることが分かる．これらのことから，肥満を予防するためにはゆっくりよく\n噛んで食べることが重要であると考えられる．\n図1.2: 食事速度別のBMI とBMI 上昇率（[5] から引用）\n4\n1.1.3\n食事行動と食事中の音楽の関係\n近年の研究では，食行動は個人の心理的・生理的状態といった内部要因だけでなく，周囲\nの環境要因（照明，色彩，温度，音楽など）にも影響を受けることが示されている．1986\n年の研究[6] では，Milliman は、レストランの客は遅い音楽を聴いているときの方が速い\n音楽を聴いている時よりも食事を終えるのに時間がかかったと結論付けた．\nまた，音楽のテンポが食事行動や感情に与える影響を調査した研究[7] では，遅いテン\nポの音楽を聴きながら食事をした参加者の方が，食事時間，咀嚼回数の合計，咀嚼時間の\n合計がすべて増加したことが確認されている．具体的には，124 人の参加者を対象に，速\nいテンポ（145 BPM）と遅いテンポ（85 BPM）の音楽を聴きながら食事をする2 つのグ\nループに分けて実験を行った．その結果，遅いテンポの音楽を聴いた参加者は，食事時間\nが20 ％増加し，咀嚼回数が約30 ％増加し，総咀嚼時間が約24 ％増加した．さらに，遅\nいテンポの音楽は参加者をより落ち着かせ，平穏な気持ちにさせる効果があることが示さ\nれた．\n音楽の特定の要素，特にテンポとアーティキュレーションが食事時間に与える影響につ\nいて調査した研究[8] では2 つの実験が行われた．実験1 では，テンポとアーティキュレー\nションが異なる2 種類の音楽を用意し，チョコレートの試食と評価を行う際の食事時間を\n測定した．参加者は，自身の食事時間が計測されていることを認識していなかった．その\n結果，遅いテンポかつレガート（slow + legato）の音楽を聴いていた場合，速いテンポ\nかつスタッカート（fast + staccato）の音楽を聴いていた場合と比較して，食事時間が有\n意に長くなることが確認された．実験2 では，テンポとアーティキュレーションの相互作\n用についてより詳細に調査するために，無音の条件を加え，遅いテンポ＋レガート，遅い\nテンポ＋スタッカート，速いテンポ＋レガート，速いテンポ＋スタッカートの計5 つの条\n件を設定した．その結果，テンポには主効果があり，遅いテンポの音楽を聴いていた場合\nのほうが速いテンポの音楽を聴いていた場合よりも食事時間が有意に長くなった．また，\nアーティキュレーションにはテンポとの交互作用が見られ，遅いテンポの音楽を聴いてい\nた場合においてのみ，レガートの音楽を聴いていたときのほうがスタッカートの音楽を聴\nいていたときよりも食事時間が延長されることが示された．一方，速いテンポの音楽条件\nでは，レガートとスタッカートの間に食事時間の有意な差は認められなかった．さらに，\n音楽の存在自体にも主効果が見られ，いずれの音楽条件においても，無音の条件で食事を\nした場合と比較して食事時間が有意に長くなった．これらの結果から，音楽のテンポは食\n5\n事時間を調整する環境要因の一つであり，特に遅いテンポの音楽は食事時間を延長させる\nことが示唆された．加えて，音楽の存在そのものが食事時間を延ばす効果を持つことが示\nされており，これらの知見は，ゆっくり食べることを促進し，過剰摂取を防ぐなど，より\n健康的な食習慣の形成に寄与する可能性がある．\n1.1.4\n肥満と食事中の会話の関係\n近年，家族が揃って食事をする機会が減少し，ひとりで食事をする孤食が問題となって\nいる．岸田らの調査によると，食事中の会話は健康に関連があることが分かっている[9]．\n食事中の家族との会話がある場合，生活習慣が規則正しく，食生活においても野菜をよく\n食べていたり，好き嫌いがないなど，健康状態である割合が高いことが示されたのだ．中\n岡らの調査からは，食事中のコミュニケーションの多さが児童の身体的・精神的健康の項\n目を含む生活全体を捉えたQOL の良好さに関連することが分かった[10]．また，森脇ら\nが女子学生を対象に行った調査結果からは，小学生の頃に食事中に楽しい会話をよくして\nいた学生は健康状態が良い傾向があることが分かった[11]．特に家族での食事中の会話は\n重要である[12, 13, 14]．会話を伴う食事は，家族それぞれの経験を共有する機会となり，\n子どもは食事中の会話を通じてコミュニケーションスキルを身に付けることができる．\n1.1.5\n食事行動認識の必要性\n近年Charge3（Fitbit 製）やwena wrist pro（Sony 製）に代表されるように，市販され\nているウェアラブルデバイスでは一日の消費カロリーの測定ができるため，これに関連し\nた人間の活動レベルをモニタリングすることが可能である．しかし，自由な食事環境での\n食事行動を自動的に検出するデバイス、特に咀嚼とともに嚥下や会話などの複数行動を\n検出するデバイスははまだ市販されている状態にない[15]．また，食事行動の中でも咀嚼\nや発話を高精度に識別可能になり，リアルタイムでの咀嚼回数や会話時間の食事者への提\n示が可能となることで，咀嚼回数の増加や発話意識の向上など，食事に対する意識の改善\nが期待できる．先行研究では，実験室環境において，食事中にリアルタイムで咀嚼回数を\nフィードバックすることで咀嚼回数が増加することが示された[16]．\nさらに食事の時間を楽しく過ごすためのテクノロジーとしてMeal Chat が開発されてい\nる[17]．これは，大学生が社交的になる機会を提供し，見知らぬ人と食事の時間を共有す\nることへの心理的な壁を低くすることを目的としている．\n6\n1.2\n研究目的\n食事の際の咀嚼回数を検出可能になれば、食事者にリアルタイムで咀嚼回数が少ないこ\nとや早食いであることをフィードバックし，肥満の予防につなげることが可能である．ま\nた，食事中の会話も検出が可能になれば，フィードバックによって食事中の会話の増加を\n期待できる．さらに，咀嚼や嚥下，会話の他に食べ物を口に運ぶ行動である摂食，水分を\n嚥下した量など，より詳細な食事行動を識別することが可能になれば，食事者の健康促進\nに貢献できると考える．以上から本研究では、自然な食事環境下でのより詳細な食事行動\nの定量化とフィードバックによる食事行動への意識改善を目的とする．具体的な目的は以\n下の2 点である．\n1. 自然な食事環境下での，詳細な食事行動をリアルタイムに検出するシステムの実現．\n2. 検出した食事行動に基づいて，フィードバックを提示することで，食事行動への意\n識改善を行うシステムの開発．\n1.3\n本論文の構成\n第1 章では，序論と題し本論文の研究背景，研究目的，そして本論文の構成について述\nべた．第2 章では，関連研究や関連技術に関して説明する．第3 章では，自然な食事環境\n下での様々なセンサを用いたリアルタイムでの食事行動検出、およびスマートフォンを用\nいた食習慣向上のためのフィードバックシステムついて述べる．第4 章では，食事行動検\n出の精度評価と考察，および，フィードバックシステムの評価と考察を述べる．第5 章で\nは，本論文のまとめと今後の展望について述べる．\n7\n第2章\n食事行動検出についての関連研究\n第2 章では本研究に関する先行研究や技術について述べる．まず，食事行動の検出方法\nや分類方法に関する先行研究について説明する．次に，食事行動に関するフィードバック\nを用いた先行研究を紹介する．最後に，本研究にかかわる研究や技術についてまとめ，先\n行研究での課題をまとめる．\n2.1\n食事行動検出・分類手法に関する研究\nZhang らは，食べ物を咀嚼することをセンシングするために，食事をモニタリングする\nためのスマートグラス「Smart eyewear」を提案した[18]．提案されたスマートグラスは\n図2.1 に示すように，３D プリントで製造され，マイクロコントローラ，EMG 電極を収\n納している．電極の配置を分析し，側頭が電極を配置する際に最適であることが確認され\nた．装着例を図2.2 に示す．咀嚼の検出は，適合率と再現率が80 ％に達した．また，5 種\n類の食品の分類精度は63 ％から84 ％の範囲であった．\n図2.1: 「Smart eyewear」\n（[18] から引用）\n図2.2: 「Smart eyewear」装着イメージ\n（[18] から引用）\nChun らは食事を検出するネックレス型デバイスを提案した[19]．ネックレス型デバイ\nスは，近接センサ（proximity sensor），BLE モジュール，マイクロコントローラ（mi-\n8\ncrocontroller）からなるウェアラブルデバイスである．図2.3 にデバイスを，図2.4 に装\n着例を示す．近接センサは顎骨（jawbone）までの距離から動きを捉え，食事行動と非食\n事行動を区別する．実験環境では，食事行動の検出が適合率（precision）91.2 ％，再現率\n（recall）92.6 ％と良い結果を示したが，自然な環境では適合率78.2 ％，再現率72.5 ％と，\n実験環境に比べて10 ％以上劣る結果となった．自然な環境での結果が実験環境と比べて\n劣る原因として，バドミントンやスケートボード（badminton and skateboarding）など\nのスポーツをしたことでデバイスが動き，センサが顎を捉えられなくなったことなどが挙\nげられている．\n図2.3: Chun らが提案する\nネックレス型デバイス\n（[19] から引用）\n図2.4: デバイス装着イメージ\n（[19] から引用）\nZhang らは食事行動検出のためのマルチセンサネックレス「NeckSense」を開発した[20]．\nネックレス型デバイスは近接センサ，環境光センサ，慣性計測ユニット（IMU）センサを\n内蔵している．近接センサでデバイスと着用者の顎の距離を計測することで咀嚼行動を検\n出し，環境光センサで着用者が食物を口に運ぶ摂食行動を捉える．また，IMU センサで\n食事をとる際の前傾姿勢の動きを捉える．システム概要を図2.5 に示す．このシステムで\nF1 値73.7 ％の咀嚼検出精度，77.1 ％の自然環境下での食事エピソード検出を達成した．\n9\n図2.5: マルチセンサネックレス「NeckSense」概要\n（[20] から引用）\nChun らは，口腔内用1 センチ未満のワイヤレスセンサによる食品種類分類手法を提案し\nている[21]．食べ物摂取時に口腔内の平均の温度変動の範囲を超えることを利用し口腔内\nをセンシングしている．システムはワイヤレス通信が可能であり，温度センサが内蔵され\nているマイクロコントローラー，加速度センサ，バッテリーによって設計されている．セ\nンサの取り付け方法は個人に特化したものとなっており，マウスピースに埋め込むことで\n歯に固定する．図2.6 にセンサと口の中に入れる型を示す．様々な温度やテクスチャの全9\n種類の食品を水分含有率や温度などから5 クラスに設定し分類する．温度に関する特徴量\nのみを用いた場合に77.5 ％の精度，温度と加速度に基づく特徴量を用いた場合に85.0 ％\nの精度を達成した．さらに日常生活における食事の検出はprecision93 ％，recall96 ％と高\nい精度を達成している．\n図2.6: 使用しているセンサとセンサをマウスピースで口腔内に装着した様子\n（[21] から引用）\nAmft らはマイクロフォンを用いた咀嚼音の解析を行った[22]．その結果，耳の内側にマ\n10\nイクロフォンを配置することによって質の高い咀嚼音を取得できることが分かった．99 ％\nの精度で食事の識別ができ，80 ％以上の精度で4 種類の食べ物を分類することができた．\nBi らは，食事行動を自動で認識するウェアラブルデバイス「Auracle」を提案した[23]．\nAuracle はコンタクトマイク，マイクロコントローラ，それらを結ぶアナログ回路が内蔵さ\nれており，コンタクトマイクは耳の後ろ側に配置するよう設計してある．図2.7 にAuracle\nとその装着例を示す．Auracle は自由な生活環境下で，食事行動の検出ができ，92.8 ％の\n精度と77.5 ％のF1 値を達成した．\n図2.7: 「Auracle」の装着イメージ（[23] から引用）\nShuzo らは図2.8 に示した骨伝導マイクロフォン利用したIC レコーダーを用いて食習\n慣分析を行っている[24]．音声データからFFT を用いてパワースペクトルを計算し，そ\nこから得られる最大の周波数などの特徴量を用いて4 つの状態（かたい食べ物を食べて\nいる，柔らかい食べ物を食べている，水を飲んでいる，しゃべっている）（enteing a hard\nfood, eating a soft food, drinking water, speaking）に分類し，各状態に対して80 ％以上\nの分類をすることができた．しかし，解析のためにPC，サンプリングレート44.1kHz の\n骨伝導マイクロフォンを用いているため，手軽に扱うことが難しい．また，日常生活で扱\nうことを考慮するのであれば，Bluetooth 接続した骨伝導マイクロフォンを用いる必要が\n11\nあり，Bluetooth 接続が可能な機器はサンプリングレートが8kHz の物が多いため，それ\nに合わせたアルゴリズムが必要となる．\n図2.8: 骨伝導マイクロフォン利用したIC レコーダー（[24] から引用）\n三井らは，食行動を改善するために骨伝導マイクロフォンを用いて咀嚼回数と発話状態\nをリアルタイムで判定し，ユーザにフィードバックするシステムを提案した[16]．リアル\nタイムでの咀嚼の判定精度が約91 ％，発話時間の判定も約96 ％と高精度での判定ができ\nた．しかし，特定の食材でしか実験が行われていないことや，発話の方法が実験者の質問\nへの返答など，自然な食事環境下での実験はまだ行われていない．\nBedri らは，食事行動を追跡するための眼鏡型デバイス「FitByte」を開発した[25]．こ\nのデバイスには，咀嚼を検出するための4 つのジャイロスコープ，嚥下および咀嚼音をモ\nニタリングする高精度加速度センサ，手を口の方へ動かすの動作を検出する近接センサ，\nおよび摂取した食べ物の映像を記録するカメラが搭載されている．このデバイスは，食事\n行動を94.1 ％の精度で認識し，食事エピソードの時間を96.3 ％の精度で推定することが\n可能であることが示された．\nPapapanagiotou らは，音声，PPG，および加速度を用いて食事行動を検出するイヤー\nデバイスを開発した[26]．このデバイスは，耳内に配置されたマイクとPPG センサで構\n成されており，図2.9 にその外観が示されている．彼らは，新しい高精度かつ低サンプリ\nングレートを備えた咀嚼検出システムのプロトタイプを提案した．特徴量を抽出し，ス\nナッキング検出をサポートベクターマシン（SVM）で分類する手法を採用した．このシ\nステムは，93.8 ％の精度と89.2 ％のクラス加重精度を達成した．\n12\n図2.9: マイク，データ記録用装置，イヤーデバイス装着イメージ（[26] から引用）\nChen らは，制御された環境下で食事行動を捉えるための食事認識システム「ChewPin」\nを提案した[27]．食事音を記録するためにデュアルマイクロフォン拡張ボードを使用し\nた．分類手法には，メルスペクトログラムを入力とする畳み込みニューラルネットワーク\n（CNN）が採用された．このシステムは，食事認識において98.23 ％の精度を達成した．\n2.2\n食事行動に関するフィードバックを用いた研究\n三井らは，咀嚼および会話のフィードバックシステムを提案した[16]（2.1 でも言及）．\n彼らは食事音を利用して咀嚼および会話を検出した．フィードバックは，咀嚼回数やその\n総数に応じてゲージや画像を変化させる形でスマートフォンやスマートウォッチに表示さ\nれた．また，会話のフィードバックは振動や光によって提供された．フィードバックがあ\nる場合の総咀嚼回数は，フィードバックがない場合と比較して有意に増加した．しかし，\n実験では被験者が実験者からの質問に答える形で話をするため，自然な会話とは言えない．\nArnold らは，実際の食事を伴う仮想現実（VR）ゲームを開発した[28]．プレイヤーの\n頬に装着したマイクを用いて咀嚼音を検出し，食事行動を感知する仕組みである．咀嚼動\n作は，音の大きさを用いて検出される．具体的には，咀嚼の開始時に一定の閾値を超え，\n終了時に別の閾値を下回るまでの経過時間によって咀嚼が判断される．このゲームでは，\n非VR プレイヤーがプレイヤーに実際の食べ物を与え，プレイヤーはそれを食べながら，\n仮想の島からの脱出を目指す．島に隠された信号拳銃を見つけることで生存し，脱出を図\nる（図2.10 参照）．咀嚼をするたびにプレイヤーの視界が徐々に広がり，完全な視界が得\nられるようになる．\n13\n図2.10: VR ゲームプレイイメージ（[28] から引用）\nKim らは，スマートな食事速度ガイドシステム「Slowee」を提案した[29]．このシステ\nムは，センサユニットとフィードバックデバイスユニットで構成されている．センサユ\nニットは，咀嚼を検出するためのヘッドフォン型EMG センサと，嚥下を検出するための\nネックレス型ピエゾセンサでユーザーの食事行動を測定する（図2.11 に示す）．フィー\nドバックデバイスユニットは，視覚的フィードバックを提供するライトと，触覚的フィー\nドバックを提供する振動付きリストバンドを備えている．図2.12 はこのシステムの使用\n例を示している．咀嚼行動の認識精度は93.8 ％，嚥下行動の認識精度は79.4 ％であった．\nテストの結果，このシステムは総咀嚼回数および1 回の嚥下あたりの咀嚼回数を有意に増\n加させることが明らかとなった．さらに，Kim らはアニメーション絵文字およびスマー\nトウォッチを利用した食事速度ガイドのフィードバックシステムも提案している[30, 31]．\n絵文字フィードバックでは，アニメーション画像で食事状況を表示した．スマートウォッ\nチベースのフィードバックでは，グラフィック，テキスト，時計，振動の4 種類を提案し\nた．グラフィック型は画像を表示し，テキスト型は文字や色の変化を表示する．時計型は\n現在時刻を色の変化とともに表示し，振動型は速い食事速度を検知した際に振動を提供す\nる．しかし，このフィードバック方法は導入段階に過ぎない．\n14\n図2.11: システムのセンサユニット\n（quoted from[29]）\n図2.12: システムのフィードバック\nデバイスユニット（quoted from[29]）\n元川らは皿駆動型食事阻害システムとしてMealJammer を開発した[32]. 図2.13 には使\n用時のイメージが，図2.14 にはこのシステムの構成が示されている．電磁石を用いて皿\nデバイスを駆動させることで食事を阻害するシステムである．皿デバイスの裏面中央に装\n着された圧力センサで載せた食品の重さを計測し，皿デバイスの下にあるランチョンマッ\nト部に電磁石が配置してある．食品の重さが任意の重さ以下になると，2 つの電磁石が交\n互に動作し，皿デバイスが左右に揺れる．チョコレートとキュウリの2 種類の食品で提案\nシステムの有無による食事時間の比較を行っている．キュウリでは9 割が，チョコレート\nでは半数以上がシステムを用いることによる食事時間の増加が確認されている．\n図2.13: 皿駆動型食事阻害システム\n使用イメージ\n（[32] から引用）\n図2.14: 皿駆動型食事阻害システムの構成\n（[32] から引用）\n蒲地らは食事音声を用いた食習慣改善システム「ChewReminder」を提案した[33]．食\n事中の骨伝導音を自動セグメンテーションし，抽出した特徴量より分類モデルを用いて食\n事行動を予測するアプリケーションを作成し，取得した一口ごとの咀嚼回数に応じてス\nマートウォッチによるリアルタイムフィードバックを行うシステムを提案した．さらに食\n15\n事後にはスマートフォン上に食事全体に対するフィードバックも表示される．アンケート\nの結果から早食いの自覚がある人に有効であることが示された．長期の実験より，スマー\nトフォン上に食事後に表示されるフィードバックも食事行動の改善に有効であることが確\n認できた．しかし嚥下の検出のF1 スコアが41 ％と低いことや，摂食タイミングを検出し\nていないこと，スマートフォン、イヤホン、スマートウォッチの三つもデバイスを使うこ\nとなどが課題として挙げられる．\n中岡らは，人々がゆっくり食事をすることを促し，より健康的な食習慣を推進するシス\nテム「eat2pic」を開発した[34]．このシステムは，センサ付き箸とデジタルキャンバスで\n構成されており，図2.15 にその構成を示す．彼らは，ユーザーの食事行動を物理的な世\n界でモニタリングし，それをデジタルの絵画世界に反映させるナッジングシステムを設計\nした．箸にはIMU センサと小型カメラが搭載され，時系列信号処理や深層学習ベースの\n画像認識を用いて，ユーザーの食事速度，選択した食べ物の種類（色），および摂取した\n量を認識する．このシステムは，健康的な食事のプロセスを風景画に徐々に色付けするこ\nとで表現し，ユーザーの健康的な食習慣を促進する．図2.16 は，このシステムのリアル\nタイム視覚フィードバックの例を示している．このシナリオでは，デジタルキャンバスは\nダイニングテーブルの隣の壁に設置される．ユーザーは風景画を眺めながら食事を楽しむ\nことができる．\n図2.15: 「eat2pic」システム概要\n（[34] から引用）\n図2.16: デジタルキャンバスの描画イメージ\n（[34] から引用）\n2.3\n関連研究についてのまとめ\n様々なセンサを使ったオリジナルデバイスが開発されている．Chun らが提案したネック\nレスタイプのデバイスは，一日中装着し，食事行動と非食事行動を区別することができる．\nしかし，食事中の複雑な行動を分類することはできず，自然な環境下では非食事行動を食\n16\n事行動として誤認識する問題がある．Zhang らが開発したNeckSense は，食事活動や食事\nエピソードを検出するためのマルチセンサーネックレスであるが，自然環境下での咀嚼検\n出の精度が低く，咀嚼や嚥下以外の食事活動を検出することはできない．他の多くの先行\n研究も，咀嚼および嚥下行動の検出精度が十分ではない．さらに，いずれのシステムも，\n摂食，咀嚼，嚥下，および会話という4 つの複雑な食事行動をすべて認識することはでき\nていない．また，フィードバック方法が食事中に画面を注視する必要があるもの，食事行\n動検出，フィードバック提示のために複数の特殊なデバイスを必要とするものなど，様々\nな課題があげられる．先行研究により，様々なセンサによって食事行動の検出が可能であ\nることと，フィードバック提示によって咀嚼回数が増えるなどの早食いを防止する効果が\nあることが言える．そこで，リアルタイムでの詳細な食事行動分類と振動によるフィード\nバックの提示を一つのデバイスで実現する，ネックレス型デバイス，\n「Chewker」を2023\n年に提案した[35]．システム概要を図2.17 に示す．IMU、ピエゾフィルム、ToF、マイク\nの四つのセンサを用いて咀嚼や嚥下などの食事行動を検出した．また，1 口の咀嚼回数が\n少ない場合に振動のフィードバックをリアルタイムで提示し，食事後にはM5StickC の画\n面上に食事全体のフィードバックを提示している．ただし，Chewker の課題として，咀嚼\n判定で用いるセンサ値の閾値が一定であるため，咀嚼判定の個人差が多いことや，振動に\nよるリアルタイムフィードバックはユーザが慣れてしまうことが課題として挙げられる．\nさらに、食事後のフィードバックでは直前の食事一回のみの情報が小さい画面に表示され\nるため，情報が少ない上に見づらく，ハードウェアに関しても，見た目の悪さや装着感の\n悪さがあることが分かった．本論文では，本節で述べた課題の解決に向け，\n「Chewker」を\nさらに進化させたシステムを提案する．新しい「Chewker」はキャリブレーションを取り\n入れることで，食事行動検出の個人差をなくす．1.1.3 節で述べたように，音楽の存在そ\nのものが食事時間を延ばす効果を持つことや，ゆっくりとした音楽は咀嚼のペースを下げ\nて，食事時間を増加させることから，リアルタイムフィードバックで音楽を利用する．音\n楽によるフィードバックは画面を注視する必要がなく，食事の邪魔にならない．また，食\n事後の視覚的フィードバックはスマートフォンの画面で表示し，過去の食事データの参照\nを可能にする．ハードウェアに関しても，装着感，見た目を向上させ，正しく装着するこ\nとで誰でも高い精度で食事行動の検出を可能にする．\n17\n図2.17: 2023 年に提案したChewker の概要\n18\n第3章\nChewker: 食習慣改善システム\n本章では，本研究で提案した食習慣改善のためのフィードバックシステム「Chewker」\nについて述べる．本システムは，ネックレス型デバイスで食事中のセンサデータを取得\nし，スマートフォン上では柔軟なフィードバックを提示する．画面を見る必要のない音楽\nによるリアルタイムフィードバックと，食事終了直後や食事時以外に確認できる視覚的な\nフィードバックの二種類のフィードバックを提示する．\n3.1\nシステムの概要\n提案システムChewker の検出システム概要は図3.1 に示した通りである．また，正面，\n後ろから見たネックレス型デバイスを図3.2 に示す．ユーザはネックレス型デバイスを装\n着し，スマートフォンを机上に置いて食事を行う．ネックレス型デバイスの構成を図3.3 に\n示す．ネックレス型デバイスにはM5StickC，ピエゾフィルム，超音波センサが搭載されて\nいる．センサ別の食事行動検出の詳細を表3.4 に示す。ネックレス型デバイスのM5StickC\n内のIMU センサ，ピエゾフィルム，超音波センサ，およびスマートフォンのマイクの４つ\nを用いて食事行動を検出する。IMU センサは食べ物を口に運ぶ摂食時（Feeding）の前傾\n姿勢を検出する。マイクは会話（Talking）を検出する。ピエゾフィルムはのどの起伏や、\n顎の動きで咀嚼（Chewing）と嚥下（Swallowing）を検出する。超音波センサは首から手\nまでの距離で摂食（Feeding）の検出に役立てる。M5StickC は首の後方に、ピエゾフィル\nムは首の前方に、超音波センサはピエゾフィルムの右側、つまり首の右前方に設置した。\nネックレス型デバイスはマジックテープで着脱可能で、長さの調節も可能である。\n本研究で使用するM5StickCはM5Stack社製，ピエゾフィルムはMEAS社製（MEAS DT\nSeries 　DT2-028K W/TH LEADS/RIVET），超音波センサはM5Stack 社製のUltrasonic\nDistance Unit（RCWL-9600）を使用する．M5StickC へのセンサ接続一覧を表3.1 に示す．\n19\n図3.1: Chewker の検出システムの概要\n図3.2: ネックレス型デバイス装着イメージ\n20\n図3.3: ネックレス型デバイスの構成\n図3.4: センサ別の食事行動検出の詳細\n表3.1: M5StickC へのセンサ接続一覧\nセンサ\n接続先\n備考\nIMU\n内部搭載\nM5StickC 内蔵IMU を使用\nピエゾフィルム\nG33\nGND 接続, 270k Ωの抵抗を挟む\n超音波センサ（Trigger）\nG26\nGND, 5V 接続\n超音波センサ（Echo）\nG0\nGND, 5V 接続\n検出された食事行動を元にフィードバックを提示する．フィードバックの概要を図3.5\nに示す．フィードバックはリアルタイム，食事後の2 種類行う．専門家によると「行動の\n21\n直後にフィードバックを行うと良い，効果がある」ことが分かっているので，行動の把握\nとフィードバックをすぐに行うことができるようスマートフォンを用いた音楽を利用す\nる．また，食事後の視覚的フィードバックは食事全体に対するフィードバックで情報が多\nいため，スマートフォン上に表示し提示する．食事直後のフィードバックに加え，過去の\n食事データを参照できる視覚的フィードバックも用意している．\n図3.5: フィードバックシステムの概要\n3.2\nネックレス型デバイスとスマートフォンの連携\n本システムは，食事者が装着するネックレス型デバイスに搭載されたM5StickC と食事\n者が食事中に机上に置くAndroid 端末がクラウドサービスのFirebase を通じて接続して\nいる構成となっている（図3.6）．Firebase はGoogle が提供しているモバイル及びWeb\nアプリケーション向けのバックエンドサービスであり，その中のRealtime Database 及び\nCloud Firestore の機能を利用する．Realtime Database はリアルタイムでアプリ間での\nデータの保存，及び同期が可能であるデータベースである．一方，Cloud Firestore は高\n性能なクエリ処理が可能であり，データの管理がしやすいデータベースである．複数の\nM5StickC 内のデータをリアルタイムでAndroid 端末へ送信する際に，Realtime Database\nが最適だと考える．また，Android 端末にて記録した食事データをユーザごとに保存する\n際にCloud Firestore が最適だと考えたため，本システムではこれらを利用する．\n22\n図3.6: Firebase を用いたネックレス型デバイスとスマートフォンの連携\nまず，M5StickC とFirebase 間のデータ送信について説明する．M5StickC では，0.01 秒\nごとにIMU によるZ 軸加速度とピエゾフィルムによる値を, 0.05 秒ごとに超音波センサ\nによる距離を取得し，タイムスタンプとともにそれぞれ用意されている配列に格納する．\n配列に200 個分のデータ（超音波センサによる距離は40 個分のデータ）が集まったら，す\nべての値を一つの長い文字列へ変換し，その文字列をFirebase のRealtime Database へ\n送信する（図3.7）．具体的には，Realtime Database のDevice/M5Device ＿1 の配下に\nPiezoIMU とDistance という2 つのキーを用意している．PiezoIMU にはタイムスタンプ\nとIMU によるZ 軸加速度とピエゾフィルムによる値を，Distance にはタイムスタンプと\n超音波センサによる距離を格納するということである．ネックレス型デバイスは2 つ作成\n済みのため，Device/M5Device ＿2 の配下にもPiezoIMU とDistance という2 つのキー\nを用意し，複数のデバイスでも対応可能である．また，Firebase への送信中にセンサによ\nる計測が途切れないよう，M5StickC はマルチタスクでセンサによる計測とFirebase への\nデータ送信を行う．Realtime Database は一つのデータを読み込むのに約1 秒かかるため，\nその1 秒の間に送られてくるデータは処理できずに欠損してしまう恐れがある．そのため，\n複数のデータを文字列へ変換し，約2 秒ごとに送信することにより，Realtime Database\nがデータの欠損なくM5StickC からデータを読み込むことを可能とし，リアルタイム性を\n保証する通信の仕組みを確立した．また，1 つの超音波センサの値を取得するのに0.03 秒\n程度かかるため，この値のみ0.05 秒ごとに値を取得することにした．\n23\n図3.7: M5StickC からセンサによるデータを取得しているFirebase Realtime Database\n次にFirebase とAndroid 間のデータ送信について説明する．Android ではFirebase の\nRealtime Database の値が更新される度に，そのデータを読み込む．そして，読み込んだ\nデータの文字列をコンマ区切りでdouble 型に変換し，配列へ格納して食事行動検出に利\n用する．食事行動検出のアルゴリズムは次の節で述べる．食事終了後，食事時間や咀嚼\n回数などの食事データはFirebase のCloud FireStore へと送信される（図3.8）．Cloud\nFireStore に保存された食事データはAndroid から呼び出すことが可能であり，Android\n端末にて過去の記録を表示し，参照することが可能である．\n図3.8: 食事データが保存されているFirebase Cloud Firestore\n3.3\nChewker の利用手順\n本節では，Chewker の利用手順について説明する．以下に具体的な手順を箇条書き形式\nでまとめる．\n24\n1. 準備\n• ネックレス型デバイスに搭載されているM5StickC とスマートフォンを十分に充\n電する．\n• M5StickC の電源をON にし，起動する．\n• ネックレス型デバイスを装着する．\n2. スマートフォンでの初期設定\n• スマートフォンアプリを起動し，ユーザ名（ニックネーム），計測パターン（実\n験管理者用），およびM5StickC の番号をプルダウンメニューから選択する（図\n3.9）．\n• Save ボタンを押し，メニュー画面に移動する（図3.10）．\n3. キャリブレーション\n• メニュー画面でCalibration ボタンを選択し，キャリブレーション画面に移動\nする（図3.11）．\n• キャリブレーションマニュアルを確認する．マニュアルは日本語版と英語版を切\nり替えるボタンが用意されている．マニュアルの内容は以下の通りである：\n(a) Start Calibration ボタンをタップする．\n(b) 自然な姿勢を5 秒間保つ．\n(c) 食べ物を口に運び，20 回噛んだ後，飲み込む．\n（食べ物をすべて飲み込む必\n要はありません．）\n(d) 自然な姿勢を5 秒間保つ．\n(e) Finish Calibration ボタンをタップし，メインメニューに戻る．\n• マニュアル通りにキャリブレーションを行い，成功すればメニュー画面に戻る．\n4. 食事中の操作\n• メニュー画面でStart Meal ボタンを押すと，食事中の画面が表示される（図\n3.12）．\n• 表示されているYouTube を再生し，音量を調節する．\n• 準備が整い次第，画面上部のStart Meal ボタンを押し，音楽を聴きながら食事\nを開始する．\n25\n5. 食事の終了\n• 食事終了時には，画面下部のFinish Meal ボタンを押す．\n• 食事終了の確認バナーに回答すると，食事終了後の画面に移動する．\n• 食事終了後には，今回の食事に関するフィードバックが表示される（図3.13）．\n6. 過去の食事データ参照\n• メニュー画面からPast Data ボタンを押すと，過去のデータを確認できる．\n（図\n3.14）．\nキャリブレーション中や，食事の計測中は，センサ値をグラフにして実験管理者が確認\nできるようにしている（図3.15）．食事中の音楽によるフィードバック，食事終了後の視\n覚的フィードバック，過去の食事データ参照の詳細は3.6 節にて述べる．\n26\n図3.9: ユーザ名・計測パターン・M5StickC\n番号の選択画面\n図3.10: メニュー画面\n27\n図3.11: キャリブレーション画面\n（左：キャリブレーション前，右：「Start Calibration」を押した後）\n28\n図3.12: 食事中の画面の一例\n（左：食事開始前，右：「Start Meal」を押した後）\n29\n図3.13: 食事終了後のフィードバック画面の\n一例\n図3.14: 過去のデータ参照画面の一例\n30\n図3.15: 管理者が確認するリアルタイムのセンサ値を示すグラフ\n（上からIMU，ピエゾフィルム，超音波センサによる値）\n3.4\n食事行動検出のアルゴリズム\nM5StickC は電源がON の間，IMU，超音波センサ，ピエゾフィルムの3 つのセンサから\n値を取得し，Firebase のRealtime Database に送信し続ける．スマートフォン上でキャリ\nブレーションを開始すると，Realtime Database からのデータ読み込みを開始し，キャリ\n31\nブレーション終了時に読み込みを終了するとともに，食事行動検出に必要な閾値を決定す\nる．食事開始ボタンを押すと，Realtime Database からのデータ読み込みが再開され，食\n事終了ボタンが押されるまでの間，キャリブレーションで決定した閾値を用いて食事行動\nを検出する．さらに，Realtime Database からのデータ読み込みに加えて，スマートフォ\nンのマイクも動作し，音声データを取得する．食事開始ボタンが押されてから，食事終了\nボタンが押されるまでの食事行動検出などに関するフローチャートを図3.16 に示す．本\nシステムでは，発話，摂食，咀嚼，嚥下の4 つの食事行動を検出しており，それぞれの検\n出方法について詳細を述べる．\n32\n図3.16: 食事開始から終了までの食事行動検出に関するフローチャート\n3.4.1\n発話検出\n食事中の会話はスマートフォンのマイクを用いて検出した．マイクからの入力値をdB\n（デシベル）に変換した．図3.17 は，デバイスを装着し，静かな環境で食事中に2 回発話\nした際の音量の例を示している．人間の話し声の平均デシベル値は55～65dB と推定され\nている[36]．そのため，55dB を閾値として設定し，この値を超えた場合を会話として検\n33\n出するようにした．図3.17 から，この閾値が適切であることが確認できる．また，会話\nとして検出された時間を加算していき，会話時間を計測している．\n図3.17: 2 回発話した際の音量の例\n3.4.2\n摂食検出\n食べ物を口に運ぶ動作を摂食（Feeding）とし，IMU によるZ 軸加速度と超音波センサ\nによる距離を用いて検出する．一般的に摂食の際，前傾姿勢になり，手が口に近づくため，\nこれらのセンサを用いることで摂食を検出できると考える．IMU は首後方のM5StickC に\n搭載されており，Z 軸加速度の変化を利用する．また，右利きを想定して首の右前方に設\n置した超音波センサから手までの距離を算出する．実際に3 回摂食を行った際のZ 軸加速\n度と距離データを図3.18 に示す．摂食時に距離が小さくなり，Z 軸加速度が増加している\nことが確認できる．\n34\n図3.18: 3 回摂食を行った際の，IMU によるZ 軸加速度と超音波センサによる距離\nキャリブレーションでは，摂食を検出するための閾値を決定する．3.3 節で述べた手順\nに従い，5 秒間の自然な姿勢の後，1 回の摂食，20 回の咀嚼，1 回の嚥下を行い，再び5\n秒間の自然な姿勢を保持する．この間に取得されたIMU のZ 軸加速度と超音波センサの\n距離データを基に，各個人に適した閾値を設定する．IMU の閾値は，キャリブレーショ\nン中に取得されたZ 軸加速度データの統計的特性を利用して決定する．具体的には，Z 軸\n加速度の平均値と最大値を算出し，その中央値を閾値として設定する．これにより，通常\nの姿勢時の基準値と，摂食動作に伴う最大加速度値の中間点を基準とすることで，個人差\nに適応した閾値の設定が可能となる．\n超音波センサの閾値は，キャリブレーション時に記録された距離データの平均値と最小\n値の中央値を用いて決定する．この閾値は，手が口元に近づいた際の距離変化を考慮し，\n摂食動作の検出精度を向上させるために用いる．\n摂食の検出は，IMU のZ 軸加速度と超音波センサの距離情報を組み合わせて行う．具\n体的には，IMU のZ 軸加速度がキャリブレーションで設定した閾値を超えた瞬間を摂食\nの開始点として記録し，この状態が一定時間維持された後，閾値を下回ることで摂食の終\n了と判断する．このようにして，IMU のデータから摂食の時間的区間を特定する．さら\nに，この期間内に超音波センサの距離がキャリブレーションで設定した閾値以下になった\n35\n場合に，摂食の確定判定を行う．どちらかのセンサのデータのみで摂食を検出すると，手\nが顔の近くにあるが食べていない場合や，前傾姿勢になるが食べていない場合に誤検出す\nる可能性があるため，両者を組み合わせることで精度を向上させる．\nキャリブレーションで決定した閾値は，Firebase を介して保存され，食事中のリアルタ\nイム検出に利用される．食事中のデータ処理では，IMU のZ 軸加速度が閾値を超えた時\n間帯を特定し，その開始・終了タイムスタンプを記録する．一方で，超音波センサの距\n離データも同様に処理され，閾値を下回る時間帯を特定する．これらのデータを照合し，\nIMU による摂食の開始から終了の間に，超音波センサの距離が閾値以下になった場合に\n摂食が検出されたと判断する．摂食が検出された場合，フィードバックシステムに通知し，\n食事行動の解析やリアルタイムフィードバックに活用される．\n3.4.3\n咀嚼と嚥下の検出\n3.5\n咀嚼と嚥下の検出\n咀嚼（Chewing）および嚥下（Swallowing）は，ピエゾフィルムの信号を用いて検出す\nる．ピエゾフィルムは首の前方に肌に密着するよう固定される．咀嚼時には顎の動きに\nよってピエゾフィルムの出力信号が周期的に変化し，嚥下時には喉の動きによって比較的\n大きなピークが発生する．実際に20 回咀嚼をして1 回嚥下を行った際のピエゾフィルム\nの出力データを図3.19 に示す．咀嚼時の小さいピークが20 個と，嚥下時の大きいピーク\nが1 つ確認できる．これらの特性を利用し，ピエゾフィルムの信号のピーク検出を行うこ\nとで，咀嚼と嚥下を識別する．また，センサ信号にはノイズを含むため，リアルタイムで\nの信号処理においてはローパスフィルタ（RC フィルタ）を適用し，Firebase へ送信する\n前にノイズ除去を行う．\n36\n図3.19: 20 回咀嚼し，1 回嚥下した際の，ピエゾフィルムによる出力データ\nキャリブレーションでは，咀嚼および嚥下を検出するための閾値を決定する．3.3 節で\n述べた手順に従い，5 秒間の自然な姿勢の後，1 回の摂食，20 回の咀嚼，1 回の嚥下を行\nい，再び5 秒間の自然な姿勢を保持する．この間に取得されたピエゾフィルムの信号デー\nタを基に，各個人に適した閾値を設定する．\n閾値の決定には，キャリブレーション中に取得されたピエゾフィルムの信号データを正\n規化し，ピーク検出を行う．ピークの分類においては，キャリブレーションデータの最後\nの30%の区間における最大ピークを嚥下の閾値とし，その他のピークのうち，振幅が0.2\n以上0.8 以下の範囲にあるものを咀嚼のピークとする．咀嚼の閾値は，咀嚼ピークの最小\n値と最大値の中央値を用いて決定する．これらの閾値はスケール変換を施し，実際のピエ\nゾフィルムの信号範囲に適用する．\nリアルタイムの咀嚼および嚥下の検出は，キャリブレーションで設定した閾値を基に行\nう．まず，ピエゾフィルムの信号の変化量を計算し，ピーク検出を行う．検出されたピー\nクが咀嚼閾値未満であれば，咀嚼と判定し，咀嚼回数をカウントする．また，咀嚼間隔を\n37\n記録し，嚥下ごとの咀嚼回数や咀嚼ペースの算出に利用する．一方，ピークが嚥下閾値未\n満であり，直前のイベントが咀嚼である場合，嚥下と判定する．嚥下が検出された場合，\n直前の咀嚼データを基に嚥下間の咀嚼回数や咀嚼ペースを評価する（3.6.2 節で詳細を述\nべる）．評価結果はリアルタイムフィードバックに利用され，音楽の再生速度の調整に反\n映される．嚥下が検出された後は，嚥下間の咀嚼回数のリセットを行い，新たな嚥下まで\nのカウントを開始する．\nキャリブレーションで決定した閾値はFirebase を介して保存され，食事中のリアルタイ\nム検出に利用される．食事中のデータ処理では，ピエゾフィルムの信号の変動を解析し，\nリアルタイムでピークを検出することで，咀嚼および嚥下を高精度に判定する．\n3.6\nフィードバックシステムの概要\n検出された食事行動を元に提示するスマートフォンによるフィードバックについて述べ\nる．図3.5 に示したように，食事中の音楽によるフィードバック，食事直後の視覚的フィー\nドバック，食事以外の時に過去の食事データが確認可能な視覚的フィードバックがある．\n3.6.1\nフィードバック内容\n検出された食事行動（摂食，咀嚼，嚥下）を基に，摂食回数，咀嚼回数，嚥下回数，嚥\n下から次の嚥下までの咀嚼回数，摂食から次の摂食までの咀嚼回数，咀嚼ペース，総食事\n時間，食事時間全体に対する会話時間や食べている時間の割合などを算出する．これら\nの値は，リアルタイムおよび食事後のフィードバックに使用される．算出される値につい\nて，以下の表3.2 に示す．\n38\n表3.2: 算出される食事行動関連指標\n指標（日本語）\n指標（英語）\n定義\n摂食回数\nFeeding Count\n食べ物を口に運ぶ回数（回）．\n咀嚼回数\nChewing Count\n食べ物を噛む回数（回）．\n嚥下回数\nSwallowing Count\n食べ物を飲み込む回数（回）．\n食事全体の時間\nTotal Meal Time\n「Start Meal」ボタンを押して，食事を開始し\nてから「Finish Meal」ボタンを押して，食事を\n終了するまでの時間（秒）．\n会話時間\nTotal Talking Time\n食事中に会話をしていた合計時間（秒）．\n食事全体に対する会\n話時間の割合\nPercentage of Talking Time\n食事全体の時間に対する会話時間の割合（％）．\n嚥下から次の嚥下ま\nでの咀嚼回数\nChews between Swallows\n1 回の嚥下から次の嚥下までに行われた咀嚼の\n回数（回）．\n摂食から次の摂食ま\nでの咀嚼回数\nChews between Feedings\n1 回の摂食から次の摂食までに行われた咀嚼の\n回数（回）．\n咀嚼ペース\nChew Pace\n咀嚼1 回から次の咀嚼1 回までにかかった時間\n（秒）．\n一般的な食事行動は，食べ物を口に運ぶ摂食（Feeding）をした後，複数回の咀嚼（Chew）\nを経て，嚥下（Swallow）をして，まだ口に残っている食べ物をさらに咀嚼し，嚥下を繰り\n返す．食べ物が口になくなったら，摂食をして，咀嚼し，嚥下，咀嚼し，嚥下と繰り返す．\n一連の流れを図3.20 に示す．この図には，咀嚼ペース（Chew Pace），嚥下から次の嚥下\nまでの咀嚼回数（Chews between swallows），摂食から次の摂食までの咀嚼回数（Chews\nbetween feedings）についてわかりやすく説明している．\n39\n図3.20: 食事行動の一連の流れと，算出される指標の説明\n3.6.2\n音楽を用いたリアルタイムフィードバック\n研究背景により，咀嚼回数，咀嚼時間や咀嚼ペースが多いほど健康的な食習慣であるこ\nとがわかった．そこでリアルタイムフィードバックでは，食事中に音楽の再生速度を変化\nさせることで咀嚼回数と咀嚼時間を増加させることを目的としている．これまでの研究か\nら，音楽のテンポが食行動や感情に影響を与えることが示されており（1.1.4 節で述べて\nいる），特に遅いテンポの音楽を聴きながら食事をした場合，食事時間，咀嚼回数，咀嚼\n時間が増加することが確認されている．また，レストランにおけるBGM の影響として，\nゆっくりとした音楽が咀嚼ペースを下げ，食事時間を延長させることが知られている．こ\nれらの知見を踏まえ，本システムではリアルタイムフィードバックに音楽を活用する．リ\nアルタイムフィードバックは「Start Meal」ボタンを押してから，\n「Finish Meal」ボタン\nを押されるまで提示される．\n具体的には，ユーザが自身の好きなYouTube の再生リストをアプリ上で再生し，嚥下\nが検出されたタイミングで食事行動に応じて再生速度を調整する．実際のリアルタイム\nフィードバック中のスマートフォンの画面とその説明を図3.21 に示す．嚥下から次の嚥\n40\n下までの咀嚼回数が基準値に満たない場合，または咀嚼ペースの平均が基準値を下回る\n場合，一時的に再生速度を0.5 倍に低下させ，どちらの条件も満たせば再生速度を1.0 倍\nに戻す．一方で，いずれかの条件が基準値を満たさない限り，速度は0.5 倍のままとなる．\nこのフィードバックは，嚥下が検出されるたびに行われ，リアルタイムで食事行動を調整\nする仕組みとなっている．ユーザは1.0 倍の再生速度をキープするために，両方の条件を\n満たそうと努力することが期待できる．\n音楽の再生速度調整の動作は，嚥下から次の嚥下までの咀嚼回数および咀嚼ペースの平\n均の基準値との比較に基づき，以下の4 つのパターンで決定される．\n• 基準値を両方満たした場合（1.0 倍速）\n– 嚥下から次の嚥下までの咀嚼回数が基準値以上\n– 咀嚼ペースの平均が基準値以上\n– 音楽の再生速度を1.0 倍速に維持\n• 咀嚼回数のみ基準値を満たさない場合（0.5 倍速）\n– 嚥下から次の嚥下までの咀嚼回数が基準値未満\n– 咀嚼ペースの平均が基準値以上\n– 音楽の再生速度を0.5 倍速に変更\n• 咀嚼ペースのみ基準値を満たさない場合（0.5 倍速）\n– 嚥下から次の嚥下までの咀嚼回数が基準値以上\n– 咀嚼ペースの平均が基準値未満\n– 音楽の再生速度を0.5 倍速に変更\n• 両方の基準値を満たさない場合（0.5 倍速）\n– 嚥下から次の嚥下までの咀嚼回数が基準値未満\n– 咀嚼ペースの平均が基準値未満\n– 音楽の再生速度を0.5 倍速に変更\n図3.22 に4 パターンの画面のスクリーンショットを示す．それぞれの条件に応じて，中\n央のテキスト内容やテキストの色が変化する．ユーザは音楽が0.5 倍速になる理由がわ\n41\nからない場合に中央のテキストに着目し，調整する．また，気になるようであれば，摂\n食回数（Feeding Count），嚥下から次の嚥下までの咀嚼回数（Chewing Count between\nSwallows），食事全体の咀嚼回数の合計（Total Chewing Count），嚥下回数（Swallowing\nCount）を確認できる．また，会話中は赤字で「Talking」というテキストが表示される．\n図3.21: 食事中のリアルタイムフィードバックを提示するスマートフォン上の画面と\nその説明\n42\n図3.22: 4 パターンの画面のスクリーンショット\n（左から基準値を両方満たした場合，咀嚼回数のみ基準値を満たさない場合，\n咀嚼ペースのみ基準値を満たさない場合，両方の基準値を満たさない場合）\nYouTube のAPI を活用する理由は，無料で自分の好きな音楽リストを作成できること，\n再生速度を変更できること，多くの人が使い慣れていることにある．また，本システム\nでは音楽を利用することで，視覚的なフィードバックを確認し続ける必要がなく，より自\n然な食事を促進できる．このように，リアルタイムフィードバックを音楽と組み合わせる\nことで，ユーザが無意識のうちに咀嚼回数を増やしたり，咀嚼のペースを落とすだけでな\nく，意識的にも適切な咀嚼を促すことが可能となる．\n嚥下から次の嚥下までの咀嚼回数の基準値は16 回，咀嚼ペースの基準値は0.8 秒とし\nた．現代人の1 口に噛む平均回数は10 回～20 回であるという文献[37] や，厚生労働省に\nよる「噛ミング30（カミングサンマル）」という一口30 回噛むことを目標とするスローガ\nン[38] などから，嚥下から嚥下まで20 回噛むことを目標とする．ただし，食べ物によっ\nて20 回咀嚼が必要ない場合もあるため，20 回の8 割である16 回を咀嚼回数の基準値と\nした．また，蒲池らの研究[33] により，食事行動検出アプリ（フィードバックなし）を使\n用し，4 人から収集した食事データから，咀嚼ペースは1.0 秒を理想としている．ただし，\n1.0 秒という条件は食べ物によっては厳しいため，その8 割である0.8 秒を基準値とした．\n43\n3.6.3\n食事直後の視覚的フィードバック\n食事を終えて，\n「Finish Meal」ボタンを押し，確認バナーにYes と答えると，食事全体の\nフィードバックを表示する．フィードバック項目は全体の結果（Total Result），食事時間\n（Meal Time），咀嚼回数（Chew Count），咀嚼ペース（Chew Pace），会話時間（Talk\nTime）の5 つに分かれており，上部のボタンで切り替えられる．\n全体の結果（Total Result）の画面のスクリーンショットを図3.23 に示す．\n「Total」とい\nう項目には全体の摂食回数，嚥下回数，咀嚼回数，会話時間，食事全体の時間を表示す\nる．\n「Average」という項目には嚥下から次の嚥下までの咀嚼回数の平均，摂食から次の摂\n食までの咀嚼回数の平均，咀嚼ペースの平均を表示する．\n「Progress Bars」という項目に\nは，食事時間，咀嚼回数，咀嚼ペース，会話時間の簡単な達成度を表す進行バーが表示さ\nれる．これらの進行バーは以下に記述する画面にて詳細を確認できる．\n44\n図3.23: 全体の結果（Total Result）の画面例\n食事時間（Meal Time）の画面のスクリーンショットを図3.24 に示す．一つの進行バー\nが表示されており，食事時間の達成度を表す．進行バーの上部にある「Target」は基準値\nを，\n「Max」は進行バーの最大値を示しており，進行バーの下部にある「You」はユーザの\n結果を表す．結果が基準値を満たす場合（達成），進行バーは緑色に，基準値を満たさな\nい場合（未達成）は赤色に表示される．15 分から20 分が理想的な食事時間である[39] と\nいうことから，基準値を1200 秒（20 分）とした．進行バーの下部にはアドバイスが表示\nされ，達成した場合と，達成しなかった場合で異なるアドバイスが表示される．アドバイ\nスを表3.3 に示す．アドバイスはタップすると日本語版，英語版を切り替えられる．\n45\n図3.24: 食事時間（Meal Time）の結果の画面例\n表3.3: 食事後のフィードバックによる食事時間についてのアドバイス\n達成状況\n日本語のアドバイス\n英語のアドバイス\n達成時\n目標達成です。20 分以上かけて、ゆっく\nり食事ができていますね。\nGreat job! You’ve taken more than 20\nminutes for your meal, eating at a re-\nlaxed pace.\n未達成時\n食事時間が20 分未満です。もう少しゆっ\nくり時間をかけて食事をしましょう。\nYour meal time is less than 20 minutes.\nTry to eat more slowly and take your\ntime.\n咀嚼回数（Chew Count）のスクリーンショットを図3.25 に示す．3 つの進行バーが表示\n46\nされており，\n「Total Chews」は食事全体の咀嚼回数の達成度を，\n「Average Chews between\nSwallows」は嚥下から次の嚥下までの咀嚼回数の平均の達成度を，\n「Average Chews between\nFeedings」は摂食から次の摂食までの咀嚼回数の平均の達成度を表す．食事時間の画面と\n同様に，それぞれの進行バーの上部にある「Target」は基準値を，「Max」は進行バーの\n最大値を示しており，進行バーの下部にある「You」はユーザの結果を表す．結果が基準\n値を満たす場合（達成），進行バーは緑色に，基準値を満たさない場合（未達成）は赤色\nに表示される．厚生労働省による「噛ミング30（カミングサンマル）」という一口30 回\n噛むことを目標とするスローガン[38] から，\n「Average Chews between Feedings」の基準\n値は30 回とした．また，1 日100 口以上食べ物を食べることが理想であるため[40]，一\n食33 口以上食べることが理想だと考える．一口を摂食から摂食までと考えると，30 回の\n咀嚼を33 回分で1000 回程度が理想となるが，食事内容により変動しやすいため，その8\n割の800 を「Total Chews」の基準値とする．3.6.2 節で述べた理由から，\n「Average Chews\nbetween Swallows」の基準値は16 回とする．画面下部にはアドバイスが表示され，3 つの\n指標の達成状況により異なるアドバイスが表示される．アドバイスを表3.4 に示す．〇は\n達成，×は未達成を示す．\n47\n図3.25: 咀嚼回数（Chew Count）の結果の画面例\n48\n表3.4: 食事後のフィードバックによる咀嚼回数についてのアドバイス\n達成状況\n日本語のアドバイス\n英語のアドバイス\n〇総咀嚼回数\n〇嚥下間の咀嚼回数\n〇摂食間の咀嚼回数\n目標の咀嚼回数をすべて達成しました！\nしっかり噛んで食事ができています。こ\nの調子で続けましょう。\nYou have achieved all the chewing\ngoals! You are chewing thoroughly dur-\ning meals. Keep up the good work.\n×総咀嚼回数\n×嚥下間の咀嚼回数\n×摂食間の咀嚼回数\n全体的に噛む回数が少ないようです。飲\nみ込む前や食べ物を口に運ぶ前に、もっ\nとよく噛むことを意識してみてください。\nYour overall chewing count seems low.\nTry to chew more thoroughly before\nswallowing or taking another bite.\n×総咀嚼回数\n〇嚥下間の咀嚼回数\n〇摂食間の咀嚼回数\n一口ごとにはしっかり噛めていますが、\n全体の回数が少ないようです。一口分の\n量が多いかもしれません。口に運ぶ量を\n減らしてみましょう。\nYou are chewing thoroughly for each\nbite, but your overall count is low. Con-\nsider reducing the size of each bite.\n〇総咀嚼回数\n×嚥下間の咀嚼回数\n〇摂食間の咀嚼回数\n全体の咀嚼回数と摂食間の咀嚼回数は目\n標を達成していますが、嚥下間での咀嚼\nが少ないようです。飲み込む前にもう少\nし噛むことを意識しましょう。\nYou have met the total chewing count\nand chewing between bites, but chewing\nbetween swallows is low. Try chewing\nmore before swallowing.\n〇総咀嚼回数\n〇嚥下間の咀嚼回数\n×摂食間の咀嚼回数\n全体の咀嚼回数と嚥下間の咀嚼回数は目\n標を達成していますが、摂食間での咀嚼\n回数が少ないようです。次の食べ物を口\nに運ぶ前に、もう少し噛むことを意識し\nましょう。\nYou have met the total chewing count\nand chewing between swallows,\nbut\nchewing between feedings is low.\nTry\nchewing more before taking the next\nbite.\n×総咀嚼回数\n×嚥下間の咀嚼回数\n〇摂食間の咀嚼回数\n全体の咀嚼回数と嚥下間の咀嚼回数が不\n足しています。1 口を食べきるための咀\n嚼はしっかりできているので、飲み込む\n前にもう少し噛むことを意識しましょう。\nThe total chewing count and chewing\nbetween swallows are insuﬃcient. You\nchew well for each bite, but try chewing\nmore before swallowing.\n×総咀嚼回数\n〇嚥下間の咀嚼回数\n×摂食間の咀嚼回数\n全体の咀嚼回数と摂食間の咀嚼回数が不\n足しています。嚥下間ではしっかり噛め\nているので、次の食べ物を口に運ぶ前に、\nもう少し噛むことを意識しましょう。\nThe total chewing count and chewing\nbetween feedings are insuﬃcient. You\nchew well between swallows, but try\nchewing more before taking the next\nbite.\n〇総咀嚼回数\n×嚥下間の咀嚼回数\n×摂食間の咀嚼回数\n全体の咀嚼回数は目標を達成しています\nが、嚥下間や摂食間での咀嚼が少ないよ\nうです。飲み込む前や食べ物を口に運ぶ\n前に、もっとよく噛むことを意識してみ\nてください。\nYou have met the total chewing count,\nbut chewing between swallows and feed-\nings seems low.\nFocus on chewing\nmore before swallowing or taking an-\nother bite.\n49\n咀嚼ペース（Chew Pace）の画面のスクリーンショットを図3.26 に示す．一つの進行\nバーが表示されており，咀嚼ペースの達成度を表す．上記と同様，進行バーの上部にある\n「Target」は基準値を，\n「Max」は進行バーの最大値を示しており，進行バーの下部にある\n「You」はユーザの結果を表す．結果が基準値を満たす場合（達成），進行バーは緑色に，\n基準値を満たさない場合（未達成）は赤色に表示される．3.6.2 節で述べた理由から，基\n準値を1.0 秒とした．進行バーの下部にはアドバイスが表示され，達成した場合と，達成\nしなかった場合で異なるアドバイスが表示される．アドバイスを表3.5 に示す．\n図3.26: 咀嚼ペース（Chew Pace）の結果の画面例\n50\n表3.5: 食事後のフィードバックによる咀嚼ペースについてのアドバイス\n達成状況\n日本語のアドバイス\n英語のアドバイス\n達成時\n咀嚼ペースとは、咀嚼と咀嚼の間の時間\nのことです。あなたの平均咀嚼ペースは\n0.8 秒以上で、理想的なペースです。\nYour chewing pace, the interval be-\ntween chews, is ideal at an average of\n1 second or more. Well done!\n未達成時\n咀嚼ペースとは、咀嚼と咀嚼の間の時間\nのことです。あなたの平均咀嚼ペースは\n0.8 秒未満なので、急がずにゆっくり噛\nんで、咀嚼ペースを落としてみましょう。\nYour chewing pace, the interval be-\ntween chews, is less than 1 second. Try\nto slow down and chew more calmly.\n会話時間（Talk Time）の画面のスクリーンショットを図3.27 に示す．一つの進行バー\nが表示されており，食事全体の時間に対する会話時間の割合の達成度を表す．上記と同\n様，進行バーの上部にある「Target」は基準値を，\n「Max」は進行バーの最大値を示してお\nり，進行バーの下部にある「You」はユーザの結果を表す．結果が基準値を満たす場合（達\n成），進行バーは緑色に，基準値を満たさない場合（未達成）は赤色に表示される．1.1.4\n節で会話のある食事が望ましいことから，基準値を10.0 ％とした．進行バーの下部には\nアドバイスが表示され，達成した場合と，達成しなかった場合で異なるアドバイスが表示\nされる．アドバイスを表3.6 に示す．\n51\n図3.27: 会話時間（Talk Time）の結果の画面例\n表3.6: 食事後のフィードバックによる会話時間についてのアドバイス\n達成状況\n日本語のアドバイス\n英語のアドバイス\n達成時\n良い会話時間です。食事中の会話は健康\nを促進すると言われています。\nGood job!\nEngaging in conversation\nduring meals is known to promote well-\nbeing.\n未達成時\nもう少し会話を増やしてみましょう。食\n事中の会話は健康を促進すると言われて\nいます。\nTry to increase your talking time. Con-\nversation during meals can promote\nhealth and enjoyment.\n52\n3.6.4\n過去のデータ参照の視覚的フィードバック\nメニュー画面の「Past Data」ボタンから，過去の食事データを参照できる．\n「Past Data」\nボタンを押すと過去の食事データ一覧画面に移動し，その画面を図3.28 に示す．画面上\n部には，食事開始時間と合計の食事時間とともに，過去の食事データが一覧表示されてお\nり，スクロールが可能である．また，任意の食事データをタップすると，食事直後に表示\nされたフィードバックを再確認できる（図3.29）．さらに，図3.28 に示す画面の下部に\nは，食事に関する各指標（食事時間（Meal Time），全体の咀嚼回数（Total Chews），嚥\n下間の咀嚼回数（Chews per Swallow），摂食間の咀嚼回数（Chews per Feeding），咀嚼\nペース（Chew Pace），会話時間（Talk Time））の棒グラフが表示される．この棒グラフ\nは，過去の全食事データを時系列順に並べたもので，各指標の推移を可視化できる．グラ\nフには基準値を示す赤い線が引かれており，基準値を達成した場合は緑色の棒，達成でき\nなかった場合は赤色の棒で表示される．グラフをタップすると，詳細を確認できるダイア\nログが表示され，拡大表示される（図3.30）．具体的な値や日付などを確認できる．過去\nの食事データを再確認・比較することで，自身の食習慣を振り返り，より良い食事を心が\nけるようになることが期待できる．\n53\n図3.28: 過去の食事データ一覧画面\n54\n図3.29: 任意の食事データタップ後にフィールドバックが再確認できる画面\n55\n図3.30: 棒グラフをタップ後に棒グラフを拡大表示するダイアログ\n56\n第4章\nChewkerの食事行動検出精度評価実験\n本章では，食事行動分類の精度を評価するための実験方法について述べる．実験の責任\n者は，臨床研究のe ラーニングコース「ICR Introduction to Clinical Research」における\n「人を対象とする医学系研究に関する倫理指針」の研修を受講し，修了している．\n4.1\n食事行動検出精度実験概要\n本実験の目的は，食事行動（主に摂食，咀嚼，嚥下）の検出精度を確認することである．\n4.2\n食事行動検出精度実験手順\n20 代男女15 人を被験者として，研究室でネックレス型デバイスを着用し，ピーナッツを\n口に運び、20 回咀嚼をして1 回嚥下するという一連の行動を4 回行った。1 回目はキャリ\nブレーションのためであり，精度評価に用いるデータは3 回分である．キャリブレーショ\nンを行い閾値が決定された後，計測を開始し，3 回分の一連の行動を連続で行った後，計\n測を終了した．評価する際の真の値は，ビデオカメラによって録画したビデオ映像の目視\nによって決定する．\n4.3\n食事行動検出精度実験結果\n精度実験での全体の、摂食、咀嚼、嚥下の分類の混合行列を図4.1に示す．摂食（Feeding）\n45 回，咀嚼（Chewing）900 回，嚥下（Swallowing）45 回分のデータである。実際に食事\n行動をした時に，正しく検出されたものの数をTP，実際には行動していないのに検出さ\nれてしまったものの数をFP，実際に行動しているのに検出されなかったものの数をTN\nとし，Precision, Recall, F1-score を算出した結果を表4.1 に示す．摂食と嚥下はデータが\n57\n少ないが，咀嚼のF1-score85 ％とかなり高い。嚥下は再現性（recall）は高いものの，咀\n嚼を嚥下として検出してしまうことが多く，F1-score は60 ％となった．\n図4.1: 精度実験における食事行動検出精度を示す混合行列\n表4.1: 食事行動分類精度結果\nPrecision\nRecall\nF1-score\nFeeding\n1.00\n0.73\n0.85\nChewing\n0.99\n0.75\n0.85\nSwallowing\n0.47\n0.82\n0.60\n食事行動ごとの詳細な考察をするため，各被験者のF1-score を示す棒グラフを図4.2,\n図4.3, 図4.4 に示し，全体の分布を示す箱ひげ図を図4.5 に示す．棒グラフでは，各被験\n者ごとのF1-score を視覚的に比較することができる．一方，箱ひげ図では，各食事行動\nのF1-score の分布のばらつきや外れ値を確認できる．これらの図を用いることで，摂食，\n咀嚼，嚥下の検出精度における個人差や，全体としての精度の傾向を分析することが可能\nとなる．さらに，各食事行動のF1-score の統計的指標として，平均値および中央値を表\n4.2 に示す．\n58\n図4.2: 被験者ごとの摂食検出精度（F1-score）\n図4.3: 被験者ごとの咀嚼検出精度（F1-score）\n図4.4: 被験者ごとの嚥下検出精度（F1-score）\n59\n図4.5: 食事行動ごとのF1-score の分布\n表4.2: 各食事行動におけるF1-score の統計値\nMean\nMedian\nFeeding\n0.827\n0.800\nChewing\n0.839\n0.812\nSwallowing\n0.642\n0.667\n表4.2 から，咀嚼のF1-score の平均値（0.839）および中央値（0.812）が最も高く，次\nいで摂食（平均値0.827，中央値0.800）が続いていることが分かる．嚥下のF1-score は\n平均値が0.642，中央値が0.667 となっており，他の食事行動と比較して低い値を示して\nいる．これらの結果を踏まえ，個々の食事行動について詳しく考察する．\n4.3.1\n摂食の検出精度\n図4.2 および図4.5 に示すように，摂食（Feeding）のF1-score の平均値は0.827，中央\n値は0.800 であり，多くの被験者において高い精度が得られている．特に，15 名のうち13\n60\n名のF1-score は0.8 以上であり，精度の安定性が確認された．これは，超音波センサによ\nる手の検出とIMU による前傾姿勢の検出を組み合わせることで，摂食の特徴的な動作を\n捉えやすいことに起因すると考えられる．\n一方で，2 名の被験者ではF1-score が0.5 以下であり，個人差による影響が見られた．こ\nの要因として，手の動きや姿勢の違いが挙げられる．しかし，全体的にはF1-score の分布\nが比較的狭く，キャリブレーションによる個別調整が有効に機能していると考えられる．\n今後は，さらに個別適応の閾値調整を行うことで，より安定した摂食検出が可能になると\n期待される．\n4.3.2\n咀嚼の検出精度\n図4.3 および図4.5 に示すように，咀嚼（Chewing）のF1-score の平均値は0.839，中央\n値は0.812 であり，他の食事行動と比較して最も高い精度が得られた．また，全被験者の\nF1-score は0.6 以上であり，0.8 以上のF1-score を記録した被験者は15 名中8 名と，半数\n以上が高い精度を示した．さらに，咀嚼データは1 人あたり20 回分と豊富に取得されて\nおり，摂食や嚥下に比べて統計的に信頼性の高い精度評価が可能である．\n咀嚼の検出精度が高い理由として，本システムがキャリブレーションを導入し，各個人\nに適した閾値を設定したことが挙げられる．キャリブレーション時に被験者の咀嚼パター\nンを取得し，個別に最適化した閾値を適用することで，咀嚼の個人差に対応しやすくなっ\nた．また，ローパスフィルタ（RC フィルタ）を用いたノイズ除去により，ピエゾフィル\nムセンサの信号が滑らかに処理され，ピーク検出の精度が向上した．さらに，センサの装\n着方法やハードウェアの改良を行い，咀嚼時の振動をより安定して取得できるようにした\nことも，精度向上に寄与したと考えられる．\n一方で，F1-score が0.6 付近の被験者も存在しており，これは咀嚼の強さや速さに個人\n差があることに起因すると考えられる．特に，咀嚼が小さい，または速いリズムで行わ\nれる場合，ピークの振幅が小さくなり，閾値を超えないケースがある．今後の改善点とし\nて，ピーク検出の閾値を可変にし，連続する咀嚼パターンを考慮することで，より高精度\nな咀嚼検出が可能になると期待される．\n61\n4.3.3\n嚥下の検出精度\n図4.4 および図4.5 に示すように，嚥下（Swallowing）のF1-score の平均値は0.642，中\n央値は0.667 であり，他の食事行動と比較して最も精度が低かった．また，被験者ごとの\nばらつきが大きく，F1-score が0.8 以上の被験者がいる一方で，0.4 以下の被験者も複数\n存在する．これは，嚥下の個人差が大きいことに起因すると考えられる．さらに，嚥下の\nデータは1 人あたり3 回と少なく，統計的に評価が不安定になりやすいことも影響してい\nると考えられる．\n嚥下の検出精度が低い原因として，咀嚼と嚥下のピークが類似しており，咀嚼を嚥下と\nして誤検出するケースがあることが考えられる．本システムでは，ピエゾフィルムの信号\nのピーク値を基に嚥下を判定しているが，嚥下時のピーク値が咀嚼時と類似している場\n合，明確な判別が困難になる．特に，嚥下時の喉の動きが小さい被験者では，嚥下のピー\nクが検出されにくくなる可能性がある．\nキャリブレーション時に嚥下時のピーク値の分布をより詳細に分析し，各個人に適した\n閾値をさらに細かく設定することが有効と考えられる．また，ピエゾフィルムの装着方法\nを最適化し，嚥下時の振動をより正確に捉えることで，検出の安定性を向上させる必要が\nある．\n62\n第5章\nChewkerのフィードバック効果検証\n本章では，Chewker のフィードバック，特にリアルタイムフィードバックの有効性を検\n証するための実験について説明する．\n5.1\nフィードバック効果検証概要\n本実験は，スマートフォンによる音楽を用いたリアルタイムフィードバックが，食事行\n動そのものや，食事行動への意識にどう影響を与えるかどうかを検証するために実施され\nた．実験の責任者は，精度実験同様，臨床研究のe ラーニングコース「ICR Introduction\nto Clinical Research」における「人を対象とする医学系研究に関する倫理指針」の研修を\n受講し，修了している．さらに，実験の全参加者には研究内容の説明を行い，同意書への\n署名を得ている．\n5.2\nフィードバック効果検証手順\n20 代の男女11 名のデータを収集した．本実験では，食事中の会話も必要とされたため，\n被験者は2 人以上のグループで食事を行った．各被験者は，リアルタイムフィードバック\nなしで食事をする条件と，リアルタイムフィードバックを受けながら食事をする条件の2\n回の実験を，異なる日に行った．全て昼食の時間帯に行われ，2 回の実験の時間帯がなる\nべく同じになるようにした．\n実験で使用した弁当は学食で販売されているものであり，すべて同じ形状のトレイに盛\nり付けられ，おおよそ同じ量であった．また，各被験者が2 回の実験で全く同じ弁当を食\nべるようにし，主菜の違いが影響しないように配慮した．弁当の主菜として，ハンバーグ，\nヒレカツ，レバニラ炒め，チキン南蛮，白身フライ，酢豚の6 種類を用いた．図5.1 に弁\n当の例を示す．\n実験の流れは，同意書への署名，事前アンケートの回答，実験1 日目，実験2 日目，2\n63\nつの実験後アンケートの回答である．実験の様子を図5.2 に示す．被験者は両条件の実験\nにおいてネックレス型デバイスを装着し，スマートフォンを机に置いて，アプリを使用し\nながら食事をした．食事終了後は食事直後のフィードバック画面を確認した．食事時間の\n制限などは設けていない．記録のために口元や顎，首が移るようビデオ録画をした．リア\nルタイムフィードバックありの条件では，音楽が低速になるフィードバックに基づき，嚥\n下間の咀嚼回数や咀嚼ペースを意識することが求められた．リアルタイムフィードバック\nなしの条件では，ネックレス型デバイスを装着し，音楽は再生されたが，音楽の速度変化\nのフィードバックや，テキストによるフィードバックは提示されなかった．初期設定の画\n面で計測パターンを実験管理者が選ぶことで，フィードバックの有無を制御できる（3.3\n節参照）．アンケートは，実験前に回答する事前アンケート，実験後に回答するSUS アン\nケートとChewker に関するアンケートの3 つを用意した．\n図5.1: 実験で使用された弁当の例\n64\n図5.2: 実験の様子\n5.2.1\n事前アンケート\n実験前に，被験者は以下の質問項目について回答し，食事に関する意識や習慣を確認し\nた．回答形式は5 段階評価または選択式であり，被験者の食事速度や咀嚼，食事中の会\n話，音楽の聴取習慣などに関するデータを収集することを目的とした．図5.3 に質問票の\nフォームを示す．\nまず，被験者にはアプリ上で表示されるためのニックネームを決定してもらった．次に，\n「自分は早食いだ（食べるスピードが速い）と思いますか」，\n「普段の食事で，噛むことを\n意識していますか」，\n「普段の食事で，会話することを意識していますか」の3 項目につい\nて，5 段階評価で回答した．また，被験者が普段の食事中に音楽を聴く習慣があるかを確\n認するため，\n「音楽を聴きながら食事をする頻度はどれぐらいですか（レストランなどで\nのBGM も含む）」という質問を設定し，選択肢として「1 日に一度以上」，\n「2～3 日に一\n度程度」，\n「1 週間に一度程度」，\n「全くない」の4 つを用意した．\nさらに，本実験ではYouTube の再生リストを用いたリアルタイムフィードバックを行\nうため，被験者に実験中に聴取する音楽の選択を求めた．選択肢の中から好きな再生リス\n65\nトを選択するか，その他の欄に希望するYouTube 再生リストのリンクを入力する形式と\nした．ただし，アプリへの埋め込みができない再生リストについては対応できない可能性\nがあることを事前に伝えた．\n最後に，被験者の安全を確保するため，食材に関するアレルギーの有無を確認した．\n「な\nい」と回答した被験者はここで質問が終了し，\n「ある」と回答した被験者には，具体的な\nアレルギー食材について追加で回答を求めた．\n図5.3: 事前アンケート質問事項\n66\n5.2.2\nSUS アンケート\nSUS アンケートはSystem Usability Scale の略で，ジョン・ブルック（John Brooke）に\nより1986 年に開発され，システムのユーザビリティの受け止められ方について測定する\nために最も広く利用されている質問票である[41][42]．このスケールは，1（まったくそう\n思わない）から5（まったくそう思う）の10 の記述から成り立っている．奇数項目の設\n問は肯定的な質問であり，偶数番号の設問は否定的な質問である．集計方法は，奇数番号\nの設問に対しては回答番号から１を引く．偶数番号の設問に対しては，５から回答番号を\n引く．そして，合計スコアに2.5 をかけて０から100 までのスケールに変換する．各スコ\nアに対する評価の指標を図5.4 に示す．\n図5.4: SUS スコア指標（[41][42] から引用）\n5.2.3\nChewker についてのアンケート\n実験後，被験者は「Chewker に関するアンケート」に回答し，本システムの使用感や\nフィードバックの効果について評価を行った．このアンケートは，食事中の意識の変化，\n67\nシステムのフィードバックの理解度，装着デバイスの違和感，およびシステムの継続利用\n意向について調査することを目的としている．図5.5 に質問票のフォームを示す．\nまず，被験者が本システムを使用したことによる食事中の意識の変化を評価するため，\n「食事中に噛むことを意識しましたか」，\n「食事中に発話に関して意識しましたか」，\n「食事\n中ゆっくり食べようと意識しましたか」の3 項目について5 段階評価で回答を求めた．ま\nた，システムの装着感について「装着デバイスに違和感はありましたか」という質問を設\n定した．\n次に，リアルタイムフィードバックと食事後のフィードバックの理解度を確認するため，\n「音楽の速度変化によるリアルタイムフィードバックはわかりやすかったですか」，\n「リア\nルタイムフィードバックによってゆっくり噛むことを意識しましたか」，「リアルタイム\nフィードバックによってたくさん噛むことを意識しましたか」，\n「スマートフォン上での食\n事後に表示されるフィードバックはわかりやすかったですか」の4 項目について5 段階評\n価で回答を求めた．\nさらに，本システムの測定精度に対する主観的評価を収集するため，\n「システムは咀嚼を\n正しくカウントしていると感じましたか」，\n「システムは嚥下（飲み込むこと）を正しく検\n出していると感じましたか」，\n「システムは発話を正しく測定していると感じましたか」の\n3 項目について5 段階評価で回答を求めた．また，\n「今後、このシステムを使いたいと思い\nましたか」という質問を設け，システムの継続利用意向を調査した．咀嚼，嚥下について\nは音楽によるリアルタイムフィードバックに直接関与しているため，リアルタイムフィー\nドバック画面下部の回数表示に注目することが予想されるため，質問に含めた．発話につ\nいてもリアルタイムフィードバック画面上に赤字で表示されるため，質問に含めた．摂食\nはリアルタイムフィードバックには関与しないため，注目する被験者が少ないことが予想\nされ，答えにくいと判断し，質問には含めなかった．\n加えて，被験者の自由な意見を収集するため，以下の3 つの自由記述形式の質問を設け\nた：「システムを使用して使いにくかった点・改善した方が良い点があれば教えてくださ\nい」，\n「システムの継続利用を想定するならば，どのようなシーンで利用したいと思うか具\n体的に教えてください」，\n「システムについて意見などがあれば自由に記述してください」．\n68\n図5.5: Chewker についての実験後アンケート\n69\n5.3\nフィードバック効果検証結果\n全体の食事時間，全体の咀嚼回数，摂食間の咀嚼回数，嚥下間の咀嚼回数，咀嚼ペース，\n会話時間の6 つの評価指標について考察する．評価結果は値が大きいほど良好である．\n5.3.1\n全体の食事時間の結果\n全被験者11 名において，リアルタイムフィードバックを用いた食事の総食事時間は，\nフィードバックなしの食事と比較して増加した．図5.6 に各被験者ごとの総食事時間の変\n化を示す．また，食事時間の結果を箱ひげ図で示したものを以下に示す．図5.7 は，リア\nルタイムフィードバックを使用した食事と使用しなかった食事の比較結果を示している．\n図5.6: 各被験者ごとの全体の食事時間の変化\n70\n図5.7: 全体の食事時間の箱ひげ図\n箱ひげ図の結果から，リアルタイムフィードバックを使用した食事では，フィードバッ\nクなしの食事と比較して平均値および中央値が増加していることが確認された．ウィルコ\nクソンの符号付順位和検定を用いて分析を行った結果，有意差があり（P¡0.05），リアル\nタイムフィードバックが食事時間の延長に寄与することが明らかとなった．特に，フィー\nドバックなしの食事と比較した食事時間の増加率は平均68.02 ％であった．リアルタイム\nフィードバックが咀嚼の意識を高め，結果として食事時間の延長につながった可能性が高\nい．これらの結果から，リアルタイムフィードバックを用いることで，よりゆっくりとし\nた食事が促進されることが示唆された．食事時間の延長は，咀嚼回数の増加や過食防止に\nもつながるため，本システムは健康的な食習慣の形成に貢献する可能性が高い．\n5.3.2\n全体の咀嚼回数の結果\n全被験者11 名のうち，リアルタイムフィードバックを使用した食事では，フィードバッ\nクなしの食事と比較して咀嚼回数が増加した被験者は10 名であった．図5.8 に各被験者\nの咀嚼回数の変化を示す．一方で，Subject J のみがフィードバックなしの食事の方が咀\n嚼回数が多かった．また，咀嚼回数の結果を箱ひげ図で示したものを図5.9 に示す．\n71\n図5.8: 各被験者ごとの全体の咀嚼回数の変化\n図5.9: 全体の咀嚼回数の箱ひげ図\n72\n箱ひげ図から，リアルタイムフィードバックを使用した食事では，フィードバックなし\nの食事と比較して平均値および中央値が増加していることが確認された．特に，フィー\nドバックなしの食事と比較した場合の咀嚼回数の増加率は平均26.88%であった．これは，\nリアルタイムフィードバックが咀嚼を意識させる効果を持ち，その結果として咀嚼回数の\n増加につながった可能性を示唆している．また，ウィルコクソンの符号付順位和検定を用\nいて分析を行った結果，有意差があった（P¡0.05）．また，フィードバックなしの食事に\n比べて，Subject J の咀嚼回数が減少している原因としては，フィードバックありの食事\nの際に，咀嚼が検知されずらかったことがあげられる．\n5.3.3\n摂食間の咀嚼回数の結果\n図5.10 に各被験者ごとの摂食から次の摂食まで（摂食間）の咀嚼回数の変化を示す．リ\nアルタイムフィードバックを用いた場合，摂食間の咀嚼回数が増加した被験者は4 名であ\nり，7 名では減少が確認された．この結果は摂食回数が関係するため，図5.11 に全体の摂\n食回数の変化を，図5.12 に摂食回数の結果をあらわした箱ひげ図を示す．\n図5.10: 各被験者ごとの摂食間の咀嚼回数の変化\n73\n図5.11: 各被験者ごとの摂食回数の変化\n図5.12: 摂食回数の箱ひげ図\n74\n摂食間の咀嚼回数の減少が見られた7 名（Subject B，C，D，E，F，H，I）は全員摂食\n回数が増加しており，全体で11 名中8 名の被験者がフィードバックありの状態で摂食回\n数を増やしていた．フィードバックを使用した食事では，フィードバックなしの食事と比\n較して摂食回数の平均値および中央値が増加している．摂食回数に関してウィルコクソン\nの符号付順位和検定を用いて分析を行った結果，有意差はなかったものの，増加率は平均\n25.70 ％であった．図5.13 にフィードバックありの食事で摂食間の咀嚼回数が減少した被\n験者7 名を強調した比較結果を示す．一方，図5.14 では，その被験者7 名の摂食回数の\n結果を強調している．\n図5.13: 7 名の被験者の結果を強調した各被\n験者ごとの摂食間の咀嚼回数の変化\n図5.14: 7 名の被験者の結果を強調した各被\n験者ごとの摂食回数の変化\nこれらの結果から，リアルタイムフィードバックにより，咀嚼を意識することで，一度\nに口に入れる食べ物の量が減り，その結果，何度も口に運ぶ摂食動作が増えたと考えられ\nる．7 名は摂食間の咀嚼回数が減少したが，全員全体の咀嚼回数は増加しているため，十\n分な咀嚼回数である．これらの結果から，リアルタイムフィードバックは，食事中の咀嚼\nを意識させることで，摂食行動を増加させる効果を持つ可能性が高い．また，同じ量のお\n弁当を食べているため，フィードバックありの食事で摂食回数が増えたということは一度\nに口に入れる食べ物の量が減り，早食いを防止できていると言える．\n75\n5.3.4\n嚥下間の咀嚼回数の結果\n図5.15 に各被験者ごとの嚥下から次の嚥下まで（嚥下間）の咀嚼回数の変化を示す．リ\nアルタイムフィードバックを用いた場合，嚥下間の咀嚼回数が増加した被験者は10 名であ\nり，Subject J のみ減少が確認された．この結果は，前述のとおり，Subject J ではフィー\nドバックありの状態で咀嚼が検知されにくく，全体の咀嚼回数が減少していたことが影響\nしていると考えられる．また，嚥下間の咀嚼回数の結果を箱ひげ図で示したものを以下に\n示す．図5.16 は，リアルタイムフィードバックを使用した食事と使用しなかった食事の\n比較結果を示している．\n図5.15: 各被験者ごとの嚥下間の咀嚼回数の変化\n76\n図5.16: 嚥下間の咀嚼回数の箱ひげ図\n箱ひげ図の結果から，リアルタイムフィードバックを使用した食事では，フィードバック\nなしの食事と比較して嚥下間の咀嚼回数の平均値および中央値が増加していることが確認\nされた．また，嚥下間の咀嚼回数の増加率は平均19.22 ％であり，ほとんどの被験者にお\nいて嚥下間の咀嚼回数が増加していることがわかる．一方で，嚥下回数の増加率は-6.69 ％\nとほとんど変化が見られなかった．この結果から，嚥下回数を減らして嚥下間の咀嚼回数\nを増やしたということではなく，嚥下回数は変わらず，フィードバックにより意識するこ\nとで咀嚼回数自体が増加したと考えられる．嚥下間の咀嚼回数は，リアルタイムフィード\nバックにおける音楽の速度変化に直接関与する重要な指標である．この指標が増加したこ\nとは，リアルタイムフィードバックが被験者の咀嚼行動に影響を与え，より多く咀嚼する\nよう促す効果があったことを示唆している．ウィルコクソンの符号付順位和検定を用いて\n分析を行った結果，有意差はなかったものの，ほとんどの被験者において嚥下間の咀嚼回\n数が増加しており，リアルタイムフィードバックが咀嚼行動の改善に寄与する可能性が示\nされた．\n77\n5.3.5\n咀嚼ペースの結果\n図5.17 に各被験者ごとの咀嚼ペースの変化を示す．リアルタイムフィードバックを用\nいた場合，咀嚼ペースが増加した被験者は11 名中8 名であった．Subject C とSubject K\nのデータが重なっており，個々の変化が視覚的に分かりづらいが，両者とも咀嚼ペースが\n増加している．また，咀嚼ペースの結果を箱ひげ図で示したものを図5.18 に示す．箱ひ\nげ図の結果から，リアルタイムフィードバックを使用した食事では，フィードバックなし\nの食事と比較して平均値および中央値が増加していることが確認された．\n図5.17: 各被験者ごとの咀嚼ペースの変化\n78\n図5.18: 咀嚼ペースの箱ひげ図\n咀嚼ペースの増加率は平均45.16 ％であり，特に咀嚼が検知されにくかったSubject J\nは増加率が100 ％と大幅に上昇していた．このため，Subject J を除いた場合の平均増加\n率は39.68 ％となる．この結果から，リアルタイムフィードバックが咀嚼ペースに影響を\n与えていることが示唆される．咀嚼ペースはリアルタイムフィードバックとしての音楽の\n速度変化に直接関与しており，咀嚼ペースの増加が確認されたことから，本システムが意\n図したフィードバック効果を発揮していることが分かる．また，ウィルコクソンの符号付\n順位和検定を用いて分析を行った結果，有意差があった（P¡0.05）ことから，リアルタイ\nムフィードバックが咀嚼ペースの向上を促す可能性が示唆される．\n5.3.6\n会話時間の結果\n図5.19 に全被験者の食事時間に対する会話時間の割合の変化を示す．リアルタイムフィー\nドバックを用いた場合，会話時間の割合が増加した被験者は11 名中4 名であった．また，\n会話時間の結果を箱ひげ図で示したものを図5.20 に示す．\n79\n図5.19: 各被験者ごとの会話時間の割合の変化\n図5.20: 会話時間の箱ひげ図\n80\nこの結果から，全体的に会話時間の割合はフィードバックなしと比較して減少傾向にあ\nることが確認された．増加率の平均は-22.48 ％であり，会話時間が減少した被験者が多\nかったことが示された．この結果の要因として，リアルタイムフィードバックにより咀嚼\nへの意識が向上し，咀嚼に集中することで会話の機会が減少した可能性が考えられる．ま\nた，被験者はフィードバックあり・なしで同じ人と同じ人数で食事を行ったわけではない\nため，環境要因が会話時間の変動に影響を与えた可能性もある．会話時間については個々\nの食事環境に依存するため，現段階では詳細な考察を行うことは難しい．しかし，将来的\nに会話を促進するためのフィードバック要素を導入することで，よりバランスの取れた食\n事行動の支援が可能になると考えられる．\n5.3.7\nSUS スコア結果\n本節ではSUS スコアの結果について考察する．スコアは表5.1 のとおりであり，スコア\n指標は図5.4 のとおりである．平均スコアは83.2 となり，A スコアであった．平均的な\nSUS スコアである68 以上のスコアが10/11 人とほとんどであり、Exellent の評価となっ\nたため，本システムのユーザビリティは優れていると結論付けることができる．\n表5.1: The result of SUS\nSubject\nScore\nA\n82.5\nB\n80.0\nC\n80.0\nD\n90.0\nE\n67.5\nF\n80.0\nG\n87.5\nH\n87.5\nI\n77.5\nJ\n90.0\nK\n92.5\n81\n5.3.8\n実験前後のアンケート結果\n本研究では、食事前後のアンケートを実施し、被験者の食事に対する意識の変化や、リ\nアルタイムフィードバックの影響を評価した。5 段階評価における「5」は「非常にそう\n思う」，\n「1」は「全く思わなかった」を示す．食事前後での意識の変化の比較のため，6 つ\nの質問の平均得点の棒グラフを図5.21 に表す．\n図5.21: 食事前後での意識の変化の比較のための6 つの質問の平均得点の棒グラフ\nまず，早食いの意識の変化について述べる．事前アンケートにおいて，\n「自分は早食いだ\nと思いますか」の質問に対して，\n「4」または「5」と回答した被験者は2 名であった．これ\nに対し，実験後のアンケートでは，\n「食事中ゆっくり食べようと意識しましたか」の質問\nに対し，7 名が「5」，4 名が「4」と回答しており，リアルタイムフィードバックが被験者\nに食事のペースを意識させる効果を持っていたことが示唆される．特に，事前アンケート\nで「早食いである」と回答した2 名も実験後には「4」または「5」を選択しており，食事\nの速度を意識する変化が見られた．\n次に，咀嚼への意識の変化を説明する．事前アンケートで「普段の食事で噛むことを意\n82\n識していますか」の質問に対し，\n「4」または「5」と回答した被験者は0 名であり，ほとん\nどの被験者（10 名）が「1」または「2」と回答していた．このことから，被験者のほと\nんどが普段は咀嚼を意識していないことが分かる．一方，実験後のアンケートでは，\n「食\n事中に噛むことを意識しましたか」の質問に対し，10 名が「5」，1 名が「4」と回答して\nおり，全被験者がフィードバックの影響を受けて咀嚼を意識したことが明らかになった．\nこの結果は，本システムが咀嚼の意識向上に大きく寄与したことを示している．\n次に，会話への意識の変化について述べる．事前アンケートにおいて，\n「普段の食事で会\n話することを意識していますか」の質問に対し，\n「4」または「5」と回答した被験者は1 名\nであった．一方，実験後のアンケートでは，\n「食事中に発話に関して意識しましたか」の\n質問に対し，\n「4」が6 名，\n「3」が2 名，\n「2」が2 名，\n「1」が1 名と結果がばらけたが，会話\nへの意識が多少なりとも向上している．5.3.6 でも述べたように，リアルタイムフィード\nバックの影響で会話よりも咀嚼を意識する傾向が強まっていると考えられる．また，被験\n者ごとに異なる食事環境の影響も考慮する必要がある．\n次に，音楽によるリアルタイムフィードバックと食事後のフィードバックの理解度と影\n響について述べる．実験後アンケートのフィードバックに関する質問の得点平均を図5.22\nに表す．\n「音楽の速度変化によるリアルタイムフィードバックは分かりやすかったですか」\nの質問に対し，\n「4」または「5」と回答した被験者は8 名であり，それ以外の被験者は「3」\nと答えていたため，多くの被験者がリアルタイムフィードバックの仕組みを理解していた\nことが分かる．また，\n「リアルタイムフィードバックによってゆっくり噛むことを意識しま\nしたか」の質問では11 名全員が「4」または「5」と回答し，\n「リアルタイムフィードバッ\nクによってたくさん噛むことを意識しましたか」の質問でも11 名全員が「4」または「5」\nと回答しており，リアルタイムフィードバックが咀嚼行動の改善に貢献した可能性が示唆\nされる．\n「スマートフォン上での食事後に表示されるフィードバックはわかりやすかった\nですか」の質問に対しても，11 名全員が「4」または「5」と回答したため，食事後の視\n覚的フィードバックは誰が見てもわかりやすいものと言える．\n83\n図5.22: 実験後アンケートのフィードバックに関する質問の得点平均\n食事行動検出精度に対する主観的評価の結果を述べる．システムが正しく食事行動（咀\n嚼・嚥下・発話）を検出しているかについての質問の得点平均を図5.23 に示す．\n「システ\nムは咀嚼を正しくカウントしていると感じましたか」の質問に対し，\n「4」または「5」と\n回答した被験者は8 名であり，多くの被験者がシステムの咀嚼検出精度を肯定的に評価し\nていた．一方で，\n「システムは嚥下（飲み込むこと）を正しく検出していると感じました\nか」の質問に対し，\n「4」と回答した被験者は4 名，\n「3」と回答した被験者は6 名，\n「2」と回\n答した被験者は1 名であった．この結果から，咀嚼の検出と比較すると，嚥下の検出に対\nする評価はやや低く，特に「3」の評価が多いことから，嚥下検出の精度には改善の余地\nがあることが示唆された．4.3 節の精度実験の結果からも，咀嚼より嚥下の方が精度が低\nいことが確認されており，アンケートによる主観評価と一致していることが分かる．\n「シ\nステムは発話を正しく測定していると感じましたか」の質問では，\n「4」または「5」と回\n答した被験者が8 名であり，多くの被験者が発話検出の精度を肯定的に評価していた．一\n方で，1 名が「3」，1 名が「2」と回答しており，一部の被験者においては発話検出の精度\nに対する懸念があることが示された．会話は，食事をしている人以外の周囲の音も検出し\nていまうことが問題点として挙げられる．\n84\n図5.23: システムが正しく食事行動（咀嚼・嚥下・発話）を検出しているかについての質\n問の得点平均\n次に，装着デバイスの違和感と継続利用意向について述べる．デバイスの装着感とシス\nテムの継続利用意向についての質問の得点平均を図5.24 に示す．\n「装着デバイスに違和感\nはありましたか」の質問では，1 名が「5」，2 名が「3」，7 名が「2」，1 名が「1」と回\n答しており，多くの被験者が装着に対して大きな違和感を感じなかったことが分かる．一\n方，\n「今後，このシステムを使いたいと思いましたか」の質問では，9 名が「4」または「5」\nと回答しており，システムの継続利用に対する関心が高いことが確認された．特に，事前\nアンケートで「普段の食事で噛むことを意識していない」と回答した被験者が多かったに\nも関わらず，実験後には全員が咀嚼を意識するようになったことは，本システムの有効性\nを示す重要な結果である．\n85\n図5.24: デバイスの装着感とシステムの継続利用意向についての質問の得点平均\nこれらの結果から，リアルタイムフィードバックは咀嚼行動や食事ペースの調整に有効\nであり，多くの被験者に受け入れられる可能性が高いことが示唆された．自由記述での質\n問の回答では，\n「デバイスの装着が少し難しいと感じた」，\n「首が苦しいと感じた」など装着\n方法や装着感についての意見が寄せられた．より簡単に，そして快適に装着できるハード\nウェアを検討する必要がある．また，\n「フィードバックのおかげで，噛む回数が増え，顎が\n疲れて普段いかに噛めてないかを自覚した」，\n「実験当日の夜に噛むことを意識した」，\n「食\n事結果と目標が「数値」としてフィードバックされることで，改善しようとする意欲が湧\nいた」「1 倍速に戻ったときの爽快感が楽しくて，キープしようと努力した」など，フィー\nドバックが意識向上につながっていることがわかる．\n86\n第6章\n結論\n6.1\nまとめ\n本研究では，食習慣の改善を目的として，リアルタイムフィードバックシステム「Chewker」\nを提案し，その有効性を検証した．IMU，ピエゾフィルム，超音波センサ，スマートフォ\nンのマイクを用いて，摂食，咀嚼，嚥下，発話の4 つの食事行動をリアルタイムに検出し，\n音楽の再生速度を変化させることでフィードバックを行う．また，食事終了後にはスマー\nトフォン上で詳細なフィードバックを提示し，食事行動の振り返りを可能にした．\n11 名の被験者による実験の結果，リアルタイムフィードバックにより総咀嚼回数が平\n均26.88 ％増加，嚥下間の咀嚼回数が平均19.22 ％増加し，両者とも10 名で増加が確認さ\nれた．また，咀嚼ペースは8 名で増加し，総食事時間は平均68.02 ％延長，すべての被験\n者で増加が確認された．さらに，8 名の摂食回数が増加しており，一口あたりの食べ物の\n量が減り，口に運ぶ回数が増えたことが示唆された．これらの結果から，フィードバック\nが，急がずたくさん噛み，ゆっくりとした食事を促すことがわかる．事前アンケートでは\n「普段の食事で噛むことを意識していない」と回答した被験者が10 名いたが，実験後には\n全員が「噛むことを意識した」と回答し，食事行動への意識の改善が明らかになった．\n本システムの食事行動検出精度に関して，摂食と咀嚼のF1-score は0.85 と高い精度を\n示した．一方で，嚥下のF1-score は0.60 と他の行動に比べて低く，咀嚼との誤検出が課\n題として挙げられた．また，SUS 平均スコアは83.2 となり，本システムのユーザビリティ\nは優れていると言える．\n本研究の目的に対する結論は以下の通り：\n1. 自然な食事環境下での，詳細な食事行動をリアルタイムに検出するシステムの実現\nができた．\n2. 検出した食事行動に基づいて，フィードバックを提示することで，食事行動への意\n識改善を行うシステムの開発ができた．\n87\n6.2\n今後の展望\n本研究では，リアルタイムフィードバックによる食事行動の変化を確認できたが，さら\nなる改良の余地がある．今後の展望として，長期間の使用による行動変容の検証や，装着\n方法の改良，精度向上を目指した改良が必要である．本研究では単回の食事を対象に検証\nを行ったが，食習慣の改善には長期的な行動変容が重要である．今後は，長期間の使用を\n通じて食習慣がどのように変化するかを検証し，持続的な効果を評価する必要がある．ま\nた，本システムには過去の食事行動を振り返る機能が備わっており，これが行動変容に与\nえる影響についても詳細に検討する必要がある．\nさらに，発話の促進を目的としたフィードバック手法の導入も検討すべきである．本シ\nステムでは，咀嚼や食事ペースの改善には効果があったものの，発話の促進には大きな影\n響を与えなかった．今後は，発話を積極的に促すフィードバック手法を導入し，食事中の\n会話を活発にするシステムの開発を進める．\n本研究の食事行動検出精度の評価は，ピーナッツを用いた実験環境下で行われたため，\n摂食および嚥下のデータが少なく，精度の信憑性に課題が残る．今後は，様々な環境で精\n度を検証し，検出アルゴリズムの改良を進める．また，リアルタイムフィードバックの効\n果を検証する際，ビデオによる記録が残っているため，これを活用して自然な食事環境下\nでの検出精度を詳細に評価することも検討する．特に嚥下の精度が劣るため，キャリブ\nレーションの改良や，デバイスの設計を見直す必要がある．\nまた，装着方法やハードウェアの改良も必要である．実験後のアンケートでは，\n「デバイ\nスの装着が少し難しい」，\n「首が苦しい」といった意見が寄せられたため，より簡単に装着\nでき，快適に使用できる設計への改良が求められる．加えて，M5StickC のバッテリー持\n続時間が約1 時間と短いため，長時間の使用に耐えられるようなバッテリー駆動の最適化\nや代替デバイスの検討も必要である．これらの改良を通じて，本システムはより実用的\nで，食事行動の改善を長期的に支援するツールへと発展することが期待される．\n88\n謝辞\n本研究を進めるにあたり，青山学院大学理工学部情報テクノロジー学科のロペズ・ギ\nヨーム教授に深く感謝申し上げます．研究目標を達成するだけでなく，高い意欲を継続し\nて研究に取り組むことができたのは，先生の温かく丁寧なご指導のおかげです．また，国\n内外での発表の機会を与えてくださり，研究者としての視野を広げることができました．\nさらに，研究室の運営や事務手続きを支えてくださった大熊ちひろ様にも，心より感謝申\nし上げます．研究に集中できる環境を整えてくださり，さまざまな手続きを円滑に進めて\nいただいたことで，本研究を滞りなく進めることができました．また，ロペズ研究室のメ\nンバーの皆様にも深く感謝いたします．日々のディスカッションを通じて新たな視点を得\nることができ，研究をより良いものにすることができました．特に，同期や先輩方からの\nアドバイスは，問題解決の大きな助けとなりました．最後に，これまで支えてくれた家族\nに心から感謝いたします．研究に打ち込むことができたのは，日々の励ましや支援があっ\nたからこそです．多くの方々のご協力と支えがあって，本研究を完遂することができまし\nた．この場を借りて，心より御礼申し上げます．\n2025 年1 月31 日\n大久保紗恵\n89\n参考文献\n[1] Obesity and overweight. https://www.who.int/news-room/fact-sheets/detail/\nobesity-and-overweight.\n[2] Japan Ministry of Health Labor and Welfare.\nThe national health and nutrition\nsurvey in japan, reiwa ﬁrst year. https://www.mhlw.go.jp/content/000711005.\npdf.\n[3] info01.pdf. http://sosyaku.umin.jp/info/file/info01.pdf.\n[4] Japan Preventive Association of Life-style related Disease. Eating too fast can lead\nto obesity and metabolic syndrome. six measures to help you chew your food well (in\njapanese). https://seikatsusyukanbyo.com/calendar/2017/009495.php.\n[5] Yuichi Ando, Nobuhiro Hanada, and Shigetaka Yanagisawa. Does ”eating slowly”\nlead to prevent obesity ? Health Science and Health Care, Vol. 8, No. 2, pp. 51–63,\n2008.\n[6] Ronald E. Milliman. The inﬂuence of background music on the behavior of restaurant\npatrons on jstor, 1986. [Online; accessed 2025-01-29].\n[7] Luisa Torri Riccardo Migliavada, Fabio Luceri. Chew that beat! how music tempo\ninﬂuences eating behaviors and emotions - sciencedirect, 9 2024.\n[8] Derek Victor Byrne Qian Janice Wang Signe Lund Mathiesen, Line Ahm Mielby.\nMusic to eat by: A systematic investigation of the relative importance of tempo and\narticulation on eating time - sciencedirect, 12 2020.\n[9] Noriko Kishida and Yoshie Kamimura. Relationship of conversation during meal and\nhealth and dietary life of school children. The Japanese Journal of Nutririon and\nDietetics, Vol. 51, No. 1, pp. 23–30, 1993.\n[10] Kanae Nakaoka, Seiko Noda, Asako Yamada, Yuriko Togashi, Naoko Namiki, and\nMasae Goseki-Sone. The association of“ the frequency of shared family meals and\n90\nspontaneous communication during mealtimes ”with decision-making, goal-setting\nskills, and qol in 5th and 6th grade students. Journal of Japanese Society of Shokuiku,\nVol. 14, No. 1, pp. 41–51, 2020.\n[11] Hiroko Moriwaki, Noriko Kishida, Yoshie Kamimura, Noriko Takeda, Akiko Sakuma,\nChieko Teraoka, and Masayuki Kakehashi. Relationship of the health condition, daily\nliving habits, and diet of female university students with their mealtime conversation\nat elementary school.\nJournal of Home Economics of Japan, Vol. 58, No. 6, pp.\n327–336, 2007.\n[12] “ food for talk ”adds meaning to family meal — the seattle times. https://www.\nseattletimes.com/news/food-for-talk-adds-meaning-to-family-meal/.\n[13] ’talking at mealtimes boosts children’s conﬁdence’ - bbc news. https://www.bbc.\ncom/news/education-23502947.\n[14] Mealtime\nconversations\nfor\nfamily\nmeals.\nhttps://extension.psu.edu/\nmealtime-conversations-for-family-meals.\n[15] Nur Asmiza Selamat and Sawal Hamid Md Ali. Automatic food intake monitoring\nbased on chewing activity: A survey. IEEE Access, Vol. 8, pp. 48846–48869, 2020.\n[16] Hideto Mitsui, Joe Ohara, Anna Yokokubo, and Guillaume Lopez. Method to improve\nreal-time chewing and speaking detection accuracy from bone-conduction sound. Mul-\ntimedia, Distributed, Cooperative, and Mobile Symposium 2018, Vol. 2018, pp. 562–\n566, 2018.\n[17] Yuxing Wu, Elisa Krebs, Adithya Hassan Shankaranand, Patrick Shih, and Chia-\nFang Chung. Meal chat: Promoting mealtime social interaction for college students.\nIn Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing\nSystems, pp. 1–8, 2020.\n[18] Rui Zhang, Severin Bernhart, and Oliver Amft. Diet eyeglasses: Recognising food\nchewing using emg and smart eyeglasses. 2016 IEEE 13th International Conference\non Wearable and Implantable Body Sensor Networks (BSN), pp. 7–12, 2016.\n[19] Keum San Chun, Sarnab Bhattacharya, and Edison Thomaz.\nDetecting eating\nepisodes by tracking jawbone movements with a non-contact wearable sensor. Pro-\n91\nceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies,\nVol. 2, No. 1, pp. 1–21, 2018.\n[20] Shibo Zhang, Yuqi Zhao, Dzung Tri Nguyen, Runsheng Xu, Sougata Sen, Josiah\nHester, and Nabil Alshurafa. Necksense: A multi-sensor necklace for detecting eating\nactivities in free-living conditions. Proceedings of the ACM on Interactive, Mobile,\nWearable and Ubiquitous Technologies, Vol. 4, No. 2, pp. 1–26, 2020.\n[21] Keum San Chun, Sarnab Bhattacharya, Caroline Dolbear, Jordon Kashanchi, and\nEdison Thomaz. Intraoral temperature and inertial sensing in automated dietary\nassessment: a feasibility study. In Proceedings of the 2020 International Symposium\non Wearable Computers, pp. 27–31, 2020.\n[22] Oliver Amft, Mathias St¨ager, Paul Lukowicz, and Gerhard Tr¨oster.\nAnalysis of\nchewing sounds for dietary monitoring. In International Conference on Ubiquitous\nComputing, pp. 56–72. Springer, 2005.\n[23] Shengjie Bi, Tao Wang, Nicole Tobias, Josephine Nordrum, Shang Wang, George\nHalvorsen, Sougata Sen, Ronald Peterson, KoﬁOdame, Kelly Caine, et al. Auracle:\nDetecting eating episodes with an ear-mounted sensor. Proceedings of the ACM on\nInteractive, Mobile, Wearable and Ubiquitous Technologies, Vol. 2, No. 3, p. 92, 2018.\n[24] Masaki Shuzo, Shintaro Komori, Tomoko Takashima, Guillaume Lopez, Seiji Tat-\nsuta, Shintaro Yanagimoto, Shin’ichi Warisawa, Jean-Jacques Delaunay, and Ichiro\nYamada. Wearable eating habit sensing system using internal body sound. Jour-\nnal of Advanced Mechanical Design, Systems, and Manufacturing, Vol. 4, No. 1, pp.\n158–166, 2010.\n[25] Abdelkareem Bedri, Diana Li, Rushil Khurana, Kunal Bhuwalka, and Mayank Goel.\nFitbyte: Automatic diet monitoring in unconstrained situations using multimodal\nsensing on eyeglasses. In Proceedings of the 2020 CHI Conference on Human Factors\nin Computing Systems, pp. 1–12, 2020.\n[26] Vasileios Papapanagiotou, Christos Diou, Lingchuan Zhou, Janet van den Boer, Mon-\nica Mars, and Anastasios Delopoulos. A novel chewing detection system based on\nppg, audio, and accelerometry. IEEE journal of biomedical and health informatics,\nVol. 21, No. 3, pp. 607–618, 2016.\n92\n[27] Yang Chen, Zhitong Cui, and Ching Chiuan Yen. Chewpin: a wearable acoustic\ndevice for chewing detection. In Adjunct Proceedings of the 2021 ACM International\nJoint Conference on Pervasive and Ubiquitous Computing and Proceedings of the\n2021 ACM International Symposium on Wearable Computers, pp. 11–12, 2021.\n[28] Peter Arnold, Rohit Ashok Khot, and Florian’Floyd’ Mueller. ” you better eat to\nsurvive” exploring cooperative eating in virtual reality games. In Proceedings of the\nTwelfth International Conference on Tangible, Embedded, and Embodied Interaction,\npp. 398–408, 2018.\n[29] Joohee Kim, Kwang-Jae Lee, Mankyung Lee, Nahyeon Lee, Byung-Chull Bae, Gene-\nhee Lee, Juhee Cho, Young Mog Shim, and Jun-Dong Cho. Slowee: A smart eating-\nspeed guide system with light and vibration feedback. In Proceedings of the 2016\nCHI Conference Extended Abstracts on Human Factors in Computing Systems, pp.\n2563–2569, 2016.\n[30] Joohee Kim and Byung-Chull Bae. An animated emoji feedback system for eating\nrate guidance. In Proceedings of the 2018 ACM International Joint Conference and\n2018 International Symposium on Pervasive and Ubiquitous Computing and Wearable\nComputers, pp. 388–391, 2018.\n[31] Joohee Kim and Byung-Chull Bae. A smartwatch-based feedback system for eating\nrate guidance. In Proceedings of the 2018 ACM International Joint Conference and\n2018 International Symposium on Pervasive and Ubiquitous Computing and Wearable\nComputers, pp. 384–387, 2018.\n[32] Nishiki Motokawa, Asuka Kato, Anna Yokokubo, and Guillaume Lopez. Mealjammer:\nPlate driven meal obstruction system using electromagnet (in japanese). Technical\nreports Entertainment Computing (EC), Vol. 2020, No. 14, pp. 1–2, 2020.\n[33] Haruka Kamachi, Sae Ohkubo, Anna Yokokubo, and Guillaume Lopez. Eating habit\nimprovement system using dietary sound. IPSJ Behavior Transformation by IoT 　\nBehavior Modiﬁcation Research Kicking-oﬀSymposium 　16.4.2022, 2022.\n[34] Rei Nakaoka, Yugo Nakamura, Yuki Matsuda, Shinya Misaki, and Keiichi Yasumoto.\neat2pic: Food-tech design as a healthy nudge with smart chopsticks and canvas. In\n2021 IEEE International Conference on Pervasive Computing and Communications\n93\nWorkshops and other Aﬃliated Events (PerCom Workshops), pp. 389–391. IEEE\nComputer Society, 2021.\n[35] Guillaume Lopez Sae Ohkubo.\nChewker:\nEating habit detection system using\nnecklace-type device.\nマルチメディア, 分散協調とモバイルシンポジウム2023 論\n文集, Vol. 2023, No. 1, pp. 1597–1604, 2023.\n[36] At how many decibels does a human speak normally. https://decibelpro.app/\nblog/how-many-decibels-does-a-human-speak-normally/.\n[37] Japan Dental Hygienists’ Association. Keep your biting power (in japanese). https:\n//www.jdha.or.jp/pdf/health/hatookuchi_20200401_2.pdf.\n[38] 厚生労働省. 歯科保健と食育の在り方に関する検討会報告書「歯・口の健康と食育～噛\nミング30（カミングサンマル）を目指して～」. https://www.mhlw.go.jp/content/\n10900000/000687163.pdf.\n[39] Eating slowly has many beneﬁts! (in japanese). https://www.osaka-tounyoubyou.\njp/ryouri/yukkuritabe/.\n[40] AOL.com Editors. Is taking 100 bites a day the key to weight loss?, 8 2014.\n[41] System usability scale - wikipedia.\nhttps://en.wikipedia.org/wiki/System\\\n_usability\\_scale.\n[42] The system usability scale: Past, present, and future. https://www.researchgate.\nnet/publication/324116412_The_System_Usability_Scale_Past_Present_\nand_Future.\n94\n付録\n付録A 本研究に関する論文と発表実績\n2023 年2 月\nHaruka Kamachi, Sae Ohkubo, Anna Yokokubo, Guillaume Lopez\n“ Eating Habit Improvement System using Dietary Sound ”\nHEALTHINH 2023 : 16th International Conference on Health Informatics @Lisbon\n2023 年7 月\nSae Ohkubo，Guillaume Lopez\n“ Chewker: Eating Habit Detection System Using Necklace-type Device ”\n情報処理学会マルチメディア、分散、協調とモバイルシンポジウム2023 @富山国際会議\n場\n2024 年6 月\n伊東優乃，大久保紗恵，木村正子，ロペズギヨーム\n“ CutRest: カトラリー置き型摂食リズム調整システム”\n一般社団法人情報処理学会マルチメディア、分散、協調とモバイルシンポジウム2024 @\n花巻温泉\n95\n付録B 本研究の実験に使用した研究同意書\n図6.1 から図6.3 までは本研究の実験で使用したの研究同意書である．\n図6.1: 本実験の同意書（1/3）\n96\n図6.2: 本実験の同意書（2/3）\n97\n図6.3: 本実験の同意書（3/3）\n98\n付録C 質疑応答内容\n伊藤教授（情報テクノロジー学科）\nQ\n実験の際のセンシングにChewker を使う必要性は何ですか．フィードバックがラン\nダムな条件の実験を行うべきです．\nA\n詳細な食事行動（摂食、咀嚼、嚥下、発話）すべてをリアルタイムで検出している\n研究はありません．摂食のみであったり、咀嚼のみの検出をする研究はありますが，\nすべてを高い精度で検出できている研究はありません．現時点ではフィードバック\nを提示するために必要なセンシングはChewker でのみ実現が可能であると言えます．\n浦垣先生（情報テクノロジー学科）\nQ\n食習慣改善に対するChewker の必要性．技術的な有用性についてどのようにお考え\nですか．このシステムは長期的に使用されるとお考えですか．また，継続利用を促\nすための工夫について教えてください．\nA\n本システムは，早食いを改善したいが自制が難しい人々を主なターゲットとしてい\nます．自身で咀嚼回数やペースを管理するのは難しく，意識していても持続するこ\nとが困難な場合が多いです．そのため，Chewker は音楽を活用しながら食事行動を\nコントロールし，アプリが客観的に食習慣の良し悪しを判断できる点で有用だと考\nえます．現代では，スマートフォンを見ながらの食事が一般的になりつつあります\nが，食事中にスマートフォンを見ることは，健康に悪影響があるという研究があり\nます．むしろ，スマートフォンなどに注視させずに，会話などを促進してくれれば良\nい食事となります．ゴールはChewker を使って，良い食事を習慣付けて，Chewker\nがなくとも良い食事をできるようになることです．できるようになるまで，どの程\n度の期間を要するかは未検証でわかりませんが，継続してもらうために，成長を示\nすメタファ（花が成長するなど）を介してフィードバックを提示することが一つの\nアイディアとしてあげられます．\n99\n山下先生（情報テクノロジー学科）\nQ\nChewker の目的は音楽を速さを変えながら流すことで咀嚼回数やペースを適切に保\nつことで合っていますか．デモ動画ですと，アプリケーションの画面を見て，回数を\n把握し，増やしたり減らすことができるように見えました．その行動が音楽によっ\nて誘発されていれば，ユーザがテキスト情報を参考に回数を調整してもいいという\nことでしょうか．想定としては音楽のみで改善してほしいのか，アプリケーション\nを見てもらう前提なのかどちらでしょうか．\nA\nChewker の目的は音楽を速さを変えながら流すことで咀嚼回数やペースを適切に保\nつことで合っています．ビデオでは配慮が足らず，画面を注視している形になって\nしまっていますが，実際には注視する必要はなく，音楽が1 倍速だと，\n「今は良い食\nべ方なんだ」，0.5 倍速なら，「今はペースもしくは回数が不十分なんだ」と感じて\nほしいです．ユーザがテキスト情報を参考に回数を調整してもいいのですが，想定\nとしては音楽のみで改善してほしいです．どうしても1 倍に戻らない場合など気に\nなった場合のみ，テキストを確認してもらう形になります．また，音楽自体がゆっ\nくり噛むことにつながったり，遅いテンポの音楽はさらに良い食事を促すことがわ\nかっているので，無意識にも咀嚼回数などの増加につながっていると考えます．\n100\n",
        "chunks": [
            "M2024_Sae_Ohkubo. M2024_Sae_Ohkubo. M2024_Sae_Ohkubo",
            "青  山  学  院  大  学 \n理  工  学  研  究  科 \n理工学専攻 \n知能情報 \nコース\n修  士  論  文 \n学 生 番 号\n35623218\n氏 \n名\n大久保　紗恵\n研究指導教員\nロペズ ギヨーム\nChewker\nネックレス型デバイスを用いた\n食習慣改善システム\n大久保紗恵\n2025/01/31\nAcademic Year of 2024, Submitted on January 31st, 2025 \n \nGraduate School of Science and Engineering, Aoyama Gakuin University \n \nTitle: Chewker: Eating Habit Improvement System using Necklace-type Device \n \nStudent Name: Sae Ohkubo \nID Number: 35623218   \nDegree: Master of Engineering \nCourse: Intelligence and Information \nThesis Advisor",
            "urse: Intelligence and Information \nThesis Advisor: Professor Guillaume Lopez \n \nAbstract  \n Obesity may lead to lifestyle diseases such as diabetes and high blood pressure. Eating \nslowly and chewing well is essential to prevent obesity. Past studies revealed that \nconversation during the meal is related to health. So, increasing conversation during \nthe meal is desirable. On the other hand, presenting information to eaters, such as \nchewing count in real-time, prevents them from eating too fas",
            "nt in real-time, prevents them from eating too fast and improves their \nconsciousness of eating activity. \nThis study developed Chewker, a system that detects eating behaviors in real time and \nprovides feedback. Chewker combines two parts: a necklace-type device equipped with \nan IMU sensor, a piezo film sensor, an ultrasonic sensor to detect feeding, chewing, and \nswallowing, and a smartphone application that uses the microphone to detect talking \nand provide feedback. Since slow music has bee",
            "ng \nand provide feedback. Since slow music has been shown to promote slower eating and \nincrease chewing count, Chewker dynamically adjusts music playback speed in real-\ntime based on chewing count and interval, slowing to 0.5x when these values fall below \na threshold and returning to normal speed when they meet the criteria. After meals, the \nsystem provides feedback on various metrics, including total chewing count, chewing \ninterval, and meal duration, storing data for long-term behavior tra",
            " duration, storing data for long-term behavior tracking.  \nEvaluation of Chewker accuracy with 15 subjects showed high F1-scores of 0.84 for \nchewing and 0.83 for feeding detection but a lower F1-score of 0.64 for swallowing, \nhighlighting the challenge of distinguishing swallowing from chewing remains. \nAn evaluation with 11 subjects showed that real-time feedback increased total meal \nduration for all subjects, total chewing count and chewing count per swallowing for 10 \nsubjects, and chewing ",
            "ount per swallowing for 10 \nsubjects, and chewing interval for eight subjects. Seven subjects showed a decrease in \nchewing count per feeding, but their feeding count increased, suggesting smaller bites \nand more frequent food intake. However, talking time decreased for many subjects, \nlikely due to increased focus on chewing. The pre-experiment survey indicated that 10 \nsubjects did not usually pay attention to chewing, but all reported greater awareness \nafter using the system. \nFuture work in",
            "awareness \nafter using the system. \nFuture work includes long-term evaluation of real-time feedback effects, improvements \nin swallowing detection through enhanced calibration and design, and modifications to \nimprove ease of use and comfort. Adding feedback to promote conversation will also be \nconsidered. \n理工学専攻修士論文要旨 \n \n \n提出年度\n      ： 2024 年度 \n提\n出\n日\n      ： 2025 年 1 月 31 日 \n専修コース： 知能情報 コース \n学生番号\n      ： 35623218 \n学生氏名\n      ： 大久保 紗恵 \n研究指導教員： ロペズ ギヨーム 教授 \n \n（論文題目） \n \nChewker ネックレス型デバイスを用いた食習慣改",
            "ペズ ギヨーム 教授 \n \n（論文題目） \n \nChewker ネックレス型デバイスを用いた食習慣改善システム \n \n（内容の要旨） \n肥満は生活習慣病を引き起こす恐れがある．早食いの人ほどBMI が高い傾向があり，ゆっくりよく\n噛んで食べることが肥満を予防するために重要である．また食事中の会話は健康に関連があることが分\nかっており，食事中の会話を増やすことが望ましい．さらに，リアルタイムで咀嚼回数などの食事に関\nする情報を食事者に提示することにより，早食いを防ぎ，食事行動に対する意識の改善を促すことが期\n待できる． \n以上より本研究の目的は，食事行動の定量化によって食習慣に基づく食事中の行動への意識改善を行\nうことである．研究目的の達成のために，自然な食事環境下でリアルタイムに食事行動を検出し，検出\nされた食事行動に基づいたフィードバックを行うシステム (Chewker) を提案する．Chewker は慣性セ\nンサ，ピエゾフィルム，超音波センサが搭載されたネックレス型デバイス，およびスマートフォンのマ\nイクの4 つを用いてリアルタイムに食事行動を検出する．検出する食事行動は摂食・咀嚼",
            "マートフォンのマ\nイクの4 つを用いてリアルタイムに食事行動を検出する．検出する食事行動は摂食・咀嚼・嚥下・発話\nの4 種類である．ゆっくりとした音楽は咀嚼のペースを下げて，咀嚼回数，食事時間を増加させること\nから，リアルタイムでのフィードバックは音楽を利用する．嚥下のタイミングで，前回の嚥下からの咀\n嚼回数と咀嚼ペースの平均を算出し，どちらか一方，もしくは両者とも基準値に満たない場合，音楽が\n0.5 倍速になり，両条件が満たされた場合は1.0 倍速に戻る．食事終了後には，摂食・咀嚼・嚥下の回\n数，および，摂食間・嚥下間の咀嚼回数の平均，咀嚼ペースの平均，総食事時間，総食事時間に対する\n会話時間の割合をもとに食事全体に対するフィードバックを表示する．食事データは保存され，いつで\nも振り返りを可能にし，可視化した過去の推移を確認できる． \nまず，Chewker の食事行動検出精度を評価した．被験者15 名に，ピーナッツを口に運び，20 回咀嚼\nして1 回嚥下するという一連の動作を3 回計測した．咀嚼のF1 値は0.84 と高い精度を示し，摂食も\n0.83 と安定した精度で検出できることが",
            "した．咀嚼のF1 値は0.84 と高い精度を示し，摂食も\n0.83 と安定した精度で検出できることが確認された．一方で，嚥下のF1 値は0.64 と他の行動に比べて\n精度が低く，咀嚼との誤検出が課題として挙げられた． \n次に，Chewker の有用性をリアルタイムフィードバックの側面から検証するために，被験者11 人に\n対し評価実験を行った．Chewker のリアルタイムフィードバック機能ありとなしのそれぞれの状態で\n同じお弁当を，日にちを変えて合計2 回食べ，総食事時間・総咀嚼回数・摂食間・嚥下間の咀嚼回数，\n咀嚼ペース，会話時間の6 項目の数値の変化を評価した．結果，Chewker の利用により，総食事時間に\nおいて全員が，総咀嚼回数・嚥下間の咀嚼回数において10 名，咀嚼ペースにおいて8 名の数値が上昇\nした．摂食間の咀嚼回数においては7 名の被験者で減少が見られたが，この7 名は摂食回数が増加して\nいるため，一口あたりの食べ物の量が減少し，口に運ぶ回数が増えたことが考えられるため，良い変化\nと言える．会話時間の割合は減少している被験者が多く，リアルタイムフィードバックにより，会",
            "，良い変化\nと言える．会話時間の割合は減少している被験者が多く，リアルタイムフィードバックにより，会話よ\nりも咀嚼に意識していると考える．事前アンケートでは「普段の食事で噛むことを意識していない」と\n回答した被験者が10 名いたが，実験後には全員が「噛むことを意識した」と回答し，食事行動への意\n識の改善が明らかになった． \n今後は，長期間の使用によるフィードバック効果検証を実施したい．また嚥下の検出精度に課題が残\nるため，キャリブレーションの改良や，デバイスの設計の見直しを検討したい．アンケートで「デバイ\nスの装着が難しい」，「首が苦しい」という意見が寄せられたため，より簡単に装着でき，快適に使用で\nきるよう改善する．さらに発話を促すリアルタイムフィードバックの追加を検討したい． \n \n \n青山学院大学大学院理工学研究科 \n目次\n第1 章\n序論\n3\n1.1\n研究背景. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n3\n1.1.1\n肥満者の増加. . . . . . . . . . . . ",
            ". . . . . .\n3\n1.1.1\n肥満者の増加. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n3\n1.1.2\n肥満と咀嚼の関係. . . . . . . . . . . . . . . . . . . . . . . . . . . .\n4\n1.1.3\n食事行動と食事中の音楽の関係. . . . . . . . . . . . . . . . . . . .\n5\n1.1.4\n肥満と食事中の会話の関係. . . . . . . . . . . . . . . . . . . . . . .\n6\n1.1.5\n食事行動認識の必要性. . . . . . . . . . . . . . . . . . . . . . . . .\n6\n1.2\n研究目的. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n7\n1.3\n本論文の構成. . . . . . . . . . . . . . . . . . . . . . . . . ",
            ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n7\n第2 章\n食事行動検出についての関連研究\n8\n2.1\n食事行動検出・分類手法に関する研究\n. . . . . . . . . . . . . . . . . . . .\n8\n2.2\n食事行動に関するフィードバックを用いた研究. . . . . . . . . . . . . . . .\n13\n2.3\n関連研究についてのまとめ. . . . . . . . . . . . . . . . . . . . . . . . . . .\n16\n第3 章\nChewker: 食習慣改善システム\n19\n3.1\nシステムの概要. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n19\n3.2\nネックレス型デバイスとスマートフォンの連携. . . . . . . . . . . . . . . .\n22\n3.3\nChewker の利用手順\n. . . . . . . . . . . . .",
            ". .\n22\n3.3\nChewker の利用手順\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n24\n3.4\n食事行動検出のアルゴリズム\n. . . . . . . . . . . . . . . . . . . . . . . . .\n31\n3.4.1\n発話検出. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n33\n3.4.2\n摂食検出. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n34\n3.4.3\n咀嚼と嚥下の検出. . . . . . . . . . . . . . . . . . . . . . . . . . . .\n36\n3.5\n咀嚼と嚥下の検出. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n36\n3.6\nフィードバックシステムの概要\n. . . . . . ",
            ". . . . . . . .\n36\n3.6\nフィードバックシステムの概要\n. . . . . . . . . . . . . . . . . . . . . . . .\n38\n3.6.1\nフィードバック内容\n. . . . . . . . . . . . . . . . . . . . . . . . . .\n38\n3.6.2\n音楽を用いたリアルタイムフィードバック. . . . . . . . . . . . . .\n40\n3.6.3\n食事直後の視覚的フィードバック. . . . . . . . . . . . . . . . . . .\n44\n3.6.4\n過去のデータ参照の視覚的フィードバック. . . . . . . . . . . . . .\n53\n第4 章\nChewker の食事行動検出精度評価実験\n57\n4.1\n食事行動検出精度実験概要. . . . . . . . . . . . . . . . . . . . . . . . . . .\n57\n4.2\n食事行動検出精度実験手順. . . . . . . . . . . . . . . . . . . . . . . .",
            "験手順. . . . . . . . . . . . . . . . . . . . . . . . . . .\n57\n4.3\n食事行動検出精度実験結果. . . . . . . . . . . . . . . . . . . . . . . . . . .\n57\n4.3.1\n摂食の検出精度. . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n60\n4.3.2\n咀嚼の検出精度. . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n61\n1\n4.3.3\n嚥下の検出精度. . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n62\n第5 章\nChewker のフィードバック効果検証\n63\n5.1\nフィードバック効果検証概要\n. . . . . . . . . . . . . . . . . . . . . . . . .\n63\n5.2\nフィードバック効果検証手順\n. . . . . . . . . . . . .",
            ". .\n63\n5.2\nフィードバック効果検証手順\n. . . . . . . . . . . . . . . . . . . . . . . . .\n63\n5.2.1\n事前アンケート. . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n65\n5.2.2\nSUS アンケート. . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n67\n5.2.3\nChewker についてのアンケート. . . . . . . . . . . . . . . . . . . .\n67\n5.3\nフィードバック効果検証結果\n. . . . . . . . . . . . . . . . . . . . . . . . .\n70\n5.3.1\n全体の食事時間の結果. . . . . . . . . . . . . . . . . . . . . . . . .\n70\n5.3.2\n全体の咀嚼回数の結果. . . . . . . . . . . . . . . . . . . . . . . . .",
            "果. . . . . . . . . . . . . . . . . . . . . . . . .\n71\n5.3.3\n摂食間の咀嚼回数の結果. . . . . . . . . . . . . . . . . . . . . . . .\n73\n5.3.4\n嚥下間の咀嚼回数の結果. . . . . . . . . . . . . . . . . . . . . . . .\n76\n5.3.5\n咀嚼ペースの結果. . . . . . . . . . . . . . . . . . . . . . . . . . . .\n78\n5.3.6\n会話時間の結果. . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n79\n5.3.7\nSUS スコア結果. . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n81\n5.3.8\n実験前後のアンケート結果. . . . . . . . . . . . . . . . . . . . . . .\n82\n第6 章\n結論\n87\n6.1\nまとめ. ",
            " . . . . . . . . . . . . .\n82\n第6 章\n結論\n87\n6.1\nまとめ. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n87\n6.2\n今後の展望\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n88\n謝辞\n89\n参考文献\n90\n付録\n95\n付録A . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n95\n付録B . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n96\n付録C . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n99\n2\n第",
            ". . . . . . . . . . . . . . . . . . . . . .\n99\n2\n第1章\n序論\n序論では，本研究を実施するに至った背景と研究の目的，本論文の構成について述べる．\n本研究にかかわる社会的背景や技術的背景を述べ，研究の意義について論述する．そのう\nえで本研究で提案する自然な環境下での様々なセンサを用いた食事行動分類によるフィー\nドバックシステムの必要性と利点について述べ，広範囲な研究範囲の中で，本研究がどの\nような位置づけであるかについて説明する．\n1.1\n研究背景\n1.1.1\n肥満者の増加\n世界保健機関ではBMI が25 以上を過体重，30 以上を肥満と定めている．2016 年には\n18 歳以上の39 ％が過体重、13 ％が肥満であったことが分かっており，さらに1975 年以\n降，世界的な肥満の数は約3 倍となっている[1]．また、世界的に見ると低体重でなくな\nるよりも過体重、肥満でなくなっている人の方が多い。肥満は、ほとんどの体のシステム\nに影響を与える病気であり、糖尿病や高血圧などの生活習慣病を引き起こす恐れがある．\n世界的に肥満が増え問題となっている",
            "気であり、糖尿病や高血圧などの生活習慣病を引き起こす恐れがある．\n世界的に肥満が増え問題となっている中，日本でも厚生労働省によって対策が講じられて\nきた．日本においてはBMI が25 以上の場合に肥満であると判定されるのだが，肥満の患\n者数は10 年前から減少していないことが示唆されている[2]．図1.1 から肥満者の割合は\n年数に対して大きな変動がないことが分かり，これは肥満者の割合が減少していないこと\nを意味する．\n　\n3\n図1.1: 日本の肥満率の年次推移（[2] をもとに作成）\n1.1.2\n肥満と咀嚼の関係\n咀嚼とは口に取り込んだ食べ物を噛み砕くことである．また，日常生活においては食物\nを飲み込むのに適した性状に噛み砕き，唾液と混ぜる口の働きと定義されている[3]．よ\nく噛むことで唾液が多く分泌され血糖値が早く上がり，その結果，満腹中枢に働くため空\n腹感が満たされる．そのため，肥満の予防にもなる[4]．また，図1.2 より，食べる速さが\n早い人ほどBMI が高い傾向にあることが示されている[5]．これにより，早食いと肥満は\n強い関係にあることが分かる．これらのことから，肥満を予",
            "されている[5]．これにより，早食いと肥満は\n強い関係にあることが分かる．これらのことから，肥満を予防するためにはゆっくりよく\n噛んで食べることが重要であると考えられる．\n図1.2: 食事速度別のBMI とBMI 上昇率（[5] から引用）\n4\n1.1.3\n食事行動と食事中の音楽の関係\n近年の研究では，食行動は個人の心理的・生理的状態といった内部要因だけでなく，周囲\nの環境要因（照明，色彩，温度，音楽など）にも影響を受けることが示されている．1986\n年の研究[6] では，Milliman は、レストランの客は遅い音楽を聴いているときの方が速い\n音楽を聴いている時よりも食事を終えるのに時間がかかったと結論付けた．\nまた，音楽のテンポが食事行動や感情に与える影響を調査した研究[7] では，遅いテン\nポの音楽を聴きながら食事をした参加者の方が，食事時間，咀嚼回数の合計，咀嚼時間の\n合計がすべて増加したことが確認されている．具体的には，124 人の参加者を対象に，速\nいテンポ（145 BPM）と遅いテンポ（85 BPM）の音楽を聴きながら食事をする2 つのグ\nループに分けて実験を行った．その",
            "と遅いテンポ（85 BPM）の音楽を聴きながら食事をする2 つのグ\nループに分けて実験を行った．その結果，遅いテンポの音楽を聴いた参加者は，食事時間\nが20 ％増加し，咀嚼回数が約30 ％増加し，総咀嚼時間が約24 ％増加した．さらに，遅\nいテンポの音楽は参加者をより落ち着かせ，平穏な気持ちにさせる効果があることが示さ\nれた．\n音楽の特定の要素，特にテンポとアーティキュレーションが食事時間に与える影響につ\nいて調査した研究[8] では2 つの実験が行われた．実験1 では，テンポとアーティキュレー\nションが異なる2 種類の音楽を用意し，チョコレートの試食と評価を行う際の食事時間を\n測定した．参加者は，自身の食事時間が計測されていることを認識していなかった．その\n結果，遅いテンポかつレガート（slow + legato）の音楽を聴いていた場合，速いテンポ\nかつスタッカート（fast + staccato）の音楽を聴いていた場合と比較して，食事時間が有\n意に長くなることが確認された．実験2 では，テンポとアーティキュレーションの相互作\n用についてより詳細に調査するために，無音の条件を加え，遅",
            "は，テンポとアーティキュレーションの相互作\n用についてより詳細に調査するために，無音の条件を加え，遅いテンポ＋レガート，遅い\nテンポ＋スタッカート，速いテンポ＋レガート，速いテンポ＋スタッカートの計5 つの条\n件を設定した．その結果，テンポには主効果があり，遅いテンポの音楽を聴いていた場合\nのほうが速いテンポの音楽を聴いていた場合よりも食事時間が有意に長くなった．また，\nアーティキュレーションにはテンポとの交互作用が見られ，遅いテンポの音楽を聴いてい\nた場合においてのみ，レガートの音楽を聴いていたときのほうがスタッカートの音楽を聴\nいていたときよりも食事時間が延長されることが示された．一方，速いテンポの音楽条件\nでは，レガートとスタッカートの間に食事時間の有意な差は認められなかった．さらに，\n音楽の存在自体にも主効果が見られ，いずれの音楽条件においても，無音の条件で食事を\nした場合と比較して食事時間が有意に長くなった．これらの結果から，音楽のテンポは食\n5\n事時間を調整する環境要因の一つであり，特に遅いテンポの音楽は食事時間を延長させる\nことが示唆された．加えて，音楽の存在そのものが食",
            "であり，特に遅いテンポの音楽は食事時間を延長させる\nことが示唆された．加えて，音楽の存在そのものが食事時間を延ばす効果を持つことが示\nされており，これらの知見は，ゆっくり食べることを促進し，過剰摂取を防ぐなど，より\n健康的な食習慣の形成に寄与する可能性がある．\n1.1.4\n肥満と食事中の会話の関係\n近年，家族が揃って食事をする機会が減少し，ひとりで食事をする孤食が問題となって\nいる．岸田らの調査によると，食事中の会話は健康に関連があることが分かっている[9]．\n食事中の家族との会話がある場合，生活習慣が規則正しく，食生活においても野菜をよく\n食べていたり，好き嫌いがないなど，健康状態である割合が高いことが示されたのだ．中\n岡らの調査からは，食事中のコミュニケーションの多さが児童の身体的・精神的健康の項\n目を含む生活全体を捉えたQOL の良好さに関連することが分かった[10]．また，森脇ら\nが女子学生を対象に行った調査結果からは，小学生の頃に食事中に楽しい会話をよくして\nいた学生は健康状態が良い傾向があることが分かった[11]．特に家族での食事中の会話は\n重要である[12, 13, 14",
            "が良い傾向があることが分かった[11]．特に家族での食事中の会話は\n重要である[12, 13, 14]．会話を伴う食事は，家族それぞれの経験を共有する機会となり，\n子どもは食事中の会話を通じてコミュニケーションスキルを身に付けることができる．\n1.1.5\n食事行動認識の必要性\n近年Charge3（Fitbit 製）やwena wrist pro（Sony 製）に代表されるように，市販され\nているウェアラブルデバイスでは一日の消費カロリーの測定ができるため，これに関連し\nた人間の活動レベルをモニタリングすることが可能である．しかし，自由な食事環境での\n食事行動を自動的に検出するデバイス、特に咀嚼とともに嚥下や会話などの複数行動を\n検出するデバイスははまだ市販されている状態にない[15]．また，食事行動の中でも咀嚼\nや発話を高精度に識別可能になり，リアルタイムでの咀嚼回数や会話時間の食事者への提\n示が可能となることで，咀嚼回数の増加や発話意識の向上など，食事に対する意識の改善\nが期待できる．先行研究では，実験室環境において，食事中にリアルタイムで咀嚼回数を\nフィードバックすることで咀嚼回数",
            "先行研究では，実験室環境において，食事中にリアルタイムで咀嚼回数を\nフィードバックすることで咀嚼回数が増加することが示された[16]．\nさらに食事の時間を楽しく過ごすためのテクノロジーとしてMeal Chat が開発されてい\nる[17]．これは，大学生が社交的になる機会を提供し，見知らぬ人と食事の時間を共有す\nることへの心理的な壁を低くすることを目的としている．\n6\n1.2\n研究目的\n食事の際の咀嚼回数を検出可能になれば、食事者にリアルタイムで咀嚼回数が少ないこ\nとや早食いであることをフィードバックし，肥満の予防につなげることが可能である．ま\nた，食事中の会話も検出が可能になれば，フィードバックによって食事中の会話の増加を\n期待できる．さらに，咀嚼や嚥下，会話の他に食べ物を口に運ぶ行動である摂食，水分を\n嚥下した量など，より詳細な食事行動を識別することが可能になれば，食事者の健康促進\nに貢献できると考える．以上から本研究では、自然な食事環境下でのより詳細な食事行動\nの定量化とフィードバックによる食事行動への意識改善を目的とする．具体的な目的は以\n下の2 点である．\n1. 自然な食事環境",
            "クによる食事行動への意識改善を目的とする．具体的な目的は以\n下の2 点である．\n1. 自然な食事環境下での，詳細な食事行動をリアルタイムに検出するシステムの実現．\n2. 検出した食事行動に基づいて，フィードバックを提示することで，食事行動への意\n識改善を行うシステムの開発．\n1.3\n本論文の構成\n第1 章では，序論と題し本論文の研究背景，研究目的，そして本論文の構成について述\nべた．第2 章では，関連研究や関連技術に関して説明する．第3 章では，自然な食事環境\n下での様々なセンサを用いたリアルタイムでの食事行動検出、およびスマートフォンを用\nいた食習慣向上のためのフィードバックシステムついて述べる．第4 章では，食事行動検\n出の精度評価と考察，および，フィードバックシステムの評価と考察を述べる．第5 章で\nは，本論文のまとめと今後の展望について述べる．\n7\n第2章\n食事行動検出についての関連研究\n第2 章では本研究に関する先行研究や技術について述べる．まず，食事行動の検出方法\nや分類方法に関する先行研究について説明する．次に，食事行動に関するフィードバック\nを用いた先行研究を紹介する．",
            "に関する先行研究について説明する．次に，食事行動に関するフィードバック\nを用いた先行研究を紹介する．最後に，本研究にかかわる研究や技術についてまとめ，先\n行研究での課題をまとめる．\n2.1\n食事行動検出・分類手法に関する研究\nZhang らは，食べ物を咀嚼することをセンシングするために，食事をモニタリングする\nためのスマートグラス「Smart eyewear」を提案した[18]．提案されたスマートグラスは\n図2.1 に示すように，３D プリントで製造され，マイクロコントローラ，EMG 電極を収\n納している．電極の配置を分析し，側頭が電極を配置する際に最適であることが確認され\nた．装着例を図2.2 に示す．咀嚼の検出は，適合率と再現率が80 ％に達した．また，5 種\n類の食品の分類精度は63 ％から84 ％の範囲であった．\n図2.1: 「Smart eyewear」\n（[18] から引用）\n図2.2: 「Smart eyewear」装着イメージ\n（[18] から引用）\nChun らは食事を検出するネックレス型デバイスを提案した[19]．ネックレス型デバイ\nスは，近接センサ（proximi",
            "検出するネックレス型デバイスを提案した[19]．ネックレス型デバイ\nスは，近接センサ（proximity sensor），BLE モジュール，マイクロコントローラ（mi-\n8\ncrocontroller）からなるウェアラブルデバイスである．図2.3 にデバイスを，図2.4 に装\n着例を示す．近接センサは顎骨（jawbone）までの距離から動きを捉え，食事行動と非食\n事行動を区別する．実験環境では，食事行動の検出が適合率（precision）91.2 ％，再現率\n（recall）92.6 ％と良い結果を示したが，自然な環境では適合率78.2 ％，再現率72.5 ％と，\n実験環境に比べて10 ％以上劣る結果となった．自然な環境での結果が実験環境と比べて\n劣る原因として，バドミントンやスケートボード（badminton and skateboarding）など\nのスポーツをしたことでデバイスが動き，センサが顎を捉えられなくなったことなどが挙\nげられている．\n図2.3: Chun らが提案する\nネックレス型デバイス\n（[19] から引用）\n図2.4: デバイス装着イメージ\n（[19] から引用",
            "ネックレス型デバイス\n（[19] から引用）\n図2.4: デバイス装着イメージ\n（[19] から引用）\nZhang らは食事行動検出のためのマルチセンサネックレス「NeckSense」を開発した[20]．\nネックレス型デバイスは近接センサ，環境光センサ，慣性計測ユニット（IMU）センサを\n内蔵している．近接センサでデバイスと着用者の顎の距離を計測することで咀嚼行動を検\n出し，環境光センサで着用者が食物を口に運ぶ摂食行動を捉える．また，IMU センサで\n食事をとる際の前傾姿勢の動きを捉える．システム概要を図2.5 に示す．このシステムで\nF1 値73.7 ％の咀嚼検出精度，77.1 ％の自然環境下での食事エピソード検出を達成した．\n9\n図2.5: マルチセンサネックレス「NeckSense」概要\n（[20] から引用）\nChun らは，口腔内用1 センチ未満のワイヤレスセンサによる食品種類分類手法を提案し\nている[21]．食べ物摂取時に口腔内の平均の温度変動の範囲を超えることを利用し口腔内\nをセンシングしている．システムはワイヤレス通信が可能であり，温度センサが内蔵され\nているマイクロコ",
            "\nをセンシングしている．システムはワイヤレス通信が可能であり，温度センサが内蔵され\nているマイクロコントローラー，加速度センサ，バッテリーによって設計されている．セ\nンサの取り付け方法は個人に特化したものとなっており，マウスピースに埋め込むことで\n歯に固定する．図2.6 にセンサと口の中に入れる型を示す．様々な温度やテクスチャの全9\n種類の食品を水分含有率や温度などから5 クラスに設定し分類する．温度に関する特徴量\nのみを用いた場合に77.5 ％の精度，温度と加速度に基づく特徴量を用いた場合に85.0 ％\nの精度を達成した．さらに日常生活における食事の検出はprecision93 ％，recall96 ％と高\nい精度を達成している．\n図2.6: 使用しているセンサとセンサをマウスピースで口腔内に装着した様子\n（[21] から引用）\nAmft らはマイクロフォンを用いた咀嚼音の解析を行った[22]．その結果，耳の内側にマ\n10\nイクロフォンを配置することによって質の高い咀嚼音を取得できることが分かった．99 ％\nの精度で食事の識別ができ，80 ％以上の精度で4 種類の食べ物を分類すること",
            "とが分かった．99 ％\nの精度で食事の識別ができ，80 ％以上の精度で4 種類の食べ物を分類することができた．\nBi らは，食事行動を自動で認識するウェアラブルデバイス「Auracle」を提案した[23]．\nAuracle はコンタクトマイク，マイクロコントローラ，それらを結ぶアナログ回路が内蔵さ\nれており，コンタクトマイクは耳の後ろ側に配置するよう設計してある．図2.7 にAuracle\nとその装着例を示す．Auracle は自由な生活環境下で，食事行動の検出ができ，92.8 ％の\n精度と77.5 ％のF1 値を達成した．\n図2.7: 「Auracle」の装着イメージ（[23] から引用）\nShuzo らは図2.8 に示した骨伝導マイクロフォン利用したIC レコーダーを用いて食習\n慣分析を行っている[24]．音声データからFFT を用いてパワースペクトルを計算し，そ\nこから得られる最大の周波数などの特徴量を用いて4 つの状態（かたい食べ物を食べて\nいる，柔らかい食べ物を食べている，水を飲んでいる，しゃべっている）（enteing a hard\nfood, eating a soft ",
            "飲んでいる，しゃべっている）（enteing a hard\nfood, eating a soft food, drinking water, speaking）に分類し，各状態に対して80 ％以上\nの分類をすることができた．しかし，解析のためにPC，サンプリングレート44.1kHz の\n骨伝導マイクロフォンを用いているため，手軽に扱うことが難しい．また，日常生活で扱\nうことを考慮するのであれば，Bluetooth 接続した骨伝導マイクロフォンを用いる必要が\n11\nあり，Bluetooth 接続が可能な機器はサンプリングレートが8kHz の物が多いため，それ\nに合わせたアルゴリズムが必要となる．\n図2.8: 骨伝導マイクロフォン利用したIC レコーダー（[24] から引用）\n三井らは，食行動を改善するために骨伝導マイクロフォンを用いて咀嚼回数と発話状態\nをリアルタイムで判定し，ユーザにフィードバックするシステムを提案した[16]．リアル\nタイムでの咀嚼の判定精度が約91 ％，発話時間の判定も約96 ％と高精度での判定ができ\nた．しかし，特定の食材でしか実験が行われていないことや，発話の",
            "定も約96 ％と高精度での判定ができ\nた．しかし，特定の食材でしか実験が行われていないことや，発話の方法が実験者の質問\nへの返答など，自然な食事環境下での実験はまだ行われていない．\nBedri らは，食事行動を追跡するための眼鏡型デバイス「FitByte」を開発した[25]．こ\nのデバイスには，咀嚼を検出するための4 つのジャイロスコープ，嚥下および咀嚼音をモ\nニタリングする高精度加速度センサ，手を口の方へ動かすの動作を検出する近接センサ，\nおよび摂取した食べ物の映像を記録するカメラが搭載されている．このデバイスは，食事\n行動を94.1 ％の精度で認識し，食事エピソードの時間を96.3 ％の精度で推定することが\n可能であることが示された．\nPapapanagiotou らは，音声，PPG，および加速度を用いて食事行動を検出するイヤー\nデバイスを開発した[26]．このデバイスは，耳内に配置されたマイクとPPG センサで構\n成されており，図2.9 にその外観が示されている．彼らは，新しい高精度かつ低サンプリ\nングレートを備えた咀嚼検出システムのプロトタイプを提案した．特徴量を抽出し，ス\nナ",
            "度かつ低サンプリ\nングレートを備えた咀嚼検出システムのプロトタイプを提案した．特徴量を抽出し，ス\nナッキング検出をサポートベクターマシン（SVM）で分類する手法を採用した．このシ\nステムは，93.8 ％の精度と89.2 ％のクラス加重精度を達成した．\n12\n図2.9: マイク，データ記録用装置，イヤーデバイス装着イメージ（[26] から引用）\nChen らは，制御された環境下で食事行動を捉えるための食事認識システム「ChewPin」\nを提案した[27]．食事音を記録するためにデュアルマイクロフォン拡張ボードを使用し\nた．分類手法には，メルスペクトログラムを入力とする畳み込みニューラルネットワーク\n（CNN）が採用された．このシステムは，食事認識において98.23 ％の精度を達成した．\n2.2\n食事行動に関するフィードバックを用いた研究\n三井らは，咀嚼および会話のフィードバックシステムを提案した[16]（2.1 でも言及）．\n彼らは食事音を利用して咀嚼および会話を検出した．フィードバックは，咀嚼回数やその\n総数に応じてゲージや画像を変化させる形でスマートフォンやスマートウォッチに表示さ\n",
            "，咀嚼回数やその\n総数に応じてゲージや画像を変化させる形でスマートフォンやスマートウォッチに表示さ\nれた．また，会話のフィードバックは振動や光によって提供された．フィードバックがあ\nる場合の総咀嚼回数は，フィードバックがない場合と比較して有意に増加した．しかし，\n実験では被験者が実験者からの質問に答える形で話をするため，自然な会話とは言えない．\nArnold らは，実際の食事を伴う仮想現実（VR）ゲームを開発した[28]．プレイヤーの\n頬に装着したマイクを用いて咀嚼音を検出し，食事行動を感知する仕組みである．咀嚼動\n作は，音の大きさを用いて検出される．具体的には，咀嚼の開始時に一定の閾値を超え，\n終了時に別の閾値を下回るまでの経過時間によって咀嚼が判断される．このゲームでは，\n非VR プレイヤーがプレイヤーに実際の食べ物を与え，プレイヤーはそれを食べながら，\n仮想の島からの脱出を目指す．島に隠された信号拳銃を見つけることで生存し，脱出を図\nる（図2.10 参照）．咀嚼をするたびにプレイヤーの視界が徐々に広がり，完全な視界が得\nられるようになる．\n13\n図2.10: VR ゲームプレイイ",
            "ーの視界が徐々に広がり，完全な視界が得\nられるようになる．\n13\n図2.10: VR ゲームプレイイメージ（[28] から引用）\nKim らは，スマートな食事速度ガイドシステム「Slowee」を提案した[29]．このシステ\nムは，センサユニットとフィードバックデバイスユニットで構成されている．センサユ\nニットは，咀嚼を検出するためのヘッドフォン型EMG センサと，嚥下を検出するための\nネックレス型ピエゾセンサでユーザーの食事行動を測定する（図2.11 に示す）．フィー\nドバックデバイスユニットは，視覚的フィードバックを提供するライトと，触覚的フィー\nドバックを提供する振動付きリストバンドを備えている．図2.12 はこのシステムの使用\n例を示している．咀嚼行動の認識精度は93.8 ％，嚥下行動の認識精度は79.4 ％であった．\nテストの結果，このシステムは総咀嚼回数および1 回の嚥下あたりの咀嚼回数を有意に増\n加させることが明らかとなった．さらに，Kim らはアニメーション絵文字およびスマー\nトウォッチを利用した食事速度ガイドのフィードバックシステムも提案している[30, 31]．\n絵文",
            "ー\nトウォッチを利用した食事速度ガイドのフィードバックシステムも提案している[30, 31]．\n絵文字フィードバックでは，アニメーション画像で食事状況を表示した．スマートウォッ\nチベースのフィードバックでは，グラフィック，テキスト，時計，振動の4 種類を提案し\nた．グラフィック型は画像を表示し，テキスト型は文字や色の変化を表示する．時計型は\n現在時刻を色の変化とともに表示し，振動型は速い食事速度を検知した際に振動を提供す\nる．しかし，このフィードバック方法は導入段階に過ぎない．\n14\n図2.11: システムのセンサユニット\n（quoted from[29]）\n図2.12: システムのフィードバック\nデバイスユニット（quoted from[29]）\n元川らは皿駆動型食事阻害システムとしてMealJammer を開発した[32]. 図2.13 には使\n用時のイメージが，図2.14 にはこのシステムの構成が示されている．電磁石を用いて皿\nデバイスを駆動させることで食事を阻害するシステムである．皿デバイスの裏面中央に装\n着された圧力センサで載せた食品の重さを計測し，皿デバイスの下にあるランチ",
            "．皿デバイスの裏面中央に装\n着された圧力センサで載せた食品の重さを計測し，皿デバイスの下にあるランチョンマッ\nト部に電磁石が配置してある．食品の重さが任意の重さ以下になると，2 つの電磁石が交\n互に動作し，皿デバイスが左右に揺れる．チョコレートとキュウリの2 種類の食品で提案\nシステムの有無による食事時間の比較を行っている．キュウリでは9 割が，チョコレート\nでは半数以上がシステムを用いることによる食事時間の増加が確認されている．\n図2.13: 皿駆動型食事阻害システム\n使用イメージ\n（[32] から引用）\n図2.14: 皿駆動型食事阻害システムの構成\n（[32] から引用）\n蒲地らは食事音声を用いた食習慣改善システム「ChewReminder」を提案した[33]．食\n事中の骨伝導音を自動セグメンテーションし，抽出した特徴量より分類モデルを用いて食\n事行動を予測するアプリケーションを作成し，取得した一口ごとの咀嚼回数に応じてス\nマートウォッチによるリアルタイムフィードバックを行うシステムを提案した．さらに食\n15\n事後にはスマートフォン上に食事全体に対するフィードバックも表示される．ア",
            "を提案した．さらに食\n15\n事後にはスマートフォン上に食事全体に対するフィードバックも表示される．アンケート\nの結果から早食いの自覚がある人に有効であることが示された．長期の実験より，スマー\nトフォン上に食事後に表示されるフィードバックも食事行動の改善に有効であることが確\n認できた．しかし嚥下の検出のF1 スコアが41 ％と低いことや，摂食タイミングを検出し\nていないこと，スマートフォン、イヤホン、スマートウォッチの三つもデバイスを使うこ\nとなどが課題として挙げられる．\n中岡らは，人々がゆっくり食事をすることを促し，より健康的な食習慣を推進するシス\nテム「eat2pic」を開発した[34]．このシステムは，センサ付き箸とデジタルキャンバスで\n構成されており，図2.15 にその構成を示す．彼らは，ユーザーの食事行動を物理的な世\n界でモニタリングし，それをデジタルの絵画世界に反映させるナッジングシステムを設計\nした．箸にはIMU センサと小型カメラが搭載され，時系列信号処理や深層学習ベースの\n画像認識を用いて，ユーザーの食事速度，選択した食べ物の種類（色），および摂取した\n量を認識する．こ",
            "\n画像認識を用いて，ユーザーの食事速度，選択した食べ物の種類（色），および摂取した\n量を認識する．このシステムは，健康的な食事のプロセスを風景画に徐々に色付けするこ\nとで表現し，ユーザーの健康的な食習慣を促進する．図2.16 は，このシステムのリアル\nタイム視覚フィードバックの例を示している．このシナリオでは，デジタルキャンバスは\nダイニングテーブルの隣の壁に設置される．ユーザーは風景画を眺めながら食事を楽しむ\nことができる．\n図2.15: 「eat2pic」システム概要\n（[34] から引用）\n図2.16: デジタルキャンバスの描画イメージ\n（[34] から引用）\n2.3\n関連研究についてのまとめ\n様々なセンサを使ったオリジナルデバイスが開発されている．Chun らが提案したネック\nレスタイプのデバイスは，一日中装着し，食事行動と非食事行動を区別することができる．\nしかし，食事中の複雑な行動を分類することはできず，自然な環境下では非食事行動を食\n16\n事行動として誤認識する問題がある．Zhang らが開発したNeckSense は，食事活動や食事\nエピソードを検出するためのマルチセン",
            "Zhang らが開発したNeckSense は，食事活動や食事\nエピソードを検出するためのマルチセンサーネックレスであるが，自然環境下での咀嚼検\n出の精度が低く，咀嚼や嚥下以外の食事活動を検出することはできない．他の多くの先行\n研究も，咀嚼および嚥下行動の検出精度が十分ではない．さらに，いずれのシステムも，\n摂食，咀嚼，嚥下，および会話という4 つの複雑な食事行動をすべて認識することはでき\nていない．また，フィードバック方法が食事中に画面を注視する必要があるもの，食事行\n動検出，フィードバック提示のために複数の特殊なデバイスを必要とするものなど，様々\nな課題があげられる．先行研究により，様々なセンサによって食事行動の検出が可能であ\nることと，フィードバック提示によって咀嚼回数が増えるなどの早食いを防止する効果が\nあることが言える．そこで，リアルタイムでの詳細な食事行動分類と振動によるフィード\nバックの提示を一つのデバイスで実現する，ネックレス型デバイス，\n「Chewker」を2023\n年に提案した[35]．システム概要を図2.17 に示す．IMU、ピエゾフィルム、ToF、マイク\nの四つ",
            "に提案した[35]．システム概要を図2.17 に示す．IMU、ピエゾフィルム、ToF、マイク\nの四つのセンサを用いて咀嚼や嚥下などの食事行動を検出した．また，1 口の咀嚼回数が\n少ない場合に振動のフィードバックをリアルタイムで提示し，食事後にはM5StickC の画\n面上に食事全体のフィードバックを提示している．ただし，Chewker の課題として，咀嚼\n判定で用いるセンサ値の閾値が一定であるため，咀嚼判定の個人差が多いことや，振動に\nよるリアルタイムフィードバックはユーザが慣れてしまうことが課題として挙げられる．\nさらに、食事後のフィードバックでは直前の食事一回のみの情報が小さい画面に表示され\nるため，情報が少ない上に見づらく，ハードウェアに関しても，見た目の悪さや装着感の\n悪さがあることが分かった．本論文では，本節で述べた課題の解決に向け，\n「Chewker」を\nさらに進化させたシステムを提案する．新しい「Chewker」はキャリブレーションを取り\n入れることで，食事行動検出の個人差をなくす．1.1.3 節で述べたように，音楽の存在そ\nのものが食事時間を延ばす効果を持つことや，ゆっ",
            "をなくす．1.1.3 節で述べたように，音楽の存在そ\nのものが食事時間を延ばす効果を持つことや，ゆっくりとした音楽は咀嚼のペースを下げ\nて，食事時間を増加させることから，リアルタイムフィードバックで音楽を利用する．音\n楽によるフィードバックは画面を注視する必要がなく，食事の邪魔にならない．また，食\n事後の視覚的フィードバックはスマートフォンの画面で表示し，過去の食事データの参照\nを可能にする．ハードウェアに関しても，装着感，見た目を向上させ，正しく装着するこ\nとで誰でも高い精度で食事行動の検出を可能にする．\n17\n図2.17: 2023 年に提案したChewker の概要\n18\n第3章\nChewker: 食習慣改善システム\n本章では，本研究で提案した食習慣改善のためのフィードバックシステム「Chewker」\nについて述べる．本システムは，ネックレス型デバイスで食事中のセンサデータを取得\nし，スマートフォン上では柔軟なフィードバックを提示する．画面を見る必要のない音楽\nによるリアルタイムフィードバックと，食事終了直後や食事時以外に確認できる視覚的な\nフィードバックの二種類のフィードバック",
            "ィードバックと，食事終了直後や食事時以外に確認できる視覚的な\nフィードバックの二種類のフィードバックを提示する．\n3.1\nシステムの概要\n提案システムChewker の検出システム概要は図3.1 に示した通りである．また，正面，\n後ろから見たネックレス型デバイスを図3.2 に示す．ユーザはネックレス型デバイスを装\n着し，スマートフォンを机上に置いて食事を行う．ネックレス型デバイスの構成を図3.3 に\n示す．ネックレス型デバイスにはM5StickC，ピエゾフィルム，超音波センサが搭載されて\nいる．センサ別の食事行動検出の詳細を表3.4 に示す。ネックレス型デバイスのM5StickC\n内のIMU センサ，ピエゾフィルム，超音波センサ，およびスマートフォンのマイクの４つ\nを用いて食事行動を検出する。IMU センサは食べ物を口に運ぶ摂食時（Feeding）の前傾\n姿勢を検出する。マイクは会話（Talking）を検出する。ピエゾフィルムはのどの起伏や、\n顎の動きで咀嚼（Chewing）と嚥下（Swallowing）を検出する。超音波センサは首から手\nまでの距離で摂食（Feeding）の検出に役立",
            "allowing）を検出する。超音波センサは首から手\nまでの距離で摂食（Feeding）の検出に役立てる。M5StickC は首の後方に、ピエゾフィル\nムは首の前方に、超音波センサはピエゾフィルムの右側、つまり首の右前方に設置した。\nネックレス型デバイスはマジックテープで着脱可能で、長さの調節も可能である。\n本研究で使用するM5StickCはM5Stack社製，ピエゾフィルムはMEAS社製（MEAS DT\nSeries 　DT2-028K W/TH LEADS/RIVET），超音波センサはM5Stack 社製のUltrasonic\nDistance Unit（RCWL-9600）を使用する．M5StickC へのセンサ接続一覧を表3.1 に示す．\n19\n図3.1: Chewker の検出システムの概要\n図3.2: ネックレス型デバイス装着イメージ\n20\n図3.3: ネックレス型デバイスの構成\n図3.4: センサ別の食事行動検出の詳細\n表3.1: M5StickC へのセンサ接続一覧\nセンサ\n接続先\n備考\nIMU\n内部搭載\nM5StickC 内蔵IMU を使用\nピエゾフィルム\nG33\nG",
            "サ\n接続先\n備考\nIMU\n内部搭載\nM5StickC 内蔵IMU を使用\nピエゾフィルム\nG33\nGND 接続, 270k Ωの抵抗を挟む\n超音波センサ（Trigger）\nG26\nGND, 5V 接続\n超音波センサ（Echo）\nG0\nGND, 5V 接続\n検出された食事行動を元にフィードバックを提示する．フィードバックの概要を図3.5\nに示す．フィードバックはリアルタイム，食事後の2 種類行う．専門家によると「行動の\n21\n直後にフィードバックを行うと良い，効果がある」ことが分かっているので，行動の把握\nとフィードバックをすぐに行うことができるようスマートフォンを用いた音楽を利用す\nる．また，食事後の視覚的フィードバックは食事全体に対するフィードバックで情報が多\nいため，スマートフォン上に表示し提示する．食事直後のフィードバックに加え，過去の\n食事データを参照できる視覚的フィードバックも用意している．\n図3.5: フィードバックシステムの概要\n3.2\nネックレス型デバイスとスマートフォンの連携\n本システムは，食事者が装着するネックレス型デバイスに搭載されたM5StickC と食事\n者が",
            "の連携\n本システムは，食事者が装着するネックレス型デバイスに搭載されたM5StickC と食事\n者が食事中に机上に置くAndroid 端末がクラウドサービスのFirebase を通じて接続して\nいる構成となっている（図3.6）．Firebase はGoogle が提供しているモバイル及びWeb\nアプリケーション向けのバックエンドサービスであり，その中のRealtime Database 及び\nCloud Firestore の機能を利用する．Realtime Database はリアルタイムでアプリ間での\nデータの保存，及び同期が可能であるデータベースである．一方，Cloud Firestore は高\n性能なクエリ処理が可能であり，データの管理がしやすいデータベースである．複数の\nM5StickC 内のデータをリアルタイムでAndroid 端末へ送信する際に，Realtime Database\nが最適だと考える．また，Android 端末にて記録した食事データをユーザごとに保存する\n際にCloud Firestore が最適だと考えたため，本システムではこれらを利用する．\n22\n図3.",
            "Cloud Firestore が最適だと考えたため，本システムではこれらを利用する．\n22\n図3.6: Firebase を用いたネックレス型デバイスとスマートフォンの連携\nまず，M5StickC とFirebase 間のデータ送信について説明する．M5StickC では，0.01 秒\nごとにIMU によるZ 軸加速度とピエゾフィルムによる値を, 0.05 秒ごとに超音波センサ\nによる距離を取得し，タイムスタンプとともにそれぞれ用意されている配列に格納する．\n配列に200 個分のデータ（超音波センサによる距離は40 個分のデータ）が集まったら，す\nべての値を一つの長い文字列へ変換し，その文字列をFirebase のRealtime Database へ\n送信する（図3.7）．具体的には，Realtime Database のDevice/M5Device ＿1 の配下に\nPiezoIMU とDistance という2 つのキーを用意している．PiezoIMU にはタイムスタンプ\nとIMU によるZ 軸加速度とピエゾフィルムによる値を，Distance にはタイムスタンプと\n超音波セン",
            "U によるZ 軸加速度とピエゾフィルムによる値を，Distance にはタイムスタンプと\n超音波センサによる距離を格納するということである．ネックレス型デバイスは2 つ作成\n済みのため，Device/M5Device ＿2 の配下にもPiezoIMU とDistance という2 つのキー\nを用意し，複数のデバイスでも対応可能である．また，Firebase への送信中にセンサによ\nる計測が途切れないよう，M5StickC はマルチタスクでセンサによる計測とFirebase への\nデータ送信を行う．Realtime Database は一つのデータを読み込むのに約1 秒かかるため，\nその1 秒の間に送られてくるデータは処理できずに欠損してしまう恐れがある．そのため，\n複数のデータを文字列へ変換し，約2 秒ごとに送信することにより，Realtime Database\nがデータの欠損なくM5StickC からデータを読み込むことを可能とし，リアルタイム性を\n保証する通信の仕組みを確立した．また，1 つの超音波センサの値を取得するのに0.03 秒\n程度かかるため，この値のみ0.05 秒ごとに値",
            "，1 つの超音波センサの値を取得するのに0.03 秒\n程度かかるため，この値のみ0.05 秒ごとに値を取得することにした．\n23\n図3.7: M5StickC からセンサによるデータを取得しているFirebase Realtime Database\n次にFirebase とAndroid 間のデータ送信について説明する．Android ではFirebase の\nRealtime Database の値が更新される度に，そのデータを読み込む．そして，読み込んだ\nデータの文字列をコンマ区切りでdouble 型に変換し，配列へ格納して食事行動検出に利\n用する．食事行動検出のアルゴリズムは次の節で述べる．食事終了後，食事時間や咀嚼\n回数などの食事データはFirebase のCloud FireStore へと送信される（図3.8）．Cloud\nFireStore に保存された食事データはAndroid から呼び出すことが可能であり，Android\n端末にて過去の記録を表示し，参照することが可能である．\n図3.8: 食事データが保存されているFirebase Cloud Firestore\n3.",
            "ある．\n図3.8: 食事データが保存されているFirebase Cloud Firestore\n3.3\nChewker の利用手順\n本節では，Chewker の利用手順について説明する．以下に具体的な手順を箇条書き形式\nでまとめる．\n24\n1. 準備\n• ネックレス型デバイスに搭載されているM5StickC とスマートフォンを十分に充\n電する．\n• M5StickC の電源をON にし，起動する．\n• ネックレス型デバイスを装着する．\n2. スマートフォンでの初期設定\n• スマートフォンアプリを起動し，ユーザ名（ニックネーム），計測パターン（実\n験管理者用），およびM5StickC の番号をプルダウンメニューから選択する（図\n3.9）．\n• Save ボタンを押し，メニュー画面に移動する（図3.10）．\n3. キャリブレーション\n• メニュー画面でCalibration ボタンを選択し，キャリブレーション画面に移動\nする（図3.11）．\n• キャリブレーションマニュアルを確認する．マニュアルは日本語版と英語版を切\nり替えるボタンが用意されている．マニュアルの内容は以下の通りである：\n(",
            "アルは日本語版と英語版を切\nり替えるボタンが用意されている．マニュアルの内容は以下の通りである：\n(a) Start Calibration ボタンをタップする．\n(b) 自然な姿勢を5 秒間保つ．\n(c) 食べ物を口に運び，20 回噛んだ後，飲み込む．\n（食べ物をすべて飲み込む必\n要はありません．）\n(d) 自然な姿勢を5 秒間保つ．\n(e) Finish Calibration ボタンをタップし，メインメニューに戻る．\n• マニュアル通りにキャリブレーションを行い，成功すればメニュー画面に戻る．\n4. 食事中の操作\n• メニュー画面でStart Meal ボタンを押すと，食事中の画面が表示される（図\n3.12）．\n• 表示されているYouTube を再生し，音量を調節する．\n• 準備が整い次第，画面上部のStart Meal ボタンを押し，音楽を聴きながら食事\nを開始する．\n25\n5. 食事の終了\n• 食事終了時には，画面下部のFinish Meal ボタンを押す．\n• 食事終了の確認バナーに回答すると，食事終了後の画面に移動する．\n• 食事終了後には，今回の食事に関するフィードバ",
            "認バナーに回答すると，食事終了後の画面に移動する．\n• 食事終了後には，今回の食事に関するフィードバックが表示される（図3.13）．\n6. 過去の食事データ参照\n• メニュー画面からPast Data ボタンを押すと，過去のデータを確認できる．\n（図\n3.14）．\nキャリブレーション中や，食事の計測中は，センサ値をグラフにして実験管理者が確認\nできるようにしている（図3.15）．食事中の音楽によるフィードバック，食事終了後の視\n覚的フィードバック，過去の食事データ参照の詳細は3.6 節にて述べる．\n26\n図3.9: ユーザ名・計測パターン・M5StickC\n番号の選択画面\n図3.10: メニュー画面\n27\n図3.11: キャリブレーション画面\n（左：キャリブレーション前，右：「Start Calibration」を押した後）\n28\n図3.12: 食事中の画面の一例\n（左：食事開始前，右：「Start Meal」を押した後）\n29\n図3.13: 食事終了後のフィードバック画面の\n一例\n図3.14: 過去のデータ参照画面の一例\n30\n図3.15: 管理者が確認するリアルタイムのセンサ値を示",
            ".14: 過去のデータ参照画面の一例\n30\n図3.15: 管理者が確認するリアルタイムのセンサ値を示すグラフ\n（上からIMU，ピエゾフィルム，超音波センサによる値）\n3.4\n食事行動検出のアルゴリズム\nM5StickC は電源がON の間，IMU，超音波センサ，ピエゾフィルムの3 つのセンサから\n値を取得し，Firebase のRealtime Database に送信し続ける．スマートフォン上でキャリ\nブレーションを開始すると，Realtime Database からのデータ読み込みを開始し，キャリ\n31\nブレーション終了時に読み込みを終了するとともに，食事行動検出に必要な閾値を決定す\nる．食事開始ボタンを押すと，Realtime Database からのデータ読み込みが再開され，食\n事終了ボタンが押されるまでの間，キャリブレーションで決定した閾値を用いて食事行動\nを検出する．さらに，Realtime Database からのデータ読み込みに加えて，スマートフォ\nンのマイクも動作し，音声データを取得する．食事開始ボタンが押されてから，食事終了\nボタンが押されるまでの食事行動検出などに",
            "声データを取得する．食事開始ボタンが押されてから，食事終了\nボタンが押されるまでの食事行動検出などに関するフローチャートを図3.16 に示す．本\nシステムでは，発話，摂食，咀嚼，嚥下の4 つの食事行動を検出しており，それぞれの検\n出方法について詳細を述べる．\n32\n図3.16: 食事開始から終了までの食事行動検出に関するフローチャート\n3.4.1\n発話検出\n食事中の会話はスマートフォンのマイクを用いて検出した．マイクからの入力値をdB\n（デシベル）に変換した．図3.17 は，デバイスを装着し，静かな環境で食事中に2 回発話\nした際の音量の例を示している．人間の話し声の平均デシベル値は55～65dB と推定され\nている[36]．そのため，55dB を閾値として設定し，この値を超えた場合を会話として検\n33\n出するようにした．図3.17 から，この閾値が適切であることが確認できる．また，会話\nとして検出された時間を加算していき，会話時間を計測している．\n図3.17: 2 回発話した際の音量の例\n3.4.2\n摂食検出\n食べ物を口に運ぶ動作を摂食（Feeding）とし，IMU によるZ 軸加速",
            "例\n3.4.2\n摂食検出\n食べ物を口に運ぶ動作を摂食（Feeding）とし，IMU によるZ 軸加速度と超音波センサ\nによる距離を用いて検出する．一般的に摂食の際，前傾姿勢になり，手が口に近づくため，\nこれらのセンサを用いることで摂食を検出できると考える．IMU は首後方のM5StickC に\n搭載されており，Z 軸加速度の変化を利用する．また，右利きを想定して首の右前方に設\n置した超音波センサから手までの距離を算出する．実際に3 回摂食を行った際のZ 軸加速\n度と距離データを図3.18 に示す．摂食時に距離が小さくなり，Z 軸加速度が増加している\nことが確認できる．\n34\n図3.18: 3 回摂食を行った際の，IMU によるZ 軸加速度と超音波センサによる距離\nキャリブレーションでは，摂食を検出するための閾値を決定する．3.3 節で述べた手順\nに従い，5 秒間の自然な姿勢の後，1 回の摂食，20 回の咀嚼，1 回の嚥下を行い，再び5\n秒間の自然な姿勢を保持する．この間に取得されたIMU のZ 軸加速度と超音波センサの\n距離データを基に，各個人に適した閾値を設定する．IMU の閾値は，",
            " のZ 軸加速度と超音波センサの\n距離データを基に，各個人に適した閾値を設定する．IMU の閾値は，キャリブレーショ\nン中に取得されたZ 軸加速度データの統計的特性を利用して決定する．具体的には，Z 軸\n加速度の平均値と最大値を算出し，その中央値を閾値として設定する．これにより，通常\nの姿勢時の基準値と，摂食動作に伴う最大加速度値の中間点を基準とすることで，個人差\nに適応した閾値の設定が可能となる．\n超音波センサの閾値は，キャリブレーション時に記録された距離データの平均値と最小\n値の中央値を用いて決定する．この閾値は，手が口元に近づいた際の距離変化を考慮し，\n摂食動作の検出精度を向上させるために用いる．\n摂食の検出は，IMU のZ 軸加速度と超音波センサの距離情報を組み合わせて行う．具\n体的には，IMU のZ 軸加速度がキャリブレーションで設定した閾値を超えた瞬間を摂食\nの開始点として記録し，この状態が一定時間維持された後，閾値を下回ることで摂食の終\n了と判断する．このようにして，IMU のデータから摂食の時間的区間を特定する．さら\nに，この期間内に超音波センサの距離がキャリブレーショ",
            " のデータから摂食の時間的区間を特定する．さら\nに，この期間内に超音波センサの距離がキャリブレーションで設定した閾値以下になった\n35\n場合に，摂食の確定判定を行う．どちらかのセンサのデータのみで摂食を検出すると，手\nが顔の近くにあるが食べていない場合や，前傾姿勢になるが食べていない場合に誤検出す\nる可能性があるため，両者を組み合わせることで精度を向上させる．\nキャリブレーションで決定した閾値は，Firebase を介して保存され，食事中のリアルタ\nイム検出に利用される．食事中のデータ処理では，IMU のZ 軸加速度が閾値を超えた時\n間帯を特定し，その開始・終了タイムスタンプを記録する．一方で，超音波センサの距\n離データも同様に処理され，閾値を下回る時間帯を特定する．これらのデータを照合し，\nIMU による摂食の開始から終了の間に，超音波センサの距離が閾値以下になった場合に\n摂食が検出されたと判断する．摂食が検出された場合，フィードバックシステムに通知し，\n食事行動の解析やリアルタイムフィードバックに活用される．\n3.4.3\n咀嚼と嚥下の検出\n3.5\n咀嚼と嚥下の検出\n咀嚼（Chewi",
            "ィードバックに活用される．\n3.4.3\n咀嚼と嚥下の検出\n3.5\n咀嚼と嚥下の検出\n咀嚼（Chewing）および嚥下（Swallowing）は，ピエゾフィルムの信号を用いて検出す\nる．ピエゾフィルムは首の前方に肌に密着するよう固定される．咀嚼時には顎の動きに\nよってピエゾフィルムの出力信号が周期的に変化し，嚥下時には喉の動きによって比較的\n大きなピークが発生する．実際に20 回咀嚼をして1 回嚥下を行った際のピエゾフィルム\nの出力データを図3.19 に示す．咀嚼時の小さいピークが20 個と，嚥下時の大きいピーク\nが1 つ確認できる．これらの特性を利用し，ピエゾフィルムの信号のピーク検出を行うこ\nとで，咀嚼と嚥下を識別する．また，センサ信号にはノイズを含むため，リアルタイムで\nの信号処理においてはローパスフィルタ（RC フィルタ）を適用し，Firebase へ送信する\n前にノイズ除去を行う．\n36\n図3.19: 20 回咀嚼し，1 回嚥下した際の，ピエゾフィルムによる出力データ\nキャリブレーションでは，咀嚼および嚥下を検出するための閾値を決定する．3.3 節で\n述べた手順に従い，5 秒間",
            "ーションでは，咀嚼および嚥下を検出するための閾値を決定する．3.3 節で\n述べた手順に従い，5 秒間の自然な姿勢の後，1 回の摂食，20 回の咀嚼，1 回の嚥下を行\nい，再び5 秒間の自然な姿勢を保持する．この間に取得されたピエゾフィルムの信号デー\nタを基に，各個人に適した閾値を設定する．\n閾値の決定には，キャリブレーション中に取得されたピエゾフィルムの信号データを正\n規化し，ピーク検出を行う．ピークの分類においては，キャリブレーションデータの最後\nの30%の区間における最大ピークを嚥下の閾値とし，その他のピークのうち，振幅が0.2\n以上0.8 以下の範囲にあるものを咀嚼のピークとする．咀嚼の閾値は，咀嚼ピークの最小\n値と最大値の中央値を用いて決定する．これらの閾値はスケール変換を施し，実際のピエ\nゾフィルムの信号範囲に適用する．\nリアルタイムの咀嚼および嚥下の検出は，キャリブレーションで設定した閾値を基に行\nう．まず，ピエゾフィルムの信号の変化量を計算し，ピーク検出を行う．検出されたピー\nクが咀嚼閾値未満であれば，咀嚼と判定し，咀嚼回数をカウントする．また，咀嚼間隔を\n37\n記録し，",
            "ー\nクが咀嚼閾値未満であれば，咀嚼と判定し，咀嚼回数をカウントする．また，咀嚼間隔を\n37\n記録し，嚥下ごとの咀嚼回数や咀嚼ペースの算出に利用する．一方，ピークが嚥下閾値未\n満であり，直前のイベントが咀嚼である場合，嚥下と判定する．嚥下が検出された場合，\n直前の咀嚼データを基に嚥下間の咀嚼回数や咀嚼ペースを評価する（3.6.2 節で詳細を述\nべる）．評価結果はリアルタイムフィードバックに利用され，音楽の再生速度の調整に反\n映される．嚥下が検出された後は，嚥下間の咀嚼回数のリセットを行い，新たな嚥下まで\nのカウントを開始する．\nキャリブレーションで決定した閾値はFirebase を介して保存され，食事中のリアルタイ\nム検出に利用される．食事中のデータ処理では，ピエゾフィルムの信号の変動を解析し，\nリアルタイムでピークを検出することで，咀嚼および嚥下を高精度に判定する．\n3.6\nフィードバックシステムの概要\n検出された食事行動を元に提示するスマートフォンによるフィードバックについて述べ\nる．図3.5 に示したように，食事中の音楽によるフィードバック，食事直後の視覚的フィー\nドバック，食事以",
            "図3.5 に示したように，食事中の音楽によるフィードバック，食事直後の視覚的フィー\nドバック，食事以外の時に過去の食事データが確認可能な視覚的フィードバックがある．\n3.6.1\nフィードバック内容\n検出された食事行動（摂食，咀嚼，嚥下）を基に，摂食回数，咀嚼回数，嚥下回数，嚥\n下から次の嚥下までの咀嚼回数，摂食から次の摂食までの咀嚼回数，咀嚼ペース，総食事\n時間，食事時間全体に対する会話時間や食べている時間の割合などを算出する．これら\nの値は，リアルタイムおよび食事後のフィードバックに使用される．算出される値につい\nて，以下の表3.2 に示す．\n38\n表3.2: 算出される食事行動関連指標\n指標（日本語）\n指標（英語）\n定義\n摂食回数\nFeeding Count\n食べ物を口に運ぶ回数（回）．\n咀嚼回数\nChewing Count\n食べ物を噛む回数（回）．\n嚥下回数\nSwallowing Count\n食べ物を飲み込む回数（回）．\n食事全体の時間\nTotal Meal Time\n「Start Meal」ボタンを押して，食事を開始し\nてから「Finish Meal」ボタンを押して，食事を\n終",
            " Meal」ボタンを押して，食事を開始し\nてから「Finish Meal」ボタンを押して，食事を\n終了するまでの時間（秒）．\n会話時間\nTotal Talking Time\n食事中に会話をしていた合計時間（秒）．\n食事全体に対する会\n話時間の割合\nPercentage of Talking Time\n食事全体の時間に対する会話時間の割合（％）．\n嚥下から次の嚥下ま\nでの咀嚼回数\nChews between Swallows\n1 回の嚥下から次の嚥下までに行われた咀嚼の\n回数（回）．\n摂食から次の摂食ま\nでの咀嚼回数\nChews between Feedings\n1 回の摂食から次の摂食までに行われた咀嚼の\n回数（回）．\n咀嚼ペース\nChew Pace\n咀嚼1 回から次の咀嚼1 回までにかかった時間\n（秒）．\n一般的な食事行動は，食べ物を口に運ぶ摂食（Feeding）をした後，複数回の咀嚼（Chew）\nを経て，嚥下（Swallow）をして，まだ口に残っている食べ物をさらに咀嚼し，嚥下を繰り\n返す．食べ物が口になくなったら，摂食をして，咀嚼し，嚥下，咀嚼し，嚥下と繰り返す．\n一連の流れを図",
            "\n返す．食べ物が口になくなったら，摂食をして，咀嚼し，嚥下，咀嚼し，嚥下と繰り返す．\n一連の流れを図3.20 に示す．この図には，咀嚼ペース（Chew Pace），嚥下から次の嚥下\nまでの咀嚼回数（Chews between swallows），摂食から次の摂食までの咀嚼回数（Chews\nbetween feedings）についてわかりやすく説明している．\n39\n図3.20: 食事行動の一連の流れと，算出される指標の説明\n3.6.2\n音楽を用いたリアルタイムフィードバック\n研究背景により，咀嚼回数，咀嚼時間や咀嚼ペースが多いほど健康的な食習慣であるこ\nとがわかった．そこでリアルタイムフィードバックでは，食事中に音楽の再生速度を変化\nさせることで咀嚼回数と咀嚼時間を増加させることを目的としている．これまでの研究か\nら，音楽のテンポが食行動や感情に影響を与えることが示されており（1.1.4 節で述べて\nいる），特に遅いテンポの音楽を聴きながら食事をした場合，食事時間，咀嚼回数，咀嚼\n時間が増加することが確認されている．また，レストランにおけるBGM の影響として，\nゆっくりとした音楽が咀嚼",
            "加することが確認されている．また，レストランにおけるBGM の影響として，\nゆっくりとした音楽が咀嚼ペースを下げ，食事時間を延長させることが知られている．こ\nれらの知見を踏まえ，本システムではリアルタイムフィードバックに音楽を活用する．リ\nアルタイムフィードバックは「Start Meal」ボタンを押してから，\n「Finish Meal」ボタン\nを押されるまで提示される．\n具体的には，ユーザが自身の好きなYouTube の再生リストをアプリ上で再生し，嚥下\nが検出されたタイミングで食事行動に応じて再生速度を調整する．実際のリアルタイム\nフィードバック中のスマートフォンの画面とその説明を図3.21 に示す．嚥下から次の嚥\n40\n下までの咀嚼回数が基準値に満たない場合，または咀嚼ペースの平均が基準値を下回る\n場合，一時的に再生速度を0.5 倍に低下させ，どちらの条件も満たせば再生速度を1.0 倍\nに戻す．一方で，いずれかの条件が基準値を満たさない限り，速度は0.5 倍のままとなる．\nこのフィードバックは，嚥下が検出されるたびに行われ，リアルタイムで食事行動を調整\nする仕組みとなっている．ユー",
            "ドバックは，嚥下が検出されるたびに行われ，リアルタイムで食事行動を調整\nする仕組みとなっている．ユーザは1.0 倍の再生速度をキープするために，両方の条件を\n満たそうと努力することが期待できる．\n音楽の再生速度調整の動作は，嚥下から次の嚥下までの咀嚼回数および咀嚼ペースの平\n均の基準値との比較に基づき，以下の4 つのパターンで決定される．\n• 基準値を両方満たした場合（1.0 倍速）\n– 嚥下から次の嚥下までの咀嚼回数が基準値以上\n– 咀嚼ペースの平均が基準値以上\n– 音楽の再生速度を1.0 倍速に維持\n• 咀嚼回数のみ基準値を満たさない場合（0.5 倍速）\n– 嚥下から次の嚥下までの咀嚼回数が基準値未満\n– 咀嚼ペースの平均が基準値以上\n– 音楽の再生速度を0.5 倍速に変更\n• 咀嚼ペースのみ基準値を満たさない場合（0.5 倍速）\n– 嚥下から次の嚥下までの咀嚼回数が基準値以上\n– 咀嚼ペースの平均が基準値未満\n– 音楽の再生速度を0.5 倍速に変更\n• 両方の基準値を満たさない場合（0.5 倍速）\n– 嚥下から次の嚥下までの咀嚼回数が基準値未満\n– 咀嚼ペースの平均が基準値未満\n",
            "（0.5 倍速）\n– 嚥下から次の嚥下までの咀嚼回数が基準値未満\n– 咀嚼ペースの平均が基準値未満\n– 音楽の再生速度を0.5 倍速に変更\n図3.22 に4 パターンの画面のスクリーンショットを示す．それぞれの条件に応じて，中\n央のテキスト内容やテキストの色が変化する．ユーザは音楽が0.5 倍速になる理由がわ\n41\nからない場合に中央のテキストに着目し，調整する．また，気になるようであれば，摂\n食回数（Feeding Count），嚥下から次の嚥下までの咀嚼回数（Chewing Count between\nSwallows），食事全体の咀嚼回数の合計（Total Chewing Count），嚥下回数（Swallowing\nCount）を確認できる．また，会話中は赤字で「Talking」というテキストが表示される．\n図3.21: 食事中のリアルタイムフィードバックを提示するスマートフォン上の画面と\nその説明\n42\n図3.22: 4 パターンの画面のスクリーンショット\n（左から基準値を両方満たした場合，咀嚼回数のみ基準値を満たさない場合，\n咀嚼ペースのみ基準値を満たさない場合，両方の基準",
            "満たした場合，咀嚼回数のみ基準値を満たさない場合，\n咀嚼ペースのみ基準値を満たさない場合，両方の基準値を満たさない場合）\nYouTube のAPI を活用する理由は，無料で自分の好きな音楽リストを作成できること，\n再生速度を変更できること，多くの人が使い慣れていることにある．また，本システム\nでは音楽を利用することで，視覚的なフィードバックを確認し続ける必要がなく，より自\n然な食事を促進できる．このように，リアルタイムフィードバックを音楽と組み合わせる\nことで，ユーザが無意識のうちに咀嚼回数を増やしたり，咀嚼のペースを落とすだけでな\nく，意識的にも適切な咀嚼を促すことが可能となる．\n嚥下から次の嚥下までの咀嚼回数の基準値は16 回，咀嚼ペースの基準値は0.8 秒とし\nた．現代人の1 口に噛む平均回数は10 回～20 回であるという文献[37] や，厚生労働省に\nよる「噛ミング30（カミングサンマル）」という一口30 回噛むことを目標とするスローガ\nン[38] などから，嚥下から嚥下まで20 回噛むことを目標とする．ただし，食べ物によっ\nて20 回咀嚼が必要ない場合もあるため，20 回の",
            "0 回噛むことを目標とする．ただし，食べ物によっ\nて20 回咀嚼が必要ない場合もあるため，20 回の8 割である16 回を咀嚼回数の基準値と\nした．また，蒲池らの研究[33] により，食事行動検出アプリ（フィードバックなし）を使\n用し，4 人から収集した食事データから，咀嚼ペースは1.0 秒を理想としている．ただし，\n1.0 秒という条件は食べ物によっては厳しいため，その8 割である0.8 秒を基準値とした．\n43\n3.6.3\n食事直後の視覚的フィードバック\n食事を終えて，\n「Finish Meal」ボタンを押し，確認バナーにYes と答えると，食事全体の\nフィードバックを表示する．フィードバック項目は全体の結果（Total Result），食事時間\n（Meal Time），咀嚼回数（Chew Count），咀嚼ペース（Chew Pace），会話時間（Talk\nTime）の5 つに分かれており，上部のボタンで切り替えられる．\n全体の結果（Total Result）の画面のスクリーンショットを図3.23 に示す．\n「Total」とい\nう項目には全体の摂食回数，嚥下回数，咀嚼回数，会話時間",
            "トを図3.23 に示す．\n「Total」とい\nう項目には全体の摂食回数，嚥下回数，咀嚼回数，会話時間，食事全体の時間を表示す\nる．\n「Average」という項目には嚥下から次の嚥下までの咀嚼回数の平均，摂食から次の摂\n食までの咀嚼回数の平均，咀嚼ペースの平均を表示する．\n「Progress Bars」という項目に\nは，食事時間，咀嚼回数，咀嚼ペース，会話時間の簡単な達成度を表す進行バーが表示さ\nれる．これらの進行バーは以下に記述する画面にて詳細を確認できる．\n44\n図3.23: 全体の結果（Total Result）の画面例\n食事時間（Meal Time）の画面のスクリーンショットを図3.24 に示す．一つの進行バー\nが表示されており，食事時間の達成度を表す．進行バーの上部にある「Target」は基準値\nを，\n「Max」は進行バーの最大値を示しており，進行バーの下部にある「You」はユーザの\n結果を表す．結果が基準値を満たす場合（達成），進行バーは緑色に，基準値を満たさな\nい場合（未達成）は赤色に表示される．15 分から20 分が理想的な食事時間である[39] と\nいうことから，基準値",
            "）は赤色に表示される．15 分から20 分が理想的な食事時間である[39] と\nいうことから，基準値を1200 秒（20 分）とした．進行バーの下部にはアドバイスが表示\nされ，達成した場合と，達成しなかった場合で異なるアドバイスが表示される．アドバイ\nスを表3.3 に示す．アドバイスはタップすると日本語版，英語版を切り替えられる．\n45\n図3.24: 食事時間（Meal Time）の結果の画面例\n表3.3: 食事後のフィードバックによる食事時間についてのアドバイス\n達成状況\n日本語のアドバイス\n英語のアドバイス\n達成時\n目標達成です。20 分以上かけて、ゆっく\nり食事ができていますね。\nGreat job! You’ve taken more than 20\nminutes for your meal, eating at a re-\nlaxed pace.\n未達成時\n食事時間が20 分未満です。もう少しゆっ\nくり時間をかけて食事をしましょう。\nYour meal time is less than 20 minutes.\nTry to eat more slowly and take",
            "s than 20 minutes.\nTry to eat more slowly and take your\ntime.\n咀嚼回数（Chew Count）のスクリーンショットを図3.25 に示す．3 つの進行バーが表示\n46\nされており，\n「Total Chews」は食事全体の咀嚼回数の達成度を，\n「Average Chews between\nSwallows」は嚥下から次の嚥下までの咀嚼回数の平均の達成度を，\n「Average Chews between\nFeedings」は摂食から次の摂食までの咀嚼回数の平均の達成度を表す．食事時間の画面と\n同様に，それぞれの進行バーの上部にある「Target」は基準値を，「Max」は進行バーの\n最大値を示しており，進行バーの下部にある「You」はユーザの結果を表す．結果が基準\n値を満たす場合（達成），進行バーは緑色に，基準値を満たさない場合（未達成）は赤色\nに表示される．厚生労働省による「噛ミング30（カミングサンマル）」という一口30 回\n噛むことを目標とするスローガン[38] から，\n「Average Chews between Feedi",
            "ことを目標とするスローガン[38] から，\n「Average Chews between Feedings」の基準\n値は30 回とした．また，1 日100 口以上食べ物を食べることが理想であるため[40]，一\n食33 口以上食べることが理想だと考える．一口を摂食から摂食までと考えると，30 回の\n咀嚼を33 回分で1000 回程度が理想となるが，食事内容により変動しやすいため，その8\n割の800 を「Total Chews」の基準値とする．3.6.2 節で述べた理由から，\n「Average Chews\nbetween Swallows」の基準値は16 回とする．画面下部にはアドバイスが表示され，3 つの\n指標の達成状況により異なるアドバイスが表示される．アドバイスを表3.4 に示す．〇は\n達成，×は未達成を示す．\n47\n図3.25: 咀嚼回数（Chew Count）の結果の画面例\n48\n表3.4: 食事後のフィードバックによる咀嚼回数についてのアドバイス\n達成状況\n日本語のアドバイス\n英語のアドバイス\n〇総咀嚼回数\n〇嚥下間の咀嚼回数\n〇摂食間の咀嚼回数\n目標の咀嚼回数をすべて達成しま",
            "語のアドバイス\n〇総咀嚼回数\n〇嚥下間の咀嚼回数\n〇摂食間の咀嚼回数\n目標の咀嚼回数をすべて達成しました！\nしっかり噛んで食事ができています。こ\nの調子で続けましょう。\nYou have achieved all the chewing\ngoals! You are chewing thoroughly dur-\ning meals. Keep up the good work.\n×総咀嚼回数\n×嚥下間の咀嚼回数\n×摂食間の咀嚼回数\n全体的に噛む回数が少ないようです。飲\nみ込む前や食べ物を口に運ぶ前に、もっ\nとよく噛むことを意識してみてください。\nYour overall chewing count seems low.\nTry to chew more thoroughly before\nswallowing or taking another bite.\n×総咀嚼回数\n〇嚥下間の咀嚼回数\n〇摂食間の咀嚼回数\n一口ごとにはしっかり噛めていますが、\n全体の回数が少ないようです。一口分の\n量が多いかもしれません。口に運ぶ量を\n減らしてみましょう。\nYou are chewing thor",
            "量が多いかもしれません。口に運ぶ量を\n減らしてみましょう。\nYou are chewing thoroughly for each\nbite, but your overall count is low. Con-\nsider reducing the size of each bite.\n〇総咀嚼回数\n×嚥下間の咀嚼回数\n〇摂食間の咀嚼回数\n全体の咀嚼回数と摂食間の咀嚼回数は目\n標を達成していますが、嚥下間での咀嚼\nが少ないようです。飲み込む前にもう少\nし噛むことを意識しましょう。\nYou have met the total chewing count\nand chewing between bites, but chewing\nbetween swallows is low. Try chewing\nmore before swallowing.\n〇総咀嚼回数\n〇嚥下間の咀嚼回数\n×摂食間の咀嚼回数\n全体の咀嚼回数と嚥下間の咀嚼回数は目\n標を達成していますが、摂食間での咀嚼\n回数が少ないようです。次の食べ物を口\nに運ぶ前に、もう少し噛むことを意識し\nましょう。\nYou have ",
            "少ないようです。次の食べ物を口\nに運ぶ前に、もう少し噛むことを意識し\nましょう。\nYou have met the total chewing count\nand chewing between swallows,\nbut\nchewing between feedings is low.\nTry\nchewing more before taking the next\nbite.\n×総咀嚼回数\n×嚥下間の咀嚼回数\n〇摂食間の咀嚼回数\n全体の咀嚼回数と嚥下間の咀嚼回数が不\n足しています。1 口を食べきるための咀\n嚼はしっかりできているので、飲み込む\n前にもう少し噛むことを意識しましょう。\nThe total chewing count and chewing\nbetween swallows are insuﬃcient. You\nchew well for each bite, but try chewing\nmore before swallowing.\n×総咀嚼回数\n〇嚥下間の咀嚼回数\n×摂食間の咀嚼回数\n全体の咀嚼回数と摂食間の咀嚼回数が不\n足しています。嚥下間ではしっかり噛め\nて",
            "\n×摂食間の咀嚼回数\n全体の咀嚼回数と摂食間の咀嚼回数が不\n足しています。嚥下間ではしっかり噛め\nているので、次の食べ物を口に運ぶ前に、\nもう少し噛むことを意識しましょう。\nThe total chewing count and chewing\nbetween feedings are insuﬃcient. You\nchew well between swallows, but try\nchewing more before taking the next\nbite.\n〇総咀嚼回数\n×嚥下間の咀嚼回数\n×摂食間の咀嚼回数\n全体の咀嚼回数は目標を達成しています\nが、嚥下間や摂食間での咀嚼が少ないよ\nうです。飲み込む前や食べ物を口に運ぶ\n前に、もっとよく噛むことを意識してみ\nてください。\nYou have met the total chewing count,\nbut chewing between swallows and feed-\nings seems low.\nFocus on chewing\nmore before swallowing or taking an-\nother",
            "chewing\nmore before swallowing or taking an-\nother bite.\n49\n咀嚼ペース（Chew Pace）の画面のスクリーンショットを図3.26 に示す．一つの進行\nバーが表示されており，咀嚼ペースの達成度を表す．上記と同様，進行バーの上部にある\n「Target」は基準値を，\n「Max」は進行バーの最大値を示しており，進行バーの下部にある\n「You」はユーザの結果を表す．結果が基準値を満たす場合（達成），進行バーは緑色に，\n基準値を満たさない場合（未達成）は赤色に表示される．3.6.2 節で述べた理由から，基\n準値を1.0 秒とした．進行バーの下部にはアドバイスが表示され，達成した場合と，達成\nしなかった場合で異なるアドバイスが表示される．アドバイスを表3.5 に示す．\n図3.26: 咀嚼ペース（Chew Pace）の結果の画面例\n50\n表3.5: 食事後のフィードバックによる咀嚼ペースについてのアドバイス\n達成状況\n日本語のアドバイス\n英語のアドバイス\n達成時\n咀嚼ペースとは、咀嚼と咀嚼の間の時間\nのことです。あなたの平均咀嚼ペースは\n0",
            "のアドバイス\n達成時\n咀嚼ペースとは、咀嚼と咀嚼の間の時間\nのことです。あなたの平均咀嚼ペースは\n0.8 秒以上で、理想的なペースです。\nYour chewing pace, the interval be-\ntween chews, is ideal at an average of\n1 second or more. Well done!\n未達成時\n咀嚼ペースとは、咀嚼と咀嚼の間の時間\nのことです。あなたの平均咀嚼ペースは\n0.8 秒未満なので、急がずにゆっくり噛\nんで、咀嚼ペースを落としてみましょう。\nYour chewing pace, the interval be-\ntween chews, is less than 1 second. Try\nto slow down and chew more calmly.\n会話時間（Talk Time）の画面のスクリーンショットを図3.27 に示す．一つの進行バー\nが表示されており，食事全体の時間に対する会話時間の割合の達成度を表す．上記と同\n様，進行バーの上部にある「Target」は基準値を，\n「Max」は進行バーの最大値を示して",
            "上記と同\n様，進行バーの上部にある「Target」は基準値を，\n「Max」は進行バーの最大値を示してお\nり，進行バーの下部にある「You」はユーザの結果を表す．結果が基準値を満たす場合（達\n成），進行バーは緑色に，基準値を満たさない場合（未達成）は赤色に表示される．1.1.4\n節で会話のある食事が望ましいことから，基準値を10.0 ％とした．進行バーの下部には\nアドバイスが表示され，達成した場合と，達成しなかった場合で異なるアドバイスが表示\nされる．アドバイスを表3.6 に示す．\n51\n図3.27: 会話時間（Talk Time）の結果の画面例\n表3.6: 食事後のフィードバックによる会話時間についてのアドバイス\n達成状況\n日本語のアドバイス\n英語のアドバイス\n達成時\n良い会話時間です。食事中の会話は健康\nを促進すると言われています。\nGood job!\nEngaging in conversation\nduring meals is known to promote well-\nbeing.\n未達成時\nもう少し会話を増やしてみましょう。食\n事中の会話は健康を促進すると言われて\nいます",
            "ng.\n未達成時\nもう少し会話を増やしてみましょう。食\n事中の会話は健康を促進すると言われて\nいます。\nTry to increase your talking time. Con-\nversation during meals can promote\nhealth and enjoyment.\n52\n3.6.4\n過去のデータ参照の視覚的フィードバック\nメニュー画面の「Past Data」ボタンから，過去の食事データを参照できる．\n「Past Data」\nボタンを押すと過去の食事データ一覧画面に移動し，その画面を図3.28 に示す．画面上\n部には，食事開始時間と合計の食事時間とともに，過去の食事データが一覧表示されてお\nり，スクロールが可能である．また，任意の食事データをタップすると，食事直後に表示\nされたフィードバックを再確認できる（図3.29）．さらに，図3.28 に示す画面の下部に\nは，食事に関する各指標（食事時間（Meal Time），全体の咀嚼回数（Total Chews），嚥\n下間の咀嚼回数（Chews per Swallow），摂食間の咀嚼回数（Chews per Fee",
            "\n下間の咀嚼回数（Chews per Swallow），摂食間の咀嚼回数（Chews per Feeding），咀嚼\nペース（Chew Pace），会話時間（Talk Time））の棒グラフが表示される．この棒グラフ\nは，過去の全食事データを時系列順に並べたもので，各指標の推移を可視化できる．グラ\nフには基準値を示す赤い線が引かれており，基準値を達成した場合は緑色の棒，達成でき\nなかった場合は赤色の棒で表示される．グラフをタップすると，詳細を確認できるダイア\nログが表示され，拡大表示される（図3.30）．具体的な値や日付などを確認できる．過去\nの食事データを再確認・比較することで，自身の食習慣を振り返り，より良い食事を心が\nけるようになることが期待できる．\n53\n図3.28: 過去の食事データ一覧画面\n54\n図3.29: 任意の食事データタップ後にフィールドバックが再確認できる画面\n55\n図3.30: 棒グラフをタップ後に棒グラフを拡大表示するダイアログ\n56\n第4章\nChewkerの食事行動検出精度評価実験\n本章では，食事行動分類の精度を評価するための実験方法について述べる．実験の責",
            "事行動検出精度評価実験\n本章では，食事行動分類の精度を評価するための実験方法について述べる．実験の責任\n者は，臨床研究のe ラーニングコース「ICR Introduction to Clinical Research」における\n「人を対象とする医学系研究に関する倫理指針」の研修を受講し，修了している．\n4.1\n食事行動検出精度実験概要\n本実験の目的は，食事行動（主に摂食，咀嚼，嚥下）の検出精度を確認することである．\n4.2\n食事行動検出精度実験手順\n20 代男女15 人を被験者として，研究室でネックレス型デバイスを着用し，ピーナッツを\n口に運び、20 回咀嚼をして1 回嚥下するという一連の行動を4 回行った。1 回目はキャリ\nブレーションのためであり，精度評価に用いるデータは3 回分である．キャリブレーショ\nンを行い閾値が決定された後，計測を開始し，3 回分の一連の行動を連続で行った後，計\n測を終了した．評価する際の真の値は，ビデオカメラによって録画したビデオ映像の目視\nによって決定する．\n4.3\n食事行動検出精度実験結果\n精度実験での全体の、摂食、咀嚼、嚥下の分類の混合行列を図4.1",
            "．\n4.3\n食事行動検出精度実験結果\n精度実験での全体の、摂食、咀嚼、嚥下の分類の混合行列を図4.1に示す．摂食（Feeding）\n45 回，咀嚼（Chewing）900 回，嚥下（Swallowing）45 回分のデータである。実際に食事\n行動をした時に，正しく検出されたものの数をTP，実際には行動していないのに検出さ\nれてしまったものの数をFP，実際に行動しているのに検出されなかったものの数をTN\nとし，Precision, Recall, F1-score を算出した結果を表4.1 に示す．摂食と嚥下はデータが\n57\n少ないが，咀嚼のF1-score85 ％とかなり高い。嚥下は再現性（recall）は高いものの，咀\n嚼を嚥下として検出してしまうことが多く，F1-score は60 ％となった．\n図4.1: 精度実験における食事行動検出精度を示す混合行列\n表4.1: 食事行動分類精度結果\nPrecision\nRecall\nF1-score\nFeeding\n1.00\n0.73\n0.85\nChewing\n0.99\n0.75\n0.85\nSwallowing\n0.47\n0.82\n0.60\n",
            "\nChewing\n0.99\n0.75\n0.85\nSwallowing\n0.47\n0.82\n0.60\n食事行動ごとの詳細な考察をするため，各被験者のF1-score を示す棒グラフを図4.2,\n図4.3, 図4.4 に示し，全体の分布を示す箱ひげ図を図4.5 に示す．棒グラフでは，各被験\n者ごとのF1-score を視覚的に比較することができる．一方，箱ひげ図では，各食事行動\nのF1-score の分布のばらつきや外れ値を確認できる．これらの図を用いることで，摂食，\n咀嚼，嚥下の検出精度における個人差や，全体としての精度の傾向を分析することが可能\nとなる．さらに，各食事行動のF1-score の統計的指標として，平均値および中央値を表\n4.2 に示す．\n58\n図4.2: 被験者ごとの摂食検出精度（F1-score）\n図4.3: 被験者ごとの咀嚼検出精度（F1-score）\n図4.4: 被験者ごとの嚥下検出精度（F1-score）\n59\n図4.5: 食事行動ごとのF1-score の分布\n表4.2: 各食事行動におけるF1-score の統計値\nMean\nMedian\nFeeding\n0.",
            "4.2: 各食事行動におけるF1-score の統計値\nMean\nMedian\nFeeding\n0.827\n0.800\nChewing\n0.839\n0.812\nSwallowing\n0.642\n0.667\n表4.2 から，咀嚼のF1-score の平均値（0.839）および中央値（0.812）が最も高く，次\nいで摂食（平均値0.827，中央値0.800）が続いていることが分かる．嚥下のF1-score は\n平均値が0.642，中央値が0.667 となっており，他の食事行動と比較して低い値を示して\nいる．これらの結果を踏まえ，個々の食事行動について詳しく考察する．\n4.3.1\n摂食の検出精度\n図4.2 および図4.5 に示すように，摂食（Feeding）のF1-score の平均値は0.827，中央\n値は0.800 であり，多くの被験者において高い精度が得られている．特に，15 名のうち13\n60\n名のF1-score は0.8 以上であり，精度の安定性が確認された．これは，超音波センサによ\nる手の検出とIMU による前傾姿勢の検出を組み合わせることで，摂食の特徴的な動作を\n捉えやすいこ",
            "よ\nる手の検出とIMU による前傾姿勢の検出を組み合わせることで，摂食の特徴的な動作を\n捉えやすいことに起因すると考えられる．\n一方で，2 名の被験者ではF1-score が0.5 以下であり，個人差による影響が見られた．こ\nの要因として，手の動きや姿勢の違いが挙げられる．しかし，全体的にはF1-score の分布\nが比較的狭く，キャリブレーションによる個別調整が有効に機能していると考えられる．\n今後は，さらに個別適応の閾値調整を行うことで，より安定した摂食検出が可能になると\n期待される．\n4.3.2\n咀嚼の検出精度\n図4.3 および図4.5 に示すように，咀嚼（Chewing）のF1-score の平均値は0.839，中央\n値は0.812 であり，他の食事行動と比較して最も高い精度が得られた．また，全被験者の\nF1-score は0.6 以上であり，0.8 以上のF1-score を記録した被験者は15 名中8 名と，半数\n以上が高い精度を示した．さらに，咀嚼データは1 人あたり20 回分と豊富に取得されて\nおり，摂食や嚥下に比べて統計的に信頼性の高い精度評価が可能である．\n咀嚼の検",
            "回分と豊富に取得されて\nおり，摂食や嚥下に比べて統計的に信頼性の高い精度評価が可能である．\n咀嚼の検出精度が高い理由として，本システムがキャリブレーションを導入し，各個人\nに適した閾値を設定したことが挙げられる．キャリブレーション時に被験者の咀嚼パター\nンを取得し，個別に最適化した閾値を適用することで，咀嚼の個人差に対応しやすくなっ\nた．また，ローパスフィルタ（RC フィルタ）を用いたノイズ除去により，ピエゾフィル\nムセンサの信号が滑らかに処理され，ピーク検出の精度が向上した．さらに，センサの装\n着方法やハードウェアの改良を行い，咀嚼時の振動をより安定して取得できるようにした\nことも，精度向上に寄与したと考えられる．\n一方で，F1-score が0.6 付近の被験者も存在しており，これは咀嚼の強さや速さに個人\n差があることに起因すると考えられる．特に，咀嚼が小さい，または速いリズムで行わ\nれる場合，ピークの振幅が小さくなり，閾値を超えないケースがある．今後の改善点とし\nて，ピーク検出の閾値を可変にし，連続する咀嚼パターンを考慮することで，より高精度\nな咀嚼検出が可能になると期待される．",
            "値を可変にし，連続する咀嚼パターンを考慮することで，より高精度\nな咀嚼検出が可能になると期待される．\n61\n4.3.3\n嚥下の検出精度\n図4.4 および図4.5 に示すように，嚥下（Swallowing）のF1-score の平均値は0.642，中\n央値は0.667 であり，他の食事行動と比較して最も精度が低かった．また，被験者ごとの\nばらつきが大きく，F1-score が0.8 以上の被験者がいる一方で，0.4 以下の被験者も複数\n存在する．これは，嚥下の個人差が大きいことに起因すると考えられる．さらに，嚥下の\nデータは1 人あたり3 回と少なく，統計的に評価が不安定になりやすいことも影響してい\nると考えられる．\n嚥下の検出精度が低い原因として，咀嚼と嚥下のピークが類似しており，咀嚼を嚥下と\nして誤検出するケースがあることが考えられる．本システムでは，ピエゾフィルムの信号\nのピーク値を基に嚥下を判定しているが，嚥下時のピーク値が咀嚼時と類似している場\n合，明確な判別が困難になる．特に，嚥下時の喉の動きが小さい被験者では，嚥下のピー\nクが検出されにくくなる可能性がある．\nキャリブレーシ",
            "嚥下時の喉の動きが小さい被験者では，嚥下のピー\nクが検出されにくくなる可能性がある．\nキャリブレーション時に嚥下時のピーク値の分布をより詳細に分析し，各個人に適した\n閾値をさらに細かく設定することが有効と考えられる．また，ピエゾフィルムの装着方法\nを最適化し，嚥下時の振動をより正確に捉えることで，検出の安定性を向上させる必要が\nある．\n62\n第5章\nChewkerのフィードバック効果検証\n本章では，Chewker のフィードバック，特にリアルタイムフィードバックの有効性を検\n証するための実験について説明する．\n5.1\nフィードバック効果検証概要\n本実験は，スマートフォンによる音楽を用いたリアルタイムフィードバックが，食事行\n動そのものや，食事行動への意識にどう影響を与えるかどうかを検証するために実施され\nた．実験の責任者は，精度実験同様，臨床研究のe ラーニングコース「ICR Introduction\nto Clinical Research」における「人を対象とする医学系研究に関する倫理指針」の研修を\n受講し，修了している．さらに，実験の全参加者には研究内容の説明を行い，同意書への\n",
            "理指針」の研修を\n受講し，修了している．さらに，実験の全参加者には研究内容の説明を行い，同意書への\n署名を得ている．\n5.2\nフィードバック効果検証手順\n20 代の男女11 名のデータを収集した．本実験では，食事中の会話も必要とされたため，\n被験者は2 人以上のグループで食事を行った．各被験者は，リアルタイムフィードバック\nなしで食事をする条件と，リアルタイムフィードバックを受けながら食事をする条件の2\n回の実験を，異なる日に行った．全て昼食の時間帯に行われ，2 回の実験の時間帯がなる\nべく同じになるようにした．\n実験で使用した弁当は学食で販売されているものであり，すべて同じ形状のトレイに盛\nり付けられ，おおよそ同じ量であった．また，各被験者が2 回の実験で全く同じ弁当を食\nべるようにし，主菜の違いが影響しないように配慮した．弁当の主菜として，ハンバーグ，\nヒレカツ，レバニラ炒め，チキン南蛮，白身フライ，酢豚の6 種類を用いた．図5.1 に弁\n当の例を示す．\n実験の流れは，同意書への署名，事前アンケートの回答，実験1 日目，実験2 日目，2\n63\nつの実験後アンケートの回答である．実験",
            "，事前アンケートの回答，実験1 日目，実験2 日目，2\n63\nつの実験後アンケートの回答である．実験の様子を図5.2 に示す．被験者は両条件の実験\nにおいてネックレス型デバイスを装着し，スマートフォンを机に置いて，アプリを使用し\nながら食事をした．食事終了後は食事直後のフィードバック画面を確認した．食事時間の\n制限などは設けていない．記録のために口元や顎，首が移るようビデオ録画をした．リア\nルタイムフィードバックありの条件では，音楽が低速になるフィードバックに基づき，嚥\n下間の咀嚼回数や咀嚼ペースを意識することが求められた．リアルタイムフィードバック\nなしの条件では，ネックレス型デバイスを装着し，音楽は再生されたが，音楽の速度変化\nのフィードバックや，テキストによるフィードバックは提示されなかった．初期設定の画\n面で計測パターンを実験管理者が選ぶことで，フィードバックの有無を制御できる（3.3\n節参照）．アンケートは，実験前に回答する事前アンケート，実験後に回答するSUS アン\nケートとChewker に関するアンケートの3 つを用意した．\n図5.1: 実験で使用された弁当の例\n64\n",
            "Chewker に関するアンケートの3 つを用意した．\n図5.1: 実験で使用された弁当の例\n64\n図5.2: 実験の様子\n5.2.1\n事前アンケート\n実験前に，被験者は以下の質問項目について回答し，食事に関する意識や習慣を確認し\nた．回答形式は5 段階評価または選択式であり，被験者の食事速度や咀嚼，食事中の会\n話，音楽の聴取習慣などに関するデータを収集することを目的とした．図5.3 に質問票の\nフォームを示す．\nまず，被験者にはアプリ上で表示されるためのニックネームを決定してもらった．次に，\n「自分は早食いだ（食べるスピードが速い）と思いますか」，\n「普段の食事で，噛むことを\n意識していますか」，\n「普段の食事で，会話することを意識していますか」の3 項目につい\nて，5 段階評価で回答した．また，被験者が普段の食事中に音楽を聴く習慣があるかを確\n認するため，\n「音楽を聴きながら食事をする頻度はどれぐらいですか（レストランなどで\nのBGM も含む）」という質問を設定し，選択肢として「1 日に一度以上」，\n「2～3 日に一\n度程度」，\n「1 週間に一度程度」，\n「全くない」の4 つを用意",
            "日に一度以上」，\n「2～3 日に一\n度程度」，\n「1 週間に一度程度」，\n「全くない」の4 つを用意した．\nさらに，本実験ではYouTube の再生リストを用いたリアルタイムフィードバックを行\nうため，被験者に実験中に聴取する音楽の選択を求めた．選択肢の中から好きな再生リス\n65\nトを選択するか，その他の欄に希望するYouTube 再生リストのリンクを入力する形式と\nした．ただし，アプリへの埋め込みができない再生リストについては対応できない可能性\nがあることを事前に伝えた．\n最後に，被験者の安全を確保するため，食材に関するアレルギーの有無を確認した．\n「な\nい」と回答した被験者はここで質問が終了し，\n「ある」と回答した被験者には，具体的な\nアレルギー食材について追加で回答を求めた．\n図5.3: 事前アンケート質問事項\n66\n5.2.2\nSUS アンケート\nSUS アンケートはSystem Usability Scale の略で，ジョン・ブルック（John Brooke）に\nより1986 年に開発され，システムのユーザビリティの受け止められ方について測定する\nために最も広く利用されている",
            "年に開発され，システムのユーザビリティの受け止められ方について測定する\nために最も広く利用されている質問票である[41][42]．このスケールは，1（まったくそう\n思わない）から5（まったくそう思う）の10 の記述から成り立っている．奇数項目の設\n問は肯定的な質問であり，偶数番号の設問は否定的な質問である．集計方法は，奇数番号\nの設問に対しては回答番号から１を引く．偶数番号の設問に対しては，５から回答番号を\n引く．そして，合計スコアに2.5 をかけて０から100 までのスケールに変換する．各スコ\nアに対する評価の指標を図5.4 に示す．\n図5.4: SUS スコア指標（[41][42] から引用）\n5.2.3\nChewker についてのアンケート\n実験後，被験者は「Chewker に関するアンケート」に回答し，本システムの使用感や\nフィードバックの効果について評価を行った．このアンケートは，食事中の意識の変化，\n67\nシステムのフィードバックの理解度，装着デバイスの違和感，およびシステムの継続利用\n意向について調査することを目的としている．図5.5 に質問票のフォームを示す．\nまず，被",
            "の継続利用\n意向について調査することを目的としている．図5.5 に質問票のフォームを示す．\nまず，被験者が本システムを使用したことによる食事中の意識の変化を評価するため，\n「食事中に噛むことを意識しましたか」，\n「食事中に発話に関して意識しましたか」，\n「食事\n中ゆっくり食べようと意識しましたか」の3 項目について5 段階評価で回答を求めた．ま\nた，システムの装着感について「装着デバイスに違和感はありましたか」という質問を設\n定した．\n次に，リアルタイムフィードバックと食事後のフィードバックの理解度を確認するため，\n「音楽の速度変化によるリアルタイムフィードバックはわかりやすかったですか」，\n「リア\nルタイムフィードバックによってゆっくり噛むことを意識しましたか」，「リアルタイム\nフィードバックによってたくさん噛むことを意識しましたか」，\n「スマートフォン上での食\n事後に表示されるフィードバックはわかりやすかったですか」の4 項目について5 段階評\n価で回答を求めた．\nさらに，本システムの測定精度に対する主観的評価を収集するため，\n「システムは咀嚼を\n正しくカウントしていると感じました",
            "の測定精度に対する主観的評価を収集するため，\n「システムは咀嚼を\n正しくカウントしていると感じましたか」，\n「システムは嚥下（飲み込むこと）を正しく検\n出していると感じましたか」，\n「システムは発話を正しく測定していると感じましたか」の\n3 項目について5 段階評価で回答を求めた．また，\n「今後、このシステムを使いたいと思い\nましたか」という質問を設け，システムの継続利用意向を調査した．咀嚼，嚥下について\nは音楽によるリアルタイムフィードバックに直接関与しているため，リアルタイムフィー\nドバック画面下部の回数表示に注目することが予想されるため，質問に含めた．発話につ\nいてもリアルタイムフィードバック画面上に赤字で表示されるため，質問に含めた．摂食\nはリアルタイムフィードバックには関与しないため，注目する被験者が少ないことが予想\nされ，答えにくいと判断し，質問には含めなかった．\n加えて，被験者の自由な意見を収集するため，以下の3 つの自由記述形式の質問を設け\nた：「システムを使用して使いにくかった点・改善した方が良い点があれば教えてくださ\nい」，\n「システムの継続利用を想定するならば，ど",
            "くかった点・改善した方が良い点があれば教えてくださ\nい」，\n「システムの継続利用を想定するならば，どのようなシーンで利用したいと思うか具\n体的に教えてください」，\n「システムについて意見などがあれば自由に記述してください」．\n68\n図5.5: Chewker についての実験後アンケート\n69\n5.3\nフィードバック効果検証結果\n全体の食事時間，全体の咀嚼回数，摂食間の咀嚼回数，嚥下間の咀嚼回数，咀嚼ペース，\n会話時間の6 つの評価指標について考察する．評価結果は値が大きいほど良好である．\n5.3.1\n全体の食事時間の結果\n全被験者11 名において，リアルタイムフィードバックを用いた食事の総食事時間は，\nフィードバックなしの食事と比較して増加した．図5.6 に各被験者ごとの総食事時間の変\n化を示す．また，食事時間の結果を箱ひげ図で示したものを以下に示す．図5.7 は，リア\nルタイムフィードバックを使用した食事と使用しなかった食事の比較結果を示している．\n図5.6: 各被験者ごとの全体の食事時間の変化\n70\n図5.7: 全体の食事時間の箱ひげ図\n箱ひげ図の結果から，リアルタイムフィードバッ",
            "時間の変化\n70\n図5.7: 全体の食事時間の箱ひげ図\n箱ひげ図の結果から，リアルタイムフィードバックを使用した食事では，フィードバッ\nクなしの食事と比較して平均値および中央値が増加していることが確認された．ウィルコ\nクソンの符号付順位和検定を用いて分析を行った結果，有意差があり（P¡0.05），リアル\nタイムフィードバックが食事時間の延長に寄与することが明らかとなった．特に，フィー\nドバックなしの食事と比較した食事時間の増加率は平均68.02 ％であった．リアルタイム\nフィードバックが咀嚼の意識を高め，結果として食事時間の延長につながった可能性が高\nい．これらの結果から，リアルタイムフィードバックを用いることで，よりゆっくりとし\nた食事が促進されることが示唆された．食事時間の延長は，咀嚼回数の増加や過食防止に\nもつながるため，本システムは健康的な食習慣の形成に貢献する可能性が高い．\n5.3.2\n全体の咀嚼回数の結果\n全被験者11 名のうち，リアルタイムフィードバックを使用した食事では，フィードバッ\nクなしの食事と比較して咀嚼回数が増加した被験者は10 名であった．図5.8 に各被験者",
            "フィードバッ\nクなしの食事と比較して咀嚼回数が増加した被験者は10 名であった．図5.8 に各被験者\nの咀嚼回数の変化を示す．一方で，Subject J のみがフィードバックなしの食事の方が咀\n嚼回数が多かった．また，咀嚼回数の結果を箱ひげ図で示したものを図5.9 に示す．\n71\n図5.8: 各被験者ごとの全体の咀嚼回数の変化\n図5.9: 全体の咀嚼回数の箱ひげ図\n72\n箱ひげ図から，リアルタイムフィードバックを使用した食事では，フィードバックなし\nの食事と比較して平均値および中央値が増加していることが確認された．特に，フィー\nドバックなしの食事と比較した場合の咀嚼回数の増加率は平均26.88%であった．これは，\nリアルタイムフィードバックが咀嚼を意識させる効果を持ち，その結果として咀嚼回数の\n増加につながった可能性を示唆している．また，ウィルコクソンの符号付順位和検定を用\nいて分析を行った結果，有意差があった（P¡0.05）．また，フィードバックなしの食事に\n比べて，Subject J の咀嚼回数が減少している原因としては，フィードバックありの食事\nの際に，咀嚼が検知されずらかったこ",
            " の咀嚼回数が減少している原因としては，フィードバックありの食事\nの際に，咀嚼が検知されずらかったことがあげられる．\n5.3.3\n摂食間の咀嚼回数の結果\n図5.10 に各被験者ごとの摂食から次の摂食まで（摂食間）の咀嚼回数の変化を示す．リ\nアルタイムフィードバックを用いた場合，摂食間の咀嚼回数が増加した被験者は4 名であ\nり，7 名では減少が確認された．この結果は摂食回数が関係するため，図5.11 に全体の摂\n食回数の変化を，図5.12 に摂食回数の結果をあらわした箱ひげ図を示す．\n図5.10: 各被験者ごとの摂食間の咀嚼回数の変化\n73\n図5.11: 各被験者ごとの摂食回数の変化\n図5.12: 摂食回数の箱ひげ図\n74\n摂食間の咀嚼回数の減少が見られた7 名（Subject B，C，D，E，F，H，I）は全員摂食\n回数が増加しており，全体で11 名中8 名の被験者がフィードバックありの状態で摂食回\n数を増やしていた．フィードバックを使用した食事では，フィードバックなしの食事と比\n較して摂食回数の平均値および中央値が増加している．摂食回数に関してウィルコクソン\nの符号付順位和検定を用い",
            "摂食回数の平均値および中央値が増加している．摂食回数に関してウィルコクソン\nの符号付順位和検定を用いて分析を行った結果，有意差はなかったものの，増加率は平均\n25.70 ％であった．図5.13 にフィードバックありの食事で摂食間の咀嚼回数が減少した被\n験者7 名を強調した比較結果を示す．一方，図5.14 では，その被験者7 名の摂食回数の\n結果を強調している．\n図5.13: 7 名の被験者の結果を強調した各被\n験者ごとの摂食間の咀嚼回数の変化\n図5.14: 7 名の被験者の結果を強調した各被\n験者ごとの摂食回数の変化\nこれらの結果から，リアルタイムフィードバックにより，咀嚼を意識することで，一度\nに口に入れる食べ物の量が減り，その結果，何度も口に運ぶ摂食動作が増えたと考えられ\nる．7 名は摂食間の咀嚼回数が減少したが，全員全体の咀嚼回数は増加しているため，十\n分な咀嚼回数である．これらの結果から，リアルタイムフィードバックは，食事中の咀嚼\nを意識させることで，摂食行動を増加させる効果を持つ可能性が高い．また，同じ量のお\n弁当を食べているため，フィードバックありの食事で摂食回数が増えたと",
            "つ可能性が高い．また，同じ量のお\n弁当を食べているため，フィードバックありの食事で摂食回数が増えたということは一度\nに口に入れる食べ物の量が減り，早食いを防止できていると言える．\n75\n5.3.4\n嚥下間の咀嚼回数の結果\n図5.15 に各被験者ごとの嚥下から次の嚥下まで（嚥下間）の咀嚼回数の変化を示す．リ\nアルタイムフィードバックを用いた場合，嚥下間の咀嚼回数が増加した被験者は10 名であ\nり，Subject J のみ減少が確認された．この結果は，前述のとおり，Subject J ではフィー\nドバックありの状態で咀嚼が検知されにくく，全体の咀嚼回数が減少していたことが影響\nしていると考えられる．また，嚥下間の咀嚼回数の結果を箱ひげ図で示したものを以下に\n示す．図5.16 は，リアルタイムフィードバックを使用した食事と使用しなかった食事の\n比較結果を示している．\n図5.15: 各被験者ごとの嚥下間の咀嚼回数の変化\n76\n図5.16: 嚥下間の咀嚼回数の箱ひげ図\n箱ひげ図の結果から，リアルタイムフィードバックを使用した食事では，フィードバック\nなしの食事と比較して嚥下間の咀嚼回数の平均値お",
            "イムフィードバックを使用した食事では，フィードバック\nなしの食事と比較して嚥下間の咀嚼回数の平均値および中央値が増加していることが確認\nされた．また，嚥下間の咀嚼回数の増加率は平均19.22 ％であり，ほとんどの被験者にお\nいて嚥下間の咀嚼回数が増加していることがわかる．一方で，嚥下回数の増加率は-6.69 ％\nとほとんど変化が見られなかった．この結果から，嚥下回数を減らして嚥下間の咀嚼回数\nを増やしたということではなく，嚥下回数は変わらず，フィードバックにより意識するこ\nとで咀嚼回数自体が増加したと考えられる．嚥下間の咀嚼回数は，リアルタイムフィード\nバックにおける音楽の速度変化に直接関与する重要な指標である．この指標が増加したこ\nとは，リアルタイムフィードバックが被験者の咀嚼行動に影響を与え，より多く咀嚼する\nよう促す効果があったことを示唆している．ウィルコクソンの符号付順位和検定を用いて\n分析を行った結果，有意差はなかったものの，ほとんどの被験者において嚥下間の咀嚼回\n数が増加しており，リアルタイムフィードバックが咀嚼行動の改善に寄与する可能性が示\nされた．\n77\n5.3.5\n咀",
            "おり，リアルタイムフィードバックが咀嚼行動の改善に寄与する可能性が示\nされた．\n77\n5.3.5\n咀嚼ペースの結果\n図5.17 に各被験者ごとの咀嚼ペースの変化を示す．リアルタイムフィードバックを用\nいた場合，咀嚼ペースが増加した被験者は11 名中8 名であった．Subject C とSubject K\nのデータが重なっており，個々の変化が視覚的に分かりづらいが，両者とも咀嚼ペースが\n増加している．また，咀嚼ペースの結果を箱ひげ図で示したものを図5.18 に示す．箱ひ\nげ図の結果から，リアルタイムフィードバックを使用した食事では，フィードバックなし\nの食事と比較して平均値および中央値が増加していることが確認された．\n図5.17: 各被験者ごとの咀嚼ペースの変化\n78\n図5.18: 咀嚼ペースの箱ひげ図\n咀嚼ペースの増加率は平均45.16 ％であり，特に咀嚼が検知されにくかったSubject J\nは増加率が100 ％と大幅に上昇していた．このため，Subject J を除いた場合の平均増加\n率は39.68 ％となる．この結果から，リアルタイムフィードバックが咀嚼ペースに影響を\n与えている",
            "\n率は39.68 ％となる．この結果から，リアルタイムフィードバックが咀嚼ペースに影響を\n与えていることが示唆される．咀嚼ペースはリアルタイムフィードバックとしての音楽の\n速度変化に直接関与しており，咀嚼ペースの増加が確認されたことから，本システムが意\n図したフィードバック効果を発揮していることが分かる．また，ウィルコクソンの符号付\n順位和検定を用いて分析を行った結果，有意差があった（P¡0.05）ことから，リアルタイ\nムフィードバックが咀嚼ペースの向上を促す可能性が示唆される．\n5.3.6\n会話時間の結果\n図5.19 に全被験者の食事時間に対する会話時間の割合の変化を示す．リアルタイムフィー\nドバックを用いた場合，会話時間の割合が増加した被験者は11 名中4 名であった．また，\n会話時間の結果を箱ひげ図で示したものを図5.20 に示す．\n79\n図5.19: 各被験者ごとの会話時間の割合の変化\n図5.20: 会話時間の箱ひげ図\n80\nこの結果から，全体的に会話時間の割合はフィードバックなしと比較して減少傾向にあ\nることが確認された．増加率の平均は-22.48 ％であり，会話時間が減少し",
            "しと比較して減少傾向にあ\nることが確認された．増加率の平均は-22.48 ％であり，会話時間が減少した被験者が多\nかったことが示された．この結果の要因として，リアルタイムフィードバックにより咀嚼\nへの意識が向上し，咀嚼に集中することで会話の機会が減少した可能性が考えられる．ま\nた，被験者はフィードバックあり・なしで同じ人と同じ人数で食事を行ったわけではない\nため，環境要因が会話時間の変動に影響を与えた可能性もある．会話時間については個々\nの食事環境に依存するため，現段階では詳細な考察を行うことは難しい．しかし，将来的\nに会話を促進するためのフィードバック要素を導入することで，よりバランスの取れた食\n事行動の支援が可能になると考えられる．\n5.3.7\nSUS スコア結果\n本節ではSUS スコアの結果について考察する．スコアは表5.1 のとおりであり，スコア\n指標は図5.4 のとおりである．平均スコアは83.2 となり，A スコアであった．平均的な\nSUS スコアである68 以上のスコアが10/11 人とほとんどであり、Exellent の評価となっ\nたため，本システムのユーザビリティは優",
            "0/11 人とほとんどであり、Exellent の評価となっ\nたため，本システムのユーザビリティは優れていると結論付けることができる．\n表5.1: The result of SUS\nSubject\nScore\nA\n82.5\nB\n80.0\nC\n80.0\nD\n90.0\nE\n67.5\nF\n80.0\nG\n87.5\nH\n87.5\nI\n77.5\nJ\n90.0\nK\n92.5\n81\n5.3.8\n実験前後のアンケート結果\n本研究では、食事前後のアンケートを実施し、被験者の食事に対する意識の変化や、リ\nアルタイムフィードバックの影響を評価した。5 段階評価における「5」は「非常にそう\n思う」，\n「1」は「全く思わなかった」を示す．食事前後での意識の変化の比較のため，6 つ\nの質問の平均得点の棒グラフを図5.21 に表す．\n図5.21: 食事前後での意識の変化の比較のための6 つの質問の平均得点の棒グラフ\nまず，早食いの意識の変化について述べる．事前アンケートにおいて，\n「自分は早食いだ\nと思いますか」の質問に対して，\n「4」または「5」と回答した被験者は2 名であった．これ\nに対し，実験後のアンケートで",
            "問に対して，\n「4」または「5」と回答した被験者は2 名であった．これ\nに対し，実験後のアンケートでは，\n「食事中ゆっくり食べようと意識しましたか」の質問\nに対し，7 名が「5」，4 名が「4」と回答しており，リアルタイムフィードバックが被験者\nに食事のペースを意識させる効果を持っていたことが示唆される．特に，事前アンケート\nで「早食いである」と回答した2 名も実験後には「4」または「5」を選択しており，食事\nの速度を意識する変化が見られた．\n次に，咀嚼への意識の変化を説明する．事前アンケートで「普段の食事で噛むことを意\n82\n識していますか」の質問に対し，\n「4」または「5」と回答した被験者は0 名であり，ほとん\nどの被験者（10 名）が「1」または「2」と回答していた．このことから，被験者のほと\nんどが普段は咀嚼を意識していないことが分かる．一方，実験後のアンケートでは，\n「食\n事中に噛むことを意識しましたか」の質問に対し，10 名が「5」，1 名が「4」と回答して\nおり，全被験者がフィードバックの影響を受けて咀嚼を意識したことが明らかになった．\nこの結果は，本システムが咀嚼の意識",
            "フィードバックの影響を受けて咀嚼を意識したことが明らかになった．\nこの結果は，本システムが咀嚼の意識向上に大きく寄与したことを示している．\n次に，会話への意識の変化について述べる．事前アンケートにおいて，\n「普段の食事で会\n話することを意識していますか」の質問に対し，\n「4」または「5」と回答した被験者は1 名\nであった．一方，実験後のアンケートでは，\n「食事中に発話に関して意識しましたか」の\n質問に対し，\n「4」が6 名，\n「3」が2 名，\n「2」が2 名，\n「1」が1 名と結果がばらけたが，会話\nへの意識が多少なりとも向上している．5.3.6 でも述べたように，リアルタイムフィード\nバックの影響で会話よりも咀嚼を意識する傾向が強まっていると考えられる．また，被験\n者ごとに異なる食事環境の影響も考慮する必要がある．\n次に，音楽によるリアルタイムフィードバックと食事後のフィードバックの理解度と影\n響について述べる．実験後アンケートのフィードバックに関する質問の得点平均を図5.22\nに表す．\n「音楽の速度変化によるリアルタイムフィードバックは分かりやすかったですか」\nの質問に対し，\n「4",
            "．\n「音楽の速度変化によるリアルタイムフィードバックは分かりやすかったですか」\nの質問に対し，\n「4」または「5」と回答した被験者は8 名であり，それ以外の被験者は「3」\nと答えていたため，多くの被験者がリアルタイムフィードバックの仕組みを理解していた\nことが分かる．また，\n「リアルタイムフィードバックによってゆっくり噛むことを意識しま\nしたか」の質問では11 名全員が「4」または「5」と回答し，\n「リアルタイムフィードバッ\nクによってたくさん噛むことを意識しましたか」の質問でも11 名全員が「4」または「5」\nと回答しており，リアルタイムフィードバックが咀嚼行動の改善に貢献した可能性が示唆\nされる．\n「スマートフォン上での食事後に表示されるフィードバックはわかりやすかった\nですか」の質問に対しても，11 名全員が「4」または「5」と回答したため，食事後の視\n覚的フィードバックは誰が見てもわかりやすいものと言える．\n83\n図5.22: 実験後アンケートのフィードバックに関する質問の得点平均\n食事行動検出精度に対する主観的評価の結果を述べる．システムが正しく食事行動（咀\n嚼・嚥下・発話）",
            "均\n食事行動検出精度に対する主観的評価の結果を述べる．システムが正しく食事行動（咀\n嚼・嚥下・発話）を検出しているかについての質問の得点平均を図5.23 に示す．\n「システ\nムは咀嚼を正しくカウントしていると感じましたか」の質問に対し，\n「4」または「5」と\n回答した被験者は8 名であり，多くの被験者がシステムの咀嚼検出精度を肯定的に評価し\nていた．一方で，\n「システムは嚥下（飲み込むこと）を正しく検出していると感じました\nか」の質問に対し，\n「4」と回答した被験者は4 名，\n「3」と回答した被験者は6 名，\n「2」と回\n答した被験者は1 名であった．この結果から，咀嚼の検出と比較すると，嚥下の検出に対\nする評価はやや低く，特に「3」の評価が多いことから，嚥下検出の精度には改善の余地\nがあることが示唆された．4.3 節の精度実験の結果からも，咀嚼より嚥下の方が精度が低\nいことが確認されており，アンケートによる主観評価と一致していることが分かる．\n「シ\nステムは発話を正しく測定していると感じましたか」の質問では，\n「4」または「5」と回\n答した被験者が8 名であり，多くの被験者が発話検出",
            "じましたか」の質問では，\n「4」または「5」と回\n答した被験者が8 名であり，多くの被験者が発話検出の精度を肯定的に評価していた．一\n方で，1 名が「3」，1 名が「2」と回答しており，一部の被験者においては発話検出の精度\nに対する懸念があることが示された．会話は，食事をしている人以外の周囲の音も検出し\nていまうことが問題点として挙げられる．\n84\n図5.23: システムが正しく食事行動（咀嚼・嚥下・発話）を検出しているかについての質\n問の得点平均\n次に，装着デバイスの違和感と継続利用意向について述べる．デバイスの装着感とシス\nテムの継続利用意向についての質問の得点平均を図5.24 に示す．\n「装着デバイスに違和感\nはありましたか」の質問では，1 名が「5」，2 名が「3」，7 名が「2」，1 名が「1」と回\n答しており，多くの被験者が装着に対して大きな違和感を感じなかったことが分かる．一\n方，\n「今後，このシステムを使いたいと思いましたか」の質問では，9 名が「4」または「5」\nと回答しており，システムの継続利用に対する関心が高いことが確認された．特に，事前\nアンケートで「普段の食事",
            "しており，システムの継続利用に対する関心が高いことが確認された．特に，事前\nアンケートで「普段の食事で噛むことを意識していない」と回答した被験者が多かったに\nも関わらず，実験後には全員が咀嚼を意識するようになったことは，本システムの有効性\nを示す重要な結果である．\n85\n図5.24: デバイスの装着感とシステムの継続利用意向についての質問の得点平均\nこれらの結果から，リアルタイムフィードバックは咀嚼行動や食事ペースの調整に有効\nであり，多くの被験者に受け入れられる可能性が高いことが示唆された．自由記述での質\n問の回答では，\n「デバイスの装着が少し難しいと感じた」，\n「首が苦しいと感じた」など装着\n方法や装着感についての意見が寄せられた．より簡単に，そして快適に装着できるハード\nウェアを検討する必要がある．また，\n「フィードバックのおかげで，噛む回数が増え，顎が\n疲れて普段いかに噛めてないかを自覚した」，\n「実験当日の夜に噛むことを意識した」，\n「食\n事結果と目標が「数値」としてフィードバックされることで，改善しようとする意欲が湧\nいた」「1 倍速に戻ったときの爽快感が楽しくて，キープし",
            "ックされることで，改善しようとする意欲が湧\nいた」「1 倍速に戻ったときの爽快感が楽しくて，キープしようと努力した」など，フィー\nドバックが意識向上につながっていることがわかる．\n86\n第6章\n結論\n6.1\nまとめ\n本研究では，食習慣の改善を目的として，リアルタイムフィードバックシステム「Chewker」\nを提案し，その有効性を検証した．IMU，ピエゾフィルム，超音波センサ，スマートフォ\nンのマイクを用いて，摂食，咀嚼，嚥下，発話の4 つの食事行動をリアルタイムに検出し，\n音楽の再生速度を変化させることでフィードバックを行う．また，食事終了後にはスマー\nトフォン上で詳細なフィードバックを提示し，食事行動の振り返りを可能にした．\n11 名の被験者による実験の結果，リアルタイムフィードバックにより総咀嚼回数が平\n均26.88 ％増加，嚥下間の咀嚼回数が平均19.22 ％増加し，両者とも10 名で増加が確認さ\nれた．また，咀嚼ペースは8 名で増加し，総食事時間は平均68.02 ％延長，すべての被験\n者で増加が確認された．さらに，8 名の摂食回数が増加しており，一口あたりの食べ物の\n量が減り，",
            "被験\n者で増加が確認された．さらに，8 名の摂食回数が増加しており，一口あたりの食べ物の\n量が減り，口に運ぶ回数が増えたことが示唆された．これらの結果から，フィードバック\nが，急がずたくさん噛み，ゆっくりとした食事を促すことがわかる．事前アンケートでは\n「普段の食事で噛むことを意識していない」と回答した被験者が10 名いたが，実験後には\n全員が「噛むことを意識した」と回答し，食事行動への意識の改善が明らかになった．\n本システムの食事行動検出精度に関して，摂食と咀嚼のF1-score は0.85 と高い精度を\n示した．一方で，嚥下のF1-score は0.60 と他の行動に比べて低く，咀嚼との誤検出が課\n題として挙げられた．また，SUS 平均スコアは83.2 となり，本システムのユーザビリティ\nは優れていると言える．\n本研究の目的に対する結論は以下の通り：\n1. 自然な食事環境下での，詳細な食事行動をリアルタイムに検出するシステムの実現\nができた．\n2. 検出した食事行動に基づいて，フィードバックを提示することで，食事行動への意\n識改善を行うシステムの開発ができた．\n87\n6.2\n今後の",
            "ドバックを提示することで，食事行動への意\n識改善を行うシステムの開発ができた．\n87\n6.2\n今後の展望\n本研究では，リアルタイムフィードバックによる食事行動の変化を確認できたが，さら\nなる改良の余地がある．今後の展望として，長期間の使用による行動変容の検証や，装着\n方法の改良，精度向上を目指した改良が必要である．本研究では単回の食事を対象に検証\nを行ったが，食習慣の改善には長期的な行動変容が重要である．今後は，長期間の使用を\n通じて食習慣がどのように変化するかを検証し，持続的な効果を評価する必要がある．ま\nた，本システムには過去の食事行動を振り返る機能が備わっており，これが行動変容に与\nえる影響についても詳細に検討する必要がある．\nさらに，発話の促進を目的としたフィードバック手法の導入も検討すべきである．本シ\nステムでは，咀嚼や食事ペースの改善には効果があったものの，発話の促進には大きな影\n響を与えなかった．今後は，発話を積極的に促すフィードバック手法を導入し，食事中の\n会話を活発にするシステムの開発を進める．\n本研究の食事行動検出精度の評価は，ピーナッツを用いた実験環境下で行われた",
            "るシステムの開発を進める．\n本研究の食事行動検出精度の評価は，ピーナッツを用いた実験環境下で行われたため，\n摂食および嚥下のデータが少なく，精度の信憑性に課題が残る．今後は，様々な環境で精\n度を検証し，検出アルゴリズムの改良を進める．また，リアルタイムフィードバックの効\n果を検証する際，ビデオによる記録が残っているため，これを活用して自然な食事環境下\nでの検出精度を詳細に評価することも検討する．特に嚥下の精度が劣るため，キャリブ\nレーションの改良や，デバイスの設計を見直す必要がある．\nまた，装着方法やハードウェアの改良も必要である．実験後のアンケートでは，\n「デバイ\nスの装着が少し難しい」，\n「首が苦しい」といった意見が寄せられたため，より簡単に装着\nでき，快適に使用できる設計への改良が求められる．加えて，M5StickC のバッテリー持\n続時間が約1 時間と短いため，長時間の使用に耐えられるようなバッテリー駆動の最適化\nや代替デバイスの検討も必要である．これらの改良を通じて，本システムはより実用的\nで，食事行動の改善を長期的に支援するツールへと発展することが期待される．\n88\n謝辞\n",
            "はより実用的\nで，食事行動の改善を長期的に支援するツールへと発展することが期待される．\n88\n謝辞\n本研究を進めるにあたり，青山学院大学理工学部情報テクノロジー学科のロペズ・ギ\nヨーム教授に深く感謝申し上げます．研究目標を達成するだけでなく，高い意欲を継続し\nて研究に取り組むことができたのは，先生の温かく丁寧なご指導のおかげです．また，国\n内外での発表の機会を与えてくださり，研究者としての視野を広げることができました．\nさらに，研究室の運営や事務手続きを支えてくださった大熊ちひろ様にも，心より感謝申\nし上げます．研究に集中できる環境を整えてくださり，さまざまな手続きを円滑に進めて\nいただいたことで，本研究を滞りなく進めることができました．また，ロペズ研究室のメ\nンバーの皆様にも深く感謝いたします．日々のディスカッションを通じて新たな視点を得\nることができ，研究をより良いものにすることができました．特に，同期や先輩方からの\nアドバイスは，問題解決の大きな助けとなりました．最後に，これまで支えてくれた家族\nに心から感謝いたします．研究に打ち込むことができたのは，日々の励ましや支援があっ\nた",
            "えてくれた家族\nに心から感謝いたします．研究に打ち込むことができたのは，日々の励ましや支援があっ\nたからこそです．多くの方々のご協力と支えがあって，本研究を完遂することができまし\nた．この場を借りて，心より御礼申し上げます．\n2025 年1 月31 日\n大久保紗恵\n89\n参考文献\n[1] Obesity and overweight. https://www.who.int/news-room/fact-sheets/detail/\nobesity-and-overweight.\n[2] Japan Ministry of Health Labor and Welfare.\nThe national health and nutrition\nsurvey in japan, reiwa ﬁrst year. https://www.mhlw.go.jp/content/000711005.\npdf.\n[3] info01.pdf. http://sosyaku.umin.jp/info/file/info01.pdf.\n[4] Japan Preventive Association ",
            "file/info01.pdf.\n[4] Japan Preventive Association of Life-style related Disease. Eating too fast can lead\nto obesity and metabolic syndrome. six measures to help you chew your food well (in\njapanese). https://seikatsusyukanbyo.com/calendar/2017/009495.php.\n[5] Yuichi Ando, Nobuhiro Hanada, and Shigetaka Yanagisawa. Does ”eating slowly”\nlead to prevent obesity ? Health Science and Health Care, Vol. 8, No. 2, pp. 51–63,\n2008.\n[6] Ronald E. Milliman. The inﬂuence of background music on the behavior",
            ". The inﬂuence of background music on the behavior of restaurant\npatrons on jstor, 1986. [Online; accessed 2025-01-29].\n[7] Luisa Torri Riccardo Migliavada, Fabio Luceri. Chew that beat! how music tempo\ninﬂuences eating behaviors and emotions - sciencedirect, 9 2024.\n[8] Derek Victor Byrne Qian Janice Wang Signe Lund Mathiesen, Line Ahm Mielby.\nMusic to eat by: A systematic investigation of the relative importance of tempo and\narticulation on eating time - sciencedirect, 12 2020.\n[9] Noriko Kish",
            "ing time - sciencedirect, 12 2020.\n[9] Noriko Kishida and Yoshie Kamimura. Relationship of conversation during meal and\nhealth and dietary life of school children. The Japanese Journal of Nutririon and\nDietetics, Vol. 51, No. 1, pp. 23–30, 1993.\n[10] Kanae Nakaoka, Seiko Noda, Asako Yamada, Yuriko Togashi, Naoko Namiki, and\nMasae Goseki-Sone. The association of“ the frequency of shared family meals and\n90\nspontaneous communication during mealtimes ”with decision-making, goal-setting\nskills, and ",
            "s ”with decision-making, goal-setting\nskills, and qol in 5th and 6th grade students. Journal of Japanese Society of Shokuiku,\nVol. 14, No. 1, pp. 41–51, 2020.\n[11] Hiroko Moriwaki, Noriko Kishida, Yoshie Kamimura, Noriko Takeda, Akiko Sakuma,\nChieko Teraoka, and Masayuki Kakehashi. Relationship of the health condition, daily\nliving habits, and diet of female university students with their mealtime conversation\nat elementary school.\nJournal of Home Economics of Japan, Vol. 58, No. 6, pp.\n327–336,",
            "e Economics of Japan, Vol. 58, No. 6, pp.\n327–336, 2007.\n[12] “ food for talk ”adds meaning to family meal — the seattle times. https://www.\nseattletimes.com/news/food-for-talk-adds-meaning-to-family-meal/.\n[13] ’talking at mealtimes boosts children’s conﬁdence’ - bbc news. https://www.bbc.\ncom/news/education-23502947.\n[14] Mealtime\nconversations\nfor\nfamily\nmeals.\nhttps://extension.psu.edu/\nmealtime-conversations-for-family-meals.\n[15] Nur Asmiza Selamat and Sawal Hamid Md Ali. Automatic food in",
            " Selamat and Sawal Hamid Md Ali. Automatic food intake monitoring\nbased on chewing activity: A survey. IEEE Access, Vol. 8, pp. 48846–48869, 2020.\n[16] Hideto Mitsui, Joe Ohara, Anna Yokokubo, and Guillaume Lopez. Method to improve\nreal-time chewing and speaking detection accuracy from bone-conduction sound. Mul-\ntimedia, Distributed, Cooperative, and Mobile Symposium 2018, Vol. 2018, pp. 562–\n566, 2018.\n[17] Yuxing Wu, Elisa Krebs, Adithya Hassan Shankaranand, Patrick Shih, and Chia-\nFang Chung",
            "n Shankaranand, Patrick Shih, and Chia-\nFang Chung. Meal chat: Promoting mealtime social interaction for college students.\nIn Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing\nSystems, pp. 1–8, 2020.\n[18] Rui Zhang, Severin Bernhart, and Oliver Amft. Diet eyeglasses: Recognising food\nchewing using emg and smart eyeglasses. 2016 IEEE 13th International Conference\non Wearable and Implantable Body Sensor Networks (BSN), pp. 7–12, 2016.\n[19] Keum San Chun, Sarnab Bhattachar",
            " 7–12, 2016.\n[19] Keum San Chun, Sarnab Bhattacharya, and Edison Thomaz.\nDetecting eating\nepisodes by tracking jawbone movements with a non-contact wearable sensor. Pro-\n91\nceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies,\nVol. 2, No. 1, pp. 1–21, 2018.\n[20] Shibo Zhang, Yuqi Zhao, Dzung Tri Nguyen, Runsheng Xu, Sougata Sen, Josiah\nHester, and Nabil Alshurafa. Necksense: A multi-sensor necklace for detecting eating\nactivities in free-living conditions. Proceedings",
            "\nactivities in free-living conditions. Proceedings of the ACM on Interactive, Mobile,\nWearable and Ubiquitous Technologies, Vol. 4, No. 2, pp. 1–26, 2020.\n[21] Keum San Chun, Sarnab Bhattacharya, Caroline Dolbear, Jordon Kashanchi, and\nEdison Thomaz. Intraoral temperature and inertial sensing in automated dietary\nassessment: a feasibility study. In Proceedings of the 2020 International Symposium\non Wearable Computers, pp. 27–31, 2020.\n[22] Oliver Amft, Mathias St¨ager, Paul Lukowicz, and Gerhard",
            " Amft, Mathias St¨ager, Paul Lukowicz, and Gerhard Tr¨oster.\nAnalysis of\nchewing sounds for dietary monitoring. In International Conference on Ubiquitous\nComputing, pp. 56–72. Springer, 2005.\n[23] Shengjie Bi, Tao Wang, Nicole Tobias, Josephine Nordrum, Shang Wang, George\nHalvorsen, Sougata Sen, Ronald Peterson, KoﬁOdame, Kelly Caine, et al. Auracle:\nDetecting eating episodes with an ear-mounted sensor. Proceedings of the ACM on\nInteractive, Mobile, Wearable and Ubiquitous Technologies, Vol. 2, ",
            "le, Wearable and Ubiquitous Technologies, Vol. 2, No. 3, p. 92, 2018.\n[24] Masaki Shuzo, Shintaro Komori, Tomoko Takashima, Guillaume Lopez, Seiji Tat-\nsuta, Shintaro Yanagimoto, Shin’ichi Warisawa, Jean-Jacques Delaunay, and Ichiro\nYamada. Wearable eating habit sensing system using internal body sound. Jour-\nnal of Advanced Mechanical Design, Systems, and Manufacturing, Vol. 4, No. 1, pp.\n158–166, 2010.\n[25] Abdelkareem Bedri, Diana Li, Rushil Khurana, Kunal Bhuwalka, and Mayank Goel.\nFitbyte: ",
            "hurana, Kunal Bhuwalka, and Mayank Goel.\nFitbyte: Automatic diet monitoring in unconstrained situations using multimodal\nsensing on eyeglasses. In Proceedings of the 2020 CHI Conference on Human Factors\nin Computing Systems, pp. 1–12, 2020.\n[26] Vasileios Papapanagiotou, Christos Diou, Lingchuan Zhou, Janet van den Boer, Mon-\nica Mars, and Anastasios Delopoulos. A novel chewing detection system based on\nppg, audio, and accelerometry. IEEE journal of biomedical and health informatics,\nVol. 21, No",
            " of biomedical and health informatics,\nVol. 21, No. 3, pp. 607–618, 2016.\n92\n[27] Yang Chen, Zhitong Cui, and Ching Chiuan Yen. Chewpin: a wearable acoustic\ndevice for chewing detection. In Adjunct Proceedings of the 2021 ACM International\nJoint Conference on Pervasive and Ubiquitous Computing and Proceedings of the\n2021 ACM International Symposium on Wearable Computers, pp. 11–12, 2021.\n[28] Peter Arnold, Rohit Ashok Khot, and Florian’Floyd’ Mueller. ” you better eat to\nsurvive” exploring coope",
            "ller. ” you better eat to\nsurvive” exploring cooperative eating in virtual reality games. In Proceedings of the\nTwelfth International Conference on Tangible, Embedded, and Embodied Interaction,\npp. 398–408, 2018.\n[29] Joohee Kim, Kwang-Jae Lee, Mankyung Lee, Nahyeon Lee, Byung-Chull Bae, Gene-\nhee Lee, Juhee Cho, Young Mog Shim, and Jun-Dong Cho. Slowee: A smart eating-\nspeed guide system with light and vibration feedback. In Proceedings of the 2016\nCHI Conference Extended Abstracts on Human Fac",
            "016\nCHI Conference Extended Abstracts on Human Factors in Computing Systems, pp.\n2563–2569, 2016.\n[30] Joohee Kim and Byung-Chull Bae. An animated emoji feedback system for eating\nrate guidance. In Proceedings of the 2018 ACM International Joint Conference and\n2018 International Symposium on Pervasive and Ubiquitous Computing and Wearable\nComputers, pp. 388–391, 2018.\n[31] Joohee Kim and Byung-Chull Bae. A smartwatch-based feedback system for eating\nrate guidance. In Proceedings of the 2018 ACM ",
            "ing\nrate guidance. In Proceedings of the 2018 ACM International Joint Conference and\n2018 International Symposium on Pervasive and Ubiquitous Computing and Wearable\nComputers, pp. 384–387, 2018.\n[32] Nishiki Motokawa, Asuka Kato, Anna Yokokubo, and Guillaume Lopez. Mealjammer:\nPlate driven meal obstruction system using electromagnet (in japanese). Technical\nreports Entertainment Computing (EC), Vol. 2020, No. 14, pp. 1–2, 2020.\n[33] Haruka Kamachi, Sae Ohkubo, Anna Yokokubo, and Guillaume Lopez.",
            "i, Sae Ohkubo, Anna Yokokubo, and Guillaume Lopez. Eating habit\nimprovement system using dietary sound. IPSJ Behavior Transformation by IoT 　\nBehavior Modiﬁcation Research Kicking-oﬀSymposium 　16.4.2022, 2022.\n[34] Rei Nakaoka, Yugo Nakamura, Yuki Matsuda, Shinya Misaki, and Keiichi Yasumoto.\neat2pic: Food-tech design as a healthy nudge with smart chopsticks and canvas. In\n2021 IEEE International Conference on Pervasive Computing and Communications\n93\nWorkshops and other Aﬃliated Events (PerCom ",
            "ns\n93\nWorkshops and other Aﬃliated Events (PerCom Workshops), pp. 389–391. IEEE\nComputer Society, 2021.\n[35] Guillaume Lopez Sae Ohkubo.\nChewker:\nEating habit detection system using\nnecklace-type device.\nマルチメディア, 分散協調とモバイルシンポジウム2023 論\n文集, Vol. 2023, No. 1, pp. 1597–1604, 2023.\n[36] At how many decibels does a human speak normally. https://decibelpro.app/\nblog/how-many-decibels-does-a-human-speak-normally/.\n[37] Japan Dental Hygienists’ Association. Keep your biting power (in japanese). https:\n//",
            "n. Keep your biting power (in japanese). https:\n//www.jdha.or.jp/pdf/health/hatookuchi_20200401_2.pdf.\n[38] 厚生労働省. 歯科保健と食育の在り方に関する検討会報告書「歯・口の健康と食育～噛\nミング30（カミングサンマル）を目指して～」. https://www.mhlw.go.jp/content/\n10900000/000687163.pdf.\n[39] Eating slowly has many beneﬁts! (in japanese). https://www.osaka-tounyoubyou.\njp/ryouri/yukkuritabe/.\n[40] AOL.com Editors. Is taking 100 bites a day the key to weight loss?, 8 2014.\n[41] System usability scale - wikipedia.\nhttps://en.wikipedia.org/wiki/System\\\n_usa",
            "ipedia.\nhttps://en.wikipedia.org/wiki/System\\\n_usability\\_scale.\n[42] The system usability scale: Past, present, and future. https://www.researchgate.\nnet/publication/324116412_The_System_Usability_Scale_Past_Present_\nand_Future.\n94\n付録\n付録A 本研究に関する論文と発表実績\n2023 年2 月\nHaruka Kamachi, Sae Ohkubo, Anna Yokokubo, Guillaume Lopez\n“ Eating Habit Improvement System using Dietary Sound ”\nHEALTHINH 2023 : 16th International Conference on Health Informatics @Lisbon\n2023 年7 月\nSae Ohkubo，Guillaume Lopez\n“ Chew",
            "Lisbon\n2023 年7 月\nSae Ohkubo，Guillaume Lopez\n“ Chewker: Eating Habit Detection System Using Necklace-type Device ”\n情報処理学会マルチメディア、分散、協調とモバイルシンポジウム2023 @富山国際会議\n場\n2024 年6 月\n伊東優乃，大久保紗恵，木村正子，ロペズギヨーム\n“ CutRest: カトラリー置き型摂食リズム調整システム”\n一般社団法人情報処理学会マルチメディア、分散、協調とモバイルシンポジウム2024 @\n花巻温泉\n95\n付録B 本研究の実験に使用した研究同意書\n図6.1 から図6.3 までは本研究の実験で使用したの研究同意書である．\n図6.1: 本実験の同意書（1/3）\n96\n図6.2: 本実験の同意書（2/3）\n97\n図6.3: 本実験の同意書（3/3）\n98\n付録C 質疑応答内容\n伊藤教授（情報テクノロジー学科）\nQ\n実験の際のセンシングにChewker を使う必要性は何ですか．フィードバックがラン\nダムな条件の実験を行うべきです．\nA\n詳細な食事行動（摂",
            "使う必要性は何ですか．フィードバックがラン\nダムな条件の実験を行うべきです．\nA\n詳細な食事行動（摂食、咀嚼、嚥下、発話）すべてをリアルタイムで検出している\n研究はありません．摂食のみであったり、咀嚼のみの検出をする研究はありますが，\nすべてを高い精度で検出できている研究はありません．現時点ではフィードバック\nを提示するために必要なセンシングはChewker でのみ実現が可能であると言えます．\n浦垣先生（情報テクノロジー学科）\nQ\n食習慣改善に対するChewker の必要性．技術的な有用性についてどのようにお考え\nですか．このシステムは長期的に使用されるとお考えですか．また，継続利用を促\nすための工夫について教えてください．\nA\n本システムは，早食いを改善したいが自制が難しい人々を主なターゲットとしてい\nます．自身で咀嚼回数やペースを管理するのは難しく，意識していても持続するこ\nとが困難な場合が多いです．そのため，Chewker は音楽を活用しながら食事行動を\nコントロールし，アプリが客観的に食習慣の良し悪しを判断できる点で有用だと考\nえます．現代では，スマートフォンを見ながらの食事が",
            "観的に食習慣の良し悪しを判断できる点で有用だと考\nえます．現代では，スマートフォンを見ながらの食事が一般的になりつつあります\nが，食事中にスマートフォンを見ることは，健康に悪影響があるという研究があり\nます．むしろ，スマートフォンなどに注視させずに，会話などを促進してくれれば良\nい食事となります．ゴールはChewker を使って，良い食事を習慣付けて，Chewker\nがなくとも良い食事をできるようになることです．できるようになるまで，どの程\n度の期間を要するかは未検証でわかりませんが，継続してもらうために，成長を示\nすメタファ（花が成長するなど）を介してフィードバックを提示することが一つの\nアイディアとしてあげられます．\n99\n山下先生（情報テクノロジー学科）\nQ\nChewker の目的は音楽を速さを変えながら流すことで咀嚼回数やペースを適切に保\nつことで合っていますか．デモ動画ですと，アプリケーションの画面を見て，回数を\n把握し，増やしたり減らすことができるように見えました．その行動が音楽によっ\nて誘発されていれば，ユーザがテキスト情報を参考に回数を調整してもいいという\nことでしょう",
            "音楽によっ\nて誘発されていれば，ユーザがテキスト情報を参考に回数を調整してもいいという\nことでしょうか．想定としては音楽のみで改善してほしいのか，アプリケーション\nを見てもらう前提なのかどちらでしょうか．\nA\nChewker の目的は音楽を速さを変えながら流すことで咀嚼回数やペースを適切に保\nつことで合っています．ビデオでは配慮が足らず，画面を注視している形になって\nしまっていますが，実際には注視する必要はなく，音楽が1 倍速だと，\n「今は良い食\nべ方なんだ」，0.5 倍速なら，「今はペースもしくは回数が不十分なんだ」と感じて\nほしいです．ユーザがテキスト情報を参考に回数を調整してもいいのですが，想定\nとしては音楽のみで改善してほしいです．どうしても1 倍に戻らない場合など気に\nなった場合のみ，テキストを確認してもらう形になります．また，音楽自体がゆっ\nくり噛むことにつながったり，遅いテンポの音楽はさらに良い食事を促すことがわ\nかっているので，無意識にも咀嚼回数などの増加につながっていると考えます．\n100\n",
            "と考えます．\n100\n"
        ]
    },
    {
        "id": "paper_14",
        "filename": "M2024_Takeshi_Shiba.pdf",
        "title": "M2024_Takeshi_Shiba",
        "fulltext": " \n \n \n \n \n青  山  学  院  大  学 \n \n理  工  学  研  究  科 \n \n \n \n理工学専攻    知能情報    コース \n \n \n \n \n修  士  論  文 \n \n \n \n       学 生 番 号      35623235         \n \n \n       氏     名     柴 武志         \n \n \n研究指導教員    Guillaume Lopez        \n \n理工学専攻修士論文要旨 \n \n \n提出年度： 2024 年度 \n提出日： 2025 年1 月31 日 \n専修コース： 知能情報 コース \n学生番号： 35623235 \n学生氏名： 柴 武志 \n研究指導教員： ロペズ・ギヨーム 教授 \n \n（論文題目） \n \n昂りに連動した動画鑑賞体験拡張スマートフォンアクセサリー \n \n（内容の要旨） \n現在，動画鑑賞は多くの人に親しまれている余暇活動の一つとして定着しており，その主な鑑賞媒体\nとしてスマートフォンが広く利用されている．しかし，スマートフォンによる動画鑑賞では，画面サイ\nズの制約により視聴覚刺激が限定されるため，映画館やテレビのような大画面での鑑賞と比較して没入\n感や情動体験の強度が弱まることが指摘されている．また，横揺れや風などの4D 技術は映画館でしか\n体験できないため，スマートフォンでの動画鑑賞体験の拡張及び，それに伴う情動体験の強化に課題が\nある．本研究は，動画鑑賞中のユーザの脈拍変動に基づいて判定する昂りに連動したフィードバックを\n行うことで，スマートフォンを用いた動画鑑賞体験の拡張を目指す． \nアクション動画鑑賞中のユーザの昂り状態を判定する機械学習モデルを構築するにあたり，9 名の被\n験者を対象に，アクション動画鑑賞中の脈拍変動データをスマートウォッチの脈拍センサから，昂りの\n時間情報を主観表記から収集した．脈拍変動指標を用いて11 個の特徴量を算出し，主観的昂りの時間\n情報を基に「昂り」あるいは「昂りでない」のラベルを付与して，ランダムフォレストによる分類モデ\nルを構築した結果，重視している再現率において，82%の精度で「昂り」と分類することを確認した．\nこの機械学習モデルを応用し，アクション動画鑑賞時にスマートウォッチの脈拍センサを用いた，リア\nルタイムな昂り判定するアプリケーションを開発した．さらに，判定結果に連動して振動と照明が同期\nした擬似心拍刺激を提示するアクセサリーを製作した．前述アプリケーションで，「昂り」と判定された\n場合，ユーザの脈拍数情報をクラウド経由でアクセサリーに送信し，それに基づき振動と照明が同期し\nた擬似心拍刺激を提示する．アクセサリーはスマートフォンを装着可能なハンドケース型に設計し，振\n動は振動アクチュエータを用いて手のひらに，照明は赤色LED にてアクセサリー周囲に提示される． \n本システムを用いたアクション動画鑑賞による情動体験への影響を検証するため，12 名の被験者を\n対象にアクション動画鑑賞実験を実施した．暗室環境で，被験者は30 分程度のアクション動画鑑賞を\nシステムの使用条件と非使用条件の2 条件で実施した．条件の順序は被験者ごとにランダムに設定し，\n同一動画を別日に鑑賞させた．鑑賞後，Self-Assessment Manikin を用いた主観的情動を評価し，使用\n条件ではSystem Usability Scale によるシステムのユーザビリティについても評価した．情動評価にお\nいて，システムを使用した場合の方が快-不快，覚醒度，主導感（没入感）の全ての尺度で有意に高い評\n価が認められた．さらに，両条件の鑑賞順序による情動評価のバイアスが確認されなかったことで，本\nシステムが情動評価に有効な影響を与えた．また，ユーザビリティ評価では，使用条件におけるアクシ\nョン動画鑑賞を経て，十分に許容されるユーザビリティを持つものとして高く評価された．一方で，脈\n拍変動指標の変化を，周波数領域指標の1 つであるLF/HF（低周波と高周波の強度の比）に着目して比\n較したが，両条件間の顕著な違いは確認されなかった．したがって，本研究のシステムは，主観的な情\n動評価には影響を与えたものの，生理指標に対する擬似心拍刺激の効果は限定的であることが分かった． \n今後の展望として，熱や香りの噴射などの他のフィードバック手法との組み合わせを検討し，スマー\nトフォンアクセサリーを拡張することで多様な動画鑑賞体験を創出する．また，アクション動画だけで\nなく，コメディ動画や恋愛動画など多種なジャンルにも対応するシステムを実現に取り組む． \n \n \n青山学院大学大学院理工学研究科 \nAcademic Year of 2024, Submitted on January 31, 2025 \n \nGraduate School of Science and Engineering, Aoyama Gakuin University \n \nTitle: Smartphone Accessory for Enhancing the Video Viewing Experience Linked to \nArousal \n \nStudent Name: Takeshi Shiba \nID Number: 35623235 \nDegree: Master of Engineering \nCourse: Intelligence and Information \nThesis Advisor: Professor Guillaume Lopez \nAbstract  \nCurrently, smartphones are used as the main medium for watching videos. However, \nit has been pointed out that the size of the screen reduces the intensity of the immersive \nand emotional experience compared to large screens, such as in a movie theater or \ntelevision. Moreover, 4D technologies such as lateral shaking and wind can only be \nexperienced in movie theaters. \nThis research aims to extend the view experience of videos on smartphones by \nproviding feedback linked to the user's arousal. Specifically, it produced a smartphone \naccessory that presents multi-modal pseudo-heartbeat stimulation based on the use’s \nstate of arousal while watching action movies. \nIn the developed system, the user’s current state of arousal is estimated using a \nmachine learning model created in preliminary experiments based on pulse rate \nvariability (PRV) data acquired by the pulse rate sensor of a smartwatch. The accessory \nis designed as a case that holds the smartphone in its center and can be held with both \nhands. It can provide vibration to the palm using a vibration actuator and illumination \nusing red light from LEDs surrounding the case. The pseudo-heartbeat stimulation is \nadjusted according to the user's pulse rate at the timing of arousal judgment.  \nThe system’s effectiveness was verified by conducting an action video-watching \nexperiment on 12 subjects who watched a 30-minute action video under two conditions: \nusing and not using the system. After watching the video, subjective emotional \nevaluation was conducted using the Self-Assessment Manikin and usability evaluation \nusing the System Usability Scale. The results of the emotional experience evaluation \nshowed that the developed system provided significantly higher in valence, arousal, and \ndominance (sense of immersion). Besides, the usability evaluation proved that the \ndeveloped system had sufficiently acceptable usability. Changes in PRV indices under \nboth conditions were compared, focusing on the LF/HF (PRV frequency spectrum low \nand high-frequency power ratio) value. Still, no significant differences were observed \nbetween the two conditions, indicating that the effect of pseudo-heartbeat stimulation \non LF/HF was limited. \nFuture prospects include considering the combination with other feedback methods, \nsuch as heat and scent injection, and expanding the accessory to handle a wider variety \nof genres, including comedy and romance videos \n昂りに連動した動画鑑賞体験拡張\nスマートフォンアクセサリー\n柴武志\n2025/01/31\n目次\n第1 章\n序章\n4\n1.1\n研究背景. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n4\n1.1.1\n動画鑑賞の普及とスマートフォン利用の現状. . . . . . . . . . . . .\n4\n1.1.2\n動画鑑賞体験を拡張する取り組み. . . . . . . . . . . . . . . . . . .\n6\n1.1.3\nスマートフォンを利用した鑑賞体験における課題. . . . . . . . . .\n7\n1.1.4\n動画鑑賞における情動強化の重要性\n. . . . . . . . . . . . . . . . .\n8\n1.1.5\nエンターテイメント領域への生体信号の活用. . . . . . . . . . . . .\n9\n1.2\n研究の目的および目標. . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n9\n1.3\n本論文の構成. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n10\n第2 章\n関連研究\n11\n2.1\n情動と心拍変動. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n11\n2.1.1\n感情の種類と情動\n. . . . . . . . . . . . . . . . . . . . . . . . . . .\n11\n2.1.2\n心拍変動と情動の関係. . . . . . . . . . . . . . . . . . . . . . . . .\n13\n2.1.3\n心拍変動を用いた情動評価に関する研究. . . . . . . . . . . . . . .\n14\n2.2\n動画鑑賞と情動. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n15\n2.2.1\n動画に対する印象及び嗜好に関する研究. . . . . . . . . . . . . . .\n15\n2.2.2\n動画鑑賞中の生理反応と映像の関係に関する研究. . . . . . . . . .\n16\n2.2.3\n動画鑑賞時の情動評価に関する研究\n. . . . . . . . . . . . . . . . .\n16\n2.3\n外部刺激によるユーザ体験の強化. . . . . . . . . . . . . . . . . . . . . . .\n18\n2.3.1\n振動刺激による影響に関する研究. . . . . . . . . . . . . . . . . . .\n18\n2.3.2\n照明刺激による影響に関する研究. . . . . . . . . . . . . . . . . . .\n20\n2.3.3\n温冷刺激による影響に関する研究. . . . . . . . . . . . . . . . . . .\n21\n2.3.4\n生体信号に基づいた演出変化による影響に関する研究. . . . . . . .\n22\n2.4\n情動喚起の機序理論とその応用. . . . . . . . . . . . . . . . . . . . . . . .\n22\n2.4.1\n情動喚起の機序. . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n22\n2.4.2\n擬似心拍刺激を利用した情動喚起に関する研究\n. . . . . . . . . . .\n23\n第3 章\n脈拍変動を用いたアクション動画鑑賞時の昂り状態の分類\n26\n3.1\nアクション動画鑑賞時の脈拍間隔の収集. . . . . . . . . . . . . . . . . . .\n26\n3.1.1\n脈拍間隔の収集目的\n. . . . . . . . . . . . . . . . . . . . . . . . . .\n26\n3.1.2\n収集実験の概要. . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n26\n3.1.3\nアクション動画鑑賞に関する質問票\n. . . . . . . . . . . . . . . . .\n27\n3.1.4\n収集実験の手順. . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n29\n3.2\n疲労感および興奮度合いに関する質問票の結果\n. . . . . . . . . . . . . . .\n30\n3.2.1\n疲労感に関する質問票への回答結果\n. . . . . . . . . . . . . . . . .\n30\n1\n3.2.2\n興奮度合いに関する質問票への回答結果. . . . . . . . . . . . . . .\n31\n3.3\n脈拍間隔に対する特徴量の算出. . . . . . . . . . . . . . . . . . . . . . . .\n31\n3.3.1\n記録した脈拍間隔および情動的な昂り\n. . . . . . . . . . . . . . . .\n31\n3.3.2\n脈拍変動の解析手法\n. . . . . . . . . . . . . . . . . . . . . . . . . .\n33\n3.3.3\n時系列の脈拍間隔に対する前処理. . . . . . . . . . . . . . . . . . .\n34\n3.3.4\n特徴量の算出. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n35\n3.4\nラベル付けとデータセットの作成. . . . . . . . . . . . . . . . . . . . . . .\n37\n3.4.1\nラベル付けの目的\n. . . . . . . . . . . . . . . . . . . . . . . . . . .\n37\n3.4.2\nラベル付けの基準\n. . . . . . . . . . . . . . . . . . . . . . . . . . .\n37\n3.4.3\nデータセットの作成\n. . . . . . . . . . . . . . . . . . . . . . . . . .\n38\n3.5\n機械学習アルゴリズムの選定と機械学習モデルの作成. . . . . . . . . . . .\n39\n3.5.1\n機械学習アルゴリズムの選定\n. . . . . . . . . . . . . . . . . . . . .\n39\n3.5.2\n選定した機械学習アルゴリズムによる分類性能\n. . . . . . . . . . .\n40\n3.5.3\n機械学習モデルの作成. . . . . . . . . . . . . . . . . . . . . . . . .\n41\n第4 章\n昂りに連動した動画鑑賞体験拡張スマートフォンアクセサリー\n43\n4.1\nシステムの概要. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n43\n4.1.1\nシステムの構成. . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n43\n4.1.2\nシステムの動作の流れ. . . . . . . . . . . . . . . . . . . . . . . . .\n44\n4.2\n昂り判定に連動した擬似心拍刺激. . . . . . . . . . . . . . . . . . . . . . .\n45\n4.2.1\n擬似心拍刺激を提示する目的\n. . . . . . . . . . . . . . . . . . . . .\n45\n4.2.2\n振動を提示する機器の検討\n. . . . . . . . . . . . . . . . . . . . . .\n46\n4.2.3\n振動を利用した擬似心拍刺激\n. . . . . . . . . . . . . . . . . . . . .\n49\n4.2.4\n照明を利用した擬似心拍刺激\n. . . . . . . . . . . . . . . . . . . . .\n51\n4.2.5\nユーザの心拍数に基づく擬似心拍刺激の対応. . . . . . . . . . . . .\n52\n4.3\n昂りに連動したスマートフォンアクセサリー. . . . . . . . . . . . . . . . .\n53\n4.3.1\n振動提示の設計. . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n53\n4.3.2\n照明提示の設計. . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n54\n4.3.3\nスマートフォンアクセサリーの構造\n. . . . . . . . . . . . . . . . .\n55\n4.3.4\nスマートフォンアクセサリーを使用した動画鑑賞方法. . . . . . . .\n58\n第5 章\nスマートフォンアクセサリーによるアクション動画鑑賞時の情動体験の影響59\n5.1\nアクション動画における鑑賞体験への影響の検証. . . . . . . . . . . . . .\n59\n5.1.1\n実験目的\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n59\n5.1.2\n実験概要\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n59\n5.1.3\n鑑賞体験を測定する指標. . . . . . . . . . . . . . . . . . . . . . . .\n60\n5.1.4\n実験手順\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n61\n5.2\n定性評価の結果および考察. . . . . . . . . . . . . . . . . . . . . . . . . . .\n63\n5.2.1\nシステムの有無での情動評価の比較\n. . . . . . . . . . . . . . . . .\n63\n5.2.2\nシステム無での1 回目と2 回目の鑑賞時の情動評価の比較. . . . .\n66\n5.2.3\nシステム有での1 回目と2 回目の鑑賞時の情動評価の比較. . . . .\n69\n5.2.4\n快適性および使用感の評価\n. . . . . . . . . . . . . . . . . . . . . .\n72\n2\n5.2.5\n擬似心拍刺激を伴うアクション動画鑑賞の評価\n. . . . . . . . . . .\n73\n5.2.6\n情動評価の結果に対する考察\n. . . . . . . . . . . . . . . . . . . . .\n74\n5.2.7\n快適性および使用感の評価に対する考察. . . . . . . . . . . . . . .\n75\n5.3\n定量評価の結果および考察. . . . . . . . . . . . . . . . . . . . . . . . . . .\n75\n5.3.1\n昂りの判定回数の比較. . . . . . . . . . . . . . . . . . . . . . . . .\n75\n5.3.2\n脈波変動指標の変化について\n. . . . . . . . . . . . . . . . . . . . .\n79\n5.3.3\n脈波変動指標の変化および昂りの判定回数に対する考察\n. . . . . .\n80\n第6 章\n結論\n82\n6.1\nまとめ. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n82\n6.2\n今後の展望\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n82\n謝辞\n84\n参考文献\n85\n付録A 本研究に関する発表実績\n95\n3\n第1章\n序章\n本章では，本研究における背景および研究目的，本論文の構成について述べる．\n1.1\n研究背景\n1.1.1\n動画鑑賞の普及とスマートフォン利用の現状\n近年，人々にとって動画鑑賞が身近な娯楽活動であるということが確認される．日本生\n産性本部が実施した「国民の余暇意識および余暇活動への参加実態調査」によれば，2020\n年の調査結果[1] では「動画鑑賞（レンタル，配信を含む）」の推計参加人口が約3900 万\n人に達し，余暇活動として初めて首位を記録した．この背景には，新型コロナウイルス感\n染症の拡大による在宅需要の増加が主な要因として示唆され，多くの人々にとって動画鑑\n賞が主要な余暇活動となったことが考えられる．さらに，2023 年の調査結果[2] では，動\n画鑑賞の推計参加人口は約3600 万人と算出され，国内観光旅行（避暑，避寒，温泉など）\nや外食（日常的なものを除く）に次いで3 位となった．この順位変動には，新型コロナウ\nイルス感染症が5 類感染症へ移行したことに伴い，人々の余暇活動が外出を伴う形で活発\n化したことが影響していると示唆される．しかしながら，動画鑑賞は依然として余暇活動\nの上位に位置しており，2020 年に首位を記録して以降，堅調に推移している．\n加えて，ICT 総研が実施した「有料動画配信サービス利用動向に関する調査」によれ\nば，2023 年の調査結果[3] では有料動画配信サービスの推計利用者数が2022 年末時点で\n約3390 万人と算出され，今後も緩やかな増加傾向が見込まれている．図1.1 は，当社が\n算出した有料動画配信サービス利用者数の推計値を基にした需要予測を示している．この\n増加傾向の背景としては，動画配信サービス間の競争激化に伴う市場拡大が寄与している\nと示唆される．特に，多くのサービス提供者が独自コンテンツの制作や多様なジャンルの\n動画配信を強化している点が注目される．このような取り組みにより，利用者は自身の嗜\n好に応じたコンテンツを選択しやすくなり，新規利用の促進および既存利用者による継続\n利用が後押しされていることが考えられる．\n以上の調査結果より，動画鑑賞が人々にとって主要な余暇活動であり，身近な娯楽とし\nて定着していることが明らかである．特に，在宅需要の増加や動画配信サービスの競争に\nよるコンテンツの多様化が，その定着に寄与していると考えられる．これらの要因を背景\nに，動画鑑賞は引き続き人々の日常における重要な娯楽活動として位置づけられる．\nまた，動画鑑賞が人々の日常に定着する中で，鑑賞するための端末として「スマートフォ\nン」が広く利用されていることが確認される．図1.2 は，前述のICT 総研が実施した調査\n結果に基づく，動画配信サービスにおける視聴端末の利用率を示している[3]．この図か\nら，スマートフォンを利用した動画鑑賞が最も高い割合を占めていることが示唆されてい\nる．この傾向は，スマートフォンの利便性および多機能性による影響が大きいと考えられ\nる．具体的には，動画配信サービス各社がスマートフォン向けに最適化されたアプリケー\n4\n図1.1: 有料動画配信サービス利用者数需要予測（[3] より引用）\nションを提供している点に加え，第5 世代移動通信システム（5G）の普及により，高速か\nつ安定した通信環境が整備され，快適な動画再生が可能となったことが要因として挙げら\nれる．この結果，スマートフォンを利用した動画鑑賞は，場所や時間に縛られることなく，\n利用者が好きな時に好きな場所で楽しめる活動として広く支持されていると推察される．\nさらに，モバイル社会研究所が実施した「スマートフォンでの動画視聴についての調査」\n[4] に基づく図1.3 で示すスマートフォンでの1 日の動画視聴時間によると，スマートフォ\nンでの動画鑑賞時間に関して，20 代以下の回答者の6 割以上が1 日に2 時間以上をスマー\nトフォンで動画鑑賞に費やしており，回答者全体で4 割を超えていることが明らかとなっ\nた．また，10 代男女および20 代女性の約3 割が，1 日に6 時間以上をスマートフォンで\n動画鑑賞に費やしていることが判明した．加えて，よく鑑賞する動画コンテンツとして，\nゲーム，アニメ，音楽，映画などのエンターテイメント系コンテンツを挙げた回答者のう\nち，4 割以上が1 日に2 時間以上をスマートフォンでの動画鑑賞に充てていると回答した\n人に該当することが確認された．\n図1.2: 動画配信サービスの視聴端末の利用率（[3] より引用）\n5\n図1.3: 性年代別「スマートフォンでの1 日の動画視聴時間」（[4] より引用）\n以上の調査結果より，動画鑑賞が人々の日常生活に定着している中で，鑑賞するための\n端末として「スマートフォン」が広く利用されていることが明らかである．スマートフォ\nンは，その利便性や多機能性により，動画鑑賞に適したデバイスであると考えられる．総\nじて，現在の動画鑑賞の利用動向を踏まえると，動画鑑賞は多くの人々に親しまれている\n余暇活動の一つとして定着しており，その主流となる鑑賞方法はスマートフォンを利用し\nたものであると見られる．\n1.1.2\n動画鑑賞体験を拡張する取り組み\n動画鑑賞は，従来の平面的な鑑賞体験を超え，より没入感のある体験へと拡張されつつ\nある．その代表例として，映画館における4D 映画が挙げられる．4D 映画は，視覚や聴\n覚に加えて触覚や嗅覚を活用することで，観客が体全体で映画を感じられる新たな映像体\n験を提供する技術である[5][6]．図1.4 は，CJ 4DPLEX 社が開発した映画館用の環境効果\n技術を示している．この技術では，映像に連動して座席が動くほか，風，香り，水しぶき\nなどの特殊効果が用いられ，\n「アトラクション型の鑑賞体験」として観客に高い没入感を\nもたらすことが可能となっている．さらに，VR（仮想現実）技術を活用した新たな視覚\n的鑑賞体験の提供も試みられている[7]．VR 技術は，360 度の視点で映像を映し出すこと\nが可能であり，視聴者の頭部や身体の動きに応じて映像の視点が変化するため，視聴者は\n6\nまるで物語の中に自らが存在しているかのような臨場感を体験できる．このような映像世\n界に入り込む感覚は，VR を活用した鑑賞体験の大きな特徴であり，強力な没入感を与え\nることが可能である．\n図1.4: CJ 4DPLEX 社製の4D 映画対応シート（[6] より引用）\nこれらの技術は，強力な没入感を提供する手法として確立されている一方で，映像と視\n聴者の間には依然として受動的な鑑賞構造が存在していた．しかし，近年では，視聴者が\n映像に介入する新しい鑑賞体験が提供され始めている．その代表例として，動画配信サー\nビスNetﬂix による「インタラクティブ動画」が挙げられる[8]．インタラクティブ動画で\nは，視聴者が物語の分岐点で提示される選択肢に対する選択を行い，選んだ選択肢に応じ\nて物語が進行する仕組みが採用されている．視聴者が選んだ選択肢により異なる結末やシ\nナリオが展開されるため，視聴者自身が能動的に物語の形成に関与できる．このような鑑\n賞体験は，従来の受動的な動画鑑賞とは大きく異なるものであり，動画鑑賞における革新\n的な手法として注目されている．\nこれらの手法により，動画鑑賞に対する期待は，従来の平面的な鑑賞体験を超え，より\n没入感のある体験の拡張へと変化する．その結果，今日の動画コンテンツの消費形態は多\n様化している．さらに，鑑賞構造の受動的な関係を拡張し，能動的な関係を取り入れた動\n画鑑賞体験を提供することは，鑑賞体験の価値を高め，動画鑑賞を促進する上で大きな意\n義を持つと考えられる．\n1.1.3\nスマートフォンを利用した鑑賞体験における課題\n現在までに，スマートフォンの平均画面サイズは拡大傾向[9] だが，多くが片手に収ま\nる程度の画面サイズである．スマートフォンを使用した動画鑑賞では，スマートフォン特\n有の画面サイズによって没入感のある体験に影響を及ぼすことが指摘されている[10][11]．\nRigby らは，異なる画面サイズが没入感にどのように影響するかを調査した[10]．初め\nて鑑賞する映画コンテンツを対象に，4.5 インチのスマートフォン，13 インチのノートパ\nソコン，および30 インチのモニターでそれぞれ10 分間鑑賞した後，没入感に関する質問\n票を用いて評価した．その結果，スマートフォンで鑑賞した場合，没入感のスコアが最も\n低く，ノートパソコンおよびモニターで鑑賞した場合と比較して，没入感に有意な影響を\n与える主効果が確認された．Dunaway らは，スマートフォンの画面サイズがニュース視\n聴時の注意力や感情的反応に与える影響を調査した[11]．ノートパソコン内でウィンドウ\nサイズを調整することで，大画面（約13 インチ幅）とスマートフォンサイズに対応する\n7\n小画面（約4.5 インチ幅）の画面サイズを再現した．各条件で，国内外のポジティブおよ\nびネガティブなニュース映像を視聴させ，皮膚電気活動および心拍変動を測定した．結果\nとして，小画面条件ではより心拍変動が減少する傾向が確認された．また，大画面条件で\nは，ニュースのネガティブな内容と皮膚電気活動の増加との関連がより強く見られた．両\n者の研究によって，スマートフォンのような小型画面は，視聴者の鑑賞体験の質や感情的\n反応に与える影響が比較的に低下する可能性が示唆された．\nこのように，一般的なスマートフォンを使用した動画鑑賞では，画面サイズの制約によ\nり視聴覚刺激が限定されるため，没入感や情動体験の強度が映画館やテレビのような大画\n面での鑑賞に比べて弱まる傾向がある．この課題に対応するための技術として，風や水し\nぶきなどの大掛かりな4D 要素が挙げられるが，これらがスマートフォン向けに実用化さ\nれた例は確認されない．そのため，スマートフォンを用いた動画鑑賞では情動体験を高め\nるという課題がある．\n1.1.4\n動画鑑賞における情動強化の重要性\n鑑賞者の感情を巧みに刺激することは，動画作品の価値を高める重要な要因の一つであ\nる．感情変動や視覚的動きが鑑賞体験に与える影響は，映画や動画の魅力を強化する役割\nを果たしていることが示されている[12][13]．\nBerger らは，感情変動（sentiment volatility）が映画評価に与える影響を分析した[12]．\n台詞に含まれる感情を感情価の得点として定量化し，映画全体の一定の時間単位または\nシーン単位での差異によって感情の転換頻度を測定した結果，感情変動が大きい作品ほ\nど，観客や批評家から高く評価されている傾向が確認された．この効果はスリラーなど刺\n激的なジャンルで顕著であり，ロマンスでは弱いことが示された．Dayan らは，映画の感\n情喚起の要因としてローカルモーション（物体や人の動き）とグローバルモーション（カ\nメラの動き）に注目し，脳活動との関係を調査した[13]．感情を含むシーンまたは中立的\nなシーンの映像クリップを視聴中の脳活動を測定した結果，感情的な場面でのグローバル\nモーションは，脳の広範囲な感情応答領域を活性化し，自己運動の錯覚を通じて感情的反\n応を引き起こすことが示された．\nまた，動画鑑賞による感情喚起には多くの利点が確認される．まず，感情的な喚起が動\n画に対する印象の向上に寄与することが示されている[14]．さらに，感情的に喚起された\n動画は，その快楽体験によって動画の継続的な鑑賞を促進する効果があり[15]，視聴者の\n社会的つながりを強化する要因として機能することが確認されている[16]．\nCahill らは，12 本の感情的に刺激的な動画と12 本の中立的な動画を提示した際の脳活\n動をポジトロン断層法（PET）で測定し，3 週間後に自由再生テストを用いて記憶評価を\n行った[14]．その結果，感情的に刺激的な動画に対する平均的な扁桃体の活動は中立的な\n動画よりも高いことが確認された．また，扁桃体の活動レベルは，記憶として想起され\nた動画の数と強い相関を示していた．Zaidel は，映画というメディアに対する人々の長期\n的な関心と，映画鑑賞を繰り返す行動の原因について，神経基盤の観点から見解を述べ\nた[15]．映画ジャンルに関係なく観察される現象として，映画鑑賞が繰り返される理由に\nは，音楽，映像美，ストーリーへの共感が相互作用し，ドーパミン報酬系を通じて強力な\n快楽体験を記憶する点が挙げられる．この快楽体験を再び求める傾向が，映画鑑賞を継続\nさせる要因であると示唆された．Berger らは，96 人の学生を対象に，感情的な覚醒が社\n8\n会的伝達に与える影響を調査した[16]．実験群には感情的に興奮する動画を，対照群には\n中立的な動画を提示した後，両群に中立的な記事や画像を提示し，\n「これを他人と共有し\nたいですか」という質問に対して7 段階評価を収集した．その結果，実験群は対照群に比\nべて他者と内容を共有したいという意欲が有意に高いことが確認された．\n以上のことから，動画鑑賞において視聴者の感情を巧みに喚起し，それを持続的な体験\nへと結びつけることが重要であるといえる．感情的な喚起は，作品への印象を向上させ\nるだけでなく，視聴者の継続的な関心を促し，動画の魅力を高める重要な要因となる．ま\nた，感情的な体験は視聴者間の社会的なつながりを強化する役割も担っており，動画鑑賞\nにおける情動強化が鑑賞体験の質を向上させる鍵となる．\n1.1.5\nエンターテイメント領域への生体信号の活用\n近年の健康管理の領域において，スマートウォッチを用いて脈拍数，皮膚温，血圧など\nの生体信号データを収集し，個人の健康状態をリアルタイムで管理する技術が進展してい\nる．そして，スマートウォッチをはじめとする生体信号を取得する機器の小型化に伴い，エ\nンターテインメント領域において生体反応を活用する取り組みが進んでいる．特に，ゲー\nムや音楽の分野では，生体信号やそれに基づくユーザの感情を反映することで，体験をよ\nり没入的かつインタラクティブにする技術が開発されている[17][18][19][20]．\n具体例として，人工知能を利用した感情分析を手掛けるOvomind 社は，ホラーゲーム\nにおいて，ユーザの手首に装着されたスマートバンドから取得する皮膚温度，脈拍数，発\n汗などの生体信号を基に感情を分析し，推定された感情状態に応じて，ゲーム画面の視\n野を狭めたり，赤くなる演出を加えたりするなど，感情状態に連動した演出を取り入れて\nいる[19]．これにより，ユーザ側はプレイ中の自身の感情状態を認識することが可能であ\nり，ゲーム体験の向上に効果を発揮する．一方，Mindset Innovation 社は，独自開発した\n脳波（EEG）センサを搭載したスマートヘッドホンを活用し，ユーザの脳波を基に集中状\n態やリラクゼーション状態をリアルタイムで監視する技術を開発している[20]．この技術\nでは，脳波状態を基に複数の音源を用いた音響刺激を提供することで，ユーザを目標とす\nる精神状態（集中，リラックスなど）へ導くことを支援している．\nこのように，生体情報を活用したエンターテインメントは，個々のユーザに最適化され\nた体験を提供する可能性を秘めており，没入感の向上やインタラクティブな関係の構築を\n通じて，新しい体験を提供する領域に発展することが考えられる．\n1.2\n研究の目的および目標\n現在，動画鑑賞は多くの人に親しまれている余暇活動の一つとして定着しており，その\n主な鑑賞媒体としてスマートフォンが広く利用されている．また，動画コンテンツの消費\n形態は，受動的な構造から能動的な構造にまで広がり，鑑賞体験が多様化している．しか\nし，スマートフォンによる動画鑑賞では，画面サイズの制約により視聴覚刺激が限定さ\nれ，映画館やテレビのような大画面での鑑賞と比較して没入感や情動体験の強度が弱まる\n傾向が指摘されている．この課題を補う手法として，横揺れや風などの4D 技術のような\n体験拡張技術がスマートフォン向けに実用化された例は未だに確認されない．そのため，\n9\nスマートフォンでの動画鑑賞を対象とした動画鑑賞体験の拡張や，これに伴う情動体験の\n強化の課題がある．\n本研究では，動画鑑賞中のユーザの脈拍変動を活用し，脈拍変動から判定される昂り状\n態に応じたフィードバックを行うことで，スマートフォンを用いた個人の動画鑑賞時の情\n動体験を強化させるための手法を提案し，スマートフォンによる動画鑑賞体験を拡張する\nことを目的とする．本論文では，この目的に向けて，アクション動画を対象に次の3 点を\n目標として取り組む．\n1. アクション動画鑑賞時の昂りに連動して，振動および照明による擬似心拍刺激を\n与えるスマートフォンアクセサリーの製作\n2. スマートフォンアクセサリーを用いた情動体験への有用性の検証\n1.3\n本論文の構成\n本論文は以下の章分けによって構成する．\n第1 章では，研究背景，研究目的及び論文の構成について述べる．\n第2 章では，関連研究について述べる．\n第3 章では，脈拍変動を用いたアクション動画鑑賞時の昂り状態\nの分類について述べる．\n第4 章では，昂りに連動した動画鑑賞体験拡張スマートフォンアクセサリー\nについて述べる．\n第5 章では，スマートフォンアクセサリーによるアクション動画鑑賞時の\n情動体験の影響について述べる．\n第6 章では，本論文のまとめと今後の展望について述べる\n10\n第2章\n関連研究\n本章では，本研究における関連研究について述べる．\n2.1\n情動と心拍変動\n2.1.1\n感情の種類と情動\n感情とは何かという問いに対して，心理学の分野を中心として議論されているが，統一\nされた定義や見解は未だ定まっていないとされている．これまでに，\n「喜怒哀楽や好悪な\nど，物事に感じて起こる気持」[21] と説明されるほか，”主観的情感（気持ち）”および”\n人間らしいもの”といった定義的特徴が当てはまることから，\n「高次な認知活動を反映する\nもの」[22] と捉える見方や，Ortony らによる「人，物，出来事，環境についてする評価的\nな反応である」[23] という広義的な定義で説くことがある[24]．\n進化論で知られるDarwin は，動物と人間の表情を対象とした比較観察を通じて，その\n類似性から動物と人間の感情が同質であると認識できるとし，人間が獲得している感情表\n現は進化的かつ適応的なものであると言及した[25]．そして，Ekman らは，表情による感\n情表現が普遍的であるかどうかを検証するため，非識字文化の人々を対象に調査を行った\n[26]．その結果，非識字文化の人々も，西洋や東洋の識字文化圏の人々と同様に，特定の\n感情を特定の表情と関連付けていることが明らかとなり，表情による感情表現が文化を超\nえて普遍的であることを支持する証拠が得られた．また，6 つの感情（喜び，悲しみ，怒\nり，恐怖，驚き，嫌悪）が人間が備え持つ基本感情であることが示唆された．\n他方，Russell は感情は離散的ではなく連続体の中で変化することを提唱し，快－不快次\n元，および覚醒－眠気次元の2 つの次元軸によって構成される2 次元座標を用いた場合，\n全ての感情はこの平面上で円環に配置されることを言及した[27]．図2.1 は，提唱された\n2 次元座標系に基づく感情の円環モデルを示す．この円環モデルでは，興奮，怒り，憂鬱\nといった異なる感情が明確な境界を持たず，それらの感情が徐々に変化し，その間に微妙\nな変化や中間的な感情を経て，他の感情に移行する様子を表現することが可能である．ま\nた，感情の二極性を包括したモデルについても言及している[28]．図2.2 のように，感情\nを快―不快の感情価次元と，活性―不活性の活性度次元という2 つの次元軸で捉えること\nによって，感情を「ポジティブ感情（PA）」および「ネガティブ感情（NA）」という抽象\n的なレベルで理解し，その二極性を表現している．\n感情の類義語として，情動という言葉がある．情動とは，\n「怒り，恐れ，喜び，悲しみな\nどのように，比較的急速に引き起こされた一時的で急激な感情の動き」[21] と説明される\nほか，\n「交感神経や内分泌系の活動によって引き起こされる，身体の興奮状態（生理的覚\n醒）を伴う強い感情」[24] と述べられている．本論文では，動画鑑賞中の身体的反応や一\n時的な興奮状態に焦点を当てるため，情動を感情を含む概念として用いる．\n11\n図2.1: 感情の円環モデル（[27] 中の図を基に作成）\n図2.2: PA・NA を包括した円環モデル（[28] 中の図を基に作成）\n12\n2.1.2\n心拍変動と情動の関係\n心臓は収縮と弛緩の運動を繰り返すことによって律動的に拍動を続けている．図2.3 は\n心電図波形を表している．心電図は，心臓の電気的活動による電位差を電極を用いて，体\n表面から非侵襲的に測定することによって得られる．心電図波形に見られるように，律動\n的な拍動間の時間間隔を心拍間隔（RRI: R-R interval）と呼ぶ．一般に，心拍間隔は常に\n一定ではなく，変動する．睡眠などの安静時および有酸素運動などの運動時の心臓の鼓動\nの違いが意識的に確認できるように，心身の状況の変化によって心拍間隔は変化する．こ\nの心拍間隔の周期的な変動を「心拍変動（HRV: Heart Rate Variability）」と呼ぶ．\n図2.3: 心電図波形（[29] より引用）\n心拍間隔にみられる周期的な変動は自律神経系の機能との関係を持つ．というのも，自\n律神経系の活動が心拍間隔の周期的な変動に影響を与えるという関係性が示されている\n[29]．自律神経系とは呼吸や血圧の他，発汗や消化などの生命活動に必要な機能を調節す\nる役割を持つ神経系であり，この自律神経系には，大きく分けて「交感神経」および「副\n交感神経」の2 種類の神経が存在する．これら2 種類の神経は心身に対して互いに相反す\nる作用を持ち，心身が健やかな状態であるためには，互いに優位状態（働きの強さ）が一\n方的な偏りなく活動している状態でなければならない．一般に，交感神経は心身に興奮や\n緊張を引き起こす神経系である．交感神経が優位に働く際，心臓の活動が活発化し，心拍\n数の増加，血管の収縮，瞳孔の拡大，そして発汗などの身体的変化が生じる．一方で，副\n交感神経は心身に休息や安静を促す役割を担う神経系である．副交感神経が優位に働く\n際，心臓の活動が抑制され，心拍数の減少，血管の拡張，瞳孔の縮小などの身体的変化が\n生じる．活動状況の例として，交感神経が副交感神経より優位に活動している場合，心身\n上では心拍数の増加や発汗などの変化が生じる．\n心拍間隔にみられる周期的な変動に影響を与える自律神経系の働きにおいて，情動体験\nによる影響があることが示唆されている．Ohira らは，快または不快な情動を喚起させる\n画像を提示した際の脳活動を陽電子断層撮影法（PET）で観測すると同時に，心拍や皮膚\n伝導反応，強い情動が誘発された際に分泌される副腎皮質刺激ホルモン（ACTH）の血中\n濃度を測定した[30]．その結果，情動的な刺激を有する画像が提示された際に，扁桃体\nが活発になり，皮膚伝導反応とACTH 濃度に正の相関関係が確認された．つまり，情動\nを司る扁桃体が活発になることで，自律神経系も活発になることが示された．この他に，\nEkman らは，情動が自律神経系の反応を引き起こす際に，それが情動ごとに異なる特徴\nを持つかどうかを調査した[31]．被験者に特定の情動を引き出すための顔面プロトタイプ\nを構築し，さらに，過去の強い情動体験（怒り，悲しみ，恐怖など）を再現させ，その際\n13\nの自律神経活動を記録した結果，情動ごとに心拍数や皮膚温の変化量が異なることが確認\nされた．つまり，情動間で自律神経系の活動は異なることが示唆された．\n前述を踏まえて，心拍変動と自律神経，および自律神経と情動には関係性があることが\n示唆されている．情動は自律神経系の活動に影響を与え，自律神経系は心拍や発汗などの\n様々な身体的変化を制御しているということに基づいて，心拍などの生体信号を解析する\nことによって，情動を判別することが可能であることが考えられる．\n2.1.3\n心拍変動を用いた情動評価に関する研究\nSubahni らは，ストレスの身体への影響に注目し，ビデオゲーム中のユーザの精神的ス\nトレスに対して心拍変動（HRV）に基づいた指標からの観察を検証した[32]．レースが題\n材のゲームを使用し，試遊前後に閉眼および開眼の時間を設けて安静時の心拍変動を測定\nすることで，ゲーム中の変化の比較対象とした．HRV は時間領域と周波数領域で分析さ\nれた．結果，ゲーム中の平均心拍数は有意に増加し，標準偏差（SDNN）は有意に減少し\nて交感神経の活性化を示した．さらに，交感神経と副交感神経のバランスを示すLF/HF\n比は，ゲーム中に休息時よりも高くなったことが確認された．\nRakshit らは，パルスオキシメータから得られる光脈波信号を基に心拍変動の特徴量を\n算出し，時間領域および周波数領域の特徴量に基づいて感情認識を行った[33]．図2.4 は\n実験時の様子を示している．被験者には「Happy」「Sad」「Neutral」の感情を引き起こす\n動画クリップを視聴させ，その間に光脈波信号を収集した．収集した光脈波信号から算出\nされた心拍変動の特徴量をデータセットとして，サポートベクターマシンを用いて分類モ\nデルを構築し，1 個抜き交差検証を行った．その結果，全体の平均分類精度は83.8%であ\nることが確認された．\n図2.4: 動画クリップ鑑賞による実験時の様子（[33] より引用）\nChoi らは，国際感情画像システム（IAPS）を用いて，感情を評価するツールとしての\n心拍変動の妥当性を検証した[34]．被験者は「Happy」「Unhappy」「Neutral」の画像を見\nた際，自己評価マネキン（SAM）で主観的感情を評価し，同時に心拍信号が記録された．\n14\n分析の結果，\n「Unhappy」画像で覚醒度が高い場合にのみ，誘発性と有意な正の相関，支配\n性と有意な負の相関が確認された．これにより，強い情動が誘発される場合に限り，HRV\nによる感情評価が可能であることが示唆された．\nWu らは，中国感情動画システム（CAVS）を用いて，特定の感情が心臓の働きに与える\n影響を調査した[35]．\n「Amused」「Fearful」「Angry」「Neutral」の感情を強く引き起こす動\n画を選定し，被験者に提示後，主観的感情の評価を行い，同時に心電図から心拍変動を収\n集した．分析の結果，\n「Amused」は他の感情と比較して心拍数を低下させ，心拍変動を増\n加させることが確認され，これにより「Amused」が副交感神経の活性化と関連している\nことが示唆された．さらに，\n「Angry」は「Fearful」と比較して心拍変動が高いことから，\nネガティブな感情の中でも特定の感情を区別できる可能性が示唆された．\nYu らは，脈拍センサから取得した心拍間隔および心拍変動を基に，ユーザーのストレ\nス度合を測定し，樹木の成長を隠喩的に用いた視覚化によるバイオフィードバックシステ\nムを提案した[36]．本システムでは，過度なストレスがかかると樹木が徐々に枯れ，反対\nにバランスの取れた状態では樹木が丈夫に成長する様子をリアルタイムで表現する．提案\nされたシステムの使用により，呼吸を意識したストレス管理や動機付けが促進され，健康\nな樹木を維持しようとする行動が確認された．\n多田らは，心拍数の上昇率と計算課題の正解率との間に負の相関があることに着目し，\n心拍数の分散に基づいて休憩を促すシステムを開発した[37]．システムの有無による計算\n課題を実施した結果，システム通知による休憩の実施回数は多かったものの，誤答数など\nに有意差がなく，頻繁な通知音が課題作業や心拍に影響を及ぼした可能性が示唆された．\n2.2\n動画鑑賞と情動\n2.2.1\n動画に対する印象及び嗜好に関する研究\n金らは，動画視聴時の嗜好評価（気に入る・気に入らない）に影響を与える感情や印象\nを調査した[38]．被験者に4 本のスクリーンセーバー映像を各20 秒間提示し，最も気に\n入る映像と気に入らない映像を選択させた後，16 の感情語と14 項目の形容詞対による印\n象評価を行った．結果として，\n「動き」と「登場する要素」の2 つの印象と「緊張」とい\nう感情が嗜好評価に関わる重要な要素であることが確認された．特に「気に入る」では興\n味，楽しさ，安心が，\n「気に入らない」では混乱，困惑，嫌悪が有意に高い選択傾向を示\nし，\n「緊張」は嗜好評価に依存して意味合いが変わることが示唆された．\nTopal らは，映画の評価や論評に含まれる感情的側面を分析し，感情マップとして可視化\nすることで新たな映画選択手法を提案した[39]．映画情報サイトであるIMDb から134 本\nの映画に対する157,344 件の論評を収集し，各ジャンルのカテゴリには少なくとも10 本の\n映画があるように整理した．各映画の上位100 件の論評を対象に，論評に含まれる語句を\nSenticNet データベースを用いて感情モデル（sensitivity，pleasantness，aptitude，attention）\nに基づいた感情次元とレベルで分類し，その結果をヒートマップとして映画の感情的特徴\nを表現した．評価として，様々な映画に適用した結果，同一ジャンルの高評価映画でも感\n情マップが異なる一方，低評価映画では類似した反応が見られることが確認された．\n15\n2.2.2\n動画鑑賞中の生理反応と映像の関係に関する研究\nSakuragi らは，喜劇および悲劇動画の視聴によって誘発される笑いや悲しみが，自律神\n経系や気分に与える影響を分析した[40]．Proﬁle of Mood States（POMS）を用いて主観的\nな気分を評価し，心拍変動のスペクトル分析により自律神経系の活動を測定した．喜劇動\n画の視聴時には交感神経系（LF/HF）の反応が確認され，視聴後には視聴前の状態に戻っ\nた．一方，悲劇動画では交感神経系の反応が緩やかに増加し，視聴後もその影響が持続し\nたことが確認された．この結果より，笑いは自律神経系に強力な一過性の影響を与え，悲\nしみは中程度の影響を与えながら持続的効果をもたらすことが示唆された．\n村瀬らは，視聴覚刺激による情動誘発の有無と自律神経系への影響を調査した[41]．滑\n稽，穏和，恐怖，不快動画を選定し，被験者に心電図計と呼吸計を装着して視聴させ，視\n聴後に情動を質問表で評価した．結果，滑稽，穏和，恐怖動画では85～93%，不快動画で\nは57%の被験者が想定する情動を認知した．自律神経系の変化では，滑稽動画で交感神\n経が有意に活性化し，副交感神経が抑制された．一方，不快，恐怖，穏和動画では交感神\n経が抑制され，副交感神経が活性化した．心拍数に有意な差はなかったが，滑稽・穏和動\n画では増加し，不快・恐怖動画では減少する傾向が見られた．不快動画で交感神経の活性\nが見られなかったのは，不快情動の認知の割合が低い影響が示唆された．\n宮本らは，動画視聴中のユーザの皮膚抵抗増加量，皮膚抵抗値，指尖皮膚温，心拍数の\n生体信号を用いて，動画に対するユーザの嗜好性との関連を調査した[42]．動画中の皮膚\n温減少場面が多い被験者ほど，動画に対して高い評価を示す傾向が確認され，動画に対す\nる嗜好性を判断する上で指尖皮膚温を用いることが有効な手段であることが示唆された．\nFukumoto らは，ホラー映画が与える心理生理学的影響を調査し，恐怖感と生理的変化\nの関係を調査した[43]．10 名の男性被験者を対象に，映画視聴中の心電図，呼吸，皮膚\n電気活動を測定した後，主観的な恐怖を感じた場面を尋ねた．呼吸のみを分析した結果，\n恐怖を感じた場面では呼吸の強度が増加し，呼吸周期も加速していることが確認された．\nこの特徴は全ての被験者で有意に見られた．\nVermeulen らは，動画視聴中のユーザの心拍数変化を基に，情動的な見所をまとめた動\n画クリップを生成するシステムを提案した[44]．手首装着型センサで心拍数を測定し，見\n所検出の実現可能性を調査した結果，特に嫌悪感，面白さ，悲しさ，恐ろしさを感じる場\n面で心拍数の減速が確認された．この結果を基に，嫌悪感のある動画で心拍数の減速が見\nられる部分を見所としてクリップを作成し，編集の専門家が作成したクリップと比較した\nところ，専門家の見所は心拍数の変化とHeartefact の両方と一致する傾向が見られた．\n2.2.3\n動画鑑賞時の情動評価に関する研究\n代蔵らは，動画鑑賞者の興奮反応に合わせて動画の音量を調整することで，鑑賞者の興\n奮を意識させること無く促進させる動画鑑賞システムE3-Player を開発した[45]．図2.5\nは，当システムを利用した動画鑑賞の概要図を示している．手のひらの皮膚コンダクタン\nス反応に基づく興奮に応じた音量変化によって，興奮の平均反応量が高いことが示され，\n興奮を促進させることが可能であることが示唆された．一方で，すべての興奮反応に対し\nて音量を変化させたとしても，興奮を促進させることができないことも示唆された．\n16\n図2.5: E3-Player 概要図（[45] より引用）\n角田らは，心拍数と呼吸数の長期変動の類似性が人の心的状態を表す可能性に着目し，\nこれを用いてコンテンツ視聴時のユーザの気分変化を推定する手法を提案した[46]．ま\nず，コンテンツ視聴中の心拍数と呼吸数，視聴前後の気分状態を測定し，心拍数と呼吸数\nの長期変動の類似度と視聴前後の気分変化量を算出した．それらを学習データとして回帰\nモデルを構築し，20 名のコメディ映像の視聴時データを用いて評価を行った．1 名のデー\nタを入力とし，残り19 名のデータで構築した回帰モデルで推定した結果，実測値との相\n関が高い推定値が得られ，提案手法の有効性が確認された．\n吉田らは，映画視聴時の情動を心拍変動から機械学習で判別できるかを検討した[47]．\n被験者はホルター心電計を装着し，映画視聴中に喜び，心配，驚き，悲しみ，嫌悪，怒り\nのいずれかの情動が生じた際にボタンを押して情動と時刻を記録した．ボタンが押された\n前後1 分，2 分，3 分間のRRI，LF，HF を特徴量として機械学習で分類した．結果，前\n後1 分間のRRI で「心配」が再現率0.620，前後1 分間のLF と前後3 分間のHF で「悲し\nみ」がそれぞれ再現率0.582，0.560 で判別された．これにより，心拍変動による情動分類\nでは，快よりも不快の情動の方が再現率が高いことが確認された．\n東海林らは，スマートウォッチから取得した心拍変動を用いて，客観的に恐怖を感じた\nとする箇所と心拍変動の反応との関係を分析した[48]．暗室でのホラー動画鑑賞時に取得\nした心拍変動から算出する自律神経機能のバランスを示すストレス指標（LF/HF）を用い\nた分析の結果，恐怖を感じたとする箇所の約15 秒前から約25 秒後にかけて，ストレス指\n標の反応が持続することが確認された．\n竹下らは，鑑賞者の恐怖感に応じて再生速度が変化するインタラクティブなホラー動画\n鑑賞システムを提案した[49]．図2.6 は，ホラー動画鑑賞システムの概要図を示している．\nスマートウォッチを用いて取得する心拍変動から算出された周波数領域成分を基に，恐怖\nを感じているか否かを推定し，その推定結果に基づいてスマートフォン上のホラー動画\nの再生速度を制御する．本システムを利用したホラー動画の鑑賞において，\n「印象に残る」\n「動きがある」「スリルを感じる」といった印象が抱かれることが確認され，恐怖に関連す\nる印象を増幅させる効果があることが示唆された．\n17\n図2.6: ホラー動画鑑賞システムの概要図（[49] より引用）\n2.3\n外部刺激によるユーザ体験の強化\n2.3.1\n振動刺激による影響に関する研究\nLemmens らは，映画鑑賞体験を感情的に没入させるため，映画の場面に同期して触覚\n刺激を与える振動アクチュエータを用いたウェアラブル触覚ジャケットを提案した[50]．\n図2.7 は，振動アクチュエータが備えられたウェアラブル触覚ジャケットを示している．\nジャケットには64 個の振動アクチュエータが内蔵され，専用ソフトウェアを使って多様\nな刺激パターンを提示できる．被験者は，ジャケットの有無の条件で7 つの動画クリップ\nを視聴し，条件別の視聴後に興奮度合いおよび没入感を評価するアンケートに回答した．\n結果として，没入感を評価する複数の項目で有意に高い得点が得られた．さらに，客観的\nな評価では，触覚刺激を伴う視聴時に皮膚伝導レベルの平均値が複数のビデオクリップで\n増加したことが確認された．\n図2.7: ウェアラブル触覚ジャケット（[50] より引用）\nSeim らは，手の触覚刺激に対する振動感知能力を調査した[51]．実験では，コイン型の\n振動モータを用いて，1) 刺激位置による知覚精度，2) 指の複数同時振動の知覚精度，3)\n18\n振動モータ（ERM とLRA）別の知覚精度を評価した．各実験の結果では，指先から手の\n中心（手のひら）に向かうにつれて知覚精度が有意に向上し，複数の同時触覚刺激の知覚\n能力は低く，特に3 つ以上の同時刺激でその傾向が顕著だった．また，ERM とLRA によ\nる振動モータ別で知覚精度に有意差は見られないことが確認された．\nMazzoni らは，振動による触覚提示を備えたウェアラブルなグローブを設計し，振動触\n覚刺激を通じて映画に含まれる音楽によって誘発される感情（Mood music）を増幅でき\nるかを検証した[52]．図2.8 は，触覚提示を備えたグローブのプロトタイプを示している．\n振動触覚刺激は，ユーザのフィードバックに基づいて段階的に設計され，低強度・低周波\nの刺激が落ち着きを与え，低強度・高周波では興奮感を高め，高強度・高周波では緊張感\nを増幅させることが確認された．また，Mood music を含む映画クリップを振動触覚刺激\nと組み合わせて視聴した結果，映像の評価自体は変わらないものの，興奮度が高まること\nが確認された．\n図2.8: グローブのプロトタイプ（[52] より引用）\nAblart らは，対象者に触れずにフィードバックを提示する空中触覚刺激が短編映画を題\n材とした視聴体験に与える影響を調査した[53]．事前に，皮膚電気反応データから感情的\nピークが現れた1 分間の映画を選定し，その感情的ピークに基づいて空中触覚刺激を設\n計した．参加者を2 つのグループに分け，触覚刺激の有無で映画を視聴させた後，2 週間\n後に再度評価を行った．結果として，触覚刺激がある条件では好意度と覚醒度が有意に高\nく，皮膚電気反応でも高い値が確認された．これにより，空中触覚刺激が視聴体験の質を\n高める可能性が示唆された．\nJeong らは，椅子を意図的に左右に傾けるモーション効果が，鑑賞中の感情や生理的反\n応に与える影響を調査した[54]．被験者には生体信号を測定するセンサを装着させ，モー\nション効果の有無で異なる映画クリップを鑑賞させた後，感情や没入感に関するアンケー\nトを実施した．その結果，モーション効果により脈拍が減少し，皮膚コンダクタンスレ\nベルが増加したことが確認された．また，覚醒感と没入感が高まることも明らかとなり，\nモーション効果が観客を興奮させ，没入させるのに有効であることが示唆された．\nKosuge らは，ハグシーンを視聴しながら上半身に振動刺激を与えることで，感情がど\nのように変化するかを調査した[55]．振動刺激には，胸部前後に接触する2 つのコイル\nモーターを使用し，ハグシーンの開始時に50Hz の振動を2 秒間与えた．被験者は8 つの\nハグシーンを視聴し，そのうち3 から5 つのシーンで振動刺激を受けた．各シーンの視聴\n19\n後，感情に関する10 個の形容詞で評価を行った結果，振動刺激のあるハグシーンにおい\nて「喜び」の感情が増幅または抑制される可能性が示唆された．\nCerdan らは，特定のタイミングで振動が発生するコインモーターを装着したグローブを\n設計し，感情的刺激を含む映像を視聴する際の視聴者の脳波を，振動の有無による2 条件\nで記録し，触覚刺激の影響を評価した[56]．触覚刺激を含む映像視聴時には，前頭部およ\nび眼窩前頭部の脳領域において，活動がより広範かつ活発になることが示された．これに\nより，振動による触覚刺激が追加されることで，注意に関連する脳領域の活動が増加し，\nその結果，感情処理に関連する領域の活動も強まることが示唆された．\nTara らは，映像視聴時の上半身への振動刺激のタイミングが皮膚コンダクタンス反応や\n主観的評価に与える影響を調査した[57]．ホラービデオでは怪物の初出現と同時の振動\nが恐怖反応を最大化し，400 ミリ秒以上の遅延では効果が減少した．一方，フィギュアス\nケートではジャンプ時の振動が興奮を促し，最適なタイミングは視聴者ごとに異なった．\nまた，110Hz 以上の振動は映像体験を劣化させる可能性が示唆された．\n2.3.2\n照明刺激による影響に関する研究\nOrtiz らは，照明の色彩が室内空間での感情に与える影響を調査した[58]．LED ストラ\nイプとマイコンを用いて光色（赤，オレンジ，黄，緑，水色，青，紫，ピンク）を制御し，\n被験者は白い壁の部屋で各色にさらされた際の感情をアンケート（緊張，娯楽，魅力な\nど）で評価した．結果，暖色系の光は緊張感があり，熱く，好ましくないと評価され，寒\n色系の光は悲しさを伴うが，心地よいと評価された．また，感情に対する色の影響は男女\nで類似しており，LED ストライプの色の特性として説明できることが示唆された．\nIwamoto らは，デート中のユーザ同士の不安を解消する手法として，ユーザの興奮度合\nいをLED の光色で視覚的に表示することでデートセッションを支援するソファ「Lovable\nCouch」を提案した[59]．光電式容積脈波センサで取得した心拍信号から興奮度合いを算\n出し，その興奮度合いに基づいてソファに備わるLED を赤色点灯する仕組みを構築した．\nシステム評価の結果，このシステムを通じて相手の愛情度の推測に役立ち，非言語的コ\nミュニケーションを支援し，不安を和らげる効果がある可能性が示唆された．\nWilms らは，色相（青，緑，赤），明度（低，中，高），彩度（低，中，高）の3 次元の\n色空間を操作し，色の刺激が情動に与える影響を主観的評価と生体信号で調査した[60]．\n被験者は30 通りの光色刺激をLED パネルで提示され，自己評価マネキン（SAM）を用\nいて感情を主観評価し，同時に皮膚コンダクタンス反応（SCR）と心拍数を記録された．\n結果として，主観的評価において色の変化は価値（valence）よりも覚醒（arousal）に強\nい影響を与え，特に彩度および明度を調整した上で赤が最も覚醒度を高めることが示され\nた．さらに，赤への色相の移行でSCR が増加し，覚醒度の評価と一致した．このことか\nら，色の感情への影響は色相，明度，彩度の組み合わせで決まり，それらの相互作用を考\n慮することが重要であると示唆された．\nWeijs らは，明度（低，中）と彩度（中，高）が異なる赤色または青色の仮想室内環境\nを用いて，色の刺激が情動に与える影響を主観評価と生体信号で調査した[61]．被験者は\n各光色条件で暴露され，自己評価マネキン（SAM）で感情を主観評価し，同時に皮膚電\n気活動（EDA）と心電図を記録された．結果では，主観評価と光色条件の間に有意な相関\nは見られなかったが，明度が心拍数と心拍変動（RMSSD）に有意な影響を，色相がEDA\n20\nに影響を与えることが確認された．特に，低明度・高彩度および中明度・中彩度の赤色条\n件でEDA が高かった．このことから，色の感情への影響は色相だけでなく，明度や彩度\nも重要であることが示唆された．\nBuechner らは，赤色刺激が情動の覚醒および価数（感情的な肯定性・否定性）の認知に\n及ぼす影響を調査した[62]．310 名の被験者を，赤色条件または青色条件のテストとニュー\nトラル条件に分け，テスト条件ではネガティブな写真を，ニュートラル条件では自然風景\n写真を4 枚提示した．各写真の枠は条件に応じた色で囲まれており，5 秒間の観覧後に覚\n醒度と価値を主観評価した．結果，赤色は刺激の価数に関係なく覚醒度の認知を高め，ネ\nガティブ画像を見た被験者において，赤色は中立的な画像に比べて否定的な価数の認知を\n強化することが確認された．\nKim らは，動画視聴における情動体験を強化するために，情動に基づいたインタラク\nティブな照明制御システムを提案し，動画視聴中に赤色光と青色光の2 種類の照明条件で\nの生理的反応を評価した[63]．図2.9 は，任意の動画に対して照明を照射した際の様子を\n示している．興奮を促す動画視聴中に赤色光を使用した場合，心拍間隔と高周波・超低周\n波比率が有意に低下し，一方で，リラックスする動画視聴中に青色光を使用すると，これ\nらの値が有意に増加することが確認された．この結果から，情動状態に応じた照明制御が\n情動体験の質を向上させる可能性が示唆された．\n図2.9: 各動画鑑賞時に制御された光色で照射される様子（[63] より引用）\nShin らは，明るさと色温度を制御した直接と間接照明（ダウンライト400lx，アップラ\nイト300lx）と直接照明（ダウンライト700lx）の2 つの照明環境で，直接と間接照明を併\n用した環境が感情や脳活動に与える影響を調査した[64]．脳波を測定中に各照明環境が4\n分間提示され，その後に照明環境についての感情を評価した．直接照明と間接照明を併用\nした環境では，直接照明環境に比べてシータ波と「快適」に有意な相関があり，直接照明\nと間接照明の併用が空間の快適性や情動的な反応に影響を与えることが示唆された．\n2.3.3\n温冷刺激による影響に関する研究\n馬場らは，ペルチェ素子を使用した温冷刺激提示機能を組み込んだゲームコントローラ\nを用いて，温度変化量とユーザの反応速度の関係性を調査した[65]．制作したゲームコン\nトローラは，一般的なコントローラへの応用を考慮した形状設計とし，温冷刺激モジュー\nルを実装可能なサイズで構築した．実験の結果，温冷刺激提示後のユーザの反応時間にお\nいて，温冷感ともに約3 秒で温度変化を知覚できることが確認された．特に冷却提示に関\n21\nしては，温度の下降速度が速くなるほど，温度変化の知覚反応時間が有意に速くなること\nが明らかとなった．\nTsuruno らは，動画鑑賞時の興奮を高めるために，温熱刺激が興奮的知覚を増強するか\nどうかを検証した[66]．温熱刺激装置を使用し，左前腕に温熱刺激を与え，興奮反応は皮\n膚コンダクタンスの変化を用いて記録した．被験者は温熱刺激の有無による2 つの条件下\nで3 本の動画を視聴し，視聴後に感情の度合いに関するアンケートに回答した．結果とし\nて，温熱刺激の有無による興奮感には有意差が確認されなかったが，ある動画においては\n緊張感に有意差が認められた．これにより，温熱刺激の提示時の温度変化速度が影響を与\nえる可能性が示唆された．\n2.3.4\n生体信号に基づいた演出変化による影響に関する研究\nDekker らは，ホラー型FPS（First Person Shooter）ゲームにおいて，生体信号に基づい\nてゲーム内の演出を動的に変化させることで，ゲーム体験を強化する手法を開発した[67]．\n指先で心拍変動とガルバニック皮膚反応を測定するセンサデバイスを装着したマウスを\n使用し，各生体信号に応じてゲーム内の音量や画面の色度などを調整した．その結果，ホ\nラーゲームを好むユーザに対してはこの手法が効果的であることが確認されたが，ホラー\nゲームを好まないユーザには効果が限定的であることが示唆された．\n荒木らは，脈拍測定バンドを用いて，ユーザの脈拍数に応じてホラーゲーム内の演出が\n変化するヘッドマウントディスプレイ対応のホラーゲームを開発した[68]．この手法によ\nるホラーゲーム体験では，多くのユーザが強い恐怖を感じることが確認され，恐怖感を提\n供するコンテンツとして高く評価された．一方で，非常に強い恐怖感によりゲームの進行\nが困難になるユーザや，ほとんど恐怖を感じないユーザも確認され，恐怖感に対する個人\n差が存在することが示唆された．\n2.4\n情動喚起の機序理論とその応用\n2.4.1\n情動喚起の機序\nJames は，情動体験に先立って生理的活動が生じると示唆している[69]．つまり，外部\n刺激に対して不随意的に身体的変化が起こり，その後に脳がそれを知覚することで情動が\n生じるという機序である．具体例として，\n「熊に遭遇する」といった外部刺激に対し，心\n臓の鼓動が速くなったり，発汗が生じるなどの身体的反応が最初に発生し，それを脳が認\n識することで「恐怖」といった情動を体験すると説明される．この理論に基づくと，情動\nは身体的変化の結果として主観的に感じられるものであり，身体的変化がなければ情動も\n存在しないと考えられる．この機序理論は一般に「抹消起源説」と呼ばれる．\nCannon らは，情動体験には生理的活動の認知が必ずしも必要ではないと示唆している\n[70]．つまり，外部刺激に対して脳の中枢である視床（視床下部）が処理を行い，この視\n床の働きによって情動が生じるという機序である．外部刺激に伴う身体的変化は，視床に\nよる処理過程の結果に過ぎないと考えられる．実験においても，脳と内臓をつなぐ神経を\n切除した動物において情動体験に変化が見られないことが確認された．この機序理論は一\n般に「中枢起源説」と呼ばれる．\n22\nSchachter らは，情動体験には生理的活動とそれに対する解釈（ラベル付け）の相互作用\nが生じると示唆している[71]．つまり，外部刺激に対して不随意的に身体的変化が生じ，\nその変化の原因に対する解釈が情動を引き起こすという機序である．具体例として，\n「熊\nに遭遇する」といった外部刺激に対し，心臓の鼓動が速くなったり，発汗が生じるなどの\n身体的変化が発生し，それと同時に「熊に襲われて負傷するかもしれない」という恐怖の\n認識が加わることで，これらの身体的変化が「恐怖」という情動として体験されると説明\nされる．この機序理論は一般に「情動二要因説」と呼ばれる．\n図2.10 は上記の機序理論をまとめた概要図である．\n「抹消起源説」では，自律神経系の\n活動によって生じる身体的変化の認知が情動体験に繋がるとする理論が主張されている．\n一方で，\n「中枢起源説」は，視床を中心とした脳内機能の処理によって情動が体験されると\nする理論であり，これに対して批判的な立場を取っている．情動喚起の機序に関しては，\n近年では身体的変化の認知が情動体験に影響を与える可能性が示唆され，\n「抹消起源説」を\n間接的に支持する考えが述べられている[72][73]．\n図2.10: 情動喚起の機序理論の概要図\n2.4.2\n擬似心拍刺激を利用した情動喚起に関する研究\nValins は，感情的な刺激に対する評価が心拍などの内的反応の認知によってどのように\n影響されるかを検証した[74]．被験者にセミヌードの女性のスライドを提示し，擬似的な\n心拍音を聴かせた．スライド中の女性の魅力を100 点満点で評価させ，心拍音を自身のも\nのと信じ込ませたグループと，無関係な音であると説明したグループで比較した結果，前\n者は心拍音を上昇させた際に女性の魅力得点をより高く評価した．これにより，擬似的な\n心拍音が情動評価に影響を与える可能性が示唆された．\nInamori は，擬似的な心拍音フィードバックがヌードスライドの評価に与える影響と，実\n際の心拍数との関連を調査した[75]．被験者には，心拍数に応じて音源が移動することを\n説明し，12 枚のヌードの女性のスライドを心拍数の増加・減少・一定の3 条件でランダム\nに提示した．スライド中の女性の魅力を100 点満点で評価させた結果，心拍数が増加する\n条件で他の条件より有意に高い評価が得られた．また，スライド提示中の実際の心拍数は\n23\nすべての条件で低下していた．このことから，Valins の見解を支持し，環境刺激に対する\n認知的・感情的評価は，実際の心拍数の変化に関係なく，フィードバック条件により修正\nされる可能性が示唆された．\nGray らは，偽の心拍フィードバックが感情評価に与える神経活動の影響を調査した[76]．\n実験では，3分間の運動条件（強弱のグリップ）中に感情的な顔画像（happy，angry，neutral）\nを提示し，感情強度を4 段階で評価させた．同時に，実心拍と同期・非同期および偽の\n心拍音フィードバックを提示し，運動中は遅い心拍数，非運動時は速い心拍数のフィード\nバックを行った．結果，偽の心拍音は中立的な表情の評価を強調し，運動の有無は影響し\nないことが確認された．また，この行動変化に対応する脳活動は，右前部島皮質および扁\n桃体に見られた．これにより，右前部島皮質が身体的変化の認知やその解釈に重要な役割\nを果たすことが示唆された．\nNishimura らは，ユーザの好意的感情を制御するため，クッションに組み込まれた擬似\n心拍提示装置を開発した[77]．この装置は，実際の心拍数を基に擬似心拍音を振動として\n生成する．心拍数の増加・一定・提示なしの3 条件でグラビア画像と組み合わせた結果，\n擬似心拍振動を提示した増加および一定の条件では，提示なしに比べて，好みとする写真\nの選択確率が高いことが確認された．これにより，周波数の調整が不要で，ランダムな心\n拍音の提示でも効果がある可能性が示唆された．\nUeoka らは，ホラー映像の没入感を高めるため，擬似的な心拍フィードバックを利用し\nたロッカー型の3D 映画鑑賞環境を構築した[78]．図2.11 はロッカー型の3D 映画鑑賞環\n境を示している．床面振動を用いて，リアルタイムで心拍数を参照し心拍振動を増加させ\nる手法および，設定した心拍数まで段階的に振動を増加させる手法を比較した．ホラー映\n画鑑賞の結果，リアルタイムに心拍振動を増加させる手法では，擬似心拍の上昇に伴い実\n際の心拍数も同期して上昇することが確認された．これにより，振動フィードバックが恐\n怖体験を強め，ユーザの心拍数と同期した疑似心拍数の生成は心拍数の変化に効果的であ\nることが示唆された．\n図2.11: ロッカー型の3D 映画鑑賞環境（[78] より引用）\n24\nPescara らは，スマートウォッチの触覚振動アクチュエータを利用し，ゲーム内のヒット\nポイント（HP）を擬似的な心拍振動で表現するシステム「LifeTact」を開発した[79]．HP\nが100%では45bpm，1%では166bpm とし，HP が0%時には振動が徐々に停止するよう\nに設定した．システムの評価では，画面上の視覚情報，視覚と触覚振動の併用，触覚振動\nのみの3 条件でゲーム体験を比較し，質的アンケートを実施した．結果，触覚振動で残り\nHP を推定でき，システム全体の満足度が高いことが確認された．\nOgawa らは，ゲーム中に提示される偽心拍音を自身のゲーム体験と関連付けて認識す\nることで，ゲームへの没入感やモチベーションにどのような影響を与えるかを調査した\n[80]．被験者は果物を拾うアクション性のあるゲームを3 分間プレイ中，実際の心拍に同\n期した音や，心拍が徐々に加速・減速する偽心拍音をヘッドホンで提示され，その後ゲー\nム体験に関するアンケートに回答した．結果，+5 bpm/min で心拍音が加速するパターン\nは，モチベーションを維持し，ゲームに対する没入感を向上させる効果が確認された．た\nだし，この効果は心拍音が実際の心拍と関連付けられる場合に限られ，関連がないと知ら\nれると効果が得られないことが明らかになった．\nOmata らは，スマートフォンの周囲に取り付けた視覚的および触覚的な擬似拍動提示装\n置を用いて，スマートフォン上での動画鑑賞体験を増幅させるデバイスを開発した[81]．\nデバイスは，スマートフォンの周囲に配置したプッシュ型ソレノイドを用いて擬似的な拍\n動を表現し，動画コンテンツに対する擬似心拍の提示タイミングは，事前にシーンに合わ\nせて設定された．デバイスを用いてホラー，ジェットコースター，風景のビデオを鑑賞し\nた結果，擬似拍動提示が主観的な感情評価に有意な効果をもたらすことはなかったが，鑑\n賞中に記録された心拍数は有意に上昇していることが確認された．\nWang らは，速い心拍を模した振動や音が実際の心拍数や不安感に与える影響を調査し\nた[82]．評価実験は2 種類行われた．1 つ目の実験では，手首に振動器具を装着し，算数タ\nスク中に120bpm の振動刺激の有無で心拍数と不安感を比較した結果，振動刺激の提示で\n心拍数と不安感が増加することが確認された．2 つ目の実験では，Apple Watch とAirPods\nを使用し，安静時の心拍数を30%増加させた振動，音，振動と音の併用，刺激なしの4 条\n件で，安静中と算数タスク中に実施した．結果として，提示するモダリティが増えるごと\nに心拍数と不安感が段階的に増加し，特にタスク中の振動と音の併用条件で不安感が有意\nに高くなることが確認された．\nChoi らは，ユーザーの心拍数に基づいて触覚刺激を提供する手首装着型のモバイル心拍\n数調整デバイス「ambienBeat」を開発した[83]．デバイスの触覚刺激の強さとリズムは，\n認知閾値を下回るように調整され，他の作業への干渉を最小限に抑えつつ心拍数を制御\nする．心拍数の任意な調節能力と作業への干渉性について，デバイスによる触覚刺激のほ\nか，聴覚，視覚のフィードバックを用いて比較した．その結果，デバイスによる触覚刺激\nが最も効率よく心拍数を増減させる能力を有し，刺激によるタスクに対する散漫度合いが\n最も少ないことが確認された．これにより，触覚フィードバックが心拍数調節において低\n干渉かつ有効であることを示唆している．\n25\n第3章\n脈拍変動を用いたアクション動画鑑賞時の\n昂り状態の分類\n本章では，本研究におけるアクション動画鑑賞時の昂り状態の分類について述べる．\n3.1\nアクション動画鑑賞時の脈拍間隔の収集\n3.1.1\n脈拍間隔の収集目的\n第2 章で述べたように，心拍変動と自律神経，さらに自律神経と情動の間には密接な関\n連性があるとされている．具体的には，情動が自律神経系の活動に影響を与え，自律神経\n系が心拍や発汗といった身体的変化を制御するというメカニズムが考えられる．この関係\nに基づき，動画鑑賞中に記録された脈拍間隔を対象とした生体信号を分析し，その特徴量\nを用いることで，動画鑑賞中の情動を推定し評価することが可能であると考えられる．\n本収集実験では，スマートフォンを使用したアクション動画鑑賞中の情動的な昂り状態\n（「昂り」あるいは「昂りでない」）と脈拍間隔を取得することを目的としている．その後，\n取得した脈拍間隔を基に，二値の昂り状態を区別するための特徴量を算出し，これらの特\n徴量に対応する二値の昂り状態をラベル付けしたデータセットを作成する．そして，機械\n学習アルゴリズムを適用してモデルを訓練し，このモデルにより動画鑑賞中の昂り状態を\n分類することを目指す．この方法により，スマートフォンを使用した動画鑑賞中の情動的\n昂り状態を推定するための基盤を構築できることが期待される．\n3.1.2\n収集実験の概要\n本収集実験は，機械学習モデルによるアクション動画鑑賞時の昂り状態（「昂り」ある\nいは「昂りでない」）を分類するために必要なデータとして，スマートフォンを使用した\nアクション動画鑑賞中の情動的な昂り状態と脈拍間隔を取得することを目標として実施し\nた．被験者は成人男女9 名（21 歳～24 歳）で構成された．脈拍信号として脈拍間隔を測\n定するため，被験者にはスマートウォッチを手首に装着してもらい，冒頭から約30 分程\n度の初めて観るアクション動画をスマートフォンで鑑賞した．実験環境として，アクショ\nン動画の鑑賞中に記録される脈拍間隔が動画以外の要因に影響されないよう，室内照明を\n消灯した暗室を使用し，暗室内では被験者は一人のみで動画鑑賞を実施した．図3.1 は，\n本収集実験の全体図を示している．\n本収集実験では，脈拍間隔の測定にPolar 社製スマートウォッチ「M600」[84] を使用し\nた．図3.2 は，Polar 社製M600 の外観を示している．このスマートウォッチは，スポーツ\n向け機能とスマートウォッチの利便性を兼ね備えたデバイスであり，加速度センサ，環境\n光センサ，ジャイロスコープ，バイブレーションモータ，マイクが搭載されているさらに，\n26\n図3.1: 収集実験時の全体図\nPolar 社独自の6 個のLED を使用した光学式脈拍センサを備えており，高精度な脈拍測定\nが可能である．また，アクション動画鑑賞時の脈拍間隔および情動的な昂り状態を記録す\nるために，スマートウォッチ上で専用のアプリケーションを実装した．\n図3.3 は，実装したアプリケーションの起動時の画面を示している．画面上部には，実\n行中に記録される脈拍間隔が表示される．画面下部にはアプリケーションの実行開始ボタ\nンが配置されており，このボタンを押すことで光学式脈拍センサを用いて脈拍間隔の取得\nおよび記録が開始される．本収集実験では，アクション動画を再生する前に実行開始ボタ\nンを押す手順をとっている．そして，画面中央の橙色の領域はボタンとして機能し，被験\n者がアクション動画鑑賞中に自身の昂り状態を主観的に感じた際に押すことで，その時点\nの情動的な昂りを記録することができる．本研究で焦点を当てる「昂り」は，Russell ら\nの感情の二極性を包括した円環モデル[28]（図2.2）に基づき，縦軸で表される感情の強\n度を示す活性度が高い状態と定義する．\n「昂り」状態は活性度が高い状態を指し，興奮，緊\n張などの心理的覚醒状態を含む．この状態では，脈拍数の上昇，発汗，皮膚表面の毛の逆\n立ち（鳥肌）などの身体的変化が生じる．一方，\n「昂りでない」状態は活性度が低い状態\nを指し，リラックスや落ち着いた感情が含まれる．\nまた，実験で使用するアクション動画の題材に「ターミネーター2」[85] を採用した．こ\nの題材を選定した理由は，国内外でアクション動画として評価が高く，冒頭約30 分程度\nの間に逃走，銃撃戦，爆発などアクション性の高い映像が含まれており，被験者が鑑賞時\nに昂りを誘発されることが期待できるためである．アクション動画を再生するためのス\nマートフォンには，画面サイズが約6.1 インチの「iPhone13 Pro」[86] を使用した．\n3.1.3\nアクション動画鑑賞に関する質問票\n本収集実験では，疲労感に関する質問票と興奮度合いに関する質問票の2 種類を取り入\nれている．まず，疲労感に関する質問票は，アクション動画鑑賞の前後で被験者の疲労感\n27\n図3.2: Polar 社製M600（[84] より引用）\n図3.3: アプリケーションの起動時の画面\nに変化があるかを確認することを目的としている．特に，全被験者において疲労感が増幅\nする傾向が見られた場合，取得した脈拍間隔に対して疲労感の影響を考慮する必要があ\nる．表3.1 は，本収集実験に取り入れた疲労感に関する質問票の質問項目一覧を示してい\nる．この質問票は，慢性的な倦怠感を評価するために開発された10 項目の自己記入式質\n問票であるFatigue Assessment Scale（FAS）[87] を参考に設計したもので，短期的な身体\n的および精神的疲労の両方を評価する構成となっている．各項目は「まったく当てはまら\nない」から「とても当てはまる」までの5 段階のリッカート尺度で回答し，総得点は10\n点から50 点の範囲で評価される．得点が高いほど強い疲労を示しており，この総得点結\n果に基づいて被験者の疲労度を測定する．\nそして，興奮度合いに関する質問票は，鑑賞したアクション動画が被験者に対して十分\nな興奮を与える動画として有用であったかを確認すること，およびアクション映画鑑賞で\n得られた脈拍間隔に情動的な興奮要素が反映されている可能性を確認することを目的と\nしている．表3.2 は，本収集実験に取り入れた興奮度合いに関する質問票の質問項目一覧\nを示している．この質問票は，興奮や満足感に焦点を当てた10 項目の自己記入式質問票\n28\nで構成されている．各項目は「まったくそう思わない」から「非常にそう思う」までの7\n段階のリッカート尺度で回答し，総得点は10 点から70 点の範囲で評価される．得点が高\nいほど，鑑賞したアクション動画から強い興奮が得られたことを示しており，この総得点\nに基づいて被験者の興奮度合いを測定する．\n表3.1: 疲労感に関する質問票の質問項目一覧\n番号\n質問内容\n1\n倦怠感がある\n2\nとても疲れやすくなっている\n3\n日中活動できない\n4\n日中生活を送るために十分元気である\n5\n体力的に疲れ切っている\n6\n物事を始めるのが困難\n7\n明確に物事を考えるのが困難\n8\n何もやる気が起こらない\n9\n精神的に疲れ切っている\n10\n物事を行う時，とても集中できる\n表3.2: 興奮度合いに関する質問票の質問項目一覧\n番号\n質問内容\n1\n映画のアクションシーンは期待に応えましたか？\n2\n映画を観ている間，心拍数が上がったと感じましたか？\n3\n映画のストーリー展開に引き込まれましたか？\n4\n映画の映像効果は迫力がありましたか？\n5\n映画の音楽や効果音が興奮を助長しましたか？\n6\n映画のキャラクターに感情移入しましたか？\n7\n映画のテンポやリズムが良かったですか？\n8\n映画のアクションシーンが特に興奮させるものでしたか？\n9\n映画のストーリーやアクションシーンが緊張感を持続させましたか？\n10\n全体的に映画の冒頭30 分に満足しましたか？\n3.1.4\n収集実験の手順\nまず，実験開始前に被験者が提示されるアクション動画が初見であるかを確認し，確認\n後，被験者を実験室に案内して指定された座席に着席させる．着席後，現時点での疲労\n感を主観的に評価するため，質問票に回答してもらう．次に，被験者の手首にスマート\nウォッチを装着し，専用アプリケーションを起動する．アプリケーションの起動後，被験\n者には操作方法を説明するとともに，主観的な昂りの記録方法を説明する．ここで，心拍\n数の上昇や鳥肌といった身体的変化，または「ドキドキ」「ハラハラ」といった心理的興\n奮を感じた際に記録するよう案内する．その後，実験室の照明を消灯し暗室状態を作り出\nす．暗室内では，被験者に数分間安静を保つよう指示する．準備が整い次第，アクション\n29\n動画の再生を開始し，被験者は一人で動画を鑑賞する．鑑賞中，被験者はスマートウォッ\nチのボタンを操作し，動画を通じて感じた主観的な昂りをリアルタイムで記録する．動画\n鑑賞が終了した後，被験者には再度質問票に回答してもらい，現時点での疲労感を評価す\nる．また，アクション動画鑑賞による興奮度合いについても主観的に評価してもらう．図\n3.4 は収集実験時の被験者の様子である．\n図3.4: 収集実験時の様子\n3.2\n疲労感および興奮度合いに関する質問票の結果\n3.2.1\n疲労感に関する質問票への回答結果\n図3.5 は，アクション動画鑑賞前後に実施した疲労感に関する質問票への全被験者の回答\n結果を示している．各被験者の鑑賞前後の疲労感が得点形式で示され，この変化量を基に\n疲労感への影響を確認した．結果として，被験者全体で鑑賞後の疲労感が増加する傾向は\n観察されなかった．また，変化に関しては統計的に有意な差がない（p 値= 0.514 > 0.05）\nという結果が得られた．この結果から，アクション動画鑑賞が被験者の疲労感に大きな影\n響を与えるとは判断できない．したがって，アクション動画鑑賞が被験者の疲労感を増幅\nさせた可能性は少ないと評価できる．\n30\n図3.5: 鑑賞前後に実施した疲労感に関する質問票の回答結果\n3.2.2\n興奮度合いに関する質問票への回答結果\n図3.6 は，アクション動画鑑賞後に実施した興奮度合いに関する質問票への全被験者の\n回答結果を示している．各被験者の鑑賞後の興奮度合いが得点形式で示され，総得点を基\nに興奮度合いへの影響を確認した．結果として，全被験者のアクション動画に対する評価\nの平均点は52.6 点，標準偏差は6.7 点であることが確認された．この平均点は，各質問項\n目に対して「ややそう思う」と肯定的な評価がされている可能性を示している．また，標\n準偏差が6.7 点であることから，得点分布に大きなばらつきは見られないことが考えられ\nる．一方で，一名の被験者（図3.6 中では”Subject 2”）の総得点が他の被験者と比較して\n低いことが確認された．この被験者からは，\n「ターミネーター同士のバトルはそこそこっ\nて感じでした」という意見が得られており，この意見が低得点と関連している可能性があ\nる．しかし，全体としては，平均点が肯定的な評価の水準にあり，鑑賞後に一定の興奮が\n誘発されている傾向が考えられる．これらの結果に基づき，アクション動画鑑賞が被験者\nに一定の興奮を誘発させた可能性があると評価できる．また，アクション動画鑑賞時に記\n録された脈拍間隔において，興奮状態の影響が反映されていると考えられる．\n3.3\n脈拍間隔に対する特徴量の算出\n3.3.1\n記録した脈拍間隔および情動的な昂り\n本収集実験では，各被験者のアクション動画鑑賞中の脈拍間隔および主観評価による情\n動的な昂りのタイムスタンプを収集した．図3.7 は，被験者A のアクション動画鑑賞中に\n記録された脈拍間隔に，情動的な昂り状態のタイムスタンプを重ね合わせたものを示して\nいる．青色のプロットは時系列における脈拍間隔を示し，赤い破線は被験者が情動的な昂\nりを記録したタイムスタンプを表している．この時点では，時系列における脈拍間隔の変\n動と情動的な昂りを記録したタイムスタンプの前後において変化を確認することはできな\nい．また，図3.8 は，被験者B のアクション動画鑑賞中に記録された脈拍間隔に，情動的\n31\n図3.6: 鑑賞後に実施した興奮度合いに関する質問票の回答結果\nな昂り状態のタイムスタンプを重ね合わせたものを示している．プロットを見る限り，両\n被験者における時系列の脈拍間隔の変動には明確な類似性は確認できない．しかし，情動\n的な昂りを記録したタイムスタンプの傾向として，鑑賞した動画の冒頭部分および終盤に\n記録が集中する傾向が見られる．実際に該当する部分は格闘，銃撃，爆発などのアクショ\nン性の高い映像が描写されている．\n図3.7: 被験者A のアクション動画鑑賞中の脈拍間隔\n本収集実験で得られた各被験者のアクション動画鑑賞中の脈拍信号を基に，脈拍間隔か\nら特徴量を算出する．その後，情動的な昂りのタイムスタンプを用いて特徴量にラベル付\nけを行い，作成したデータセットを機械学習に適用することで，昂り状態を特徴量から分\n類できるようにする．\n32\n図3.8: 被験者B のアクション動画鑑賞中の脈拍間隔\n3.3.2\n脈拍変動の解析手法\n動画鑑賞中の昂り状態を脈拍間隔から分類するためには，収集した時系列の脈拍間隔に\n見られる脈拍変動に基づき，二値の昂り状態を区別するための特徴量を算出する必要が\nある．この特徴量を算出する際には，脈拍変動の解析手法として主に「時間領域解析」と\n「周波数領域解析」の2 つが用いられる．それぞれの手法は異なる観点から脈拍変動を評\n価するものであり，自律神経系の活動を多面的に解析することが可能である．\nまず，時間領域解析（Time Domain Analysis）とは，時間に関連する指標を計算して心\n拍数や心拍間隔の変動を解析する手法である．この手法は複雑な計算を必要とせず，心拍\nリズムの変化を簡易に測定できる基本的なアプローチとして，心臓の自律神経活動を評価\nする際に広く活用されている．表3.3 は，時間領域解析によって算出される主な指標を示\nしている．一方，周波数領域解析（Frequency Domain Analysis）は，時間領域解析とは異\nなり，心拍間隔の変動を周波数成分に分解し，それぞれの成分の振幅をスペクトル密度と\nして表現する手法である．スペクトル密度は，パワースペクトルやパワースペクトル密度\n（PSD: Power Spectral Density）とも呼ばれる．この解析により，自律神経系（交感神経お\nよび副交感神経）の活動を特定の周波数帯域に対応付けて評価することが可能となる．一\n般的な周波数領域解析手法としては，高速フーリエ変換や最大エントロピー法が用いられ\nている[29]．表3.4 は，周波数領域解析によって算出される主な指標を示している．\n表3.3: 時間領域解析で算出される主な指標（[88] より引用）\n指標\n単位\n定義\nMean\nms\n心拍間隔全体の平均値\nSDNN\nms\n心拍間隔全体の標準偏差\nRMSSD\nms\n隣接する心拍間隔の差の二乗和の平均の平方根\nSDSD\nms\n隣接する心拍間隔の差の標準偏差\nNN50\n隣接する心拍間隔の差分が50ms 以上の回数\npNN50\n%\n心拍間隔全体に対する隣接する心拍間隔の差分が50ms 以上の割合\n33\n表3.4: 周波数領域解析で算出される主な指標（[88] より引用）\n指標\n単位\n定義\nLF\nms2\n0.04～0.15Hz のパワー\nLF norm\nnu\n0.04Hz 以上のパワーに対するLF の割合\nHF\nms2\n0.15～0.40Hz のパワー\nHF norm\nnu\n0.04Hz 以上のパワーに対するHF の割合\nLF/HF\nHF に対するLF の割合\nTotalPower\nms2\n0.40Hz までの総パワー\n3.3.3\n時系列の脈拍間隔に対する前処理\n収集実験で記録された時系列の脈拍間隔から特徴量を算出するにあたり，生の脈拍間隔\nデータには脈拍センサのノイズや外部要因（体動や接触不良）による異常値が含まれてい\nる可能性がある．このような異常値が特徴量の算出に使用されると，ノイズの影響によっ\nて算出結果が歪む可能性がある．そのため，具体的な特徴量の算出に先立ち，記録された\n生の脈拍間隔データに対して異常値を除去する前処理を行う．\n本論文では，異常値を除去する前処理を「異常値検出」と「異常値の補完」の2 つの段\n階で行う．異常値検出では，ノイズの影響によって正確に記録されていない可能性がある\n脈拍間隔値を特定する．次に，異常値の補完では，検出された異常値を新たに補完した脈\n拍間隔で置き換える処理を行う．異常値をそのまま削除する削除法ではなく，補完法を採\n用した理由として，脈拍変動に基づく特徴量の算出，特に周波数領域解析において削除法\nが推奨されていないことが示唆されているためである[89]．さらに，補完法は生データに\n含まれるサンプル数を保持できる点で優れているため，本研究では補完法を選択した．\nまず，生の脈拍間隔データに対する異常値検出には，連続する脈拍間隔の差が200ms 以\n上であるものを閾値として設定し，この閾値を超えた脈拍間隔を異常値として検出する方\n法を採用した．連続する脈拍間隔の差が200ms 以上である場合，脈拍センサの誤検出で\nある可能性が高いことに加え，心臓に何らかの疾患があることを示唆する可能性があるた\nめである．本論文では，収集実験で記録された脈拍間隔データが連続的な正常洞調律で記\n録されていることを仮定している．そのため，連続する脈拍間隔の差が200ms 以上であ\nる場合を異常値として検出する基準とした．\nそして，検出された異常値に対する補完方法では，0 次補完，線形補完，スプライン補\n完，非線形予測補完など様々なアルゴリズムが存在する[89]．本論文では，0 次補完に相\n当する直近の3 点の脈拍間隔から計算された平均値で補完する方法と，異常値が連続する\n場合には線形補完を用いて，直近の2 点を結ぶ直線から指定する時間に対応する値で補完\nする方法を採用した．2 種類の補完方法を採用した理由は，連続する異常な脈拍間隔に対\nして0 次補完を利用すると，同じ平均値を使用することで脈拍間隔の時系列に平坦な形状\nが生じることが確認されたためである．一方，線形補完では傾斜状の形を作り出すことが\n確認されている．これらの特徴を考慮し，実際の脈拍間隔のトレンドを反映しつつ異常値\nを補完するために，2 種類の補完方法を場合分けして使用するアプローチが相互に補完の\n問題を解決できると考えられる．\n図3.9 は，異常値検出および補完を行う前の生の脈拍間隔データを示している．一方，\n34\n図3.10 は，異常値検出および補完を行った後の脈拍間隔データを重ね合わせて示してい\nる．異常値検出および補完を行う前の生の脈拍間隔データでは，周期的な変動が見られる\nものの，特に図中央付近で急激な値の変化が確認される．この変化は脈拍間隔の変動トレ\nンドから大きく逸脱しており，脈拍センサのノイズや誤検出によるものであると考えられ\nる．このようなノイズを処理しない場合，算出される特徴量が不正確になる可能性が高\nい．これに対して異常値の検出および補完を行った結果，急激な値の変化が解消され，正\n常な脈拍間隔データが得られることが確認された．これにより，脈拍変動の正確な解析に\n必要なデータ品質が確保される．\n図3.9: 異常値検出および補完する前の生の時系列脈拍間隔\n図3.10: 異常値検出および補完前後の脈拍間隔データで重ね合わせ\n3.3.4\n特徴量の算出\n脈拍センサのノイズや外部要因（体動や接触不良）による異常値を処理した時系列の脈\n拍間隔データに対して，時間領域解析および周波数領域解析を行い，それぞれの解析に\nよって得られる特徴量を算出する．本論文では，解析を行う際の時系列の脈拍間隔に対す\nる窓サイズを240 秒，シフトサイズを5 秒と設定した．この設定を採用した理由は，後の\n35\n機械学習モデルの分類性能評価において，この窓サイズおよびシフトサイズを用いること\nで他の設定よりも良好な分類性能が得られたためである．\n周波数領域解析を行うには，等間隔の脈拍間隔データが必要となる．これは，通常の脈\n拍間隔データが心臓の拍動ごとにサンプル点を記録する形式であるため，時間軸上で等間\n隔になっておらず，周波数領域解析に適さないためである．そのため，本論文では，1 秒\n間隔の脈拍間隔データに変換するため，リサンプリングを実施した．リサンプリングには\n線形補完を用い，1 秒間隔のサンプル点を補完してデータを整えた．この処理により，周\n波数領域解析に適した等間隔のデータが得られるようにした．\nまた，周波数領域解析手法には，高速フーリエ変換（FFT: Fast Fourier Transform）を使\n用した．高速フーリエ変換とは，波形を正弦波の組み合わせとして仮定し，時系列データ\nから周波数成分を効率的に求めるアルゴリズムである．通常，有限長のデータを無限長の\n周期信号として扱い，窓関数を適用することで信号端の不連続性による影響を軽減する\n[90]．周波数領域解析に高速フーリエ変換を利用した理由は，計算処理が高速であるとい\nう利点を持つためである．高速フーリエ変換には，データが短い場合にスペクトルの精度\nが低下する欠点があるものの，リアルタイムで周波数解析を行うような実装において，計\n算負荷を抑える必要があることを考慮し，本手法を利用した．\nそして，異常値を処理した時系列の脈拍間隔データに対して時間領域解析を，1 秒間隔\nにリサンプリングした脈拍間隔データに対して周波数領域解析を行い，二値の昂り状態\nを分類するための特徴量を算出した．表3.5 は，本論文で時間領域解析および周波数領域\n解析に基づいて算出した特徴量を示している．時間領域解析では，窓サイズ内の脈拍間隔\nデータにおける最大値，最小値，平均値などの標準的な指標を特徴量として算出した．一\n方，周波数領域解析では，高速フーリエ変換を用いて脈拍間隔の波形に含まれる周波数成\n分を求めた．その際，0.04～0.15Hz の低周波数帯（LF: Low Frequency）と0.15～0.40Hz\nの高周波数帯（HF: High Frequency）のパワースペクトルを算出し，それらの割合や総パ\nワーを示す指標を含めて特徴量として加えた．\n表3.5: 本論文で算出した特徴量\n領域解析\n指標\n定義\n時間領域解析\nMax\n心拍間隔全体の最大値\nMin\n心拍間隔全体の最小値\nMean\n心拍間隔全体の平均値\nSDNN\n心拍間隔全体の標準偏差\nRMSSD\n隣接する心拍間隔の差の二乗和の平均の平方根\npNN20\n心拍間隔全体に対する隣接する心拍間隔の差分が20ms 以上の割合\npNN50\n心拍間隔全体に対する隣接する心拍間隔の差分が50ms 以上の割合\n周波数領域解析\nLF\n0.04～0.15Hz のパワー\nHF\n0.15～0.40Hz のパワー\nLF/HF\nLF とHF の比率\nTotalPower\n0.40Hz までの総パワー\n特徴量の算出では，時系列の脈拍間隔データに対して解析を行う際の窓サイズを240 秒，\nシフトサイズを5 秒と設定し，時間領域および周波数領域解析によって合計11 個の特徴\n36\n量を算出した．時系列の脈拍間隔データを240 秒の窓サイズで5 秒ずつシフトすること\nで，各被験者ごとに特徴量を算出した時点の経過時間と，それに対応する11 個の特徴量\nが組み合わさった時系列の特徴量データが作成される．この特徴量データに二値の昂り状\n態のラベル付けを行うことで，特徴量と情動状態の関連を学習する機械学習モデルの構築\nが可能となる．\n3.4\nラベル付けとデータセットの作成\n3.4.1\nラベル付けの目的\n本研究では，アクション動画鑑賞時の二値の昂り状態を機械学習を用いて分類する．機\n械学習には「教師あり学習」と「教師なし学習」の2 種類が存在するが，本研究では教師\nあり学習を利用する．教師あり学習とは，事前に用意した各入力データに対応する正解ラ\nベルが付与された訓練データを用いてモデルを訓練し，新たなデータに対して分類（カテ\nゴリ分け）や回帰（連続値の予測）を行う手法である．したがって，教師あり学習では，\n正解ラベルが付与された訓練データの準備が不可欠であり，昂り状態を分類するモデルを\n生成する上で重要な役割を果たす．ラベル付けでは，二値の昂り状態を分類する教師あり\n学習のための訓練データを作成することを目的とする．\n3.4.2\nラベル付けの基準\n本研究における二値の昂り状態のラベル付けには，収集実験中に被験者が鑑賞時に記録\nした主観評価による情動的な昂りのタイムスタンプを活用する．このタイムスタンプは被\n験者自身によって記録されたものであり，タイムスタンプが記録された時点およびその前\n後の脈拍間隔には，アクション動画によって引き起こされた情動的な昂りが反映されてい\nると考えられる．したがって，特徴量に対するラベル付けは，設定したタイムスタンプの\n前後の区間に該当する特徴量を「昂り」とし，それ以外の特徴量をすべて「昂りでない」\nとする．\n複数の研究では，動画鑑賞中に引き起こされた情動の時点を中心に，その前後を対応す\nる情動のラベル付け区間として設定しており，前後数十秒から数分とされている[48][47]．\n本研究では，\n「昂り」とラベル付けするタイムスタンプの前後の区間を「前10 秒」，\n「後30\n秒」と設定した．前10 秒と設定した理由は，アクション動画鑑賞中に被験者が昂りを引\nき起こされ，それを知覚するまでの過程を考慮したためである．また，後30 秒と設定し\nた理由は，情動的な昂りの影響がアクション動画からの刺激と共に一定の持続時間を伴\nうことを考慮したためである．さらに，感情誘導後に脈拍変動における副交感神経指標\n（ANI: Analgesia Nociception Index）が2 分以内に回復することを示した研究[91] や，皮\n膚電気活動における皮膚伝導反応が刺激提示後に即座に反応し，十数秒以内に収束する事\n象を確認した研究[92] を踏まえ，生体信号は情動喚起時に即座に反応し，短時間で回復\nすることを考慮したためである．\n図3.11 は，本研究で行う二値の昂り状態のラベル付け方法を示している．プロット図中\nの赤破線は，被験者が鑑賞時に記録した主観評価による情動的な昂りのタイムスタンプを\n示しており，その前後の薄い赤色の領域は前10 秒，後30 秒の区間を表している．また，\n37\n複数の紺色枠は，窓サイズ240 秒，シフトサイズ5 秒で設定したスライディングウィンド\nウ手法による特徴量の算出範囲を可視化している．時系列の脈拍間隔データから算出され\nた特徴量データは，特徴量を算出した時点の経過時間（例: 0～240 秒の脈拍間隔データか\nら算出した場合，経過時間は”240 秒”として記録）と，それに対応する11 個の特徴量が\n組み合わさった時系列のデータである．その中で，経過時間が主観評価による情動的な昂\nり状態のタイムスタンプの前後区間内の時間に該当する場合，その特徴量に対するラベル\nを「昂り」とした．反対に該当しない特徴量にはすべて「昂りでない」とした．\n図3.11: 算出した特徴量に対するラベル付け方法\n3.4.3\nデータセットの作成\n算出した時系列の特徴量データに対するラベル付け方法を設定し，それに基づいて全て\nの被験者から算出した特徴量データにラベル付けを行った．表3.6 は，ラベル付けされた\n全ての特徴量をまとめて作成したデータセット内のラベルの分布を示している．機械学習\n用に作成したデータセットでは，時間領域および周波数領域から算出した11 個の特徴量\nを1 組として，合計3175 組のラベル付けされた特徴量データが記録されている．その内\n訳は，約76%（2420 組）が「昂りでない」とラベル付けされ，約24%（755 組）が「昂\nり」とラベル付けされている．\n表3.6: 作成したデータセット内のラベルの分布\n昂り\n昂りでない\n合計\nラベル数\n755\n2420\n3175\n比率\n23.8%\n76.2%\n100%\n比率を見ると，\n「昂りでない」とラベル付けされた特徴量データが7 割以上を占めており，\nこのデータセットをそのまま機械学習に使用すると，クラス不均衡の問題が発生する可能\n性がある．クラス不均衡の問題とは，訓練された機械学習モデルが「昂りでない」（多数\n38\n派クラス）を過剰に予測し，\n「昂り」（少数派クラス）を正しく分類できなくなる可能性を\n示唆するものである．この問題を解決する方法の一つとして，少数派クラスである「昂\nり」のデータを増やすオーバーサンプリング手法が挙げられる．しかし，本研究では，作\n成したデータセットをそのまま使用し，モデルの分類性能を精度（accuracy）だけでなく，\n少数派クラスである「昂り」を正しく分類できているかを示す再現率（recall）などを用\nいて評価する．\n3.5\n機械学習アルゴリズムの選定と機械学習モデルの作成\n3.5.1\n機械学習アルゴリズムの選定\n本研究では，アクション動画鑑賞時の二値の昂り状態でラベル付けされた特徴量データ\nを用いて，教師あり学習による機械学習を実施し，二値の分類タスクを行う分類モデルを\n作成する．分類モデルの作成にあたり，任意の機械学習アルゴリズムを選択し，どのアル\nゴリズムが二値の昂り状態をより高い精度で分類できるかを調査する必要がある．本研\n究では，複数の機械学習アルゴリズムを用い，学習させた機械学習モデルの分類精度を比\n較した．比較検証には，人工知能や機械学習の分野で広く活用されているプログラミング\n言語「Python」[93] を使用し，Python で利用可能なオープンソースの機械学習ライブラリ\n「scikit-learn」[94] を活用した．\n分類精度の比較対象とした機械学習アルゴリズムは，ロジスティック回帰（Logistic Re-\ngression），サポートベクターマシン（SVM），決定木（Decision Tree），ランダムフォレ\nスト（Random Forest），k 近傍法（k-Nearest Neighbors），ナイーブベイズ（Naive Bayes），\n勾配ブースティング（Gradient Boosting）の合計7 種類である．各アルゴリズムを用いて\n学習させた機械学習モデルの分類精度を評価するために，層化シャッフルk 分割交差検証\nを利用した．層化シャッフルk 分割交差検証とは，シャッフルしてランダム化したデータ\nセットをk 個の等しいサイズの部分集合（フォールド）に分割する際，各フォールド内の\n目的変数（ラベル）のクラス分布がデータセット全体のクラス分布と一致するように調整\nする交差検証手法である[95]．この手法の主な利点は，クラス不均衡への対応である．ク\nラスごとのデータ数に偏りがある場合でも，層化によって各フォールド内のクラス分布を\nデータ全体の分布に近似させることができるため，特定のクラスが欠落したり過剰に含\nまれたりするリスクを軽減し，評価の一貫性を保つことができる．一方，通常のk 分割交\n差検証では，データセットを単純にk 個のフォールドに分割するため，各フォールドのク\nラス分布が全体の分布と一致しない可能性がある．特にクラスの不均衡がある場合，ある\nフォールドに特定のクラスのデータがほとんど含まれない，または全く含まれないことが\n起こり得る．この結果，交差検証による分類精度の評価が不正確になる可能性がある．\n表3.7 は，層化シャッフル10 分割交差検証を適用し，機械学習アルゴリズムを用いて学\n習した各モデルによる二値の昂り状態の分類精度を示している．また，図3.12 は，各機\n械学習モデルの分類精度を棒グラフで可視化し，比較を容易にしたものである．結果とし\nて，ランダムフォレストに基づくアルゴリズムによる機械学習モデルが最も高い分類精度\nを示した．ランダムフォレストは，複数の決定木で予測されたクラスの多数決を基に分類\n結果を出力するアルゴリズムであり，過学習の影響が少ないという利点を持つ．以上の結\n39\n果を踏まえ，本研究では，アクション動画鑑賞時の二値の昂り状態を分類する機械学習モ\nデルにランダムフォレストに基づくアルゴリズムを選定する．\n表3.7: 各機械学習モデルの平均分類精度の一覧\nモデル名\n平均精度\n標準偏差\nLogistic Regression\n0.762\n0.0\nSVM\n0.763\n0.001\nDecision Tree\n0.905\n0.015\nRandom Forest\n0.936\n0.013\nK-Nearest Neighbors\n0.910\n0.012\nNaive Bayes\n0.719\n0.017\nGradient Boosting\n0.841\n0.011\n図3.12: 機械学習モデルの分類精度の比較\n3.5.2\n選定した機械学習アルゴリズムによる分類性能\n二値の昂り状態を分類する機械学習モデルとしてランダムフォレストに基づくアルゴリ\nズムを選定したが，前項では層化シャッフルk 分割交差検証による平均の分類精度のみが\n評価されていた．したがって，より詳細な分類性能について評価し，特に「昂り」を正し\nく分類する能力を確認する必要がある．\n表3.8 は，層化シャッフル10 分割交差検証によって得られたランダムフォレストに基づ\nく機械学習モデルの詳細な分類性能を示す分類レポートの平均値を示している．また，図\n3.13 は，同じ交差検証によって得られた分類結果をまとめた混同行列の平均を示してい\nる．分類レポートの平均を見ると，クラス1（「昂り」）を正しく分類する指標である再現\n率（recall）が0.824 であることが確認できる．つまり，\n「昂り」とラベル付けされた特徴\n量に対して，機械学習モデルは82.4%の精度で「昂り」と正しく分類する性能を持つこと\nを示している．また，混同行列の平均では，誤分類された数も確認されるが，正しく分類\nされた数がそれを上回っていることが確認され，モデルの性能の有効性を裏付けている．\n40\n表3.8: 層化シャッフル10 分割交差検証による分類レポートの平均\nClass\nPrecision\nRecall\nF1-Score\nSupport\n0\n0.947\n0.970\n0.958\n484\n1\n0.898\n0.824\n0.859\n151\nAccuracy\n0.936\n0.936\n0.936\n0.936\nMacro Avg\n0.922\n0.897\n0.908\n635\nWeighted Avg\n0.935\n0.936\n0.935\n635\n図3.13: 層化シャッフル10 分割交差検証による混同行列の平均\nランダムフォレストに基づくアルゴリズムによって学習した二値の昂り状態を分類する\n機械学習モデルは，分類精度の平均が他のモデルより高いことに加え，\n「昂り」とラベル\n付けされた特徴量を正しく分類する性能が確認された．したがって，アクション動画鑑賞\n時の二値の昂り状態を特徴量から分類するために，このランダムフォレストに基づく機械\n学習モデルを使用し，最終的に分類モデルを作成する．\n3.5.3\n機械学習モデルの作成\n本研究では，ランダムフォレストに基づくアルゴリズムによって訓練された機械学習モ\nデルをスマートウォッチ上で動作する専用アプリケーションに組み込む必要がある．その\nため，機械学習モデルの作成には，オープンソースの機械学習ソフトウェアであるWEKA\n（Waikato Environment for Knowledge Analysis）[96] を利用する．WEKA はJava 言語で開\n発されたデータマイニングおよび機械学習ソフトウェアであり，分類，回帰，クラスタリ\nング，関連ルールの発見，データの可視化など，多様なデータ分析に対応している．さら\nに，WEKA を利用することで，作成した機械学習モデルをファイル形式（.model）とし\n41\nて保存できる．この形式は，WEKA のライブラリ（weka.jar）を用いることで，Java アプ\nリケーションやAndroid アプリケーションに容易に組み込むことが可能である．\n最後に，昂り状態を示すラベル付けがされた特徴量データを使用し，WEKA 上でラン\nダムフォレストに基づくアルゴリズムによって訓練した二値の昂り状態を分類する機械学\n習モデルを作成した．このモデルをスマートウォッチ上の専用アプリケーションに組み込\nみ，スマートウォッチで取得した脈拍間隔データから算出した特徴量を機械学習モデルに\n入力することで，鑑賞者の昂り状態を分類し，推定できる仕組みが構築される．\n42\n第4章\n昂りに連動した動画鑑賞体験拡張スマート\nフォンアクセサリー\n本章では，昂りに連動した動画鑑賞体験拡張スマートフォンアクセサリーについて述\nべる．\n4.1\nシステムの概要\n4.1.1\nシステムの構成\n本研究では，スマートフォンを用いた動画鑑賞時において，ユーザの脈拍変動を基に\n「昂り」を判定し，その結果に連動して擬似心拍刺激を提示することで，動画鑑賞時の情\n動体験を強化する手法として，昂りに連動した動画鑑賞体験拡張スマートフォンアクセサ\nリーを提案する．図4.1 は，提案システムの全体構成を示す概要図を示している．\n図4.1: 提案システムの概要図\n本システムは，大別して2 つの構成に分かれている．1 つ目は，スマートフォンを用い\nた動画鑑賞中のユーザの昂り状態を判定する部分であり，2 つ目は，その判定結果に基づ\nいて擬似心拍刺激を動画鑑賞中のユーザに提示する部分である．ユーザの昂り状態を判定\nする部分では，脈拍センサ付きのスマートウォッチで取得した脈拍データを活用し，機械\n学習モデルを用いてユーザの昂り状態を判定する．これにより，リアルタイムで動画鑑賞\n43\n中のユーザの情動的な昂り状態を把握することが可能である．昂り状態の判定結果に基づ\nいて擬似心拍刺激を提示する部分では，判定された昂りに連動して，振動および照明によ\nる実際のユーザの脈拍数に基づいた擬似的な心拍刺激を，製作したスマートフォンアクセ\nサリーを通じて提示する．\n4.1.2\nシステムの動作の流れ\n本研究のシステムの動作の流れを図4.2 に示す．本システムを実現するために，脈拍セ\nンサ付きのスマートウォッチ，クラウドデータベース，マイクロコントローラを組み合わ\nせて使用している．各領域のプログラムは，相互に通信を行いながら，リアルタイムでの\nデータ処理とユーザへのフィードバックを実現している．本研究のシステムにおける各領\n域で使用されるデバイスやソフトウェア，およびその処理内容について以下に説明する．\n図4.2: 本研究のシステムの動作の流れ\nまず，脈拍センサ付きのスマートウォッチにはPolar 社製「M600」[84] を使用する．処\n理内容は，主に3 節で述べた「脈拍間隔に対する特徴量の算出」の過程をリアルタイムで\n実行し，\n「機械学習モデルの作成」で作成した二値の昂り状態（「昂り」または「昂りでな\nい」）に分類する機械学習モデルを使用する．具体的には，スマートウォッチ上で行われ\nるリアルタイムの処理は以下のように進行する．動画鑑賞中に取得される脈拍間隔データ\nは，異常値についての処理の後，逐次専用のデータリストに格納される．この取得処理と\n並行して，脈拍間隔データを1 秒間隔にリサンプリングし，別のデータリストに格納され\nる．次に，リサンプリングされたデータリストが設定した240 秒の窓サイズに達すると，\n特徴量の算出処理が開始される．この時点で，周波数領域の特徴量はリサンプリングされ\nたデータリストから算出され，時間領域の特徴量は元の脈拍間隔データリストから240 秒\n分のデータを抽出して算出される．算出された特徴量は，二値の昂り状態を分類する機械\n学習モデルに入力される．機械学習モデルはこれらの特徴量を基に昂り状態を分類し，分\n44\n類結果は直近2 回分の分類結果と比較され，多数決に基づいて最終的な昂り状態が判定さ\nれる．そして，判定した昂り状態を表したデータはクラウドデータベースに送信される．\nその後，設定した5 秒のシフトサイズでデータリストをスライドさせて次の処理を開始\nする．\n次に，クラウドデータベースとしてGoogle 社が提供する「Firebase Realtime Database」\n[97] を使用する．Firebase Realtime Database は，クラウドホスト型のNoSQL データベー\nスであり，データをJSON 形式で保存し，接続されたすべてのクライアント間でリアルタ\nイムに同期する機能を備えている．このデータベースは，スマートウォッチで出力された\n昂り状態についてのデータを保存し，振動や照明によるフィードバックを駆動させるマイ\nクロコントローラに更新されたデータを渡すようにして，データの橋渡し役を担う．\n最後に，マイクロコントローラとして，M5Stack 社が開発した超小型IoT デバイス開発\nモジュール「Atom-Lite」[98] を使用する．図4.3 はAtom-Lite の外観を示している．Atom-\nLite は，24 × 24mm という非常に小型のサイズで設計され，多数のGPIO を備えており，\nホームデバイスや玩具の製作など，組み込み用途への活用に適している．メイン制御に\nは，Wi-Fi 接続機能を統合したESP32-PICO チップを採用し，4MB のフラッシュメモリを\n内蔵している．本研究では，Atom-Lite をスマートフォンアクセサリーに組み込む形で使\n用する．このマイクロコントローラは，振動および照明を用いた擬似心拍刺激を駆動させ\nる役割を担う．処理内容としては，Wi-Fi を介してクラウドデータベースに接続し，デー\nタベースから受信した昂り状態を表すデータを検証する．検証の結果，データが「昂り」\nを表すとされる場合，併せて送信されるユーザの脈拍数を基に，振動および照明が同期し\nた擬似心拍刺激を提示させる．\n図4.3: M5Stack 社製Atom-Lite の外観および比較（[98] より引用）\n4.2\n昂り判定に連動した擬似心拍刺激\n4.2.1\n擬似心拍刺激を提示する目的\n本研究では，アクション動画鑑賞中の脈拍変動から算出した特徴量を基に，機械学習モ\nデルを用いて判定される昂り状態に連動して，ユーザの脈拍数に基づいた「擬似心拍刺\n激」を提示する．昂りとする判定時に擬似心拍刺激を提示する理由は，動画鑑賞中のユー\nザの昂りを効果的に高める必要があるためである．\nまず，情動がどのように生み出されるかについての理論を振り返る．情動に関する理論\nでは，少なからず身体的変化が情動の形成に関与するとされている[69][70][71]．特に，抹\n45\n消起源説では，外部刺激により心拍数の上昇などの身体的変化を認知することで情動が生\nじると説明されている．この理論に基づいた関連研究では，視覚刺激とともに高い擬似心\n拍音を提示することで，対象の魅力が向上することが確認されている[74][75][77]．これ\nにより，擬似心拍刺激が情動を意図的に操作できる可能性が示唆されている．\nこれらを踏まえ，本研究では，情動と生理的反応が互いに結びついていることに着目し，\n擬似心拍刺激が情動体験を促進する可能性があると仮定した．この仮定に基づき，ユーザ\nの実際の脈拍数に基づいて意図的に高い擬似心拍刺激を提示することで，昂りを認識さ\nせ，さらに昂りを高めることが可能であるかを仮説として検証する．\nまた，擬似心拍刺激をフィードバックする手段として，本研究では，動画鑑賞における\n振動と照明によるフィードバックの効果に着目した．振動については，ジャケットやグ\nローブ型デバイスを用いて映像に合わせた振動を提示することで，緊張感や興奮を高め\nる効果が示唆されている[50][52]．照明については，昂りを促す動画に赤色の光を提示す\nることで，生理的な覚醒が上昇し，適切な照明が動画体験を向上させることが示唆されて\nいる[63]．これらの知見から，擬似心拍刺激に振動と照明を用いることで，動画鑑賞中の\n「昂り」をさらに高める効果が期待できる．\n4.2.2\n振動を提示する機器の検討\n本研究では，擬似心拍刺激を提示するために振動を利用する．このため，振動機器を選\n定した．選定基準は，擬似心拍を利用したフィードバックにおいて，単調な音よりも心臓\nの拍動を模倣した音が効果的であることを示唆した研究[80] を参考に，心臓の拍動を模\n倣できる多様な振動を提示可能であることに加え，動画鑑賞中の振動による雑音が発生し\nない静音性を備え，振動が十分に知覚できる強度を持つ振動機器を選定基準とした．\n振動機器の選定にあたり，複数の振動機器を試用した．はじめに試用したのは，M5Stack\n社製の振動ユニット「Unit Vibrator」[99] である．図4.4 は，振動ユニット「Unit Vibrator」\nの外観を示している．この振動ユニットには，直流電圧で動作する小型ギヤードモータで\nあるN20 モータが搭載されており，モータの回転によって露出した偏心錘が回転し，振動\nを提示する仕組みである．Atom-Lite とは専用のケーブルを介して容易に接続でき，PWM\n信号を使用して振動の強弱を調整することが可能である．しかし，偏心錘の回転により全\n体が振動する設計のため，強力な振動を起こすと，振動に伴うモータの動作音が大きいこ\nとが確認され，本研究の振動提示としては不十分であることが確認された．したがって，\n本研究ではこの振動モーターユニットを採用しない．\n図4.4: M5Stack 社製Unit Vibrator（[99] より引用）\n46\n次に試用したのは，コイン型振動モータである．図4.5 は，本研究が試用したコイン型\n振動モータを示している．コイン型振動モータは直径10mm の小型モータであり，適切\nな動作電圧を供給することで円盤部分が振動する仕組みを持つ．このモータは局所的な振\n動提示に適している点が特徴である．振動モータを制御する機器として，使用可能なPIN\n数の関係上，Arduino 社製の「Arduino UNO R4 Minima」[100] を使用した．ただし，この\n構成では振動の開始と停止のみが制御可能で，連続的な振動の強度を操作することはでき\nなかった．そのため，振動の強さを自由に制御するために，SparkFun Electronics 社製の\nモータドライバ「DRV2605L」[101] を使用し，振動モータで擬似心拍振動を表現可能に\nした．図4.6 は，SparkFun Electronics 社製のモータドライバ「DRV2605L」の外観を示し\nている．そして，図4.7 は，これらを活用したコイン型振動モータの全体像を示している．\nしかしながら，コイン型振動モータの小型性ゆえに振動が非常に弱いことが確認され，触\n覚として擬似心拍振動を知覚するには不十分であった．また，Arduino を含む制御機器や\n配線，モータドライバが広範囲のスペースを必要とし，スマートフォンアクセサリーに組\nみ込むには実用性が低いと判断された．以上の理由から，本研究ではコイン型振動モータ\nを採用しないこととした．\n図4.5: コイン型振動モータ\n図4.6: SparkFun 社製DRV2605L\n最後に試用したのは，フォスター電機社製の振動アクチュエータ「ACOUSTICHAPTIC®\n639897」[102] である．この振動アクチュエータは，重さ28g，直径25mm，高さ27mm\nのサイズを持ち，以前に使用した振動機器と比較して重く，大型である．図4.8 は，フォ\nスター電機社製の振動アクチュエータの外観を示している．本研究では，この振動アク\nチュエータを駆動させるために，BitTradeOne 社が提供する触感デバイス開発モジュール\n「hapstak デジタル版」[103] を利用した．\n「hapstak デジタル版」は，振動による触感の再現\nを簡便に扱えるモジュールであり，付属する駆動回路基板を使用することで，M5Stack 社\n製のAtom-Lite などのマイコンからの命令で直接音声データを再生し，振動アクチュエー\nタに振動を発生させることが可能である．さらに，振動アクチュエータにはマイコン側か\nら駆動回路を通じて電源供給が行われるため，マイコン側への電源が確保できれば，複雑\nな配線を必要としない利便性を持つ．図4.9 は，振動アクチュエータと駆動回路基板を接\n続した例を示している．この回路基板に，振動アクチュエータを制御するマイコンとマイ\nコンへの電源を接続することで，振動アクチュエータの駆動が可能となる．\n振動アクチュエータの駆動を体験するために，開発モジュールに付属する木製の組み立\n47\n図4.7: モータドライバを活用したコイン型振動モータの全体像\n図4.8: フォスター電機社製ACOUSTICHAPTIC® 639897（[102] より引用）\nてボードを使用し，簡易的な振動提示デバイスを作成した．図4.10 は，木製の組み立て\nボードの各パーツを示している．また，図4.11 は，組み立てボードを用いて作成した振\n動提示デバイスの外観を示している．振動提示デバイスは，図に対して，左側に配置され\nた振動アクチュエータ，中央のM5Stack 社製の小型開発モジュール「Atom-Matrix」[104]，\n右側のM5Stack 社製マイコンに電源を供給する外部バッテリー「Tail Bat」[105] で構成さ\nれている．このデバイスを使用し，マイコンに格納された複数の音声データを再生させ，\n振動アクチュエータを音声データに基づいて駆動させた．その結果，非常に強い振動を\n感じられたほか，再生した音声データの表現（恐竜の足音，銃の単発発射，心臓の拍動な\nど）を触覚として正確に知覚することが可能であった．また，振動時の騒音は小さく，最\n大でも30 デシベル程度であり，寝室程度の静粛性を備えていることが確認された．した\nがって，本研究では，擬似心拍刺激を提示する振動機器として，フォスター電機社製の振\n動アクチュエータ「ACOUSTICHAPTIC® 639897」を採用する．また，この振動アクチュ\nエータを駆動するために，BitTradeOne 社が提供する「hapstak デジタル版」に付属する駆\n動回路基板を利用する．\n48\n図4.9: ACOUSTICHAPTIC® 639897 と駆動回路基盤との接続例（[103] より引用）\n図4.10: 木製の組み立てボード\n図4.11: 簡易的な振動提示デバイス\n4.2.3\n振動を利用した擬似心拍刺激\n本研究で選定された振動アクチュエータを駆動回路基板を用いて動作させるには，他の\n振動機器とは異なり，あらかじめ特定の振動を作成して動作させる必要がある．具体的に\nは，複数の心拍数を表現する擬似心拍を音声信号データとして作成した後，8 ビット形式\nのバイナリデータに変換してマイコン（Atom-Lite）に格納する．\n「昂り」判定時には，マ\nイコンから指定する心拍数を表現された擬似心拍の音声信号データを実行し，振動機器を\nデータに基づいて繰り返し振動させることで，擬似心拍振動が実現される．\n本研究では，振動によって提示する擬似心拍を表現する音声信号データに，BitTradeOne\n社が提供する「Heartbeat」の音声信号データ[103] を利用した．この音声信号データを選\n定した理由は，振動アクチュエータを通じて体感した際に，心臓の拍動を限りなく模倣し\nていることが確認されたためである．図4.12 は，この音声信号データを基に再生時間を1\n秒に拡張して作成した心拍数60 bpm の拍動を表現する音声信号データを示している．こ\nの音声信号データを実行し，振動機器を繰り返し振動させることで，心拍数60 bpm の擬\n似心拍振動を提示することが可能となる．さらに，再生時間を調整した波形を作成する\nことで，任意の心拍数を表現する擬似心拍振動も提示可能である．例として，再生時間\nを0.86 秒に調整して作成した音声信号データを基に振動機器を駆動させることで，心拍\n数70 bpm の擬似心拍振動を提示することが可能となる．\n振動として提示される擬似心拍を表現する時系列の音声信号データについて，時系列の\n周波数成分の強さを確認するため，スペクトログラムとして可視化を行った．図4.13 は，\n図4.12 で示した再生時間1 秒の一拍の拍動を表現する音声信号データに対するスペクト\nログラム解析の結果を示している．横軸は時間（秒単位），縦軸は周波数を表し，赤線は\n49\n図4.12: 再生時間１秒の一拍の拍動が表現された音声信号データ\n各時間時点で最も強い周波数成分を折線で結んだものである．この赤線により，時間的な\n周波数変化が可視化されている．スペクトログラムの結果から，擬似心拍を表現する音声\n信号データにおいて，最も強い周波数の平均は42Hz であることが確認された．この結果\nは，最も強い周波数成分が42Hz 前後に集中していることを示しており，振動機器がこの\n周波数帯域（40～50Hz）に基づいて動作する際，体感的にこの周波数帯の振動が強調さ\nれる可能性を示唆している．さらに，この周波数帯の振動は，人間が持つ振動に対する手\nのひらの知覚特性[106] に基づき，十分に知覚可能な範囲に含まれる．また，110Hz 以上\nの振動が映像視聴を妨げるという研究[57] の知見にも配慮した結果であり，映像鑑賞体\n験を損なわない振動であると考えられる．\n図4.13: 図4.12 の音声信号データに対するスペクトログラム解析の結果\n50\n4.2.4\n照明を利用した擬似心拍刺激\n本研究では，擬似心拍刺激を提示するために振動に加え，照明も利用する．照明では赤\n色光を活用した擬似心拍刺激を行う．これは，赤色光による情動への効果，視覚に対する\nフィードバックが他の感覚や認知に影響を与える錯覚効果，マルチモーダルな擬似心拍刺\n激による情動への効果という3 つの観点に基づいて使用している．\n赤色光による情動への効果は，赤色光の刺激が心理的および生理的な覚醒を促進する可\n能性に基づいている．関連研究によれば，赤色光は情動における覚醒度を高めることが示\n唆されており[58][60]，昂りを促す動画と共に赤色光を提示することで，生理的な覚醒が\n上昇し，動画体験の質が向上する可能性が示されている[63]．これらの知見は，赤色光が\nユーザの覚醒を促し，特にアクション動画鑑賞時に情動体験を高める効果を持つことを示\n唆している．視覚に対するフィードバックが他の感覚や認知に影響を与える錯覚効果は，\n感覚間相互作用に基づいている．Narumi らは，拡張現実技術を用いて食べ物の見た目の\nサイズを操作し，見た目の変化だけで満腹感の認識を変化させ，摂取量を制御できること\nを示した[107]．また，Ban らは，視覚フィードバックを利用して指が触れる位置を変化\nさせることで，実際には円柱形の物体に触れているにもかかわらず，異なる曲率やサイズ\nを持つ仮想の形状に触れているような錯覚を誘発するシステムを開発し，85%の参加者が\nその錯覚を感じたと報告している[108]．これらの研究は，視覚的な操作が他の感覚や認\n知に大きな影響を与える可能性を示している．このような知見に基づき，視覚的な照明効\n果として赤色光を用いた擬似心拍刺激が，実際の身体反応であると錯覚される可能性が考\nえられる．さらに，マルチモーダルな擬似心拍刺激による情動への効果は，複数の感覚器\nに対して刺激を提示することで心理的および生理的な影響を強化する可能性に基づいて\nいる．関連研究では，提示するモダリティが増加するごとに心拍数と不安感が増加するこ\nとが示唆されており[82]，赤色光による擬似心拍刺激の追加がアクション動画鑑賞時の昂\nり判定時の情動体験をさらに強化する可能性が考えられる．\n本研究では，赤色光の擬似心拍刺激を提示する照明機器として，M5Stack 社製のLED\nテープ「SK6812 Digital RGB LED Strip」を使用した．図4.14 は，使用したLED テープの\n外観を示している．本研究で使用するマイコン（Atom-Lite）とLED テープは，専用ケー\nブル[109] を用いることで容易に接続および制御が可能である．このLED テープは，マ\nイコンを通じて帯状に連なる各LED に対して個別にRGB カラーや明るさを設定できる．\nまた，任意の長さに切断や延長が可能であり，用途に応じた柔軟な対応が可能である．\n図4.14: M5Stack 社製SK6812 Digital RGB LED Strip（[110] より引用）\n図4.15 は，LED テープを用いた赤色光による擬似心拍刺激の光色の変化を示している．\n51\nこの赤色光の擬似心拍刺激は，振動による擬似心拍刺激と同期して提示されるため，振動\nに合わせて赤色が強くなるように照明制御を行う．具体的には，図4.12 に示されている\n音声信号データを基に，縦軸の振幅が大きくなるタイミング（振動機器が強く動作するタ\nイミング）に合わせて赤色の色味および明るさを上昇させる．一方で，振幅が小さい，ま\nたはないタイミング（振動機器が弱く動作する，もしくは振動がほとんど感じられないタ\nイミング）においては，赤色の色味および明るさを抑えるように制御する．\n図4.15: 赤色光を用いた擬似心拍刺激における心拍数60 bpm の光色変化\n4.2.5\nユーザの心拍数に基づく擬似心拍刺激の対応\n本研究では，アクション動画鑑賞中のユーザの脈拍変動を基に機械学習モデルが「昂り」\nと判定した場合，その判定時のユーザの脈拍数を基に，振動および照明が同期した擬似心\n拍刺激を提示する．そのため，ユーザの脈拍数に応じて提示する擬似心拍刺激の設定を\n行った．表4.1 は，判定時における実際のユーザの脈拍数と，それに対応する擬似心拍刺\n激の対応表を示している．\n本研究では，提示する擬似心拍刺激の脈拍数を，実際の脈拍数よりも高く設定している．\nこれは，実際の心拍に基づいた擬似心拍振動の提示手法において，意図的に高い擬似心拍\nを提示することで，実際の心拍数も同期して上昇することが確認された研究[78] を参考\nにしたものである．この設定により，擬似心拍刺激がユーザの生理反応に影響を与え，情\n動的な昂りを高める可能性が期待できる．\n表4.1: 実際の脈拍数と擬似心拍刺激の対応表\n実際の脈拍数(bpm)\n擬似心拍刺激(bpm)\n86 以上\n100\n76～85\n90\n66～75\n80\n65 以下\n70\n52\n4.3\n昂りに連動したスマートフォンアクセサリー\n4.3.1\n振動提示の設計\nスマートフォンアクセサリーでは，振動提示を持ち手に当たる手のひらに提示する設計\nとした．この設計は，人間の手の繊細な知覚処理能力を参考にしている．脳の感覚野に\nおける，人体の様々な部位に生じた感覚に対する情報処理領域を表した脳地図[111] によ\nると，手や指は大脳の大きな割合（約4 分の1）を占有していることが確認されている．\nこれは，手や指が非常に繊細で多様な感覚情報を処理する能力を持つことを示している．\n図4.16 は，スマートフォンアクセサリーで擬似心拍振動を提示するためのデザインを示\nしている．振動が持ち手部分に提示されることで，擬似心拍振動を手のひらで繊細に体感\nできることが考えられる．\n図4.16: スマートフォンアクセサリーに対する振動提示部のデザイン\n本研究では，スマートフォンアクセサリーにおける擬似心拍振動を提示するため，振動\n提示部を3D プリンタで造形した．図4.17 は，モデリングしたデータを基に3D プリンタ\nで造形した振動提示部を示している．モデリングの際には，図4.11 に示される簡易的な振\n動提示デバイスの振動アクチュエータやマイコンの位置関係を参考に，振動アクチュエー\nタ，アクチュエータを制御するマイコン，および電源供給用の外部バッテリーを密接に配\n置できるよう設計した．さらに，図4.18 は，振動機器などを取り付けた完成形の様子を\n示している．完成時に，振動アクチュエータで振動を起こした際，造形素材であるプラス\nチックとアクチュエータの接触により雑音が発生することが確認された．これを改善する\nため，接触部分にフェルトを挿入し，接触による雑音を軽減するとともに，振動を効率的\nに振動提示部全体へ伝達するよう工夫した．\nまた，振動提示部の裏側に当たる手のひらで接触する把持部分は，丸みを帯びた形状に\n設計した．丸みを帯びた形状にすることで，手のひら全体に振動を効果的に伝えるととも\nに，スマートフォンアクセサリーの持ちやすさを向上させる効果がある．特に，動画鑑賞\n時にはスマートフォンアクセサリーを持ち続けることが多いため，持ちやすさは鑑賞体験\nに大きな影響を及ぼすと考えられる．把持部分に違和感があると，鑑賞中の集中が妨げら\nれる可能性があるため，持ちやすさを重視した設計は重要性を持つ．\n53\n図4.17: 造形した振動提示部\n図4.18: 振動機器などを取り付けた様子\n4.3.2\n照明提示の設計\nスマートフォンアクセサリーでは，照明提示をユーザの視覚に直接的に提示する設計\nとした．図4.19 は，LED テープを用いて光刺激による擬似心拍を提示するためのデザイ\nンを示している．LED テープはスマートフォンアクセサリーの側面に取り付けられ，各\nLED の主な光の照射方向はユーザの目に直接向いていない．しかし，LED の点灯や輝き\nはユーザから視認可能である．この場合，光の照射方向は「間接的」に見えるが，視覚\n刺激としてはユーザが直接認識できるため，\n「直接的」とみなす．また，LED テープをス\nマートフォンアクセサリーの外側の側面に取り付ける理由は，擬似心拍刺激として照射さ\nれる赤色光が，鑑賞する動画の色味に影響を与えることで，鑑賞体験に悪影響を及ぼす懸\n念を軽減するためである．\n図4.19: スマートフォンアクセサリーに対する照明提示部のデザイン\n本研究では，スマートフォンアクセサリーの側面にLED テープを取り付ける際，角形\nシリコンチューブ[112] を活用した．LED テープをそのまま側面に取り付けると，持つ際\n54\nに直接手に触れて違和感が生じる可能性があるほか，LED 素子が直接見えることで光が\n点状に見え，場合によっては発色が白っぽく感じられることがある．この問題を解決する\nため，LED テープを角形シリコンチューブに通した状態で取り付けた．これにより，手\nに触れても違和感がなくなるとともに，光がやや拡散されることで色が柔らかく見えると\nいう利点が得られる．図4.20 は，LED テープを角形シリコンチューブに通した状態で取\nり付け，擬似心拍刺激に扱う赤色光を照射した様子を示している．\n図4.20: 側面に取り付けたLED テープによる赤色光照射の様子\n4.3.3\nスマートフォンアクセサリーの構造\n振動提示および照明提示の設計を基に製作したスマートフォンアクセサリーを図4.21 に\n示す．スマートフォンアクセサリーの大きさは，縦の長さが約13cm，横の長さが約21.5cm，\n厚さが約6.3cm であり，単体での重さは305g である．鑑賞端末であるスマートフォンは，\nバネの反発力を利用して挟む方式で固定する．この固定方法により，一般的なスマート\nフォンのサイズ[9] に対応し，ほとんどのスマートフォンが装着可能となる．図4.22 は\nスマートフォンアクセサリーの裏面を示しており，振動提示部が両側に配置されている．\nまた，中央には照明機器を制御するマイコン（Atom-Lite）および電源供給用バッテリー\n（TailBat）を格納するポケットが取り付けられている．さらに，図4.23 はスマートフォン\nアクセサリーの側面を示しており，厚さが約6.3cm あるため，手のひらで覆うようにして\nしっかりと把持することが可能である．\n55\n図4.21: スマートフォンアクセサリー\n図4.22: スマートフォンアクセサリー（裏面）\n56\n図4.23: スマートフォンアクセサリー（側面）\n57\n4.3.4\nスマートフォンアクセサリーを使用した動画鑑賞方法\nスマートフォンアクセサリーを使用した動画鑑賞方法を以下に説明する．まず，Wi-Fi\nに接続したスマートウォッチを手首に装着し，専用アプリケーションを起動する．図4.24\nは，専用アプリケーションを起動した際の画面を示しており，画面上にはデータベースと\nの接続状況，脈拍センサの測定状況，昂りの判定状況が表示される．次に，鑑賞端末であ\nるスマートフォンをスマートフォンアクセサリーに固定し，専用アプリケーションの画面\n下部にある開始ボタンを押下する．図4.25 は，開始ボタン押下後の画面を示している．開\n始ボタンを押下すると，脈拍センサが脈拍間隔を取得し始め，取得したデータに基づいて\n昂りの判定が行われる．鑑賞終了後，スマートウォッチ上の画面下部をもう一度タップす\nることで，アプリケーションを終了する．\n図4.24: 専用アプリケーション\nの起動時の画面\n図4.25: 専用アプリケーション\nの開始ボタンを押下した後\n58\n第5章\nスマートフォンアクセサリーによるアク\nション動画鑑賞時の情動体験の影響\n本章では，第4 章で作成したシステムの評価実験の概要および実験方法について述べる．\n実験担当者は，臨床研究に携わる人のe ラーニングサイト「ICR 臨床研究入門」にて，\n「研\n究倫理と被験者保護」および「人を対象とする医学系研究に関する倫理指針」を履修し\nている．また，本実験は，青山学院大学理工学部ライフサイエンス委員会の「人に係る研\n究」に関する審査・承認を受け実施され（承認番号H23-035），被験者は実験説明を受け，\n実験に対する同意書による同意をもって，実験に参加頂いている．\n5.1\nアクション動画における鑑賞体験への影響の検証\n5.1.1\n実験目的\n本研究のシステムは，アクション動画鑑賞中のユーザの脈波変動を基に「昂り」を判定\nし，その結果に応じた擬似心拍を表現する振動および照明刺激を提示することで，情動的\nな昂りを高めることを目標として取り組んだ．そのため，評価実験では，アクション動画\nの鑑賞中に，脈波変動に基づく昂り判定と連動した擬似心拍刺激を与えることによって鑑\n賞体験にどのような影響を与えるかを検証することを目的とする．\n5.1.2\n実験概要\n本実験では，昂りに連動した振動と照明による擬似心拍刺激を組み込んだ動画鑑賞型ス\nマートフォンアクセサリーを使用したアクション動画鑑賞が，鑑賞体験に与える影響を検\n証するために実施した．被験者は成人男女12 名（22 歳～24 歳）で構成された．実験環境\nとして，アクション動画鑑賞中に記録される脈波間隔がアクション動画以外の要因に影\n響されないよう，室内照明を消灯した暗室に加え，イヤホンを使用した．被験者は暗室内\nで1 人で実験を行い，脈波信号として脈波間隔を測定するためにスマートウォッチを手首\nに装着し，冒頭から約30 分間の初めて観るアクション動画をスマートフォンで鑑賞した．\n本実験では，提案システムの効果を検証するため，システムを使用した場合と使用しない\n場合の2 条件でアクション動画の鑑賞を行わせた．どちらの条件でも，同じ内容および時\n間のアクション動画を鑑賞したが，条件ごとに鑑賞日は別日に分けて設定した．さらに，\nシステムを使用する場合と使用しない場合の順序は被験者ごとにランダムに設定した．図\n5.1 は，本実験の全体図を示している．\n本収集実験では，脈波間隔の測定にPolar 社製スマートウォッチ「M600」[84] を使用し\nた．また，実験で使用するアクション動画の題材に「ミッション：インポッシブル」シリー\nズ[113] を採用した．この題材を選定した理由は，国内外でアクション動画として評価が\n59\n図5.1: 実験の全体図\n高く，冒頭約30 分程度の間に逃走，銃撃戦，爆発などアクション性の高い映像が含まれ\nており，被験者が鑑賞時に昂りを誘発されることが期待できるためである．本実験でアク\nション動画を再生するためのスマートフォンには，画面サイズが約6.1 インチの「iPhone13\nPro」[86] を使用した．\n5.1.3\n鑑賞体験を測定する指標\n本実験では，スマートフォンアクセサリーを使用したアクション動画鑑賞が鑑賞体験に\n与える影響を評価するため，質問票を活用した定性評価と，脈波信号を活用した定量評価\nの2 つの手法を採用した．これらの手法を基に鑑賞体験の効果を測定し，差異をもって，\n鑑賞体験の向上の程度を評価する．質問票を活用した定性評価では，アクション動画鑑賞\nを通じた情動を評価するために「Self-Assessment Manikin（以下略称：SAM）」[114] を利\n用した質問票，および本研究のシステムの快適性や使いやすさを評価するために「System\nUsability Scale（以下略称：SUS）」[115] を利用した質問票を作成した．\n本実験では，システムを使用した場合と使用しない場合のアクション動画鑑賞における\n主観的な情動を評価するため，情動反応を評価する非言語的な測定指標であるSAM を使\n用した．この指標は，被験者が絵画を用いて自身の情動を直感的に評価する方法であり，\n快-不快（Valence），覚醒度（Arousal），主導感（Dominance）の3 次元に基づいて情動\nを詳細に測定するものである．快-不快は，喜びから悲しみまでの情動の幅を表し，覚醒\n度は情動の強度や興奮状態の度合いを示す．主導感は通常，自身の感情をどの程度コント\nロールできるかを測定する次元として定義される．図5.2 は，SAM を用いた評価方法の\n一例を示している．本実験では，快-不快，覚醒度，主導感の3 つの尺度について，それ\nぞれ9 段階の評価を行った．快-不快尺度では，\n「楽しい・心地よい」に相当する快表現を\n高得点とし，覚醒度尺度では，\n「興奮・刺激を感じた」に相当する覚醒度表現を高得点とし\nた．主導感では，\n「感情のコントロールできない」に相当する主導感表現を高得点とした．\n60\nまた，主導感については，鑑賞体験における没入感の尺度として再解釈する．通常の主導\n感は対象や状況に対する感情のコントロール度を評価する次元であるが，アクション動画\n鑑賞においては，鑑賞者が映像世界にどれだけ引き込まれるかを測定する尺度として用い\nる．この解釈に基づき，主導感が低い状態は鑑賞者が映像世界に深く引き込まれ，没入感\nが高い状態を示す．反対に，主導感が高い状態は，鑑賞者が映像世界を俯瞰的に捉え，没\n入感が低い状態を示す．この再解釈により，主導感の尺度を動画鑑賞体験における没入感\nの評価に特化した指標として活用する．被験者は，各尺度について提示された9 つの人形\nの絵から，自身の情動状態に最も近いものを選択することで評価を行う．この評価方法は\n言語に依存しないため，文化的な違いや解釈のばらつきが抑えられるという特徴を持つ．\n本実験では，これらの再解釈および評価方法を通じて，アクション動画鑑賞における情動\n体験を捉える．\n図5.2: SAM（Self-Assessment Manikin）の一例（[116] より引用）\n一方で，システムを使用したアクション動画鑑賞において，システムの快適性や使いや\nすさを評価するため，本実験では製品やサービスのユーザビリティを測定する指標である\nSUS を使用した．この指標は，快適性や使いやすさに関する10 個の質問で構成されてお\nり，それぞれの質問に対して5 段階のリッカート尺度を用いて，\n「そう思う」から「そう\n思わない」までの範囲で回答する形式となっている．回答結果に基づいて各質問の得点に\n重みづけを施し，算出された総得点が72 点以上であれば，ユーザビリティが良好（good）\nであると判断できるとされる[117]．表5.1 は，本実験で被験者に提示されるSUS を用い\nた質問票の質問項目を示している．\n5.1.4\n実験手順\n実験開始前に，被験者が提示されるアクション動画が初見であることを確認し，実験室\nに案内して指定された座席に着席させる．次に，被験者の手首にスマートウォッチを装着\nし，専用アプリケーションを起動して操作方法を説明する．システムを使用する条件で\nは，スマートフォンを専用アクセサリーに装着させる．\nその後，音量や画面の明るさを確認し，イヤホンを装着させた上で，実験室の照明を消\n灯して暗室状態を作り出し，数分間安静を保つよう指示する．準備が整い次第，アクショ\nン動画を再生し，被験者は暗室内で一人で動画を鑑賞する．動画鑑賞後，被験者には質問\n61\n表5.1: SUS での質問項目\n番号\n質問内容\n1\nこのシステムを頻繁に利用したいと感じた\n2\nこのシステムは必要以上に複雑だと感じた\n3\nこのシステムは使いやすいと感じた\n4\nこのシステムを使えるようになるためには，専門の助けが必要だと感じた\n5\nこのシステムはいろんな機能が上手くまとまっていると感じた\n6\nこのシステムはちぐはぐな点が多すぎると感じた\n7\nこのシステムの使い方は大抵の人がすぐに使いこなせると感じた\n8\nこのシステムはとても扱いづらいと感じた\n9\nこのシステムを使いこなせると自信がある\n10\nこのシステムを使い始める前に使用法を学ぶことが多いと感じた\n票を用いて主観的な情動評価を実施する．システムを使用する条件では，情動評価に加え\nてシステムのユーザビリティ評価も行う．図5.3 は，実験中の被験者の様子である．\n図5.3: 実験時の様子\n62\n5.2\n定性評価の結果および考察\n5.2.1\nシステムの有無での情動評価の比較\nシステムを使用した場合（with）と使用しない場合（without）における情動評価を比較\nするため，SAM を利用した質問票を用いて評価を実施した．図5.4，図5.5，図5.6 は，12\n名の被験者がシステム使用の有無による条件間で実施した快-不快，覚醒度，主導感に対\nする情動評価の結果を箱ひげ図で示している．これらの図を通じて，システムの使用が各\n情動評価に与える影響を可視化している．まず，システム有無における快-不快尺度の評\n価分布を箱ひげ図で比較すると，システム有の条件では中央値および平均値がシステム\n無の条件よりも高い結果となった．また，システム有の条件では，中央値よりも平均値が\n上回っていることから，評価分布が上方向にシフトしていることが確認できる．この結果\nは，本実験において，システムを使用したアクション動画鑑賞の体験が，被験者の情動を\nポジティブな方向へと高める可能性を示唆していると考えられる．\n図5.4: システム有無での快-不快（Valence）尺度の評価分布\n次に，システム有無における覚醒度尺度の評価分布を箱ひげ図で比較すると，システム\n有の条件では中央値および平均値がシステム無の条件よりも高い結果が得られた．また，\nシステム有の条件では中央値よりも平均値が上回っており，評価分布が上方向にシフトし\nていることが確認できる．一方で，システム無の条件では中央値よりも平均値が下回って\nおり，評価分布が下方向にシフトしていることが確認され，両条件間で平均値の差が拡大\nしている．この結果は，システムを使用したアクション動画鑑賞の体験が，被験者の情動\nの強度をより高め，興奮度合いを増加させる可能性を示唆していると考えられる．\n最後に，システム有無における主導感尺度の評価分布を箱ひげ図で比較すると，システ\nム有の条件では中央値がシステム無の条件と同じ値を示しているものの，平均値はシステ\n63\n図5.5: システム有無での覚醒度（Arousal）尺度の評価分布\nム無の条件よりも高い結果が得られた．また，システム有の条件では中央値よりも平均値\nが上回っており，評価分布が上方向にシフトしていることが確認できる．一方，システム\n無の条件では中央値よりも平均値が下回っており，評価分布が下方向にシフトしているこ\nとが確認され，両条件間で平均値の差が拡大している．この結果は，システムを使用した\nアクション動画鑑賞の体験が，被験者の没入感をより高める効果を持つ可能性を示唆して\nいると考えられる．\nまた，表5.2 は，各尺度におけるシステム有無の条件間での平均値およびその差分を示\nしている．この結果から，システム有の条件が全ての尺度において平均値が高い傾向にあ\nることが確認された．特に，覚醒度尺度では他の尺度よりも高い評価が得られているこ\nとが明らかとなった．しかしながら，これらの平均値の差は偶然によるものなのか，それ\nとも統計的に有意な差であるのかを判断する必要がある．そこで，有意水準を5%に設定\nし，システム有無の条件間での評価の違いについて，対応ありのt 検定を実施した．t 検\n定は，t 分布を利用して2 つの集団の平均値の差が有意であるかを検定する[118]．t 分布\nは，正規分布を母集団とし，母分散が未知の場合に用いられる分布で，少ない標本数でも\n信頼性のある分析を可能にする．t 検定の過程では，まず帰無仮説を設定する．帰無仮説\nとは，\n「平均値に差がない」といった主張であり，検定の出発点となる仮定である．例え\nば，薬の効果を検証する場合，\n「薬を投与したグループと投与しなかったグループの平均\n値に差がない」という仮説が帰無仮説となる．次に，得られたデータから算出されるt 値\nやp 値を基に仮説を検証する．t 値は平均値の差が偶然によるものかを示し，p 値は観測\n結果の希少性を示す指標である．一般的な有意水準（0.05）を基準に，p 値がこれを下回\nる場合，帰無仮説を棄却し，\n「平均値の差が統計的に有意である」と判断する．\nシステムの有無での情動評価の比較では，帰無仮説を「システムの有無でのアクション\n64\n図5.6: システム有無での主導感（Dominance）尺度の評価分布\n表5.2: システム有無での各尺度の平均と条件間の差\n快-不快尺度の平均\n覚醒度尺度の平均\n主導感尺度の平均\nシステム有\n7.4\n7.0\n7.5\nシステム無\n6.6\n5.5\n6.3\nシステム有無の差（有-無）\n0.8\n1.5\n1.2\n動画鑑賞体験において尺度の情動評価に差がない」と設定し，有意水準を0.05 とした．表\n5.3 は，対応ありt 検定を実施した結果を示している．この結果より，快‐不快および覚\n醒度については，t 値が片側検定の棄却域（1.796）に含まれており，p 値も有意水準未満\nであることから，システムの有無による情動評価に有意な差があると判断される．また，\n主導感については，t 値（2.184）が片側検定の棄却域（1.796）に含まれ，p 値（0.026）も\n有意水準未満であることから，システム有の条件がシステム無よりも支配感を高めると\nいう方向性の仮説を支持する結果が得られた．これらの結果から，帰無仮説は棄却され，\n快‐不快，覚醒度，支配感のいずれについても，システムの有無による情動評価に差があ\nり，システム有の条件がこれらの情動評価を向上させる可能性が示唆される．\n表5.3: システム有無での各尺度の情動評価に関する検定統計量とp 値の結果\n尺度\nt 値\n片側検定p 値\n片側検定境界値\n両側検定p 値\n両側検定境界値\n快-不快\n2.803\n0.009\n1.796\n0.017\n2.201\n覚醒度\n3.317\n0.003\n1.796\n0.007\n2.201\n支配感\n2.184\n0.026\n1.796\n0.052\n2.201\n65\n5.2.2\nシステム無での1 回目と2 回目の鑑賞時の情動評価の比較\nシステムの有無による情動評価に差があり，システム有の条件がこれらの情動評価を向\n上させる可能性が示唆された結果を受けて，まずはシステム無での1 回目と2 回目の鑑賞\n時の情動評価を比較し，順序効果（1 回目の鑑賞が2 回目の鑑賞に影響を与えること）の\n有無を検証した．具体的には，同じアクション動画を2 回鑑賞した場合，鑑賞回数（1 回\n目と2 回目）の違いが情動評価に与える影響を確認し，\n「情動の減衰」や「新奇性の低下」\nがどの程度起こるかを調べることを目的としている．図5.7，図5.8，図5.9 は，12 名の被\n験者がシステム無で鑑賞した際の順序（1 回目と2 回目）における快-不快，覚醒度，主導\n感に対する情動評価の結果を箱ひげ図で示している．なお，1 回目と2 回目の鑑賞におけ\nる情動評価は，異なる6 名ずつの被験者によって行われている．これらの図を通じて，シ\nステム無での鑑賞順序が情動評価に与える影響を可視化した．\nまず，システム無での鑑賞順序における快-不快尺度の評価分布を箱ひげ図で比較する\nと，1 回目の鑑賞では中央値および平均値が2 回目の鑑賞よりも高い結果が得られた．ま\nた，この尺度において，2 回目の評価の中央値が1 回目の最小値を下回っていることが確\n認された．この結果は，快-不快尺度において，鑑賞順序による順序効果が存在すること\nを示唆していると考えられる．次に，システム無での鑑賞順序における覚醒度尺度の評価\n分布を箱ひげ図で比較すると，1 回目の鑑賞では中央値および平均値が2 回目の鑑賞より\nも高い結果が得られた．また，この尺度においては，1 回目の中央値より下の評価が多数\n分布していることが確認された．この結果は，覚醒度尺度においても鑑賞順序による順序\n効果が存在する可能性を示唆していると考えられる．最後に，システム無での鑑賞順序に\nおける主導感尺度の評価分布を箱ひげ図で比較すると，1 回目の鑑賞では中央値および平\n均値が2 回目の鑑賞よりも高い結果が得られた．また，この尺度においても，1 回目の中\n央値より下の評価が多数分布していることが確認された．この結果は，主導感尺度におい\nても鑑賞順序による順序効果が存在する可能性を示唆していると考えられる．\n66\n図5.7: システム無での鑑賞順序における快-不快（Valence）尺度の評価分布\n図5.8: システム無での鑑賞順序における覚醒度（Arousal）尺度の評価分布\nまた，表5.4 は，各尺度におけるシステム無での鑑賞順序の条件間における平均値およ\nびその差分を示している．この結果から，システム無での2 回目の鑑賞が全ての尺度にお\nいて平均値が低い傾向にあることが確認され，鑑賞順序による順序効果が存在する可能性\n67\nが示唆される．しかしながら，これらの平均値の差が偶然によるものか，統計的に有意な\n差であるのかを判断する必要がある．そこで，有意水準を5%に設定し，システム無での\n鑑賞順序による評価の違いについて，対応なしのt 検定を実施した．\n図5.9: システム無での鑑賞順序における主導感（Dominance）尺度の評価分布\n表5.4: システム無での鑑賞順序における各尺度の平均と条件間の差\n快-不快尺度の平均\n覚醒度尺度の平均\n主導感尺度の平均\n1 回目\n6.8\n6.0\n6.6\n2 回目\n6.3\n5.0\n6.0\n鑑賞順序における差（2 回目-1 回目）\n-0.5\n-1.0\n-0.6\nシステム無での鑑賞順序における情動評価の比較では，帰無仮説を「システム無での鑑\n賞順序におけるアクション動画鑑賞体験において各尺度の情動評価に差がない」と設定\nし，有意水準を0.05 とした．表5.5 は，対応なしt 検定を実施した結果を示している．こ\nの結果より，快‐不快，覚醒度，および支配感について，いずれもt 値が片側検定の棄却\n域（1.812）および両側検定の棄却域（2.228）のいずれにも含まれず，p 値も有意水準以上\nであることから，システム無の鑑賞順序による情動評価に有意な差は確認されなかった．\nこれらの結果から，帰無仮説は棄却されず，鑑賞順序が情動評価に影響を及ぼす可能性は\n低いことを示唆している．\n68\n表5.5: 鑑賞順序における各尺度の情動評価に関する検定統計量とp 値の結果\n尺度\nt 値\n片側検定p 値\n片側検定境界値\n両側検定p 値\n両側検定境界値\n快-不快\n0.785\n0.225\n1.812\n0.451\n2.228\n覚醒度\n1.035\n0.163\n1.812\n0.325\n2.228\n支配感\n0.674\n0.258\n1.812\n0.515\n2.228\n5.2.3\nシステム有での1 回目と2 回目の鑑賞時の情動評価の比較\n次に，システム有での1 回目と2 回目の鑑賞時の情動評価を比較し，システム使用によ\nる効果が鑑賞順序（1 回目・2 回目）に依存しないことを検証した．特に，システム有を\n2 回目に使用した場合でも，情動評価に変化が見られるかを確認し，システムの効果が一\n貫して情動評価を向上させているかを明らかにすることを目的としている．また，システ\nム無と有の条件を比較することで，有意差をもってシステム有の条件が情動評価を向上さ\nせる可能性を検討し，順序効果の影響を考慮する．図5.10，図5.11，図5.12 は，12 名の\n被験者がシステム有で鑑賞した際の順序（1 回目と2 回目）における快-不快，覚醒度，主\n導感に対する情動評価の結果を箱ひげ図で示している．なお，1 回目と2 回目の鑑賞にお\nける情動評価は，異なる6 名ずつの被験者によって行われている．これらの図を通じて，\nシステム有での鑑賞順序が情動評価に与える影響を可視化した．\nまず，システム有での鑑賞順序における快-不快尺度の評価分布を箱ひげ図で比較する\nと，1 回目と2 回目の中央値および平均値には大きな違いが見られないことが確認された．\nまた，分布の範囲においては，1 回目の方がわずかに広がりが大きいものの，全体的な評\n価の傾向は一貫している．この結果は，快-不快尺度において，鑑賞順序による順序効果\nが影響を及ぼしていない可能性を示唆していると考えられる．次に，システム有での鑑賞\n順序における覚醒度尺度の評価分布を箱ひげ図で比較すると，1 回目と2 回目の中央値や\n平均値に大きな違いは見られないものの，2 回目では中央値および平均値がやや高い傾向\nが確認された．また，分布の範囲においては，2 回目の最大値が1 回目の最大値を上回り，\n評価分布が上方向にシフトしていることが確認された．さらに，評価のばらつきも2 回目\nの方が増加していることが示されている．この結果は，覚醒度尺度において，鑑賞順序が\n評価に影響を与える順序効果が存在する可能性を示唆していると考えられる．最後に，シ\nステム有での鑑賞順序における主導感尺度の評価分布を箱ひげ図で比較すると，1 回目と\n2 回目の中央値および平均値には大きな違いが見られないことが確認された．しかし，分\n布の範囲においては，2 回目の方がわずかに広がりが大きく，評価のばらつきが増加して\nいることが確認された．この結果は，主導感尺度において，鑑賞順序が評価に影響を与え\nる順序効果が存在する可能性を示唆していると考えられる．\n69\n図5.10: システム有での鑑賞順序における快-不快（Valence）尺度の評価分布\n図5.11: システム有での鑑賞順序における覚醒度（Arousal）尺度の評価分布\nまた，表5.6 は，各尺度におけるシステム有での鑑賞順序の条件間における平均値およ\nびその差分を示している．システム有での1 回目と2 回目の各尺度の情動評価を比較する\nと，類似した結果が得られる尺度もあれば，分布の違いが見られる尺度も存在したもの\n70\n図5.12: システム有での鑑賞順序における主導感（Dominance）尺度の評価分布\nの，平均値の差は全体的に0 に近い傾向を示していることが確認された．この結果は，鑑\n賞順序による順序効果が存在しない可能性を示唆していると考えられる．しかしながら，\nこれらの平均値の差が偶然によるものか，統計的に有意な差であるかを判断する必要があ\nる．そのため，有意水準を5%に設定し，システム有での鑑賞順序による評価の違いにつ\nいて，対応なしのt 検定を実施した．\n表5.6: システム有での鑑賞順序における各尺度の平均と条件間の差\n快-不快尺度の平均\n覚醒度尺度の平均\n主導感尺度の平均\n1 回目\n7.3\n6.7\n7.7\n2 回目\n7.5\n7.3\n7.3\n鑑賞順序における差（2 回目-1 回目）\n0.2\n0.6\n-0.4\nシステム有での鑑賞順序における情動評価の比較では，帰無仮説を「システム有での鑑\n賞順序におけるアクション動画鑑賞体験において各尺度の情動評価に差がない」と設定\nし，有意水準を0.05 とした．表5.7 は，対応なしt 検定を実施した結果を示している．こ\nの結果より，快‐不快，覚醒度，および支配感について，いずれもt 値が片側検定の棄却\n域（1.812）および両側検定の棄却域（2.228）のいずれにも含まれず，p 値も有意水準以上\nであることから，システム有の鑑賞順序による情動評価に有意な差は確認されなかった．\nこれらの結果から，帰無仮説は棄却されず，鑑賞順序が情動評価に影響を及ぼす可能性は\n低いことを示唆している．\n71\n表5.7: 鑑賞順序における各尺度の情動評価に関する検定統計量とp 値の結果\n尺度\nt 値\n片側検定p 値\n片側検定境界値\n両側検定p 値\n両側検定境界値\n快-不快\n-0.349\n0.367\n1.812\n0.734\n2.228\n覚醒度\n-0.845\n0.209\n1.812\n0.418\n2.228\n支配感\n0.620\n0.275\n1.812\n0.549\n2.228\n5.2.4\n快適性および使用感の評価\n本研究のシステムを使用したアクション動画鑑賞時におけるシステムの快適性や使いや\nすさを評価するため，SUS を利用した質問票を用いて評価を実施した．具体的には，ス\nマートウォッチの装着からスマートフォンをスマートフォンアクセサリーに固定し，動画\n鑑賞を行う一連の操作に関するユーザビリティを被験者に評価してもらった．図5.13 は，\n12 名の被験者がSUS の10 項目に基づくユーザビリティに関する質問に回答し，それぞ\nれの得点を重み付けして算出されたSUS スコアを可視化したものである．この図を通じ\nて，システム全体の快適性や使いやすさに関する評価結果を視覚的に確認することができ\nる．全体の得点結果を見ると，12 名の被験者全員の得点は75 点から100 点の範囲に分布\nしている．特に，図中で示されている被験者2 および被験者7 は満点（100 点）を記録し\nており，システムのユーザビリティについて非常に高い評価を与えていることがわかる．\nまた，全被験者の平均点は86.5 点であり，全般的に高い評価が得られていることが考え\nられる．一方で，最低得点を記録した被験者は被験者9 であり，その得点は約75 点であっ\nた．この結果は，全体として本システムが快適性や使いやすさにおいて良好な評価を受け\nたことを示している．\n全被験者の平均点を基に，本システムを用いたアクション動画鑑賞におけるユーザビリ\nティの評価を行った．図5.14 は，SUS に基づく評価得点に対する評価尺度[117] を示して\nいる．この評価尺度にある許容度（Acceptability）の基準を適用すると，全被験者の平均\n点である86.5 点は「acceptable」に該当する．また，被験者から評価された最低点である\n約75 点についても同様に「acceptable」に該当することが確認された．以上の結果から，\n本システムのユーザビリティは高く評価されており，十分に許容できるレベルの快適性と\n使いやすさを備えていることが示唆された．\nまた，本実験では，SUS で直接評価の対象として言及していない「システムの重さ」に\n関する評価を，SUS の質問票に加えて独自の評価を行った．この質問票では，それぞれの\n質問に対して5 段階のリッカート尺度を用い，\n「そう思う」から「そう思わない」までの範\n囲で回答を得た．表5.8 は，本システムを用いたアクション動画鑑賞時に使用したスマー\nトフォンアクセサリーの重さに関する評価結果を示している．本実験で使用したスマート\nフォンアクセサリーは，スマートフォンを固定した状態での総重量が510g であり，この\n重量が長時間の鑑賞において被験者に疲労を与える可能性が懸念された．\n「鑑賞時に固定\nしたスマートフォンを含むスマートフォンアクセサリーは全体的に軽かった」という質問\nに対しては，評価は「どちらともいえない」に集中しており，アクセサリーの重量に対し\nて中立的な意見が多かった．しかし，\n「スマートフォンアクセサリーを60 分間持ち続けた\n場合，手や腕に疲れを感じないと思う」および「スマートフォンアクセサリーを90 分間\n持ち続けた場合，手や腕に疲れを感じないと思う」という質問に対しては，否定的な評価\n72\n図5.13: SUS に基づく各被験者の快適性と使用感に関する評価得点\n図5.14: SUS に基づく評価得点に対する評価尺度（[117] より引用）\nが多く見られ，長時間の使用において重量感が疲労の蓄積を引き起こす可能性が示唆され\nた．一方で，\n「スマートフォンアクセサリーの形状は持ちやすさに適している」という質\n問に対しては高い評価が得られ，アクセサリーの形状が被験者の使用感において好意的に\n受け止められたことが確認された．この結果から，スマートフォンアクセサリーの形状が\n持ちやすさを向上させる一方で，重量感が長時間の使用における課題として残されている\nことが考えられる．\n5.2.5\n擬似心拍刺激を伴うアクション動画鑑賞の評価\n本実験では，システムを使用したアクション動画鑑賞後に実施したSUS によるユーザ\nビリティ評価に加えて，擬似心拍刺激に焦点を当てたアクション動画鑑賞の独自の評価を\n行った．この評価では，それぞれの質問に対して5 段階のリッカート尺度を用い，\n「そう思\nう」から「そう思わない」までの範囲で回答を得た．表5.9 は，擬似心拍刺激を伴うアク\nション動画鑑賞に関する評価結果を示している．結果から，擬似心拍刺激がアクション動\n画鑑賞中の主観的な没入感や興奮度合いを高めることについて肯定的な評価が得られた\nことが確認された．特に，擬似心拍刺激はアクション動画鑑賞時の緊張感や興奮度を高め\n73\n表5.8: スマートフォンアクセサリーの重さに関する評価\n質問文（回答者：12 名）\n評価（5 点満点）\n評価（100%）\n鑑賞時に固定したスマートフォンを含むスマート\nフォンアクセサリーは全体的に軽かった\n3\n60%\nスマートフォンアクセサリーを持っている間，手\nや腕に疲れを感じなかった\n3.25\n65%\nスマートフォンアクセサリーを30 分間持ち続けた\n場合，手や腕に疲れを感じないと思う\n3.5\n70%\nスマートフォンアクセサリーを60 分間持ち続けた\n場合，手や腕に疲れを感じないと思う\n2.5\n50%\nスマートフォンアクセサリーを90 分間持ち続けた\n場合，手や腕に疲れを感じないと思う\n1.92\n38%\nスマートフォンアクセサリーの形状や表面の材質\nは，持ちやすさに適している\n4.5\n90%\nる点において有効であることが示された．また，\n「擬似心拍刺激がアクション動画鑑賞体\n験に良い影響を与えた」という質問項目においても高い評価が得られた．この結果から，\nスマートフォンアクセサリーによる昂りに連動した擬似心拍刺激は，アクション動画鑑賞\n時の情動の強度を高め，全体的な鑑賞体験の向上に寄与する可能性が示唆される．\n表5.9: 擬似心拍刺激を伴うアクション動画鑑賞に関する評価\n質問文（回答者：12 名）\n評価（5 点満点）\n評価（100%）\n擬似心拍刺激がアクション動画鑑賞中の没入感を\n高めたと感じた\n4\n80%\n擬似心拍刺激がアクション動画鑑賞中の緊張感や\n興奮度を高めたと感じた\n4.4\n88%\n擬似心拍刺激はアクション動画鑑賞の体験を新鮮\nなものにした\n4.8\n95%\n擬似心拍刺激がアクション動画鑑賞の体験に良い\n影響を与えてた\n4.4\n88%\n5.2.6\n情動評価の結果に対する考察\n本実験では，昂りに連動した擬似心拍刺激によるフィードバックを行うスマートフォン\nアクセサリーを用いたアクション動画鑑賞体験と，従来のスマートフォン単体でのアク\nション動画鑑賞体験における情動評価を，SAM を用いた主観的評価に基づいて比較した．\n74\nその結果，システムの有無による条件間の情動評価において，システムを使用した場合の\n方が快-不快，覚醒度，主導感の各尺度で評価が高く，すべての尺度において統計的に有\n意な差が認められた．また，鑑賞順序の影響を考慮し，システム無およびシステム有の順\n序ごとに情動評価を分析したところ，各尺度において有意差は確認されず，鑑賞順序によ\nる順序効果のバイアスが生じていないことが示唆された．これにより，鑑賞順序の影響で\nはなく，システムの有無そのものが情動評価に影響を与えたと考えられる．以上の結果か\nら，スマートフォンアクセサリーを用いた昂りに連動する振動および照明による擬似心拍\n刺激のフィードバックは，ユーザに自身の昂りを認識させるとともに，興奮を促進させる\n効果を持つことが示唆された．このことから，本システムはアクション動画鑑賞時の情動\n体験を強化し，より没入感のある鑑賞体験を提供する可能性が高いと考えられる．\n5.2.7\n快適性および使用感の評価に対する考察\nSUS を利用したシステムのユーザビリティ評価の結果では，平均点および最低点のいず\nれも，評価尺度における許容度の基準を満たしており，\n「acceptable」に該当することが確\n認された．これにより，本システムは十分に許容できるレベルの快適性と使いやすさを備\nえていることが示唆される．スマートフォンをアクセサリーに装着し，専用アプリケー\nションを起動・実行するだけで容易に使用できるシンプルな操作性とハンドケース型によ\nる負担のない設計が，ユーザビリティの高評価に寄与したと考えられる．\nしかし，スマートフォンアクセサリーの重さに関する評価では，「鑑賞時に固定したス\nマートフォンを含むスマートフォンアクセサリーは全体的に軽かった」という質問に対し，\n多くの回答が「どちらともいえない」に集中した．これは，アクセサリーの重量に対して\n中立的な意見が多く，長時間の使用においては重さによる疲労感が蓄積する可能性がある\nことを示唆している．動画鑑賞媒体として使用するスマートフォンの重さも影響を与える\n要因ではあるが，アクセサリー単体でも約300g の重量があるため，サイズの縮小や軽量\n化など，よりコンパクトな設計を検討する必要があると考えられる．\n5.3\n定量評価の結果および考察\n5.3.1\n昂りの判定回数の比較\n本実験では，システムを使用した場合と使用しない場合でのアクション動画鑑賞におい\nて，脈波変動の特徴量を基に機械学習モデルを通して「昂り」かどうかを分類し，直近の\n分類結果と比較して判定された「昂り」の回数を記録した．この「昂り」の判定回数を基\nに，システムの有無によるアクション動画鑑賞中の昂りの判定回数を比較する．図5.15\nは，システム有無でのアクション動画鑑賞中における昂りの判定回数の分布を箱ひげ図を\n用いて示している．分布結果を見ると，システムを使用した場合では，中央値および平均\n値がシステムを使用しない場合よりも高いことが確認された．また，システム有の条件\nでは，評価分布が全体的に上方向にシフトしており，両条件の平均値の差が顕著である．\nまた，表5.10 は，システム有無の条件間におけるアクション動画鑑賞時の昂りの判定回\n数の平均値およびその差分を示している．この結果から，システム有の条件では平均値が\n顕著に高い傾向にあることが確認された．この結果は，システムを使用することで提示さ\n75\nれるフィードバックが，アクション動画鑑賞中の昂りの頻度が増加し，システムが情動体\n験の強化に寄与する可能性を示唆していると考えられる．しかしながら，これらの平均値\nの差が偶然によるものか，統計的に有意な差であるかを判断する必要がある．そのため，\n有意水準を5%に設定し，システム有無の条件間における昂りの判定回数の違いについて\n対応ありのt 検定を実施した．\n図5.15: システム有無でのアクション動画鑑賞時の「昂り」の判定回数の分布\n表5.10: システム有無でのアクション動画鑑賞時の「昂り」の判定回数の平均と条件間の\n差\n「昂り」の判定回数の平均\nシステム有\n75.9\nシステム無\n32.7\nシステム有無の差（有-無）\n43.2\nシステムの有無による「昂り」の判定回数の比較では，帰無仮説を「システムの有無で\nのアクション動画鑑賞体験において「昂り」の判定回数に差がない」と設定し，有意水準\nを0.05 に設定した．表5.11 は，対応ありt 検定を実施した結果を示している．この結果\nから，昂りの判定回数においてt 値が片側検定の棄却域（1.796）に含まれ，さらにp 値も\n有意水準未満であることが確認された．これらの結果を踏まえ，帰無仮説は棄却され，シ\nステムの有無が昂りの判定回数に影響を及ぼしていることが示された．また，システム有\nの条件では昂りの回数が増加する傾向が見られ，システムによるフィードバックが情動体\n験の強化に寄与する可能性が示唆していると考える．\n昂りの判定回数においても，システムの有無に差がある結果を受けて，順序効果の有無\n76\n表5.11: システム有無での「昂り」の判定回数に関する検定統計量とp 値の結果\n尺度\nt 値\n片側検定p 値\n片側検定境界値\n両側検定p 値\n両側検定境界値\n判定回数\n2.451\n0.016\n1.796\n0.032\n2.201\nを検証した．図5.16 は，システム無での鑑賞順序における「昂り」の判定回数の分布を\n箱ひげ図で示している．分布結果を見ると，システム無での鑑賞順序における1 回目と2\n回目の平均値はほとんど同じであることが確認された．また，中央値は1 回目がわずかに\n低いものの，分布の範囲において1 回目と2 回目の間に大きな違いは見られず，全体的に\n似通った傾向を示している．また，表5.12 は，システム無での鑑賞順序における「昂り」\nの判定回数の平均値およびその差分を示している．この結果から，システム無での鑑賞順\n序において，\n「昂り」の判定回数に差異はないことが考えられる．しかしながら，これら\nの平均値の差が偶然によるものか，統計的に有意な差であるかを判断する必要がある．そ\nのため，有意水準を5%に設定し，システム無での鑑賞順序における「昂り」の判定回数\nの違いについて対応なしのt 検定を実施した．\n図5.16: システム無での鑑賞順序における「昂り」の判定回数の分布\n表5.12: システム無での鑑賞順序における「昂り」の判定回数の平均と条件間の差\n「昂り」の判定回数の平均\n1 回目\n75.9\n2 回目\n32.7\n鑑賞順序における差（2 回目-1 回目）\n43.2\n77\nシステム無での鑑賞順序における「昂り」の判定回数の比較では，帰無仮説を「システ\nム無での鑑賞順序におけるアクション動画鑑賞体験において「昂り」の判定回数に差が\nない」と設定し，有意水準を0.05 とした．表5.13 は，対応なしt 検定を実施した結果を\n示している．この結果より，昂りの判定回数について，いずれもt 値が片側検定の棄却域\n（1.812）および両側検定の棄却域（2.228）のいずれにも含まれず，p 値も有意水準以上で\nあることから，システム無の鑑賞順序による昂りの判定回数に有意な差は確認されなかっ\nた．これらの結果から，帰無仮説は棄却されず，システム無での鑑賞順序が「昂り」の判\n定回数に影響を及ぼす可能性は低いことを示唆している．\n表5.13: システム無での鑑賞順序の「昂り」の判定回数に関する検定統計量とp 値の結果\n尺度\nt 値\n片側検定p 値\n片側検定境界値\n両側検定p 値\n両側検定境界値\n判定回数\n-0.030\n0.488\n1.812\n0.977\n2.228\n図5.17 は，システム有での鑑賞順序における「昂り」の判定回数の分布を箱ひげ図で\n示している．分布結果を見ると，1 回目の中央値および平均値が2 回目の中央値および平\n均値よりも顕著に高いことが確認された．また，分布範囲においても，1 回目が高い判定\n回数で広がりを持つ傾向が見られる．この結果から，システム有での鑑賞順序において，\n1 回目の判定回数が高いことが示され，順序効果が影響している可能性が考えられる．さ\nらに，表5.14 は，システム有での鑑賞順序における「昂り」の判定回数の平均値および\nその差分を示している．この結果から，システム有の条件において鑑賞順序が「昂り」の\n判定回数に顕著な差をもたらしていることが確認された．しかし，これらの平均値の差が\n偶然によるものか，統計的に有意な差であるかを判断する必要がある．そのため，有意水\n準を5%に設定し，システム有での鑑賞順序における「昂り」の判定回数の違いについて\n対応なしのt 検定を実施した．\n表5.14: システム有での鑑賞順序の「昂り」の判定回数の平均と条件間の差\n「昂り」の判定回数の平均\n1 回目\n95.8\n2 回目\n56.0\n鑑賞順序における差（2 回目-1 回目）\n-39.8\nシステム有での鑑賞順序における「昂り」の判定回数の比較では，帰無仮説を「システ\nム有での鑑賞順序におけるアクション動画鑑賞体験において「昂り」の判定回数に差が\nない」と設定し，有意水準を0.05 とした．表5.15 は，対応なしt 検定を実施した結果を\n示している．この結果より，昂りの判定回数について，いずれもt 値が片側検定の棄却域\n（1.812）および両側検定の棄却域（2.228）のいずれにも含まれず，p 値も有意水準以上で\nあることから，システム有の鑑賞順序による昂りの判定回数に有意な差は確認されなかっ\nた．これらの結果から，帰無仮説は棄却されず，システム有での鑑賞順序が「昂り」の判\n定回数に影響を及ぼす可能性は低いことを示唆している．\n78\n図5.17: システム有での鑑賞順序における「昂り」の判定回数の分布\n表5.15: システム有での鑑賞順序の「昂り」の判定回数に関する検定統計量とp 値の結果\n尺度\nt 値\n片側検定p 値\n片側検定境界値\n両側検定p 値\n両側検定境界値\n判定回数\n0.892\n0.197\n1.812\n0.393\n2.228\n5.3.2\n脈波変動指標の変化について\n本実験では，アクション動画鑑賞によって誘発される興奮的情動が脈波変動に与える影\n響を検証するため，情動的興奮時に周波数領域指標の一つである「LF/HF」が増加したこ\nとが見られた研究[40][32] を参考に，\n「LF/HF」に注目し，システムの有無によるアクショ\nン動画鑑賞中のこの指標の変化の差異を比較した．\n30 分間のアクション動画鑑賞において，システムの有無に応じたLF/HF の変化を比較\nするため，窓サイズ240 秒，シフトサイズ5 秒で算出されたLF/HF の時系列データを用\nいて，開始から30 分までの10 分ごとの区間を設けた．各被験者（12 名）ごとに，それぞ\nれの区間におけるLF/HF の平均値を算出し，システム有無での違いを検討した．図5.18\nは，システム有無における10 分ごとのLF/HF の平均値の差（システム有－システム無）\nの推移を示したものである．図中において，値が高い方向に推移している場合，システム\n有の条件におけるLF/HF の平均値が高いことを意味し，システム使用時により強い興奮\nが誘発されている可能性が考えられる．しかし，10 分ごとのLF/HF の平均値の差の推移\nにおいて，平均値は0 付近（ベースライン付近）を推移しており，システムの使用時と非\n使用時でLF/HF に顕著な変化は見られない．\n一方で，一部の被験者の20～30 分の区間において，システムの使用時と非使用時で\nLF/HF が顕著に異なることが確認された．図5.19 は，該当する被験者A のシステムの有\n79\n図5.18: システム有無における10 分ごとのLF/HF の平均値の差の推移\n無によるLF/HF の時系列的な変化を示し，加えて，システム有の条件で昂りと判定され，\n擬似心拍刺激によるフィードバックが行われたタイミングを縦の赤色破線で示している．\nこの被験者において，20～30 分の区間では，システム無の条件ではLF/HF が減少傾向に\nあるのに対し，システム有の条件では昂り判定による，連続的な擬似心拍刺激のフィード\nバックが行われることで，LF/HF が増加している．この結果は，一部の被験者に対して，\n擬似心拍刺激によるフィードバックが自律神経活動に影響を与え，交感神経優位な状態を\n促進する可能性を示唆していると考えられる．\n図5.19: 被験者A のシステムの有無でのアクション動画鑑賞時のLF/HF の推移\n5.3.3\n脈波変動指標の変化および昂りの判定回数に対する考察\n本実験では，周波数領域指標の一つである「LF/HF」に着目し，システムの有無による\nアクション動画鑑賞中のこの指標の変化の差異を比較した．その結果，システムの有無に\n80\nよるアクション動画鑑賞時のLF/HF の推移に，顕著な違いは確認されなかった．この結\n果は，昂りに連動した振動および照明による擬似心拍刺激が，交感神経と副交感神経のバ\nランスに大きな影響を及ぼしていない可能性を示唆している．したがって，本研究のシス\nテムは主観的な情動評価には影響を与えたものの，生理指標における交感神経活動と副\n交感神経活動の相対的な比率に対する擬似心拍刺激の効果は限定的であると考えられる．\n本実験では「LF/HF」に着目したが，被験者の「手に汗を握る感覚があった」という感想\nから，興奮に伴う発汗度合いへの影響に着目した評価を今後の検討とする．\n一方で，システムを使用したアクション動画鑑賞では，使用しない場合と比較して，脈\n波変動の特徴量を用いた昂りの分類モデルによる「昂り」の判定回数が有意に増加するこ\nとが確認された．この結果は，システムを使用することで，フィードバックを通じて昂り\nの回数が増加する効果があることを示唆している．さらに，フィードバックに対する期待\n感が脈波信号に影響を与え，昂る回数の増加を促している可能性も考えられる．\n81\n第6章\n結論\n6.1\nまとめ\n本研究では，個人の動画鑑賞における情動体験を強化することを通じて，スマートフォ\nンでの動画鑑賞体験の拡張を目的とし，アクション動画鑑賞中にスマートウォッチを用い\nて取得するユーザの脈拍変動を基に，機械学習モデルによってリアルタイムに「昂り」を\n判定するアプリケーションを使用して，判定結果に応じて振動および照明が同期した擬似\n心拍刺激を提示するスマートフォンアクセサリーを製作した．\n本システムによる動画鑑賞体験への影響を検証するため，システム使用の有無による2\n条件でアクション動画鑑賞を実施し，Self-Assessment Manikin を用いた主観的情動評価の\n比較およびSystem Usability Scale を用いたユーザビリティ評価を行った．その結果，シ\nステムを使用した場合の方が，快-不快，覚醒度，主導感（没入感）のすべての尺度にお\nいて評価が高く，統計的に有意な差が認められた．また，システム有無の鑑賞順序別の情\n動評価では，有意な差は確認されず，順序効果の影響は生じていないことが示された．こ\nれにより，システムの使用が情動評価に有効であることが示された．さらに，ユーザビリ\nティ評価の結果，システムを使用したアクション動画鑑賞後に十分に許容可能なユーザビ\nリティを有すると高く評価された．\n一方で，両条件における脈拍変動指標の変化について，周波数領域指標の一つである\nLF/HF に着目して分析した結果，30 分間のアクション動画鑑賞中の10 分ごとの推移にお\nいて，使用条件と非使用条件の間に顕著な違いは確認されなかった．したがって，本シス\nテムは主観的な情動評価には影響を与えたものの，LF/HF に対する擬似心拍刺激の効果\nは限定的であることが確認された．しかしながら，生理指標に関しては，動画鑑賞中の発\n汗度合いなど，興奮に関連する他の生理指標について検討が必要であり，今後の課題とし\nて取り組む必要がある．\n以上の結果を踏まえ，昂りに連動して振動および照明が同期した擬似心拍刺激を提示す\nるスマートフォンアクセサリーは，従来の動画鑑賞と比較して，使用時の負担を抑えつ\nつ，興奮をより高める効果を有し，主観的な情動体験の強化に寄与することが示された．\nこの成果を基に，本システムはスマートフォンによる動画鑑賞体験の拡張手法として有用\nであると考えられる．\n6.2\n今後の展望\n今後の展望としては，図6.1 に示すように，本システムにおけるさらなる取り組みとし\nて，熱を利用した温冷提示やアロマを活用した香りの提示など，他のフィードバック手法\nとの組み合わせを検討し，スマートフォンアクセサリーを拡張することで，多様な動画鑑\n賞体験の創出を目指す．また，動画鑑賞中のフィードバックが適切なタイミングで行われ\n82\nない場合，鑑賞体験を損なうリスクが高まることが考えられる．そのため，動画鑑賞時の\n昂りをより正確に判定するために，多様な年齢層や性別の被験者データを収集し，分析お\nよび分類精度の向上を行う必要がある．さらに，本研究で対象としたアクション動画に限\n定せず，コメディ動画や恋愛動画など，さまざまなジャンルの動画にも対応できる動画鑑\n賞システムの実現に取り組む．\n図6.1: 本システムにおける今後の取り組み\n83\n謝辞\n本研究はJSPS 科研費23K11961 の助成を受けたものです．\n本稿の執筆に際し，研究方針から丁寧なご指導を賜りました，青山学院大学理工学部情\n報テクノロジー学科Guillaume Lopez 教授に深く感謝申し上げます．また，副査として，\n提案手法や実験手法に対して様々な意見やご助言をいただきました青山学院大学理工学\n部情報テクノロジー学科DURST, Martin Jakob 教授に深く感謝申し上げます．そして，研\n究会などを通して客観的な視点でのアイデアの提供や，励ましをいただきましたウェアラ\nブル環境情報システム研究室の皆様，並びに，貴重な時間を割いて実験に協力していただ\nいた被験者の皆様に深く感謝いたします．最後に，学部生の時から常に心身を支えてくだ\nさった家族の皆様に心より感謝申し上げます．\n2025 年1 月31 日\n柴武志\n84\n参考文献\n[1] 日本生産性本部.\nレジャー白書2021 巻頭要約.\nhttps://www.jpc-net.jp/\nresearch/assets/pdf/summary2021_leisure.pdf, 9 2021.\n（最終参照\n日：2023/10/17）.\n[2] 日本生産性本部.\nレジャー白書2024 巻頭要約.\nhttps://www.jpc-net.jp/\nresearch/assets/pdf/summary2024_leisure.pdf, 10 2024. （最終参照\n日：2024/12/17）.\n[3] ICT 総研. 2023 年有料動画配信サービス利用動向に関する調査. https://ictr.\nco.jp/report/20230421.html/, 4 2023. （最終参照日：2023/10/17）.\n[4] モバイル社会研究所.\n10 代男女の約3 割が1 日6 時間以上スマホで動画を視\n聴.\nhttps://www.moba-ken.jp/project/lifestyle/20241021.html,\n10 2024. （最終参照日：2024/12/17）.\n[5] MediaMotion. Mx4d motion efx experience. https://www.mediamation.com/\nmx4d-theatres/. （最終参照日：2024/2/12）.\n[6] CJ 4DPLEX.\n4dx.\nhttps://www.cj4dplex.com/4dx.\n（最終参照日：\n2024/2/12）.\n[7] NHK. 映画を変えるか「vr映画」が切り開く新たな映像体験. https://www3.nhk.\nor.jp/news/special/sci_cul/2023/04/special/story_vr_movie/.\n（最終参照日：2024/2/12）.\n[8] Netﬂix. Interactive tv shows and movies on netﬂix. https://help.netflix.com/\nen/node/62526. （最終参照日：2024/2/12）.\n[9] 株式会社BCN. スマホの平均画面サイズ、「5.87 インチ」で高止まり？iphone の歴史\nとともに振り返ってみた. https://www.bcnretail.com/market/detail/\n20230325_321595.html, 3 2023. （最終参照日：2024/10/19）.\n[10] Jacob M Rigby, Duncan P Brumby, Anna L Cox, and Sandy JJ Gould. Watching movies\non netﬂix: investigating the effect of screen size on viewer immersion. In Proceedings\nof the 18th international conference on human-computer interaction with mobile devices\nand services adjunct, pp. 714–721, 2016.\n[11] Johanna Dunaway and Stuart Soroka. Smartphone-size screens constrain cognitive access\nto video news stories. Information, Communication & Society, Vol. 24, No. 1, pp. 69–84,\n2021.\n85\n[12] Jonah Berger, Yoon Duk Kim, and Robert Meyer. What makes content engaging? how\nemotional dynamics shape success. Journal of Consumer Research, Vol. 48, No. 2, pp.\n235–250, 2021.\n[13] Eran Dayan, Avi Barliya, Beatrice de Gelder, Talma Hendler, Rafael Malach, and Tamar\nFlash. Motion cues modulate responses to emotion in movies. Scientiﬁc reports, Vol. 8,\nNo. 1, p. 10881, 2018.\n[14] Larry Cahill, Richard J Haier, James Fallon, Michael T Alkire, Cheuk Tang, David\nKeator, Joseph Wu, and James L McGaugh.\nAmygdala activity at encoding corre-\nlated with long-term, free recall of emotional information. Proceedings of the National\nAcademy of sciences, Vol. 93, No. 15, pp. 8016–8021, 1996.\n[15] Dahlia W Zaidel. The art of ﬁlm: Perspective on neural clues to repeated attraction to\nmovie watching. Neuropsychologia, Vol. 180, p. 108485, 2023.\n[16] Jonah Berger. Arousal increases social transmission of information. Psychological sci-\nence, Vol. 22, No. 7, pp. 891–893, 2011.\n[17] Red\nMeat\nGames.\nBring\nto\nlight.\nhttps://redmeat.games/\nbring-to-light/. （最終参照日：2024/6/17）.\n[18] Flying Mollusk. Nevermind. https://nevermindgame.com. （最終参照日：\n2024/6/17）.\n[19] OVOMIND.\nOvomind home.\nhttps://ovomind.com/.\n（最終参照日：\n2024/10/15）.\n[20] ENO.\nAudio neuro-stimulation angle.\nhttps://getenophone.com/pages/\naudio-neuro-stimulation-angle. （最終参照日：2024/6/17）.\n[21] 新村出編. 広辞苑（第六版）. 岩波書店, 2008.\n[22] 白井真理子, 武藤世良, 中村真. 日本感情心理学会員が考える「感情とは何か」(1)―\n感情= 情動なのか―. 感情心理学研究, Vol. 28, No. Supplement, pp. ps17–ps17, 2020.\n[23] Andrew Ortony, Gerald L Clore, and Allan Collins. The cognitive structure of emotions.\nCambridge university press, 2022.\n[24] 大平英樹編. 感情心理学・入門. 有斐閣アルマ, 2010.\n[25] Ursula Hess and Pascal Thibault. Darwin and emotion expression. American Psycholo-\ngist, Vol. 64, No. 2, p. 120, 2009.\n[26] Paul Ekman and Wallace V Friesen. Constants across cultures in the face and emotion.\nJournal of personality and social psychology, Vol. 17, No. 2, p. 124, 1971.\n[27] James A Russell. A circumplex model of affect. Journal of personality and social psy-\nchology, Vol. 39, No. 6, p. 1161, 1980.\n86\n[28] James A Russell and James M Carroll. On the bipolarity of positive and negative affect.\nPsychological bulletin, Vol. 125, No. 1, p. 3, 1999.\n[29] 日本生理人類学会編. 人間科学の百科辞典. 丸善出版, 2015.\n[30] Hideki Ohira, Michio Nomura, Naho Ichikawa, Tokiko Isowa, Tetsuya Iidaka, Atsushi\nSato, Seisuke Fukuyama, Toshihiko Nakajima, and Jitsuhiro Yamada. Association of\nneural and physiological responses during voluntary emotion suppression. Neuroimage,\nVol. 29, No. 3, pp. 721–733, 2006.\n[31] Paul Ekman, Robert W Levenson, and Wallace V Friesen. Autonomic nervous system\nactivity distinguishes among emotions. science, Vol. 221, No. 4616, pp. 1208–1210,\n1983.\n[32] Ahmad Rauf Subahni, Likun Xia, and Aamir Saeed Malik. Association of mental stress\nwith video games. In 2012 4th International Conference on Intelligent and Advanced\nSystems (ICIAS2012), Vol. 1, pp. 82–85. IEEE, 2012.\n[33] Raj Rakshit, V Ramu Reddy, and Parijat Deshpande. Emotion detection and recognition\nusing hrv features derived from photoplethysmogram signals. In Proceedings of the 2nd\nworkshop on Emotion Representations and Modelling for Companion Systems, pp. 1–6,\n2016.\n[34] Kwang-Ho Choi, Junbeom Kim, O Sang Kwon, Min Ji Kim, Yeon Hee Ryu, and Ji-Eun\nPark. Is heart rate variability (hrv) an adequate tool for evaluating human emotions?–a\nfocus on the use of the international affective picture system (iaps). Psychiatry research,\nVol. 251, pp. 192–196, 2017.\n[35] Yan Wu, Ruolei Gu, Qiwei Yang, and Yue-jia Luo. How do amusement, anger and fear\ninﬂuence heart rate and heart rate variability? Frontiers in neuroscience, Vol. 13, p. 1131,\n2019.\n[36] Bin Yu, Mathias Funk, Jun Hu, and Loe Feijs. Stresstree: A metaphorical visualization\nfor biofeedback-assisted stress management. In Proceedings of the 2017 conference on\ndesigning interactive systems, pp. 333–337, 2017.\n[37] 多田有輝, 伊藤淳子, 宗森純ほか. スマートウォッチを用いた人の状況判定システム\nの開発. 2020 年度情報処理学会関西支部支部大会講演論文集, Vol. 2020, , 2020.\n[38] 金多賢, 北島宗雄, 李昇姫. 映像に対する嗜好と感情反応・印象評価の関係. 日本感\n性工学会論文誌, Vol. 13, No. 1, pp. 181–189, 2014.\n[39] Kamil Topal and Gultekin Ozsoyoglu. Movie review analysis: Emotion analysis of imdb\nmovie reviews. In 2016 IEEE/ACM International Conference on Advances in Social\nNetworks Analysis and Mining (ASONAM), pp. 1170–1176. IEEE, 2016.\n[40] Sokichi Sakuragi, Yoshiki Sugiyama, and Kiyomi Takeuchi. Effects of laughing and\nweeping on mood and heart rate variability. Journal of physiological anthropology and\napplied human science, Vol. 21, No. 3, pp. 159–165, 2002.\n87\n[41] 村瀬千春, 川本利恵子, 杉本助男. 視聴覚刺激による情動の変化-心拍変動の分析.\nJournal of UOEH, Vol. 26, No. 4, pp. 461–471, 2004.\n[42] 宮本晴司, 代蔵巧, 棟方渚, 小野哲雄ほか. 生体信号を用いた動画視聴中のユーザ評\n価の推定. エンタテインメントコンピューティングシンポジウム2015 論文集, Vol.\n2015, pp. 568–573, 2015.\n[43] Makoto Fukumoto and Yuuki Tsukino. Relationship of terror feelings and physiological\nresponse during watching horror movie. In Computer Information Systems and Industrial\nManagement: 14th IFIP TC 8 International Conference, CISIM 2015, Warsaw, Poland,\nSeptember 24-26, 2015, Proceedings 14, pp. 500–507. Springer, 2015.\n[44] Jo Vermeulen, Lindsay MacDonald, Johannes Sch¨oning, Russell Beale, and Sheelagh\nCarpendale. Heartefacts: augmenting mobile video sharing using wrist-worn heart rate\nsensors. In Proceedings of the 2016 ACM Conference on Designing Interactive Systems,\npp. 712–723, 2016.\n[45] 代蔵巧, 棟方渚, 小野哲雄ほか. E3-player: 鑑賞者の興奮を促進させる動画鑑賞シス\nテム. エンタテインメントコンピューティングシンポジウム2013 論文集, Vol. 2013,\npp. 272–277, 2013.\n[46] 角田啓介, 江口佳那, 吉田和広, 渡部智樹, 水野理ほか. 心拍と呼吸を用いたコンテン\nツ視聴による気分変化の推定: コメディ視聴における検討. 情報処理学会論文誌コン\nシューマ・デバイス& システム(CDS), Vol. 7, No. 1, pp. 44–52, 2017.\n[47] 吉田豊, 山本健人, 湯田恵美, 早野順一郎ほか. 心拍変動へ機械学習適用による映画\n視聴時の情動判別. 研究報告電子化知的財産・社会基盤(EIP), Vol. 2018, No. 10, pp.\n1–2, 2018.\n[48] Reika Takeshita, Aya Shoji, Tahera Hossain, Anna Yokokubo, and Guillaume Lopez.\nEmotion recognition from heart rate variability data of smartwatch while watching a\nvideo. In 2021 Thirteenth International Conference on Mobile Computing and Ubiq-\nuitous Network (ICMU), pp. 1–6. IEEE, 2021.\n[49] Reika Takeshita, Anna Yokokubo, and Guillaume Lopez. Proposal for an individually\nadapted video viewing system linked to the user ’s feeling of fear. In Extended Abstracts\nof the 2022 Annual Symposium on Computer-Human Interaction in Play, pp. 166–170,\n2022.\n[50] Paul Lemmens, Floris Crompvoets, Dirk Brokken, Jack Van Den Eerenbeemd, and Gert-\nJan de Vries.\nA body-conforming tactile jacket to enrich movie viewing.\nIn World\nHaptics 2009-Third Joint EuroHaptics conference and Symposium on Haptic Interfaces\nfor Virtual Environment and Teleoperator Systems, pp. 7–12. IEEE, 2009.\n[51] Caitlyn Seim, James Hallam, Shashank Raghu, Tri-An Le, Greg Bishop, and Thad\nStarner. Perception in hand-worn haptics: placement, simultaneous stimuli, and vibration\nmotor comparisons. 2015.\n88\n[52] Antonella Mazzoni and Nick Bryan-Kinns. Mood glove: A haptic wearable prototype\nsystem to enhance mood music in ﬁlm. Entertainment Computing, Vol. 17, pp. 9–17,\n2016.\n[53] Damien Ablart, Carlos Velasco, and Marianna Obrist. Integrating mid-air haptics into\nmovie experiences. In Proceedings of the 2017 ACM international conference on inter-\nactive experiences for TV and online video, pp. 77–84, 2017.\n[54] Dawoon Jeong, Sung H Han, Kimin Kwon, and Wan Sun Shin. Emotional and physiolog-\nical responses to the roll motion effect in 4d movies. Affective and Pleasurable Design,\nVol. 41, No. 41, 2022.\n[55] Yuki Kosuge, Yumeka Ogura, and Shogo Okamoto. Vibration to upper body manipulates\njoyful experience while viewing emotional scenes. In 2023 IEEE 12th Global Conference\non Consumer Electronics (GCCE), pp. 613–615. IEEE, 2023.\n[56] V´ıctor Cerd´an-Mart´ınez, ´Alvaro Garc´ıa-L´opez, Pablo Revuelta-Sanz, Tom´as Ortiz, and\nRicardo Vergaz. Haptic stimulation during the viewing of a ﬁlm: an eeg-based study.\nMultimedia Tools and Applications, pp. 1–14, 2024.\n[57] Ibuki Tara, Shogo Okamoto, Yasuhiro Akiyama, and Hidetaka Ozeki. Timing of vibra-\ntory stimuli to the upper body for enhancing fear and excitement of audio-visual content.\nInternational Journal of Affective Engineering, Vol. 22, No. 2, pp. 105–113, 2023.\n[58] Vicente Ortiz-Garc´ıa-Cervig´on, Marina V Sokolova, Rosa Mar´ıa Garc´ıa-Mu˜noz, and An-\ntonio Fern´andez-Caballero. Led strips for color-and illumination-based emotion regula-\ntion at home. In Ambient Assisted Living. ICT-based Solutions in Real Life Situations:\n7th International Work-Conference, IWAAL 2015, Puerto Varas, Chile, December 1-4,\n2015, Proceedings 7, pp. 277–287. Springer, 2015.\n[59] Takuya Iwamoto and Soh Masuko. Lovable couch: Mitigating distrustful feelings for\ncouples by visualizing excitation. In Proceedings of the 6th Augmented Human Interna-\ntional Conference, pp. 157–158, 2015.\n[60] Lisa Wilms and Daniel Oberfeld. Color and emotion: effects of hue, saturation, and\nbrightness. Psychological research, Vol. 82, No. 5, pp. 896–914, 2018.\n[61] Marieke Lieve Weijs, Domicele Jonauskaite, Ricarda Reutimann, Christine Mohr, and\nBigna Lenggenhager. Effects of environmental colours in virtual reality: Physiological\narousal affected by lightness and hue. Royal Society Open Science, Vol. 10, No. 10, p.\n230432, 2023.\n[62] Vanessa L Buechner and Markus A Maier. Not always a matter of context: direct effects\nof red on arousal but context-dependent moderations on valence. PeerJ, Vol. 4, p. e2515,\n2016.\n89\n[63] Dong Keun Kim, Sangmin Ahn, Sangin Park, and Mincheol Whang. Interactive emo-\ntional lighting system using physiological signals. IEEE Transactions on Consumer Elec-\ntronics, Vol. 59, No. 4, pp. 765–771, 2013.\n[64] Yu-Bin Shin, Seung-Hyun Woo, Dong-Hyeon Kim, Jinseong Kim, Jae-Jin Kim, and\nJin Young Park. The effect on emotions and brain activity by the direct/indirect lighting\nin the residential environment. Neuroscience letters, Vol. 584, pp. 28–32, 2015.\n[65] 馬場哲晃, 笠松慶子, 土井幸輝, 串山久美子ほか. 温冷呈示を利用したビデオゲームイ\nンタラクションにおける手法の検討と開発. 情報処理学会論文誌, Vol. 53, No. 3, pp.\n1082–1091, 2012.\n[66] Ryota Tsuruno, Kentaro Kotani, Satoshi Suzuki, and Takafumi Asao. Use of presentation\nof thermal stimulus for enhancing excitement during video viewing. In Proceedings of\nthe 20th Congress of the International Ergonomics Association (IEA 2018) Volume X:\nAuditory and Vocal Ergonomics, Visual Ergonomics, Psychophysiology in Ergonomics,\nErgonomics in Advanced Imaging 20, pp. 366–370. Springer, 2019.\n[67] Andrew Dekker and Erik Champion. Please biofeed the zombies: enhancing the game-\nplay and display of a horror game using biofeedback. In DiGRA’07-Proceedings of the\n2007 DiGRA International Conference: Situated Play, pp. 550–558, 2007.\n[68] 荒木勇人, 池田太一, 落合優介, 阿部将之, 小澤拓海, 一瀬啓太, 佐久間拓也, 川合康央.\nユーザの脈拍数に応じて演出が変化する没入感を高めたホラーゲームの開発, 2017.\n[69] William James. What is an emotion? Mind, Vol. 9, No. 34, pp. 188–205, 1884.\n[70] Walter B Cannon. The james-lange theory of emotions: A critical examination and an\nalternative theory. The American journal of psychology, Vol. 39, No. 1/4, pp. 106–124,\n1927.\n[71] Stanley Schachter and Jerome Singer. Cognitive, social, and physiological determinants\nof emotional state. Psychological review, Vol. 69, No. 5, p. 379, 1962.\n[72] Jeff T Larsen, Gary G Berntson, Kirsten M Poehlmann, Tiffany A Ito, and John T Ca-\ncioppo. The psychophysiology of emotion. Handbook of emotions, Vol. 3, pp. 180–195,\n2008.\n[73] 鈴木直人編. 感情心理学. 朝倉書店, 2017.\n[74] Stuart Valins. Cognitive effects of false heart-rate feedback. Journal of personality and\nsocial psychology, Vol. 4, No. 4, p. 400, 1966.\n[75] Yoshio Inamori. Effects of false heart rate feedback on cognitive appraisal and physio-\nlogical responses to emotional stimuli. Japanese Psychological Research, Vol. 21, No. 3,\npp. 153–157, 1979.\n90\n[76] Marcus A Gray, Neil A Harrison, Stefan Wiens, and Hugo D Critchley. Modulation of\nemotional appraisal by false physiological feedback during fmri. PLoS one, Vol. 2, No. 6,\np. e546, 2007.\n[77] Narihiro Nishimura, Taku Hachisu, Michi Sato, Shogo Fukushima, and Hiroyuki Kaji-\nmoto. Evaluation of a tactile device for augmentation of audiovisual experiences with a\npseudo heartbeat. In Proceedings of the 4th Augmented Human International Conference,\npp. 242–242, 2013.\n[78] Ryoko Ueoka and Kouya Ishigaki. Development of the horror emotion ampliﬁcation\nsystem by means of biofeedback method.\nIn Human Interface and the Management\nof Information. Information and Knowledge in Context: 17th International Conference,\nHCI International 2015, Los Angeles, CA, USA, August 2-7, 2015, Proceedings, Part II\n17, pp. 657–665. Springer, 2015.\n[79] Erik Pescara, Alexander Wolpert, Matthias Budde, Andrea Schankin, and Michael Beigl.\nLifetact: utilizing smartwatches as tactile heartbeat displays in video games. In Proceed-\nings of the 16th International Conference on Mobile and Ubiquitous Multimedia, pp.\n97–101, 2017.\n[80] Sayaka Ogawa, Koichi Fujiwara, and Manabu Kano. Auditory feedback of false heart\nrate for video game experience improvement. IEEE Transactions on Affective Computing,\nVol. 14, No. 1, pp. 487–497, 2020.\n[81] Masaki Omata and Yuta Nakada. An implementation of a pseudo-beat presentation de-\nvice affecting emotion of a smartphone video viewer. In CHIRA, pp. 149–157, 2021.\n[82] Ruoqi Wang, Haifeng Zhang, Shaun Alexander Macdonald, and Patrizia Di Campli\nSan Vito. Increasing heart rate and anxiety level with vibrotactile and audio presentation\nof fast heartbeat. In Proceedings of the 25th International Conference on Multimodal\nInteraction, pp. 355–363, 2023.\n[83] Kyung Yun Choi and Hiroshi Ishii. ambienbeat: Wrist-worn mobile tactile biofeedback\nfor heart rate rhythmic regulation. In Proceedings of the fourteenth international confer-\nence on tangible, embedded, and embodied interaction, pp. 17–30, 2020.\n[84] Polar. M600 ユーザマニュアル. https://support.polar.com/e_manuals/\nM600/wear-os/polar-m600-user-manual-japanese/Content/\nintroduction.htm. (参照日2022/1/3).\n[85] The Internet Movie Database. Terminator 2: Judgment day. https://www.imdb.\ncom/title/tt0103064/. （最終参照日：2024/7/19）.\n[86] Apple.\niphone13 pro - 技術仕様.\nhttps://support.apple.com/ja-jp/\n111871. （最終参照日：2024/3/18）.\n91\n[87] Helen J Michielsen, Jolanda De Vries, and Guus L Van Heck. Psychometric qualities of a\nbrief self-rated fatigue measure: The fatigue assessment scale. Journal of psychosomatic\nresearch, Vol. 54, No. 4, pp. 345–352, 2003.\n[88] Task Force of the European Society of Cardiology the North American Society of Pac-\ning Electrophysiology. Heart rate variability: standards of measurement, physiological\ninterpretation, and clinical use. Circulation, Vol. 93, No. 5, pp. 1043–1065, 1996.\n[89] Mirja A Peltola. Role of editing of r–r intervals in the analysis of heart rate variability.\nFrontiers in physiology, Vol. 3, p. 148, 2012.\n[90] 駒澤真人, 板生研一, 羅志偉. スマートフォンのカメラを用いた心拍変動解析システ\nムの開発. 第20 回人間情報学会ポスター発表集, pp. 19–20, 2014.\n[91] Delphine Rommel, JL Nandrino, M Jeanne, R Logier, et al. Heart rate variability analysis\nas an index of emotion regulation processes: interest of the analgesia nociception index\n(ani). In 2012 Annual international conference of the IEEE engineering in medicine and\nbiology society, pp. 3432–3435. IEEE, 2012.\n[92] 櫻井優太, 清水遵. 感情体験と生理指標の共変動―感情リアルタイム評定法による時\n系列的検討―. 感情心理学研究, Vol. 20, No. Supplement, pp. 44–44, 2013.\n[93] Python. About python. https://www.python.org/about/. （最終参照日：\n2024/9/26）.\n[94] scikit learn. scikit-learn: machine learning in python. https://scikit-learn.\norg/stable/#. （最終参照日：2024/9/26）.\n[95] scikit learn.\nStratiﬁedshufﬂesplit - scikit-learn.\nhttps://scikit-learn.\norg/stable/modules/generated/sklearn.model_selection.\nStratifiedShuffleSplit.html. （最終参照日：2024/9/26）.\n[96] The university of Waikato.\nSoftware - university of waikato.\nhttps:\n//www.waikato.ac.nz/research/institutes-centres-entities/\ninstitutes/artificial-intelligence-institute/research/\nsoftware/. （最終参照日：2024/9/26）.\n[97] Google. Firebase realtime database. https://firebase.google.com/docs/\ndatabase?hl=ja. （最終参照日：2024/10/21）.\n[98] M5Stack. Atom-lite. https://docs.m5stack.com/en/core/ATOM%20Lite.\n（最終参照日：2024/10/21）.\n[99] M5Stack. Unit vibrator. https://docs.m5stack.com/en/unit/vibrator.\n（最終参照日：2024/10/21）.\n[100] Arduino.\nArduino uno r4 minima.\nhttps://docs.arduino.cc/hardware/\nuno-r4-minima/. （最終参照日：2024/10/21）.\n92\n[101] SparkFun Electronics.\nSparkfun haptic motor driver - drv2605l.\nhttps://www.\nsparkfun.com/sparkfun-haptic-motor-driver-drv2605l.html.（最\n終参照日：2024/9/28）.\n[102] フォスター電機株式会社.\nバイブレーションアクチュエータ.\nhttps://www.\nfoster.co.jp/products/productdata/VCA_C25_639897.pdf.（最終参\n照日：2024/10/22）.\n[103] BitTradeOne. 触感デバイス開発/体感モジュール“ hapstak ”. https://github.\ncom/bit-trade-one/ADACHACY-hapStak. （最終参照日：2024/10/22）.\n[104] M5Stack.\nAtom-matrix.\nhttps://docs.m5stack.com/en/core/ATOM%\n20Matrix. （最終参照日：2024/10/21）.\n[105] M5Stack. Tail bat. https://docs.m5stack.com/en/atom/tailbat. （最終\n参照日：2024/10/21）.\n[106] 宮岡徹. ヒト触覚情報処理の基礎. 計測と制御, Vol. 47, No. 7, pp. 554–560, 2008.\n[107] Takuji Narumi, Yuki Ban, Takashi Kajinami, Tomohiro Tanikawa, and Michitaka Hirose.\nAugmented perception of satiety: controlling food consumption by changing apparent\nsize of food with augmented reality. In Proceedings of the SIGCHI conference on human\nfactors in computing systems, pp. 109–118, 2012.\n[108] Yuki Ban, Takuji Narumi, Tomohiro Tanikawa, and Michitaka Hirose. Modifying per-\nceived size of a handled object through hand image deformation. Presence: Teleoperators\nand Virtual Environments, Vol. 22, No. 3, pp. 255–270, 2013.\n[109] M5Stack. Unbuckled grove cable. https://shop.m5stack.com/products/\n4pin-buckled-grove-cable. （最終参照日：2024/10/21）.\n[110] M5Stack.\nSk6812 digital rgb led strip.\nhttps://shop.m5stack.com/\nproducts/sk6812-rgb-led-flex-strip?variant=32042216882266.\n（最終参照日：2024/10/21）.\n[111] Peter J Snyder and Harry A Whitaker. Neurologic heuristics and artistic whimsy: The\ncerebral cartography of wilder penﬁeld. Journal of the History of the Neurosciences,\nVol. 22, No. 3, pp. 277–291, 2013.\n[112] ピカリ館. 角形シリコンチューブ. https://www.akiba-led.jp/product/\n530?srsltid=AfmBOoqeElZ7OEJ5GluaK-zVtA14aQh14yznue0NpB_\nO-1A_BRzNU_aT. （最終参照日：2024/11/10）.\n[113] Paramount Pictures.\n『ミッション：インポッシブル』シリーズ.\nhttps://\nparamount.jp/mi-dvd/mi3/index.html. （最終参照日：2024/12/10）.\n[114] Margaret M Bradley and Peter J Lang. Measuring emotion: the self-assessment manikin\nand the semantic differential. Journal of behavior therapy and experimental psychiatry,\nVol. 25, No. 1, pp. 49–59, 1994.\n93\n[115] J Brooke. Sus: A quick and dirty usability scale. Usability Evaluation in Industry, 1996.\n[116] Borja F Villar, Pablo F Vi˜nas, Javier P Turiel, J Carlos Fraile Marinero, and Alfonso\nGordaliza. Inﬂuence on the user’s emotional state of the graphic complexity level in vir-\ntual therapies based on a robot-assisted neuro-rehabilitation platform. Computer Methods\nand Programs in Biomedicine, Vol. 190, p. 105359, 2020.\n[117] Aaron Bangor, Philip Kortum, and James Miller. Determining what individual sus scores\nmean: Adding an adjective rating scale. Journal of usability studies, Vol. 4, No. 3, pp.\n114–123, 2009.\n[118] KUROCO. t 検定とはexcel で分析を行う方法を解説. https://kuroco.team/\nblog-data-t-test-excel/. （最終参照日：2025/1/10）.\n94\n付録A\n本研究に関する発表実績\n1. 柴武志，竹下怜花，ロペズギヨーム: MEASc：動画恐怖体験拡張スマートフォン\nケース, マルチメディア, 分散, 協調とモバイル(DICOMO2023) シンポジウム論文集,\npp.853-859(2023)\n2. Takeshi Shiba，Reika Takeshita，Guillaume Lopez，\n“Development of a Smartphone Case\nfor Horror Movie Experience Augmentation ”, The International Conference on Activity\nand Behavior computing, 2023, @Deutsches Forschungszentrum f¨ur K¨unstliche Intelli-\ngenz Kaiserslautern\n95\n質疑応答\n工藤聖人情報テクノロジー学科助手\nQ\nなぜ暗いところで評価実験を行ったのですか？\nA\n理由は2 点あります．1 点目は，照明をフィードバックとして利用しているた\nめです．擬似心拍刺激を赤色光で提示することで，十分な効果を与えられると\n考えました．2 点目は，赤色光が情動に与える影響に関する関連研究に基づい\nているためです．複数の関連研究では，実験環境として暗室が用いられており，\n情動に作用する可能性が示された研究結果は，暗室環境を前提としたものであ\nることを考慮しました．\n工藤聖人情報テクノロジー学科助手\nQ\n暗い中で30 分動画見る上で画面の明るさが負担になり得ると思いますが，そ\nの影響は？\nA\n実験において，暗室内で約30 分間のアクション動画を鑑賞することは，眼精\n疲労を誘発する可能性が考えられます．しかし，鑑賞前に各被験者に対し，動\n画の冒頭1 分程度を再生して画面の輝度を調整するよう指示し，実際に調整を\n行った上で鑑賞してもらうことで，負担の影響を抑えました．\n浦垣啓志郎情報テクノロジー学科助手\nQ\n今後の課題の4DX 化みたいなことをしてシステムが肥大化しすぎると映画館\nで良いのでは？となるので，スマートフォンだからこそできるフィードバック\n(映画館では実現できないフィードバック) を模索してみると面白いと思いまし\nた．\nA\n貴重なご意見ありがとうございます．本研究では，映画館での4DX 体験をそ\nのままスマートフォンに移植するのではなく，個々人で鑑賞するという体型を\n活かしたフィードバックを重視しています．具体的には，鑑賞者の生理的反応\nに基づいて判定する昂りに連動して個別なタイミングでフィードバックを提供\nする点が特徴であり，これは映画館のような大規模環境では実現が確認されて\nいない手法です．今後の課題としても，スマートフォンならではの利点を活か\nしたフィードバックのあり方を模索し，スマートフォンアクセサリーの拡張に\nよって，多様な動画鑑賞体験の創出を目指します．\n96\n",
        "chunks": [
            "M2024_Takeshi_Shiba. M2024_Takeshi_Shiba. M2024_Takeshi_Shiba",
            " \n \n \n \n \n青  山  学  院  大  学 \n \n理  工  学  研  究  科 \n \n \n \n理工学専攻    知能情報    コース \n \n \n \n \n修  士  論  文 \n \n \n \n       学 生 番 号      35623235         \n \n \n       氏     名     柴 武志         \n \n \n研究指導教員    Guillaume Lopez        \n \n理工学専攻修士論文要旨 \n \n \n提出年度： 2024 年度 \n提出日： 2025 年1 月31 日 \n専修コース： 知能情報 コース \n学生番号： 35623235 \n学生氏名： 柴 武志 \n研究指導教員： ロペズ・ギヨーム 教授 \n \n（論文題目） \n \n昂りに連動した動画鑑賞体験拡張スマートフォンアクセサリー \n \n（内容の要旨） \n現在，動画鑑賞は多くの人に親しまれている余暇活動の一つとして定着しており，その主な鑑賞媒体\nとしてスマートフォンが広く利用されている．しかし，スマートフォンによる動画鑑賞では，画面サイ\nズの制約により視聴覚刺激が限定されるた",
            "れている．しかし，スマートフォンによる動画鑑賞では，画面サイ\nズの制約により視聴覚刺激が限定されるため，映画館やテレビのような大画面での鑑賞と比較して没入\n感や情動体験の強度が弱まることが指摘されている．また，横揺れや風などの4D 技術は映画館でしか\n体験できないため，スマートフォンでの動画鑑賞体験の拡張及び，それに伴う情動体験の強化に課題が\nある．本研究は，動画鑑賞中のユーザの脈拍変動に基づいて判定する昂りに連動したフィードバックを\n行うことで，スマートフォンを用いた動画鑑賞体験の拡張を目指す． \nアクション動画鑑賞中のユーザの昂り状態を判定する機械学習モデルを構築するにあたり，9 名の被\n験者を対象に，アクション動画鑑賞中の脈拍変動データをスマートウォッチの脈拍センサから，昂りの\n時間情報を主観表記から収集した．脈拍変動指標を用いて11 個の特徴量を算出し，主観的昂りの時間\n情報を基に「昂り」あるいは「昂りでない」のラベルを付与して，ランダムフォレストによる分類モデ\nルを構築した結果，重視している再現率において，82%の精度で「昂り」と分類することを確認した．\nこの機械学習モデルを",
            "，重視している再現率において，82%の精度で「昂り」と分類することを確認した．\nこの機械学習モデルを応用し，アクション動画鑑賞時にスマートウォッチの脈拍センサを用いた，リア\nルタイムな昂り判定するアプリケーションを開発した．さらに，判定結果に連動して振動と照明が同期\nした擬似心拍刺激を提示するアクセサリーを製作した．前述アプリケーションで，「昂り」と判定された\n場合，ユーザの脈拍数情報をクラウド経由でアクセサリーに送信し，それに基づき振動と照明が同期し\nた擬似心拍刺激を提示する．アクセサリーはスマートフォンを装着可能なハンドケース型に設計し，振\n動は振動アクチュエータを用いて手のひらに，照明は赤色LED にてアクセサリー周囲に提示される． \n本システムを用いたアクション動画鑑賞による情動体験への影響を検証するため，12 名の被験者を\n対象にアクション動画鑑賞実験を実施した．暗室環境で，被験者は30 分程度のアクション動画鑑賞を\nシステムの使用条件と非使用条件の2 条件で実施した．条件の順序は被験者ごとにランダムに設定し，\n同一動画を別日に鑑賞させた．鑑賞後，Self-Assessmen",
            "序は被験者ごとにランダムに設定し，\n同一動画を別日に鑑賞させた．鑑賞後，Self-Assessment Manikin を用いた主観的情動を評価し，使用\n条件ではSystem Usability Scale によるシステムのユーザビリティについても評価した．情動評価にお\nいて，システムを使用した場合の方が快-不快，覚醒度，主導感（没入感）の全ての尺度で有意に高い評\n価が認められた．さらに，両条件の鑑賞順序による情動評価のバイアスが確認されなかったことで，本\nシステムが情動評価に有効な影響を与えた．また，ユーザビリティ評価では，使用条件におけるアクシ\nョン動画鑑賞を経て，十分に許容されるユーザビリティを持つものとして高く評価された．一方で，脈\n拍変動指標の変化を，周波数領域指標の1 つであるLF/HF（低周波と高周波の強度の比）に着目して比\n較したが，両条件間の顕著な違いは確認されなかった．したがって，本研究のシステムは，主観的な情\n動評価には影響を与えたものの，生理指標に対する擬似心拍刺激の効果は限定的であることが分かった． \n今後の展望として，熱や香りの噴射などの他のフィードバック手",
            "激の効果は限定的であることが分かった． \n今後の展望として，熱や香りの噴射などの他のフィードバック手法との組み合わせを検討し，スマー\nトフォンアクセサリーを拡張することで多様な動画鑑賞体験を創出する．また，アクション動画だけで\nなく，コメディ動画や恋愛動画など多種なジャンルにも対応するシステムを実現に取り組む． \n \n \n青山学院大学大学院理工学研究科 \nAcademic Year of 2024, Submitted on January 31, 2025 \n \nGraduate School of Science and Engineering, Aoyama Gakuin University \n \nTitle: Smartphone Accessory for Enhancing the Video Viewing Experience Linked to \nArousal \n \nStudent Name: Takeshi Shiba \nID Number: 35623235 \nDegree: Master of Engineering \nCourse: Intelligenc",
            "Degree: Master of Engineering \nCourse: Intelligence and Information \nThesis Advisor: Professor Guillaume Lopez \nAbstract  \nCurrently, smartphones are used as the main medium for watching videos. However, \nit has been pointed out that the size of the screen reduces the intensity of the immersive \nand emotional experience compared to large screens, such as in a movie theater or \ntelevision. Moreover, 4D technologies such as lateral shaking and wind can only be \nexperienced in movie theaters. \nThis",
            " can only be \nexperienced in movie theaters. \nThis research aims to extend the view experience of videos on smartphones by \nproviding feedback linked to the user's arousal. Specifically, it produced a smartphone \naccessory that presents multi-modal pseudo-heartbeat stimulation based on the use’s \nstate of arousal while watching action movies. \nIn the developed system, the user’s current state of arousal is estimated using a \nmachine learning model created in preliminary experiments based on puls",
            "l created in preliminary experiments based on pulse rate \nvariability (PRV) data acquired by the pulse rate sensor of a smartwatch. The accessory \nis designed as a case that holds the smartphone in its center and can be held with both \nhands. It can provide vibration to the palm using a vibration actuator and illumination \nusing red light from LEDs surrounding the case. The pseudo-heartbeat stimulation is \nadjusted according to the user's pulse rate at the timing of arousal judgment.  \nThe syste",
            "ate at the timing of arousal judgment.  \nThe system’s effectiveness was verified by conducting an action video-watching \nexperiment on 12 subjects who watched a 30-minute action video under two conditions: \nusing and not using the system. After watching the video, subjective emotional \nevaluation was conducted using the Self-Assessment Manikin and usability evaluation \nusing the System Usability Scale. The results of the emotional experience evaluation \nshowed that the developed system provided ",
            "uation \nshowed that the developed system provided significantly higher in valence, arousal, and \ndominance (sense of immersion). Besides, the usability evaluation proved that the \ndeveloped system had sufficiently acceptable usability. Changes in PRV indices under \nboth conditions were compared, focusing on the LF/HF (PRV frequency spectrum low \nand high-frequency power ratio) value. Still, no significant differences were observed \nbetween the two conditions, indicating that the effect of pseudo",
            "o conditions, indicating that the effect of pseudo-heartbeat stimulation \non LF/HF was limited. \nFuture prospects include considering the combination with other feedback methods, \nsuch as heat and scent injection, and expanding the accessory to handle a wider variety \nof genres, including comedy and romance videos \n昂りに連動した動画鑑賞体験拡張\nスマートフォンアクセサリー\n柴武志\n2025/01/31\n目次\n第1 章\n序章\n4\n1.1\n研究背景. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n4\n1.1.1\n動画鑑賞の普及とスマートフォン利用の現状. . . . . . . .",
            " . . .\n4\n1.1.1\n動画鑑賞の普及とスマートフォン利用の現状. . . . . . . . . . . . .\n4\n1.1.2\n動画鑑賞体験を拡張する取り組み. . . . . . . . . . . . . . . . . . .\n6\n1.1.3\nスマートフォンを利用した鑑賞体験における課題. . . . . . . . . .\n7\n1.1.4\n動画鑑賞における情動強化の重要性\n. . . . . . . . . . . . . . . . .\n8\n1.1.5\nエンターテイメント領域への生体信号の活用. . . . . . . . . . . . .\n9\n1.2\n研究の目的および目標. . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n9\n1.3\n本論文の構成. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n10\n第2 章\n関連研究\n11\n2.1\n情動と心拍変動. . . . . . . . . . . . . . . . . ",
            "究\n11\n2.1\n情動と心拍変動. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n11\n2.1.1\n感情の種類と情動\n. . . . . . . . . . . . . . . . . . . . . . . . . . .\n11\n2.1.2\n心拍変動と情動の関係. . . . . . . . . . . . . . . . . . . . . . . . .\n13\n2.1.3\n心拍変動を用いた情動評価に関する研究. . . . . . . . . . . . . . .\n14\n2.2\n動画鑑賞と情動. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n15\n2.2.1\n動画に対する印象及び嗜好に関する研究. . . . . . . . . . . . . . .\n15\n2.2.2\n動画鑑賞中の生理反応と映像の関係に関する研究. . . . . . . . . .\n16\n2.2.3\n動画鑑賞時の情動評価に関する研究\n. . . ",
            ". . . . . . . . .\n16\n2.2.3\n動画鑑賞時の情動評価に関する研究\n. . . . . . . . . . . . . . . . .\n16\n2.3\n外部刺激によるユーザ体験の強化. . . . . . . . . . . . . . . . . . . . . . .\n18\n2.3.1\n振動刺激による影響に関する研究. . . . . . . . . . . . . . . . . . .\n18\n2.3.2\n照明刺激による影響に関する研究. . . . . . . . . . . . . . . . . . .\n20\n2.3.3\n温冷刺激による影響に関する研究. . . . . . . . . . . . . . . . . . .\n21\n2.3.4\n生体信号に基づいた演出変化による影響に関する研究. . . . . . . .\n22\n2.4\n情動喚起の機序理論とその応用. . . . . . . . . . . . . . . . . . . . . . . .\n22\n2.4.1\n情動喚起の機序. . . . . . . . . . . . . . . . . ",
            "22\n2.4.1\n情動喚起の機序. . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n22\n2.4.2\n擬似心拍刺激を利用した情動喚起に関する研究\n. . . . . . . . . . .\n23\n第3 章\n脈拍変動を用いたアクション動画鑑賞時の昂り状態の分類\n26\n3.1\nアクション動画鑑賞時の脈拍間隔の収集. . . . . . . . . . . . . . . . . . .\n26\n3.1.1\n脈拍間隔の収集目的\n. . . . . . . . . . . . . . . . . . . . . . . . . .\n26\n3.1.2\n収集実験の概要. . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n26\n3.1.3\nアクション動画鑑賞に関する質問票\n. . . . . . . . . . . . . . . . .\n27\n3.1.4\n収集実験の手順. . . . . . . . . . . . . . . . . . . . . . . . . . . ",
            ". . . . . . . . . . . . . . . . . . . . . . . . . . .\n29\n3.2\n疲労感および興奮度合いに関する質問票の結果\n. . . . . . . . . . . . . . .\n30\n3.2.1\n疲労感に関する質問票への回答結果\n. . . . . . . . . . . . . . . . .\n30\n1\n3.2.2\n興奮度合いに関する質問票への回答結果. . . . . . . . . . . . . . .\n31\n3.3\n脈拍間隔に対する特徴量の算出. . . . . . . . . . . . . . . . . . . . . . . .\n31\n3.3.1\n記録した脈拍間隔および情動的な昂り\n. . . . . . . . . . . . . . . .\n31\n3.3.2\n脈拍変動の解析手法\n. . . . . . . . . . . . . . . . . . . . . . . . . .\n33\n3.3.3\n時系列の脈拍間隔に対する前処理. . . . . . . . . . . . . . . . . . .\n34\n3.3.",
            "する前処理. . . . . . . . . . . . . . . . . . .\n34\n3.3.4\n特徴量の算出. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n35\n3.4\nラベル付けとデータセットの作成. . . . . . . . . . . . . . . . . . . . . . .\n37\n3.4.1\nラベル付けの目的\n. . . . . . . . . . . . . . . . . . . . . . . . . . .\n37\n3.4.2\nラベル付けの基準\n. . . . . . . . . . . . . . . . . . . . . . . . . . .\n37\n3.4.3\nデータセットの作成\n. . . . . . . . . . . . . . . . . . . . . . . . . .\n38\n3.5\n機械学習アルゴリズムの選定と機械学習モデルの作成. . . . . . . . . . . .\n39\n3.5.1\n機械学習アルゴリズムの選定\n. . . . . . . . . . .",
            ". . .\n39\n3.5.1\n機械学習アルゴリズムの選定\n. . . . . . . . . . . . . . . . . . . . .\n39\n3.5.2\n選定した機械学習アルゴリズムによる分類性能\n. . . . . . . . . . .\n40\n3.5.3\n機械学習モデルの作成. . . . . . . . . . . . . . . . . . . . . . . . .\n41\n第4 章\n昂りに連動した動画鑑賞体験拡張スマートフォンアクセサリー\n43\n4.1\nシステムの概要. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n43\n4.1.1\nシステムの構成. . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n43\n4.1.2\nシステムの動作の流れ. . . . . . . . . . . . . . . . . . . . . . . . .\n44\n4.2\n昂り判定に連動した擬似心拍刺激. . . . . . . . . . . . .",
            " .\n44\n4.2\n昂り判定に連動した擬似心拍刺激. . . . . . . . . . . . . . . . . . . . . . .\n45\n4.2.1\n擬似心拍刺激を提示する目的\n. . . . . . . . . . . . . . . . . . . . .\n45\n4.2.2\n振動を提示する機器の検討\n. . . . . . . . . . . . . . . . . . . . . .\n46\n4.2.3\n振動を利用した擬似心拍刺激\n. . . . . . . . . . . . . . . . . . . . .\n49\n4.2.4\n照明を利用した擬似心拍刺激\n. . . . . . . . . . . . . . . . . . . . .\n51\n4.2.5\nユーザの心拍数に基づく擬似心拍刺激の対応. . . . . . . . . . . . .\n52\n4.3\n昂りに連動したスマートフォンアクセサリー. . . . . . . . . . . . . . . . .\n53\n4.3.1\n振動提示の設計. . . . . . . . . . . . . . . . . . ",
            "\n4.3.1\n振動提示の設計. . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n53\n4.3.2\n照明提示の設計. . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n54\n4.3.3\nスマートフォンアクセサリーの構造\n. . . . . . . . . . . . . . . . .\n55\n4.3.4\nスマートフォンアクセサリーを使用した動画鑑賞方法. . . . . . . .\n58\n第5 章\nスマートフォンアクセサリーによるアクション動画鑑賞時の情動体験の影響59\n5.1\nアクション動画における鑑賞体験への影響の検証. . . . . . . . . . . . . .\n59\n5.1.1\n実験目的\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n59\n5.1.2\n実験概要\n. . . . . . . . . . . . . . . . . . . . . . . . . . . ",
            ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n59\n5.1.3\n鑑賞体験を測定する指標. . . . . . . . . . . . . . . . . . . . . . . .\n60\n5.1.4\n実験手順\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n61\n5.2\n定性評価の結果および考察. . . . . . . . . . . . . . . . . . . . . . . . . . .\n63\n5.2.1\nシステムの有無での情動評価の比較\n. . . . . . . . . . . . . . . . .\n63\n5.2.2\nシステム無での1 回目と2 回目の鑑賞時の情動評価の比較. . . . .\n66\n5.2.3\nシステム有での1 回目と2 回目の鑑賞時の情動評価の比較. . . . .\n69\n5.2.4\n快適性および使用感の評価\n. . . . . . . . . . . . . . . . . . . . . .\n7",
            "感の評価\n. . . . . . . . . . . . . . . . . . . . . .\n72\n2\n5.2.5\n擬似心拍刺激を伴うアクション動画鑑賞の評価\n. . . . . . . . . . .\n73\n5.2.6\n情動評価の結果に対する考察\n. . . . . . . . . . . . . . . . . . . . .\n74\n5.2.7\n快適性および使用感の評価に対する考察. . . . . . . . . . . . . . .\n75\n5.3\n定量評価の結果および考察. . . . . . . . . . . . . . . . . . . . . . . . . . .\n75\n5.3.1\n昂りの判定回数の比較. . . . . . . . . . . . . . . . . . . . . . . . .\n75\n5.3.2\n脈波変動指標の変化について\n. . . . . . . . . . . . . . . . . . . . .\n79\n5.3.3\n脈波変動指標の変化および昂りの判定回数に対する考察\n. . . . . .\n80\n第6 章\n結論\n82\n6.1\nまと",
            "化および昂りの判定回数に対する考察\n. . . . . .\n80\n第6 章\n結論\n82\n6.1\nまとめ. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n82\n6.2\n今後の展望\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n82\n謝辞\n84\n参考文献\n85\n付録A 本研究に関する発表実績\n95\n3\n第1章\n序章\n本章では，本研究における背景および研究目的，本論文の構成について述べる．\n1.1\n研究背景\n1.1.1\n動画鑑賞の普及とスマートフォン利用の現状\n近年，人々にとって動画鑑賞が身近な娯楽活動であるということが確認される．日本生\n産性本部が実施した「国民の余暇意識および余暇活動への参加実態調査」によれば，2020\n年の調査結果[1] では「動画鑑賞（レンタル，配信を含む）」の推計参加人口が約3900 万\n人に達し，余暇活動として初めて首位を記録した．この背景には，新型コロナウイルス感\n染症",
            "3900 万\n人に達し，余暇活動として初めて首位を記録した．この背景には，新型コロナウイルス感\n染症の拡大による在宅需要の増加が主な要因として示唆され，多くの人々にとって動画鑑\n賞が主要な余暇活動となったことが考えられる．さらに，2023 年の調査結果[2] では，動\n画鑑賞の推計参加人口は約3600 万人と算出され，国内観光旅行（避暑，避寒，温泉など）\nや外食（日常的なものを除く）に次いで3 位となった．この順位変動には，新型コロナウ\nイルス感染症が5 類感染症へ移行したことに伴い，人々の余暇活動が外出を伴う形で活発\n化したことが影響していると示唆される．しかしながら，動画鑑賞は依然として余暇活動\nの上位に位置しており，2020 年に首位を記録して以降，堅調に推移している．\n加えて，ICT 総研が実施した「有料動画配信サービス利用動向に関する調査」によれ\nば，2023 年の調査結果[3] では有料動画配信サービスの推計利用者数が2022 年末時点で\n約3390 万人と算出され，今後も緩やかな増加傾向が見込まれている．図1.1 は，当社が\n算出した有料動画配信サービス利用者数の推計値を",
            "やかな増加傾向が見込まれている．図1.1 は，当社が\n算出した有料動画配信サービス利用者数の推計値を基にした需要予測を示している．この\n増加傾向の背景としては，動画配信サービス間の競争激化に伴う市場拡大が寄与している\nと示唆される．特に，多くのサービス提供者が独自コンテンツの制作や多様なジャンルの\n動画配信を強化している点が注目される．このような取り組みにより，利用者は自身の嗜\n好に応じたコンテンツを選択しやすくなり，新規利用の促進および既存利用者による継続\n利用が後押しされていることが考えられる．\n以上の調査結果より，動画鑑賞が人々にとって主要な余暇活動であり，身近な娯楽とし\nて定着していることが明らかである．特に，在宅需要の増加や動画配信サービスの競争に\nよるコンテンツの多様化が，その定着に寄与していると考えられる．これらの要因を背景\nに，動画鑑賞は引き続き人々の日常における重要な娯楽活動として位置づけられる．\nまた，動画鑑賞が人々の日常に定着する中で，鑑賞するための端末として「スマートフォ\nン」が広く利用されていることが確認される．図1.2 は，前述のICT 総研が実施した調査\n",
            "ートフォ\nン」が広く利用されていることが確認される．図1.2 は，前述のICT 総研が実施した調査\n結果に基づく，動画配信サービスにおける視聴端末の利用率を示している[3]．この図か\nら，スマートフォンを利用した動画鑑賞が最も高い割合を占めていることが示唆されてい\nる．この傾向は，スマートフォンの利便性および多機能性による影響が大きいと考えられ\nる．具体的には，動画配信サービス各社がスマートフォン向けに最適化されたアプリケー\n4\n図1.1: 有料動画配信サービス利用者数需要予測（[3] より引用）\nションを提供している点に加え，第5 世代移動通信システム（5G）の普及により，高速か\nつ安定した通信環境が整備され，快適な動画再生が可能となったことが要因として挙げら\nれる．この結果，スマートフォンを利用した動画鑑賞は，場所や時間に縛られることなく，\n利用者が好きな時に好きな場所で楽しめる活動として広く支持されていると推察される．\nさらに，モバイル社会研究所が実施した「スマートフォンでの動画視聴についての調査」\n[4] に基づく図1.3 で示すスマートフォンでの1 日の動画視聴時間によると，",
            "聴についての調査」\n[4] に基づく図1.3 で示すスマートフォンでの1 日の動画視聴時間によると，スマートフォ\nンでの動画鑑賞時間に関して，20 代以下の回答者の6 割以上が1 日に2 時間以上をスマー\nトフォンで動画鑑賞に費やしており，回答者全体で4 割を超えていることが明らかとなっ\nた．また，10 代男女および20 代女性の約3 割が，1 日に6 時間以上をスマートフォンで\n動画鑑賞に費やしていることが判明した．加えて，よく鑑賞する動画コンテンツとして，\nゲーム，アニメ，音楽，映画などのエンターテイメント系コンテンツを挙げた回答者のう\nち，4 割以上が1 日に2 時間以上をスマートフォンでの動画鑑賞に充てていると回答した\n人に該当することが確認された．\n図1.2: 動画配信サービスの視聴端末の利用率（[3] より引用）\n5\n図1.3: 性年代別「スマートフォンでの1 日の動画視聴時間」（[4] より引用）\n以上の調査結果より，動画鑑賞が人々の日常生活に定着している中で，鑑賞するための\n端末として「スマートフォン」が広く利用されていることが明らかである．スマートフォ\nンは，その利便",
            "の\n端末として「スマートフォン」が広く利用されていることが明らかである．スマートフォ\nンは，その利便性や多機能性により，動画鑑賞に適したデバイスであると考えられる．総\nじて，現在の動画鑑賞の利用動向を踏まえると，動画鑑賞は多くの人々に親しまれている\n余暇活動の一つとして定着しており，その主流となる鑑賞方法はスマートフォンを利用し\nたものであると見られる．\n1.1.2\n動画鑑賞体験を拡張する取り組み\n動画鑑賞は，従来の平面的な鑑賞体験を超え，より没入感のある体験へと拡張されつつ\nある．その代表例として，映画館における4D 映画が挙げられる．4D 映画は，視覚や聴\n覚に加えて触覚や嗅覚を活用することで，観客が体全体で映画を感じられる新たな映像体\n験を提供する技術である[5][6]．図1.4 は，CJ 4DPLEX 社が開発した映画館用の環境効果\n技術を示している．この技術では，映像に連動して座席が動くほか，風，香り，水しぶき\nなどの特殊効果が用いられ，\n「アトラクション型の鑑賞体験」として観客に高い没入感を\nもたらすことが可能となっている．さらに，VR（仮想現実）技術を活用した新たな視覚\n",
            "客に高い没入感を\nもたらすことが可能となっている．さらに，VR（仮想現実）技術を活用した新たな視覚\n的鑑賞体験の提供も試みられている[7]．VR 技術は，360 度の視点で映像を映し出すこと\nが可能であり，視聴者の頭部や身体の動きに応じて映像の視点が変化するため，視聴者は\n6\nまるで物語の中に自らが存在しているかのような臨場感を体験できる．このような映像世\n界に入り込む感覚は，VR を活用した鑑賞体験の大きな特徴であり，強力な没入感を与え\nることが可能である．\n図1.4: CJ 4DPLEX 社製の4D 映画対応シート（[6] より引用）\nこれらの技術は，強力な没入感を提供する手法として確立されている一方で，映像と視\n聴者の間には依然として受動的な鑑賞構造が存在していた．しかし，近年では，視聴者が\n映像に介入する新しい鑑賞体験が提供され始めている．その代表例として，動画配信サー\nビスNetﬂix による「インタラクティブ動画」が挙げられる[8]．インタラクティブ動画で\nは，視聴者が物語の分岐点で提示される選択肢に対する選択を行い，選んだ選択肢に応じ\nて物語が進行する仕組みが採用されてい",
            "分岐点で提示される選択肢に対する選択を行い，選んだ選択肢に応じ\nて物語が進行する仕組みが採用されている．視聴者が選んだ選択肢により異なる結末やシ\nナリオが展開されるため，視聴者自身が能動的に物語の形成に関与できる．このような鑑\n賞体験は，従来の受動的な動画鑑賞とは大きく異なるものであり，動画鑑賞における革新\n的な手法として注目されている．\nこれらの手法により，動画鑑賞に対する期待は，従来の平面的な鑑賞体験を超え，より\n没入感のある体験の拡張へと変化する．その結果，今日の動画コンテンツの消費形態は多\n様化している．さらに，鑑賞構造の受動的な関係を拡張し，能動的な関係を取り入れた動\n画鑑賞体験を提供することは，鑑賞体験の価値を高め，動画鑑賞を促進する上で大きな意\n義を持つと考えられる．\n1.1.3\nスマートフォンを利用した鑑賞体験における課題\n現在までに，スマートフォンの平均画面サイズは拡大傾向[9] だが，多くが片手に収ま\nる程度の画面サイズである．スマートフォンを使用した動画鑑賞では，スマートフォン特\n有の画面サイズによって没入感のある体験に影響を及ぼすことが指摘されている[10][1",
            "マートフォン特\n有の画面サイズによって没入感のある体験に影響を及ぼすことが指摘されている[10][11]．\nRigby らは，異なる画面サイズが没入感にどのように影響するかを調査した[10]．初め\nて鑑賞する映画コンテンツを対象に，4.5 インチのスマートフォン，13 インチのノートパ\nソコン，および30 インチのモニターでそれぞれ10 分間鑑賞した後，没入感に関する質問\n票を用いて評価した．その結果，スマートフォンで鑑賞した場合，没入感のスコアが最も\n低く，ノートパソコンおよびモニターで鑑賞した場合と比較して，没入感に有意な影響を\n与える主効果が確認された．Dunaway らは，スマートフォンの画面サイズがニュース視\n聴時の注意力や感情的反応に与える影響を調査した[11]．ノートパソコン内でウィンドウ\nサイズを調整することで，大画面（約13 インチ幅）とスマートフォンサイズに対応する\n7\n小画面（約4.5 インチ幅）の画面サイズを再現した．各条件で，国内外のポジティブおよ\nびネガティブなニュース映像を視聴させ，皮膚電気活動および心拍変動を測定した．結果\nとして，小画面条件ではより心拍",
            "なニュース映像を視聴させ，皮膚電気活動および心拍変動を測定した．結果\nとして，小画面条件ではより心拍変動が減少する傾向が確認された．また，大画面条件で\nは，ニュースのネガティブな内容と皮膚電気活動の増加との関連がより強く見られた．両\n者の研究によって，スマートフォンのような小型画面は，視聴者の鑑賞体験の質や感情的\n反応に与える影響が比較的に低下する可能性が示唆された．\nこのように，一般的なスマートフォンを使用した動画鑑賞では，画面サイズの制約によ\nり視聴覚刺激が限定されるため，没入感や情動体験の強度が映画館やテレビのような大画\n面での鑑賞に比べて弱まる傾向がある．この課題に対応するための技術として，風や水し\nぶきなどの大掛かりな4D 要素が挙げられるが，これらがスマートフォン向けに実用化さ\nれた例は確認されない．そのため，スマートフォンを用いた動画鑑賞では情動体験を高め\nるという課題がある．\n1.1.4\n動画鑑賞における情動強化の重要性\n鑑賞者の感情を巧みに刺激することは，動画作品の価値を高める重要な要因の一つであ\nる．感情変動や視覚的動きが鑑賞体験に与える影響は，映画や動画の魅力を強",
            "を高める重要な要因の一つであ\nる．感情変動や視覚的動きが鑑賞体験に与える影響は，映画や動画の魅力を強化する役割\nを果たしていることが示されている[12][13]．\nBerger らは，感情変動（sentiment volatility）が映画評価に与える影響を分析した[12]．\n台詞に含まれる感情を感情価の得点として定量化し，映画全体の一定の時間単位または\nシーン単位での差異によって感情の転換頻度を測定した結果，感情変動が大きい作品ほ\nど，観客や批評家から高く評価されている傾向が確認された．この効果はスリラーなど刺\n激的なジャンルで顕著であり，ロマンスでは弱いことが示された．Dayan らは，映画の感\n情喚起の要因としてローカルモーション（物体や人の動き）とグローバルモーション（カ\nメラの動き）に注目し，脳活動との関係を調査した[13]．感情を含むシーンまたは中立的\nなシーンの映像クリップを視聴中の脳活動を測定した結果，感情的な場面でのグローバル\nモーションは，脳の広範囲な感情応答領域を活性化し，自己運動の錯覚を通じて感情的反\n応を引き起こすことが示された．\nまた，動画鑑賞による感情喚",
            "活性化し，自己運動の錯覚を通じて感情的反\n応を引き起こすことが示された．\nまた，動画鑑賞による感情喚起には多くの利点が確認される．まず，感情的な喚起が動\n画に対する印象の向上に寄与することが示されている[14]．さらに，感情的に喚起された\n動画は，その快楽体験によって動画の継続的な鑑賞を促進する効果があり[15]，視聴者の\n社会的つながりを強化する要因として機能することが確認されている[16]．\nCahill らは，12 本の感情的に刺激的な動画と12 本の中立的な動画を提示した際の脳活\n動をポジトロン断層法（PET）で測定し，3 週間後に自由再生テストを用いて記憶評価を\n行った[14]．その結果，感情的に刺激的な動画に対する平均的な扁桃体の活動は中立的な\n動画よりも高いことが確認された．また，扁桃体の活動レベルは，記憶として想起され\nた動画の数と強い相関を示していた．Zaidel は，映画というメディアに対する人々の長期\n的な関心と，映画鑑賞を繰り返す行動の原因について，神経基盤の観点から見解を述べ\nた[15]．映画ジャンルに関係なく観察される現象として，映画鑑賞が繰り返される理由に",
            "から見解を述べ\nた[15]．映画ジャンルに関係なく観察される現象として，映画鑑賞が繰り返される理由に\nは，音楽，映像美，ストーリーへの共感が相互作用し，ドーパミン報酬系を通じて強力な\n快楽体験を記憶する点が挙げられる．この快楽体験を再び求める傾向が，映画鑑賞を継続\nさせる要因であると示唆された．Berger らは，96 人の学生を対象に，感情的な覚醒が社\n8\n会的伝達に与える影響を調査した[16]．実験群には感情的に興奮する動画を，対照群には\n中立的な動画を提示した後，両群に中立的な記事や画像を提示し，\n「これを他人と共有し\nたいですか」という質問に対して7 段階評価を収集した．その結果，実験群は対照群に比\nべて他者と内容を共有したいという意欲が有意に高いことが確認された．\n以上のことから，動画鑑賞において視聴者の感情を巧みに喚起し，それを持続的な体験\nへと結びつけることが重要であるといえる．感情的な喚起は，作品への印象を向上させ\nるだけでなく，視聴者の継続的な関心を促し，動画の魅力を高める重要な要因となる．ま\nた，感情的な体験は視聴者間の社会的なつながりを強化する役割も担っており，動",
            "める重要な要因となる．ま\nた，感情的な体験は視聴者間の社会的なつながりを強化する役割も担っており，動画鑑賞\nにおける情動強化が鑑賞体験の質を向上させる鍵となる．\n1.1.5\nエンターテイメント領域への生体信号の活用\n近年の健康管理の領域において，スマートウォッチを用いて脈拍数，皮膚温，血圧など\nの生体信号データを収集し，個人の健康状態をリアルタイムで管理する技術が進展してい\nる．そして，スマートウォッチをはじめとする生体信号を取得する機器の小型化に伴い，エ\nンターテインメント領域において生体反応を活用する取り組みが進んでいる．特に，ゲー\nムや音楽の分野では，生体信号やそれに基づくユーザの感情を反映することで，体験をよ\nり没入的かつインタラクティブにする技術が開発されている[17][18][19][20]．\n具体例として，人工知能を利用した感情分析を手掛けるOvomind 社は，ホラーゲーム\nにおいて，ユーザの手首に装着されたスマートバンドから取得する皮膚温度，脈拍数，発\n汗などの生体信号を基に感情を分析し，推定された感情状態に応じて，ゲーム画面の視\n野を狭めたり，赤くなる演出を加えたり",
            "を基に感情を分析し，推定された感情状態に応じて，ゲーム画面の視\n野を狭めたり，赤くなる演出を加えたりするなど，感情状態に連動した演出を取り入れて\nいる[19]．これにより，ユーザ側はプレイ中の自身の感情状態を認識することが可能であ\nり，ゲーム体験の向上に効果を発揮する．一方，Mindset Innovation 社は，独自開発した\n脳波（EEG）センサを搭載したスマートヘッドホンを活用し，ユーザの脳波を基に集中状\n態やリラクゼーション状態をリアルタイムで監視する技術を開発している[20]．この技術\nでは，脳波状態を基に複数の音源を用いた音響刺激を提供することで，ユーザを目標とす\nる精神状態（集中，リラックスなど）へ導くことを支援している．\nこのように，生体情報を活用したエンターテインメントは，個々のユーザに最適化され\nた体験を提供する可能性を秘めており，没入感の向上やインタラクティブな関係の構築を\n通じて，新しい体験を提供する領域に発展することが考えられる．\n1.2\n研究の目的および目標\n現在，動画鑑賞は多くの人に親しまれている余暇活動の一つとして定着しており，その\n主な鑑賞媒体として",
            "\n現在，動画鑑賞は多くの人に親しまれている余暇活動の一つとして定着しており，その\n主な鑑賞媒体としてスマートフォンが広く利用されている．また，動画コンテンツの消費\n形態は，受動的な構造から能動的な構造にまで広がり，鑑賞体験が多様化している．しか\nし，スマートフォンによる動画鑑賞では，画面サイズの制約により視聴覚刺激が限定さ\nれ，映画館やテレビのような大画面での鑑賞と比較して没入感や情動体験の強度が弱まる\n傾向が指摘されている．この課題を補う手法として，横揺れや風などの4D 技術のような\n体験拡張技術がスマートフォン向けに実用化された例は未だに確認されない．そのため，\n9\nスマートフォンでの動画鑑賞を対象とした動画鑑賞体験の拡張や，これに伴う情動体験の\n強化の課題がある．\n本研究では，動画鑑賞中のユーザの脈拍変動を活用し，脈拍変動から判定される昂り状\n態に応じたフィードバックを行うことで，スマートフォンを用いた個人の動画鑑賞時の情\n動体験を強化させるための手法を提案し，スマートフォンによる動画鑑賞体験を拡張する\nことを目的とする．本論文では，この目的に向けて，アクション動画を対象に次の3",
            "動画鑑賞体験を拡張する\nことを目的とする．本論文では，この目的に向けて，アクション動画を対象に次の3 点を\n目標として取り組む．\n1. アクション動画鑑賞時の昂りに連動して，振動および照明による擬似心拍刺激を\n与えるスマートフォンアクセサリーの製作\n2. スマートフォンアクセサリーを用いた情動体験への有用性の検証\n1.3\n本論文の構成\n本論文は以下の章分けによって構成する．\n第1 章では，研究背景，研究目的及び論文の構成について述べる．\n第2 章では，関連研究について述べる．\n第3 章では，脈拍変動を用いたアクション動画鑑賞時の昂り状態\nの分類について述べる．\n第4 章では，昂りに連動した動画鑑賞体験拡張スマートフォンアクセサリー\nについて述べる．\n第5 章では，スマートフォンアクセサリーによるアクション動画鑑賞時の\n情動体験の影響について述べる．\n第6 章では，本論文のまとめと今後の展望について述べる\n10\n第2章\n関連研究\n本章では，本研究における関連研究について述べる．\n2.1\n情動と心拍変動\n2.1.1\n感情の種類と情動\n感情とは何かという問いに対して，心理学の分野を中心として",
            "動と心拍変動\n2.1.1\n感情の種類と情動\n感情とは何かという問いに対して，心理学の分野を中心として議論されているが，統一\nされた定義や見解は未だ定まっていないとされている．これまでに，\n「喜怒哀楽や好悪な\nど，物事に感じて起こる気持」[21] と説明されるほか，”主観的情感（気持ち）”および”\n人間らしいもの”といった定義的特徴が当てはまることから，\n「高次な認知活動を反映する\nもの」[22] と捉える見方や，Ortony らによる「人，物，出来事，環境についてする評価的\nな反応である」[23] という広義的な定義で説くことがある[24]．\n進化論で知られるDarwin は，動物と人間の表情を対象とした比較観察を通じて，その\n類似性から動物と人間の感情が同質であると認識できるとし，人間が獲得している感情表\n現は進化的かつ適応的なものであると言及した[25]．そして，Ekman らは，表情による感\n情表現が普遍的であるかどうかを検証するため，非識字文化の人々を対象に調査を行った\n[26]．その結果，非識字文化の人々も，西洋や東洋の識字文化圏の人々と同様に，特定の\n感情を特定の表情と関連",
            "．その結果，非識字文化の人々も，西洋や東洋の識字文化圏の人々と同様に，特定の\n感情を特定の表情と関連付けていることが明らかとなり，表情による感情表現が文化を超\nえて普遍的であることを支持する証拠が得られた．また，6 つの感情（喜び，悲しみ，怒\nり，恐怖，驚き，嫌悪）が人間が備え持つ基本感情であることが示唆された．\n他方，Russell は感情は離散的ではなく連続体の中で変化することを提唱し，快－不快次\n元，および覚醒－眠気次元の2 つの次元軸によって構成される2 次元座標を用いた場合，\n全ての感情はこの平面上で円環に配置されることを言及した[27]．図2.1 は，提唱された\n2 次元座標系に基づく感情の円環モデルを示す．この円環モデルでは，興奮，怒り，憂鬱\nといった異なる感情が明確な境界を持たず，それらの感情が徐々に変化し，その間に微妙\nな変化や中間的な感情を経て，他の感情に移行する様子を表現することが可能である．ま\nた，感情の二極性を包括したモデルについても言及している[28]．図2.2 のように，感情\nを快―不快の感情価次元と，活性―不活性の活性度次元という2 つの次元軸で捉えるこ",
            "2 のように，感情\nを快―不快の感情価次元と，活性―不活性の活性度次元という2 つの次元軸で捉えること\nによって，感情を「ポジティブ感情（PA）」および「ネガティブ感情（NA）」という抽象\n的なレベルで理解し，その二極性を表現している．\n感情の類義語として，情動という言葉がある．情動とは，\n「怒り，恐れ，喜び，悲しみな\nどのように，比較的急速に引き起こされた一時的で急激な感情の動き」[21] と説明される\nほか，\n「交感神経や内分泌系の活動によって引き起こされる，身体の興奮状態（生理的覚\n醒）を伴う強い感情」[24] と述べられている．本論文では，動画鑑賞中の身体的反応や一\n時的な興奮状態に焦点を当てるため，情動を感情を含む概念として用いる．\n11\n図2.1: 感情の円環モデル（[27] 中の図を基に作成）\n図2.2: PA・NA を包括した円環モデル（[28] 中の図を基に作成）\n12\n2.1.2\n心拍変動と情動の関係\n心臓は収縮と弛緩の運動を繰り返すことによって律動的に拍動を続けている．図2.3 は\n心電図波形を表している．心電図は，心臓の電気的活動による電位差を電極を用いて，体\n",
            "る．図2.3 は\n心電図波形を表している．心電図は，心臓の電気的活動による電位差を電極を用いて，体\n表面から非侵襲的に測定することによって得られる．心電図波形に見られるように，律動\n的な拍動間の時間間隔を心拍間隔（RRI: R-R interval）と呼ぶ．一般に，心拍間隔は常に\n一定ではなく，変動する．睡眠などの安静時および有酸素運動などの運動時の心臓の鼓動\nの違いが意識的に確認できるように，心身の状況の変化によって心拍間隔は変化する．こ\nの心拍間隔の周期的な変動を「心拍変動（HRV: Heart Rate Variability）」と呼ぶ．\n図2.3: 心電図波形（[29] より引用）\n心拍間隔にみられる周期的な変動は自律神経系の機能との関係を持つ．というのも，自\n律神経系の活動が心拍間隔の周期的な変動に影響を与えるという関係性が示されている\n[29]．自律神経系とは呼吸や血圧の他，発汗や消化などの生命活動に必要な機能を調節す\nる役割を持つ神経系であり，この自律神経系には，大きく分けて「交感神経」および「副\n交感神経」の2 種類の神経が存在する．これら2 種類の神経は心身に対して互",
            "て「交感神経」および「副\n交感神経」の2 種類の神経が存在する．これら2 種類の神経は心身に対して互いに相反す\nる作用を持ち，心身が健やかな状態であるためには，互いに優位状態（働きの強さ）が一\n方的な偏りなく活動している状態でなければならない．一般に，交感神経は心身に興奮や\n緊張を引き起こす神経系である．交感神経が優位に働く際，心臓の活動が活発化し，心拍\n数の増加，血管の収縮，瞳孔の拡大，そして発汗などの身体的変化が生じる．一方で，副\n交感神経は心身に休息や安静を促す役割を担う神経系である．副交感神経が優位に働く\n際，心臓の活動が抑制され，心拍数の減少，血管の拡張，瞳孔の縮小などの身体的変化が\n生じる．活動状況の例として，交感神経が副交感神経より優位に活動している場合，心身\n上では心拍数の増加や発汗などの変化が生じる．\n心拍間隔にみられる周期的な変動に影響を与える自律神経系の働きにおいて，情動体験\nによる影響があることが示唆されている．Ohira らは，快または不快な情動を喚起させる\n画像を提示した際の脳活動を陽電子断層撮影法（PET）で観測すると同時に，心拍や皮膚\n伝導反応，強い情動",
            "像を提示した際の脳活動を陽電子断層撮影法（PET）で観測すると同時に，心拍や皮膚\n伝導反応，強い情動が誘発された際に分泌される副腎皮質刺激ホルモン（ACTH）の血中\n濃度を測定した[30]．その結果，情動的な刺激を有する画像が提示された際に，扁桃体\nが活発になり，皮膚伝導反応とACTH 濃度に正の相関関係が確認された．つまり，情動\nを司る扁桃体が活発になることで，自律神経系も活発になることが示された．この他に，\nEkman らは，情動が自律神経系の反応を引き起こす際に，それが情動ごとに異なる特徴\nを持つかどうかを調査した[31]．被験者に特定の情動を引き出すための顔面プロトタイプ\nを構築し，さらに，過去の強い情動体験（怒り，悲しみ，恐怖など）を再現させ，その際\n13\nの自律神経活動を記録した結果，情動ごとに心拍数や皮膚温の変化量が異なることが確認\nされた．つまり，情動間で自律神経系の活動は異なることが示唆された．\n前述を踏まえて，心拍変動と自律神経，および自律神経と情動には関係性があることが\n示唆されている．情動は自律神経系の活動に影響を与え，自律神経系は心拍や発汗などの\n様々な身体的",
            "とが\n示唆されている．情動は自律神経系の活動に影響を与え，自律神経系は心拍や発汗などの\n様々な身体的変化を制御しているということに基づいて，心拍などの生体信号を解析する\nことによって，情動を判別することが可能であることが考えられる．\n2.1.3\n心拍変動を用いた情動評価に関する研究\nSubahni らは，ストレスの身体への影響に注目し，ビデオゲーム中のユーザの精神的ス\nトレスに対して心拍変動（HRV）に基づいた指標からの観察を検証した[32]．レースが題\n材のゲームを使用し，試遊前後に閉眼および開眼の時間を設けて安静時の心拍変動を測定\nすることで，ゲーム中の変化の比較対象とした．HRV は時間領域と周波数領域で分析さ\nれた．結果，ゲーム中の平均心拍数は有意に増加し，標準偏差（SDNN）は有意に減少し\nて交感神経の活性化を示した．さらに，交感神経と副交感神経のバランスを示すLF/HF\n比は，ゲーム中に休息時よりも高くなったことが確認された．\nRakshit らは，パルスオキシメータから得られる光脈波信号を基に心拍変動の特徴量を\n算出し，時間領域および周波数領域の特徴量に基づいて感情認識を",
            "れる光脈波信号を基に心拍変動の特徴量を\n算出し，時間領域および周波数領域の特徴量に基づいて感情認識を行った[33]．図2.4 は\n実験時の様子を示している．被験者には「Happy」「Sad」「Neutral」の感情を引き起こす\n動画クリップを視聴させ，その間に光脈波信号を収集した．収集した光脈波信号から算出\nされた心拍変動の特徴量をデータセットとして，サポートベクターマシンを用いて分類モ\nデルを構築し，1 個抜き交差検証を行った．その結果，全体の平均分類精度は83.8%であ\nることが確認された．\n図2.4: 動画クリップ鑑賞による実験時の様子（[33] より引用）\nChoi らは，国際感情画像システム（IAPS）を用いて，感情を評価するツールとしての\n心拍変動の妥当性を検証した[34]．被験者は「Happy」「Unhappy」「Neutral」の画像を見\nた際，自己評価マネキン（SAM）で主観的感情を評価し，同時に心拍信号が記録された．\n14\n分析の結果，\n「Unhappy」画像で覚醒度が高い場合にのみ，誘発性と有意な正の相関，支配\n性と有意な負の相関が確認された．これにより，強い情動",
            "が高い場合にのみ，誘発性と有意な正の相関，支配\n性と有意な負の相関が確認された．これにより，強い情動が誘発される場合に限り，HRV\nによる感情評価が可能であることが示唆された．\nWu らは，中国感情動画システム（CAVS）を用いて，特定の感情が心臓の働きに与える\n影響を調査した[35]．\n「Amused」「Fearful」「Angry」「Neutral」の感情を強く引き起こす動\n画を選定し，被験者に提示後，主観的感情の評価を行い，同時に心電図から心拍変動を収\n集した．分析の結果，\n「Amused」は他の感情と比較して心拍数を低下させ，心拍変動を増\n加させることが確認され，これにより「Amused」が副交感神経の活性化と関連している\nことが示唆された．さらに，\n「Angry」は「Fearful」と比較して心拍変動が高いことから，\nネガティブな感情の中でも特定の感情を区別できる可能性が示唆された．\nYu らは，脈拍センサから取得した心拍間隔および心拍変動を基に，ユーザーのストレ\nス度合を測定し，樹木の成長を隠喩的に用いた視覚化によるバイオフィードバックシステ\nムを提案した[36]．本システ",
            "し，樹木の成長を隠喩的に用いた視覚化によるバイオフィードバックシステ\nムを提案した[36]．本システムでは，過度なストレスがかかると樹木が徐々に枯れ，反対\nにバランスの取れた状態では樹木が丈夫に成長する様子をリアルタイムで表現する．提案\nされたシステムの使用により，呼吸を意識したストレス管理や動機付けが促進され，健康\nな樹木を維持しようとする行動が確認された．\n多田らは，心拍数の上昇率と計算課題の正解率との間に負の相関があることに着目し，\n心拍数の分散に基づいて休憩を促すシステムを開発した[37]．システムの有無による計算\n課題を実施した結果，システム通知による休憩の実施回数は多かったものの，誤答数など\nに有意差がなく，頻繁な通知音が課題作業や心拍に影響を及ぼした可能性が示唆された．\n2.2\n動画鑑賞と情動\n2.2.1\n動画に対する印象及び嗜好に関する研究\n金らは，動画視聴時の嗜好評価（気に入る・気に入らない）に影響を与える感情や印象\nを調査した[38]．被験者に4 本のスクリーンセーバー映像を各20 秒間提示し，最も気に\n入る映像と気に入らない映像を選択させた後，16 の感情語と14",
            "ー映像を各20 秒間提示し，最も気に\n入る映像と気に入らない映像を選択させた後，16 の感情語と14 項目の形容詞対による印\n象評価を行った．結果として，\n「動き」と「登場する要素」の2 つの印象と「緊張」とい\nう感情が嗜好評価に関わる重要な要素であることが確認された．特に「気に入る」では興\n味，楽しさ，安心が，\n「気に入らない」では混乱，困惑，嫌悪が有意に高い選択傾向を示\nし，\n「緊張」は嗜好評価に依存して意味合いが変わることが示唆された．\nTopal らは，映画の評価や論評に含まれる感情的側面を分析し，感情マップとして可視化\nすることで新たな映画選択手法を提案した[39]．映画情報サイトであるIMDb から134 本\nの映画に対する157,344 件の論評を収集し，各ジャンルのカテゴリには少なくとも10 本の\n映画があるように整理した．各映画の上位100 件の論評を対象に，論評に含まれる語句を\nSenticNet データベースを用いて感情モデル（sensitivity，pleasantness，aptitude，attention）\nに基づいた感情次元とレベルで分類し，その結果をヒ",
            "tness，aptitude，attention）\nに基づいた感情次元とレベルで分類し，その結果をヒートマップとして映画の感情的特徴\nを表現した．評価として，様々な映画に適用した結果，同一ジャンルの高評価映画でも感\n情マップが異なる一方，低評価映画では類似した反応が見られることが確認された．\n15\n2.2.2\n動画鑑賞中の生理反応と映像の関係に関する研究\nSakuragi らは，喜劇および悲劇動画の視聴によって誘発される笑いや悲しみが，自律神\n経系や気分に与える影響を分析した[40]．Proﬁle of Mood States（POMS）を用いて主観的\nな気分を評価し，心拍変動のスペクトル分析により自律神経系の活動を測定した．喜劇動\n画の視聴時には交感神経系（LF/HF）の反応が確認され，視聴後には視聴前の状態に戻っ\nた．一方，悲劇動画では交感神経系の反応が緩やかに増加し，視聴後もその影響が持続し\nたことが確認された．この結果より，笑いは自律神経系に強力な一過性の影響を与え，悲\nしみは中程度の影響を与えながら持続的効果をもたらすことが示唆された．\n村瀬らは，視聴覚刺激による情動誘発の有",
            "程度の影響を与えながら持続的効果をもたらすことが示唆された．\n村瀬らは，視聴覚刺激による情動誘発の有無と自律神経系への影響を調査した[41]．滑\n稽，穏和，恐怖，不快動画を選定し，被験者に心電図計と呼吸計を装着して視聴させ，視\n聴後に情動を質問表で評価した．結果，滑稽，穏和，恐怖動画では85～93%，不快動画で\nは57%の被験者が想定する情動を認知した．自律神経系の変化では，滑稽動画で交感神\n経が有意に活性化し，副交感神経が抑制された．一方，不快，恐怖，穏和動画では交感神\n経が抑制され，副交感神経が活性化した．心拍数に有意な差はなかったが，滑稽・穏和動\n画では増加し，不快・恐怖動画では減少する傾向が見られた．不快動画で交感神経の活性\nが見られなかったのは，不快情動の認知の割合が低い影響が示唆された．\n宮本らは，動画視聴中のユーザの皮膚抵抗増加量，皮膚抵抗値，指尖皮膚温，心拍数の\n生体信号を用いて，動画に対するユーザの嗜好性との関連を調査した[42]．動画中の皮膚\n温減少場面が多い被験者ほど，動画に対して高い評価を示す傾向が確認され，動画に対す\nる嗜好性を判断する上で指尖皮膚温を用いるこ",
            "ど，動画に対して高い評価を示す傾向が確認され，動画に対す\nる嗜好性を判断する上で指尖皮膚温を用いることが有効な手段であることが示唆された．\nFukumoto らは，ホラー映画が与える心理生理学的影響を調査し，恐怖感と生理的変化\nの関係を調査した[43]．10 名の男性被験者を対象に，映画視聴中の心電図，呼吸，皮膚\n電気活動を測定した後，主観的な恐怖を感じた場面を尋ねた．呼吸のみを分析した結果，\n恐怖を感じた場面では呼吸の強度が増加し，呼吸周期も加速していることが確認された．\nこの特徴は全ての被験者で有意に見られた．\nVermeulen らは，動画視聴中のユーザの心拍数変化を基に，情動的な見所をまとめた動\n画クリップを生成するシステムを提案した[44]．手首装着型センサで心拍数を測定し，見\n所検出の実現可能性を調査した結果，特に嫌悪感，面白さ，悲しさ，恐ろしさを感じる場\n面で心拍数の減速が確認された．この結果を基に，嫌悪感のある動画で心拍数の減速が見\nられる部分を見所としてクリップを作成し，編集の専門家が作成したクリップと比較した\nところ，専門家の見所は心拍数の変化とHeartefact",
            "，編集の専門家が作成したクリップと比較した\nところ，専門家の見所は心拍数の変化とHeartefact の両方と一致する傾向が見られた．\n2.2.3\n動画鑑賞時の情動評価に関する研究\n代蔵らは，動画鑑賞者の興奮反応に合わせて動画の音量を調整することで，鑑賞者の興\n奮を意識させること無く促進させる動画鑑賞システムE3-Player を開発した[45]．図2.5\nは，当システムを利用した動画鑑賞の概要図を示している．手のひらの皮膚コンダクタン\nス反応に基づく興奮に応じた音量変化によって，興奮の平均反応量が高いことが示され，\n興奮を促進させることが可能であることが示唆された．一方で，すべての興奮反応に対し\nて音量を変化させたとしても，興奮を促進させることができないことも示唆された．\n16\n図2.5: E3-Player 概要図（[45] より引用）\n角田らは，心拍数と呼吸数の長期変動の類似性が人の心的状態を表す可能性に着目し，\nこれを用いてコンテンツ視聴時のユーザの気分変化を推定する手法を提案した[46]．ま\nず，コンテンツ視聴中の心拍数と呼吸数，視聴前後の気分状態を測定し，心拍数と呼吸数\nの",
            "た[46]．ま\nず，コンテンツ視聴中の心拍数と呼吸数，視聴前後の気分状態を測定し，心拍数と呼吸数\nの長期変動の類似度と視聴前後の気分変化量を算出した．それらを学習データとして回帰\nモデルを構築し，20 名のコメディ映像の視聴時データを用いて評価を行った．1 名のデー\nタを入力とし，残り19 名のデータで構築した回帰モデルで推定した結果，実測値との相\n関が高い推定値が得られ，提案手法の有効性が確認された．\n吉田らは，映画視聴時の情動を心拍変動から機械学習で判別できるかを検討した[47]．\n被験者はホルター心電計を装着し，映画視聴中に喜び，心配，驚き，悲しみ，嫌悪，怒り\nのいずれかの情動が生じた際にボタンを押して情動と時刻を記録した．ボタンが押された\n前後1 分，2 分，3 分間のRRI，LF，HF を特徴量として機械学習で分類した．結果，前\n後1 分間のRRI で「心配」が再現率0.620，前後1 分間のLF と前後3 分間のHF で「悲し\nみ」がそれぞれ再現率0.582，0.560 で判別された．これにより，心拍変動による情動分類\nでは，快よりも不快の情動の方が再現率が高いことが確認さ",
            "別された．これにより，心拍変動による情動分類\nでは，快よりも不快の情動の方が再現率が高いことが確認された．\n東海林らは，スマートウォッチから取得した心拍変動を用いて，客観的に恐怖を感じた\nとする箇所と心拍変動の反応との関係を分析した[48]．暗室でのホラー動画鑑賞時に取得\nした心拍変動から算出する自律神経機能のバランスを示すストレス指標（LF/HF）を用い\nた分析の結果，恐怖を感じたとする箇所の約15 秒前から約25 秒後にかけて，ストレス指\n標の反応が持続することが確認された．\n竹下らは，鑑賞者の恐怖感に応じて再生速度が変化するインタラクティブなホラー動画\n鑑賞システムを提案した[49]．図2.6 は，ホラー動画鑑賞システムの概要図を示している．\nスマートウォッチを用いて取得する心拍変動から算出された周波数領域成分を基に，恐怖\nを感じているか否かを推定し，その推定結果に基づいてスマートフォン上のホラー動画\nの再生速度を制御する．本システムを利用したホラー動画の鑑賞において，\n「印象に残る」\n「動きがある」「スリルを感じる」といった印象が抱かれることが確認され，恐怖に関連す\nる印象を増",
            "る」\n「動きがある」「スリルを感じる」といった印象が抱かれることが確認され，恐怖に関連す\nる印象を増幅させる効果があることが示唆された．\n17\n図2.6: ホラー動画鑑賞システムの概要図（[49] より引用）\n2.3\n外部刺激によるユーザ体験の強化\n2.3.1\n振動刺激による影響に関する研究\nLemmens らは，映画鑑賞体験を感情的に没入させるため，映画の場面に同期して触覚\n刺激を与える振動アクチュエータを用いたウェアラブル触覚ジャケットを提案した[50]．\n図2.7 は，振動アクチュエータが備えられたウェアラブル触覚ジャケットを示している．\nジャケットには64 個の振動アクチュエータが内蔵され，専用ソフトウェアを使って多様\nな刺激パターンを提示できる．被験者は，ジャケットの有無の条件で7 つの動画クリップ\nを視聴し，条件別の視聴後に興奮度合いおよび没入感を評価するアンケートに回答した．\n結果として，没入感を評価する複数の項目で有意に高い得点が得られた．さらに，客観的\nな評価では，触覚刺激を伴う視聴時に皮膚伝導レベルの平均値が複数のビデオクリップで\n増加したことが確認された．\n図2.",
            "刺激を伴う視聴時に皮膚伝導レベルの平均値が複数のビデオクリップで\n増加したことが確認された．\n図2.7: ウェアラブル触覚ジャケット（[50] より引用）\nSeim らは，手の触覚刺激に対する振動感知能力を調査した[51]．実験では，コイン型の\n振動モータを用いて，1) 刺激位置による知覚精度，2) 指の複数同時振動の知覚精度，3)\n18\n振動モータ（ERM とLRA）別の知覚精度を評価した．各実験の結果では，指先から手の\n中心（手のひら）に向かうにつれて知覚精度が有意に向上し，複数の同時触覚刺激の知覚\n能力は低く，特に3 つ以上の同時刺激でその傾向が顕著だった．また，ERM とLRA によ\nる振動モータ別で知覚精度に有意差は見られないことが確認された．\nMazzoni らは，振動による触覚提示を備えたウェアラブルなグローブを設計し，振動触\n覚刺激を通じて映画に含まれる音楽によって誘発される感情（Mood music）を増幅でき\nるかを検証した[52]．図2.8 は，触覚提示を備えたグローブのプロトタイプを示している．\n振動触覚刺激は，ユーザのフィードバックに基づいて段階的に設計され，",
            "ーブのプロトタイプを示している．\n振動触覚刺激は，ユーザのフィードバックに基づいて段階的に設計され，低強度・低周波\nの刺激が落ち着きを与え，低強度・高周波では興奮感を高め，高強度・高周波では緊張感\nを増幅させることが確認された．また，Mood music を含む映画クリップを振動触覚刺激\nと組み合わせて視聴した結果，映像の評価自体は変わらないものの，興奮度が高まること\nが確認された．\n図2.8: グローブのプロトタイプ（[52] より引用）\nAblart らは，対象者に触れずにフィードバックを提示する空中触覚刺激が短編映画を題\n材とした視聴体験に与える影響を調査した[53]．事前に，皮膚電気反応データから感情的\nピークが現れた1 分間の映画を選定し，その感情的ピークに基づいて空中触覚刺激を設\n計した．参加者を2 つのグループに分け，触覚刺激の有無で映画を視聴させた後，2 週間\n後に再度評価を行った．結果として，触覚刺激がある条件では好意度と覚醒度が有意に高\nく，皮膚電気反応でも高い値が確認された．これにより，空中触覚刺激が視聴体験の質を\n高める可能性が示唆された．\nJeong らは，椅",
            "認された．これにより，空中触覚刺激が視聴体験の質を\n高める可能性が示唆された．\nJeong らは，椅子を意図的に左右に傾けるモーション効果が，鑑賞中の感情や生理的反\n応に与える影響を調査した[54]．被験者には生体信号を測定するセンサを装着させ，モー\nション効果の有無で異なる映画クリップを鑑賞させた後，感情や没入感に関するアンケー\nトを実施した．その結果，モーション効果により脈拍が減少し，皮膚コンダクタンスレ\nベルが増加したことが確認された．また，覚醒感と没入感が高まることも明らかとなり，\nモーション効果が観客を興奮させ，没入させるのに有効であることが示唆された．\nKosuge らは，ハグシーンを視聴しながら上半身に振動刺激を与えることで，感情がど\nのように変化するかを調査した[55]．振動刺激には，胸部前後に接触する2 つのコイル\nモーターを使用し，ハグシーンの開始時に50Hz の振動を2 秒間与えた．被験者は8 つの\nハグシーンを視聴し，そのうち3 から5 つのシーンで振動刺激を受けた．各シーンの視聴\n19\n後，感情に関する10 個の形容詞で評価を行った結果，振動刺激のあるハグシー",
            "た．各シーンの視聴\n19\n後，感情に関する10 個の形容詞で評価を行った結果，振動刺激のあるハグシーンにおい\nて「喜び」の感情が増幅または抑制される可能性が示唆された．\nCerdan らは，特定のタイミングで振動が発生するコインモーターを装着したグローブを\n設計し，感情的刺激を含む映像を視聴する際の視聴者の脳波を，振動の有無による2 条件\nで記録し，触覚刺激の影響を評価した[56]．触覚刺激を含む映像視聴時には，前頭部およ\nび眼窩前頭部の脳領域において，活動がより広範かつ活発になることが示された．これに\nより，振動による触覚刺激が追加されることで，注意に関連する脳領域の活動が増加し，\nその結果，感情処理に関連する領域の活動も強まることが示唆された．\nTara らは，映像視聴時の上半身への振動刺激のタイミングが皮膚コンダクタンス反応や\n主観的評価に与える影響を調査した[57]．ホラービデオでは怪物の初出現と同時の振動\nが恐怖反応を最大化し，400 ミリ秒以上の遅延では効果が減少した．一方，フィギュアス\nケートではジャンプ時の振動が興奮を促し，最適なタイミングは視聴者ごとに異なった．\nまた",
            "フィギュアス\nケートではジャンプ時の振動が興奮を促し，最適なタイミングは視聴者ごとに異なった．\nまた，110Hz 以上の振動は映像体験を劣化させる可能性が示唆された．\n2.3.2\n照明刺激による影響に関する研究\nOrtiz らは，照明の色彩が室内空間での感情に与える影響を調査した[58]．LED ストラ\nイプとマイコンを用いて光色（赤，オレンジ，黄，緑，水色，青，紫，ピンク）を制御し，\n被験者は白い壁の部屋で各色にさらされた際の感情をアンケート（緊張，娯楽，魅力な\nど）で評価した．結果，暖色系の光は緊張感があり，熱く，好ましくないと評価され，寒\n色系の光は悲しさを伴うが，心地よいと評価された．また，感情に対する色の影響は男女\nで類似しており，LED ストライプの色の特性として説明できることが示唆された．\nIwamoto らは，デート中のユーザ同士の不安を解消する手法として，ユーザの興奮度合\nいをLED の光色で視覚的に表示することでデートセッションを支援するソファ「Lovable\nCouch」を提案した[59]．光電式容積脈波センサで取得した心拍信号から興奮度合いを算\n出し，その興奮度",
            "ch」を提案した[59]．光電式容積脈波センサで取得した心拍信号から興奮度合いを算\n出し，その興奮度合いに基づいてソファに備わるLED を赤色点灯する仕組みを構築した．\nシステム評価の結果，このシステムを通じて相手の愛情度の推測に役立ち，非言語的コ\nミュニケーションを支援し，不安を和らげる効果がある可能性が示唆された．\nWilms らは，色相（青，緑，赤），明度（低，中，高），彩度（低，中，高）の3 次元の\n色空間を操作し，色の刺激が情動に与える影響を主観的評価と生体信号で調査した[60]．\n被験者は30 通りの光色刺激をLED パネルで提示され，自己評価マネキン（SAM）を用\nいて感情を主観評価し，同時に皮膚コンダクタンス反応（SCR）と心拍数を記録された．\n結果として，主観的評価において色の変化は価値（valence）よりも覚醒（arousal）に強\nい影響を与え，特に彩度および明度を調整した上で赤が最も覚醒度を高めることが示され\nた．さらに，赤への色相の移行でSCR が増加し，覚醒度の評価と一致した．このことか\nら，色の感情への影響は色相，明度，彩度の組み合わせで決まり，それらの",
            "度の評価と一致した．このことか\nら，色の感情への影響は色相，明度，彩度の組み合わせで決まり，それらの相互作用を考\n慮することが重要であると示唆された．\nWeijs らは，明度（低，中）と彩度（中，高）が異なる赤色または青色の仮想室内環境\nを用いて，色の刺激が情動に与える影響を主観評価と生体信号で調査した[61]．被験者は\n各光色条件で暴露され，自己評価マネキン（SAM）で感情を主観評価し，同時に皮膚電\n気活動（EDA）と心電図を記録された．結果では，主観評価と光色条件の間に有意な相関\nは見られなかったが，明度が心拍数と心拍変動（RMSSD）に有意な影響を，色相がEDA\n20\nに影響を与えることが確認された．特に，低明度・高彩度および中明度・中彩度の赤色条\n件でEDA が高かった．このことから，色の感情への影響は色相だけでなく，明度や彩度\nも重要であることが示唆された．\nBuechner らは，赤色刺激が情動の覚醒および価数（感情的な肯定性・否定性）の認知に\n及ぼす影響を調査した[62]．310 名の被験者を，赤色条件または青色条件のテストとニュー\nトラル条件に分け，テスト条件ではネガテ",
            "310 名の被験者を，赤色条件または青色条件のテストとニュー\nトラル条件に分け，テスト条件ではネガティブな写真を，ニュートラル条件では自然風景\n写真を4 枚提示した．各写真の枠は条件に応じた色で囲まれており，5 秒間の観覧後に覚\n醒度と価値を主観評価した．結果，赤色は刺激の価数に関係なく覚醒度の認知を高め，ネ\nガティブ画像を見た被験者において，赤色は中立的な画像に比べて否定的な価数の認知を\n強化することが確認された．\nKim らは，動画視聴における情動体験を強化するために，情動に基づいたインタラク\nティブな照明制御システムを提案し，動画視聴中に赤色光と青色光の2 種類の照明条件で\nの生理的反応を評価した[63]．図2.9 は，任意の動画に対して照明を照射した際の様子を\n示している．興奮を促す動画視聴中に赤色光を使用した場合，心拍間隔と高周波・超低周\n波比率が有意に低下し，一方で，リラックスする動画視聴中に青色光を使用すると，これ\nらの値が有意に増加することが確認された．この結果から，情動状態に応じた照明制御が\n情動体験の質を向上させる可能性が示唆された．\n図2.9: 各動画鑑賞時に制御",
            "状態に応じた照明制御が\n情動体験の質を向上させる可能性が示唆された．\n図2.9: 各動画鑑賞時に制御された光色で照射される様子（[63] より引用）\nShin らは，明るさと色温度を制御した直接と間接照明（ダウンライト400lx，アップラ\nイト300lx）と直接照明（ダウンライト700lx）の2 つの照明環境で，直接と間接照明を併\n用した環境が感情や脳活動に与える影響を調査した[64]．脳波を測定中に各照明環境が4\n分間提示され，その後に照明環境についての感情を評価した．直接照明と間接照明を併用\nした環境では，直接照明環境に比べてシータ波と「快適」に有意な相関があり，直接照明\nと間接照明の併用が空間の快適性や情動的な反応に影響を与えることが示唆された．\n2.3.3\n温冷刺激による影響に関する研究\n馬場らは，ペルチェ素子を使用した温冷刺激提示機能を組み込んだゲームコントローラ\nを用いて，温度変化量とユーザの反応速度の関係性を調査した[65]．制作したゲームコン\nトローラは，一般的なコントローラへの応用を考慮した形状設計とし，温冷刺激モジュー\nルを実装可能なサイズで構築した．実験の結果，温",
            "ーラへの応用を考慮した形状設計とし，温冷刺激モジュー\nルを実装可能なサイズで構築した．実験の結果，温冷刺激提示後のユーザの反応時間にお\nいて，温冷感ともに約3 秒で温度変化を知覚できることが確認された．特に冷却提示に関\n21\nしては，温度の下降速度が速くなるほど，温度変化の知覚反応時間が有意に速くなること\nが明らかとなった．\nTsuruno らは，動画鑑賞時の興奮を高めるために，温熱刺激が興奮的知覚を増強するか\nどうかを検証した[66]．温熱刺激装置を使用し，左前腕に温熱刺激を与え，興奮反応は皮\n膚コンダクタンスの変化を用いて記録した．被験者は温熱刺激の有無による2 つの条件下\nで3 本の動画を視聴し，視聴後に感情の度合いに関するアンケートに回答した．結果とし\nて，温熱刺激の有無による興奮感には有意差が確認されなかったが，ある動画においては\n緊張感に有意差が認められた．これにより，温熱刺激の提示時の温度変化速度が影響を与\nえる可能性が示唆された．\n2.3.4\n生体信号に基づいた演出変化による影響に関する研究\nDekker らは，ホラー型FPS（First Person Shooter）",
            "よる影響に関する研究\nDekker らは，ホラー型FPS（First Person Shooter）ゲームにおいて，生体信号に基づい\nてゲーム内の演出を動的に変化させることで，ゲーム体験を強化する手法を開発した[67]．\n指先で心拍変動とガルバニック皮膚反応を測定するセンサデバイスを装着したマウスを\n使用し，各生体信号に応じてゲーム内の音量や画面の色度などを調整した．その結果，ホ\nラーゲームを好むユーザに対してはこの手法が効果的であることが確認されたが，ホラー\nゲームを好まないユーザには効果が限定的であることが示唆された．\n荒木らは，脈拍測定バンドを用いて，ユーザの脈拍数に応じてホラーゲーム内の演出が\n変化するヘッドマウントディスプレイ対応のホラーゲームを開発した[68]．この手法によ\nるホラーゲーム体験では，多くのユーザが強い恐怖を感じることが確認され，恐怖感を提\n供するコンテンツとして高く評価された．一方で，非常に強い恐怖感によりゲームの進行\nが困難になるユーザや，ほとんど恐怖を感じないユーザも確認され，恐怖感に対する個人\n差が存在することが示唆された．\n2.4\n情動喚起の機序理論",
            "ないユーザも確認され，恐怖感に対する個人\n差が存在することが示唆された．\n2.4\n情動喚起の機序理論とその応用\n2.4.1\n情動喚起の機序\nJames は，情動体験に先立って生理的活動が生じると示唆している[69]．つまり，外部\n刺激に対して不随意的に身体的変化が起こり，その後に脳がそれを知覚することで情動が\n生じるという機序である．具体例として，\n「熊に遭遇する」といった外部刺激に対し，心\n臓の鼓動が速くなったり，発汗が生じるなどの身体的反応が最初に発生し，それを脳が認\n識することで「恐怖」といった情動を体験すると説明される．この理論に基づくと，情動\nは身体的変化の結果として主観的に感じられるものであり，身体的変化がなければ情動も\n存在しないと考えられる．この機序理論は一般に「抹消起源説」と呼ばれる．\nCannon らは，情動体験には生理的活動の認知が必ずしも必要ではないと示唆している\n[70]．つまり，外部刺激に対して脳の中枢である視床（視床下部）が処理を行い，この視\n床の働きによって情動が生じるという機序である．外部刺激に伴う身体的変化は，視床に\nよる処理過程の結果に過ぎないと考",
            "て情動が生じるという機序である．外部刺激に伴う身体的変化は，視床に\nよる処理過程の結果に過ぎないと考えられる．実験においても，脳と内臓をつなぐ神経を\n切除した動物において情動体験に変化が見られないことが確認された．この機序理論は一\n般に「中枢起源説」と呼ばれる．\n22\nSchachter らは，情動体験には生理的活動とそれに対する解釈（ラベル付け）の相互作用\nが生じると示唆している[71]．つまり，外部刺激に対して不随意的に身体的変化が生じ，\nその変化の原因に対する解釈が情動を引き起こすという機序である．具体例として，\n「熊\nに遭遇する」といった外部刺激に対し，心臓の鼓動が速くなったり，発汗が生じるなどの\n身体的変化が発生し，それと同時に「熊に襲われて負傷するかもしれない」という恐怖の\n認識が加わることで，これらの身体的変化が「恐怖」という情動として体験されると説明\nされる．この機序理論は一般に「情動二要因説」と呼ばれる．\n図2.10 は上記の機序理論をまとめた概要図である．\n「抹消起源説」では，自律神経系の\n活動によって生じる身体的変化の認知が情動体験に繋がるとする理論が主張されてい",
            "説」では，自律神経系の\n活動によって生じる身体的変化の認知が情動体験に繋がるとする理論が主張されている．\n一方で，\n「中枢起源説」は，視床を中心とした脳内機能の処理によって情動が体験されると\nする理論であり，これに対して批判的な立場を取っている．情動喚起の機序に関しては，\n近年では身体的変化の認知が情動体験に影響を与える可能性が示唆され，\n「抹消起源説」を\n間接的に支持する考えが述べられている[72][73]．\n図2.10: 情動喚起の機序理論の概要図\n2.4.2\n擬似心拍刺激を利用した情動喚起に関する研究\nValins は，感情的な刺激に対する評価が心拍などの内的反応の認知によってどのように\n影響されるかを検証した[74]．被験者にセミヌードの女性のスライドを提示し，擬似的な\n心拍音を聴かせた．スライド中の女性の魅力を100 点満点で評価させ，心拍音を自身のも\nのと信じ込ませたグループと，無関係な音であると説明したグループで比較した結果，前\n者は心拍音を上昇させた際に女性の魅力得点をより高く評価した．これにより，擬似的な\n心拍音が情動評価に影響を与える可能性が示唆された．\nInamo",
            "り高く評価した．これにより，擬似的な\n心拍音が情動評価に影響を与える可能性が示唆された．\nInamori は，擬似的な心拍音フィードバックがヌードスライドの評価に与える影響と，実\n際の心拍数との関連を調査した[75]．被験者には，心拍数に応じて音源が移動することを\n説明し，12 枚のヌードの女性のスライドを心拍数の増加・減少・一定の3 条件でランダム\nに提示した．スライド中の女性の魅力を100 点満点で評価させた結果，心拍数が増加する\n条件で他の条件より有意に高い評価が得られた．また，スライド提示中の実際の心拍数は\n23\nすべての条件で低下していた．このことから，Valins の見解を支持し，環境刺激に対する\n認知的・感情的評価は，実際の心拍数の変化に関係なく，フィードバック条件により修正\nされる可能性が示唆された．\nGray らは，偽の心拍フィードバックが感情評価に与える神経活動の影響を調査した[76]．\n実験では，3分間の運動条件（強弱のグリップ）中に感情的な顔画像（happy，angry，neutral）\nを提示し，感情強度を4 段階で評価させた．同時に，実心拍と同期・非同期およ",
            "gry，neutral）\nを提示し，感情強度を4 段階で評価させた．同時に，実心拍と同期・非同期および偽の\n心拍音フィードバックを提示し，運動中は遅い心拍数，非運動時は速い心拍数のフィード\nバックを行った．結果，偽の心拍音は中立的な表情の評価を強調し，運動の有無は影響し\nないことが確認された．また，この行動変化に対応する脳活動は，右前部島皮質および扁\n桃体に見られた．これにより，右前部島皮質が身体的変化の認知やその解釈に重要な役割\nを果たすことが示唆された．\nNishimura らは，ユーザの好意的感情を制御するため，クッションに組み込まれた擬似\n心拍提示装置を開発した[77]．この装置は，実際の心拍数を基に擬似心拍音を振動として\n生成する．心拍数の増加・一定・提示なしの3 条件でグラビア画像と組み合わせた結果，\n擬似心拍振動を提示した増加および一定の条件では，提示なしに比べて，好みとする写真\nの選択確率が高いことが確認された．これにより，周波数の調整が不要で，ランダムな心\n拍音の提示でも効果がある可能性が示唆された．\nUeoka らは，ホラー映像の没入感を高めるため，擬似的な心拍フィ",
            "も効果がある可能性が示唆された．\nUeoka らは，ホラー映像の没入感を高めるため，擬似的な心拍フィードバックを利用し\nたロッカー型の3D 映画鑑賞環境を構築した[78]．図2.11 はロッカー型の3D 映画鑑賞環\n境を示している．床面振動を用いて，リアルタイムで心拍数を参照し心拍振動を増加させ\nる手法および，設定した心拍数まで段階的に振動を増加させる手法を比較した．ホラー映\n画鑑賞の結果，リアルタイムに心拍振動を増加させる手法では，擬似心拍の上昇に伴い実\n際の心拍数も同期して上昇することが確認された．これにより，振動フィードバックが恐\n怖体験を強め，ユーザの心拍数と同期した疑似心拍数の生成は心拍数の変化に効果的であ\nることが示唆された．\n図2.11: ロッカー型の3D 映画鑑賞環境（[78] より引用）\n24\nPescara らは，スマートウォッチの触覚振動アクチュエータを利用し，ゲーム内のヒット\nポイント（HP）を擬似的な心拍振動で表現するシステム「LifeTact」を開発した[79]．HP\nが100%では45bpm，1%では166bpm とし，HP が0%時には振動が徐々に停止す",
            "]．HP\nが100%では45bpm，1%では166bpm とし，HP が0%時には振動が徐々に停止するよう\nに設定した．システムの評価では，画面上の視覚情報，視覚と触覚振動の併用，触覚振動\nのみの3 条件でゲーム体験を比較し，質的アンケートを実施した．結果，触覚振動で残り\nHP を推定でき，システム全体の満足度が高いことが確認された．\nOgawa らは，ゲーム中に提示される偽心拍音を自身のゲーム体験と関連付けて認識す\nることで，ゲームへの没入感やモチベーションにどのような影響を与えるかを調査した\n[80]．被験者は果物を拾うアクション性のあるゲームを3 分間プレイ中，実際の心拍に同\n期した音や，心拍が徐々に加速・減速する偽心拍音をヘッドホンで提示され，その後ゲー\nム体験に関するアンケートに回答した．結果，+5 bpm/min で心拍音が加速するパターン\nは，モチベーションを維持し，ゲームに対する没入感を向上させる効果が確認された．た\nだし，この効果は心拍音が実際の心拍と関連付けられる場合に限られ，関連がないと知ら\nれると効果が得られないことが明らかになった．\nOmata らは，スマート",
            "に限られ，関連がないと知ら\nれると効果が得られないことが明らかになった．\nOmata らは，スマートフォンの周囲に取り付けた視覚的および触覚的な擬似拍動提示装\n置を用いて，スマートフォン上での動画鑑賞体験を増幅させるデバイスを開発した[81]．\nデバイスは，スマートフォンの周囲に配置したプッシュ型ソレノイドを用いて擬似的な拍\n動を表現し，動画コンテンツに対する擬似心拍の提示タイミングは，事前にシーンに合わ\nせて設定された．デバイスを用いてホラー，ジェットコースター，風景のビデオを鑑賞し\nた結果，擬似拍動提示が主観的な感情評価に有意な効果をもたらすことはなかったが，鑑\n賞中に記録された心拍数は有意に上昇していることが確認された．\nWang らは，速い心拍を模した振動や音が実際の心拍数や不安感に与える影響を調査し\nた[82]．評価実験は2 種類行われた．1 つ目の実験では，手首に振動器具を装着し，算数タ\nスク中に120bpm の振動刺激の有無で心拍数と不安感を比較した結果，振動刺激の提示で\n心拍数と不安感が増加することが確認された．2 つ目の実験では，Apple Watch とAirPod",
            "心拍数と不安感が増加することが確認された．2 つ目の実験では，Apple Watch とAirPods\nを使用し，安静時の心拍数を30%増加させた振動，音，振動と音の併用，刺激なしの4 条\n件で，安静中と算数タスク中に実施した．結果として，提示するモダリティが増えるごと\nに心拍数と不安感が段階的に増加し，特にタスク中の振動と音の併用条件で不安感が有意\nに高くなることが確認された．\nChoi らは，ユーザーの心拍数に基づいて触覚刺激を提供する手首装着型のモバイル心拍\n数調整デバイス「ambienBeat」を開発した[83]．デバイスの触覚刺激の強さとリズムは，\n認知閾値を下回るように調整され，他の作業への干渉を最小限に抑えつつ心拍数を制御\nする．心拍数の任意な調節能力と作業への干渉性について，デバイスによる触覚刺激のほ\nか，聴覚，視覚のフィードバックを用いて比較した．その結果，デバイスによる触覚刺激\nが最も効率よく心拍数を増減させる能力を有し，刺激によるタスクに対する散漫度合いが\n最も少ないことが確認された．これにより，触覚フィードバックが心拍数調節において低\n干渉かつ有効であることを示",
            "いことが確認された．これにより，触覚フィードバックが心拍数調節において低\n干渉かつ有効であることを示唆している．\n25\n第3章\n脈拍変動を用いたアクション動画鑑賞時の\n昂り状態の分類\n本章では，本研究におけるアクション動画鑑賞時の昂り状態の分類について述べる．\n3.1\nアクション動画鑑賞時の脈拍間隔の収集\n3.1.1\n脈拍間隔の収集目的\n第2 章で述べたように，心拍変動と自律神経，さらに自律神経と情動の間には密接な関\n連性があるとされている．具体的には，情動が自律神経系の活動に影響を与え，自律神経\n系が心拍や発汗といった身体的変化を制御するというメカニズムが考えられる．この関係\nに基づき，動画鑑賞中に記録された脈拍間隔を対象とした生体信号を分析し，その特徴量\nを用いることで，動画鑑賞中の情動を推定し評価することが可能であると考えられる．\n本収集実験では，スマートフォンを使用したアクション動画鑑賞中の情動的な昂り状態\n（「昂り」あるいは「昂りでない」）と脈拍間隔を取得することを目的としている．その後，\n取得した脈拍間隔を基に，二値の昂り状態を区別するための特徴量を算出し，これらの特\n徴量",
            "る．その後，\n取得した脈拍間隔を基に，二値の昂り状態を区別するための特徴量を算出し，これらの特\n徴量に対応する二値の昂り状態をラベル付けしたデータセットを作成する．そして，機械\n学習アルゴリズムを適用してモデルを訓練し，このモデルにより動画鑑賞中の昂り状態を\n分類することを目指す．この方法により，スマートフォンを使用した動画鑑賞中の情動的\n昂り状態を推定するための基盤を構築できることが期待される．\n3.1.2\n収集実験の概要\n本収集実験は，機械学習モデルによるアクション動画鑑賞時の昂り状態（「昂り」ある\nいは「昂りでない」）を分類するために必要なデータとして，スマートフォンを使用した\nアクション動画鑑賞中の情動的な昂り状態と脈拍間隔を取得することを目標として実施し\nた．被験者は成人男女9 名（21 歳～24 歳）で構成された．脈拍信号として脈拍間隔を測\n定するため，被験者にはスマートウォッチを手首に装着してもらい，冒頭から約30 分程\n度の初めて観るアクション動画をスマートフォンで鑑賞した．実験環境として，アクショ\nン動画の鑑賞中に記録される脈拍間隔が動画以外の要因に影響されないよう，",
            "た．実験環境として，アクショ\nン動画の鑑賞中に記録される脈拍間隔が動画以外の要因に影響されないよう，室内照明を\n消灯した暗室を使用し，暗室内では被験者は一人のみで動画鑑賞を実施した．図3.1 は，\n本収集実験の全体図を示している．\n本収集実験では，脈拍間隔の測定にPolar 社製スマートウォッチ「M600」[84] を使用し\nた．図3.2 は，Polar 社製M600 の外観を示している．このスマートウォッチは，スポーツ\n向け機能とスマートウォッチの利便性を兼ね備えたデバイスであり，加速度センサ，環境\n光センサ，ジャイロスコープ，バイブレーションモータ，マイクが搭載されているさらに，\n26\n図3.1: 収集実験時の全体図\nPolar 社独自の6 個のLED を使用した光学式脈拍センサを備えており，高精度な脈拍測定\nが可能である．また，アクション動画鑑賞時の脈拍間隔および情動的な昂り状態を記録す\nるために，スマートウォッチ上で専用のアプリケーションを実装した．\n図3.3 は，実装したアプリケーションの起動時の画面を示している．画面上部には，実\n行中に記録される脈拍間隔が表示される．画面下",
            "ケーションの起動時の画面を示している．画面上部には，実\n行中に記録される脈拍間隔が表示される．画面下部にはアプリケーションの実行開始ボタ\nンが配置されており，このボタンを押すことで光学式脈拍センサを用いて脈拍間隔の取得\nおよび記録が開始される．本収集実験では，アクション動画を再生する前に実行開始ボタ\nンを押す手順をとっている．そして，画面中央の橙色の領域はボタンとして機能し，被験\n者がアクション動画鑑賞中に自身の昂り状態を主観的に感じた際に押すことで，その時点\nの情動的な昂りを記録することができる．本研究で焦点を当てる「昂り」は，Russell ら\nの感情の二極性を包括した円環モデル[28]（図2.2）に基づき，縦軸で表される感情の強\n度を示す活性度が高い状態と定義する．\n「昂り」状態は活性度が高い状態を指し，興奮，緊\n張などの心理的覚醒状態を含む．この状態では，脈拍数の上昇，発汗，皮膚表面の毛の逆\n立ち（鳥肌）などの身体的変化が生じる．一方，\n「昂りでない」状態は活性度が低い状態\nを指し，リラックスや落ち着いた感情が含まれる．\nまた，実験で使用するアクション動画の題材に「ターミネータ",
            "し，リラックスや落ち着いた感情が含まれる．\nまた，実験で使用するアクション動画の題材に「ターミネーター2」[85] を採用した．こ\nの題材を選定した理由は，国内外でアクション動画として評価が高く，冒頭約30 分程度\nの間に逃走，銃撃戦，爆発などアクション性の高い映像が含まれており，被験者が鑑賞時\nに昂りを誘発されることが期待できるためである．アクション動画を再生するためのス\nマートフォンには，画面サイズが約6.1 インチの「iPhone13 Pro」[86] を使用した．\n3.1.3\nアクション動画鑑賞に関する質問票\n本収集実験では，疲労感に関する質問票と興奮度合いに関する質問票の2 種類を取り入\nれている．まず，疲労感に関する質問票は，アクション動画鑑賞の前後で被験者の疲労感\n27\n図3.2: Polar 社製M600（[84] より引用）\n図3.3: アプリケーションの起動時の画面\nに変化があるかを確認することを目的としている．特に，全被験者において疲労感が増幅\nする傾向が見られた場合，取得した脈拍間隔に対して疲労感の影響を考慮する必要があ\nる．表3.1 は，本収集実験に取り入れた",
            "合，取得した脈拍間隔に対して疲労感の影響を考慮する必要があ\nる．表3.1 は，本収集実験に取り入れた疲労感に関する質問票の質問項目一覧を示してい\nる．この質問票は，慢性的な倦怠感を評価するために開発された10 項目の自己記入式質\n問票であるFatigue Assessment Scale（FAS）[87] を参考に設計したもので，短期的な身体\n的および精神的疲労の両方を評価する構成となっている．各項目は「まったく当てはまら\nない」から「とても当てはまる」までの5 段階のリッカート尺度で回答し，総得点は10\n点から50 点の範囲で評価される．得点が高いほど強い疲労を示しており，この総得点結\n果に基づいて被験者の疲労度を測定する．\nそして，興奮度合いに関する質問票は，鑑賞したアクション動画が被験者に対して十分\nな興奮を与える動画として有用であったかを確認すること，およびアクション映画鑑賞で\n得られた脈拍間隔に情動的な興奮要素が反映されている可能性を確認することを目的と\nしている．表3.2 は，本収集実験に取り入れた興奮度合いに関する質問票の質問項目一覧\nを示している．この質問票は，興奮や満",
            "，本収集実験に取り入れた興奮度合いに関する質問票の質問項目一覧\nを示している．この質問票は，興奮や満足感に焦点を当てた10 項目の自己記入式質問票\n28\nで構成されている．各項目は「まったくそう思わない」から「非常にそう思う」までの7\n段階のリッカート尺度で回答し，総得点は10 点から70 点の範囲で評価される．得点が高\nいほど，鑑賞したアクション動画から強い興奮が得られたことを示しており，この総得点\nに基づいて被験者の興奮度合いを測定する．\n表3.1: 疲労感に関する質問票の質問項目一覧\n番号\n質問内容\n1\n倦怠感がある\n2\nとても疲れやすくなっている\n3\n日中活動できない\n4\n日中生活を送るために十分元気である\n5\n体力的に疲れ切っている\n6\n物事を始めるのが困難\n7\n明確に物事を考えるのが困難\n8\n何もやる気が起こらない\n9\n精神的に疲れ切っている\n10\n物事を行う時，とても集中できる\n表3.2: 興奮度合いに関する質問票の質問項目一覧\n番号\n質問内容\n1\n映画のアクションシーンは期待に応えましたか？\n2\n映画を観ている間，心拍数が上がったと感じましたか？\n3\n映画のストーリー展",
            "期待に応えましたか？\n2\n映画を観ている間，心拍数が上がったと感じましたか？\n3\n映画のストーリー展開に引き込まれましたか？\n4\n映画の映像効果は迫力がありましたか？\n5\n映画の音楽や効果音が興奮を助長しましたか？\n6\n映画のキャラクターに感情移入しましたか？\n7\n映画のテンポやリズムが良かったですか？\n8\n映画のアクションシーンが特に興奮させるものでしたか？\n9\n映画のストーリーやアクションシーンが緊張感を持続させましたか？\n10\n全体的に映画の冒頭30 分に満足しましたか？\n3.1.4\n収集実験の手順\nまず，実験開始前に被験者が提示されるアクション動画が初見であるかを確認し，確認\n後，被験者を実験室に案内して指定された座席に着席させる．着席後，現時点での疲労\n感を主観的に評価するため，質問票に回答してもらう．次に，被験者の手首にスマート\nウォッチを装着し，専用アプリケーションを起動する．アプリケーションの起動後，被験\n者には操作方法を説明するとともに，主観的な昂りの記録方法を説明する．ここで，心拍\n数の上昇や鳥肌といった身体的変化，または「ドキドキ」「ハラハラ」といった心理的興\n奮",
            "．ここで，心拍\n数の上昇や鳥肌といった身体的変化，または「ドキドキ」「ハラハラ」といった心理的興\n奮を感じた際に記録するよう案内する．その後，実験室の照明を消灯し暗室状態を作り出\nす．暗室内では，被験者に数分間安静を保つよう指示する．準備が整い次第，アクション\n29\n動画の再生を開始し，被験者は一人で動画を鑑賞する．鑑賞中，被験者はスマートウォッ\nチのボタンを操作し，動画を通じて感じた主観的な昂りをリアルタイムで記録する．動画\n鑑賞が終了した後，被験者には再度質問票に回答してもらい，現時点での疲労感を評価す\nる．また，アクション動画鑑賞による興奮度合いについても主観的に評価してもらう．図\n3.4 は収集実験時の被験者の様子である．\n図3.4: 収集実験時の様子\n3.2\n疲労感および興奮度合いに関する質問票の結果\n3.2.1\n疲労感に関する質問票への回答結果\n図3.5 は，アクション動画鑑賞前後に実施した疲労感に関する質問票への全被験者の回答\n結果を示している．各被験者の鑑賞前後の疲労感が得点形式で示され，この変化量を基に\n疲労感への影響を確認した．結果として，被験者全体で鑑賞後の疲労感",
            "得点形式で示され，この変化量を基に\n疲労感への影響を確認した．結果として，被験者全体で鑑賞後の疲労感が増加する傾向は\n観察されなかった．また，変化に関しては統計的に有意な差がない（p 値= 0.514 > 0.05）\nという結果が得られた．この結果から，アクション動画鑑賞が被験者の疲労感に大きな影\n響を与えるとは判断できない．したがって，アクション動画鑑賞が被験者の疲労感を増幅\nさせた可能性は少ないと評価できる．\n30\n図3.5: 鑑賞前後に実施した疲労感に関する質問票の回答結果\n3.2.2\n興奮度合いに関する質問票への回答結果\n図3.6 は，アクション動画鑑賞後に実施した興奮度合いに関する質問票への全被験者の\n回答結果を示している．各被験者の鑑賞後の興奮度合いが得点形式で示され，総得点を基\nに興奮度合いへの影響を確認した．結果として，全被験者のアクション動画に対する評価\nの平均点は52.6 点，標準偏差は6.7 点であることが確認された．この平均点は，各質問項\n目に対して「ややそう思う」と肯定的な評価がされている可能性を示している．また，標\n準偏差が6.7 点であることから，得点分布",
            "」と肯定的な評価がされている可能性を示している．また，標\n準偏差が6.7 点であることから，得点分布に大きなばらつきは見られないことが考えられ\nる．一方で，一名の被験者（図3.6 中では”Subject 2”）の総得点が他の被験者と比較して\n低いことが確認された．この被験者からは，\n「ターミネーター同士のバトルはそこそこっ\nて感じでした」という意見が得られており，この意見が低得点と関連している可能性があ\nる．しかし，全体としては，平均点が肯定的な評価の水準にあり，鑑賞後に一定の興奮が\n誘発されている傾向が考えられる．これらの結果に基づき，アクション動画鑑賞が被験者\nに一定の興奮を誘発させた可能性があると評価できる．また，アクション動画鑑賞時に記\n録された脈拍間隔において，興奮状態の影響が反映されていると考えられる．\n3.3\n脈拍間隔に対する特徴量の算出\n3.3.1\n記録した脈拍間隔および情動的な昂り\n本収集実験では，各被験者のアクション動画鑑賞中の脈拍間隔および主観評価による情\n動的な昂りのタイムスタンプを収集した．図3.7 は，被験者A のアクション動画鑑賞中に\n記録された脈拍間隔に",
            "りのタイムスタンプを収集した．図3.7 は，被験者A のアクション動画鑑賞中に\n記録された脈拍間隔に，情動的な昂り状態のタイムスタンプを重ね合わせたものを示して\nいる．青色のプロットは時系列における脈拍間隔を示し，赤い破線は被験者が情動的な昂\nりを記録したタイムスタンプを表している．この時点では，時系列における脈拍間隔の変\n動と情動的な昂りを記録したタイムスタンプの前後において変化を確認することはできな\nい．また，図3.8 は，被験者B のアクション動画鑑賞中に記録された脈拍間隔に，情動的\n31\n図3.6: 鑑賞後に実施した興奮度合いに関する質問票の回答結果\nな昂り状態のタイムスタンプを重ね合わせたものを示している．プロットを見る限り，両\n被験者における時系列の脈拍間隔の変動には明確な類似性は確認できない．しかし，情動\n的な昂りを記録したタイムスタンプの傾向として，鑑賞した動画の冒頭部分および終盤に\n記録が集中する傾向が見られる．実際に該当する部分は格闘，銃撃，爆発などのアクショ\nン性の高い映像が描写されている．\n図3.7: 被験者A のアクション動画鑑賞中の脈拍間隔\n本収集実験で得ら",
            "高い映像が描写されている．\n図3.7: 被験者A のアクション動画鑑賞中の脈拍間隔\n本収集実験で得られた各被験者のアクション動画鑑賞中の脈拍信号を基に，脈拍間隔か\nら特徴量を算出する．その後，情動的な昂りのタイムスタンプを用いて特徴量にラベル付\nけを行い，作成したデータセットを機械学習に適用することで，昂り状態を特徴量から分\n類できるようにする．\n32\n図3.8: 被験者B のアクション動画鑑賞中の脈拍間隔\n3.3.2\n脈拍変動の解析手法\n動画鑑賞中の昂り状態を脈拍間隔から分類するためには，収集した時系列の脈拍間隔に\n見られる脈拍変動に基づき，二値の昂り状態を区別するための特徴量を算出する必要が\nある．この特徴量を算出する際には，脈拍変動の解析手法として主に「時間領域解析」と\n「周波数領域解析」の2 つが用いられる．それぞれの手法は異なる観点から脈拍変動を評\n価するものであり，自律神経系の活動を多面的に解析することが可能である．\nまず，時間領域解析（Time Domain Analysis）とは，時間に関連する指標を計算して心\n拍数や心拍間隔の変動を解析する手法である．この手法は複雑な",
            "s）とは，時間に関連する指標を計算して心\n拍数や心拍間隔の変動を解析する手法である．この手法は複雑な計算を必要とせず，心拍\nリズムの変化を簡易に測定できる基本的なアプローチとして，心臓の自律神経活動を評価\nする際に広く活用されている．表3.3 は，時間領域解析によって算出される主な指標を示\nしている．一方，周波数領域解析（Frequency Domain Analysis）は，時間領域解析とは異\nなり，心拍間隔の変動を周波数成分に分解し，それぞれの成分の振幅をスペクトル密度と\nして表現する手法である．スペクトル密度は，パワースペクトルやパワースペクトル密度\n（PSD: Power Spectral Density）とも呼ばれる．この解析により，自律神経系（交感神経お\nよび副交感神経）の活動を特定の周波数帯域に対応付けて評価することが可能となる．一\n般的な周波数領域解析手法としては，高速フーリエ変換や最大エントロピー法が用いられ\nている[29]．表3.4 は，周波数領域解析によって算出される主な指標を示している．\n表3.3: 時間領域解析で算出される主な指標（[88] より引用）\n指標\n",
            "る主な指標を示している．\n表3.3: 時間領域解析で算出される主な指標（[88] より引用）\n指標\n単位\n定義\nMean\nms\n心拍間隔全体の平均値\nSDNN\nms\n心拍間隔全体の標準偏差\nRMSSD\nms\n隣接する心拍間隔の差の二乗和の平均の平方根\nSDSD\nms\n隣接する心拍間隔の差の標準偏差\nNN50\n隣接する心拍間隔の差分が50ms 以上の回数\npNN50\n%\n心拍間隔全体に対する隣接する心拍間隔の差分が50ms 以上の割合\n33\n表3.4: 周波数領域解析で算出される主な指標（[88] より引用）\n指標\n単位\n定義\nLF\nms2\n0.04～0.15Hz のパワー\nLF norm\nnu\n0.04Hz 以上のパワーに対するLF の割合\nHF\nms2\n0.15～0.40Hz のパワー\nHF norm\nnu\n0.04Hz 以上のパワーに対するHF の割合\nLF/HF\nHF に対するLF の割合\nTotalPower\nms2\n0.40Hz までの総パワー\n3.3.3\n時系列の脈拍間隔に対する前処理\n収集実験で記録された時系列の脈拍間隔から特徴量を算出するにあたり，生の脈拍間隔\nデータに",
            "する前処理\n収集実験で記録された時系列の脈拍間隔から特徴量を算出するにあたり，生の脈拍間隔\nデータには脈拍センサのノイズや外部要因（体動や接触不良）による異常値が含まれてい\nる可能性がある．このような異常値が特徴量の算出に使用されると，ノイズの影響によっ\nて算出結果が歪む可能性がある．そのため，具体的な特徴量の算出に先立ち，記録された\n生の脈拍間隔データに対して異常値を除去する前処理を行う．\n本論文では，異常値を除去する前処理を「異常値検出」と「異常値の補完」の2 つの段\n階で行う．異常値検出では，ノイズの影響によって正確に記録されていない可能性がある\n脈拍間隔値を特定する．次に，異常値の補完では，検出された異常値を新たに補完した脈\n拍間隔で置き換える処理を行う．異常値をそのまま削除する削除法ではなく，補完法を採\n用した理由として，脈拍変動に基づく特徴量の算出，特に周波数領域解析において削除法\nが推奨されていないことが示唆されているためである[89]．さらに，補完法は生データに\n含まれるサンプル数を保持できる点で優れているため，本研究では補完法を選択した．\nまず，生の脈拍間隔データに対",
            "サンプル数を保持できる点で優れているため，本研究では補完法を選択した．\nまず，生の脈拍間隔データに対する異常値検出には，連続する脈拍間隔の差が200ms 以\n上であるものを閾値として設定し，この閾値を超えた脈拍間隔を異常値として検出する方\n法を採用した．連続する脈拍間隔の差が200ms 以上である場合，脈拍センサの誤検出で\nある可能性が高いことに加え，心臓に何らかの疾患があることを示唆する可能性があるた\nめである．本論文では，収集実験で記録された脈拍間隔データが連続的な正常洞調律で記\n録されていることを仮定している．そのため，連続する脈拍間隔の差が200ms 以上であ\nる場合を異常値として検出する基準とした．\nそして，検出された異常値に対する補完方法では，0 次補完，線形補完，スプライン補\n完，非線形予測補完など様々なアルゴリズムが存在する[89]．本論文では，0 次補完に相\n当する直近の3 点の脈拍間隔から計算された平均値で補完する方法と，異常値が連続する\n場合には線形補完を用いて，直近の2 点を結ぶ直線から指定する時間に対応する値で補完\nする方法を採用した．2 種類の補完方法を採用",
            "近の2 点を結ぶ直線から指定する時間に対応する値で補完\nする方法を採用した．2 種類の補完方法を採用した理由は，連続する異常な脈拍間隔に対\nして0 次補完を利用すると，同じ平均値を使用することで脈拍間隔の時系列に平坦な形状\nが生じることが確認されたためである．一方，線形補完では傾斜状の形を作り出すことが\n確認されている．これらの特徴を考慮し，実際の脈拍間隔のトレンドを反映しつつ異常値\nを補完するために，2 種類の補完方法を場合分けして使用するアプローチが相互に補完の\n問題を解決できると考えられる．\n図3.9 は，異常値検出および補完を行う前の生の脈拍間隔データを示している．一方，\n34\n図3.10 は，異常値検出および補完を行った後の脈拍間隔データを重ね合わせて示してい\nる．異常値検出および補完を行う前の生の脈拍間隔データでは，周期的な変動が見られる\nものの，特に図中央付近で急激な値の変化が確認される．この変化は脈拍間隔の変動トレ\nンドから大きく逸脱しており，脈拍センサのノイズや誤検出によるものであると考えられ\nる．このようなノイズを処理しない場合，算出される特徴量が不正確になる可能性",
            "よるものであると考えられ\nる．このようなノイズを処理しない場合，算出される特徴量が不正確になる可能性が高\nい．これに対して異常値の検出および補完を行った結果，急激な値の変化が解消され，正\n常な脈拍間隔データが得られることが確認された．これにより，脈拍変動の正確な解析に\n必要なデータ品質が確保される．\n図3.9: 異常値検出および補完する前の生の時系列脈拍間隔\n図3.10: 異常値検出および補完前後の脈拍間隔データで重ね合わせ\n3.3.4\n特徴量の算出\n脈拍センサのノイズや外部要因（体動や接触不良）による異常値を処理した時系列の脈\n拍間隔データに対して，時間領域解析および周波数領域解析を行い，それぞれの解析に\nよって得られる特徴量を算出する．本論文では，解析を行う際の時系列の脈拍間隔に対す\nる窓サイズを240 秒，シフトサイズを5 秒と設定した．この設定を採用した理由は，後の\n35\n機械学習モデルの分類性能評価において，この窓サイズおよびシフトサイズを用いること\nで他の設定よりも良好な分類性能が得られたためである．\n周波数領域解析を行うには，等間隔の脈拍間隔データが必要となる．これは，通",
            "性能が得られたためである．\n周波数領域解析を行うには，等間隔の脈拍間隔データが必要となる．これは，通常の脈\n拍間隔データが心臓の拍動ごとにサンプル点を記録する形式であるため，時間軸上で等間\n隔になっておらず，周波数領域解析に適さないためである．そのため，本論文では，1 秒\n間隔の脈拍間隔データに変換するため，リサンプリングを実施した．リサンプリングには\n線形補完を用い，1 秒間隔のサンプル点を補完してデータを整えた．この処理により，周\n波数領域解析に適した等間隔のデータが得られるようにした．\nまた，周波数領域解析手法には，高速フーリエ変換（FFT: Fast Fourier Transform）を使\n用した．高速フーリエ変換とは，波形を正弦波の組み合わせとして仮定し，時系列データ\nから周波数成分を効率的に求めるアルゴリズムである．通常，有限長のデータを無限長の\n周期信号として扱い，窓関数を適用することで信号端の不連続性による影響を軽減する\n[90]．周波数領域解析に高速フーリエ変換を利用した理由は，計算処理が高速であるとい\nう利点を持つためである．高速フーリエ変換には，データが短い場合",
            "した理由は，計算処理が高速であるとい\nう利点を持つためである．高速フーリエ変換には，データが短い場合にスペクトルの精度\nが低下する欠点があるものの，リアルタイムで周波数解析を行うような実装において，計\n算負荷を抑える必要があることを考慮し，本手法を利用した．\nそして，異常値を処理した時系列の脈拍間隔データに対して時間領域解析を，1 秒間隔\nにリサンプリングした脈拍間隔データに対して周波数領域解析を行い，二値の昂り状態\nを分類するための特徴量を算出した．表3.5 は，本論文で時間領域解析および周波数領域\n解析に基づいて算出した特徴量を示している．時間領域解析では，窓サイズ内の脈拍間隔\nデータにおける最大値，最小値，平均値などの標準的な指標を特徴量として算出した．一\n方，周波数領域解析では，高速フーリエ変換を用いて脈拍間隔の波形に含まれる周波数成\n分を求めた．その際，0.04～0.15Hz の低周波数帯（LF: Low Frequency）と0.15～0.40Hz\nの高周波数帯（HF: High Frequency）のパワースペクトルを算出し，それらの割合や総パ\nワーを示す指標を含めて特徴",
            "gh Frequency）のパワースペクトルを算出し，それらの割合や総パ\nワーを示す指標を含めて特徴量として加えた．\n表3.5: 本論文で算出した特徴量\n領域解析\n指標\n定義\n時間領域解析\nMax\n心拍間隔全体の最大値\nMin\n心拍間隔全体の最小値\nMean\n心拍間隔全体の平均値\nSDNN\n心拍間隔全体の標準偏差\nRMSSD\n隣接する心拍間隔の差の二乗和の平均の平方根\npNN20\n心拍間隔全体に対する隣接する心拍間隔の差分が20ms 以上の割合\npNN50\n心拍間隔全体に対する隣接する心拍間隔の差分が50ms 以上の割合\n周波数領域解析\nLF\n0.04～0.15Hz のパワー\nHF\n0.15～0.40Hz のパワー\nLF/HF\nLF とHF の比率\nTotalPower\n0.40Hz までの総パワー\n特徴量の算出では，時系列の脈拍間隔データに対して解析を行う際の窓サイズを240 秒，\nシフトサイズを5 秒と設定し，時間領域および周波数領域解析によって合計11 個の特徴\n36\n量を算出した．時系列の脈拍間隔データを240 秒の窓サイズで5 秒ずつシフトすること\nで，各被験者ごとに特徴量を",
            "．時系列の脈拍間隔データを240 秒の窓サイズで5 秒ずつシフトすること\nで，各被験者ごとに特徴量を算出した時点の経過時間と，それに対応する11 個の特徴量\nが組み合わさった時系列の特徴量データが作成される．この特徴量データに二値の昂り状\n態のラベル付けを行うことで，特徴量と情動状態の関連を学習する機械学習モデルの構築\nが可能となる．\n3.4\nラベル付けとデータセットの作成\n3.4.1\nラベル付けの目的\n本研究では，アクション動画鑑賞時の二値の昂り状態を機械学習を用いて分類する．機\n械学習には「教師あり学習」と「教師なし学習」の2 種類が存在するが，本研究では教師\nあり学習を利用する．教師あり学習とは，事前に用意した各入力データに対応する正解ラ\nベルが付与された訓練データを用いてモデルを訓練し，新たなデータに対して分類（カテ\nゴリ分け）や回帰（連続値の予測）を行う手法である．したがって，教師あり学習では，\n正解ラベルが付与された訓練データの準備が不可欠であり，昂り状態を分類するモデルを\n生成する上で重要な役割を果たす．ラベル付けでは，二値の昂り状態を分類する教師あり\n学習のための訓練デ",
            "生成する上で重要な役割を果たす．ラベル付けでは，二値の昂り状態を分類する教師あり\n学習のための訓練データを作成することを目的とする．\n3.4.2\nラベル付けの基準\n本研究における二値の昂り状態のラベル付けには，収集実験中に被験者が鑑賞時に記録\nした主観評価による情動的な昂りのタイムスタンプを活用する．このタイムスタンプは被\n験者自身によって記録されたものであり，タイムスタンプが記録された時点およびその前\n後の脈拍間隔には，アクション動画によって引き起こされた情動的な昂りが反映されてい\nると考えられる．したがって，特徴量に対するラベル付けは，設定したタイムスタンプの\n前後の区間に該当する特徴量を「昂り」とし，それ以外の特徴量をすべて「昂りでない」\nとする．\n複数の研究では，動画鑑賞中に引き起こされた情動の時点を中心に，その前後を対応す\nる情動のラベル付け区間として設定しており，前後数十秒から数分とされている[48][47]．\n本研究では，\n「昂り」とラベル付けするタイムスタンプの前後の区間を「前10 秒」，\n「後30\n秒」と設定した．前10 秒と設定した理由は，アクション動画鑑賞中に被験",
            "を「前10 秒」，\n「後30\n秒」と設定した．前10 秒と設定した理由は，アクション動画鑑賞中に被験者が昂りを引\nき起こされ，それを知覚するまでの過程を考慮したためである．また，後30 秒と設定し\nた理由は，情動的な昂りの影響がアクション動画からの刺激と共に一定の持続時間を伴\nうことを考慮したためである．さらに，感情誘導後に脈拍変動における副交感神経指標\n（ANI: Analgesia Nociception Index）が2 分以内に回復することを示した研究[91] や，皮\n膚電気活動における皮膚伝導反応が刺激提示後に即座に反応し，十数秒以内に収束する事\n象を確認した研究[92] を踏まえ，生体信号は情動喚起時に即座に反応し，短時間で回復\nすることを考慮したためである．\n図3.11 は，本研究で行う二値の昂り状態のラベル付け方法を示している．プロット図中\nの赤破線は，被験者が鑑賞時に記録した主観評価による情動的な昂りのタイムスタンプを\n示しており，その前後の薄い赤色の領域は前10 秒，後30 秒の区間を表している．また，\n37\n複数の紺色枠は，窓サイズ240 秒，シフトサイズ5 秒で",
            "後30 秒の区間を表している．また，\n37\n複数の紺色枠は，窓サイズ240 秒，シフトサイズ5 秒で設定したスライディングウィンド\nウ手法による特徴量の算出範囲を可視化している．時系列の脈拍間隔データから算出され\nた特徴量データは，特徴量を算出した時点の経過時間（例: 0～240 秒の脈拍間隔データか\nら算出した場合，経過時間は”240 秒”として記録）と，それに対応する11 個の特徴量が\n組み合わさった時系列のデータである．その中で，経過時間が主観評価による情動的な昂\nり状態のタイムスタンプの前後区間内の時間に該当する場合，その特徴量に対するラベル\nを「昂り」とした．反対に該当しない特徴量にはすべて「昂りでない」とした．\n図3.11: 算出した特徴量に対するラベル付け方法\n3.4.3\nデータセットの作成\n算出した時系列の特徴量データに対するラベル付け方法を設定し，それに基づいて全て\nの被験者から算出した特徴量データにラベル付けを行った．表3.6 は，ラベル付けされた\n全ての特徴量をまとめて作成したデータセット内のラベルの分布を示している．機械学習\n用に作成したデータセットでは，時間領",
            "めて作成したデータセット内のラベルの分布を示している．機械学習\n用に作成したデータセットでは，時間領域および周波数領域から算出した11 個の特徴量\nを1 組として，合計3175 組のラベル付けされた特徴量データが記録されている．その内\n訳は，約76%（2420 組）が「昂りでない」とラベル付けされ，約24%（755 組）が「昂\nり」とラベル付けされている．\n表3.6: 作成したデータセット内のラベルの分布\n昂り\n昂りでない\n合計\nラベル数\n755\n2420\n3175\n比率\n23.8%\n76.2%\n100%\n比率を見ると，\n「昂りでない」とラベル付けされた特徴量データが7 割以上を占めており，\nこのデータセットをそのまま機械学習に使用すると，クラス不均衡の問題が発生する可能\n性がある．クラス不均衡の問題とは，訓練された機械学習モデルが「昂りでない」（多数\n38\n派クラス）を過剰に予測し，\n「昂り」（少数派クラス）を正しく分類できなくなる可能性を\n示唆するものである．この問題を解決する方法の一つとして，少数派クラスである「昂\nり」のデータを増やすオーバーサンプリング手法が挙げられる．しかし",
            "一つとして，少数派クラスである「昂\nり」のデータを増やすオーバーサンプリング手法が挙げられる．しかし，本研究では，作\n成したデータセットをそのまま使用し，モデルの分類性能を精度（accuracy）だけでなく，\n少数派クラスである「昂り」を正しく分類できているかを示す再現率（recall）などを用\nいて評価する．\n3.5\n機械学習アルゴリズムの選定と機械学習モデルの作成\n3.5.1\n機械学習アルゴリズムの選定\n本研究では，アクション動画鑑賞時の二値の昂り状態でラベル付けされた特徴量データ\nを用いて，教師あり学習による機械学習を実施し，二値の分類タスクを行う分類モデルを\n作成する．分類モデルの作成にあたり，任意の機械学習アルゴリズムを選択し，どのアル\nゴリズムが二値の昂り状態をより高い精度で分類できるかを調査する必要がある．本研\n究では，複数の機械学習アルゴリズムを用い，学習させた機械学習モデルの分類精度を比\n較した．比較検証には，人工知能や機械学習の分野で広く活用されているプログラミング\n言語「Python」[93] を使用し，Python で利用可能なオープンソースの機械学習ライブラリ",
            "言語「Python」[93] を使用し，Python で利用可能なオープンソースの機械学習ライブラリ\n「scikit-learn」[94] を活用した．\n分類精度の比較対象とした機械学習アルゴリズムは，ロジスティック回帰（Logistic Re-\ngression），サポートベクターマシン（SVM），決定木（Decision Tree），ランダムフォレ\nスト（Random Forest），k 近傍法（k-Nearest Neighbors），ナイーブベイズ（Naive Bayes），\n勾配ブースティング（Gradient Boosting）の合計7 種類である．各アルゴリズムを用いて\n学習させた機械学習モデルの分類精度を評価するために，層化シャッフルk 分割交差検証\nを利用した．層化シャッフルk 分割交差検証とは，シャッフルしてランダム化したデータ\nセットをk 個の等しいサイズの部分集合（フォールド）に分割する際，各フォールド内の\n目的変数（ラベル）のクラス分布がデータセット全体のクラス分布と一致するように調整\nする交差検証手法である[95]．この手法の主な利点は，クラス不均衡への対応",
            "分布と一致するように調整\nする交差検証手法である[95]．この手法の主な利点は，クラス不均衡への対応である．ク\nラスごとのデータ数に偏りがある場合でも，層化によって各フォールド内のクラス分布を\nデータ全体の分布に近似させることができるため，特定のクラスが欠落したり過剰に含\nまれたりするリスクを軽減し，評価の一貫性を保つことができる．一方，通常のk 分割交\n差検証では，データセットを単純にk 個のフォールドに分割するため，各フォールドのク\nラス分布が全体の分布と一致しない可能性がある．特にクラスの不均衡がある場合，ある\nフォールドに特定のクラスのデータがほとんど含まれない，または全く含まれないことが\n起こり得る．この結果，交差検証による分類精度の評価が不正確になる可能性がある．\n表3.7 は，層化シャッフル10 分割交差検証を適用し，機械学習アルゴリズムを用いて学\n習した各モデルによる二値の昂り状態の分類精度を示している．また，図3.12 は，各機\n械学習モデルの分類精度を棒グラフで可視化し，比較を容易にしたものである．結果とし\nて，ランダムフォレストに基づくアルゴリズムによる機械学習モ",
            "し，比較を容易にしたものである．結果とし\nて，ランダムフォレストに基づくアルゴリズムによる機械学習モデルが最も高い分類精度\nを示した．ランダムフォレストは，複数の決定木で予測されたクラスの多数決を基に分類\n結果を出力するアルゴリズムであり，過学習の影響が少ないという利点を持つ．以上の結\n39\n果を踏まえ，本研究では，アクション動画鑑賞時の二値の昂り状態を分類する機械学習モ\nデルにランダムフォレストに基づくアルゴリズムを選定する．\n表3.7: 各機械学習モデルの平均分類精度の一覧\nモデル名\n平均精度\n標準偏差\nLogistic Regression\n0.762\n0.0\nSVM\n0.763\n0.001\nDecision Tree\n0.905\n0.015\nRandom Forest\n0.936\n0.013\nK-Nearest Neighbors\n0.910\n0.012\nNaive Bayes\n0.719\n0.017\nGradient Boosting\n0.841\n0.011\n図3.12: 機械学習モデルの分類精度の比較\n3.5.2\n選定した機械学習アルゴリズムによる分類性能\n二値の昂り状態を",
            "学習モデルの分類精度の比較\n3.5.2\n選定した機械学習アルゴリズムによる分類性能\n二値の昂り状態を分類する機械学習モデルとしてランダムフォレストに基づくアルゴリ\nズムを選定したが，前項では層化シャッフルk 分割交差検証による平均の分類精度のみが\n評価されていた．したがって，より詳細な分類性能について評価し，特に「昂り」を正し\nく分類する能力を確認する必要がある．\n表3.8 は，層化シャッフル10 分割交差検証によって得られたランダムフォレストに基づ\nく機械学習モデルの詳細な分類性能を示す分類レポートの平均値を示している．また，図\n3.13 は，同じ交差検証によって得られた分類結果をまとめた混同行列の平均を示してい\nる．分類レポートの平均を見ると，クラス1（「昂り」）を正しく分類する指標である再現\n率（recall）が0.824 であることが確認できる．つまり，\n「昂り」とラベル付けされた特徴\n量に対して，機械学習モデルは82.4%の精度で「昂り」と正しく分類する性能を持つこと\nを示している．また，混同行列の平均では，誤分類された数も確認されるが，正しく分類\nされた数がそれを上回ってい",
            "いる．また，混同行列の平均では，誤分類された数も確認されるが，正しく分類\nされた数がそれを上回っていることが確認され，モデルの性能の有効性を裏付けている．\n40\n表3.8: 層化シャッフル10 分割交差検証による分類レポートの平均\nClass\nPrecision\nRecall\nF1-Score\nSupport\n0\n0.947\n0.970\n0.958\n484\n1\n0.898\n0.824\n0.859\n151\nAccuracy\n0.936\n0.936\n0.936\n0.936\nMacro Avg\n0.922\n0.897\n0.908\n635\nWeighted Avg\n0.935\n0.936\n0.935\n635\n図3.13: 層化シャッフル10 分割交差検証による混同行列の平均\nランダムフォレストに基づくアルゴリズムによって学習した二値の昂り状態を分類する\n機械学習モデルは，分類精度の平均が他のモデルより高いことに加え，\n「昂り」とラベル\n付けされた特徴量を正しく分類する性能が確認された．したがって，アクション動画鑑賞\n時の二値の昂り状態を特徴量から分類するために，このランダムフォレストに基づく機",
            "，アクション動画鑑賞\n時の二値の昂り状態を特徴量から分類するために，このランダムフォレストに基づく機械\n学習モデルを使用し，最終的に分類モデルを作成する．\n3.5.3\n機械学習モデルの作成\n本研究では，ランダムフォレストに基づくアルゴリズムによって訓練された機械学習モ\nデルをスマートウォッチ上で動作する専用アプリケーションに組み込む必要がある．その\nため，機械学習モデルの作成には，オープンソースの機械学習ソフトウェアであるWEKA\n（Waikato Environment for Knowledge Analysis）[96] を利用する．WEKA はJava 言語で開\n発されたデータマイニングおよび機械学習ソフトウェアであり，分類，回帰，クラスタリ\nング，関連ルールの発見，データの可視化など，多様なデータ分析に対応している．さら\nに，WEKA を利用することで，作成した機械学習モデルをファイル形式（.model）とし\n41\nて保存できる．この形式は，WEKA のライブラリ（weka.jar）を用いることで，Java アプ\nリケーションやAndroid アプリケーションに容易に組み込む",
            "ar）を用いることで，Java アプ\nリケーションやAndroid アプリケーションに容易に組み込むことが可能である．\n最後に，昂り状態を示すラベル付けがされた特徴量データを使用し，WEKA 上でラン\nダムフォレストに基づくアルゴリズムによって訓練した二値の昂り状態を分類する機械学\n習モデルを作成した．このモデルをスマートウォッチ上の専用アプリケーションに組み込\nみ，スマートウォッチで取得した脈拍間隔データから算出した特徴量を機械学習モデルに\n入力することで，鑑賞者の昂り状態を分類し，推定できる仕組みが構築される．\n42\n第4章\n昂りに連動した動画鑑賞体験拡張スマート\nフォンアクセサリー\n本章では，昂りに連動した動画鑑賞体験拡張スマートフォンアクセサリーについて述\nべる．\n4.1\nシステムの概要\n4.1.1\nシステムの構成\n本研究では，スマートフォンを用いた動画鑑賞時において，ユーザの脈拍変動を基に\n「昂り」を判定し，その結果に連動して擬似心拍刺激を提示することで，動画鑑賞時の情\n動体験を強化する手法として，昂りに連動した動画鑑賞体験拡張スマートフォンアクセサ\nリーを提案する．図4.1",
            "を強化する手法として，昂りに連動した動画鑑賞体験拡張スマートフォンアクセサ\nリーを提案する．図4.1 は，提案システムの全体構成を示す概要図を示している．\n図4.1: 提案システムの概要図\n本システムは，大別して2 つの構成に分かれている．1 つ目は，スマートフォンを用い\nた動画鑑賞中のユーザの昂り状態を判定する部分であり，2 つ目は，その判定結果に基づ\nいて擬似心拍刺激を動画鑑賞中のユーザに提示する部分である．ユーザの昂り状態を判定\nする部分では，脈拍センサ付きのスマートウォッチで取得した脈拍データを活用し，機械\n学習モデルを用いてユーザの昂り状態を判定する．これにより，リアルタイムで動画鑑賞\n43\n中のユーザの情動的な昂り状態を把握することが可能である．昂り状態の判定結果に基づ\nいて擬似心拍刺激を提示する部分では，判定された昂りに連動して，振動および照明によ\nる実際のユーザの脈拍数に基づいた擬似的な心拍刺激を，製作したスマートフォンアクセ\nサリーを通じて提示する．\n4.1.2\nシステムの動作の流れ\n本研究のシステムの動作の流れを図4.2 に示す．本システムを実現するために，脈拍セ\n",
            "ムの動作の流れ\n本研究のシステムの動作の流れを図4.2 に示す．本システムを実現するために，脈拍セ\nンサ付きのスマートウォッチ，クラウドデータベース，マイクロコントローラを組み合わ\nせて使用している．各領域のプログラムは，相互に通信を行いながら，リアルタイムでの\nデータ処理とユーザへのフィードバックを実現している．本研究のシステムにおける各領\n域で使用されるデバイスやソフトウェア，およびその処理内容について以下に説明する．\n図4.2: 本研究のシステムの動作の流れ\nまず，脈拍センサ付きのスマートウォッチにはPolar 社製「M600」[84] を使用する．処\n理内容は，主に3 節で述べた「脈拍間隔に対する特徴量の算出」の過程をリアルタイムで\n実行し，\n「機械学習モデルの作成」で作成した二値の昂り状態（「昂り」または「昂りでな\nい」）に分類する機械学習モデルを使用する．具体的には，スマートウォッチ上で行われ\nるリアルタイムの処理は以下のように進行する．動画鑑賞中に取得される脈拍間隔データ\nは，異常値についての処理の後，逐次専用のデータリストに格納される．この取得処理と\n並行して，脈拍間隔",
            "は，異常値についての処理の後，逐次専用のデータリストに格納される．この取得処理と\n並行して，脈拍間隔データを1 秒間隔にリサンプリングし，別のデータリストに格納され\nる．次に，リサンプリングされたデータリストが設定した240 秒の窓サイズに達すると，\n特徴量の算出処理が開始される．この時点で，周波数領域の特徴量はリサンプリングされ\nたデータリストから算出され，時間領域の特徴量は元の脈拍間隔データリストから240 秒\n分のデータを抽出して算出される．算出された特徴量は，二値の昂り状態を分類する機械\n学習モデルに入力される．機械学習モデルはこれらの特徴量を基に昂り状態を分類し，分\n44\n類結果は直近2 回分の分類結果と比較され，多数決に基づいて最終的な昂り状態が判定さ\nれる．そして，判定した昂り状態を表したデータはクラウドデータベースに送信される．\nその後，設定した5 秒のシフトサイズでデータリストをスライドさせて次の処理を開始\nする．\n次に，クラウドデータベースとしてGoogle 社が提供する「Firebase Realtime Database」\n[97] を使用する．Firebase",
            "する「Firebase Realtime Database」\n[97] を使用する．Firebase Realtime Database は，クラウドホスト型のNoSQL データベー\nスであり，データをJSON 形式で保存し，接続されたすべてのクライアント間でリアルタ\nイムに同期する機能を備えている．このデータベースは，スマートウォッチで出力された\n昂り状態についてのデータを保存し，振動や照明によるフィードバックを駆動させるマイ\nクロコントローラに更新されたデータを渡すようにして，データの橋渡し役を担う．\n最後に，マイクロコントローラとして，M5Stack 社が開発した超小型IoT デバイス開発\nモジュール「Atom-Lite」[98] を使用する．図4.3 はAtom-Lite の外観を示している．Atom-\nLite は，24 × 24mm という非常に小型のサイズで設計され，多数のGPIO を備えており，\nホームデバイスや玩具の製作など，組み込み用途への活用に適している．メイン制御に\nは，Wi-Fi 接続機能を統合したESP32-PICO チップを採用し，4MB のフラッシュメモ",
            "に\nは，Wi-Fi 接続機能を統合したESP32-PICO チップを採用し，4MB のフラッシュメモリを\n内蔵している．本研究では，Atom-Lite をスマートフォンアクセサリーに組み込む形で使\n用する．このマイクロコントローラは，振動および照明を用いた擬似心拍刺激を駆動させ\nる役割を担う．処理内容としては，Wi-Fi を介してクラウドデータベースに接続し，デー\nタベースから受信した昂り状態を表すデータを検証する．検証の結果，データが「昂り」\nを表すとされる場合，併せて送信されるユーザの脈拍数を基に，振動および照明が同期し\nた擬似心拍刺激を提示させる．\n図4.3: M5Stack 社製Atom-Lite の外観および比較（[98] より引用）\n4.2\n昂り判定に連動した擬似心拍刺激\n4.2.1\n擬似心拍刺激を提示する目的\n本研究では，アクション動画鑑賞中の脈拍変動から算出した特徴量を基に，機械学習モ\nデルを用いて判定される昂り状態に連動して，ユーザの脈拍数に基づいた「擬似心拍刺\n激」を提示する．昂りとする判定時に擬似心拍刺激を提示する理由は，動画鑑賞中のユー\nザの昂りを効果的に高める",
            "提示する．昂りとする判定時に擬似心拍刺激を提示する理由は，動画鑑賞中のユー\nザの昂りを効果的に高める必要があるためである．\nまず，情動がどのように生み出されるかについての理論を振り返る．情動に関する理論\nでは，少なからず身体的変化が情動の形成に関与するとされている[69][70][71]．特に，抹\n45\n消起源説では，外部刺激により心拍数の上昇などの身体的変化を認知することで情動が生\nじると説明されている．この理論に基づいた関連研究では，視覚刺激とともに高い擬似心\n拍音を提示することで，対象の魅力が向上することが確認されている[74][75][77]．これ\nにより，擬似心拍刺激が情動を意図的に操作できる可能性が示唆されている．\nこれらを踏まえ，本研究では，情動と生理的反応が互いに結びついていることに着目し，\n擬似心拍刺激が情動体験を促進する可能性があると仮定した．この仮定に基づき，ユーザ\nの実際の脈拍数に基づいて意図的に高い擬似心拍刺激を提示することで，昂りを認識さ\nせ，さらに昂りを高めることが可能であるかを仮説として検証する．\nまた，擬似心拍刺激をフィードバックする手段として，本研究",
            "ることが可能であるかを仮説として検証する．\nまた，擬似心拍刺激をフィードバックする手段として，本研究では，動画鑑賞における\n振動と照明によるフィードバックの効果に着目した．振動については，ジャケットやグ\nローブ型デバイスを用いて映像に合わせた振動を提示することで，緊張感や興奮を高め\nる効果が示唆されている[50][52]．照明については，昂りを促す動画に赤色の光を提示す\nることで，生理的な覚醒が上昇し，適切な照明が動画体験を向上させることが示唆されて\nいる[63]．これらの知見から，擬似心拍刺激に振動と照明を用いることで，動画鑑賞中の\n「昂り」をさらに高める効果が期待できる．\n4.2.2\n振動を提示する機器の検討\n本研究では，擬似心拍刺激を提示するために振動を利用する．このため，振動機器を選\n定した．選定基準は，擬似心拍を利用したフィードバックにおいて，単調な音よりも心臓\nの拍動を模倣した音が効果的であることを示唆した研究[80] を参考に，心臓の拍動を模\n倣できる多様な振動を提示可能であることに加え，動画鑑賞中の振動による雑音が発生し\nない静音性を備え，振動が十分に知覚できる強度を持",
            "あることに加え，動画鑑賞中の振動による雑音が発生し\nない静音性を備え，振動が十分に知覚できる強度を持つ振動機器を選定基準とした．\n振動機器の選定にあたり，複数の振動機器を試用した．はじめに試用したのは，M5Stack\n社製の振動ユニット「Unit Vibrator」[99] である．図4.4 は，振動ユニット「Unit Vibrator」\nの外観を示している．この振動ユニットには，直流電圧で動作する小型ギヤードモータで\nあるN20 モータが搭載されており，モータの回転によって露出した偏心錘が回転し，振動\nを提示する仕組みである．Atom-Lite とは専用のケーブルを介して容易に接続でき，PWM\n信号を使用して振動の強弱を調整することが可能である．しかし，偏心錘の回転により全\n体が振動する設計のため，強力な振動を起こすと，振動に伴うモータの動作音が大きいこ\nとが確認され，本研究の振動提示としては不十分であることが確認された．したがって，\n本研究ではこの振動モーターユニットを採用しない．\n図4.4: M5Stack 社製Unit Vibrator（[99] より引用）\n46\n次に試用した",
            "図4.4: M5Stack 社製Unit Vibrator（[99] より引用）\n46\n次に試用したのは，コイン型振動モータである．図4.5 は，本研究が試用したコイン型\n振動モータを示している．コイン型振動モータは直径10mm の小型モータであり，適切\nな動作電圧を供給することで円盤部分が振動する仕組みを持つ．このモータは局所的な振\n動提示に適している点が特徴である．振動モータを制御する機器として，使用可能なPIN\n数の関係上，Arduino 社製の「Arduino UNO R4 Minima」[100] を使用した．ただし，この\n構成では振動の開始と停止のみが制御可能で，連続的な振動の強度を操作することはでき\nなかった．そのため，振動の強さを自由に制御するために，SparkFun Electronics 社製の\nモータドライバ「DRV2605L」[101] を使用し，振動モータで擬似心拍振動を表現可能に\nした．図4.6 は，SparkFun Electronics 社製のモータドライバ「DRV2605L」の外観を示し\nている．そして，図4.7 は，これらを活用したコイン型振動モータ",
            "バ「DRV2605L」の外観を示し\nている．そして，図4.7 は，これらを活用したコイン型振動モータの全体像を示している．\nしかしながら，コイン型振動モータの小型性ゆえに振動が非常に弱いことが確認され，触\n覚として擬似心拍振動を知覚するには不十分であった．また，Arduino を含む制御機器や\n配線，モータドライバが広範囲のスペースを必要とし，スマートフォンアクセサリーに組\nみ込むには実用性が低いと判断された．以上の理由から，本研究ではコイン型振動モータ\nを採用しないこととした．\n図4.5: コイン型振動モータ\n図4.6: SparkFun 社製DRV2605L\n最後に試用したのは，フォスター電機社製の振動アクチュエータ「ACOUSTICHAPTIC®\n639897」[102] である．この振動アクチュエータは，重さ28g，直径25mm，高さ27mm\nのサイズを持ち，以前に使用した振動機器と比較して重く，大型である．図4.8 は，フォ\nスター電機社製の振動アクチュエータの外観を示している．本研究では，この振動アク\nチュエータを駆動させるために，BitTradeOne 社が提供する触感デ",
            "．本研究では，この振動アク\nチュエータを駆動させるために，BitTradeOne 社が提供する触感デバイス開発モジュール\n「hapstak デジタル版」[103] を利用した．\n「hapstak デジタル版」は，振動による触感の再現\nを簡便に扱えるモジュールであり，付属する駆動回路基板を使用することで，M5Stack 社\n製のAtom-Lite などのマイコンからの命令で直接音声データを再生し，振動アクチュエー\nタに振動を発生させることが可能である．さらに，振動アクチュエータにはマイコン側か\nら駆動回路を通じて電源供給が行われるため，マイコン側への電源が確保できれば，複雑\nな配線を必要としない利便性を持つ．図4.9 は，振動アクチュエータと駆動回路基板を接\n続した例を示している．この回路基板に，振動アクチュエータを制御するマイコンとマイ\nコンへの電源を接続することで，振動アクチュエータの駆動が可能となる．\n振動アクチュエータの駆動を体験するために，開発モジュールに付属する木製の組み立\n47\n図4.7: モータドライバを活用したコイン型振動モータの全体像\n図4.8: フォスター電機社製A",
            "7\n図4.7: モータドライバを活用したコイン型振動モータの全体像\n図4.8: フォスター電機社製ACOUSTICHAPTIC® 639897（[102] より引用）\nてボードを使用し，簡易的な振動提示デバイスを作成した．図4.10 は，木製の組み立て\nボードの各パーツを示している．また，図4.11 は，組み立てボードを用いて作成した振\n動提示デバイスの外観を示している．振動提示デバイスは，図に対して，左側に配置され\nた振動アクチュエータ，中央のM5Stack 社製の小型開発モジュール「Atom-Matrix」[104]，\n右側のM5Stack 社製マイコンに電源を供給する外部バッテリー「Tail Bat」[105] で構成さ\nれている．このデバイスを使用し，マイコンに格納された複数の音声データを再生させ，\n振動アクチュエータを音声データに基づいて駆動させた．その結果，非常に強い振動を\n感じられたほか，再生した音声データの表現（恐竜の足音，銃の単発発射，心臓の拍動な\nど）を触覚として正確に知覚することが可能であった．また，振動時の騒音は小さく，最\n大でも30 デシベル程度であり，寝室程",
            "に知覚することが可能であった．また，振動時の騒音は小さく，最\n大でも30 デシベル程度であり，寝室程度の静粛性を備えていることが確認された．した\nがって，本研究では，擬似心拍刺激を提示する振動機器として，フォスター電機社製の振\n動アクチュエータ「ACOUSTICHAPTIC® 639897」を採用する．また，この振動アクチュ\nエータを駆動するために，BitTradeOne 社が提供する「hapstak デジタル版」に付属する駆\n動回路基板を利用する．\n48\n図4.9: ACOUSTICHAPTIC® 639897 と駆動回路基盤との接続例（[103] より引用）\n図4.10: 木製の組み立てボード\n図4.11: 簡易的な振動提示デバイス\n4.2.3\n振動を利用した擬似心拍刺激\n本研究で選定された振動アクチュエータを駆動回路基板を用いて動作させるには，他の\n振動機器とは異なり，あらかじめ特定の振動を作成して動作させる必要がある．具体的に\nは，複数の心拍数を表現する擬似心拍を音声信号データとして作成した後，8 ビット形式\nのバイナリデータに変換してマイコン（Atom-Lite）に格納する．",
            "して作成した後，8 ビット形式\nのバイナリデータに変換してマイコン（Atom-Lite）に格納する．\n「昂り」判定時には，マ\nイコンから指定する心拍数を表現された擬似心拍の音声信号データを実行し，振動機器を\nデータに基づいて繰り返し振動させることで，擬似心拍振動が実現される．\n本研究では，振動によって提示する擬似心拍を表現する音声信号データに，BitTradeOne\n社が提供する「Heartbeat」の音声信号データ[103] を利用した．この音声信号データを選\n定した理由は，振動アクチュエータを通じて体感した際に，心臓の拍動を限りなく模倣し\nていることが確認されたためである．図4.12 は，この音声信号データを基に再生時間を1\n秒に拡張して作成した心拍数60 bpm の拍動を表現する音声信号データを示している．こ\nの音声信号データを実行し，振動機器を繰り返し振動させることで，心拍数60 bpm の擬\n似心拍振動を提示することが可能となる．さらに，再生時間を調整した波形を作成する\nことで，任意の心拍数を表現する擬似心拍振動も提示可能である．例として，再生時間\nを0.86 秒に調整して作",
            "，任意の心拍数を表現する擬似心拍振動も提示可能である．例として，再生時間\nを0.86 秒に調整して作成した音声信号データを基に振動機器を駆動させることで，心拍\n数70 bpm の擬似心拍振動を提示することが可能となる．\n振動として提示される擬似心拍を表現する時系列の音声信号データについて，時系列の\n周波数成分の強さを確認するため，スペクトログラムとして可視化を行った．図4.13 は，\n図4.12 で示した再生時間1 秒の一拍の拍動を表現する音声信号データに対するスペクト\nログラム解析の結果を示している．横軸は時間（秒単位），縦軸は周波数を表し，赤線は\n49\n図4.12: 再生時間１秒の一拍の拍動が表現された音声信号データ\n各時間時点で最も強い周波数成分を折線で結んだものである．この赤線により，時間的な\n周波数変化が可視化されている．スペクトログラムの結果から，擬似心拍を表現する音声\n信号データにおいて，最も強い周波数の平均は42Hz であることが確認された．この結果\nは，最も強い周波数成分が42Hz 前後に集中していることを示しており，振動機器がこの\n周波数帯域（40～50Hz）に基づ",
            "分が42Hz 前後に集中していることを示しており，振動機器がこの\n周波数帯域（40～50Hz）に基づいて動作する際，体感的にこの周波数帯の振動が強調さ\nれる可能性を示唆している．さらに，この周波数帯の振動は，人間が持つ振動に対する手\nのひらの知覚特性[106] に基づき，十分に知覚可能な範囲に含まれる．また，110Hz 以上\nの振動が映像視聴を妨げるという研究[57] の知見にも配慮した結果であり，映像鑑賞体\n験を損なわない振動であると考えられる．\n図4.13: 図4.12 の音声信号データに対するスペクトログラム解析の結果\n50\n4.2.4\n照明を利用した擬似心拍刺激\n本研究では，擬似心拍刺激を提示するために振動に加え，照明も利用する．照明では赤\n色光を活用した擬似心拍刺激を行う．これは，赤色光による情動への効果，視覚に対する\nフィードバックが他の感覚や認知に影響を与える錯覚効果，マルチモーダルな擬似心拍刺\n激による情動への効果という3 つの観点に基づいて使用している．\n赤色光による情動への効果は，赤色光の刺激が心理的および生理的な覚醒を促進する可\n能性に基づいている．関連研究によれ",
            "動への効果は，赤色光の刺激が心理的および生理的な覚醒を促進する可\n能性に基づいている．関連研究によれば，赤色光は情動における覚醒度を高めることが示\n唆されており[58][60]，昂りを促す動画と共に赤色光を提示することで，生理的な覚醒が\n上昇し，動画体験の質が向上する可能性が示されている[63]．これらの知見は，赤色光が\nユーザの覚醒を促し，特にアクション動画鑑賞時に情動体験を高める効果を持つことを示\n唆している．視覚に対するフィードバックが他の感覚や認知に影響を与える錯覚効果は，\n感覚間相互作用に基づいている．Narumi らは，拡張現実技術を用いて食べ物の見た目の\nサイズを操作し，見た目の変化だけで満腹感の認識を変化させ，摂取量を制御できること\nを示した[107]．また，Ban らは，視覚フィードバックを利用して指が触れる位置を変化\nさせることで，実際には円柱形の物体に触れているにもかかわらず，異なる曲率やサイズ\nを持つ仮想の形状に触れているような錯覚を誘発するシステムを開発し，85%の参加者が\nその錯覚を感じたと報告している[108]．これらの研究は，視覚的な操作が他の感覚や認\n",
            "%の参加者が\nその錯覚を感じたと報告している[108]．これらの研究は，視覚的な操作が他の感覚や認\n知に大きな影響を与える可能性を示している．このような知見に基づき，視覚的な照明効\n果として赤色光を用いた擬似心拍刺激が，実際の身体反応であると錯覚される可能性が考\nえられる．さらに，マルチモーダルな擬似心拍刺激による情動への効果は，複数の感覚器\nに対して刺激を提示することで心理的および生理的な影響を強化する可能性に基づいて\nいる．関連研究では，提示するモダリティが増加するごとに心拍数と不安感が増加するこ\nとが示唆されており[82]，赤色光による擬似心拍刺激の追加がアクション動画鑑賞時の昂\nり判定時の情動体験をさらに強化する可能性が考えられる．\n本研究では，赤色光の擬似心拍刺激を提示する照明機器として，M5Stack 社製のLED\nテープ「SK6812 Digital RGB LED Strip」を使用した．図4.14 は，使用したLED テープの\n外観を示している．本研究で使用するマイコン（Atom-Lite）とLED テープは，専用ケー\nブル[109] を用いることで容易に接続および制",
            "（Atom-Lite）とLED テープは，専用ケー\nブル[109] を用いることで容易に接続および制御が可能である．このLED テープは，マ\nイコンを通じて帯状に連なる各LED に対して個別にRGB カラーや明るさを設定できる．\nまた，任意の長さに切断や延長が可能であり，用途に応じた柔軟な対応が可能である．\n図4.14: M5Stack 社製SK6812 Digital RGB LED Strip（[110] より引用）\n図4.15 は，LED テープを用いた赤色光による擬似心拍刺激の光色の変化を示している．\n51\nこの赤色光の擬似心拍刺激は，振動による擬似心拍刺激と同期して提示されるため，振動\nに合わせて赤色が強くなるように照明制御を行う．具体的には，図4.12 に示されている\n音声信号データを基に，縦軸の振幅が大きくなるタイミング（振動機器が強く動作するタ\nイミング）に合わせて赤色の色味および明るさを上昇させる．一方で，振幅が小さい，ま\nたはないタイミング（振動機器が弱く動作する，もしくは振動がほとんど感じられないタ\nイミング）においては，赤色の色味および明るさを抑えるように制御す",
            "しくは振動がほとんど感じられないタ\nイミング）においては，赤色の色味および明るさを抑えるように制御する．\n図4.15: 赤色光を用いた擬似心拍刺激における心拍数60 bpm の光色変化\n4.2.5\nユーザの心拍数に基づく擬似心拍刺激の対応\n本研究では，アクション動画鑑賞中のユーザの脈拍変動を基に機械学習モデルが「昂り」\nと判定した場合，その判定時のユーザの脈拍数を基に，振動および照明が同期した擬似心\n拍刺激を提示する．そのため，ユーザの脈拍数に応じて提示する擬似心拍刺激の設定を\n行った．表4.1 は，判定時における実際のユーザの脈拍数と，それに対応する擬似心拍刺\n激の対応表を示している．\n本研究では，提示する擬似心拍刺激の脈拍数を，実際の脈拍数よりも高く設定している．\nこれは，実際の心拍に基づいた擬似心拍振動の提示手法において，意図的に高い擬似心拍\nを提示することで，実際の心拍数も同期して上昇することが確認された研究[78] を参考\nにしたものである．この設定により，擬似心拍刺激がユーザの生理反応に影響を与え，情\n動的な昂りを高める可能性が期待できる．\n表4.1: 実際の脈拍数と擬似心",
            "の生理反応に影響を与え，情\n動的な昂りを高める可能性が期待できる．\n表4.1: 実際の脈拍数と擬似心拍刺激の対応表\n実際の脈拍数(bpm)\n擬似心拍刺激(bpm)\n86 以上\n100\n76～85\n90\n66～75\n80\n65 以下\n70\n52\n4.3\n昂りに連動したスマートフォンアクセサリー\n4.3.1\n振動提示の設計\nスマートフォンアクセサリーでは，振動提示を持ち手に当たる手のひらに提示する設計\nとした．この設計は，人間の手の繊細な知覚処理能力を参考にしている．脳の感覚野に\nおける，人体の様々な部位に生じた感覚に対する情報処理領域を表した脳地図[111] によ\nると，手や指は大脳の大きな割合（約4 分の1）を占有していることが確認されている．\nこれは，手や指が非常に繊細で多様な感覚情報を処理する能力を持つことを示している．\n図4.16 は，スマートフォンアクセサリーで擬似心拍振動を提示するためのデザインを示\nしている．振動が持ち手部分に提示されることで，擬似心拍振動を手のひらで繊細に体感\nできることが考えられる．\n図4.16: スマートフォンアクセサリーに対する振動提示部のデザイン\n",
            "感\nできることが考えられる．\n図4.16: スマートフォンアクセサリーに対する振動提示部のデザイン\n本研究では，スマートフォンアクセサリーにおける擬似心拍振動を提示するため，振動\n提示部を3D プリンタで造形した．図4.17 は，モデリングしたデータを基に3D プリンタ\nで造形した振動提示部を示している．モデリングの際には，図4.11 に示される簡易的な振\n動提示デバイスの振動アクチュエータやマイコンの位置関係を参考に，振動アクチュエー\nタ，アクチュエータを制御するマイコン，および電源供給用の外部バッテリーを密接に配\n置できるよう設計した．さらに，図4.18 は，振動機器などを取り付けた完成形の様子を\n示している．完成時に，振動アクチュエータで振動を起こした際，造形素材であるプラス\nチックとアクチュエータの接触により雑音が発生することが確認された．これを改善する\nため，接触部分にフェルトを挿入し，接触による雑音を軽減するとともに，振動を効率的\nに振動提示部全体へ伝達するよう工夫した．\nまた，振動提示部の裏側に当たる手のひらで接触する把持部分は，丸みを帯びた形状に\n設計した．丸みを帯びた",
            "た，振動提示部の裏側に当たる手のひらで接触する把持部分は，丸みを帯びた形状に\n設計した．丸みを帯びた形状にすることで，手のひら全体に振動を効果的に伝えるととも\nに，スマートフォンアクセサリーの持ちやすさを向上させる効果がある．特に，動画鑑賞\n時にはスマートフォンアクセサリーを持ち続けることが多いため，持ちやすさは鑑賞体験\nに大きな影響を及ぼすと考えられる．把持部分に違和感があると，鑑賞中の集中が妨げら\nれる可能性があるため，持ちやすさを重視した設計は重要性を持つ．\n53\n図4.17: 造形した振動提示部\n図4.18: 振動機器などを取り付けた様子\n4.3.2\n照明提示の設計\nスマートフォンアクセサリーでは，照明提示をユーザの視覚に直接的に提示する設計\nとした．図4.19 は，LED テープを用いて光刺激による擬似心拍を提示するためのデザイ\nンを示している．LED テープはスマートフォンアクセサリーの側面に取り付けられ，各\nLED の主な光の照射方向はユーザの目に直接向いていない．しかし，LED の点灯や輝き\nはユーザから視認可能である．この場合，光の照射方向は「間接的」に見えるが，視覚",
            "LED の点灯や輝き\nはユーザから視認可能である．この場合，光の照射方向は「間接的」に見えるが，視覚\n刺激としてはユーザが直接認識できるため，\n「直接的」とみなす．また，LED テープをス\nマートフォンアクセサリーの外側の側面に取り付ける理由は，擬似心拍刺激として照射さ\nれる赤色光が，鑑賞する動画の色味に影響を与えることで，鑑賞体験に悪影響を及ぼす懸\n念を軽減するためである．\n図4.19: スマートフォンアクセサリーに対する照明提示部のデザイン\n本研究では，スマートフォンアクセサリーの側面にLED テープを取り付ける際，角形\nシリコンチューブ[112] を活用した．LED テープをそのまま側面に取り付けると，持つ際\n54\nに直接手に触れて違和感が生じる可能性があるほか，LED 素子が直接見えることで光が\n点状に見え，場合によっては発色が白っぽく感じられることがある．この問題を解決する\nため，LED テープを角形シリコンチューブに通した状態で取り付けた．これにより，手\nに触れても違和感がなくなるとともに，光がやや拡散されることで色が柔らかく見えると\nいう利点が得られる．図4.20 は，L",
            "くなるとともに，光がやや拡散されることで色が柔らかく見えると\nいう利点が得られる．図4.20 は，LED テープを角形シリコンチューブに通した状態で取\nり付け，擬似心拍刺激に扱う赤色光を照射した様子を示している．\n図4.20: 側面に取り付けたLED テープによる赤色光照射の様子\n4.3.3\nスマートフォンアクセサリーの構造\n振動提示および照明提示の設計を基に製作したスマートフォンアクセサリーを図4.21 に\n示す．スマートフォンアクセサリーの大きさは，縦の長さが約13cm，横の長さが約21.5cm，\n厚さが約6.3cm であり，単体での重さは305g である．鑑賞端末であるスマートフォンは，\nバネの反発力を利用して挟む方式で固定する．この固定方法により，一般的なスマート\nフォンのサイズ[9] に対応し，ほとんどのスマートフォンが装着可能となる．図4.22 は\nスマートフォンアクセサリーの裏面を示しており，振動提示部が両側に配置されている．\nまた，中央には照明機器を制御するマイコン（Atom-Lite）および電源供給用バッテリー\n（TailBat）を格納するポケットが取り付けられている",
            "om-Lite）および電源供給用バッテリー\n（TailBat）を格納するポケットが取り付けられている．さらに，図4.23 はスマートフォン\nアクセサリーの側面を示しており，厚さが約6.3cm あるため，手のひらで覆うようにして\nしっかりと把持することが可能である．\n55\n図4.21: スマートフォンアクセサリー\n図4.22: スマートフォンアクセサリー（裏面）\n56\n図4.23: スマートフォンアクセサリー（側面）\n57\n4.3.4\nスマートフォンアクセサリーを使用した動画鑑賞方法\nスマートフォンアクセサリーを使用した動画鑑賞方法を以下に説明する．まず，Wi-Fi\nに接続したスマートウォッチを手首に装着し，専用アプリケーションを起動する．図4.24\nは，専用アプリケーションを起動した際の画面を示しており，画面上にはデータベースと\nの接続状況，脈拍センサの測定状況，昂りの判定状況が表示される．次に，鑑賞端末であ\nるスマートフォンをスマートフォンアクセサリーに固定し，専用アプリケーションの画面\n下部にある開始ボタンを押下する．図4.25 は，開始ボタン押下後の画面を示している．開\n始ボタン",
            "面\n下部にある開始ボタンを押下する．図4.25 は，開始ボタン押下後の画面を示している．開\n始ボタンを押下すると，脈拍センサが脈拍間隔を取得し始め，取得したデータに基づいて\n昂りの判定が行われる．鑑賞終了後，スマートウォッチ上の画面下部をもう一度タップす\nることで，アプリケーションを終了する．\n図4.24: 専用アプリケーション\nの起動時の画面\n図4.25: 専用アプリケーション\nの開始ボタンを押下した後\n58\n第5章\nスマートフォンアクセサリーによるアク\nション動画鑑賞時の情動体験の影響\n本章では，第4 章で作成したシステムの評価実験の概要および実験方法について述べる．\n実験担当者は，臨床研究に携わる人のe ラーニングサイト「ICR 臨床研究入門」にて，\n「研\n究倫理と被験者保護」および「人を対象とする医学系研究に関する倫理指針」を履修し\nている．また，本実験は，青山学院大学理工学部ライフサイエンス委員会の「人に係る研\n究」に関する審査・承認を受け実施され（承認番号H23-035），被験者は実験説明を受け，\n実験に対する同意書による同意をもって，実験に参加頂いている．\n5.1\nアクシ",
            "験者は実験説明を受け，\n実験に対する同意書による同意をもって，実験に参加頂いている．\n5.1\nアクション動画における鑑賞体験への影響の検証\n5.1.1\n実験目的\n本研究のシステムは，アクション動画鑑賞中のユーザの脈波変動を基に「昂り」を判定\nし，その結果に応じた擬似心拍を表現する振動および照明刺激を提示することで，情動的\nな昂りを高めることを目標として取り組んだ．そのため，評価実験では，アクション動画\nの鑑賞中に，脈波変動に基づく昂り判定と連動した擬似心拍刺激を与えることによって鑑\n賞体験にどのような影響を与えるかを検証することを目的とする．\n5.1.2\n実験概要\n本実験では，昂りに連動した振動と照明による擬似心拍刺激を組み込んだ動画鑑賞型ス\nマートフォンアクセサリーを使用したアクション動画鑑賞が，鑑賞体験に与える影響を検\n証するために実施した．被験者は成人男女12 名（22 歳～24 歳）で構成された．実験環境\nとして，アクション動画鑑賞中に記録される脈波間隔がアクション動画以外の要因に影\n響されないよう，室内照明を消灯した暗室に加え，イヤホンを使用した．被験者は暗室内\nで1 人で実",
            "に影\n響されないよう，室内照明を消灯した暗室に加え，イヤホンを使用した．被験者は暗室内\nで1 人で実験を行い，脈波信号として脈波間隔を測定するためにスマートウォッチを手首\nに装着し，冒頭から約30 分間の初めて観るアクション動画をスマートフォンで鑑賞した．\n本実験では，提案システムの効果を検証するため，システムを使用した場合と使用しない\n場合の2 条件でアクション動画の鑑賞を行わせた．どちらの条件でも，同じ内容および時\n間のアクション動画を鑑賞したが，条件ごとに鑑賞日は別日に分けて設定した．さらに，\nシステムを使用する場合と使用しない場合の順序は被験者ごとにランダムに設定した．図\n5.1 は，本実験の全体図を示している．\n本収集実験では，脈波間隔の測定にPolar 社製スマートウォッチ「M600」[84] を使用し\nた．また，実験で使用するアクション動画の題材に「ミッション：インポッシブル」シリー\nズ[113] を採用した．この題材を選定した理由は，国内外でアクション動画として評価が\n59\n図5.1: 実験の全体図\n高く，冒頭約30 分程度の間に逃走，銃撃戦，爆発などアクション性の高い",
            "9\n図5.1: 実験の全体図\n高く，冒頭約30 分程度の間に逃走，銃撃戦，爆発などアクション性の高い映像が含まれ\nており，被験者が鑑賞時に昂りを誘発されることが期待できるためである．本実験でアク\nション動画を再生するためのスマートフォンには，画面サイズが約6.1 インチの「iPhone13\nPro」[86] を使用した．\n5.1.3\n鑑賞体験を測定する指標\n本実験では，スマートフォンアクセサリーを使用したアクション動画鑑賞が鑑賞体験に\n与える影響を評価するため，質問票を活用した定性評価と，脈波信号を活用した定量評価\nの2 つの手法を採用した．これらの手法を基に鑑賞体験の効果を測定し，差異をもって，\n鑑賞体験の向上の程度を評価する．質問票を活用した定性評価では，アクション動画鑑賞\nを通じた情動を評価するために「Self-Assessment Manikin（以下略称：SAM）」[114] を利\n用した質問票，および本研究のシステムの快適性や使いやすさを評価するために「System\nUsability Scale（以下略称：SUS）」[115] を利用した質問票を作成した．\n本実験では，シ",
            "ility Scale（以下略称：SUS）」[115] を利用した質問票を作成した．\n本実験では，システムを使用した場合と使用しない場合のアクション動画鑑賞における\n主観的な情動を評価するため，情動反応を評価する非言語的な測定指標であるSAM を使\n用した．この指標は，被験者が絵画を用いて自身の情動を直感的に評価する方法であり，\n快-不快（Valence），覚醒度（Arousal），主導感（Dominance）の3 次元に基づいて情動\nを詳細に測定するものである．快-不快は，喜びから悲しみまでの情動の幅を表し，覚醒\n度は情動の強度や興奮状態の度合いを示す．主導感は通常，自身の感情をどの程度コント\nロールできるかを測定する次元として定義される．図5.2 は，SAM を用いた評価方法の\n一例を示している．本実験では，快-不快，覚醒度，主導感の3 つの尺度について，それ\nぞれ9 段階の評価を行った．快-不快尺度では，\n「楽しい・心地よい」に相当する快表現を\n高得点とし，覚醒度尺度では，\n「興奮・刺激を感じた」に相当する覚醒度表現を高得点とし\nた．主導感では，\n「感情のコントロールできない」に",
            "・刺激を感じた」に相当する覚醒度表現を高得点とし\nた．主導感では，\n「感情のコントロールできない」に相当する主導感表現を高得点とした．\n60\nまた，主導感については，鑑賞体験における没入感の尺度として再解釈する．通常の主導\n感は対象や状況に対する感情のコントロール度を評価する次元であるが，アクション動画\n鑑賞においては，鑑賞者が映像世界にどれだけ引き込まれるかを測定する尺度として用い\nる．この解釈に基づき，主導感が低い状態は鑑賞者が映像世界に深く引き込まれ，没入感\nが高い状態を示す．反対に，主導感が高い状態は，鑑賞者が映像世界を俯瞰的に捉え，没\n入感が低い状態を示す．この再解釈により，主導感の尺度を動画鑑賞体験における没入感\nの評価に特化した指標として活用する．被験者は，各尺度について提示された9 つの人形\nの絵から，自身の情動状態に最も近いものを選択することで評価を行う．この評価方法は\n言語に依存しないため，文化的な違いや解釈のばらつきが抑えられるという特徴を持つ．\n本実験では，これらの再解釈および評価方法を通じて，アクション動画鑑賞における情動\n体験を捉える．\n図5.2: SAM（",
            "の再解釈および評価方法を通じて，アクション動画鑑賞における情動\n体験を捉える．\n図5.2: SAM（Self-Assessment Manikin）の一例（[116] より引用）\n一方で，システムを使用したアクション動画鑑賞において，システムの快適性や使いや\nすさを評価するため，本実験では製品やサービスのユーザビリティを測定する指標である\nSUS を使用した．この指標は，快適性や使いやすさに関する10 個の質問で構成されてお\nり，それぞれの質問に対して5 段階のリッカート尺度を用いて，\n「そう思う」から「そう\n思わない」までの範囲で回答する形式となっている．回答結果に基づいて各質問の得点に\n重みづけを施し，算出された総得点が72 点以上であれば，ユーザビリティが良好（good）\nであると判断できるとされる[117]．表5.1 は，本実験で被験者に提示されるSUS を用い\nた質問票の質問項目を示している．\n5.1.4\n実験手順\n実験開始前に，被験者が提示されるアクション動画が初見であることを確認し，実験室\nに案内して指定された座席に着席させる．次に，被験者の手首にスマートウォッチを装着\n",
            "を確認し，実験室\nに案内して指定された座席に着席させる．次に，被験者の手首にスマートウォッチを装着\nし，専用アプリケーションを起動して操作方法を説明する．システムを使用する条件で\nは，スマートフォンを専用アクセサリーに装着させる．\nその後，音量や画面の明るさを確認し，イヤホンを装着させた上で，実験室の照明を消\n灯して暗室状態を作り出し，数分間安静を保つよう指示する．準備が整い次第，アクショ\nン動画を再生し，被験者は暗室内で一人で動画を鑑賞する．動画鑑賞後，被験者には質問\n61\n表5.1: SUS での質問項目\n番号\n質問内容\n1\nこのシステムを頻繁に利用したいと感じた\n2\nこのシステムは必要以上に複雑だと感じた\n3\nこのシステムは使いやすいと感じた\n4\nこのシステムを使えるようになるためには，専門の助けが必要だと感じた\n5\nこのシステムはいろんな機能が上手くまとまっていると感じた\n6\nこのシステムはちぐはぐな点が多すぎると感じた\n7\nこのシステムの使い方は大抵の人がすぐに使いこなせると感じた\n8\nこのシステムはとても扱いづらいと感じた\n9\nこのシステムを使いこなせると自信がある\n10\n",
            "じた\n8\nこのシステムはとても扱いづらいと感じた\n9\nこのシステムを使いこなせると自信がある\n10\nこのシステムを使い始める前に使用法を学ぶことが多いと感じた\n票を用いて主観的な情動評価を実施する．システムを使用する条件では，情動評価に加え\nてシステムのユーザビリティ評価も行う．図5.3 は，実験中の被験者の様子である．\n図5.3: 実験時の様子\n62\n5.2\n定性評価の結果および考察\n5.2.1\nシステムの有無での情動評価の比較\nシステムを使用した場合（with）と使用しない場合（without）における情動評価を比較\nするため，SAM を利用した質問票を用いて評価を実施した．図5.4，図5.5，図5.6 は，12\n名の被験者がシステム使用の有無による条件間で実施した快-不快，覚醒度，主導感に対\nする情動評価の結果を箱ひげ図で示している．これらの図を通じて，システムの使用が各\n情動評価に与える影響を可視化している．まず，システム有無における快-不快尺度の評\n価分布を箱ひげ図で比較すると，システム有の条件では中央値および平均値がシステム\n無の条件よりも高い結果となった．また，システム有",
            "，システム有の条件では中央値および平均値がシステム\n無の条件よりも高い結果となった．また，システム有の条件では，中央値よりも平均値が\n上回っていることから，評価分布が上方向にシフトしていることが確認できる．この結果\nは，本実験において，システムを使用したアクション動画鑑賞の体験が，被験者の情動を\nポジティブな方向へと高める可能性を示唆していると考えられる．\n図5.4: システム有無での快-不快（Valence）尺度の評価分布\n次に，システム有無における覚醒度尺度の評価分布を箱ひげ図で比較すると，システム\n有の条件では中央値および平均値がシステム無の条件よりも高い結果が得られた．また，\nシステム有の条件では中央値よりも平均値が上回っており，評価分布が上方向にシフトし\nていることが確認できる．一方で，システム無の条件では中央値よりも平均値が下回って\nおり，評価分布が下方向にシフトしていることが確認され，両条件間で平均値の差が拡大\nしている．この結果は，システムを使用したアクション動画鑑賞の体験が，被験者の情動\nの強度をより高め，興奮度合いを増加させる可能性を示唆していると考えられる．\n最後",
            "験が，被験者の情動\nの強度をより高め，興奮度合いを増加させる可能性を示唆していると考えられる．\n最後に，システム有無における主導感尺度の評価分布を箱ひげ図で比較すると，システ\nム有の条件では中央値がシステム無の条件と同じ値を示しているものの，平均値はシステ\n63\n図5.5: システム有無での覚醒度（Arousal）尺度の評価分布\nム無の条件よりも高い結果が得られた．また，システム有の条件では中央値よりも平均値\nが上回っており，評価分布が上方向にシフトしていることが確認できる．一方，システム\n無の条件では中央値よりも平均値が下回っており，評価分布が下方向にシフトしているこ\nとが確認され，両条件間で平均値の差が拡大している．この結果は，システムを使用した\nアクション動画鑑賞の体験が，被験者の没入感をより高める効果を持つ可能性を示唆して\nいると考えられる．\nまた，表5.2 は，各尺度におけるシステム有無の条件間での平均値およびその差分を示\nしている．この結果から，システム有の条件が全ての尺度において平均値が高い傾向にあ\nることが確認された．特に，覚醒度尺度では他の尺度よりも高い評価が得られて",
            "おいて平均値が高い傾向にあ\nることが確認された．特に，覚醒度尺度では他の尺度よりも高い評価が得られているこ\nとが明らかとなった．しかしながら，これらの平均値の差は偶然によるものなのか，それ\nとも統計的に有意な差であるのかを判断する必要がある．そこで，有意水準を5%に設定\nし，システム有無の条件間での評価の違いについて，対応ありのt 検定を実施した．t 検\n定は，t 分布を利用して2 つの集団の平均値の差が有意であるかを検定する[118]．t 分布\nは，正規分布を母集団とし，母分散が未知の場合に用いられる分布で，少ない標本数でも\n信頼性のある分析を可能にする．t 検定の過程では，まず帰無仮説を設定する．帰無仮説\nとは，\n「平均値に差がない」といった主張であり，検定の出発点となる仮定である．例え\nば，薬の効果を検証する場合，\n「薬を投与したグループと投与しなかったグループの平均\n値に差がない」という仮説が帰無仮説となる．次に，得られたデータから算出されるt 値\nやp 値を基に仮説を検証する．t 値は平均値の差が偶然によるものかを示し，p 値は観測\n結果の希少性を示す指標である．一般的な有意",
            "t 値は平均値の差が偶然によるものかを示し，p 値は観測\n結果の希少性を示す指標である．一般的な有意水準（0.05）を基準に，p 値がこれを下回\nる場合，帰無仮説を棄却し，\n「平均値の差が統計的に有意である」と判断する．\nシステムの有無での情動評価の比較では，帰無仮説を「システムの有無でのアクション\n64\n図5.6: システム有無での主導感（Dominance）尺度の評価分布\n表5.2: システム有無での各尺度の平均と条件間の差\n快-不快尺度の平均\n覚醒度尺度の平均\n主導感尺度の平均\nシステム有\n7.4\n7.0\n7.5\nシステム無\n6.6\n5.5\n6.3\nシステム有無の差（有-無）\n0.8\n1.5\n1.2\n動画鑑賞体験において尺度の情動評価に差がない」と設定し，有意水準を0.05 とした．表\n5.3 は，対応ありt 検定を実施した結果を示している．この結果より，快‐不快および覚\n醒度については，t 値が片側検定の棄却域（1.796）に含まれており，p 値も有意水準未満\nであることから，システムの有無による情動評価に有意な差があると判断される．また，\n主導感については，t 値（2.184",
            "ステムの有無による情動評価に有意な差があると判断される．また，\n主導感については，t 値（2.184）が片側検定の棄却域（1.796）に含まれ，p 値（0.026）も\n有意水準未満であることから，システム有の条件がシステム無よりも支配感を高めると\nいう方向性の仮説を支持する結果が得られた．これらの結果から，帰無仮説は棄却され，\n快‐不快，覚醒度，支配感のいずれについても，システムの有無による情動評価に差があ\nり，システム有の条件がこれらの情動評価を向上させる可能性が示唆される．\n表5.3: システム有無での各尺度の情動評価に関する検定統計量とp 値の結果\n尺度\nt 値\n片側検定p 値\n片側検定境界値\n両側検定p 値\n両側検定境界値\n快-不快\n2.803\n0.009\n1.796\n0.017\n2.201\n覚醒度\n3.317\n0.003\n1.796\n0.007\n2.201\n支配感\n2.184\n0.026\n1.796\n0.052\n2.201\n65\n5.2.2\nシステム無での1 回目と2 回目の鑑賞時の情動評価の比較\nシステムの有無による情動評価に差があり，システム有の条件がこれらの情動評価を向",
            "賞時の情動評価の比較\nシステムの有無による情動評価に差があり，システム有の条件がこれらの情動評価を向\n上させる可能性が示唆された結果を受けて，まずはシステム無での1 回目と2 回目の鑑賞\n時の情動評価を比較し，順序効果（1 回目の鑑賞が2 回目の鑑賞に影響を与えること）の\n有無を検証した．具体的には，同じアクション動画を2 回鑑賞した場合，鑑賞回数（1 回\n目と2 回目）の違いが情動評価に与える影響を確認し，\n「情動の減衰」や「新奇性の低下」\nがどの程度起こるかを調べることを目的としている．図5.7，図5.8，図5.9 は，12 名の被\n験者がシステム無で鑑賞した際の順序（1 回目と2 回目）における快-不快，覚醒度，主導\n感に対する情動評価の結果を箱ひげ図で示している．なお，1 回目と2 回目の鑑賞におけ\nる情動評価は，異なる6 名ずつの被験者によって行われている．これらの図を通じて，シ\nステム無での鑑賞順序が情動評価に与える影響を可視化した．\nまず，システム無での鑑賞順序における快-不快尺度の評価分布を箱ひげ図で比較する\nと，1 回目の鑑賞では中央値および平均値が2 回目の鑑賞より",
            "不快尺度の評価分布を箱ひげ図で比較する\nと，1 回目の鑑賞では中央値および平均値が2 回目の鑑賞よりも高い結果が得られた．ま\nた，この尺度において，2 回目の評価の中央値が1 回目の最小値を下回っていることが確\n認された．この結果は，快-不快尺度において，鑑賞順序による順序効果が存在すること\nを示唆していると考えられる．次に，システム無での鑑賞順序における覚醒度尺度の評価\n分布を箱ひげ図で比較すると，1 回目の鑑賞では中央値および平均値が2 回目の鑑賞より\nも高い結果が得られた．また，この尺度においては，1 回目の中央値より下の評価が多数\n分布していることが確認された．この結果は，覚醒度尺度においても鑑賞順序による順序\n効果が存在する可能性を示唆していると考えられる．最後に，システム無での鑑賞順序に\nおける主導感尺度の評価分布を箱ひげ図で比較すると，1 回目の鑑賞では中央値および平\n均値が2 回目の鑑賞よりも高い結果が得られた．また，この尺度においても，1 回目の中\n央値より下の評価が多数分布していることが確認された．この結果は，主導感尺度におい\nても鑑賞順序による順序効果が存在する可",
            "数分布していることが確認された．この結果は，主導感尺度におい\nても鑑賞順序による順序効果が存在する可能性を示唆していると考えられる．\n66\n図5.7: システム無での鑑賞順序における快-不快（Valence）尺度の評価分布\n図5.8: システム無での鑑賞順序における覚醒度（Arousal）尺度の評価分布\nまた，表5.4 は，各尺度におけるシステム無での鑑賞順序の条件間における平均値およ\nびその差分を示している．この結果から，システム無での2 回目の鑑賞が全ての尺度にお\nいて平均値が低い傾向にあることが確認され，鑑賞順序による順序効果が存在する可能性\n67\nが示唆される．しかしながら，これらの平均値の差が偶然によるものか，統計的に有意な\n差であるのかを判断する必要がある．そこで，有意水準を5%に設定し，システム無での\n鑑賞順序による評価の違いについて，対応なしのt 検定を実施した．\n図5.9: システム無での鑑賞順序における主導感（Dominance）尺度の評価分布\n表5.4: システム無での鑑賞順序における各尺度の平均と条件間の差\n快-不快尺度の平均\n覚醒度尺度の平均\n主導感尺度の平均",
            "での鑑賞順序における各尺度の平均と条件間の差\n快-不快尺度の平均\n覚醒度尺度の平均\n主導感尺度の平均\n1 回目\n6.8\n6.0\n6.6\n2 回目\n6.3\n5.0\n6.0\n鑑賞順序における差（2 回目-1 回目）\n-0.5\n-1.0\n-0.6\nシステム無での鑑賞順序における情動評価の比較では，帰無仮説を「システム無での鑑\n賞順序におけるアクション動画鑑賞体験において各尺度の情動評価に差がない」と設定\nし，有意水準を0.05 とした．表5.5 は，対応なしt 検定を実施した結果を示している．こ\nの結果より，快‐不快，覚醒度，および支配感について，いずれもt 値が片側検定の棄却\n域（1.812）および両側検定の棄却域（2.228）のいずれにも含まれず，p 値も有意水準以上\nであることから，システム無の鑑賞順序による情動評価に有意な差は確認されなかった．\nこれらの結果から，帰無仮説は棄却されず，鑑賞順序が情動評価に影響を及ぼす可能性は\n低いことを示唆している．\n68\n表5.5: 鑑賞順序における各尺度の情動評価に関する検定統計量とp 値の結果\n尺度\nt 値\n片側検定p 値\n片側検定境界値\n両側",
            "各尺度の情動評価に関する検定統計量とp 値の結果\n尺度\nt 値\n片側検定p 値\n片側検定境界値\n両側検定p 値\n両側検定境界値\n快-不快\n0.785\n0.225\n1.812\n0.451\n2.228\n覚醒度\n1.035\n0.163\n1.812\n0.325\n2.228\n支配感\n0.674\n0.258\n1.812\n0.515\n2.228\n5.2.3\nシステム有での1 回目と2 回目の鑑賞時の情動評価の比較\n次に，システム有での1 回目と2 回目の鑑賞時の情動評価を比較し，システム使用によ\nる効果が鑑賞順序（1 回目・2 回目）に依存しないことを検証した．特に，システム有を\n2 回目に使用した場合でも，情動評価に変化が見られるかを確認し，システムの効果が一\n貫して情動評価を向上させているかを明らかにすることを目的としている．また，システ\nム無と有の条件を比較することで，有意差をもってシステム有の条件が情動評価を向上さ\nせる可能性を検討し，順序効果の影響を考慮する．図5.10，図5.11，図5.12 は，12 名の\n被験者がシステム有で鑑賞した際の順序（1 回目と2 回目）における快-不快，覚醒",
            "2 は，12 名の\n被験者がシステム有で鑑賞した際の順序（1 回目と2 回目）における快-不快，覚醒度，主\n導感に対する情動評価の結果を箱ひげ図で示している．なお，1 回目と2 回目の鑑賞にお\nける情動評価は，異なる6 名ずつの被験者によって行われている．これらの図を通じて，\nシステム有での鑑賞順序が情動評価に与える影響を可視化した．\nまず，システム有での鑑賞順序における快-不快尺度の評価分布を箱ひげ図で比較する\nと，1 回目と2 回目の中央値および平均値には大きな違いが見られないことが確認された．\nまた，分布の範囲においては，1 回目の方がわずかに広がりが大きいものの，全体的な評\n価の傾向は一貫している．この結果は，快-不快尺度において，鑑賞順序による順序効果\nが影響を及ぼしていない可能性を示唆していると考えられる．次に，システム有での鑑賞\n順序における覚醒度尺度の評価分布を箱ひげ図で比較すると，1 回目と2 回目の中央値や\n平均値に大きな違いは見られないものの，2 回目では中央値および平均値がやや高い傾向\nが確認された．また，分布の範囲においては，2 回目の最大値が1 回目の最大値",
            "び平均値がやや高い傾向\nが確認された．また，分布の範囲においては，2 回目の最大値が1 回目の最大値を上回り，\n評価分布が上方向にシフトしていることが確認された．さらに，評価のばらつきも2 回目\nの方が増加していることが示されている．この結果は，覚醒度尺度において，鑑賞順序が\n評価に影響を与える順序効果が存在する可能性を示唆していると考えられる．最後に，シ\nステム有での鑑賞順序における主導感尺度の評価分布を箱ひげ図で比較すると，1 回目と\n2 回目の中央値および平均値には大きな違いが見られないことが確認された．しかし，分\n布の範囲においては，2 回目の方がわずかに広がりが大きく，評価のばらつきが増加して\nいることが確認された．この結果は，主導感尺度において，鑑賞順序が評価に影響を与え\nる順序効果が存在する可能性を示唆していると考えられる．\n69\n図5.10: システム有での鑑賞順序における快-不快（Valence）尺度の評価分布\n図5.11: システム有での鑑賞順序における覚醒度（Arousal）尺度の評価分布\nまた，表5.6 は，各尺度におけるシステム有での鑑賞順序の条件間における平",
            "usal）尺度の評価分布\nまた，表5.6 は，各尺度におけるシステム有での鑑賞順序の条件間における平均値およ\nびその差分を示している．システム有での1 回目と2 回目の各尺度の情動評価を比較する\nと，類似した結果が得られる尺度もあれば，分布の違いが見られる尺度も存在したもの\n70\n図5.12: システム有での鑑賞順序における主導感（Dominance）尺度の評価分布\nの，平均値の差は全体的に0 に近い傾向を示していることが確認された．この結果は，鑑\n賞順序による順序効果が存在しない可能性を示唆していると考えられる．しかしながら，\nこれらの平均値の差が偶然によるものか，統計的に有意な差であるかを判断する必要があ\nる．そのため，有意水準を5%に設定し，システム有での鑑賞順序による評価の違いにつ\nいて，対応なしのt 検定を実施した．\n表5.6: システム有での鑑賞順序における各尺度の平均と条件間の差\n快-不快尺度の平均\n覚醒度尺度の平均\n主導感尺度の平均\n1 回目\n7.3\n6.7\n7.7\n2 回目\n7.5\n7.3\n7.3\n鑑賞順序における差（2 回目-1 回目）\n0.2\n0.6\n-0.4\nシ",
            "回目\n7.5\n7.3\n7.3\n鑑賞順序における差（2 回目-1 回目）\n0.2\n0.6\n-0.4\nシステム有での鑑賞順序における情動評価の比較では，帰無仮説を「システム有での鑑\n賞順序におけるアクション動画鑑賞体験において各尺度の情動評価に差がない」と設定\nし，有意水準を0.05 とした．表5.7 は，対応なしt 検定を実施した結果を示している．こ\nの結果より，快‐不快，覚醒度，および支配感について，いずれもt 値が片側検定の棄却\n域（1.812）および両側検定の棄却域（2.228）のいずれにも含まれず，p 値も有意水準以上\nであることから，システム有の鑑賞順序による情動評価に有意な差は確認されなかった．\nこれらの結果から，帰無仮説は棄却されず，鑑賞順序が情動評価に影響を及ぼす可能性は\n低いことを示唆している．\n71\n表5.7: 鑑賞順序における各尺度の情動評価に関する検定統計量とp 値の結果\n尺度\nt 値\n片側検定p 値\n片側検定境界値\n両側検定p 値\n両側検定境界値\n快-不快\n-0.349\n0.367\n1.812\n0.734\n2.228\n覚醒度\n-0.845\n0.209\n1.812",
            "349\n0.367\n1.812\n0.734\n2.228\n覚醒度\n-0.845\n0.209\n1.812\n0.418\n2.228\n支配感\n0.620\n0.275\n1.812\n0.549\n2.228\n5.2.4\n快適性および使用感の評価\n本研究のシステムを使用したアクション動画鑑賞時におけるシステムの快適性や使いや\nすさを評価するため，SUS を利用した質問票を用いて評価を実施した．具体的には，ス\nマートウォッチの装着からスマートフォンをスマートフォンアクセサリーに固定し，動画\n鑑賞を行う一連の操作に関するユーザビリティを被験者に評価してもらった．図5.13 は，\n12 名の被験者がSUS の10 項目に基づくユーザビリティに関する質問に回答し，それぞ\nれの得点を重み付けして算出されたSUS スコアを可視化したものである．この図を通じ\nて，システム全体の快適性や使いやすさに関する評価結果を視覚的に確認することができ\nる．全体の得点結果を見ると，12 名の被験者全員の得点は75 点から100 点の範囲に分布\nしている．特に，図中で示されている被験者2 および被験者7 は満点（100 点）を記録",
            "の範囲に分布\nしている．特に，図中で示されている被験者2 および被験者7 は満点（100 点）を記録し\nており，システムのユーザビリティについて非常に高い評価を与えていることがわかる．\nまた，全被験者の平均点は86.5 点であり，全般的に高い評価が得られていることが考え\nられる．一方で，最低得点を記録した被験者は被験者9 であり，その得点は約75 点であっ\nた．この結果は，全体として本システムが快適性や使いやすさにおいて良好な評価を受け\nたことを示している．\n全被験者の平均点を基に，本システムを用いたアクション動画鑑賞におけるユーザビリ\nティの評価を行った．図5.14 は，SUS に基づく評価得点に対する評価尺度[117] を示して\nいる．この評価尺度にある許容度（Acceptability）の基準を適用すると，全被験者の平均\n点である86.5 点は「acceptable」に該当する．また，被験者から評価された最低点である\n約75 点についても同様に「acceptable」に該当することが確認された．以上の結果から，\n本システムのユーザビリティは高く評価されており，十分に許容できるレベ",
            "が確認された．以上の結果から，\n本システムのユーザビリティは高く評価されており，十分に許容できるレベルの快適性と\n使いやすさを備えていることが示唆された．\nまた，本実験では，SUS で直接評価の対象として言及していない「システムの重さ」に\n関する評価を，SUS の質問票に加えて独自の評価を行った．この質問票では，それぞれの\n質問に対して5 段階のリッカート尺度を用い，\n「そう思う」から「そう思わない」までの範\n囲で回答を得た．表5.8 は，本システムを用いたアクション動画鑑賞時に使用したスマー\nトフォンアクセサリーの重さに関する評価結果を示している．本実験で使用したスマート\nフォンアクセサリーは，スマートフォンを固定した状態での総重量が510g であり，この\n重量が長時間の鑑賞において被験者に疲労を与える可能性が懸念された．\n「鑑賞時に固定\nしたスマートフォンを含むスマートフォンアクセサリーは全体的に軽かった」という質問\nに対しては，評価は「どちらともいえない」に集中しており，アクセサリーの重量に対し\nて中立的な意見が多かった．しかし，\n「スマートフォンアクセサリーを60 分間持ち続け",
            "ーの重量に対し\nて中立的な意見が多かった．しかし，\n「スマートフォンアクセサリーを60 分間持ち続けた\n場合，手や腕に疲れを感じないと思う」および「スマートフォンアクセサリーを90 分間\n持ち続けた場合，手や腕に疲れを感じないと思う」という質問に対しては，否定的な評価\n72\n図5.13: SUS に基づく各被験者の快適性と使用感に関する評価得点\n図5.14: SUS に基づく評価得点に対する評価尺度（[117] より引用）\nが多く見られ，長時間の使用において重量感が疲労の蓄積を引き起こす可能性が示唆され\nた．一方で，\n「スマートフォンアクセサリーの形状は持ちやすさに適している」という質\n問に対しては高い評価が得られ，アクセサリーの形状が被験者の使用感において好意的に\n受け止められたことが確認された．この結果から，スマートフォンアクセサリーの形状が\n持ちやすさを向上させる一方で，重量感が長時間の使用における課題として残されている\nことが考えられる．\n5.2.5\n擬似心拍刺激を伴うアクション動画鑑賞の評価\n本実験では，システムを使用したアクション動画鑑賞後に実施したSUS によるユーザ\nビ",
            "動画鑑賞の評価\n本実験では，システムを使用したアクション動画鑑賞後に実施したSUS によるユーザ\nビリティ評価に加えて，擬似心拍刺激に焦点を当てたアクション動画鑑賞の独自の評価を\n行った．この評価では，それぞれの質問に対して5 段階のリッカート尺度を用い，\n「そう思\nう」から「そう思わない」までの範囲で回答を得た．表5.9 は，擬似心拍刺激を伴うアク\nション動画鑑賞に関する評価結果を示している．結果から，擬似心拍刺激がアクション動\n画鑑賞中の主観的な没入感や興奮度合いを高めることについて肯定的な評価が得られた\nことが確認された．特に，擬似心拍刺激はアクション動画鑑賞時の緊張感や興奮度を高め\n73\n表5.8: スマートフォンアクセサリーの重さに関する評価\n質問文（回答者：12 名）\n評価（5 点満点）\n評価（100%）\n鑑賞時に固定したスマートフォンを含むスマート\nフォンアクセサリーは全体的に軽かった\n3\n60%\nスマートフォンアクセサリーを持っている間，手\nや腕に疲れを感じなかった\n3.25\n65%\nスマートフォンアクセサリーを30 分間持ち続けた\n場合，手や腕に疲れを感じないと思う\n",
            "25\n65%\nスマートフォンアクセサリーを30 分間持ち続けた\n場合，手や腕に疲れを感じないと思う\n3.5\n70%\nスマートフォンアクセサリーを60 分間持ち続けた\n場合，手や腕に疲れを感じないと思う\n2.5\n50%\nスマートフォンアクセサリーを90 分間持ち続けた\n場合，手や腕に疲れを感じないと思う\n1.92\n38%\nスマートフォンアクセサリーの形状や表面の材質\nは，持ちやすさに適している\n4.5\n90%\nる点において有効であることが示された．また，\n「擬似心拍刺激がアクション動画鑑賞体\n験に良い影響を与えた」という質問項目においても高い評価が得られた．この結果から，\nスマートフォンアクセサリーによる昂りに連動した擬似心拍刺激は，アクション動画鑑賞\n時の情動の強度を高め，全体的な鑑賞体験の向上に寄与する可能性が示唆される．\n表5.9: 擬似心拍刺激を伴うアクション動画鑑賞に関する評価\n質問文（回答者：12 名）\n評価（5 点満点）\n評価（100%）\n擬似心拍刺激がアクション動画鑑賞中の没入感を\n高めたと感じた\n4\n80%\n擬似心拍刺激がアクション動画鑑賞中の緊張感や\n興奮度を高めたと",
            "没入感を\n高めたと感じた\n4\n80%\n擬似心拍刺激がアクション動画鑑賞中の緊張感や\n興奮度を高めたと感じた\n4.4\n88%\n擬似心拍刺激はアクション動画鑑賞の体験を新鮮\nなものにした\n4.8\n95%\n擬似心拍刺激がアクション動画鑑賞の体験に良い\n影響を与えてた\n4.4\n88%\n5.2.6\n情動評価の結果に対する考察\n本実験では，昂りに連動した擬似心拍刺激によるフィードバックを行うスマートフォン\nアクセサリーを用いたアクション動画鑑賞体験と，従来のスマートフォン単体でのアク\nション動画鑑賞体験における情動評価を，SAM を用いた主観的評価に基づいて比較した．\n74\nその結果，システムの有無による条件間の情動評価において，システムを使用した場合の\n方が快-不快，覚醒度，主導感の各尺度で評価が高く，すべての尺度において統計的に有\n意な差が認められた．また，鑑賞順序の影響を考慮し，システム無およびシステム有の順\n序ごとに情動評価を分析したところ，各尺度において有意差は確認されず，鑑賞順序によ\nる順序効果のバイアスが生じていないことが示唆された．これにより，鑑賞順序の影響で\nはなく，システムの有",
            "順序効果のバイアスが生じていないことが示唆された．これにより，鑑賞順序の影響で\nはなく，システムの有無そのものが情動評価に影響を与えたと考えられる．以上の結果か\nら，スマートフォンアクセサリーを用いた昂りに連動する振動および照明による擬似心拍\n刺激のフィードバックは，ユーザに自身の昂りを認識させるとともに，興奮を促進させる\n効果を持つことが示唆された．このことから，本システムはアクション動画鑑賞時の情動\n体験を強化し，より没入感のある鑑賞体験を提供する可能性が高いと考えられる．\n5.2.7\n快適性および使用感の評価に対する考察\nSUS を利用したシステムのユーザビリティ評価の結果では，平均点および最低点のいず\nれも，評価尺度における許容度の基準を満たしており，\n「acceptable」に該当することが確\n認された．これにより，本システムは十分に許容できるレベルの快適性と使いやすさを備\nえていることが示唆される．スマートフォンをアクセサリーに装着し，専用アプリケー\nションを起動・実行するだけで容易に使用できるシンプルな操作性とハンドケース型によ\nる負担のない設計が，ユーザビリティの高評価",
            "けで容易に使用できるシンプルな操作性とハンドケース型によ\nる負担のない設計が，ユーザビリティの高評価に寄与したと考えられる．\nしかし，スマートフォンアクセサリーの重さに関する評価では，「鑑賞時に固定したス\nマートフォンを含むスマートフォンアクセサリーは全体的に軽かった」という質問に対し，\n多くの回答が「どちらともいえない」に集中した．これは，アクセサリーの重量に対して\n中立的な意見が多く，長時間の使用においては重さによる疲労感が蓄積する可能性がある\nことを示唆している．動画鑑賞媒体として使用するスマートフォンの重さも影響を与える\n要因ではあるが，アクセサリー単体でも約300g の重量があるため，サイズの縮小や軽量\n化など，よりコンパクトな設計を検討する必要があると考えられる．\n5.3\n定量評価の結果および考察\n5.3.1\n昂りの判定回数の比較\n本実験では，システムを使用した場合と使用しない場合でのアクション動画鑑賞におい\nて，脈波変動の特徴量を基に機械学習モデルを通して「昂り」かどうかを分類し，直近の\n分類結果と比較して判定された「昂り」の回数を記録した．この「昂り」の判定回数を基\nに",
            "分類し，直近の\n分類結果と比較して判定された「昂り」の回数を記録した．この「昂り」の判定回数を基\nに，システムの有無によるアクション動画鑑賞中の昂りの判定回数を比較する．図5.15\nは，システム有無でのアクション動画鑑賞中における昂りの判定回数の分布を箱ひげ図を\n用いて示している．分布結果を見ると，システムを使用した場合では，中央値および平均\n値がシステムを使用しない場合よりも高いことが確認された．また，システム有の条件\nでは，評価分布が全体的に上方向にシフトしており，両条件の平均値の差が顕著である．\nまた，表5.10 は，システム有無の条件間におけるアクション動画鑑賞時の昂りの判定回\n数の平均値およびその差分を示している．この結果から，システム有の条件では平均値が\n顕著に高い傾向にあることが確認された．この結果は，システムを使用することで提示さ\n75\nれるフィードバックが，アクション動画鑑賞中の昂りの頻度が増加し，システムが情動体\n験の強化に寄与する可能性を示唆していると考えられる．しかしながら，これらの平均値\nの差が偶然によるものか，統計的に有意な差であるかを判断する必要がある．そ",
            "かしながら，これらの平均値\nの差が偶然によるものか，統計的に有意な差であるかを判断する必要がある．そのため，\n有意水準を5%に設定し，システム有無の条件間における昂りの判定回数の違いについて\n対応ありのt 検定を実施した．\n図5.15: システム有無でのアクション動画鑑賞時の「昂り」の判定回数の分布\n表5.10: システム有無でのアクション動画鑑賞時の「昂り」の判定回数の平均と条件間の\n差\n「昂り」の判定回数の平均\nシステム有\n75.9\nシステム無\n32.7\nシステム有無の差（有-無）\n43.2\nシステムの有無による「昂り」の判定回数の比較では，帰無仮説を「システムの有無で\nのアクション動画鑑賞体験において「昂り」の判定回数に差がない」と設定し，有意水準\nを0.05 に設定した．表5.11 は，対応ありt 検定を実施した結果を示している．この結果\nから，昂りの判定回数においてt 値が片側検定の棄却域（1.796）に含まれ，さらにp 値も\n有意水準未満であることが確認された．これらの結果を踏まえ，帰無仮説は棄却され，シ\nステムの有無が昂りの判定回数に影響を及ぼしていることが示された．また",
            "踏まえ，帰無仮説は棄却され，シ\nステムの有無が昂りの判定回数に影響を及ぼしていることが示された．また，システム有\nの条件では昂りの回数が増加する傾向が見られ，システムによるフィードバックが情動体\n験の強化に寄与する可能性が示唆していると考える．\n昂りの判定回数においても，システムの有無に差がある結果を受けて，順序効果の有無\n76\n表5.11: システム有無での「昂り」の判定回数に関する検定統計量とp 値の結果\n尺度\nt 値\n片側検定p 値\n片側検定境界値\n両側検定p 値\n両側検定境界値\n判定回数\n2.451\n0.016\n1.796\n0.032\n2.201\nを検証した．図5.16 は，システム無での鑑賞順序における「昂り」の判定回数の分布を\n箱ひげ図で示している．分布結果を見ると，システム無での鑑賞順序における1 回目と2\n回目の平均値はほとんど同じであることが確認された．また，中央値は1 回目がわずかに\n低いものの，分布の範囲において1 回目と2 回目の間に大きな違いは見られず，全体的に\n似通った傾向を示している．また，表5.12 は，システム無での鑑賞順序における「昂り」\nの判定回数",
            "\n似通った傾向を示している．また，表5.12 は，システム無での鑑賞順序における「昂り」\nの判定回数の平均値およびその差分を示している．この結果から，システム無での鑑賞順\n序において，\n「昂り」の判定回数に差異はないことが考えられる．しかしながら，これら\nの平均値の差が偶然によるものか，統計的に有意な差であるかを判断する必要がある．そ\nのため，有意水準を5%に設定し，システム無での鑑賞順序における「昂り」の判定回数\nの違いについて対応なしのt 検定を実施した．\n図5.16: システム無での鑑賞順序における「昂り」の判定回数の分布\n表5.12: システム無での鑑賞順序における「昂り」の判定回数の平均と条件間の差\n「昂り」の判定回数の平均\n1 回目\n75.9\n2 回目\n32.7\n鑑賞順序における差（2 回目-1 回目）\n43.2\n77\nシステム無での鑑賞順序における「昂り」の判定回数の比較では，帰無仮説を「システ\nム無での鑑賞順序におけるアクション動画鑑賞体験において「昂り」の判定回数に差が\nない」と設定し，有意水準を0.05 とした．表5.13 は，対応なしt 検定を実施した結果を\n示し",
            "\nない」と設定し，有意水準を0.05 とした．表5.13 は，対応なしt 検定を実施した結果を\n示している．この結果より，昂りの判定回数について，いずれもt 値が片側検定の棄却域\n（1.812）および両側検定の棄却域（2.228）のいずれにも含まれず，p 値も有意水準以上で\nあることから，システム無の鑑賞順序による昂りの判定回数に有意な差は確認されなかっ\nた．これらの結果から，帰無仮説は棄却されず，システム無での鑑賞順序が「昂り」の判\n定回数に影響を及ぼす可能性は低いことを示唆している．\n表5.13: システム無での鑑賞順序の「昂り」の判定回数に関する検定統計量とp 値の結果\n尺度\nt 値\n片側検定p 値\n片側検定境界値\n両側検定p 値\n両側検定境界値\n判定回数\n-0.030\n0.488\n1.812\n0.977\n2.228\n図5.17 は，システム有での鑑賞順序における「昂り」の判定回数の分布を箱ひげ図で\n示している．分布結果を見ると，1 回目の中央値および平均値が2 回目の中央値および平\n均値よりも顕著に高いことが確認された．また，分布範囲においても，1 回目が高い判定\n回数で広がり",
            "平\n均値よりも顕著に高いことが確認された．また，分布範囲においても，1 回目が高い判定\n回数で広がりを持つ傾向が見られる．この結果から，システム有での鑑賞順序において，\n1 回目の判定回数が高いことが示され，順序効果が影響している可能性が考えられる．さ\nらに，表5.14 は，システム有での鑑賞順序における「昂り」の判定回数の平均値および\nその差分を示している．この結果から，システム有の条件において鑑賞順序が「昂り」の\n判定回数に顕著な差をもたらしていることが確認された．しかし，これらの平均値の差が\n偶然によるものか，統計的に有意な差であるかを判断する必要がある．そのため，有意水\n準を5%に設定し，システム有での鑑賞順序における「昂り」の判定回数の違いについて\n対応なしのt 検定を実施した．\n表5.14: システム有での鑑賞順序の「昂り」の判定回数の平均と条件間の差\n「昂り」の判定回数の平均\n1 回目\n95.8\n2 回目\n56.0\n鑑賞順序における差（2 回目-1 回目）\n-39.8\nシステム有での鑑賞順序における「昂り」の判定回数の比較では，帰無仮説を「システ\nム有での鑑賞順序における",
            "テム有での鑑賞順序における「昂り」の判定回数の比較では，帰無仮説を「システ\nム有での鑑賞順序におけるアクション動画鑑賞体験において「昂り」の判定回数に差が\nない」と設定し，有意水準を0.05 とした．表5.15 は，対応なしt 検定を実施した結果を\n示している．この結果より，昂りの判定回数について，いずれもt 値が片側検定の棄却域\n（1.812）および両側検定の棄却域（2.228）のいずれにも含まれず，p 値も有意水準以上で\nあることから，システム有の鑑賞順序による昂りの判定回数に有意な差は確認されなかっ\nた．これらの結果から，帰無仮説は棄却されず，システム有での鑑賞順序が「昂り」の判\n定回数に影響を及ぼす可能性は低いことを示唆している．\n78\n図5.17: システム有での鑑賞順序における「昂り」の判定回数の分布\n表5.15: システム有での鑑賞順序の「昂り」の判定回数に関する検定統計量とp 値の結果\n尺度\nt 値\n片側検定p 値\n片側検定境界値\n両側検定p 値\n両側検定境界値\n判定回数\n0.892\n0.197\n1.812\n0.393\n2.228\n5.3.2\n脈波変動指標の変化について",
            "\n0.892\n0.197\n1.812\n0.393\n2.228\n5.3.2\n脈波変動指標の変化について\n本実験では，アクション動画鑑賞によって誘発される興奮的情動が脈波変動に与える影\n響を検証するため，情動的興奮時に周波数領域指標の一つである「LF/HF」が増加したこ\nとが見られた研究[40][32] を参考に，\n「LF/HF」に注目し，システムの有無によるアクショ\nン動画鑑賞中のこの指標の変化の差異を比較した．\n30 分間のアクション動画鑑賞において，システムの有無に応じたLF/HF の変化を比較\nするため，窓サイズ240 秒，シフトサイズ5 秒で算出されたLF/HF の時系列データを用\nいて，開始から30 分までの10 分ごとの区間を設けた．各被験者（12 名）ごとに，それぞ\nれの区間におけるLF/HF の平均値を算出し，システム有無での違いを検討した．図5.18\nは，システム有無における10 分ごとのLF/HF の平均値の差（システム有－システム無）\nの推移を示したものである．図中において，値が高い方向に推移している場合，システム\n有の条件におけるLF/HF の平均値が高いことを意",
            "おいて，値が高い方向に推移している場合，システム\n有の条件におけるLF/HF の平均値が高いことを意味し，システム使用時により強い興奮\nが誘発されている可能性が考えられる．しかし，10 分ごとのLF/HF の平均値の差の推移\nにおいて，平均値は0 付近（ベースライン付近）を推移しており，システムの使用時と非\n使用時でLF/HF に顕著な変化は見られない．\n一方で，一部の被験者の20～30 分の区間において，システムの使用時と非使用時で\nLF/HF が顕著に異なることが確認された．図5.19 は，該当する被験者A のシステムの有\n79\n図5.18: システム有無における10 分ごとのLF/HF の平均値の差の推移\n無によるLF/HF の時系列的な変化を示し，加えて，システム有の条件で昂りと判定され，\n擬似心拍刺激によるフィードバックが行われたタイミングを縦の赤色破線で示している．\nこの被験者において，20～30 分の区間では，システム無の条件ではLF/HF が減少傾向に\nあるのに対し，システム有の条件では昂り判定による，連続的な擬似心拍刺激のフィード\nバックが行われることで，LF/HF ",
            "テム有の条件では昂り判定による，連続的な擬似心拍刺激のフィード\nバックが行われることで，LF/HF が増加している．この結果は，一部の被験者に対して，\n擬似心拍刺激によるフィードバックが自律神経活動に影響を与え，交感神経優位な状態を\n促進する可能性を示唆していると考えられる．\n図5.19: 被験者A のシステムの有無でのアクション動画鑑賞時のLF/HF の推移\n5.3.3\n脈波変動指標の変化および昂りの判定回数に対する考察\n本実験では，周波数領域指標の一つである「LF/HF」に着目し，システムの有無による\nアクション動画鑑賞中のこの指標の変化の差異を比較した．その結果，システムの有無に\n80\nよるアクション動画鑑賞時のLF/HF の推移に，顕著な違いは確認されなかった．この結\n果は，昂りに連動した振動および照明による擬似心拍刺激が，交感神経と副交感神経のバ\nランスに大きな影響を及ぼしていない可能性を示唆している．したがって，本研究のシス\nテムは主観的な情動評価には影響を与えたものの，生理指標における交感神経活動と副\n交感神経活動の相対的な比率に対する擬似心拍刺激の効果は限定的であると考",
            "指標における交感神経活動と副\n交感神経活動の相対的な比率に対する擬似心拍刺激の効果は限定的であると考えられる．\n本実験では「LF/HF」に着目したが，被験者の「手に汗を握る感覚があった」という感想\nから，興奮に伴う発汗度合いへの影響に着目した評価を今後の検討とする．\n一方で，システムを使用したアクション動画鑑賞では，使用しない場合と比較して，脈\n波変動の特徴量を用いた昂りの分類モデルによる「昂り」の判定回数が有意に増加するこ\nとが確認された．この結果は，システムを使用することで，フィードバックを通じて昂り\nの回数が増加する効果があることを示唆している．さらに，フィードバックに対する期待\n感が脈波信号に影響を与え，昂る回数の増加を促している可能性も考えられる．\n81\n第6章\n結論\n6.1\nまとめ\n本研究では，個人の動画鑑賞における情動体験を強化することを通じて，スマートフォ\nンでの動画鑑賞体験の拡張を目的とし，アクション動画鑑賞中にスマートウォッチを用い\nて取得するユーザの脈拍変動を基に，機械学習モデルによってリアルタイムに「昂り」を\n判定するアプリケーションを使用して，判定結果に応じて",
            "機械学習モデルによってリアルタイムに「昂り」を\n判定するアプリケーションを使用して，判定結果に応じて振動および照明が同期した擬似\n心拍刺激を提示するスマートフォンアクセサリーを製作した．\n本システムによる動画鑑賞体験への影響を検証するため，システム使用の有無による2\n条件でアクション動画鑑賞を実施し，Self-Assessment Manikin を用いた主観的情動評価の\n比較およびSystem Usability Scale を用いたユーザビリティ評価を行った．その結果，シ\nステムを使用した場合の方が，快-不快，覚醒度，主導感（没入感）のすべての尺度にお\nいて評価が高く，統計的に有意な差が認められた．また，システム有無の鑑賞順序別の情\n動評価では，有意な差は確認されず，順序効果の影響は生じていないことが示された．こ\nれにより，システムの使用が情動評価に有効であることが示された．さらに，ユーザビリ\nティ評価の結果，システムを使用したアクション動画鑑賞後に十分に許容可能なユーザビ\nリティを有すると高く評価された．\n一方で，両条件における脈拍変動指標の変化について，周波数領域指標の一つであ",
            "有すると高く評価された．\n一方で，両条件における脈拍変動指標の変化について，周波数領域指標の一つである\nLF/HF に着目して分析した結果，30 分間のアクション動画鑑賞中の10 分ごとの推移にお\nいて，使用条件と非使用条件の間に顕著な違いは確認されなかった．したがって，本シス\nテムは主観的な情動評価には影響を与えたものの，LF/HF に対する擬似心拍刺激の効果\nは限定的であることが確認された．しかしながら，生理指標に関しては，動画鑑賞中の発\n汗度合いなど，興奮に関連する他の生理指標について検討が必要であり，今後の課題とし\nて取り組む必要がある．\n以上の結果を踏まえ，昂りに連動して振動および照明が同期した擬似心拍刺激を提示す\nるスマートフォンアクセサリーは，従来の動画鑑賞と比較して，使用時の負担を抑えつ\nつ，興奮をより高める効果を有し，主観的な情動体験の強化に寄与することが示された．\nこの成果を基に，本システムはスマートフォンによる動画鑑賞体験の拡張手法として有用\nであると考えられる．\n6.2\n今後の展望\n今後の展望としては，図6.1 に示すように，本システムにおけるさらなる取り組みと",
            "6.2\n今後の展望\n今後の展望としては，図6.1 に示すように，本システムにおけるさらなる取り組みとし\nて，熱を利用した温冷提示やアロマを活用した香りの提示など，他のフィードバック手法\nとの組み合わせを検討し，スマートフォンアクセサリーを拡張することで，多様な動画鑑\n賞体験の創出を目指す．また，動画鑑賞中のフィードバックが適切なタイミングで行われ\n82\nない場合，鑑賞体験を損なうリスクが高まることが考えられる．そのため，動画鑑賞時の\n昂りをより正確に判定するために，多様な年齢層や性別の被験者データを収集し，分析お\nよび分類精度の向上を行う必要がある．さらに，本研究で対象としたアクション動画に限\n定せず，コメディ動画や恋愛動画など，さまざまなジャンルの動画にも対応できる動画鑑\n賞システムの実現に取り組む．\n図6.1: 本システムにおける今後の取り組み\n83\n謝辞\n本研究はJSPS 科研費23K11961 の助成を受けたものです．\n本稿の執筆に際し，研究方針から丁寧なご指導を賜りました，青山学院大学理工学部情\n報テクノロジー学科Guillaume Lopez 教授に深く感謝申し上げます．ま",
            "学院大学理工学部情\n報テクノロジー学科Guillaume Lopez 教授に深く感謝申し上げます．また，副査として，\n提案手法や実験手法に対して様々な意見やご助言をいただきました青山学院大学理工学\n部情報テクノロジー学科DURST, Martin Jakob 教授に深く感謝申し上げます．そして，研\n究会などを通して客観的な視点でのアイデアの提供や，励ましをいただきましたウェアラ\nブル環境情報システム研究室の皆様，並びに，貴重な時間を割いて実験に協力していただ\nいた被験者の皆様に深く感謝いたします．最後に，学部生の時から常に心身を支えてくだ\nさった家族の皆様に心より感謝申し上げます．\n2025 年1 月31 日\n柴武志\n84\n参考文献\n[1] 日本生産性本部.\nレジャー白書2021 巻頭要約.\nhttps://www.jpc-net.jp/\nresearch/assets/pdf/summary2021_leisure.pdf, 9 2021.\n（最終参照\n日：2023/10/17）.\n[2] 日本生産性本部.\nレジャー白書2024 巻頭要約.\nhttps://www.jpc-net.j",
            "2] 日本生産性本部.\nレジャー白書2024 巻頭要約.\nhttps://www.jpc-net.jp/\nresearch/assets/pdf/summary2024_leisure.pdf, 10 2024. （最終参照\n日：2024/12/17）.\n[3] ICT 総研. 2023 年有料動画配信サービス利用動向に関する調査. https://ictr.\nco.jp/report/20230421.html/, 4 2023. （最終参照日：2023/10/17）.\n[4] モバイル社会研究所.\n10 代男女の約3 割が1 日6 時間以上スマホで動画を視\n聴.\nhttps://www.moba-ken.jp/project/lifestyle/20241021.html,\n10 2024. （最終参照日：2024/12/17）.\n[5] MediaMotion. Mx4d motion efx experience. https://www.mediamation.com/\nmx4d-theatres/. （最終参照日：2024/2/12）.\n[6] CJ 4DPLEX.\n4dx",
            "d-theatres/. （最終参照日：2024/2/12）.\n[6] CJ 4DPLEX.\n4dx.\nhttps://www.cj4dplex.com/4dx.\n（最終参照日：\n2024/2/12）.\n[7] NHK. 映画を変えるか「vr映画」が切り開く新たな映像体験. https://www3.nhk.\nor.jp/news/special/sci_cul/2023/04/special/story_vr_movie/.\n（最終参照日：2024/2/12）.\n[8] Netﬂix. Interactive tv shows and movies on netﬂix. https://help.netflix.com/\nen/node/62526. （最終参照日：2024/2/12）.\n[9] 株式会社BCN. スマホの平均画面サイズ、「5.87 インチ」で高止まり？iphone の歴史\nとともに振り返ってみた. https://www.bcnretail.com/market/detail/\n20230325_321595.html, 3 2023. （最終参照日：2024/10",
            "tail/\n20230325_321595.html, 3 2023. （最終参照日：2024/10/19）.\n[10] Jacob M Rigby, Duncan P Brumby, Anna L Cox, and Sandy JJ Gould. Watching movies\non netﬂix: investigating the effect of screen size on viewer immersion. In Proceedings\nof the 18th international conference on human-computer interaction with mobile devices\nand services adjunct, pp. 714–721, 2016.\n[11] Johanna Dunaway and Stuart Soroka. Smartphone-size screens constrain cognitive access\nto video news stories. Information, Communication & S",
            "video news stories. Information, Communication & Society, Vol. 24, No. 1, pp. 69–84,\n2021.\n85\n[12] Jonah Berger, Yoon Duk Kim, and Robert Meyer. What makes content engaging? how\nemotional dynamics shape success. Journal of Consumer Research, Vol. 48, No. 2, pp.\n235–250, 2021.\n[13] Eran Dayan, Avi Barliya, Beatrice de Gelder, Talma Hendler, Rafael Malach, and Tamar\nFlash. Motion cues modulate responses to emotion in movies. Scientiﬁc reports, Vol. 8,\nNo. 1, p. 10881, 2018.\n[14] Larry Cahill, Rich",
            " 8,\nNo. 1, p. 10881, 2018.\n[14] Larry Cahill, Richard J Haier, James Fallon, Michael T Alkire, Cheuk Tang, David\nKeator, Joseph Wu, and James L McGaugh.\nAmygdala activity at encoding corre-\nlated with long-term, free recall of emotional information. Proceedings of the National\nAcademy of sciences, Vol. 93, No. 15, pp. 8016–8021, 1996.\n[15] Dahlia W Zaidel. The art of ﬁlm: Perspective on neural clues to repeated attraction to\nmovie watching. Neuropsychologia, Vol. 180, p. 108485, 2023.\n[16] Jonah",
            "psychologia, Vol. 180, p. 108485, 2023.\n[16] Jonah Berger. Arousal increases social transmission of information. Psychological sci-\nence, Vol. 22, No. 7, pp. 891–893, 2011.\n[17] Red\nMeat\nGames.\nBring\nto\nlight.\nhttps://redmeat.games/\nbring-to-light/. （最終参照日：2024/6/17）.\n[18] Flying Mollusk. Nevermind. https://nevermindgame.com. （最終参照日：\n2024/6/17）.\n[19] OVOMIND.\nOvomind home.\nhttps://ovomind.com/.\n（最終参照日：\n2024/10/15）.\n[20] ENO.\nAudio neuro-stimulation angle.\nhttps://getenophone.com/pages/\naudio-neu",
            "on angle.\nhttps://getenophone.com/pages/\naudio-neuro-stimulation-angle. （最終参照日：2024/6/17）.\n[21] 新村出編. 広辞苑（第六版）. 岩波書店, 2008.\n[22] 白井真理子, 武藤世良, 中村真. 日本感情心理学会員が考える「感情とは何か」(1)―\n感情= 情動なのか―. 感情心理学研究, Vol. 28, No. Supplement, pp. ps17–ps17, 2020.\n[23] Andrew Ortony, Gerald L Clore, and Allan Collins. The cognitive structure of emotions.\nCambridge university press, 2022.\n[24] 大平英樹編. 感情心理学・入門. 有斐閣アルマ, 2010.\n[25] Ursula Hess and Pascal Thibault. Darwin and emotion expression. American Psycholo-\ngist, Vol.",
            " emotion expression. American Psycholo-\ngist, Vol. 64, No. 2, p. 120, 2009.\n[26] Paul Ekman and Wallace V Friesen. Constants across cultures in the face and emotion.\nJournal of personality and social psychology, Vol. 17, No. 2, p. 124, 1971.\n[27] James A Russell. A circumplex model of affect. Journal of personality and social psy-\nchology, Vol. 39, No. 6, p. 1161, 1980.\n86\n[28] James A Russell and James M Carroll. On the bipolarity of positive and negative affect.\nPsychological bulletin, Vol. 12",
            "d negative affect.\nPsychological bulletin, Vol. 125, No. 1, p. 3, 1999.\n[29] 日本生理人類学会編. 人間科学の百科辞典. 丸善出版, 2015.\n[30] Hideki Ohira, Michio Nomura, Naho Ichikawa, Tokiko Isowa, Tetsuya Iidaka, Atsushi\nSato, Seisuke Fukuyama, Toshihiko Nakajima, and Jitsuhiro Yamada. Association of\nneural and physiological responses during voluntary emotion suppression. Neuroimage,\nVol. 29, No. 3, pp. 721–733, 2006.\n[31] Paul Ekman, Robert W Levenson, and Wallace V Friesen. Autonomic nervous system\nactivity distingu",
            "riesen. Autonomic nervous system\nactivity distinguishes among emotions. science, Vol. 221, No. 4616, pp. 1208–1210,\n1983.\n[32] Ahmad Rauf Subahni, Likun Xia, and Aamir Saeed Malik. Association of mental stress\nwith video games. In 2012 4th International Conference on Intelligent and Advanced\nSystems (ICIAS2012), Vol. 1, pp. 82–85. IEEE, 2012.\n[33] Raj Rakshit, V Ramu Reddy, and Parijat Deshpande. Emotion detection and recognition\nusing hrv features derived from photoplethysmogram signals. In Pro",
            "es derived from photoplethysmogram signals. In Proceedings of the 2nd\nworkshop on Emotion Representations and Modelling for Companion Systems, pp. 1–6,\n2016.\n[34] Kwang-Ho Choi, Junbeom Kim, O Sang Kwon, Min Ji Kim, Yeon Hee Ryu, and Ji-Eun\nPark. Is heart rate variability (hrv) an adequate tool for evaluating human emotions?–a\nfocus on the use of the international affective picture system (iaps). Psychiatry research,\nVol. 251, pp. 192–196, 2017.\n[35] Yan Wu, Ruolei Gu, Qiwei Yang, and Yue-jia Lu",
            "[35] Yan Wu, Ruolei Gu, Qiwei Yang, and Yue-jia Luo. How do amusement, anger and fear\ninﬂuence heart rate and heart rate variability? Frontiers in neuroscience, Vol. 13, p. 1131,\n2019.\n[36] Bin Yu, Mathias Funk, Jun Hu, and Loe Feijs. Stresstree: A metaphorical visualization\nfor biofeedback-assisted stress management. In Proceedings of the 2017 conference on\ndesigning interactive systems, pp. 333–337, 2017.\n[37] 多田有輝, 伊藤淳子, 宗森純ほか. スマートウォッチを用いた人の状況判定システム\nの開発. 2020 年度情報処理学会関西支部支部大会講演論文集, Vol. 2020",
            "況判定システム\nの開発. 2020 年度情報処理学会関西支部支部大会講演論文集, Vol. 2020, , 2020.\n[38] 金多賢, 北島宗雄, 李昇姫. 映像に対する嗜好と感情反応・印象評価の関係. 日本感\n性工学会論文誌, Vol. 13, No. 1, pp. 181–189, 2014.\n[39] Kamil Topal and Gultekin Ozsoyoglu. Movie review analysis: Emotion analysis of imdb\nmovie reviews. In 2016 IEEE/ACM International Conference on Advances in Social\nNetworks Analysis and Mining (ASONAM), pp. 1170–1176. IEEE, 2016.\n[40] Sokichi Sakuragi, Yoshiki Sugiyama, and Kiyomi Takeuchi. Effects of laughing and\nweeping on mood and heart ra",
            "fects of laughing and\nweeping on mood and heart rate variability. Journal of physiological anthropology and\napplied human science, Vol. 21, No. 3, pp. 159–165, 2002.\n87\n[41] 村瀬千春, 川本利恵子, 杉本助男. 視聴覚刺激による情動の変化-心拍変動の分析.\nJournal of UOEH, Vol. 26, No. 4, pp. 461–471, 2004.\n[42] 宮本晴司, 代蔵巧, 棟方渚, 小野哲雄ほか. 生体信号を用いた動画視聴中のユーザ評\n価の推定. エンタテインメントコンピューティングシンポジウム2015 論文集, Vol.\n2015, pp. 568–573, 2015.\n[43] Makoto Fukumoto and Yuuki Tsukino. Relationship of terror feelings and physiological\nresponse during watching",
            "eelings and physiological\nresponse during watching horror movie. In Computer Information Systems and Industrial\nManagement: 14th IFIP TC 8 International Conference, CISIM 2015, Warsaw, Poland,\nSeptember 24-26, 2015, Proceedings 14, pp. 500–507. Springer, 2015.\n[44] Jo Vermeulen, Lindsay MacDonald, Johannes Sch¨oning, Russell Beale, and Sheelagh\nCarpendale. Heartefacts: augmenting mobile video sharing using wrist-worn heart rate\nsensors. In Proceedings of the 2016 ACM Conference on Designing Inte",
            "dings of the 2016 ACM Conference on Designing Interactive Systems,\npp. 712–723, 2016.\n[45] 代蔵巧, 棟方渚, 小野哲雄ほか. E3-player: 鑑賞者の興奮を促進させる動画鑑賞シス\nテム. エンタテインメントコンピューティングシンポジウム2013 論文集, Vol. 2013,\npp. 272–277, 2013.\n[46] 角田啓介, 江口佳那, 吉田和広, 渡部智樹, 水野理ほか. 心拍と呼吸を用いたコンテン\nツ視聴による気分変化の推定: コメディ視聴における検討. 情報処理学会論文誌コン\nシューマ・デバイス& システム(CDS), Vol. 7, No. 1, pp. 44–52, 2017.\n[47] 吉田豊, 山本健人, 湯田恵美, 早野順一郎ほか. 心拍変動へ機械学習適用による映画\n視聴時の情動判別. 研究報告電子化知的財産・社会基盤(EIP), Vol. 2018, No. 10, pp.\n1–2, 2018.\n[48] Reika Takeshita, Aya Shoji, ",
            ", pp.\n1–2, 2018.\n[48] Reika Takeshita, Aya Shoji, Tahera Hossain, Anna Yokokubo, and Guillaume Lopez.\nEmotion recognition from heart rate variability data of smartwatch while watching a\nvideo. In 2021 Thirteenth International Conference on Mobile Computing and Ubiq-\nuitous Network (ICMU), pp. 1–6. IEEE, 2021.\n[49] Reika Takeshita, Anna Yokokubo, and Guillaume Lopez. Proposal for an individually\nadapted video viewing system linked to the user ’s feeling of fear. In Extended Abstracts\nof the 2022 ",
            "eeling of fear. In Extended Abstracts\nof the 2022 Annual Symposium on Computer-Human Interaction in Play, pp. 166–170,\n2022.\n[50] Paul Lemmens, Floris Crompvoets, Dirk Brokken, Jack Van Den Eerenbeemd, and Gert-\nJan de Vries.\nA body-conforming tactile jacket to enrich movie viewing.\nIn World\nHaptics 2009-Third Joint EuroHaptics conference and Symposium on Haptic Interfaces\nfor Virtual Environment and Teleoperator Systems, pp. 7–12. IEEE, 2009.\n[51] Caitlyn Seim, James Hallam, Shashank Raghu, Tri",
            "1] Caitlyn Seim, James Hallam, Shashank Raghu, Tri-An Le, Greg Bishop, and Thad\nStarner. Perception in hand-worn haptics: placement, simultaneous stimuli, and vibration\nmotor comparisons. 2015.\n88\n[52] Antonella Mazzoni and Nick Bryan-Kinns. Mood glove: A haptic wearable prototype\nsystem to enhance mood music in ﬁlm. Entertainment Computing, Vol. 17, pp. 9–17,\n2016.\n[53] Damien Ablart, Carlos Velasco, and Marianna Obrist. Integrating mid-air haptics into\nmovie experiences. In Proceedings of the ",
            "ics into\nmovie experiences. In Proceedings of the 2017 ACM international conference on inter-\nactive experiences for TV and online video, pp. 77–84, 2017.\n[54] Dawoon Jeong, Sung H Han, Kimin Kwon, and Wan Sun Shin. Emotional and physiolog-\nical responses to the roll motion effect in 4d movies. Affective and Pleasurable Design,\nVol. 41, No. 41, 2022.\n[55] Yuki Kosuge, Yumeka Ogura, and Shogo Okamoto. Vibration to upper body manipulates\njoyful experience while viewing emotional scenes. In 2023 IE",
            "erience while viewing emotional scenes. In 2023 IEEE 12th Global Conference\non Consumer Electronics (GCCE), pp. 613–615. IEEE, 2023.\n[56] V´ıctor Cerd´an-Mart´ınez, ´Alvaro Garc´ıa-L´opez, Pablo Revuelta-Sanz, Tom´as Ortiz, and\nRicardo Vergaz. Haptic stimulation during the viewing of a ﬁlm: an eeg-based study.\nMultimedia Tools and Applications, pp. 1–14, 2024.\n[57] Ibuki Tara, Shogo Okamoto, Yasuhiro Akiyama, and Hidetaka Ozeki. Timing of vibra-\ntory stimuli to the upper body for enhancing fear ",
            "tory stimuli to the upper body for enhancing fear and excitement of audio-visual content.\nInternational Journal of Affective Engineering, Vol. 22, No. 2, pp. 105–113, 2023.\n[58] Vicente Ortiz-Garc´ıa-Cervig´on, Marina V Sokolova, Rosa Mar´ıa Garc´ıa-Mu˜noz, and An-\ntonio Fern´andez-Caballero. Led strips for color-and illumination-based emotion regula-\ntion at home. In Ambient Assisted Living. ICT-based Solutions in Real Life Situations:\n7th International Work-Conference, IWAAL 2015, Puerto Varas",
            "national Work-Conference, IWAAL 2015, Puerto Varas, Chile, December 1-4,\n2015, Proceedings 7, pp. 277–287. Springer, 2015.\n[59] Takuya Iwamoto and Soh Masuko. Lovable couch: Mitigating distrustful feelings for\ncouples by visualizing excitation. In Proceedings of the 6th Augmented Human Interna-\ntional Conference, pp. 157–158, 2015.\n[60] Lisa Wilms and Daniel Oberfeld. Color and emotion: effects of hue, saturation, and\nbrightness. Psychological research, Vol. 82, No. 5, pp. 896–914, 2018.\n[61] Ma",
            "search, Vol. 82, No. 5, pp. 896–914, 2018.\n[61] Marieke Lieve Weijs, Domicele Jonauskaite, Ricarda Reutimann, Christine Mohr, and\nBigna Lenggenhager. Effects of environmental colours in virtual reality: Physiological\narousal affected by lightness and hue. Royal Society Open Science, Vol. 10, No. 10, p.\n230432, 2023.\n[62] Vanessa L Buechner and Markus A Maier. Not always a matter of context: direct effects\nof red on arousal but context-dependent moderations on valence. PeerJ, Vol. 4, p. e2515,\n20",
            "oderations on valence. PeerJ, Vol. 4, p. e2515,\n2016.\n89\n[63] Dong Keun Kim, Sangmin Ahn, Sangin Park, and Mincheol Whang. Interactive emo-\ntional lighting system using physiological signals. IEEE Transactions on Consumer Elec-\ntronics, Vol. 59, No. 4, pp. 765–771, 2013.\n[64] Yu-Bin Shin, Seung-Hyun Woo, Dong-Hyeon Kim, Jinseong Kim, Jae-Jin Kim, and\nJin Young Park. The effect on emotions and brain activity by the direct/indirect lighting\nin the residential environment. Neuroscience letters, Vol",
            "residential environment. Neuroscience letters, Vol. 584, pp. 28–32, 2015.\n[65] 馬場哲晃, 笠松慶子, 土井幸輝, 串山久美子ほか. 温冷呈示を利用したビデオゲームイ\nンタラクションにおける手法の検討と開発. 情報処理学会論文誌, Vol. 53, No. 3, pp.\n1082–1091, 2012.\n[66] Ryota Tsuruno, Kentaro Kotani, Satoshi Suzuki, and Takafumi Asao. Use of presentation\nof thermal stimulus for enhancing excitement during video viewing. In Proceedings of\nthe 20th Congress of the International Ergonomics Association (IEA 2018) Volume X:\nAuditory and Vocal Ergonomics, Visual Ergonomics,",
            "\nAuditory and Vocal Ergonomics, Visual Ergonomics, Psychophysiology in Ergonomics,\nErgonomics in Advanced Imaging 20, pp. 366–370. Springer, 2019.\n[67] Andrew Dekker and Erik Champion. Please biofeed the zombies: enhancing the game-\nplay and display of a horror game using biofeedback. In DiGRA’07-Proceedings of the\n2007 DiGRA International Conference: Situated Play, pp. 550–558, 2007.\n[68] 荒木勇人, 池田太一, 落合優介, 阿部将之, 小澤拓海, 一瀬啓太, 佐久間拓也, 川合康央.\nユーザの脈拍数に応じて演出が変化する没入感を高めたホラーゲームの開発, 2017.\n[69] William Jam",
            "応じて演出が変化する没入感を高めたホラーゲームの開発, 2017.\n[69] William James. What is an emotion? Mind, Vol. 9, No. 34, pp. 188–205, 1884.\n[70] Walter B Cannon. The james-lange theory of emotions: A critical examination and an\nalternative theory. The American journal of psychology, Vol. 39, No. 1/4, pp. 106–124,\n1927.\n[71] Stanley Schachter and Jerome Singer. Cognitive, social, and physiological determinants\nof emotional state. Psychological review, Vol. 69, No. 5, p. 379, 1962.\n[72] Jeff T Larsen, Gary G Berntson, Kir",
            "79, 1962.\n[72] Jeff T Larsen, Gary G Berntson, Kirsten M Poehlmann, Tiffany A Ito, and John T Ca-\ncioppo. The psychophysiology of emotion. Handbook of emotions, Vol. 3, pp. 180–195,\n2008.\n[73] 鈴木直人編. 感情心理学. 朝倉書店, 2017.\n[74] Stuart Valins. Cognitive effects of false heart-rate feedback. Journal of personality and\nsocial psychology, Vol. 4, No. 4, p. 400, 1966.\n[75] Yoshio Inamori. Effects of false heart rate feedback on cognitive appraisal and physio-\nlogical responses to emotional stimuli. Japan",
            "sio-\nlogical responses to emotional stimuli. Japanese Psychological Research, Vol. 21, No. 3,\npp. 153–157, 1979.\n90\n[76] Marcus A Gray, Neil A Harrison, Stefan Wiens, and Hugo D Critchley. Modulation of\nemotional appraisal by false physiological feedback during fmri. PLoS one, Vol. 2, No. 6,\np. e546, 2007.\n[77] Narihiro Nishimura, Taku Hachisu, Michi Sato, Shogo Fukushima, and Hiroyuki Kaji-\nmoto. Evaluation of a tactile device for augmentation of audiovisual experiences with a\npseudo heartbeat.",
            "f audiovisual experiences with a\npseudo heartbeat. In Proceedings of the 4th Augmented Human International Conference,\npp. 242–242, 2013.\n[78] Ryoko Ueoka and Kouya Ishigaki. Development of the horror emotion ampliﬁcation\nsystem by means of biofeedback method.\nIn Human Interface and the Management\nof Information. Information and Knowledge in Context: 17th International Conference,\nHCI International 2015, Los Angeles, CA, USA, August 2-7, 2015, Proceedings, Part II\n17, pp. 657–665. Springer, 2015",
            "oceedings, Part II\n17, pp. 657–665. Springer, 2015.\n[79] Erik Pescara, Alexander Wolpert, Matthias Budde, Andrea Schankin, and Michael Beigl.\nLifetact: utilizing smartwatches as tactile heartbeat displays in video games. In Proceed-\nings of the 16th International Conference on Mobile and Ubiquitous Multimedia, pp.\n97–101, 2017.\n[80] Sayaka Ogawa, Koichi Fujiwara, and Manabu Kano. Auditory feedback of false heart\nrate for video game experience improvement. IEEE Transactions on Affective Computing",
            "rovement. IEEE Transactions on Affective Computing,\nVol. 14, No. 1, pp. 487–497, 2020.\n[81] Masaki Omata and Yuta Nakada. An implementation of a pseudo-beat presentation de-\nvice affecting emotion of a smartphone video viewer. In CHIRA, pp. 149–157, 2021.\n[82] Ruoqi Wang, Haifeng Zhang, Shaun Alexander Macdonald, and Patrizia Di Campli\nSan Vito. Increasing heart rate and anxiety level with vibrotactile and audio presentation\nof fast heartbeat. In Proceedings of the 25th International Conference ",
            " Proceedings of the 25th International Conference on Multimodal\nInteraction, pp. 355–363, 2023.\n[83] Kyung Yun Choi and Hiroshi Ishii. ambienbeat: Wrist-worn mobile tactile biofeedback\nfor heart rate rhythmic regulation. In Proceedings of the fourteenth international confer-\nence on tangible, embedded, and embodied interaction, pp. 17–30, 2020.\n[84] Polar. M600 ユーザマニュアル. https://support.polar.com/e_manuals/\nM600/wear-os/polar-m600-user-manual-japanese/Content/\nintroduction.htm. (参照日2022/1/3).\n[8",
            "anese/Content/\nintroduction.htm. (参照日2022/1/3).\n[85] The Internet Movie Database. Terminator 2: Judgment day. https://www.imdb.\ncom/title/tt0103064/. （最終参照日：2024/7/19）.\n[86] Apple.\niphone13 pro - 技術仕様.\nhttps://support.apple.com/ja-jp/\n111871. （最終参照日：2024/3/18）.\n91\n[87] Helen J Michielsen, Jolanda De Vries, and Guus L Van Heck. Psychometric qualities of a\nbrief self-rated fatigue measure: The fatigue assessment scale. Journal of psychosomatic\nresearch, Vol. 54, No. 4, pp. 345–352, 2003.\n[88] Task",
            "arch, Vol. 54, No. 4, pp. 345–352, 2003.\n[88] Task Force of the European Society of Cardiology the North American Society of Pac-\ning Electrophysiology. Heart rate variability: standards of measurement, physiological\ninterpretation, and clinical use. Circulation, Vol. 93, No. 5, pp. 1043–1065, 1996.\n[89] Mirja A Peltola. Role of editing of r–r intervals in the analysis of heart rate variability.\nFrontiers in physiology, Vol. 3, p. 148, 2012.\n[90] 駒澤真人, 板生研一, 羅志偉. スマートフォンのカメラを用いた心拍変動解析システ\nムの開発. 第",
            " 駒澤真人, 板生研一, 羅志偉. スマートフォンのカメラを用いた心拍変動解析システ\nムの開発. 第20 回人間情報学会ポスター発表集, pp. 19–20, 2014.\n[91] Delphine Rommel, JL Nandrino, M Jeanne, R Logier, et al. Heart rate variability analysis\nas an index of emotion regulation processes: interest of the analgesia nociception index\n(ani). In 2012 Annual international conference of the IEEE engineering in medicine and\nbiology society, pp. 3432–3435. IEEE, 2012.\n[92] 櫻井優太, 清水遵. 感情体験と生理指標の共変動―感情リアルタイム評定法による時\n系列的検討―. 感情心理学研究, Vol. 20, No. Supplement, pp. 44–44, 2",
            "討―. 感情心理学研究, Vol. 20, No. Supplement, pp. 44–44, 2013.\n[93] Python. About python. https://www.python.org/about/. （最終参照日：\n2024/9/26）.\n[94] scikit learn. scikit-learn: machine learning in python. https://scikit-learn.\norg/stable/#. （最終参照日：2024/9/26）.\n[95] scikit learn.\nStratiﬁedshufﬂesplit - scikit-learn.\nhttps://scikit-learn.\norg/stable/modules/generated/sklearn.model_selection.\nStratifiedShuffleSplit.html. （最終参照日：2024/9/26）.\n[96] The university of Waikato.\nSoftware - university of waikato.\nhttps",
            "f Waikato.\nSoftware - university of waikato.\nhttps:\n//www.waikato.ac.nz/research/institutes-centres-entities/\ninstitutes/artificial-intelligence-institute/research/\nsoftware/. （最終参照日：2024/9/26）.\n[97] Google. Firebase realtime database. https://firebase.google.com/docs/\ndatabase?hl=ja. （最終参照日：2024/10/21）.\n[98] M5Stack. Atom-lite. https://docs.m5stack.com/en/core/ATOM%20Lite.\n（最終参照日：2024/10/21）.\n[99] M5Stack. Unit vibrator. https://docs.m5stack.com/en/unit/vibrator.\n（最終参照日：2024/10/21）.\n[100] Ardui",
            "/en/unit/vibrator.\n（最終参照日：2024/10/21）.\n[100] Arduino.\nArduino uno r4 minima.\nhttps://docs.arduino.cc/hardware/\nuno-r4-minima/. （最終参照日：2024/10/21）.\n92\n[101] SparkFun Electronics.\nSparkfun haptic motor driver - drv2605l.\nhttps://www.\nsparkfun.com/sparkfun-haptic-motor-driver-drv2605l.html.（最\n終参照日：2024/9/28）.\n[102] フォスター電機株式会社.\nバイブレーションアクチュエータ.\nhttps://www.\nfoster.co.jp/products/productdata/VCA_C25_639897.pdf.（最終参\n照日：2024/10/22）.\n[103] BitTradeOne. 触感デバイス開発/体感モジュール“ hapstak ”. https://github.\ncom/b",
            "触感デバイス開発/体感モジュール“ hapstak ”. https://github.\ncom/bit-trade-one/ADACHACY-hapStak. （最終参照日：2024/10/22）.\n[104] M5Stack.\nAtom-matrix.\nhttps://docs.m5stack.com/en/core/ATOM%\n20Matrix. （最終参照日：2024/10/21）.\n[105] M5Stack. Tail bat. https://docs.m5stack.com/en/atom/tailbat. （最終\n参照日：2024/10/21）.\n[106] 宮岡徹. ヒト触覚情報処理の基礎. 計測と制御, Vol. 47, No. 7, pp. 554–560, 2008.\n[107] Takuji Narumi, Yuki Ban, Takashi Kajinami, Tomohiro Tanikawa, and Michitaka Hirose.\nAugmented perception of satiety: controlling food consumpt",
            "d perception of satiety: controlling food consumption by changing apparent\nsize of food with augmented reality. In Proceedings of the SIGCHI conference on human\nfactors in computing systems, pp. 109–118, 2012.\n[108] Yuki Ban, Takuji Narumi, Tomohiro Tanikawa, and Michitaka Hirose. Modifying per-\nceived size of a handled object through hand image deformation. Presence: Teleoperators\nand Virtual Environments, Vol. 22, No. 3, pp. 255–270, 2013.\n[109] M5Stack. Unbuckled grove cable. https://shop.m5s",
            "] M5Stack. Unbuckled grove cable. https://shop.m5stack.com/products/\n4pin-buckled-grove-cable. （最終参照日：2024/10/21）.\n[110] M5Stack.\nSk6812 digital rgb led strip.\nhttps://shop.m5stack.com/\nproducts/sk6812-rgb-led-flex-strip?variant=32042216882266.\n（最終参照日：2024/10/21）.\n[111] Peter J Snyder and Harry A Whitaker. Neurologic heuristics and artistic whimsy: The\ncerebral cartography of wilder penﬁeld. Journal of the History of the Neurosciences,\nVol. 22, No. 3, pp. 277–291, 2013.\n[112] ピカリ館. 角形シリコンチューブ. h",
            "o. 3, pp. 277–291, 2013.\n[112] ピカリ館. 角形シリコンチューブ. https://www.akiba-led.jp/product/\n530?srsltid=AfmBOoqeElZ7OEJ5GluaK-zVtA14aQh14yznue0NpB_\nO-1A_BRzNU_aT. （最終参照日：2024/11/10）.\n[113] Paramount Pictures.\n『ミッション：インポッシブル』シリーズ.\nhttps://\nparamount.jp/mi-dvd/mi3/index.html. （最終参照日：2024/12/10）.\n[114] Margaret M Bradley and Peter J Lang. Measuring emotion: the self-assessment manikin\nand the semantic differential. Journal of behavior therapy and experimental psychiatry,\nVol. 25, No. 1, pp. 49–59, 1994.\n93\n",
            "l psychiatry,\nVol. 25, No. 1, pp. 49–59, 1994.\n93\n[115] J Brooke. Sus: A quick and dirty usability scale. Usability Evaluation in Industry, 1996.\n[116] Borja F Villar, Pablo F Vi˜nas, Javier P Turiel, J Carlos Fraile Marinero, and Alfonso\nGordaliza. Inﬂuence on the user’s emotional state of the graphic complexity level in vir-\ntual therapies based on a robot-assisted neuro-rehabilitation platform. Computer Methods\nand Programs in Biomedicine, Vol. 190, p. 105359, 2020.\n[117] Aaron Bangor, Philip",
            ". 190, p. 105359, 2020.\n[117] Aaron Bangor, Philip Kortum, and James Miller. Determining what individual sus scores\nmean: Adding an adjective rating scale. Journal of usability studies, Vol. 4, No. 3, pp.\n114–123, 2009.\n[118] KUROCO. t 検定とはexcel で分析を行う方法を解説. https://kuroco.team/\nblog-data-t-test-excel/. （最終参照日：2025/1/10）.\n94\n付録A\n本研究に関する発表実績\n1. 柴武志，竹下怜花，ロペズギヨーム: MEASc：動画恐怖体験拡張スマートフォン\nケース, マルチメディア, 分散, 協調とモバイル(DICOMO2023) シンポジウム論文集,\npp.853-859(2023)\n2. Takeshi Shiba，Reika Takeshita，Guillaume Lopez",
            ")\n2. Takeshi Shiba，Reika Takeshita，Guillaume Lopez，\n“Development of a Smartphone Case\nfor Horror Movie Experience Augmentation ”, The International Conference on Activity\nand Behavior computing, 2023, @Deutsches Forschungszentrum f¨ur K¨unstliche Intelli-\ngenz Kaiserslautern\n95\n質疑応答\n工藤聖人情報テクノロジー学科助手\nQ\nなぜ暗いところで評価実験を行ったのですか？\nA\n理由は2 点あります．1 点目は，照明をフィードバックとして利用しているた\nめです．擬似心拍刺激を赤色光で提示することで，十分な効果を与えられると\n考えました．2 点目は，赤色光が情動に与える影響に関する関連研究に基づい\nているためです．複数の関連研究では，実験環境として暗室が用いられており，\n情動に作用する可能性が示された研究結果は，暗室環境",
            "連研究では，実験環境として暗室が用いられており，\n情動に作用する可能性が示された研究結果は，暗室環境を前提としたものであ\nることを考慮しました．\n工藤聖人情報テクノロジー学科助手\nQ\n暗い中で30 分動画見る上で画面の明るさが負担になり得ると思いますが，そ\nの影響は？\nA\n実験において，暗室内で約30 分間のアクション動画を鑑賞することは，眼精\n疲労を誘発する可能性が考えられます．しかし，鑑賞前に各被験者に対し，動\n画の冒頭1 分程度を再生して画面の輝度を調整するよう指示し，実際に調整を\n行った上で鑑賞してもらうことで，負担の影響を抑えました．\n浦垣啓志郎情報テクノロジー学科助手\nQ\n今後の課題の4DX 化みたいなことをしてシステムが肥大化しすぎると映画館\nで良いのでは？となるので，スマートフォンだからこそできるフィードバック\n(映画館では実現できないフィードバック) を模索してみると面白いと思いまし\nた．\nA\n貴重なご意見ありがとうございます．本研究では，映画館での4DX 体験をそ\nのままスマートフォンに移植するのではなく，個々人で鑑賞するという体型を\n活かしたフィードバックを重視し",
            "ままスマートフォンに移植するのではなく，個々人で鑑賞するという体型を\n活かしたフィードバックを重視しています．具体的には，鑑賞者の生理的反応\nに基づいて判定する昂りに連動して個別なタイミングでフィードバックを提供\nする点が特徴であり，これは映画館のような大規模環境では実現が確認されて\nいない手法です．今後の課題としても，スマートフォンならではの利点を活か\nしたフィードバックのあり方を模索し，スマートフォンアクセサリーの拡張に\nよって，多様な動画鑑賞体験の創出を目指します．\n96\n"
        ]
    },
    {
        "id": "paper_15",
        "filename": "M2024_Tatsuhiko_Hirai.pdf",
        "title": "M2024_Tatsuhiko_Hirai",
        "fulltext": " \n \n \n \n \n \n \n \n青 \n山 \n学 \n院 \n大 \n学 \n理 \n工 \n学 \n研 \n究 \n科 \n \n \n \n \n理工学専攻 \n知能情報 \nコース \n \n \n \n修 \n士 \n論 \n文 \n \n \n学 生 番 号 \n  35623242 \n \n \n \n氏 \n名 \n平井 龍彦  \n \n \n \n研究指導教員 \nロペズ・ギヨーム 教授 \n \nAcademic Year of 2024, Submitted on January 31, 2025 \n \nGraduate School of Science and Engineering, Aoyama Gakuin University \n \nTitle: IMU-Based Automatic Evaluation Method for Soccer Shooting Form \n \nStudent Name: Tatsuhiko Hirai \nID Number: 35623242 \nDegree: Master of Engineering \nCourse: Intelligence and Information \nThesis Advisor: Professor Guillaume Lopez \nAbstract  \nWith advancements in information technology, the application of technology in soccer \nhas progressed, leading to the development of various support systems. However, most \nof these systems focus on performance analysis rather than providing detailed \nassistance for skill improvement, such as shoot form enhancement. \nThis study aims to develop a skill improvement support system that players can use \nindependently using an affordable Inertial Measurement Unit (IMU) sensor. Specifically, \nit compares and evaluates two methods for automatically assessing soccer shooting \nform: motion recognition and evaluation using sensor-based posture estimation and \nform evaluation using machine learning. \nIMU sensors are attached to both ankles and the chest in the proposed method to \ncollect acceleration and angular velocity data. The posture estimation approach applies \na complementary filter to estimate the sensor’s orientation. The player's posture is \ncalculated from the sensor's posture estimation results. Meanwhile, the machine \nlearning approach detects and segments shooting motions from time-series data and \nextracts features to construct a classification model. The evaluation accuracy of both \nmethods is compared across four assessment criteria. \nThe results show that the machine learning approach accurately distinguishes good \nand poor shooting forms, while the posture estimation method effectively recognizes key \nshooting phases and analyzes form characteristics. However, some errors were observed \nin posture estimation. Overall, the machine learning method demonstrates superior \naccuracy, while the posture estimation approach proves helpful for motion segmentation \nand analysis. \nFuture work should focus on expanding data collection to include a more diverse range \nof players to improve model generalization. Although the posture estimation method \nhad lower evaluation accuracy, its effectiveness in motion segmentation and analysis \nwas demonstrated. Improving its precision through algorithm refinement and \noptimizing sensor placement could enhance its applicability for form evaluation. \n理工学専攻修士論文要旨 \n \n \n提出年度： 2024 年度 \n提出日： 2025 年1 月31 日 \n専修コース： 知能情報 コース \n学生番号： 35623242 \n学生氏名： 平井 龍彦 \n研究指導教員： ロペズ・ギヨーム 教授 \n \n（論文題目） \n \n慣性計測装置を用いたサッカーにおけるシュートフォーム自動評価手法 \n \n（内容の要旨） \n近年のIT 技術の進化により，サッカーにおける技術活用が進んでいる．プロサッカーでは，選手の \nパフォーマンス分析が重視され，カメラベースのシステムによる戦術解析やウェアラブルセンサによ \nる選手のパフォーマンス分析やコンディション管理に利用されている．アマチュア向けのサポートシ \nステムも登場し，手軽にフィジカルデータの取得が可能となった．しかし，これらは主にパフォーマン\nス分析が中心であり，キックフォームの改善など細かいスキル向上を支援する機能は限られている．こ\nのため，より詳細な技能向上を目的としたシステムの開発が求められている． \n本研究では，安価な小型慣性計測装置（IMU）を用いて，選手自身で利用可能な技能向上支援システ\nムの開発を目的としている．具体的に，サッカーのシュートフォームを自動評価する手法として，IMU \nのデータから姿勢を推定し，シュート動作の認識及び評価の精度を検証する．さらに，比較検証として，\n先行研究でサッカー動作の識別や熟練度の判定に活用されていた機械学習を用い，シュートフォームの\n良否判定の精度を検証する．これにより，姿勢推定と機械学習の両手法の有効性を評価し，より適切な\nフォーム評価手法を明らかにすることを目標とした． \n提案手法では，IMU センサを選手の両足首および胸部に装着し，加速度・角速度データを取得する． \n姿勢推定手法では，取得したデータに対して適切な前処理を施した上で，相補フィルタを用いてセンサ\nの姿勢を推定する．その後，推定した姿勢情報を基に，シュートの主要なポイントであるアプローチ，\nバックスイング，インパクト，フォロースルーの動作を認識し，選手のフォームを推定する．機械学習\n手法では，IMU センサの時系列データからシュート動作の自動検出およびセグメントを行い，加速度・\n角速度の6 軸の統計データを抽出する．これらの特徴量を用いて機械学習モデルを構築し，シュートフ\nォームの良否を識別する．本研究で扱うフォームの評価項目には，バックスイング時の蹴り足の角度，\nフォロースルー時の蹴り足の角度，軸足の傾き，上半身の傾きの4 つの項目を設定し，それぞれの手法\nの評価精度を比較する．バックスイング時の蹴り足の角度，フォロースルー時の蹴り足の角度は，角度\nの推定値としてそれぞれ算出し，ラベリング結果との平均絶対誤差（MAE）および平均絶対誤差率\n（MAPE）を算出する．そのほかの評価項目は推定結果とラベリング結果の一致率を算出し，評価精度\nを検証した． \n結果として，姿勢推定手法と機械学習手法による評価精度を比較したところ，機械学習手法がより高\n精度にフォームの良否を識別できることが確認された．時系列データから特徴を抽出し，適切な分類モ\nデルを用いることで，フォームの良否を高い精度で判定できた．姿勢推定手法では，相補フィルタを用\nいた姿勢推定により，シュートの主要なポイントを認識し，フォームの特徴を解析したが，一部の姿勢\n推定に誤差が見られた．総合的に，機械学習手法は精度面で優れており，姿勢推定手法は動作の分割と\n解析に有用であることが明らかになった． \n本研究では，現役の選手を対象にデータの収集実験を行ったため，フォームの良し悪しに偏りが生じ\nる可能性があった．今後は，より多様な選手を対象にデータを収集し，モデルの汎用性を向上させる必\n要がある．また，姿勢推定手法は評価精度としては低かったものの，動作の分割と解析に有用であるこ\nとが示された．精度の向上により，フォーム評価にも有効な手法となる可能性があるため，アルゴリズ\nムの改良やセンサ配置の最適化を進めることが求められる． \n \n \n青山学院大学大学院理工学研究科 \n慣性計測装置を用いたサッカーにおける\nシュートフォーム自動評価手法\n平井龍彦\n2025/1/31\n目次\n第1 章\n序章\n3\n1.1\n現代サッカーにおける研究背景. . . . . . . . . . . . . . . . . . . . . . . .\n3\n1.1.1\nサッカーの競技者数と指導者の関係\n. . . . . . . . . . . . . . . . .\n3\n1.1.2\nサッカーのIT 技術の活用\n. . . . . . . . . . . . . . . . . . . . . . .\n5\n1.1.3\nウェアラブルサッカーサポート製品\n. . . . . . . . . . . . . . . . .\n6\n1.2\n研究目的と目標. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n7\n1.3\n本論文の構成. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n8\n第2 章\n関連研究\n9\n2.1\n複数のサッカー動作を識別した研究. . . . . . . . . . . . . . . . . . . . . .\n9\n2.2\n熟練者と未熟練者の違いを解析および識別した研究. . . . . . . . . . . . .\n12\n2.3\nサッカー動作の評価に関する研究. . . . . . . . . . . . . . . . . . . . . . .\n14\n2.4\n選手・コーチへのサポートシステムを開発した研究. . . . . . . . . . . . .\n16\n2.5\n先行研究で残された課題と本研究の優位性. . . . . . . . . . . . . . . . . .\n18\n第3 章\nサッカースキルの向上支援の提案手法\n20\n3.1\nサッカースキル向上支援の概要. . . . . . . . . . . . . . . . . . . . . . . .\n20\n3.1.1\n本研究で扱うサッカー動作\n. . . . . . . . . . . . . . . . . . . . . .\n20\n3.1.2\n正しいキックフォームの定義\n. . . . . . . . . . . . . . . . . . . . .\n21\n3.1.3\n本研究で扱う評価項目. . . . . . . . . . . . . . . . . . . . . . . . .\n22\n3.2\n計測システムの開発\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n23\n3.2.1\n計測システムの開発\n. . . . . . . . . . . . . . . . . . . . . . . . . .\n23\n3.2.2\nセンサの装着位置\n. . . . . . . . . . . . . . . . . . . . . . . . . . .\n24\n3.3\n姿勢推定による動作評価手法\n. . . . . . . . . . . . . . . . . . . . . . . . .\n24\n3.3.1\n姿勢推定による動作評価手法の概要\n. . . . . . . . . . . . . . . . .\n24\n3.3.2\nセンサの姿勢推定処理. . . . . . . . . . . . . . . . . . . . . . . . .\n25\n3.3.3\nシュート動作の主要ポイントの認識\n. . . . . . . . . . . . . . . . .\n29\n3.3.4\n姿勢推定手法によるシュートフォーム評価. . . . . . . . . . . . . .\n31\n3.4\n機械学習による動作評価手法\n. . . . . . . . . . . . . . . . . . . . . . . . .\n32\n3.4.1\n機械学習による動作評価手法の概要\n. . . . . . . . . . . . . . . . .\n32\n3.4.2\nセグメンテーション手法. . . . . . . . . . . . . . . . . . . . . . . .\n33\n3.4.3\n特徴量の抽出. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n34\n3.4.4\n機械学習手法によるシュートフォーム評価. . . . . . . . . . . . . .\n34\n1\n第4 章\n提案手法の検証実験\n36\n4.1\nデータ収集実験. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n36\n4.1.1\n実験目的\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n36\n4.1.2\n被験者. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n36\n4.1.3\n実験方法\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n36\n4.1.4\nデータ収集実験の結果. . . . . . . . . . . . . . . . . . . . . . . . .\n37\n4.2\nラベリング方法. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n38\n4.3\n評価精度検証方法. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n39\n4.3.1\n姿勢推定手法の検証方法. . . . . . . . . . . . . . . . . . . . . . . .\n39\n4.3.2\n機械学習手法の検証方法. . . . . . . . . . . . . . . . . . . . . . . .\n40\n第5 章\n提案手法の検証結果と考察\n41\n5.1\n姿勢推定による動作評価手法の結果と考察. . . . . . . . . . . . . . . . . .\n41\n5.1.1\n姿勢推定による動作評価手法の結果\n. . . . . . . . . . . . . . . . .\n41\n5.1.2\n姿勢推定による動作評価手法の考察\n. . . . . . . . . . . . . . . . .\n42\n5.2\n機械学習による動作評価手法の結果と考察. . . . . . . . . . . . . . . . . .\n42\n5.2.1\n機械学習による動作評価手法の結果\n. . . . . . . . . . . . . . . . .\n42\n5.2.2\n機械学習による動作評価手法の考察\n. . . . . . . . . . . . . . . . .\n44\n第6 章\n結論と今後の展望\n46\n6.1\n結論. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n46\n6.2\n今後の展望\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n46\n謝辞\n48\n参考文献\n49\n2\n第1章\n序章\n1.1\n現代サッカーにおける研究背景\n1.1.1\nサッカーの競技者数と指導者の関係\nサッカーは世界的に人気であるスポーツの1 つで，世界中に35 億人以上を超えるファン\nがいると言われている[1]．特にワールドカップなどの国際大会では，世界中のサッカー\nファンが注目し，スポーツ文化の一環として大きな影響力を持っている．日本のサッカー競\n技人口に着目すると，2023 年度の日本サッカー協会の登録者数は約83 万人である[2]．図\n1.1 は1979 年から2023 年までの日本サッカー協会の登録者数の推移を表している．1993\n年のJ リーグ開幕をきっかけに競技者数が増加し，近年は増加と減少を繰り返していなが\nらも，概ね80 万人以上の競技者数を維持している．このような競技者数の推移はJ リー\nグやワールドカップなどが大きく影響し，今後もサッカーが日本国内の主要なスポーツと\nなると考えられる．図1.2 は2023 年度の登録選手の各カテゴリーの割合を表している．J\nリーグに所属するプロサッカー選手は全体で0.2%で，ほとんどがアマチュア以下の選手\nであることがわかる．特に若年層が大半を占めており，これは部活動や地域のクラブな\nど，サッカーを行う機会が多いことが大きな要因として挙げられる．このように若年層の\n競技者数が多いことは日本サッカーの将来にとって重要であり，これを維持するには教育\n的な側面や地域の格差への配慮が必要である．\n図1.1: 日本サッカー協会選手登録数（1979 年～2023 年）([2] より引用)\n3\n図1.2: 日本サッカー協会カテゴリー別選手登録割合（2023 年度）([2] より引用)\n図1.3 は日本サッカー協会に登録されている指導者数の推移を示しており，継続的に増\n加し，2023 年度には9 万人を超えている[3]．日本サッカー協会では，指導者に対して，\n指導レベルに応じたライセンスを発行しており，プロフェッショナルレベルのS 級コーチ\nから，アマチュアレベルのA～D 級コーチに分類されている[4]．特に，アマチュアレベ\nルの中でもA 級とB 級は「質の高いサッカー指導が可能である」とされる指導者に与え\nられるライセンスであるが，A 級は全体のわずか3%，B 級は9%に過ぎず，これらのライ\nセンス保持者の割合は非常に少ない．\n図1.3: 日本サッカー協会指導者数（2004 年～2023 年）([3] より引用)\n4\n日本サッカー協会の指導者登録数は増加傾向にあるものの，選手一人当たりの指導者数\nは依然として不足しており，これは選手一人に与える指導の質に直接的な影響を及ぼして\nいる．選手と指導者の適切な比率は年齢層によって異なるが，一般的に年齢が若いほど\nより多くの指導者が必要と考えられている．イングランドのサッカー連盟（The FA）は，\nコーチと選手の適切な比率についてガイドラインを出しており，コーチ1 人あたりに対\nする選手数として，4～8 歳は6 人，9～12 歳はは8 人，13～18 歳は10 人を推奨している\n[5]．これは年齢が低く，技術的に成長の初期段階において質の高い指導が非常に重要で\nあり，年齢が上がるにつれて熟練度及び自立度が高くなるため，指導者数がより少ない人\n数でも効率的に指導できるようになるからである．ただし，年齢が上がった場合でも，指\n導者の不足は，選手一人当たりに十分な指導が行き届かず，技術の習得や戦術理解が十分\nに進まないというリスクとなることは同様である．このため，指導者数および指導の質の\n向上が日本サッカーの将来にとって重要な課題となる．\n1.1.2\nサッカーのIT 技術の活用\n現代のIT 技術の進化に伴い，その技術がサッカーに対して活用されることが増えた．プ\nロサッカーの試合では，試合を円滑かつフェアに進めるために，審判をサポートするため\nに利用される事例が多く見られる．代表的なものとして，2012 年に競技規則に導入され\nた「ゴールライン・テクノロジー（GLT）」がある[6]．GLT はボールがゴールラインを完\n全に超えたかどうかを判断するために使用される技術であり，重要な得点シーンでの誤審\nを防ぐことが可能である．ゴールラインの両側に設置されたカメラやセンサがボールの位\n置を正確に測定することで，得点があったかどうかを審判に通知する仕組みである．さら\nに，2018 年からは「ビデオ・アシスタント・レフェリー（VAR）」システムが正式に導入\nされた[6]．VAR は主審が見逃した可能性のある重大なプレーについて，ビデオ映像を確\n認することで判定をサポートするシステムである．特にゴール，ペナルティキック，レッ\nドカードなど試合の行方に大きく影響する場合で使用される．VAR の導入により，試合\nの公平性を高めることが可能となった．\nまた，選手やコーチなどの競技者をサポートするため，IT 技術が活用されることも増\nえている．チームのマネジメントおよびパフォーマンスのモニタリングを目的として，ド\nイツの大手ソフトウェア企業SAP によって開発された「SAP Sports One」（図1.4）があ\nる[7]．このシステムはサッカーをはじめとするプロスポーツチームに向けて設計されて\nおり，チーム運営のさまざまな側面でサポートすることができる．ウェアラブルデバイス\nや高精細カメラによってフィールド上の選手とボールの動きをトラッキングし，走行距離\nやスプリント速度，パス成功率などをリアルタイムに解析する．選手に対するサポートと\nして，各選手のスマートデバイスで確認することを可能にすることで，自身のパフォーマ\nンスを客観的に振り返ることができる．一方でコーチに対するサポートは選手の位置や相\n手チームの情報をもとに戦術の最適化を図ることができる．同時に医療データや生体デー\nタから選手のコンディション管理をすることで怪我の予防や早期発見に貢献する．これに\nよってチームは試合に向けた準備を効果的に進めることができる．\n「SAP Sports One」はド\nイツのFC バイエルン・ミュンヘンや，日本のヴィッセル神戸など世界19ヶ国で80 チーム\n以上をサポートしている．\n5\n図1.4: SAP 社が開発したSAP Sports One（[7] より引用）\n1.1.3\nウェアラブルサッカーサポート製品\nサッカーのパフォーマンス分析には，映像解析によるカメラベースと信号解析によるセ\nンサベースの2 種類が主流である．カメラを用いたシステムは選手全体やフィールドの広\n範囲を捉えることができ，戦術的な分析には優れているが，設置や運用に高いコストと手\n間がかかるというデメリットがある．一方，ウェアラブルデバイスは比較的容易に導入す\nることが可能であり，個々の選手の動きをリアルタイムにトラッキングすることで，個人\nのパフォーマンス向上に役に立つデータの取得ができる．市販されているウェアラブルな\nサッカーサポートデバイスはプロ向けの高価なものからアマチュア向けの安価なものまで\nある．\nCatapult 社の「Catapult Vector Pro」（図1.5）は世界中の1200 以上のプロサッカーチー\nムで利用されているGPS を用いた代表的なサポートシステムである[8]．このデバイスを\n背中に装着することで，走行距離，走行速度，加速・減速，脈拍数などの情報を計測する\nことができる．高精度なトラッキングにより，個人のパフォーマンスの定量化やチーム全\n体の戦術改善，怪我のリスク低減が可能である．これらのデバイスは個人向けではなく\nチーム全体のサポートに特化したシステムである．\n図1.5: Catapult 社が開発したVector Pro（[8] より引用）\n6\n一方で，比較的安価で個人向けなシステムとして，Playermaker 社が開発した「Player-\nmaker 2.0」（図1.6）がある[9]．このシステムはスパイクに取り付けるタイプのスマート\nセンサを用いたアマチュア向けのウェアラブルシステムである．内蔵された加速度センサ\nと角速度センサから取得したデータから，走行距離やスプリント数，各足のタッチ数やパ\nス数，キックパワーなどの情報をトラッキングすることができる．\n図1.6: Playermaker 社が開発したplayermaker2.0([9] より引用)\nウェアラブルデバイスは選手個々の動きをリアルタイムにトラッキングし，パフォーマ\nンスを詳細に評価できる点で優れており，装着するだけで簡単に利用できるという特徴が\nある．しかし，取得できるデータや評価指標には限りがあるため，キックフォームの細か\nい改善を提示するような機能はないという課題がある．他にも様々なサッカーサポート製\n品があるが，選手のレベルや目的に応じた情報の取得ができるものを選び，有効に活用す\nることで，自身のパフォーマンス向上に繋げることが可能である．\n1.2\n研究目的と目標\n1.1.1 項で述べたように，サッカーは世界中で人気であり，日本においてもJ リーグの開\n幕などをきっかけに競技者が増加し，その大半は若年層を占める．しかし，選手一人あた\nりの指導者数は十分であるとは言えず，指導者全体の指導の質に関しても改善の必要性が\n課題として挙げられている．\n1.1.2 項で述べたように，現代のIT 技術の進化に伴い，それらの技術をプロサッカーの\n試合やチーム運営に活用されていることがわかった．審判へのサポートでは試合を円滑に\n進めるために，競技者へのサポートではパフォーマンスの評価や怪我の予測に役立てられ\nている．これらの技術はプロチームに向けた高価なものであり，アマチュアにとっては導\n入は難しいという課題がある．\n一方で，1.1.3 項で述べたように，ウェアラブルなサポート製品が多く販売されており，\nアマチュア向けの比較的安価な製品もある．これらの製品は選手の動きをトラッキング\nし，パフォーマンスを評価でき，装着するだけで簡単に利用できるという特徴がある．し\nかし取得できるデータの限界からキックフォームの細かい改善を提示するような機能はな\nいという課題が残されている．以上のことから，本研究の目的は安価な小型の慣性計測装\n7\n置を用いて，指導者がいない環境においても選手自身で利用可能なキックフォームフィー\nドバックシステムを開発することとする．\n以下に本研究の目的を達成するための目標を示す．\n• サッカー動作の重要な評価基準の設定\n• サッカースキルの自動評価手法の検証\n1.3\n本論文の構成\n本論文は以下の構成である．\n第1 章：本論文の研究背景，研究目的及び論文の構成について述べる．\n第2 章：サッカーの技術支援を目的とした先行研究と本研究の位置付けについ\nて述べる．\n第3 章：提案するシュートフォームの自動評価手法について述べる．\n第4 章：検証に用いるデータ収集実験と提案手法の精度検証について述べる.\n第5 章：精度検証の結果および考察を述べる．\n第6 章：本論文の結論と今後の展望について述べる．\n8\n第2章\n関連研究\n2.1\n複数のサッカー動作を識別した研究\nサッカーは，パス，シュート，ドリブル，ヘディングなど多様な動作から成り立つスポー\nツである．これらを正確に識別することは，選手の特性理解や戦術改善，そして技能向\n上システムの実現において重要である．この分野では，選手の動作を計測する手法とし\nて，センサ技術や映像解析技術が活用されている．本節では，それぞれの手法を用いた\nサッカー動作の識別に関する研究を紹介する．\n青柳らは，右足に装着した小型な慣性計測センサを用いて，サッカーの基本動作である\nシュート，ドリブル，パス，ヘディングを識別する手法を提案した[10]．慣性計測センサ\nから収集した3 軸加速度データからサッカー動作を検出し，自動セグメンテーションに\nよって分割した．さらに分割した動作データから特徴量を抽出し，ランダムフォレスト，\nサポートベクターマシン，ロジスティック回帰，k 近傍法，ガウスナイーブベイズ分類器\nの5 種類の分類モデルで動作の識別精度を検証した．その結果，シュート，パス，ドリブ\nルは90%以上の精度で検出が可能であり，特にサポートベクターマシンでは85%以上の\n分類精度を達成した．一方で，ヘディングの検出と分類精度が低く，ヘディングの識別精\n度の改善が課題として残った．\nD.Schuldhaus らは，IMU センサベースの計測システムを利用し，シュートとパスを識\n別する手法を提案した[11]．図2.1 に示すように，スパイクの内部にIMU センサ，脛当て\nに記憶装置を設置し，両足の加速度と角速度を計測するシステムを開発した．取得した\nデータから信号振幅ベクトル（SMV）を算出し，ピーク検出によって動作をセグメント\nした．セグメントした部分から平均，分散，歪度，尖度の4 つの統計的特徴をを抽出し，\nサポートベクターマシン，分類回帰木，ナイーブベイズの3 種類の分類モデルによって分\n類精度を検証した．分類は2 段階で分類する階層的アプローチを採用し，まずイベント\n（シュート，パス）とその他（タックル，ランニング，サイドステップを含む）に分類し，\n次にイベントからシュートとパスに分類した．結果として，イベントとその他の分類精度\nは89.5%，シュートとパスの分類精度は84.2%を達成し，サポートベクターマシンが最も\n高い性能を示した．\n9\n図2.1: （左）スパイク内部のIMU センサ，\n（右）脛当ての記憶装置（[11] から引用）\n伊藤らはサッカー選手のオフザボールに着目した動作分析システムを提案した[12]．こ\nのシステムは地磁気センサ，角速度センサ，GPS センサを選手の体に装着し，それらの\nデータを組み合わせることで，選手の向き，動作内容，位置情報を分析する．図2.2 にセ\nンサおよび周辺機器の装着位置を示す．大腿部に装着した角速度センサで内転・外転や屈\n曲・伸展による角速度変化を測定し，歩行，走行，ステップワーク，ジャンプなどの動作\nを判別することを可能にした．また，背中に装着した地磁気センサで選手の向いている方\n向を判別し，GPS センサを用いて選手の位置情報を取得する仕組みを構築した．基礎評\n価によってマルチセンサの組み合わせで詳細な動作分析が可能であることが確認された．\nしかし精度検証は行われておらず，試合での実用性を考慮したセンサ装着方法やGPS セ\nンサの位置測定の精度向上が課題として残された．\n図2.2: センサおよび周辺機器の装着位置（[12] から引用）\n10\nStoeve らはシューズに装着したIMU センサで計測したシュートとパスを深層学習モデ\nルによって識別する手法を提案した[13]．データ収集には，制御された条件下での環境と\n実際の試合や練習の環境で行い，それぞれの環境下での識別精度を検証することでシステ\nムの有効性を検証した．分類モデルは，先行研究のサポートベクターマシンと3 つの深層\n学習モデル(CNN，LSTM，convLSTM）を採用した．スライディングウィンドウ法によ\nる自動セグメンテーションを行い，加速度と角速度の各軸のキックフェーズ中の信号の絶\n対和を計算し，6 つの特徴量を分類器に入力した．結果として，試合や練習の環境で収集\nされたデータにおいてCNN がF1 スコア92.8%の最も高い識別精度を示した．\nMascher らは，MEMS 加速度センサを搭載したスマート脛当てを開発し，サッカー選手\nの動作識別を目的とした性能評価を実施した[14]．本システムでは立つ，歩く，走る，パ\nス，シュートの5 つの動作を対象とし，3 軸加速度データから合成加速度のピークを検出し\nてセグメンテーションを実施した．特徴量抽出に主成分分析と線形判別分析を適用し，機\n械学習アルゴリズムとしてロジスティック回帰，サポートベクターマシン，ランダムフォ\nレスト，人工ニューラルネットワークの分類精度を比較した．分類は2 段階で行い，第一\n段階でキックと他の動作，第二段階で詳細に分類するというアーキテクチャを提案した．\n結果として，線形判別分析を適用したロジスティック回帰とランダムフォレストが最も高\nい精度を達成した．被験者数が1 人に限定されており，さらなるデータ収集やドリブルな\nどの複雑な動作を含む分析が課題として残された．\nAlobaid らは加速度センサを搭載したスマートフォンを腹部に装着し，サッカーの5 つ\nの基本動作（シュート，パス，ヘディング，ランニング，ドリブル）をリアルタイムに識別\nする手法を提案した[15]．分類手法は，Time Series Forest Classiﬁer（TSF），Fast Shapelet\nTransform Classiﬁer（FS），Bag of SFA Symbols（BOSS），これらの複数のアルゴリズム\nの長所を組み合わせた協調モデルの4 つを比較した．結果として，協調モデルの精度が最\nも高い精度（84%）を達成し，学習時間を短縮することも可能であった．一方で，腹部に\nスマートフォンを装着する方法は激しい動作が行われるサッカーには不向きであり，カメ\nラを元に3 秒間のウィンドウでセグメントしているため動作外のデータが含まれてしまう\n点が課題として残された．\nHossain らは，リストバンド型のウェアラブルデバイスを用いて，サッカー選手の動作\nを解析するシステム「SoccerMate」を開発した[16]．このシステムはパス，キック，スプ\nリント，ランニング，ドリブルなどの動作を分類し，パフォーマンスを数値化することを\n目的としている．解析には，加速度データを用いて，動作の変化点を検出し，イベントご\nとにデータを分割し，Restricted Boltzmann Machine を用いた深層学習による動作の分類\nを行った．全体の分類精度は86.5%に達し，\n「走行」や「ランニング」，\n「静止」の動作にお\nいては高い精度を示した．一方で，ドリブルの動作は速度変化が明確にデータに現れない\n場合が多く，精度が低下することが確認された．\n今井らは，カメラで取得したサッカートラッキングデータを用いて，選手とボールの位\n置情報から10 種類のボールタッチプレーを自動認識する手法を提案した[17]．データは\nJ1 リーグ公式20 試合分を使用し，ボールの軌道や速度の変化に基づく条件でプレーを検\n出した．認識にはConditional Random Field（CRF），サポートベクターマシン，ランダム\nフォレストの3 種類の機械学習モデルを比較し，ボールの移動距離や選手間の距離などを\n特徴量として利用した．結果として，プレーの検出は86%を達成し，全体的に高い性能\n11\nを示した．一方で，プレーの認識はプレーごとに精度に差が見られ，パスやトラップは高\nい精度を示したがシュートやクリアなどの一部のプレーでは精度が低下する傾向が見られ\nた．データ数が少ない動作や曖昧な動作の認識に課題が残された．\n2.2\n熟練者と未熟練者の違いを解析および識別した研究\nサッカーの熟練者と未熟練者の動作にはそれぞれ特徴的な差が存在する．それを解析す\nることで，技能向上のための指標を提供することが可能となる．この分野では，サッカー\n動作のデータ収集手法として，センサ技術や映像解析技術が活用されている．本節では，\n熟練度の違いに着目したサッカー動作の解析に関する研究を紹介する．\n紅林らは，スポーツの動作解析を目的とした計測システムを開発し，現役サッカー選手と\n未経験者のインステップキック動作の違いを明らかにした[18]．計測システムはArduino，\n3 軸加速度センサ・角速度センサ，モバイルバッテリーを組み合わせて構築されており，足\nに装着することでキック動作を計測することができる．現役のサッカー選手と未経験者を\n対象とした実験の結果，現役選手はキック前に足を大きく引き上げ，加速度と角速度の最\n大値が高く，効率的な動作を行っていることが確認された．一方，未経験者は足の動きに\n無駄が多く，キック後も不要な動作が見られるなど，動作の非効率性が明らかになった．\n今後の課題として，上半身の動作にも着目し，サッカーの熟練度による違いを詳細に分析\nすること，本格的な利用に向けた計測デバイスの小型化などが挙げられた．\n真鍋らは，身体7 箇所に装着した慣性センサから取得したデータを基に，サッカー経験\nを持つ上級者と初心者のインステップキック動作を解析し，その違いを明らかにした[19]．\n静止したボールと動いたボールの両方を対象にキック動作の実験を実施し，解析では特に\n骨盤と蹴り足に注目した．解析の結果，上級者は初心者に比べて，骨盤の前後および上下\n方向の回転速度が速く，蹴り足の角速度も高いことが確認された．特に，動いているボー\nルに対するキックでは，これらの違いが顕著に増加し，効率的に伝達していることが示さ\nれた．また，スキルテストによるインステップキックのスコアと蹴り足の回転速度には正\nの相関が見られ，競技者の技術レベルを動作データを基に定量化できることを明らかに\nした．\nPiechota らは，熟練度が異なるサッカーのゴールキーパーを対象に，筋電図（EMG）を\n用いて意思決定時間と筋電図緊張値の違いを解析した[20]．2 対1 の典型的なゲーム状況\nを模擬し，シュートが打たれてからゴールキーパーがセーブアクションを完了するまでを\n意思決定時間と定義し，図2.3 に示すように，両足の10 箇所に装着された筋電図でデー\nタを収集した．結果として，熟練者は未熟練者より意思決定時間が優位に短いことが確認\nされた．また，熟練者は主要な姿勢筋の動作範囲を最適化し，効率の良い動作パターンを\n示した．一方，未熟練者は筋電図の緊張値が高く動作効率が低い傾向が示された．これら\nの結果から，熟練者が視覚情報と筋肉活動の連携を通じて動作の精度と効率を向上させて\nいることが示唆された．\n12\n図2.3: 筋電図の装着位置（[20] から引用）\nRoss らは，モーションキャプチャデータを用いて生成したIMU センサのシミュレーショ\nンデータを活用し，エリート選手と初心者を識別する分類手法を提案した[21]．モーショ\nンキャプチャから得た動作データを基に，IMU データとして線形加速度と角速度をシミュ\nレーションし，7 種類の動作の分類を行った．検証では，モーションキャプチャを用いた\n分類精度とシミュレートされたIMU センサを用いた分類精度で比較された．結果として，\nモーションキャプチャの分類精度は平均78.1%に対して，シミュレートされたIMU デー\nタでは平均80.2%を記録し，IMU データがモーションキャプチャと同等以上の精度を示す\nことが確認された．結果より，比較的低コストなIMU センサでも動作の評価が可能であ\nることが明らかになった．\n中村らは，熟練者と未熟練者のインステップキック動作を解析し，その違いを明らかに\nした[22]．測定には図2.4 に示したモーションキャプチャ測定システムを用いて実施され\nた．解析ではボールの速度，腰部や股関節の動き，軸足の傾斜角度に着目した．結果とし\nて，熟練者はボール速度が速く，腰部の動きが大きいことから体幹を効率的に活用してエ\nネルギーを伝達していることが示された．また，股関節では屈曲や外旋の動作範囲が広く，\n正確で力強いキック動作が可能であることが明らかになった．さらに，軸足の傾斜角度が\n大きいことで安定した姿勢を保ちながらキックを行っている点が特徴として挙げられた．\n一方，未熟練者はこれらの動きが全体的に小さく，動作効率が悪いことが確認された．\n図2.4: （左）測定システムの全景，\n（右）マーカの設置位置（[22] から引用）\n13\n辻元らは，3 次元動作解析システムを構築し，サッカー未経験者と熟練者のインステッ\nプ動作の違いを分析した[23]．このシステムは被験者に反射マーカを装着した状態で，4\n台のハイスピードカメラで撮影し，動作分析ソフトと用いた3 次元DLT 法によって各部\n位の三次元座標を取得することができる．解析の結果，熟練者は膝関節の伸展角速度が\n高く，下肢のムチの動作を効率的に利用していた．一方，未経験者は股関節が過剰に屈曲\nし，股関節の伸展角速度が低いことなど効率的なキック動作ができていないことが示され\nた．未経験者は軸足の傾きが小さく，インパクト時に安定した姿勢を取れていないことも\n明らかになった．今後の課題として，未経験者のキック技術向上を目指した指導法の開発\nや熟練者の動作を基にした効率的な練習法の提案が挙げられた．\n金子らは，人体の関節座標を取得するツール「OpenPose」を用いて，サッカーのシュー\nト動作を解析し，熟練度を識別する手法を提案した[24]．身体の18 箇所の関節座標を取\n得し，体の向き，軸足の位置，腰の回転，フォロースルーの4 つの特徴量を抽出した．こ\nれらの特徴量を基に，サポートベクターマシン，ランダムフォレスト，ロジスティック回\n帰などの機械学習モデルで，熟練度を分類した．結果として，ランダムフォレストが最も\n高い精度である84.0%を達成した．さらに，体の向きや腰の回転が熟練度を識別する上で\n重要な指標であることが示された．また，関節座標データを活用することで，体の向きや\n腰の回転などを数値化できる可能が確認され，動作解析における有効性が示唆された．\n正木らは，モーションキャプチャ技術を活用して，サッカーのトラップおよびパス動作\nにおける経験者と未経験者の違いを解析した[25]．被験者の上半身3 点（頭部，脊椎，腰\n部）から三角形の面積と傾き角度を特徴量として算出し，経験者と未経験者の識別に有用\nであるかを検証した．また，これらの特徴量を教師あり学習の分類モデル用いることで，\n分類精度を評価した．結果として，経験者は動作中の姿勢が安定しており，三角形の面積\nや傾き角度の変動が小さいことが確認された．一方で，未経験者は体軸のブレが大きく，\n三角形の面積と傾き角度に大きな変動が見られた．さらに提案した特徴量を用いた分類精\n度は，次元を削減しない生データを直接用いた分類精度に近い結果を示し，動作傾向の分\n析や識別に有効であることが示された．\n2.3\nサッカー動作の評価に関する研究\nサッカー動作を定量的に評価することで，選手の現在の技術レベルを客観的に把握し，\n具体的な改善点を特定することにつながる．また，評価結果を基にトレーニング内容を最\n適化することが可能となり，効果的なスキル向上が期待できる．定量的な評価を行うモデ\nルを開発するために，センサ技術やカメラ技術を用いて選手の動作データが収集される．\n本節ではこれらの技術を用いた動作評価に関する研究を紹介する．\nYu らは，足に装着したIMU センサの軌跡を推定することによって，キック動作の質を評\n価する解析手法を提案した[26]．IMU センサで収集した加速度・角速度データからクォー\nタニオンによる姿勢推定，座標変換することによって2 次元および3 次元の軌跡を構築し\nた．図2.5 はインステップキック時のデータから構築された2 次元および3 次元の軌跡を\n表している．提案手法は軌跡データから蹴り足の最大速度，バックスイングの最高点を抽\n出することで動作の特徴を解析した．精度検証には，高速カメラで取得したビデオデー\nタを正解データとして利用し，IMU センサによる推定結果との比較を行った．その結果，\n14\n足の最大速度とバックスイングの最高点についてはそれぞれ誤差4%と2.8%と高い精度を\n達成した．軌跡の位置誤差は0.07m，速度誤差は0.034m/s と低い値を示し，IMU センサ\nを用いた解析がキック動作の詳細な特徴を識別する手法として有効であることが示唆さ\nれた．\n図2.5: （左）インステップ時の2 次元のIMU センサの軌跡，\n（右）インステップ時の3 次\n元のIMU センサの軌跡（[26] から引用）\nWilmes らは，サッカー動作の中で加速，減速，切り返し，ジャンプ，キックに着目し，\n動作の強度を評価するシステムを提案した[27]．9 軸IMU センサを下半身の5 箇所（骨\n盤，大腿部，脛部）に装着し，膝および股関節の角度と角速度を算出し，動作の強度と\nして「低」「中」「高」の3 段階で精度の検証をした．モーションキャプチャを基準とし，\nRMSD（ルート平均二乗誤差）を用いて角度の誤差を評価し，CMC（多重相関係数）を用\nいてIMU センサとモーションキャプチャ間のデータ一致度を測定した．その結果，膝関\n節と股関節の角度におけるRMSD はそれぞれ平均5.3 °および8.0 °であり，CMC は0.985\nおよび0.940 と非常に高い一致率を示した．これらの結果は，IMU センサを用いて動作の\n強度を正確に評価できる可能性を示唆している．\nTakizadeh らは，k 近傍法（KNN）アルゴリズムとIMU センサを組み合わせて，子供の\nキックスキルを評価する手法を提案した[28]．IMU センサを両足のくるぶし上部と腰部\nに装着し，収集した加速度および角速度データを基に，子供の運動発達を質的に評価する\n標準化された項目（TGMD-3）に基づいて基礎運動スキルの評価を自動化した．専門家に\nよるスコアリングと本システムの評価結果を比較し，一致度を算出した結果，0.90 と高い\n精度が確認された．また，システムの評価分類精度も95%に達し，動作の正確な評価が\n可能であることが示された．さらに，本システムは従来の手動評価と比較して，1 回の動\n作の評価時間を平均5 分から30 秒未満に短縮する効率性も実証された．\nRada らは，選手評価および選抜のセレクションに有効な指標として，ポケットレーダー\nを用いたボール速度による評価手法を提案した[29]．ユースサッカー選手を対象に，ポ\nケットレーダーで記録した最大キック速度を基に，年代カテゴリ（U-15，U-17，U-19）お\nよびチームステータス（ファーストチームとリザーブチーム）の違いを統計的に分析し\nた．また，受信者動作特性（ROC）解析を用いて，測定結果が競技レベルを区別する診\n15\n断能力を評価した．結果として，ファーストチームの選手はリザーブチームの選手より一\n貫して高いキック速度を示し，特に若年カテゴリ（U-15 およびU-17）でその差が顕著で\nあった．また，ROC 解析により，最大キック速度は競技レベルを区別する上で有効な指\n標であることが確認された．\n安達らは，ビデオカメラと深層学習技術を用いて，ロングキック，トラップ動作を自動\n評価し改善アドバイスを提示する個人練習支援システムを提案した[30]．このシステムで\nは，Google MediaPipe を用いて選手の骨格情報を推定し，各関節の角度を算出した．図\n2.6 はMediaPipe の骨格推定の結果例である．この結果を基に，理想のフォームから逸脱\nしたポイントを特定し，改善に向けたアドバイスを生成する仕組みである．システムの精\n度検証では，モーションキャプチャシステムを基準として，一致度およびアドバイスの表\n示回数を比較した．経験者における一致度は7 割に達し，未経験者では誤表示が見られた\nものの，全てのアドバイスを提示することができた．課題として，ビデオカメラの角度に\nより体の一部が隠れることで，骨格推定の誤差や精度低下が生じる点が挙げられた．\n図2.6: MediaPipe による骨格推定の結果例（[30] から引用）\n2.4\n選手・コーチへのサポートシステムを開発した研究\n節2.1～2.3 節では，サッカー動作の識別や評価に関する研究について述べた．一方で，\n動作の識別や評価を活用し，具体的なフィードバックを通じて選手やコーチを直接的に支\n援するサポートシステムも開発されている．これらのシステムは，トレーニング内容の改\n善や戦術指導の補助に役立ち，選手のパフォーマンス向上や健康管理を支援するものであ\nる．本節では，これらのサポートシステムの概要とその効果について紹介する．\nMarris らは，サッカー動作を識別するシステムを利用して，ポジションやトレーニング\nメニューごとの技術動作の頻度や傾向を解析した[31]．このシステムはボールタッチやリ\nリース（パス，シュートなど）の動作を記録することが可能である．システムの識別精度\nの検証として，ビデオカメラを基準に比較した結果，一致率95%という高い精度で動作\nを識別可能であることを明らかにした．さらに，ポジション別の解析では，中盤選手が最\nも多く技術動作を行い，トレーニングメニューごとの解析では，小規模ゲーム形式の練習\nが技術動作の頻度を最も高めることが確認された．コーチが練習メニューや戦術の改善に\n役立つ具体的なデータを得ることが可能であることを示した．\n16\nIkram らは，サッカー選手の健康管理を目的としたIoT ベースの監視システム「IoT Foot-\nball」（図2.7）を開発した[32]．このシステムは，選手に装着されたセンサから生理的デー\nタ（心拍数，体温，発汗率など）をリアルタイムに収集し，クラウド上で解析することで\n健康状態の異常を検出する．また，気温や照明強度といった環境データも収集し，選手の\n健康とパフォーマンスに影響を与える要因を総合的に監視し，異常が検出された場合には\nモバイルアプリを通じてコーチや監督にアラートを通知する仕組みになっている．検証実\n験では，健康異常の検出率が99%以上という高精度を示し，リアルタイム通知により迅\n速な対応が可能であることが確認された．モバイルアプリを通じた通知機能の正確性や遅\n延時間を評価した結果，異常発生時に迅速かつ正確にアラートが送信されることが実証さ\nれた．\n図2.7: 「IoT Football」のシステム構成図（[32] から引用）\nStensland らは，選手のパフォーマンス解析と戦術可視化の効率化を目的としたリアルタ\nイムサポートシステム「Bagadus」（図2.8）を提案した[33]．トラッキングセンサ，カメ\nラ，コーチ向けのアノテーションツールを統合し，選手の動きやイベントをリアルタイム\nで記録・解析する．複数のカメラで撮影した映像を動的に切り替えたり，選手の位置デー\nタを基に特定イベント（パスやシュートなど）を自動的にタグ付けする機能を提供する．\nさらに，過去のプレーデータを瞬時に検索し，特定の状況を再生することも可能である．\nシステムの検証では，位置データと映像の同期性能やイベント抽出・再生までの時間を測\n定した．遅延時間は平均671ms で，リアルタイム解析に十分な効率性を示した．本研究\nは，選手のパフォーマンス向上やコーチによる戦術改善を効果的に支援するシステムとし\nて有効であることを示している．\n17\n図2.8: 「Bagadus」のシステム構成図（[33] から引用）\n2.5\n先行研究で残された課題と本研究の優位性\n2.1 節では，サッカー動作の識別に関する研究を紹介した．ウェアラブルセンサやカメ\nラから取得したデータを機械学習や深層学習を用いて分類することで，シュート，パスな\nどの基本動作を高精度で識別できることが示された．しかし，ヘディングやドリブルなど\nの複雑な動作に関しては識別精度が低いなど，使用するセンサによってプレーの認識精度\nに差が見られる課題が残った．また，これらの研究では動作の識別に重点を置いており，\n選手個人のフォーム改善や技術向上の支援まで至っていない．2.2 節では，サッカーの技\n能レベルの識別や動作の違いを解析した研究を紹介した．技能レベルの識別については，\n機械学習を用いることで高精度な識別が可能であることが示された．また，技術レベル\nによる動作の違いを詳細に解析した結果，熟練者は効率的かつ無駄の少ないフォームで\n動作する一方，未熟練者には非効率的な動作が多いことが明らかになった．このことか\nら，IMU センサやカメラで収集したデータに適切な信号処理や映像解析を適用すること\nで，動作の評価を行い，具体的かつ実用的な技術向上支援システムの実現が可能である\nことが示唆された．2.3 節で述べた，サッカーの動作評価に関する研究では，関節角度や\nバックスイングの高さなどフォームの特徴の数値化や，ボール速度や動作の強度を判定す\nることが可能であることが示された．しかし「良いフォーム」を明確に定義したものは少\nなく，それを基準とした総合的なフォーム評価は十分に行われていない．さらに，評価結\n果を選手にフィードバックする仕組みの構築がされていないという課題があった．2.4 節\nでは，選手やコーチを支援するサポートシステムに関する研究を紹介した．これらのシス\nテムは主に選手の健康管理や戦術改善に重点を置いており，生体データや技術動作を解析\nすることでトレーニングを補助することができ，トレーニング内容や指導を補助すること\nが可能となる．これらのシステムはチームの活動のサポートには有効である一方で，選手\n個人の技術向上を直接的に支援する仕組みは考えられていない．\n以上のことから，本研究ではサッカー技能向上を目的としたサッカー動作のフォーム改\n善を支援するシステムを開発する．まず，選手に負担の少ない計測システムを構築すると\n18\nともに，サッカー動作を詳細に認識する．さらに正しいフォームを明確に定義し，その定\n義に基づいて動作を評価判定するアルゴリズムを確立する．また，本研究ではカメラを用\nいる手法に比べて利用環境への負担が少なく，選手に装着するだけで計測が可能なIMU\nセンサを採用することで，指導者がいない環境でも選手自身が効率的にトレーニングに取\nり組むことができるシステムを目指す．図2.9 に本研究の位置付けを示す．\n図2.9: 本研究の位置付け\n19\n第3章\nサッカースキルの向上支援の提案手法\n3.1\nサッカースキル向上支援の概要\n本節では，本研究で対象とするサッカースキル，正しいフォームの定義，定義をもとに\n設定した評価項目について説明する．\n3.1.1\n本研究で扱うサッカー動作\nサッカーには多くの重要なスキルが存在し，大きく分けると「オープンスキル」と「ク\nローズドスキル」の2 種類に分類される．図3.1 にサッカースキルの全体図を示す．\n「オー\nプンスキル」とは，外的要因によって変化する状況に適応する能力を指し，具体例として\nプレーの判断力や状況の把握能力などが挙げられる．一方，\n「クローズドスキル」とは，安\n定した環境下で決められた動作を再現する能力を指し，シュート，パス，ドリブルといっ\nた基本的なサッカースキルと呼ばれる技術がこれに該当する．サッカーのパフォーマンス\nを向上させるには，どちらのスキルも必要不可欠である．理想は，これらのスキルをバラ\nンスよく習得していくことが望ましいが，スキルの習得は年齢による影響を大きく受け\nる．JFA（日本サッカー協会）は，特に若年層においてクローズドスキルの習得を推奨し\nている[34]．これは，U-10～U-12 の年代が「ゴールデンエイジ」と呼ばれる，技術習得\nに最適な時期であるためである．この時期に身につけた基本技術は長期的に維持されやす\nい特徴がある．一方で，年齢が上がるにつれて練習内容がオープンスキル中心へ移行する\n傾向があり，技術の新たな習得や修正が比較的に困難になる．そのため，本研究では若年\n層における効率的な技術習得だけでなく，高年層の技術の習得・向上を支援することを目\n的として，クローズドスキルに着目する．\n図3.1: サッカースキルの全体図\n20\nサッカーにおけるクローズドスキルは，図3.1 が示すように多様なスキルが含まれる．\nこれらのスキルは全て重要であるが，特に「シュート」が試合結果やチームの成績に大き\nな影響を与えることが先行研究で明らかにされている．Bilek らは，2017-2018 シーズン\nのイングランド・プレミアリーグの試合データを分析し，試合結果および得点数に影響を\n与える要因を特定する研究を実施した[35]．分析の結果，枠内シュート数が多いほど得点\nの可能性が高まり，試合の勝率が向上する傾向が示された．また，Souza らは，2010 年か\nら2018 年のスペイン・ラ・リーガの試合データを分析し，シーズン終了時の勝ち点に影\n響を与える要因を調査した[36]．その結果，攻撃面ではシュート精度の高さ，守備面では\n相手チームのシュート機会を減らし，被シュートの精度を低下させることがチームの好成\n績に繋がる要因であると結論づけている．これらの研究結果からシュートが試合結果を左\n右する重要なスキルであることが分かる．本研究ではシュートフォームを評価する手法を\n提案し技能向上の支援を目指す．\n3.1.2\n正しいキックフォームの定義\nシュートフォームを評価するために，正しいキックフォームを定義する．まず，図3.2\nに示すキック動作における4 つの主要なポイントを明確に設定した上で，そのポイントを\n基準に3 つのフェーズとして分割し，正しいフォームを定義する．以下にキック動作にお\nける4 つの主要なポイントと本研究で各動作を識別するための基準を示す．\n1. アプローチ\nキックのためにボールに向かう一連の動作\n識別の基準：蹴り足がインパクト前に最後に地面に設置した状態\n2. バックスイング\n蹴り足を後ろに引く動作\n識別の基準：蹴り足が最も高い位置になった状態\n3. インパクト\n蹴り足をボールに接触する動作\n識別の基準：蹴り足がボールに接触した状態\n4. フォロースルー\n蹴り足をターゲットの方向に最後まで振り切る動作\n識別の基準：蹴り足が前方に伸び切った状態\n21\n図3.2: キック動作の4 つの主要なポイント\nこれらの4 つの主要ポイントを元にシュート動作を3 つのフェーズに分割し，各フェー\nズの正しいフォームを定義する．本研究では，既存の研究論文およびサッカー技術に関す\nる教本を参考に正しいフォームを定義をした．研究論文はキック動作をバイオメカニクス\nの観点で解析し，効果的な動作や身体の状態に関する知見がまとめられている[37]．また\n教本ではキックの種類やボールの質を決める要素，それを踏まえた実践的な正しいフォー\nムが画像付きで説明されている[38]．これらをもとに，各フェーズにおける正しいフォー\nムを以下の通りに定義する．\nバックスイングフェーズ（アプローチ～バックスイング）\n• 蹴り足：高い位置で十分に振りかぶっている\n• 軸足：ボールの真横または少し前に適切な距離で接地できている．\nインパクトフェーズ（バックスイング～インパクト）\n• 蹴り足：足首が最大限に伸展し，ぶれないように固定されている\n• インパクト位置：ボールの中心近くをインパクトできている\n• 軸足：ブレーキをかけるようにすねの角度を後ろに倒している\n• 上半身：後傾していない（前傾または直立）\nフォロースルーフェーズ（インパクト～フォロースルー）\n• 蹴り足：蹴り足を止めずに上ではなく前方に足を振り抜いている\n• 上半身：ターゲットの方向を向いている\n3.1.3\n本研究で扱う評価項目\n3.1.2 項で定義した正しいキックフォームを元に，本研究で扱うシュート動作の各フェー\nズの評価項目を設定した．これらの評価項目は，慣性計測装置を用いて計測可能であると\n判断したものを選定した．また，評価としてフォームの良し悪しを判定する方法と，具体\n22\n的な姿勢角度などを定量化する方法がある．良し悪しの基準が明確に定義されている動作\nについては判定を行い，基準が曖昧な動作については客観的な評価が可能となる数値で表\n現する．\n評価項目1: バックスイング\n十分に高い位置に蹴り足を運んでいるか\n評価項目2: フォロースルー\n蹴り足を上ではなく，前に振り抜くことができているか\n評価項目3: 軸足の傾き\nインパクト時に，ブレーキをかけるように軸足の脛の角度が後ろに倒れているか\n評価項目4: 上半身の傾き\nフォロースルー時に，上半身が後ろに倒れていないか\n3.2\n計測システムの開発\n本節は，シュート動作を計測するためのシステムについて説明する．本研究では選手の\n動作を計測する手段として，IMU（慣性計測装置）センサを採用する．アマチュア選手に\nとって，高精度なカメラシステムなどの高価なデバイスを利用することは現実的ではな\nく，また個人での利用を考慮した場合，カメラを用いた計測環境を構築するには多大な労\n力とコストがかかるという課題がある．これらの理由から本研究では，比較的安価である\nIMU センサを活用することにより，低コストかつ手軽に計測可能なシステムを構築する．\n3.2.1\n計測システムの開発\n計測システムの構成を図3.3 に示す．本研究では，シュート動作を計測するため，IMU\nセンサとしてSUUNTO 社のMovesense[39] を使用し，記録用デバイスとしてApple 社の\niPhone 15[40] を採用した計測システムを構築した．Movesense はスポーツおよび健康分野\n向けのセンサで，9 軸IMU センサによる加速度・角速度・地磁気の動作計測に加え，心\n拍センサによる心拍数や心拍間隔などの計測が可能である．本研究では，先行研究でも利\n用されていた加速度および角速度を，サンプリングレート100Hz で計測する．計測され\nた3 軸加速度および角速度データは，Bluetooth を通じて，iPhone に送信され，専用アプ\nリケーションによって記録される．このアプリケーションは，Google 社が提供するマル\nチプラットフォームフレームワークFlutter[41] を利用して開発した．\n23\n図3.3: 計測システムの構成図\n3.2.2\nセンサの装着位置\n本研究ではIMU センサの装着位置として，図3.4 に示す胸部および両足首（外果の上）\nを選定した．これは，3.1.3 項で設定した評価項目に基づいて，評価に必要なデータを取\n得することを目的としている．\nまず胸部への装着は，上半身の状態を計測する上で適した位置である．背部への装着方\n法も検討したが，装着時に他者の補助を必要とする可能性が高く，1 人での使用には不向\nきであると判断した．一方，胸部への装着は自身で容易に装着することができ，日常的な\n練習や試合での実用性が高い．次に，両足首（外果の上）の装着は，足の動作を直接的に\n計測する上で適した位置である．特に外側に装着することでボールの接触リスクが低く，\n計測の不具合やセンサの故障を防ぐことができる．また，先行研究で提案されていたスパ\nイク内部や脛当てに装着するものに比べ，スパイクの種類やサイズに依存することがな\nく，専用のバンドで固定することによって，センサの安定性を確保しつつ，選手にとって\nストレスの少ない装着が可能となる．\n図3.4: （左）胸部の装着イメージ，\n（右）足首の装着イメージ\n3.3\n姿勢推定による動作評価手法\n3.3.1\n姿勢推定による動作評価手法の概要\n本研究では，シュートフォームの評価手法として，IMU センサによる姿勢推定を利用し\nた手法を提案する．両足首および胸部に装着したセンサの姿勢を推定することで，選手自\n24\n身の姿勢推定を実施し，3.1.3 項で設定した評価項目に基づいて，シュートのフォームを\n評価する．\n図3.7 に姿勢推定による動作評価手法の概要図を示す．まず計測したIMU センサデータ\nに適切な前処理を行い，センサの姿勢推定を実施する．次に，蹴り足の姿勢推定結果を用\nいて，シュートを構成する4 つの主要ポイント（アプローチ，バックスイング，インパク\nト，フォロースルー）を認識する．これらのポイントを明確に認識することで，シュート\nフォームを3 つのフェーズに分割し，各フェーズの評価項目に対応するセンサの姿勢情報\nを利用して選手のシュートフォームを評価する．\n図3.5: 姿勢推定による動作評価手法の概要図\n3.3.2\nセンサの姿勢推定処理\nセンサデータの姿勢推定の流れを図3.6 に示す．本項では姿勢推定までの各処理につい\nて説明する．\n25\n図3.6: センサの姿勢推定の流れ\nリサンプリング\n本研究で利用する計測システムでは，取得される加速度および角速度データは不等間隔\nで記録される．データを扱いやすくするため，等間隔データに変換するリサンプリング処\n理を実施した．リサンプリングには，計算効率と精度のバランスを考慮し，線形補間を採\n用した．線形補間の式を式3.1 に示す．この線形補間を適用することで，不等間隔データ\nを等間隔データに変換する．\nf(x) = f(x1) + f(x2) −f(x1)\nx2 −x1\n· (x −x1)\n(3.1)\nセンサキャリブレーション\nセンサには静止状態であっても一定のオフセットが存在し，測定値が実際の値からズレ\nる問題がみられた．これを補正するため以下の手順でバイアスキャリブレーションを実施\n26\nした．\n1. 静止状態の検出\nデータの差分値を計算し，一定の閾値以下である区間を静止状態と見なし，該当サ\nンプル数をカウントする．\n2. 静止時の平均値計算\n静止時の加速度および角速度データ（各軸）の平均値を算出する．\n3. バイアス補正\n算出された平均値およびセンサ装着方向を考慮した期待される値の差をバイアスと\nみなし，計測値を補正する．\n平滑化処理\nセンサデータのノイズを低減する処理として，移動平均フィルタを適用する．移動平均\nフィルタは一定の範囲内のデータの平均を算出することで短期的な変動を抑え，滑らかな\nデータを得ることができる．移動平均フィルタの式を式3.2 に示す．本研究では移動平均\nフィルタのウィンドウサイズを3 に設定する．\nSsmoothed(t) = 1\nk\nk\n∑\ni=1\nS(t −i)\n(3.2)\n加速度センサおよび角速度センサの特性\n加速度センサは重力加速度を計測することにより，静的な環境におけるセンサの絶対的\nな姿勢を推定することが可能である．加速度センサによる姿勢推定の利点として，長時間\nにわたって安定した姿勢推定が可能という点が挙げられる．しかし，動きが激しい動的環\n境下における精度の低さが課題である．これは，運動時に伴う重力加速度以外の加速度の\n影響を大きく受けるため，短期的な動作や急激な姿勢変化に対応することが難しくなるた\nめである．\n一方，角速度センサは回転角速度を測定することで姿勢を推定することが可能である．\n角速度センサの利点として，短期的な姿勢変化に対して高い精度で姿勢推定が可能であ\nり，高速な動作や衝撃が伴う環境下でも比較的安定した姿勢推定ができるという点が挙げ\nられる．しかし，角速度センサによる姿勢推定では長期的な推定には適していないという\n課題がある．角速度センサの姿勢推定の仕組みとして，回転速度を時間積分し，過去の姿\n勢に対して回転の変化量を加算していくことで姿勢を推定する．この過程で発生した微小\nな誤差が継続的に蓄積していく「累積誤差（ドリフト）」という現象が生じてしまう．僅\nかな誤差であっても，長期的な時間の経過とともに誤差が積み重なり，最終的には実際の\n姿勢と大きく異なる推定となってしまう．\nセンサフュージョンの適用\n加速度センサと角速度センサはそれぞれ異なる特性を持ち，単独では姿勢推定において\n限界がある．本研究ではそれぞれのセンサの課題を補うセンサフュージョンの手法を適用\n27\nし精度の高い姿勢推定を実現する．代表的なセンサフュージョン手法として，相補フィル\nタを利用する．相補フィルタは，加速度センサと角速度センサのデータを統合し，それぞ\nれの弱点を補完する手法である．基本原理は，ローパスフィルタで加速度データの低周波\n成分を，ハイパスフィルタで角速度センサの高周波成分を抽出し，これらを組み合わせる\nことで，短期的な姿勢変化に追従しつつ，長期的な安定性を確保できる．フィルタの設計\nでは，ローパスフィルタとハイパスフィルタのゲインの和を1 とすることで，バランスを\n維持しつつ，位相遅れを抑えた安定した推定が可能である．相補フィルタの式を式3.3 に\n示す．重み付け係数α は，ジャイロセンサの信頼度を調整するパラメータであり，本研究\nでは0.9 に設定した．\nθ(t) = α · θgyro(t) + (1 −α) · θacc(t)\n(3.3)\n姿勢推定の補正\n相補フィルタによるセンサの姿勢結果より，前処理およびセンサフュージョン手法を用\nいた場合でも，累積誤差の影響を完全に除去することができず，時間の経過とともに推定\n値が一方向に偏る傾向が見られた．この現象が発生すると，初期状態と同じ姿勢に戻った\n場合でも，異なる姿勢として推定される問題が生じる．本研究では，線形回帰を用いた補\n正手法を導入し，累積誤差による傾きを除去する処理を行う．まず，各姿勢データの傾向\nを線形回帰によってモデル化し，データ全体の傾きを求める．次に補正の適用に際し，時\n間の経過とともに補正量を大きくするため，時間を0 から1 に正規化した補正スケールを\n導入する．これにより，時系列の初期段階では補正を緩やかにし，時間の経過とともに補\n正を強める設計とした．最後に，線形回帰で求めた傾きと各時刻の補正スケールをもとに\n補正量を計算し，元のデータから差し引くことで累積誤差の影響を低減する．補正の式を\n式3.4 に示す．\nθcorrected(t) = θ(t) −mθ · t · Scorr(t)\n(3.4)\nここで，θcorrected(t) は補正後の推定角度（ロール・ピッチ・ヨーのいずれか），θ(t) は補\n正前の推定角度を表す．また，mθ は累積誤差の傾向を示す線形回帰によって求めた傾き\nであり，時間の経過に伴う推定値の偏りを示す．さらに，t は時刻データ，Scorr(t) は補正\nスケールを表し，時間の経過とともに補正量が大きくなるよう設計されている．図3.7 に\n補正前および補正後の姿勢推定の結果を示す．\n28\n図3.7: （左）補正前の姿勢推定結果と回帰直線，\n（右）補正後の姿勢推定結果\n3.3.3\nシュート動作の主要ポイントの認識\nシュート動作における4 つの主要ポイントを認識する手法としてセンサの姿勢推定結果\nを利用する．本研究では，蹴り足に装着したセンサの進行方向に対する前後の姿勢推定を\n利用する．この回転軸は，足の側面を通るような回転軸の回転角度を示す．\n29\nバックスイングの認識\nバックスイングは蹴り足が最も高い状態である．足の側面を通るような回転軸を考慮す\nると，バックスイング時は特定の方向に最大の回転をすると考えられる．姿勢推定結果の\n最低値がバックスイングのポイントにあたる．推定結果から最低値を検出することでバッ\nクスイングを認識する．\nフォロースルーの認識\nフォロースルーは蹴り足が最も前方にある状態となる．足の側面を通るような回転軸を\n考慮すると，フォロースルー時はバックスイングとは逆方向に最大の回転をすると考えら\nれる．姿勢推定結果より，最大値がフォロースルーのポイントにあたる．推定結果から最\n大値を検出することでフォロースルーを認識する．\nインパクトの認識\nインパクトの前後で蹴り足の傾きに着目すると，インパクト前は蹴り足がバックスイン\nグと同様であり，インパクト後はフォロースルーと同様の傾きになる．そこでインパクト\nの認識は，蹴り足の姿勢推定の値の正負が切り替わるポイントであると考えられる．本研\n究では，バックスイングからフォロースルーにかけて，最後のマイナスであるサンプルを\n検出することでインパクトを認識する．\nアプローチの認識\n本研究で定義したアプローチのポイントは蹴り足がインパクト前に最後に地面に接地し\nている状態であり，直立している時の足の状態と近い．姿勢推定結果より，アプローチの\nポイントは回転がほぼゼロに近い状態であるポイントとなる．ランニングの動作はバック\nスイングのように足が後ろにある状態と地面に接している状態を繰り返すことになる．足\nが後ろにある状態はバックスイングと同様に負の値を示し，地面に接している状態は直立\n状態に近いため0 に近い値を示していることがわかる．本研究で定義したアプローチのポ\nイントはインパクト前に蹴り足が最後に地面に接しているポイントである．そこでバック\nスイングから遡って，最初に0 に近いピークを示したポイントをアプローチのポイントと\nして認識することができる．\n以上の説明をまとめると，各ポイントはそれぞれ特徴的な姿勢推定の結果をもとに認識\nすることができる．図??に姿勢推定の結果に基づいた各ポイントの認識の例を示す．\n30\n図3.8\n3.3.4\n姿勢推定手法によるシュートフォーム評価\n本項では，3.1.3 項で設定した評価項目をセンサの姿勢推定によって評価する方法を述\nべる．表3.1 に各評価項目について，対象となるセンサと判定のタイミングを示す．\n評価項目1「バックスイング」および評価項目2「フォロースルー」については，蹴り\n足に装着したセンサの姿勢推定結果を基に，バックスイング時およびフォロースルー時\nの角度を回帰的に求め，これらの角度をもとに評価を行う．一方で評価項目3「軸足の傾\nき」および評価項目4「上半身の傾き」については，蹴り足センサが認識した各ポイント\n（インパクトやフォロースルー）における，軸足および胸部のセンサの姿勢推定から姿勢\n状態を確認し，それぞれの良し悪しを分類的に評価する．具体的な判定方法は，評価項目\n3「軸足の傾き」はインパクト時に0 °以下の場合は「良」，0 °より上の場合は「悪」と\n判定し，評価項目4「上半身の傾き」はフォロースルー時に0 °以上の場合は「良」，0 °\nより未満の場合は「悪」と判定する．\n31\n表3.1: 評価項目の判定タイミングと使用センサ\n評価項目\n判定タイミング\n使用センサ\nバックスイング\nバックスイング時\n蹴り足\nフォロースルー\nフォロースルー時\n蹴り足\n軸足の傾き\nインパクト時\n軸足\n上半身の傾き\nフォロースルー時\n胸部\n3.4\n機械学習による動作評価手法\n3.4.1\n機械学習による動作評価手法の概要\n本研究では，3.3 節で紹介した姿勢推定による評価手法の比較検証として，機械学習を\n用いた評価手法を提案する．先行研究では，動作の分類や熟練度の判別手法として機械学\n習が広く活用されており，その結果，多様な動作パターンを学習し，高精度な識別が可能\nであることが示されている．これを踏まえ，本研究では機械学習手法をシュート動作の評\n価に応用できるかを検証する．\n図3.9 に機械学習による動作評価手法の概要図を示す．まず計測したIMU センサデータ\nからシュート動作をセグメントし，機械学習に利用する特徴量を抽出する．特徴量の抽出\nに際しては，統計データを抽出した上で，主成分分析（PCA）を用いて次元削減を実施す\nる．最後に機械学習による分類によってシュートフォームの良し悪しを判別をすることで\n動作を評価する．\n図3.9: 機械学習による動作評価手法の概要図\n32\n3.4.2\nセグメンテーション手法\n計測した時系列データには，助走を行う前やキックを行った後などの評価範囲外の不要\nなデータが含まれる．そのため，時系列データからキックを行った部分のみを抜き出す必\n要がある．そこで時系列データからキックイベントを検出し，セグメントすることで抽出\nする．\n本研究ではセグメンテーション手法としてインパクトを基準にセグメントを実施する．\nインパクトは蹴り足とボールが接触する瞬間の動作を指す．この動作の特徴として，蹴り\n足はインパクトにかけて加速し，ボールに接触した後は急激に減速する．この加速と減速\nの特性は加速度データにも反映され，特徴的なピークとして現れると考えられる．本研究\nでは適切な前処理によって加速度データからインパクトを検出する．インパクト検出の流\nれを図3.10 に示す．\n図3.10: インパクト検出フロー\n33\nインパクト検出のための前処理\n最初に加速度データから重力加速度成分を取り除き，キック動作に起因する加速度成分\nのみを抽出する．本研究の計測システムのセンサデータは不等間隔であるため，まず線形\n補間を用いて100Hz の等間隔データにリサンプリングする．その後，高速フーリエ変換\n（FFT）を適用し，0.5Hz 以下の低周波成分を削除することで重力加速度成分を除去した．\n次に，3 軸加速度データを統合し，運動の方向に依存しない単純な運動の強度を抽出す\nる．これは3 軸加速度データのノルムを計算する．ノルムは式（3.5）によって算出する．\nnorm =\n√\nx2 + y2 + z2\n(3.5)\n次に，移動平均フィルタを用いてノルムデータを平滑化し，ノイズを除去する．この処\n理によって加速度データの特徴的なピークを明確化する．本研究では移動平均フィルタの\nウィンドウサイズを10 に設定した．平滑化したデータは式（3.6）によって算出する．\nSt = 1\nk\nk\n∑\ni=1\nnorm(t −i)\n(3.6)\nセグメンテーション\n最後に平滑化したノルムデータを基に，インパクトをノルムデータの最大値として検出\nする．検出したインパクトを基準とし，インパクト前1.5 秒，インパクト後0.5 秒の範囲\nをセグメントすることで抽出する．この時間範囲は，映像データをもとに算出し，シュー\nト動作の前後の動きを十分に含むように設定した．動作の始まりから終わりまでを適切に\nカバーすることで，シュート動作の特徴を十分に捉えられるようにした．\n3.4.3\n特徴量の抽出\nセグメント化されたデータを基に，機械学習の入力データとして適切な特徴量を抽出す\nる．統計的な特徴量として，3 軸加速度および3 軸角速度の各軸から最大値，最小値，標\n準偏差，平均値，中央値，範囲（最大値-最小値），尖度，歪度の8 種類を算出する．数\n値解析ソフトウェアであるMATLAB[42] を用いて，合計48 個の特徴量を抽出したデータ\nセットを作成した．\n抽出した特徴量の次元が高い場合，機械学習モデルに対して，過学習を引き起こす可能\n性がある．特徴量の数が増えるとモデルの複雑性が増し，学習データへの適合度が過剰に\n高くなり，新しいデータに対する分類精度が低下するリスクが生じる．そこで，本研究で\nは主成分分析（PCA）を用いた次元削減を行い，データの分散を保持しつつ，不要な特徴\n量を削減することで，モデルの汎化性能向上を図る．具体的には，累積寄与率が95%を\n保持しつつ，主成分を選択することで，情報の損失を抑えながら，次元圧縮を行う．\n3.4.4\n機械学習手法によるシュートフォーム評価\n本研究では，シュートフォームを評価するために，回帰モデルと分類モデルを構築し，\n比較検証を実施する．評価項目1「バックスイング」と評価項目2「フォロースルー」に\n34\nついては具体的な角度を推定するため，回帰モデル構築し，評価を行う．本研究では，線\n形回帰（Liner Regression），ランダムフォレスト回帰（Random Forest Regression），サ\nポートベクター回帰（SVR，Support Vector Regression），k 近傍回帰（k-Nearest Neighbors\nRegression, k-NNR）の4 種類を用いて比較検証を実施する．評価項目3「軸足の傾き」，\n評価項目4「上半身の傾き」については，フォームの良し悪しを判定するため，分類モデ\nルを構築することで評価を行う．本研究では，ランダムフォレスト（Random Forest），サ\nポートベクターマシン（SVM，Support Vector Machine），k 近傍法（k-Nearest Neighbors,\nk-NN），ナイーブベイズ（Naive Bayes）の5 種類の分類器を用いて比較検証を実施する．\n35\n第4章\n提案手法の検証実験\n4.1\nデータ収集実験\n本節は，第3 章で提案したシュートフォームの評価手法の検証するために実施したデー\nタ収集実験とその結果について説明する．\n実験担当者は，臨床研究に携わる人のe ラーニングサイト「ICR 臨床研究入門」にて，\n「研究倫理と被験者保護」および「人を対象とする医学系研究に関する倫理指針」を履修\nしている．また，本実験は，青山学院大学理工学部ライフサイエンス委員会の「人に係る\n研究」に関する審査・承認を受け実施され（承認番号H20-S10-2），被験者は実験説明を\n受け，実験に対する同意書による同意をもって，実験に参加頂いている．\n4.1.1\n実験目的\n本実験の目的は，第3 章で提案したシュートフォームの評価手法を検証するためのデー\nタを収集することである．現役のサッカー選手のシュート動作を対象にデータを取得し，\n収集したデータを基に評価精度を検証することで提案手法の有効性を評価する．\n4.1.2\n被験者\n本実験は，青山学院大学男子サッカー部に所属する現役選手18 名を被験者として実施し\nた．被験者は平均身長171.5 ± 11.5 cm，平均体重63.0 ± 12 kg，全員がサッカー歴10 年以\n上の経験を有している．また，被験者の利き足は右利きが15 名，左利きが3 名であった．\n4.1.3\n実験方法\n本実験はサッカー部が日常的に利用している人工芝グラウンドで実施した．計測には3.2\n節で述べた計測システムで動作を計測するとともに，カメラを被験者の後方および被験者\nの利き足側に設置することで，シュート動作全体を撮影する．この撮影データを基に正解\nデータとしてラベリングを実施し，提案手法の精度を検証する．\n被験者にはゴールに対して正面の位置を初期位置として，静止した状態のボールに対し\nてシュート動作を開始してもらった．計測システムの操作は実験担当者が行い，各被験\n者に対して5 回ずつ繰り返して計測した．計測中にセンサとシステムの切断が確認され\nた場合は，追加で計測を実施した．また，被験者には特別な指示を与えず，自然な動作で\nシュートを蹴るように求めた．本研究の実験環境を図4.1 に示す．\n36\n図4.1: 実験の概要図\n4.1.4\nデータ収集実験の結果\n本実験の結果として，途中で通信が切断してしまったものも含めて，合計で102 回の計\n測を実施した．計測データを確認した結果，一部のデータにおいて，図4.2 に示すように\n途切れているデータが確認された．このようなデータは検証に使用できないため除外対象\nとした．各センサで有効と判断されたデータ数を表4.1 に示す．\n胸部および左足に装着したセンサデータは比較的安定した計測が可能であった．一方で，\n右足のセンサデータは通信が途切れやすい傾向が見られた．この要因として，右足が蹴り\n足として大きな動作を伴うため，センサに加わる動作負荷が影響した可能性が考えられ\nる．また，センサデータを受信するスマートフォンの位置が蹴り足とは反対側となること\nが多かったため，通信距離が長くなったことも要因の1 つとなった可能性がある．\n37\n図4.2: 除外対象としたデータ例\n表4.1: 各センサで有効と判断されたデータ数\nセンサ部位\n有効データ数\n左足\n88\n胸部\n93\n右足\n93\n4.2\nラベリング方法\nデータ収集実験で取得したデータのラベル付けには，スポーツ解析を目的とした運動解\n析ソフトウェアのKinovea[43] を用いた．Kinovea は撮影した映像をインポートすること\nで，距離，角度，速度の計測，軌跡を描画する機能など運動の動作解析に特化した機能を\n利用することができる．図4.3 にKinovea の利用画面を示す．本研究では，設定した評価\n項目に関連する足の角度や上半身の傾きに関するラベリングを実施した．ラベリングの項\n目を表4.2 に示す．\n表4.2: ラベリングの項目\nラベリング項目\n取得データ\nバックスイング\n蹴り足の角度\nフォロースルー\n蹴り足の角度\n軸足の傾き\n軸足が前傾しているか/ していないか\n胸の姿勢\n胸部が前傾しているか/ していないか\n38\n図4.3: Kinovea（[43] から引用）\n4.3\n評価精度検証方法\n4.3.1\n姿勢推定手法の検証方法\nIMU センサを用いた姿勢推定手法の精度を検証するため，数値データを用いた誤差の\n評価と分類ラベルの一致率による評価の2 種類の方法を採用する．蹴り足の角度のように\n連続値を持つデータに対しては，推定値とラベリング結果の誤差を平均絶対誤差（MAE）\nおよび平均絶対誤差率（MAPE）を用いて算出し，推定精度を評価する．一方，軸足の傾\nきや上半身の方向のようにカテゴリ分類が必要なデータに対しては，推定値とラベルの一\n致率を指標として評価を行う．バックスイングとフォロースルーの検証では，蹴り足の角\n度に関する数値データを用い，MAE およびMAPE を算出して誤差の大きさを評価する．\nインパクト時の軸足の傾き，上半身の傾き，上半身の方向の検証では，姿勢推定による分\n類結果とラベリング結果を比較し，一致率を求めることで精度を評価する．これらの手法\nを用いて，IMU センサを活用した姿勢推定の妥当性を検証する．\nIMU センサを用いた姿勢推定手法の精度を検証する方法として，回帰的な誤差評価と\n分類的な一致率評価の2 種類で検証する．バックスイングやフォロースルーの蹴り足の角\n度に関しては，推定値とラベリング結果の誤差を平均絶対誤差（MAE）および平均絶対\n誤差率（MAPE）を用いて算出し，回帰的な手法で推定精度を評価する．一方，インパク\nト時の軸足の傾きやフォロースルー時の上半身の傾きについては，姿勢推定による分類結\n果とラベリング結果の一致率を指標とし，分類的な手法で精度を評価する．これらの手法\nを用いて，IMU センサを活用した姿勢推定の妥当性を検証する．\n39\n4.3.2\n機械学習手法の検証方法\n本研究では，3.4 節で紹介した機械学習手法を用いて回帰モデルと分類モデルの両方を\n構築し，動作評価の精度を検証する．回帰モデルの検証は，姿勢推定手法の検証方法と同\n様に平均絶対誤差（MAE）および平均絶対誤差率（MAPE）を用いて算出し，推定精度\nを評価する．一方で分類モデルは，収集実験で得られたデータ数が限られているため，1\n人抜き交差検証（Leave-One-Subject-Out Cross-Validation, LOSO-CV) を適用し，適合率，\n再現率，F1 スコアを算出し，各モデルの性能を比較する．1 人抜き交差検証は，全被験者\nのデータから，1 人分をテストデータとして除外し，残りの被験者データを用いて学習を\n行い，学習後に除外した被験者のデータを用いて，モデルの性能を検証する手法である．\nこのプロセスを被験者の数だけ繰り返し，最終的に全ての被験者に対する各モデルの性能\nを比較する．これにより，個人差の影響を考慮しつつ，異なる被験者に対しても適用可能\nなモデルの精度を評価する．\n40\n第5章\n提案手法の検証結果と考察\n5.1\n姿勢推定による動作評価手法の結果と考察\n5.1.1\n姿勢推定による動作評価手法の結果\n評価項目1「バックスイング」および評価項目2「フォロースルー」の検証結果\nIMU センサを用いた姿勢推定による動作評価手法の精度を検証するため，評価項目1\n「バックスイング」および評価項目2「フォロースルー」は推定結果とラベリング結果の\n平均絶対誤差（MAE）および平均絶対誤差率（MAPE）を指標として検証した．検証結\n果を表5.1 に示す．\n表5.1: 評価項目1「バックスイング」および評価項目2「フォロースルー」に関する姿勢\n推定による評価精度\n評価項目\nMAE（°）\nMAPE（%）\n十分なバックスイング\n17.5\n14.0\nフォロースルーの前方への動き\n13.5\n25.2\nMAE は，推定値と正解値の絶対誤差の平均を示し，数値が小さいほど推定値が実際の\n値に近いことを意味する．一方，MAPE は誤差を正解値に対する割合で示し，相対的な誤\n差の大きさを評価する指標である．バックスイングの結果はMAE=17.5°，MAPE=14.0%，\nフォロースルーの結果はMAE=13.5 °，MAPE=25.2%であった．これにより，バックスイ\nングよりもフォロースルーの方が推定誤差は小さいものの，相対誤差（MAPE）は大きく，\n動作ごとのばらつきの影響を受けている可能性が示唆された．精度の観点では，バックス\nイングは一定の精度を保っているが，フォロースルーでは個人差や姿勢推定の誤差が相対\n的に大きくなる傾向が見られた．\n評価項目3「軸足の傾き」および評価項目4「上半身の傾き」の検証結果\n評価項目3「軸足の傾き」および評価項目4「上半身の傾き」は推定結果とラベリング\n結果の一致率を指標として検証した．検証結果を表5.2 に示す．\n表5.2: 軸足の傾きおよび上半身の評価精度\n評価項目\n一致率（%）\nインパクト時の軸足の傾き\n67.0\nフォロースルー時の上半身の傾き\n44.0\n41\n5.1.2\n姿勢推定による動作評価手法の考察\nバックスイングとフォロースルーの回帰的な評価には，IMU センサによる姿勢推定の結\n果をそのまま利用しているため，正確な評価には一定以上の姿勢推定精度が求められる．\nしかし，バックスイングやフォロースルーのように大きな角度変化を伴う動作では，IMU\nセンサの特性上，姿勢推定時の積分計算による累積誤差の影響を受けやすい．特に，バッ\nクスイングのMAPE が14%と比較的低い値で収まっているのに対し，フォロースルーは\n20%以上と高い誤差を示しており，フォロースルーの方が動作として激しく，姿勢推定誤\n差が大きくなっている可能性が考えられる．また，シュート動作の流れとしてフォロース\nルーはバックスイングよりも後の動作であり，順番的に累積誤差が蓄積されることで，誤\n差がより大きくなった可能性もある．この課題に対処する方法としては，現在用いている\n相補フィルタ以外のセンサフュージョン技術を導入し，姿勢推定アルゴリズムを改良する\nことで累積誤差を低減することが考えられる．また，より多くのデータを収集し，実際の\n値との誤差を統計的に分析することで，誤差の傾向を明らかにし，それを考慮した補正を\n加えることで評価システムとしての実用性を向上させることが可能である．\n軸足の傾きや上半身の傾きの分類的な評価においては，いずれも高い精度を達成するこ\nとはできなかった．精度が低下した要因としては，先述のバックスイングとフォロース\nルーと同様にIMU センサの姿勢推定の精度自体が十分でないため，評価方法として0 °以\n上を「良」，0 °未満を「悪」のように単純な閾値設定をした場合，誤った判定結果になっ\nてしまう可能性が考えられる．この課題に対する対処法として，姿勢推定の誤差を考慮し\nた閾値の設定を行うことが必要である．誤差がマイナス方向に生じてしまう場合は，閾値\nを低めに設定するなど，姿勢推定の誤差の傾向を考慮した閾値設定を導入することで，よ\nり安定した評価が可能になると考えられる．\n5.2\n機械学習による動作評価手法の結果と考察\n5.2.1\n機械学習による動作評価手法の結果\n評価項目1：バックスイング\n表5.3 に評価項目1「バックスイング」の回帰モデルによる推定結果を示す．最も精度\nが高かったのはランダムフォレスト（MAE = 8.6 °, MAPE = 6.8%）であり，最も精度が\n低かったのは線形回帰（MAE = 11.1 °, MAPE = 9.1%）であった．\n表5.3: 評価項目1「バックスイング」の評価精度結果\nModel\nMAE（°）\nMAPE（%）\nLinear Regression\n11.1\n9.1\nRandom Forest\n8.6\n6.8\nSVR\n9.0\n7.0\nk-NN\n8.8\n7.0\n42\n評価項目3：フォロースルー\n表5.4 に「フォロースルーの前方への動き」の回帰モデルによる推定結果を示す．最も\n精度が高かったのはランダムフォレスト（MAE = 5.9 °, MAPE = 11.7%）であり，最も精\n度が低かったのは線形回帰（MAE = 8.2 °, MAPE = 17.4%）であった．\n表5.4: 評価項目3「フォロースルー」の評価精度結果\nModel\nMAE（°）\nMAPE（%）\nLinear Regression\n8.3\n17.4\nRandom Forest\n5.9\n11.7\nSVR\n6.3\n12.4\nk-NN\n6.7\n13.1\n評価項目2：軸足の傾き\n表5.5 に「軸足の傾き」の機械学習による評価精度の結果を示す．ナイーブベイズが適\n合率81.1%，再現率81.3%，F1 スコア81.1%という最も高い精度を達成した．その他のモ\nデルも比較的高い評価精度を示したが，サポートベクターマシンはF1 スコア71.1%と他\nの手法に比べてやや低い結果となった．\n表5.5: 評価項目2「インパクト時の軸足の傾き」の評価精度結果\nModel\nPrecision[%]\nRecall[%]\nF1 score[%]\nRandom Forest\n76.7\n78.9\n76.7\nSupport Vector Machine\n71.1\n81.8\n71.1\nk-Nearest Neighbor\n72.2\n79.5\n72.2\nNaive Bayes\n81.1\n81.3\n81.1\n評価項目4：上半身の傾き\n表5.6 に「上半身の傾き」の機械学習による評価精度の結果を示す．k 近傍法（k-Nearest\nNeighbor, k-NN）が適合率87.4%，再現率73.6%，F1 スコア77.4%という最も高い精度を\n達成した．その他のモデルも比較的高い評価精度を示したが，ナイーブベイズはF1 スコ\nア69.6% と他の手法に比べてやや低い結果となった．\n表5.6: 評価項目4「上半身の傾き」の評価精度結果\nModel\nPrecision[%]\nRecall[%]\nF1 score[%]\nRandom Forest\n83.7\n71.7\n73.3\nSupport Vector Machine\n84.1\n71.4\n74.3\nk-Nearest Neighbor\n87.4\n73.6\n77.4\nNaive Bayes\n81.5\n65.0\n69.6\n43\n5.2.2\n機械学習による動作評価手法の考察\nバックスイングおよびフォロースルーの評価精度は，どちらもランダムフォレストが\n最も精度が高く，線形回帰が最も低い精度となった．この結果は，バックスイングとフォ\nロースルーの動作が単純な線形関係で表現できないことを示している．これらの動作は複\n数の関節が連動して行われるため，線形回帰のような単純なモデルでは適切に学習するこ\nとが難しいと考えられる．一方で，ランダムフォレストのような非線形な関係を捉えられ\nるモデルは特徴量間の相互作用を考慮できるため，高い精度を示したと考えられる．\n軸足の傾きの評価精度はナイーブベイズが最も精度が高かった．ナイーブベイスの混同\n行列を図5.1 に示す．\n「軸足の傾きが適切である」と分類すべきデータ（クラス0）につい\nて，69 件中66 件を正しく分類しており，高い識別精度を持つことがわかる．しかし，\n「軸\n足の傾きが適切でない」とすべきデータ（クラス1）については，16 件中14 件が誤分類さ\nれ，適切である（クラス0）と判定されてしまった．この誤分類の要因として，学習デー\nタの中でクラス1 のサンプル数が少なく，モデルがクラス0 に偏った学習をしてしまった．\n可能性が考えられる．その結果，適切でない軸足の傾きを正しき識別する精度が低下した\nと考えられる．\n図5.1: 「軸足の傾き」に対するナイーブベイズによる混同行列\n上半身の評価精度はk 近傍法が最も精度が高かった．k 近傍法の混同行列を図5.2 に示\nす．結果を確認すると，k 近傍法はクラス0（適切な上半身の傾き）について，66 件中57\n件を正しく判定している．しかし，クラス1（不適切な上半身の傾き）の識別精度は低く，\n44\n27 件のうち16 件が誤分類されており，誤判定が多数を占める結果となった．これは，ク\nラス1 のサンプル数が少なく，データサンプルに偏りがあるため，モデルがクラス0 に\n偏った学習が考えられる．\n図5.2: 「上半身の傾き」に対するk 近傍法の混同行列\n45\n第6章\n結論と今後の展望\n6.1\n結論\n本研究では，IMU センサを用いたサッカーのシュートフォーム自動評価手法を提案し，\n姿勢推定手法と機械学習手法を比較・検証した．姿勢推定手法はシュート動作の主要フェー\nズを正確に識別し，フォームの特徴を解析することに有用である一方で，一部の姿勢推定\nに誤差が生じた．一方，機械学習手法は時系列データから適切な特徴量を抽出し，フォー\nムの良否を高精度で識別できることが確認された．これらの結果から，機械学習手法が評\n価精度の面で優れていること，姿勢推定手法が動作の分節や詳細なフォーム解析に有効で\nあることが示された．\nまた，本研究では現役のサッカー選手を対象にデータ収集を行ったが，対象者の範囲が\n限定されていたため，モデルの汎用性向上のためにはさらなるデータ収集が必要である．\nさらに，姿勢推定手法の評価精度を向上させるためには，アルゴリズムの改良やセンサの\n装着位置の最適化が求められる．\n6.2\n今後の展望\n本研究で提案したシュートフォーム評価手法をより実用的なシステムへと発展させるた\nめには，いくつかの課題を解決する必要がある．まず，データ収集の多様化が挙げられる．\n本研究では主に現役選手を対象にデータを取得したが，より多様な選手の動作データを収\n集することで，モデルの一般化能力を向上させることが可能となる．特に，初心者やプロ\n選手を含めたデータを取得することで，技術レベルごとのフォームの違いをより詳細に分\n析できる．また，試合環境下でのデータ収集を行うことで，より実践的なフォーム評価の\n精度を検証し，実際のプレーシーンでの適用可能性を高めることが重要である．\n次に，姿勢推定手法の精度向上が求められる．本研究では，IMU センサを用いた姿勢\n推定において，相補フィルタを適用することで動作の認識を行ったが，一部の姿勢推定に\n誤差が生じる課題があった．今後は，姿勢推定アルゴリズムの改良を行い，IMU データ\nからの角度推定精度を向上させるとともに，センサの装着位置の最適化を進めることで，\n測定誤差を低減する必要がある．例えば，異なる身体部位にセンサを装着することで，よ\nり正確な姿勢情報を取得し，動作解析の精度を向上させることが考えられる．\nさらに，機械学習手法の高度化も今後の重要な課題となる．本研究では，時系列デー\nタから特徴量を抽出し，フォーム評価モデルを構築したが，より精度の高い識別を実現\nするためには，追加の動作特徴を抽出し，学習モデルの最適化を行う必要がある．特に，\nLSTM やTransformer などの深層学習モデルを導入することで，時系列データの複雑なパ\nターンを捉え，より高精度なフォーム識別が可能となると考えられる．また，従来の閾値\n判定手法と組み合わせることで，定量的な評価と機械学習による柔軟な識別を両立させる\n46\nことも有効である．\n本研究の成果を実際のトレーニング環境で活用するためには，リアルタイムフィード\nバックシステムの開発も重要である．選手が自身のフォームを即座に確認し，修正できる\nシステムを構築することで，より効果的な技能向上が可能となる．例えば，スマートフォ\nンやタブレットを用いたアプリケーションを開発し，選手にリアルタイムでフォームの\nフィードバックを提供する仕組みを導入することが考えられる．さらに，音声や振動を用\nいた直感的なフィードバック機能を追加することで，選手が瞬時にフォームの改善点を認\n識し，修正できるようになる．\n加えて，本研究で提案したフォーム評価手法をサッカーの他の動作にも応用することが\n期待される．シュート動作だけでなく，ドリブルやパス，ヘディングといった動作にも適\n用することで，総合的なスキル向上支援システムの構築が可能となる．また，コーチング\n支援機能を強化し，選手ごとの課題点や改善方法を具体的に提示できるシステムを開発す\nることで，指導者の負担軽減やトレーニングの効率化にも寄与することができる．\n本研究の成果をもとに，今後はIMU センサを活用したフォーム評価技術の発展を促進\nし，サッカー選手の技術向上を支援する実用的なシステムの構築を目指す．\n47\n謝辞\n本研究はJSPS 科研費JP22K11998 の助成を受け, 実施されました．\n本研究を遂行するにあたり，青山学院大学理工学部情報テクノロジー学科ロペズ・ギヨー\nム教授に深く感謝申し上げます．先生のもとで研究に取り組むことができたからこそ，最\n後までやり遂げることができたと感じています．約4 年間に渡り，研究についてご助言い\nただき，また多くの学びの機会を与えてくださったことに，改めて御礼申し上げます．研\n究補助員の大熊ちひろ様には，研究室の環境整備やTA などの事務手続きにおいて，多大\nなサポートをしていただきました．研究に専念できる寛容を整えてくださったことに，深\nく感謝いたします．本研究の実験にご協力いただいた青山学院大学サッカー部の選手の皆\n様，監督，コーチの皆様にも厚く御礼申し上げます．お忙しい中，実験のための環境をご\n提供いただき，貴重なデータ収集にご協力いただいたことに，心より感謝申し上げます．\n最後に，これまで支えてくれた家族に，心から感謝いたします．常に温かく見守り，励\nましてくれたおかげで，ここまで研究を続けることができました．\n2025 年1 月31 日\n平井龍彦\n48\n参考文献\n[1] WorldAtlas. The most popular sports in the world. https://www.worldatlas.\ncom/articles/what-are-the-most-popular-sports-in-the-world.\nhtml. (参照日2024/7/29).\n[2] 公益財団法人日本サッカー協会(JFA). 日本サッカー協会選手登録数. https://\nwww.jfa.jp/about_jfa/organization/databox/player.html. (参照日\n2024/8/1).\n[3] 公益財団法人日本サッカー協会(JFA). 日本サッカー協会指導者登録数. https:\n//www.jfa.jp/about_jfa/organization/databox/coach.html.\n(参照\n日2024/8/1).\n[4] 公益財団法人日本サッカー協会(JFA).\n指導者養成講習会.\nhttps://jfa.jp/\ncoach/official/license.html. (参照日2024/8/1).\n[5] イングランドサッカー協会（TheFA）.\nRatios\nof\nadults\nto\nchil-\ndren.\nhttps://www.thefa.com/-/media/thefacom-new/files/\nrules-and-regulations/safeguarding/section-5/26072024/\n55-ratios-of-adults-to-children.pdf. (参照日2024/8/1).\n[6] INSIDE\nFIFA.\nGoal-line\ntechnology.\nhttps://\ninside.fifa.com/technical/football-technology/\nfootball-technologies-and-innovations-at-the-fifa-world-cup-2022/\ngoal-line-technology. (参照日2024/8/1).\n[7] SAP. Sports team management software—sap sports one. https://www.sap.com/\nproducts/technology-platform/sports-one.html. (参照日2024/8/1).\n[8] Catapult.\nCatapult vector pro.\nhttps://www.catapult.com/solutions/\nvector-pro. (参照日2024/8/1).\n[9] Playermaker.\nPlayermaker 2.0.\nhttps://www.playermaker.com/product/\nplayermaker/. (参照日2024/8/1).\n[10] 青柳光璃, ギヨーム・ロペズ, 横窪安奈. Footbsense: 慣性計測装置を用いた自然環境下\nにおけるサッカー動作の識別. 情報処理学会シンポジウムシリーズ(IPSJ Symposium\nSeries (CD-ROM)), 第2022 巻, pp. ROMBUNNO.8C–3. 情報処理学会, 7 2022.\n[11] Dominik Schuldhaus, Constantin Zwick, Harald K¨orger, Eva Dorschky, Robert Kirk, and\nBjoern M. Eskoﬁer. Inertial sensor-based approach for shot/pass classiﬁcation during a\nsoccer match. KDD Workshop on Large-Scale Sports Analytics, pp. 1–6, 2015.\n49\n[12] 伊藤大晃, 後藤佑介. マルチセンサを用いたサッカー選手の動作分析システムの提案. 情\n報処理学会研究報告, Vol. Vol.2016-DPS-167 No.9, Vol.2016-MBL-79 No.9, Vol.2016-\nITS-65 No.9, , 2016.\n[13] Maike Stoeve, Dominik Schuldhaus, Axel Gamp, Constantin Zwick, and Bjoern M. Es-\nkoﬁer. From the laboratory to the ﬁeld: Imu-based shot and pass detection in football\ntraining and game scenarios using deep learning. Sensors, Vol. 21, No. 9, p. 3071, 2021.\n[14] Karin Mascher, Stefan Laller, and Manfred Wieser. Development of smart shin guards for\nsoccer performance analysis based on mems accelerometers, machine learning, and gnss.\nCEUR Workshop Proceedings, Vol. ICL-GNSS 2021 WiP Proceedings, , 2021.\n[15] Omar Alobaid and Lakshmish Ramaswamy. A feature-based approach for identifying\nsoccer moves using an accelerometer sensor. In Proceedings of the 13th International\nJoint Conference on Biomedical Engineering Systems and Technologies (BIOSTEC 2020)\n- Volume 5: HEALTHINF, pp. 34–44, Valletta, Malta, 2020. SCITEPRESS – Science and\nTechnology Publications, Lda.\n[16] H M Sajjad Hossain, Md Abdullah Al Haﬁz Khan, and Nirmalya Roy. Soccermate: A\npersonal soccer attribute proﬁler using wearables. In Proceedings of the First IEEE In-\nternational Workshop on Behavioral Implications of Contextual Analytics (PerCom Work-\nshops), pp. 1–6, Kona, Hawaii, USA, 2017. IEEE.\n[17] 今井友揮, 内山彰, 馬込卓弥, 東野輝夫. サッカートラッキングデータを用いた機械\n学習に基づくプレー認識手法の提案. 情報処理学会研究報告, Vol. Vol.2018-MBL-86\nNo.47, Vol.2018-UBI-57 No.47, , 2 2018.\n[18] 紅林佑亮, 清水剛士, 長谷川明生. Arduinoおよびセンサーを用いたスポーツ動作解析シ\nステムの試作. 情報処理学会研究報告(IPSJ SIG Technical Report), 第Vol.2016-IOT-34\n巻, pp. 1–6. 情報処理学会, 6 2016.\n[19] 真鍋晃大, 石井直方, 福崎千穂. 慣性センサを用いたサッカー動作の解析と評価.\n[20] Katarzyna Piechota and Edyta Majorczyk. Decision-making time and neuromuscular co-\nordination in youth and senior soccer goalkeepers. Sensors, Vol. 23, , 2023.\n[21] Gwyneth B. Ross, Brittany Dowling, Nikolaus F. Troje, Steven L. Fischer, and Ryan B.\nGraham.\nClassifying elite from novice athletes using simulated wearable sensor data.\nFrontiers in Bioengineering and Biotechnology, 2020.\n[22] 中村康雄, 齊藤稔, 林豊彦, 江原義弘. 熟練者・未熟練者におけるインステップキック\n動作解析. バイオメカニズム, Vol. 20, pp. 53–64, 2010.\n[23] 辻元典央, 内藤景, 川崎廉, 絹巻悟. サッカー未経験者におけるインステップキック動\n作の特徴. 福井工業大学研究紀要, Vol. 50, , 2020.\n[24] 金子和輝, 中村拓真, 矢入郁子, 平田均. Openpose を用いたサッカー熟練度の分類. 人\n工知能学会第34 回全国大会論文集, 2020.\n50\n[25] 正木直樹, 三村瑠郁, 小泉信郎, 鈴木元樹, 塩谷浩之. サッカーのパス・トラップ動作に\nおける姿勢解析のためのモーションキャプチャを用いた動作特徴量の抽出に関する\n検討. 情報処理学会第85 回全国大会, 2023.\n[26] Chun Yu, Ting-Yuan Huang, and Hsi-Pin Ma. Motion analysis of football kick based on\nan imu sensor. Sensors, 2022.\n[27] Erik Wilmes, Cornelis J. de Ruiter, Bram J.C. Bastiaansen, Jasper F.J.A. van Zon,\nRiemer J.K. Vegter, Michel S. Brink, Edwin A. Goedhart, Koen A.P.M. Lemmink, and\nGeert J.P. Savelsbergh. Inertial sensor-based motion tracking in football with movement\nintensity quantiﬁcation. Sensors, Vol. 20, No. 9, p. 2527, 2020.\n[28] Khaled Takizadeh, Fazlollah Bagherzadeh, Mahmoud Sheikh, Davood Hoomenian Sharif\nAbadi, and Hadi Veisi. The application of artiﬁcial neural network and wearable inertial\nsensor in kicking skill assessment. Journal of Advanced Sport Technology, Vol. 8, No. 1,\npp. 34–45, 2023.\n[29] Ante Raa, Goran Kuvaˇci´c, Andrea De Giorgio, Maha Sellami, Luca Paolo Ardig`o,\nNicola Luigi Bragazzi, and Johnny Padulo.\nThe ball kicking speed: A new, efﬁcient\nperformance indicator in youth soccer. PLOS ONE, Vol. 14, No. 5, p. e0217101, 2019.\n[30] 安達凱永, 雪竹翼, 中原匡哉. 深層学習を活用したサッカーにおける個人練習の支援技\n術の開発. 情報処理学会全国大会講演論文集, Vol. 85, pp. 373–374, 2023.\n[31] Joshua Marris, Steve Barrett, Grant Abt, and Chris Towlson. Quantifying technical ac-\ntions in professional soccer using foot-mounted inertial measurement units. Science and\nMedicine in Football, 2021.\n[32] Mohammed Ikram, Mohammad Dahman Alshehri, and Farookh Khadeer Hussain. Archi-\ntecture of an iot-based system for football supervision (iot football). Conference Paper,\n2015.\n[33] H˚akon Kvale Stensland, Vamsidhar Reddy Gaddam, Marius Tennøe, Espen Helgedagsrud,\nMikkel Næss, Henrik Kjus Alstad, Asgeir Mortensen, Ragnar Langseth, Sigurd Ljødal,\nØystein Landsverk, Carsten Griwodz, and P˚al Halvorsen. Bagadus: An integrated real-\ntime system for soccer analytics. ACM Transactions on Multimedia Computing, Commu-\nnications, and Applications, Vol. 10, No. 1s, p. Article 14 (21 pages), 2014.\n[34] 公益財団法人日本サッカー協会(JFA). JFA キッズ（U-8/U-10）ハンドブック. 公益\n財団法人日本サッカー協会(JFA), 3 2012. JFA キッズプログラム.\n[35] G¨unal Bilek and Bet¨ul Ayg¨un. Factors associated with match result and number of goals\nscored and conceded in the english premier league.\nBitlis Eren University Journal of\nScience, Vol. 11, No. 1, pp. 227–236, 2022.\n[36] Diego Brito Souza, Roberto L´opez-Del Campo, Hugo Blanco-Pita, Ricardo Resta, and\nJuan Del Coso. A new paradigm to understand success in professional football: analysis\n51\nof match statistics in laliga for 8 complete seasons. International Journal of Performance\nAnalysis in Sport, Vol. 19, No. 4, pp. 123–135.\n[37] A. Lees, T. Asai, T. B. Andersen, H. Nunome, and T. Sterzing. The biomechanics of\nkicking in soccer: A review. Journal of Sports Sciences, Vol. 28, No. 8, pp. 805–817,\n2010.\n[38] 田所剛之. 東大卒キックコーチが教える本当に正しいキックの蹴り方: 思い通りの\nシュートやパスを蹴られる選手になる! 日本文芸社, 東京, 4 2023. 物理学に基づく\nキック理論を解説した実践書.\n[39] Suunto. Movesense. https://movesense.com/.\n[40] Apple.\niphone15.\nhttps://www.apple.com/jp/shop/buy-iphone/\niphone-15.\n[41] google. ﬂutter. https://flutter.dev/.\n[42] MathWorks.\nMatlab.\nhttps://www.mathworks.com/products/matlab.\nhtml.\n[43] Kinovea. Kinovea - video analysis software for sports. https://www.kinovea.\norg/.\n52\n質疑応答\n大原　剛三　情報テクノロジー学科　教授\nQ\n機械学習の分類精度の指標として，なぜAccuracy で評価をしたのか？評価する上\nではPrecision も重要だと思います．\nA\nご質問ありがとうございます．姿勢推定の評価精度の指標はAccuracy のみを算出\nしていたため，機械学習による評価精度に関しては他の指標は省略し，accuracy を\n掲載しました．本論文には他の評価指標の結果も掲載しております．\n浦垣　啓志郎　情報テクノロジー学科　助手\nQ\nセンサを使った姿勢推定はいくつかあると思いますが，サッカーにおける姿勢推\n定の難しさは？\nA\nご質問ありがとうございます．サッカーの動作は曲線的で急加速・急減速が多く，\nセンサのノイズが大きくなりやすいという課題があります．また，長時間の利用で\nは静止状態の姿勢推定を用いて定期的に補正するのが理想ですが，サッカーではそ\nの機会が少なく，補正が難しいと考えられます．今回は接触プレーを考慮していま\nせんが，試合や対人練習を想定した場合，より激しい動きによってノイズが増加す\nるため，安定した推定が難しくなる可能性があります．\nQ\nサッカーにおける姿勢推定の難しさに対する対処は？また，難しい結果になったこ\nとに対する考察は？\nA\n本研究では，ノイズ除去やセンサキャリブレーションを行い，精度の高い姿勢推定\nを目指しました．その結果，姿勢推定のグラフ形状は理想的でしたが，姿勢推定の\n具体的な値に関しては低い傾向がありました．ノイズを除去し切ることができてい\nない可能性や補正の限界による影響と考えられます．今後は，さらなる補正手法の\n改良や異なるセンサフュージョン手法による精度向上を検討する必要があります．\nQ\nIMU をサッカー選手につけると運動の邪魔になる欠点があると思います．非侵襲的\n案Vision-based なフォーム推定と提案手法とを比べた利点/欠点をもう少し強調した\n方が良いような気がしました．\nA\nカメラベースは選手の動作を妨げずに高精度な動作解析が可能ですが，設置や環境\nの制約が多く，コストも高くなるという欠点があります．一方，センサベースは安価\nで持ち運びが容易であり，環境への依存性が少なく利用できるという利点が考えら\nれます．カメラベースとセンサベースには対照的な特徴がそれぞれありますが，ア\nマチュア向けのシステム開発を目指す上で，センサベースの手法を選択しました．\n53\n",
        "chunks": [
            "M2024_Tatsuhiko_Hirai. M2024_Tatsuhiko_Hirai. M2024_Tatsuhiko_Hirai",
            " \n \n \n \n \n \n \n \n青 \n山 \n学 \n院 \n大 \n学 \n理 \n工 \n学 \n研 \n究 \n科 \n \n \n \n \n理工学専攻 \n知能情報 \nコース \n \n \n \n修 \n士 \n論 \n文 \n \n \n学 生 番 号 \n  35623242 \n \n \n \n氏 \n名 \n平井 龍彦  \n \n \n \n研究指導教員 \nロペズ・ギヨーム 教授 \n \nAcademic Year of 2024, Submitted on January 31, 2025 \n \nGraduate School of Science and Engineering, Aoyama Gakuin University \n \nTitle: IMU-Based Automatic Evaluation Method for Soccer Shooting Form \n \nStudent Name: Tatsuhiko Hirai \nID Number: 35623242 \nDegree: Master of Engineering \nCourse: Intelligence and Information \nThesis A",
            "ng \nCourse: Intelligence and Information \nThesis Advisor: Professor Guillaume Lopez \nAbstract  \nWith advancements in information technology, the application of technology in soccer \nhas progressed, leading to the development of various support systems. However, most \nof these systems focus on performance analysis rather than providing detailed \nassistance for skill improvement, such as shoot form enhancement. \nThis study aims to develop a skill improvement support system that players can use \nin",
            "mprovement support system that players can use \nindependently using an affordable Inertial Measurement Unit (IMU) sensor. Specifically, \nit compares and evaluates two methods for automatically assessing soccer shooting \nform: motion recognition and evaluation using sensor-based posture estimation and \nform evaluation using machine learning. \nIMU sensors are attached to both ankles and the chest in the proposed method to \ncollect acceleration and angular velocity data. The posture estimation appr",
            "angular velocity data. The posture estimation approach applies \na complementary filter to estimate the sensor’s orientation. The player's posture is \ncalculated from the sensor's posture estimation results. Meanwhile, the machine \nlearning approach detects and segments shooting motions from time-series data and \nextracts features to construct a classification model. The evaluation accuracy of both \nmethods is compared across four assessment criteria. \nThe results show that the machine learning a",
            "ria. \nThe results show that the machine learning approach accurately distinguishes good \nand poor shooting forms, while the posture estimation method effectively recognizes key \nshooting phases and analyzes form characteristics. However, some errors were observed \nin posture estimation. Overall, the machine learning method demonstrates superior \naccuracy, while the posture estimation approach proves helpful for motion segmentation \nand analysis. \nFuture work should focus on expanding data collec",
            "\nFuture work should focus on expanding data collection to include a more diverse range \nof players to improve model generalization. Although the posture estimation method \nhad lower evaluation accuracy, its effectiveness in motion segmentation and analysis \nwas demonstrated. Improving its precision through algorithm refinement and \noptimizing sensor placement could enhance its applicability for form evaluation. \n理工学専攻修士論文要旨 \n \n \n提出年度： 2024 年度 \n提出日： 2025 年1 月31 日 \n専修コース： 知能情報 コース \n学生番号： 35623242 ",
            "日： 2025 年1 月31 日 \n専修コース： 知能情報 コース \n学生番号： 35623242 \n学生氏名： 平井 龍彦 \n研究指導教員： ロペズ・ギヨーム 教授 \n \n（論文題目） \n \n慣性計測装置を用いたサッカーにおけるシュートフォーム自動評価手法 \n \n（内容の要旨） \n近年のIT 技術の進化により，サッカーにおける技術活用が進んでいる．プロサッカーでは，選手の \nパフォーマンス分析が重視され，カメラベースのシステムによる戦術解析やウェアラブルセンサによ \nる選手のパフォーマンス分析やコンディション管理に利用されている．アマチュア向けのサポートシ \nステムも登場し，手軽にフィジカルデータの取得が可能となった．しかし，これらは主にパフォーマン\nス分析が中心であり，キックフォームの改善など細かいスキル向上を支援する機能は限られている．こ\nのため，より詳細な技能向上を目的としたシステムの開発が求められている． \n本研究では，安価な小型慣性計測装置（IMU）を用いて，選手自身で利用可能な技能向上支援システ\nムの開発を目的としている．具体的に，サッカーのシュートフォームを自動評価する",
            "能な技能向上支援システ\nムの開発を目的としている．具体的に，サッカーのシュートフォームを自動評価する手法として，IMU \nのデータから姿勢を推定し，シュート動作の認識及び評価の精度を検証する．さらに，比較検証として，\n先行研究でサッカー動作の識別や熟練度の判定に活用されていた機械学習を用い，シュートフォームの\n良否判定の精度を検証する．これにより，姿勢推定と機械学習の両手法の有効性を評価し，より適切な\nフォーム評価手法を明らかにすることを目標とした． \n提案手法では，IMU センサを選手の両足首および胸部に装着し，加速度・角速度データを取得する． \n姿勢推定手法では，取得したデータに対して適切な前処理を施した上で，相補フィルタを用いてセンサ\nの姿勢を推定する．その後，推定した姿勢情報を基に，シュートの主要なポイントであるアプローチ，\nバックスイング，インパクト，フォロースルーの動作を認識し，選手のフォームを推定する．機械学習\n手法では，IMU センサの時系列データからシュート動作の自動検出およびセグメントを行い，加速度・\n角速度の6 軸の統計データを抽出する．これらの特徴量を用いて機械",
            "出およびセグメントを行い，加速度・\n角速度の6 軸の統計データを抽出する．これらの特徴量を用いて機械学習モデルを構築し，シュートフ\nォームの良否を識別する．本研究で扱うフォームの評価項目には，バックスイング時の蹴り足の角度，\nフォロースルー時の蹴り足の角度，軸足の傾き，上半身の傾きの4 つの項目を設定し，それぞれの手法\nの評価精度を比較する．バックスイング時の蹴り足の角度，フォロースルー時の蹴り足の角度は，角度\nの推定値としてそれぞれ算出し，ラベリング結果との平均絶対誤差（MAE）および平均絶対誤差率\n（MAPE）を算出する．そのほかの評価項目は推定結果とラベリング結果の一致率を算出し，評価精度\nを検証した． \n結果として，姿勢推定手法と機械学習手法による評価精度を比較したところ，機械学習手法がより高\n精度にフォームの良否を識別できることが確認された．時系列データから特徴を抽出し，適切な分類モ\nデルを用いることで，フォームの良否を高い精度で判定できた．姿勢推定手法では，相補フィルタを用\nいた姿勢推定により，シュートの主要なポイントを認識し，フォームの特徴を解析したが，一部の姿勢\n推定に",
            "いた姿勢推定により，シュートの主要なポイントを認識し，フォームの特徴を解析したが，一部の姿勢\n推定に誤差が見られた．総合的に，機械学習手法は精度面で優れており，姿勢推定手法は動作の分割と\n解析に有用であることが明らかになった． \n本研究では，現役の選手を対象にデータの収集実験を行ったため，フォームの良し悪しに偏りが生じ\nる可能性があった．今後は，より多様な選手を対象にデータを収集し，モデルの汎用性を向上させる必\n要がある．また，姿勢推定手法は評価精度としては低かったものの，動作の分割と解析に有用であるこ\nとが示された．精度の向上により，フォーム評価にも有効な手法となる可能性があるため，アルゴリズ\nムの改良やセンサ配置の最適化を進めることが求められる． \n \n \n青山学院大学大学院理工学研究科 \n慣性計測装置を用いたサッカーにおける\nシュートフォーム自動評価手法\n平井龍彦\n2025/1/31\n目次\n第1 章\n序章\n3\n1.1\n現代サッカーにおける研究背景. . . . . . . . . . . . . . . . . . . . . . . .\n3\n1.1.1\nサッカーの競技者数と指導",
            ". . . . . . . . . . . . . . .\n3\n1.1.1\nサッカーの競技者数と指導者の関係\n. . . . . . . . . . . . . . . . .\n3\n1.1.2\nサッカーのIT 技術の活用\n. . . . . . . . . . . . . . . . . . . . . . .\n5\n1.1.3\nウェアラブルサッカーサポート製品\n. . . . . . . . . . . . . . . . .\n6\n1.2\n研究目的と目標. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n7\n1.3\n本論文の構成. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n8\n第2 章\n関連研究\n9\n2.1\n複数のサッカー動作を識別した研究. . . . . . . . . . . . . . . . . . . . . .\n9\n2.2\n熟練者と未熟練者の違いを解析および識別した研究. . . . . . . . . ",
            " .\n9\n2.2\n熟練者と未熟練者の違いを解析および識別した研究. . . . . . . . . . . . .\n12\n2.3\nサッカー動作の評価に関する研究. . . . . . . . . . . . . . . . . . . . . . .\n14\n2.4\n選手・コーチへのサポートシステムを開発した研究. . . . . . . . . . . . .\n16\n2.5\n先行研究で残された課題と本研究の優位性. . . . . . . . . . . . . . . . . .\n18\n第3 章\nサッカースキルの向上支援の提案手法\n20\n3.1\nサッカースキル向上支援の概要. . . . . . . . . . . . . . . . . . . . . . . .\n20\n3.1.1\n本研究で扱うサッカー動作\n. . . . . . . . . . . . . . . . . . . . . .\n20\n3.1.2\n正しいキックフォームの定義\n. . . . . . . . . . . . . . . . . . . . .\n21\n3.1.3\n本研究で扱う評価項目. . . . . .",
            ". . . . . . . . . .\n21\n3.1.3\n本研究で扱う評価項目. . . . . . . . . . . . . . . . . . . . . . . . .\n22\n3.2\n計測システムの開発\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n23\n3.2.1\n計測システムの開発\n. . . . . . . . . . . . . . . . . . . . . . . . . .\n23\n3.2.2\nセンサの装着位置\n. . . . . . . . . . . . . . . . . . . . . . . . . . .\n24\n3.3\n姿勢推定による動作評価手法\n. . . . . . . . . . . . . . . . . . . . . . . . .\n24\n3.3.1\n姿勢推定による動作評価手法の概要\n. . . . . . . . . . . . . . . . .\n24\n3.3.2\nセンサの姿勢推定処理. . . . . . . . . . . . . . . . . . . . .",
            "ンサの姿勢推定処理. . . . . . . . . . . . . . . . . . . . . . . . .\n25\n3.3.3\nシュート動作の主要ポイントの認識\n. . . . . . . . . . . . . . . . .\n29\n3.3.4\n姿勢推定手法によるシュートフォーム評価. . . . . . . . . . . . . .\n31\n3.4\n機械学習による動作評価手法\n. . . . . . . . . . . . . . . . . . . . . . . . .\n32\n3.4.1\n機械学習による動作評価手法の概要\n. . . . . . . . . . . . . . . . .\n32\n3.4.2\nセグメンテーション手法. . . . . . . . . . . . . . . . . . . . . . . .\n33\n3.4.3\n特徴量の抽出. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n34\n3.4.4\n機械学習手法によるシュートフォーム評価. . . . . . . . . . . .",
            "4\n3.4.4\n機械学習手法によるシュートフォーム評価. . . . . . . . . . . . . .\n34\n1\n第4 章\n提案手法の検証実験\n36\n4.1\nデータ収集実験. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n36\n4.1.1\n実験目的\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n36\n4.1.2\n被験者. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n36\n4.1.3\n実験方法\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n36\n4.1.4\nデータ収集実験の結果. . . . . . . . . . . . . . . . . . . . . . . . .\n37\n4.2\nラベリング方法. . . . . . . . . . . . . ",
            ". . . . .\n37\n4.2\nラベリング方法. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n38\n4.3\n評価精度検証方法. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n39\n4.3.1\n姿勢推定手法の検証方法. . . . . . . . . . . . . . . . . . . . . . . .\n39\n4.3.2\n機械学習手法の検証方法. . . . . . . . . . . . . . . . . . . . . . . .\n40\n第5 章\n提案手法の検証結果と考察\n41\n5.1\n姿勢推定による動作評価手法の結果と考察. . . . . . . . . . . . . . . . . .\n41\n5.1.1\n姿勢推定による動作評価手法の結果\n. . . . . . . . . . . . . . . . .\n41\n5.1.2\n姿勢推定による動作評価手法の考察\n. . . . . . . . . . . . . ",
            "\n5.1.2\n姿勢推定による動作評価手法の考察\n. . . . . . . . . . . . . . . . .\n42\n5.2\n機械学習による動作評価手法の結果と考察. . . . . . . . . . . . . . . . . .\n42\n5.2.1\n機械学習による動作評価手法の結果\n. . . . . . . . . . . . . . . . .\n42\n5.2.2\n機械学習による動作評価手法の考察\n. . . . . . . . . . . . . . . . .\n44\n第6 章\n結論と今後の展望\n46\n6.1\n結論. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n46\n6.2\n今後の展望\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n46\n謝辞\n48\n参考文献\n49\n2\n第1章\n序章\n1.1\n現代サッカーにおける研究背景\n1.1.1\nサッカーの競技者数と指導者の関係\nサッカーは",
            "序章\n1.1\n現代サッカーにおける研究背景\n1.1.1\nサッカーの競技者数と指導者の関係\nサッカーは世界的に人気であるスポーツの1 つで，世界中に35 億人以上を超えるファン\nがいると言われている[1]．特にワールドカップなどの国際大会では，世界中のサッカー\nファンが注目し，スポーツ文化の一環として大きな影響力を持っている．日本のサッカー競\n技人口に着目すると，2023 年度の日本サッカー協会の登録者数は約83 万人である[2]．図\n1.1 は1979 年から2023 年までの日本サッカー協会の登録者数の推移を表している．1993\n年のJ リーグ開幕をきっかけに競技者数が増加し，近年は増加と減少を繰り返していなが\nらも，概ね80 万人以上の競技者数を維持している．このような競技者数の推移はJ リー\nグやワールドカップなどが大きく影響し，今後もサッカーが日本国内の主要なスポーツと\nなると考えられる．図1.2 は2023 年度の登録選手の各カテゴリーの割合を表している．J\nリーグに所属するプロサッカー選手は全体で0.2%で，ほとんどがアマチュア以下の選手\nであることがわかる．特に若年層が大",
            "ロサッカー選手は全体で0.2%で，ほとんどがアマチュア以下の選手\nであることがわかる．特に若年層が大半を占めており，これは部活動や地域のクラブな\nど，サッカーを行う機会が多いことが大きな要因として挙げられる．このように若年層の\n競技者数が多いことは日本サッカーの将来にとって重要であり，これを維持するには教育\n的な側面や地域の格差への配慮が必要である．\n図1.1: 日本サッカー協会選手登録数（1979 年～2023 年）([2] より引用)\n3\n図1.2: 日本サッカー協会カテゴリー別選手登録割合（2023 年度）([2] より引用)\n図1.3 は日本サッカー協会に登録されている指導者数の推移を示しており，継続的に増\n加し，2023 年度には9 万人を超えている[3]．日本サッカー協会では，指導者に対して，\n指導レベルに応じたライセンスを発行しており，プロフェッショナルレベルのS 級コーチ\nから，アマチュアレベルのA～D 級コーチに分類されている[4]．特に，アマチュアレベ\nルの中でもA 級とB 級は「質の高いサッカー指導が可能である」とされる指導者に与え\nられるライセンスであるが，A ",
            "級とB 級は「質の高いサッカー指導が可能である」とされる指導者に与え\nられるライセンスであるが，A 級は全体のわずか3%，B 級は9%に過ぎず，これらのライ\nセンス保持者の割合は非常に少ない．\n図1.3: 日本サッカー協会指導者数（2004 年～2023 年）([3] より引用)\n4\n日本サッカー協会の指導者登録数は増加傾向にあるものの，選手一人当たりの指導者数\nは依然として不足しており，これは選手一人に与える指導の質に直接的な影響を及ぼして\nいる．選手と指導者の適切な比率は年齢層によって異なるが，一般的に年齢が若いほど\nより多くの指導者が必要と考えられている．イングランドのサッカー連盟（The FA）は，\nコーチと選手の適切な比率についてガイドラインを出しており，コーチ1 人あたりに対\nする選手数として，4～8 歳は6 人，9～12 歳はは8 人，13～18 歳は10 人を推奨している\n[5]．これは年齢が低く，技術的に成長の初期段階において質の高い指導が非常に重要で\nあり，年齢が上がるにつれて熟練度及び自立度が高くなるため，指導者数がより少ない人\n数でも効率的に指導できるようになる",
            "るにつれて熟練度及び自立度が高くなるため，指導者数がより少ない人\n数でも効率的に指導できるようになるからである．ただし，年齢が上がった場合でも，指\n導者の不足は，選手一人当たりに十分な指導が行き届かず，技術の習得や戦術理解が十分\nに進まないというリスクとなることは同様である．このため，指導者数および指導の質の\n向上が日本サッカーの将来にとって重要な課題となる．\n1.1.2\nサッカーのIT 技術の活用\n現代のIT 技術の進化に伴い，その技術がサッカーに対して活用されることが増えた．プ\nロサッカーの試合では，試合を円滑かつフェアに進めるために，審判をサポートするため\nに利用される事例が多く見られる．代表的なものとして，2012 年に競技規則に導入され\nた「ゴールライン・テクノロジー（GLT）」がある[6]．GLT はボールがゴールラインを完\n全に超えたかどうかを判断するために使用される技術であり，重要な得点シーンでの誤審\nを防ぐことが可能である．ゴールラインの両側に設置されたカメラやセンサがボールの位\n置を正確に測定することで，得点があったかどうかを審判に通知する仕組みである．さら\nに，2",
            "ボールの位\n置を正確に測定することで，得点があったかどうかを審判に通知する仕組みである．さら\nに，2018 年からは「ビデオ・アシスタント・レフェリー（VAR）」システムが正式に導入\nされた[6]．VAR は主審が見逃した可能性のある重大なプレーについて，ビデオ映像を確\n認することで判定をサポートするシステムである．特にゴール，ペナルティキック，レッ\nドカードなど試合の行方に大きく影響する場合で使用される．VAR の導入により，試合\nの公平性を高めることが可能となった．\nまた，選手やコーチなどの競技者をサポートするため，IT 技術が活用されることも増\nえている．チームのマネジメントおよびパフォーマンスのモニタリングを目的として，ド\nイツの大手ソフトウェア企業SAP によって開発された「SAP Sports One」（図1.4）があ\nる[7]．このシステムはサッカーをはじめとするプロスポーツチームに向けて設計されて\nおり，チーム運営のさまざまな側面でサポートすることができる．ウェアラブルデバイス\nや高精細カメラによってフィールド上の選手とボールの動きをトラッキングし，走行距離\nやスプリン",
            "バイス\nや高精細カメラによってフィールド上の選手とボールの動きをトラッキングし，走行距離\nやスプリント速度，パス成功率などをリアルタイムに解析する．選手に対するサポートと\nして，各選手のスマートデバイスで確認することを可能にすることで，自身のパフォーマ\nンスを客観的に振り返ることができる．一方でコーチに対するサポートは選手の位置や相\n手チームの情報をもとに戦術の最適化を図ることができる．同時に医療データや生体デー\nタから選手のコンディション管理をすることで怪我の予防や早期発見に貢献する．これに\nよってチームは試合に向けた準備を効果的に進めることができる．\n「SAP Sports One」はド\nイツのFC バイエルン・ミュンヘンや，日本のヴィッセル神戸など世界19ヶ国で80 チーム\n以上をサポートしている．\n5\n図1.4: SAP 社が開発したSAP Sports One（[7] より引用）\n1.1.3\nウェアラブルサッカーサポート製品\nサッカーのパフォーマンス分析には，映像解析によるカメラベースと信号解析によるセ\nンサベースの2 種類が主流である．カメラを用いたシステムは選手全体やフィ",
            "ラベースと信号解析によるセ\nンサベースの2 種類が主流である．カメラを用いたシステムは選手全体やフィールドの広\n範囲を捉えることができ，戦術的な分析には優れているが，設置や運用に高いコストと手\n間がかかるというデメリットがある．一方，ウェアラブルデバイスは比較的容易に導入す\nることが可能であり，個々の選手の動きをリアルタイムにトラッキングすることで，個人\nのパフォーマンス向上に役に立つデータの取得ができる．市販されているウェアラブルな\nサッカーサポートデバイスはプロ向けの高価なものからアマチュア向けの安価なものまで\nある．\nCatapult 社の「Catapult Vector Pro」（図1.5）は世界中の1200 以上のプロサッカーチー\nムで利用されているGPS を用いた代表的なサポートシステムである[8]．このデバイスを\n背中に装着することで，走行距離，走行速度，加速・減速，脈拍数などの情報を計測する\nことができる．高精度なトラッキングにより，個人のパフォーマンスの定量化やチーム全\n体の戦術改善，怪我のリスク低減が可能である．これらのデバイスは個人向けではなく\nチーム全体のサポー",
            "\n体の戦術改善，怪我のリスク低減が可能である．これらのデバイスは個人向けではなく\nチーム全体のサポートに特化したシステムである．\n図1.5: Catapult 社が開発したVector Pro（[8] より引用）\n6\n一方で，比較的安価で個人向けなシステムとして，Playermaker 社が開発した「Player-\nmaker 2.0」（図1.6）がある[9]．このシステムはスパイクに取り付けるタイプのスマート\nセンサを用いたアマチュア向けのウェアラブルシステムである．内蔵された加速度センサ\nと角速度センサから取得したデータから，走行距離やスプリント数，各足のタッチ数やパ\nス数，キックパワーなどの情報をトラッキングすることができる．\n図1.6: Playermaker 社が開発したplayermaker2.0([9] より引用)\nウェアラブルデバイスは選手個々の動きをリアルタイムにトラッキングし，パフォーマ\nンスを詳細に評価できる点で優れており，装着するだけで簡単に利用できるという特徴が\nある．しかし，取得できるデータや評価指標には限りがあるため，キックフォームの細か\nい改善を提示する",
            "\nある．しかし，取得できるデータや評価指標には限りがあるため，キックフォームの細か\nい改善を提示するような機能はないという課題がある．他にも様々なサッカーサポート製\n品があるが，選手のレベルや目的に応じた情報の取得ができるものを選び，有効に活用す\nることで，自身のパフォーマンス向上に繋げることが可能である．\n1.2\n研究目的と目標\n1.1.1 項で述べたように，サッカーは世界中で人気であり，日本においてもJ リーグの開\n幕などをきっかけに競技者が増加し，その大半は若年層を占める．しかし，選手一人あた\nりの指導者数は十分であるとは言えず，指導者全体の指導の質に関しても改善の必要性が\n課題として挙げられている．\n1.1.2 項で述べたように，現代のIT 技術の進化に伴い，それらの技術をプロサッカーの\n試合やチーム運営に活用されていることがわかった．審判へのサポートでは試合を円滑に\n進めるために，競技者へのサポートではパフォーマンスの評価や怪我の予測に役立てられ\nている．これらの技術はプロチームに向けた高価なものであり，アマチュアにとっては導\n入は難しいという課題がある．\n一方で，1.1.3",
            "ムに向けた高価なものであり，アマチュアにとっては導\n入は難しいという課題がある．\n一方で，1.1.3 項で述べたように，ウェアラブルなサポート製品が多く販売されており，\nアマチュア向けの比較的安価な製品もある．これらの製品は選手の動きをトラッキング\nし，パフォーマンスを評価でき，装着するだけで簡単に利用できるという特徴がある．し\nかし取得できるデータの限界からキックフォームの細かい改善を提示するような機能はな\nいという課題が残されている．以上のことから，本研究の目的は安価な小型の慣性計測装\n7\n置を用いて，指導者がいない環境においても選手自身で利用可能なキックフォームフィー\nドバックシステムを開発することとする．\n以下に本研究の目的を達成するための目標を示す．\n• サッカー動作の重要な評価基準の設定\n• サッカースキルの自動評価手法の検証\n1.3\n本論文の構成\n本論文は以下の構成である．\n第1 章：本論文の研究背景，研究目的及び論文の構成について述べる．\n第2 章：サッカーの技術支援を目的とした先行研究と本研究の位置付けについ\nて述べる．\n第3 章：提案するシュートフォームの自動評価手",
            "的とした先行研究と本研究の位置付けについ\nて述べる．\n第3 章：提案するシュートフォームの自動評価手法について述べる．\n第4 章：検証に用いるデータ収集実験と提案手法の精度検証について述べる.\n第5 章：精度検証の結果および考察を述べる．\n第6 章：本論文の結論と今後の展望について述べる．\n8\n第2章\n関連研究\n2.1\n複数のサッカー動作を識別した研究\nサッカーは，パス，シュート，ドリブル，ヘディングなど多様な動作から成り立つスポー\nツである．これらを正確に識別することは，選手の特性理解や戦術改善，そして技能向\n上システムの実現において重要である．この分野では，選手の動作を計測する手法とし\nて，センサ技術や映像解析技術が活用されている．本節では，それぞれの手法を用いた\nサッカー動作の識別に関する研究を紹介する．\n青柳らは，右足に装着した小型な慣性計測センサを用いて，サッカーの基本動作である\nシュート，ドリブル，パス，ヘディングを識別する手法を提案した[10]．慣性計測センサ\nから収集した3 軸加速度データからサッカー動作を検出し，自動セグメンテーションに\nよって分割した．さらに分割した",
            "3 軸加速度データからサッカー動作を検出し，自動セグメンテーションに\nよって分割した．さらに分割した動作データから特徴量を抽出し，ランダムフォレスト，\nサポートベクターマシン，ロジスティック回帰，k 近傍法，ガウスナイーブベイズ分類器\nの5 種類の分類モデルで動作の識別精度を検証した．その結果，シュート，パス，ドリブ\nルは90%以上の精度で検出が可能であり，特にサポートベクターマシンでは85%以上の\n分類精度を達成した．一方で，ヘディングの検出と分類精度が低く，ヘディングの識別精\n度の改善が課題として残った．\nD.Schuldhaus らは，IMU センサベースの計測システムを利用し，シュートとパスを識\n別する手法を提案した[11]．図2.1 に示すように，スパイクの内部にIMU センサ，脛当て\nに記憶装置を設置し，両足の加速度と角速度を計測するシステムを開発した．取得した\nデータから信号振幅ベクトル（SMV）を算出し，ピーク検出によって動作をセグメント\nした．セグメントした部分から平均，分散，歪度，尖度の4 つの統計的特徴をを抽出し，\nサポートベクターマシン，分類回帰木，ナイーブベイ",
            "，分散，歪度，尖度の4 つの統計的特徴をを抽出し，\nサポートベクターマシン，分類回帰木，ナイーブベイズの3 種類の分類モデルによって分\n類精度を検証した．分類は2 段階で分類する階層的アプローチを採用し，まずイベント\n（シュート，パス）とその他（タックル，ランニング，サイドステップを含む）に分類し，\n次にイベントからシュートとパスに分類した．結果として，イベントとその他の分類精度\nは89.5%，シュートとパスの分類精度は84.2%を達成し，サポートベクターマシンが最も\n高い性能を示した．\n9\n図2.1: （左）スパイク内部のIMU センサ，\n（右）脛当ての記憶装置（[11] から引用）\n伊藤らはサッカー選手のオフザボールに着目した動作分析システムを提案した[12]．こ\nのシステムは地磁気センサ，角速度センサ，GPS センサを選手の体に装着し，それらの\nデータを組み合わせることで，選手の向き，動作内容，位置情報を分析する．図2.2 にセ\nンサおよび周辺機器の装着位置を示す．大腿部に装着した角速度センサで内転・外転や屈\n曲・伸展による角速度変化を測定し，歩行，走行，ステップワーク，ジャンプ",
            "角速度センサで内転・外転や屈\n曲・伸展による角速度変化を測定し，歩行，走行，ステップワーク，ジャンプなどの動作\nを判別することを可能にした．また，背中に装着した地磁気センサで選手の向いている方\n向を判別し，GPS センサを用いて選手の位置情報を取得する仕組みを構築した．基礎評\n価によってマルチセンサの組み合わせで詳細な動作分析が可能であることが確認された．\nしかし精度検証は行われておらず，試合での実用性を考慮したセンサ装着方法やGPS セ\nンサの位置測定の精度向上が課題として残された．\n図2.2: センサおよび周辺機器の装着位置（[12] から引用）\n10\nStoeve らはシューズに装着したIMU センサで計測したシュートとパスを深層学習モデ\nルによって識別する手法を提案した[13]．データ収集には，制御された条件下での環境と\n実際の試合や練習の環境で行い，それぞれの環境下での識別精度を検証することでシステ\nムの有効性を検証した．分類モデルは，先行研究のサポートベクターマシンと3 つの深層\n学習モデル(CNN，LSTM，convLSTM）を採用した．スライディングウィンドウ法によ\nる",
            "深層\n学習モデル(CNN，LSTM，convLSTM）を採用した．スライディングウィンドウ法によ\nる自動セグメンテーションを行い，加速度と角速度の各軸のキックフェーズ中の信号の絶\n対和を計算し，6 つの特徴量を分類器に入力した．結果として，試合や練習の環境で収集\nされたデータにおいてCNN がF1 スコア92.8%の最も高い識別精度を示した．\nMascher らは，MEMS 加速度センサを搭載したスマート脛当てを開発し，サッカー選手\nの動作識別を目的とした性能評価を実施した[14]．本システムでは立つ，歩く，走る，パ\nス，シュートの5 つの動作を対象とし，3 軸加速度データから合成加速度のピークを検出し\nてセグメンテーションを実施した．特徴量抽出に主成分分析と線形判別分析を適用し，機\n械学習アルゴリズムとしてロジスティック回帰，サポートベクターマシン，ランダムフォ\nレスト，人工ニューラルネットワークの分類精度を比較した．分類は2 段階で行い，第一\n段階でキックと他の動作，第二段階で詳細に分類するというアーキテクチャを提案した．\n結果として，線形判別分析を適用したロジスティック回帰とラン",
            "分類するというアーキテクチャを提案した．\n結果として，線形判別分析を適用したロジスティック回帰とランダムフォレストが最も高\nい精度を達成した．被験者数が1 人に限定されており，さらなるデータ収集やドリブルな\nどの複雑な動作を含む分析が課題として残された．\nAlobaid らは加速度センサを搭載したスマートフォンを腹部に装着し，サッカーの5 つ\nの基本動作（シュート，パス，ヘディング，ランニング，ドリブル）をリアルタイムに識別\nする手法を提案した[15]．分類手法は，Time Series Forest Classiﬁer（TSF），Fast Shapelet\nTransform Classiﬁer（FS），Bag of SFA Symbols（BOSS），これらの複数のアルゴリズム\nの長所を組み合わせた協調モデルの4 つを比較した．結果として，協調モデルの精度が最\nも高い精度（84%）を達成し，学習時間を短縮することも可能であった．一方で，腹部に\nスマートフォンを装着する方法は激しい動作が行われるサッカーには不向きであり，カメ\nラを元に3 秒間のウィンドウでセグメントしているため動作外",
            "が行われるサッカーには不向きであり，カメ\nラを元に3 秒間のウィンドウでセグメントしているため動作外のデータが含まれてしまう\n点が課題として残された．\nHossain らは，リストバンド型のウェアラブルデバイスを用いて，サッカー選手の動作\nを解析するシステム「SoccerMate」を開発した[16]．このシステムはパス，キック，スプ\nリント，ランニング，ドリブルなどの動作を分類し，パフォーマンスを数値化することを\n目的としている．解析には，加速度データを用いて，動作の変化点を検出し，イベントご\nとにデータを分割し，Restricted Boltzmann Machine を用いた深層学習による動作の分類\nを行った．全体の分類精度は86.5%に達し，\n「走行」や「ランニング」，\n「静止」の動作にお\nいては高い精度を示した．一方で，ドリブルの動作は速度変化が明確にデータに現れない\n場合が多く，精度が低下することが確認された．\n今井らは，カメラで取得したサッカートラッキングデータを用いて，選手とボールの位\n置情報から10 種類のボールタッチプレーを自動認識する手法を提案した[17]．データは",
            "とボールの位\n置情報から10 種類のボールタッチプレーを自動認識する手法を提案した[17]．データは\nJ1 リーグ公式20 試合分を使用し，ボールの軌道や速度の変化に基づく条件でプレーを検\n出した．認識にはConditional Random Field（CRF），サポートベクターマシン，ランダム\nフォレストの3 種類の機械学習モデルを比較し，ボールの移動距離や選手間の距離などを\n特徴量として利用した．結果として，プレーの検出は86%を達成し，全体的に高い性能\n11\nを示した．一方で，プレーの認識はプレーごとに精度に差が見られ，パスやトラップは高\nい精度を示したがシュートやクリアなどの一部のプレーでは精度が低下する傾向が見られ\nた．データ数が少ない動作や曖昧な動作の認識に課題が残された．\n2.2\n熟練者と未熟練者の違いを解析および識別した研究\nサッカーの熟練者と未熟練者の動作にはそれぞれ特徴的な差が存在する．それを解析す\nることで，技能向上のための指標を提供することが可能となる．この分野では，サッカー\n動作のデータ収集手法として，センサ技術や映像解析技術が活用されている．本節では，\n熟",
            "では，サッカー\n動作のデータ収集手法として，センサ技術や映像解析技術が活用されている．本節では，\n熟練度の違いに着目したサッカー動作の解析に関する研究を紹介する．\n紅林らは，スポーツの動作解析を目的とした計測システムを開発し，現役サッカー選手と\n未経験者のインステップキック動作の違いを明らかにした[18]．計測システムはArduino，\n3 軸加速度センサ・角速度センサ，モバイルバッテリーを組み合わせて構築されており，足\nに装着することでキック動作を計測することができる．現役のサッカー選手と未経験者を\n対象とした実験の結果，現役選手はキック前に足を大きく引き上げ，加速度と角速度の最\n大値が高く，効率的な動作を行っていることが確認された．一方，未経験者は足の動きに\n無駄が多く，キック後も不要な動作が見られるなど，動作の非効率性が明らかになった．\n今後の課題として，上半身の動作にも着目し，サッカーの熟練度による違いを詳細に分析\nすること，本格的な利用に向けた計測デバイスの小型化などが挙げられた．\n真鍋らは，身体7 箇所に装着した慣性センサから取得したデータを基に，サッカー経験\nを持つ上級者",
            "た．\n真鍋らは，身体7 箇所に装着した慣性センサから取得したデータを基に，サッカー経験\nを持つ上級者と初心者のインステップキック動作を解析し，その違いを明らかにした[19]．\n静止したボールと動いたボールの両方を対象にキック動作の実験を実施し，解析では特に\n骨盤と蹴り足に注目した．解析の結果，上級者は初心者に比べて，骨盤の前後および上下\n方向の回転速度が速く，蹴り足の角速度も高いことが確認された．特に，動いているボー\nルに対するキックでは，これらの違いが顕著に増加し，効率的に伝達していることが示さ\nれた．また，スキルテストによるインステップキックのスコアと蹴り足の回転速度には正\nの相関が見られ，競技者の技術レベルを動作データを基に定量化できることを明らかに\nした．\nPiechota らは，熟練度が異なるサッカーのゴールキーパーを対象に，筋電図（EMG）を\n用いて意思決定時間と筋電図緊張値の違いを解析した[20]．2 対1 の典型的なゲーム状況\nを模擬し，シュートが打たれてからゴールキーパーがセーブアクションを完了するまでを\n意思決定時間と定義し，図2.3 に示すように，両足の10 箇所",
            "ーがセーブアクションを完了するまでを\n意思決定時間と定義し，図2.3 に示すように，両足の10 箇所に装着された筋電図でデー\nタを収集した．結果として，熟練者は未熟練者より意思決定時間が優位に短いことが確認\nされた．また，熟練者は主要な姿勢筋の動作範囲を最適化し，効率の良い動作パターンを\n示した．一方，未熟練者は筋電図の緊張値が高く動作効率が低い傾向が示された．これら\nの結果から，熟練者が視覚情報と筋肉活動の連携を通じて動作の精度と効率を向上させて\nいることが示唆された．\n12\n図2.3: 筋電図の装着位置（[20] から引用）\nRoss らは，モーションキャプチャデータを用いて生成したIMU センサのシミュレーショ\nンデータを活用し，エリート選手と初心者を識別する分類手法を提案した[21]．モーショ\nンキャプチャから得た動作データを基に，IMU データとして線形加速度と角速度をシミュ\nレーションし，7 種類の動作の分類を行った．検証では，モーションキャプチャを用いた\n分類精度とシミュレートされたIMU センサを用いた分類精度で比較された．結果として，\nモーションキャプチャの分類精度は",
            "ートされたIMU センサを用いた分類精度で比較された．結果として，\nモーションキャプチャの分類精度は平均78.1%に対して，シミュレートされたIMU デー\nタでは平均80.2%を記録し，IMU データがモーションキャプチャと同等以上の精度を示す\nことが確認された．結果より，比較的低コストなIMU センサでも動作の評価が可能であ\nることが明らかになった．\n中村らは，熟練者と未熟練者のインステップキック動作を解析し，その違いを明らかに\nした[22]．測定には図2.4 に示したモーションキャプチャ測定システムを用いて実施され\nた．解析ではボールの速度，腰部や股関節の動き，軸足の傾斜角度に着目した．結果とし\nて，熟練者はボール速度が速く，腰部の動きが大きいことから体幹を効率的に活用してエ\nネルギーを伝達していることが示された．また，股関節では屈曲や外旋の動作範囲が広く，\n正確で力強いキック動作が可能であることが明らかになった．さらに，軸足の傾斜角度が\n大きいことで安定した姿勢を保ちながらキックを行っている点が特徴として挙げられた．\n一方，未熟練者はこれらの動きが全体的に小さく，動作効率が悪いこ",
            "行っている点が特徴として挙げられた．\n一方，未熟練者はこれらの動きが全体的に小さく，動作効率が悪いことが確認された．\n図2.4: （左）測定システムの全景，\n（右）マーカの設置位置（[22] から引用）\n13\n辻元らは，3 次元動作解析システムを構築し，サッカー未経験者と熟練者のインステッ\nプ動作の違いを分析した[23]．このシステムは被験者に反射マーカを装着した状態で，4\n台のハイスピードカメラで撮影し，動作分析ソフトと用いた3 次元DLT 法によって各部\n位の三次元座標を取得することができる．解析の結果，熟練者は膝関節の伸展角速度が\n高く，下肢のムチの動作を効率的に利用していた．一方，未経験者は股関節が過剰に屈曲\nし，股関節の伸展角速度が低いことなど効率的なキック動作ができていないことが示され\nた．未経験者は軸足の傾きが小さく，インパクト時に安定した姿勢を取れていないことも\n明らかになった．今後の課題として，未経験者のキック技術向上を目指した指導法の開発\nや熟練者の動作を基にした効率的な練習法の提案が挙げられた．\n金子らは，人体の関節座標を取得するツール「OpenPose」を用いて",
            "的な練習法の提案が挙げられた．\n金子らは，人体の関節座標を取得するツール「OpenPose」を用いて，サッカーのシュー\nト動作を解析し，熟練度を識別する手法を提案した[24]．身体の18 箇所の関節座標を取\n得し，体の向き，軸足の位置，腰の回転，フォロースルーの4 つの特徴量を抽出した．こ\nれらの特徴量を基に，サポートベクターマシン，ランダムフォレスト，ロジスティック回\n帰などの機械学習モデルで，熟練度を分類した．結果として，ランダムフォレストが最も\n高い精度である84.0%を達成した．さらに，体の向きや腰の回転が熟練度を識別する上で\n重要な指標であることが示された．また，関節座標データを活用することで，体の向きや\n腰の回転などを数値化できる可能が確認され，動作解析における有効性が示唆された．\n正木らは，モーションキャプチャ技術を活用して，サッカーのトラップおよびパス動作\nにおける経験者と未経験者の違いを解析した[25]．被験者の上半身3 点（頭部，脊椎，腰\n部）から三角形の面積と傾き角度を特徴量として算出し，経験者と未経験者の識別に有用\nであるかを検証した．また，これらの特徴量を教師",
            "度を特徴量として算出し，経験者と未経験者の識別に有用\nであるかを検証した．また，これらの特徴量を教師あり学習の分類モデル用いることで，\n分類精度を評価した．結果として，経験者は動作中の姿勢が安定しており，三角形の面積\nや傾き角度の変動が小さいことが確認された．一方で，未経験者は体軸のブレが大きく，\n三角形の面積と傾き角度に大きな変動が見られた．さらに提案した特徴量を用いた分類精\n度は，次元を削減しない生データを直接用いた分類精度に近い結果を示し，動作傾向の分\n析や識別に有効であることが示された．\n2.3\nサッカー動作の評価に関する研究\nサッカー動作を定量的に評価することで，選手の現在の技術レベルを客観的に把握し，\n具体的な改善点を特定することにつながる．また，評価結果を基にトレーニング内容を最\n適化することが可能となり，効果的なスキル向上が期待できる．定量的な評価を行うモデ\nルを開発するために，センサ技術やカメラ技術を用いて選手の動作データが収集される．\n本節ではこれらの技術を用いた動作評価に関する研究を紹介する．\nYu らは，足に装着したIMU センサの軌跡を推定することによって，キ",
            "評価に関する研究を紹介する．\nYu らは，足に装着したIMU センサの軌跡を推定することによって，キック動作の質を評\n価する解析手法を提案した[26]．IMU センサで収集した加速度・角速度データからクォー\nタニオンによる姿勢推定，座標変換することによって2 次元および3 次元の軌跡を構築し\nた．図2.5 はインステップキック時のデータから構築された2 次元および3 次元の軌跡を\n表している．提案手法は軌跡データから蹴り足の最大速度，バックスイングの最高点を抽\n出することで動作の特徴を解析した．精度検証には，高速カメラで取得したビデオデー\nタを正解データとして利用し，IMU センサによる推定結果との比較を行った．その結果，\n14\n足の最大速度とバックスイングの最高点についてはそれぞれ誤差4%と2.8%と高い精度を\n達成した．軌跡の位置誤差は0.07m，速度誤差は0.034m/s と低い値を示し，IMU センサ\nを用いた解析がキック動作の詳細な特徴を識別する手法として有効であることが示唆さ\nれた．\n図2.5: （左）インステップ時の2 次元のIMU センサの軌跡，\n（右）インステップ時の",
            "\nれた．\n図2.5: （左）インステップ時の2 次元のIMU センサの軌跡，\n（右）インステップ時の3 次\n元のIMU センサの軌跡（[26] から引用）\nWilmes らは，サッカー動作の中で加速，減速，切り返し，ジャンプ，キックに着目し，\n動作の強度を評価するシステムを提案した[27]．9 軸IMU センサを下半身の5 箇所（骨\n盤，大腿部，脛部）に装着し，膝および股関節の角度と角速度を算出し，動作の強度と\nして「低」「中」「高」の3 段階で精度の検証をした．モーションキャプチャを基準とし，\nRMSD（ルート平均二乗誤差）を用いて角度の誤差を評価し，CMC（多重相関係数）を用\nいてIMU センサとモーションキャプチャ間のデータ一致度を測定した．その結果，膝関\n節と股関節の角度におけるRMSD はそれぞれ平均5.3 °および8.0 °であり，CMC は0.985\nおよび0.940 と非常に高い一致率を示した．これらの結果は，IMU センサを用いて動作の\n強度を正確に評価できる可能性を示唆している．\nTakizadeh らは，k 近傍法（KNN）アルゴリズムとIMU センサを組み合わせ",
            "唆している．\nTakizadeh らは，k 近傍法（KNN）アルゴリズムとIMU センサを組み合わせて，子供の\nキックスキルを評価する手法を提案した[28]．IMU センサを両足のくるぶし上部と腰部\nに装着し，収集した加速度および角速度データを基に，子供の運動発達を質的に評価する\n標準化された項目（TGMD-3）に基づいて基礎運動スキルの評価を自動化した．専門家に\nよるスコアリングと本システムの評価結果を比較し，一致度を算出した結果，0.90 と高い\n精度が確認された．また，システムの評価分類精度も95%に達し，動作の正確な評価が\n可能であることが示された．さらに，本システムは従来の手動評価と比較して，1 回の動\n作の評価時間を平均5 分から30 秒未満に短縮する効率性も実証された．\nRada らは，選手評価および選抜のセレクションに有効な指標として，ポケットレーダー\nを用いたボール速度による評価手法を提案した[29]．ユースサッカー選手を対象に，ポ\nケットレーダーで記録した最大キック速度を基に，年代カテゴリ（U-15，U-17，U-19）お\nよびチームステータス（ファーストチームとリ",
            "度を基に，年代カテゴリ（U-15，U-17，U-19）お\nよびチームステータス（ファーストチームとリザーブチーム）の違いを統計的に分析し\nた．また，受信者動作特性（ROC）解析を用いて，測定結果が競技レベルを区別する診\n15\n断能力を評価した．結果として，ファーストチームの選手はリザーブチームの選手より一\n貫して高いキック速度を示し，特に若年カテゴリ（U-15 およびU-17）でその差が顕著で\nあった．また，ROC 解析により，最大キック速度は競技レベルを区別する上で有効な指\n標であることが確認された．\n安達らは，ビデオカメラと深層学習技術を用いて，ロングキック，トラップ動作を自動\n評価し改善アドバイスを提示する個人練習支援システムを提案した[30]．このシステムで\nは，Google MediaPipe を用いて選手の骨格情報を推定し，各関節の角度を算出した．図\n2.6 はMediaPipe の骨格推定の結果例である．この結果を基に，理想のフォームから逸脱\nしたポイントを特定し，改善に向けたアドバイスを生成する仕組みである．システムの精\n度検証では，モーションキャプチャシステムを基準と",
            "けたアドバイスを生成する仕組みである．システムの精\n度検証では，モーションキャプチャシステムを基準として，一致度およびアドバイスの表\n示回数を比較した．経験者における一致度は7 割に達し，未経験者では誤表示が見られた\nものの，全てのアドバイスを提示することができた．課題として，ビデオカメラの角度に\nより体の一部が隠れることで，骨格推定の誤差や精度低下が生じる点が挙げられた．\n図2.6: MediaPipe による骨格推定の結果例（[30] から引用）\n2.4\n選手・コーチへのサポートシステムを開発した研究\n節2.1～2.3 節では，サッカー動作の識別や評価に関する研究について述べた．一方で，\n動作の識別や評価を活用し，具体的なフィードバックを通じて選手やコーチを直接的に支\n援するサポートシステムも開発されている．これらのシステムは，トレーニング内容の改\n善や戦術指導の補助に役立ち，選手のパフォーマンス向上や健康管理を支援するものであ\nる．本節では，これらのサポートシステムの概要とその効果について紹介する．\nMarris らは，サッカー動作を識別するシステムを利用して，ポジションやトレー",
            "について紹介する．\nMarris らは，サッカー動作を識別するシステムを利用して，ポジションやトレーニング\nメニューごとの技術動作の頻度や傾向を解析した[31]．このシステムはボールタッチやリ\nリース（パス，シュートなど）の動作を記録することが可能である．システムの識別精度\nの検証として，ビデオカメラを基準に比較した結果，一致率95%という高い精度で動作\nを識別可能であることを明らかにした．さらに，ポジション別の解析では，中盤選手が最\nも多く技術動作を行い，トレーニングメニューごとの解析では，小規模ゲーム形式の練習\nが技術動作の頻度を最も高めることが確認された．コーチが練習メニューや戦術の改善に\n役立つ具体的なデータを得ることが可能であることを示した．\n16\nIkram らは，サッカー選手の健康管理を目的としたIoT ベースの監視システム「IoT Foot-\nball」（図2.7）を開発した[32]．このシステムは，選手に装着されたセンサから生理的デー\nタ（心拍数，体温，発汗率など）をリアルタイムに収集し，クラウド上で解析することで\n健康状態の異常を検出する．また，気温や照明強度といっ",
            "アルタイムに収集し，クラウド上で解析することで\n健康状態の異常を検出する．また，気温や照明強度といった環境データも収集し，選手の\n健康とパフォーマンスに影響を与える要因を総合的に監視し，異常が検出された場合には\nモバイルアプリを通じてコーチや監督にアラートを通知する仕組みになっている．検証実\n験では，健康異常の検出率が99%以上という高精度を示し，リアルタイム通知により迅\n速な対応が可能であることが確認された．モバイルアプリを通じた通知機能の正確性や遅\n延時間を評価した結果，異常発生時に迅速かつ正確にアラートが送信されることが実証さ\nれた．\n図2.7: 「IoT Football」のシステム構成図（[32] から引用）\nStensland らは，選手のパフォーマンス解析と戦術可視化の効率化を目的としたリアルタ\nイムサポートシステム「Bagadus」（図2.8）を提案した[33]．トラッキングセンサ，カメ\nラ，コーチ向けのアノテーションツールを統合し，選手の動きやイベントをリアルタイム\nで記録・解析する．複数のカメラで撮影した映像を動的に切り替えたり，選手の位置デー\nタを基に特定イベント",
            "記録・解析する．複数のカメラで撮影した映像を動的に切り替えたり，選手の位置デー\nタを基に特定イベント（パスやシュートなど）を自動的にタグ付けする機能を提供する．\nさらに，過去のプレーデータを瞬時に検索し，特定の状況を再生することも可能である．\nシステムの検証では，位置データと映像の同期性能やイベント抽出・再生までの時間を測\n定した．遅延時間は平均671ms で，リアルタイム解析に十分な効率性を示した．本研究\nは，選手のパフォーマンス向上やコーチによる戦術改善を効果的に支援するシステムとし\nて有効であることを示している．\n17\n図2.8: 「Bagadus」のシステム構成図（[33] から引用）\n2.5\n先行研究で残された課題と本研究の優位性\n2.1 節では，サッカー動作の識別に関する研究を紹介した．ウェアラブルセンサやカメ\nラから取得したデータを機械学習や深層学習を用いて分類することで，シュート，パスな\nどの基本動作を高精度で識別できることが示された．しかし，ヘディングやドリブルなど\nの複雑な動作に関しては識別精度が低いなど，使用するセンサによってプレーの認識精度\nに差が見られる課題が",
            "複雑な動作に関しては識別精度が低いなど，使用するセンサによってプレーの認識精度\nに差が見られる課題が残った．また，これらの研究では動作の識別に重点を置いており，\n選手個人のフォーム改善や技術向上の支援まで至っていない．2.2 節では，サッカーの技\n能レベルの識別や動作の違いを解析した研究を紹介した．技能レベルの識別については，\n機械学習を用いることで高精度な識別が可能であることが示された．また，技術レベル\nによる動作の違いを詳細に解析した結果，熟練者は効率的かつ無駄の少ないフォームで\n動作する一方，未熟練者には非効率的な動作が多いことが明らかになった．このことか\nら，IMU センサやカメラで収集したデータに適切な信号処理や映像解析を適用すること\nで，動作の評価を行い，具体的かつ実用的な技術向上支援システムの実現が可能である\nことが示唆された．2.3 節で述べた，サッカーの動作評価に関する研究では，関節角度や\nバックスイングの高さなどフォームの特徴の数値化や，ボール速度や動作の強度を判定す\nることが可能であることが示された．しかし「良いフォーム」を明確に定義したものは少\nなく，それを基準",
            "\nることが可能であることが示された．しかし「良いフォーム」を明確に定義したものは少\nなく，それを基準とした総合的なフォーム評価は十分に行われていない．さらに，評価結\n果を選手にフィードバックする仕組みの構築がされていないという課題があった．2.4 節\nでは，選手やコーチを支援するサポートシステムに関する研究を紹介した．これらのシス\nテムは主に選手の健康管理や戦術改善に重点を置いており，生体データや技術動作を解析\nすることでトレーニングを補助することができ，トレーニング内容や指導を補助すること\nが可能となる．これらのシステムはチームの活動のサポートには有効である一方で，選手\n個人の技術向上を直接的に支援する仕組みは考えられていない．\n以上のことから，本研究ではサッカー技能向上を目的としたサッカー動作のフォーム改\n善を支援するシステムを開発する．まず，選手に負担の少ない計測システムを構築すると\n18\nともに，サッカー動作を詳細に認識する．さらに正しいフォームを明確に定義し，その定\n義に基づいて動作を評価判定するアルゴリズムを確立する．また，本研究ではカメラを用\nいる手法に比べて利用環境への",
            "て動作を評価判定するアルゴリズムを確立する．また，本研究ではカメラを用\nいる手法に比べて利用環境への負担が少なく，選手に装着するだけで計測が可能なIMU\nセンサを採用することで，指導者がいない環境でも選手自身が効率的にトレーニングに取\nり組むことができるシステムを目指す．図2.9 に本研究の位置付けを示す．\n図2.9: 本研究の位置付け\n19\n第3章\nサッカースキルの向上支援の提案手法\n3.1\nサッカースキル向上支援の概要\n本節では，本研究で対象とするサッカースキル，正しいフォームの定義，定義をもとに\n設定した評価項目について説明する．\n3.1.1\n本研究で扱うサッカー動作\nサッカーには多くの重要なスキルが存在し，大きく分けると「オープンスキル」と「ク\nローズドスキル」の2 種類に分類される．図3.1 にサッカースキルの全体図を示す．\n「オー\nプンスキル」とは，外的要因によって変化する状況に適応する能力を指し，具体例として\nプレーの判断力や状況の把握能力などが挙げられる．一方，\n「クローズドスキル」とは，安\n定した環境下で決められた動作を再現する能力を指し，シュート，パス，ドリブルとい",
            "ズドスキル」とは，安\n定した環境下で決められた動作を再現する能力を指し，シュート，パス，ドリブルといっ\nた基本的なサッカースキルと呼ばれる技術がこれに該当する．サッカーのパフォーマンス\nを向上させるには，どちらのスキルも必要不可欠である．理想は，これらのスキルをバラ\nンスよく習得していくことが望ましいが，スキルの習得は年齢による影響を大きく受け\nる．JFA（日本サッカー協会）は，特に若年層においてクローズドスキルの習得を推奨し\nている[34]．これは，U-10～U-12 の年代が「ゴールデンエイジ」と呼ばれる，技術習得\nに最適な時期であるためである．この時期に身につけた基本技術は長期的に維持されやす\nい特徴がある．一方で，年齢が上がるにつれて練習内容がオープンスキル中心へ移行する\n傾向があり，技術の新たな習得や修正が比較的に困難になる．そのため，本研究では若年\n層における効率的な技術習得だけでなく，高年層の技術の習得・向上を支援することを目\n的として，クローズドスキルに着目する．\n図3.1: サッカースキルの全体図\n20\nサッカーにおけるクローズドスキルは，図3.1 が示すように多様な",
            "1: サッカースキルの全体図\n20\nサッカーにおけるクローズドスキルは，図3.1 が示すように多様なスキルが含まれる．\nこれらのスキルは全て重要であるが，特に「シュート」が試合結果やチームの成績に大き\nな影響を与えることが先行研究で明らかにされている．Bilek らは，2017-2018 シーズン\nのイングランド・プレミアリーグの試合データを分析し，試合結果および得点数に影響を\n与える要因を特定する研究を実施した[35]．分析の結果，枠内シュート数が多いほど得点\nの可能性が高まり，試合の勝率が向上する傾向が示された．また，Souza らは，2010 年か\nら2018 年のスペイン・ラ・リーガの試合データを分析し，シーズン終了時の勝ち点に影\n響を与える要因を調査した[36]．その結果，攻撃面ではシュート精度の高さ，守備面では\n相手チームのシュート機会を減らし，被シュートの精度を低下させることがチームの好成\n績に繋がる要因であると結論づけている．これらの研究結果からシュートが試合結果を左\n右する重要なスキルであることが分かる．本研究ではシュートフォームを評価する手法を\n提案し技能向上の支援",
            "する重要なスキルであることが分かる．本研究ではシュートフォームを評価する手法を\n提案し技能向上の支援を目指す．\n3.1.2\n正しいキックフォームの定義\nシュートフォームを評価するために，正しいキックフォームを定義する．まず，図3.2\nに示すキック動作における4 つの主要なポイントを明確に設定した上で，そのポイントを\n基準に3 つのフェーズとして分割し，正しいフォームを定義する．以下にキック動作にお\nける4 つの主要なポイントと本研究で各動作を識別するための基準を示す．\n1. アプローチ\nキックのためにボールに向かう一連の動作\n識別の基準：蹴り足がインパクト前に最後に地面に設置した状態\n2. バックスイング\n蹴り足を後ろに引く動作\n識別の基準：蹴り足が最も高い位置になった状態\n3. インパクト\n蹴り足をボールに接触する動作\n識別の基準：蹴り足がボールに接触した状態\n4. フォロースルー\n蹴り足をターゲットの方向に最後まで振り切る動作\n識別の基準：蹴り足が前方に伸び切った状態\n21\n図3.2: キック動作の4 つの主要なポイント\nこれらの4 つの主要ポイントを元にシュート動作を3 つのフェ",
            ": キック動作の4 つの主要なポイント\nこれらの4 つの主要ポイントを元にシュート動作を3 つのフェーズに分割し，各フェー\nズの正しいフォームを定義する．本研究では，既存の研究論文およびサッカー技術に関す\nる教本を参考に正しいフォームを定義をした．研究論文はキック動作をバイオメカニクス\nの観点で解析し，効果的な動作や身体の状態に関する知見がまとめられている[37]．また\n教本ではキックの種類やボールの質を決める要素，それを踏まえた実践的な正しいフォー\nムが画像付きで説明されている[38]．これらをもとに，各フェーズにおける正しいフォー\nムを以下の通りに定義する．\nバックスイングフェーズ（アプローチ～バックスイング）\n• 蹴り足：高い位置で十分に振りかぶっている\n• 軸足：ボールの真横または少し前に適切な距離で接地できている．\nインパクトフェーズ（バックスイング～インパクト）\n• 蹴り足：足首が最大限に伸展し，ぶれないように固定されている\n• インパクト位置：ボールの中心近くをインパクトできている\n• 軸足：ブレーキをかけるようにすねの角度を後ろに倒している\n• 上半身：後傾していない（",
            "きている\n• 軸足：ブレーキをかけるようにすねの角度を後ろに倒している\n• 上半身：後傾していない（前傾または直立）\nフォロースルーフェーズ（インパクト～フォロースルー）\n• 蹴り足：蹴り足を止めずに上ではなく前方に足を振り抜いている\n• 上半身：ターゲットの方向を向いている\n3.1.3\n本研究で扱う評価項目\n3.1.2 項で定義した正しいキックフォームを元に，本研究で扱うシュート動作の各フェー\nズの評価項目を設定した．これらの評価項目は，慣性計測装置を用いて計測可能であると\n判断したものを選定した．また，評価としてフォームの良し悪しを判定する方法と，具体\n22\n的な姿勢角度などを定量化する方法がある．良し悪しの基準が明確に定義されている動作\nについては判定を行い，基準が曖昧な動作については客観的な評価が可能となる数値で表\n現する．\n評価項目1: バックスイング\n十分に高い位置に蹴り足を運んでいるか\n評価項目2: フォロースルー\n蹴り足を上ではなく，前に振り抜くことができているか\n評価項目3: 軸足の傾き\nインパクト時に，ブレーキをかけるように軸足の脛の角度が後ろに倒れているか\n評価項",
            "目3: 軸足の傾き\nインパクト時に，ブレーキをかけるように軸足の脛の角度が後ろに倒れているか\n評価項目4: 上半身の傾き\nフォロースルー時に，上半身が後ろに倒れていないか\n3.2\n計測システムの開発\n本節は，シュート動作を計測するためのシステムについて説明する．本研究では選手の\n動作を計測する手段として，IMU（慣性計測装置）センサを採用する．アマチュア選手に\nとって，高精度なカメラシステムなどの高価なデバイスを利用することは現実的ではな\nく，また個人での利用を考慮した場合，カメラを用いた計測環境を構築するには多大な労\n力とコストがかかるという課題がある．これらの理由から本研究では，比較的安価である\nIMU センサを活用することにより，低コストかつ手軽に計測可能なシステムを構築する．\n3.2.1\n計測システムの開発\n計測システムの構成を図3.3 に示す．本研究では，シュート動作を計測するため，IMU\nセンサとしてSUUNTO 社のMovesense[39] を使用し，記録用デバイスとしてApple 社の\niPhone 15[40] を採用した計測システムを構築した．Movesense ",
            "Apple 社の\niPhone 15[40] を採用した計測システムを構築した．Movesense はスポーツおよび健康分野\n向けのセンサで，9 軸IMU センサによる加速度・角速度・地磁気の動作計測に加え，心\n拍センサによる心拍数や心拍間隔などの計測が可能である．本研究では，先行研究でも利\n用されていた加速度および角速度を，サンプリングレート100Hz で計測する．計測され\nた3 軸加速度および角速度データは，Bluetooth を通じて，iPhone に送信され，専用アプ\nリケーションによって記録される．このアプリケーションは，Google 社が提供するマル\nチプラットフォームフレームワークFlutter[41] を利用して開発した．\n23\n図3.3: 計測システムの構成図\n3.2.2\nセンサの装着位置\n本研究ではIMU センサの装着位置として，図3.4 に示す胸部および両足首（外果の上）\nを選定した．これは，3.1.3 項で設定した評価項目に基づいて，評価に必要なデータを取\n得することを目的としている．\nまず胸部への装着は，上半身の状態を計測する上で適した位置である．背部への装着",
            "ことを目的としている．\nまず胸部への装着は，上半身の状態を計測する上で適した位置である．背部への装着方\n法も検討したが，装着時に他者の補助を必要とする可能性が高く，1 人での使用には不向\nきであると判断した．一方，胸部への装着は自身で容易に装着することができ，日常的な\n練習や試合での実用性が高い．次に，両足首（外果の上）の装着は，足の動作を直接的に\n計測する上で適した位置である．特に外側に装着することでボールの接触リスクが低く，\n計測の不具合やセンサの故障を防ぐことができる．また，先行研究で提案されていたスパ\nイク内部や脛当てに装着するものに比べ，スパイクの種類やサイズに依存することがな\nく，専用のバンドで固定することによって，センサの安定性を確保しつつ，選手にとって\nストレスの少ない装着が可能となる．\n図3.4: （左）胸部の装着イメージ，\n（右）足首の装着イメージ\n3.3\n姿勢推定による動作評価手法\n3.3.1\n姿勢推定による動作評価手法の概要\n本研究では，シュートフォームの評価手法として，IMU センサによる姿勢推定を利用し\nた手法を提案する．両足首および胸部に装着したセンサの姿",
            "として，IMU センサによる姿勢推定を利用し\nた手法を提案する．両足首および胸部に装着したセンサの姿勢を推定することで，選手自\n24\n身の姿勢推定を実施し，3.1.3 項で設定した評価項目に基づいて，シュートのフォームを\n評価する．\n図3.7 に姿勢推定による動作評価手法の概要図を示す．まず計測したIMU センサデータ\nに適切な前処理を行い，センサの姿勢推定を実施する．次に，蹴り足の姿勢推定結果を用\nいて，シュートを構成する4 つの主要ポイント（アプローチ，バックスイング，インパク\nト，フォロースルー）を認識する．これらのポイントを明確に認識することで，シュート\nフォームを3 つのフェーズに分割し，各フェーズの評価項目に対応するセンサの姿勢情報\nを利用して選手のシュートフォームを評価する．\n図3.5: 姿勢推定による動作評価手法の概要図\n3.3.2\nセンサの姿勢推定処理\nセンサデータの姿勢推定の流れを図3.6 に示す．本項では姿勢推定までの各処理につい\nて説明する．\n25\n図3.6: センサの姿勢推定の流れ\nリサンプリング\n本研究で利用する計測システムでは，取得される加速度および角速度",
            "ンサの姿勢推定の流れ\nリサンプリング\n本研究で利用する計測システムでは，取得される加速度および角速度データは不等間隔\nで記録される．データを扱いやすくするため，等間隔データに変換するリサンプリング処\n理を実施した．リサンプリングには，計算効率と精度のバランスを考慮し，線形補間を採\n用した．線形補間の式を式3.1 に示す．この線形補間を適用することで，不等間隔データ\nを等間隔データに変換する．\nf(x) = f(x1) + f(x2) −f(x1)\nx2 −x1\n· (x −x1)\n(3.1)\nセンサキャリブレーション\nセンサには静止状態であっても一定のオフセットが存在し，測定値が実際の値からズレ\nる問題がみられた．これを補正するため以下の手順でバイアスキャリブレーションを実施\n26\nした．\n1. 静止状態の検出\nデータの差分値を計算し，一定の閾値以下である区間を静止状態と見なし，該当サ\nンプル数をカウントする．\n2. 静止時の平均値計算\n静止時の加速度および角速度データ（各軸）の平均値を算出する．\n3. バイアス補正\n算出された平均値およびセンサ装着方向を考慮した期待される値の差をバイ",
            "算出する．\n3. バイアス補正\n算出された平均値およびセンサ装着方向を考慮した期待される値の差をバイアスと\nみなし，計測値を補正する．\n平滑化処理\nセンサデータのノイズを低減する処理として，移動平均フィルタを適用する．移動平均\nフィルタは一定の範囲内のデータの平均を算出することで短期的な変動を抑え，滑らかな\nデータを得ることができる．移動平均フィルタの式を式3.2 に示す．本研究では移動平均\nフィルタのウィンドウサイズを3 に設定する．\nSsmoothed(t) = 1\nk\nk\n∑\ni=1\nS(t −i)\n(3.2)\n加速度センサおよび角速度センサの特性\n加速度センサは重力加速度を計測することにより，静的な環境におけるセンサの絶対的\nな姿勢を推定することが可能である．加速度センサによる姿勢推定の利点として，長時間\nにわたって安定した姿勢推定が可能という点が挙げられる．しかし，動きが激しい動的環\n境下における精度の低さが課題である．これは，運動時に伴う重力加速度以外の加速度の\n影響を大きく受けるため，短期的な動作や急激な姿勢変化に対応することが難しくなるた\nめである．\n一方，角速度センサ",
            "受けるため，短期的な動作や急激な姿勢変化に対応することが難しくなるた\nめである．\n一方，角速度センサは回転角速度を測定することで姿勢を推定することが可能である．\n角速度センサの利点として，短期的な姿勢変化に対して高い精度で姿勢推定が可能であ\nり，高速な動作や衝撃が伴う環境下でも比較的安定した姿勢推定ができるという点が挙げ\nられる．しかし，角速度センサによる姿勢推定では長期的な推定には適していないという\n課題がある．角速度センサの姿勢推定の仕組みとして，回転速度を時間積分し，過去の姿\n勢に対して回転の変化量を加算していくことで姿勢を推定する．この過程で発生した微小\nな誤差が継続的に蓄積していく「累積誤差（ドリフト）」という現象が生じてしまう．僅\nかな誤差であっても，長期的な時間の経過とともに誤差が積み重なり，最終的には実際の\n姿勢と大きく異なる推定となってしまう．\nセンサフュージョンの適用\n加速度センサと角速度センサはそれぞれ異なる特性を持ち，単独では姿勢推定において\n限界がある．本研究ではそれぞれのセンサの課題を補うセンサフュージョンの手法を適用\n27\nし精度の高い姿勢推定を実現する．",
            "はそれぞれのセンサの課題を補うセンサフュージョンの手法を適用\n27\nし精度の高い姿勢推定を実現する．代表的なセンサフュージョン手法として，相補フィル\nタを利用する．相補フィルタは，加速度センサと角速度センサのデータを統合し，それぞ\nれの弱点を補完する手法である．基本原理は，ローパスフィルタで加速度データの低周波\n成分を，ハイパスフィルタで角速度センサの高周波成分を抽出し，これらを組み合わせる\nことで，短期的な姿勢変化に追従しつつ，長期的な安定性を確保できる．フィルタの設計\nでは，ローパスフィルタとハイパスフィルタのゲインの和を1 とすることで，バランスを\n維持しつつ，位相遅れを抑えた安定した推定が可能である．相補フィルタの式を式3.3 に\n示す．重み付け係数α は，ジャイロセンサの信頼度を調整するパラメータであり，本研究\nでは0.9 に設定した．\nθ(t) = α · θgyro(t) + (1 −α) · θacc(t)\n(3.3)\n姿勢推定の補正\n相補フィルタによるセンサの姿勢結果より，前処理およびセンサフュージョン手法を用\nいた場合でも，累積誤差の影響を完全に除去することができず",
            "り，前処理およびセンサフュージョン手法を用\nいた場合でも，累積誤差の影響を完全に除去することができず，時間の経過とともに推定\n値が一方向に偏る傾向が見られた．この現象が発生すると，初期状態と同じ姿勢に戻った\n場合でも，異なる姿勢として推定される問題が生じる．本研究では，線形回帰を用いた補\n正手法を導入し，累積誤差による傾きを除去する処理を行う．まず，各姿勢データの傾向\nを線形回帰によってモデル化し，データ全体の傾きを求める．次に補正の適用に際し，時\n間の経過とともに補正量を大きくするため，時間を0 から1 に正規化した補正スケールを\n導入する．これにより，時系列の初期段階では補正を緩やかにし，時間の経過とともに補\n正を強める設計とした．最後に，線形回帰で求めた傾きと各時刻の補正スケールをもとに\n補正量を計算し，元のデータから差し引くことで累積誤差の影響を低減する．補正の式を\n式3.4 に示す．\nθcorrected(t) = θ(t) −mθ · t · Scorr(t)\n(3.4)\nここで，θcorrected(t) は補正後の推定角度（ロール・ピッチ・ヨーのいずれか），θ(t) は",
            "こで，θcorrected(t) は補正後の推定角度（ロール・ピッチ・ヨーのいずれか），θ(t) は補\n正前の推定角度を表す．また，mθ は累積誤差の傾向を示す線形回帰によって求めた傾き\nであり，時間の経過に伴う推定値の偏りを示す．さらに，t は時刻データ，Scorr(t) は補正\nスケールを表し，時間の経過とともに補正量が大きくなるよう設計されている．図3.7 に\n補正前および補正後の姿勢推定の結果を示す．\n28\n図3.7: （左）補正前の姿勢推定結果と回帰直線，\n（右）補正後の姿勢推定結果\n3.3.3\nシュート動作の主要ポイントの認識\nシュート動作における4 つの主要ポイントを認識する手法としてセンサの姿勢推定結果\nを利用する．本研究では，蹴り足に装着したセンサの進行方向に対する前後の姿勢推定を\n利用する．この回転軸は，足の側面を通るような回転軸の回転角度を示す．\n29\nバックスイングの認識\nバックスイングは蹴り足が最も高い状態である．足の側面を通るような回転軸を考慮す\nると，バックスイング時は特定の方向に最大の回転をすると考えられる．姿勢推定結果の\n最低値がバックスイングのポイン",
            "スイング時は特定の方向に最大の回転をすると考えられる．姿勢推定結果の\n最低値がバックスイングのポイントにあたる．推定結果から最低値を検出することでバッ\nクスイングを認識する．\nフォロースルーの認識\nフォロースルーは蹴り足が最も前方にある状態となる．足の側面を通るような回転軸を\n考慮すると，フォロースルー時はバックスイングとは逆方向に最大の回転をすると考えら\nれる．姿勢推定結果より，最大値がフォロースルーのポイントにあたる．推定結果から最\n大値を検出することでフォロースルーを認識する．\nインパクトの認識\nインパクトの前後で蹴り足の傾きに着目すると，インパクト前は蹴り足がバックスイン\nグと同様であり，インパクト後はフォロースルーと同様の傾きになる．そこでインパクト\nの認識は，蹴り足の姿勢推定の値の正負が切り替わるポイントであると考えられる．本研\n究では，バックスイングからフォロースルーにかけて，最後のマイナスであるサンプルを\n検出することでインパクトを認識する．\nアプローチの認識\n本研究で定義したアプローチのポイントは蹴り足がインパクト前に最後に地面に接地し\nている状態であり，直立している",
            "義したアプローチのポイントは蹴り足がインパクト前に最後に地面に接地し\nている状態であり，直立している時の足の状態と近い．姿勢推定結果より，アプローチの\nポイントは回転がほぼゼロに近い状態であるポイントとなる．ランニングの動作はバック\nスイングのように足が後ろにある状態と地面に接している状態を繰り返すことになる．足\nが後ろにある状態はバックスイングと同様に負の値を示し，地面に接している状態は直立\n状態に近いため0 に近い値を示していることがわかる．本研究で定義したアプローチのポ\nイントはインパクト前に蹴り足が最後に地面に接しているポイントである．そこでバック\nスイングから遡って，最初に0 に近いピークを示したポイントをアプローチのポイントと\nして認識することができる．\n以上の説明をまとめると，各ポイントはそれぞれ特徴的な姿勢推定の結果をもとに認識\nすることができる．図??に姿勢推定の結果に基づいた各ポイントの認識の例を示す．\n30\n図3.8\n3.3.4\n姿勢推定手法によるシュートフォーム評価\n本項では，3.1.3 項で設定した評価項目をセンサの姿勢推定によって評価する方法を述\nべる．表3",
            "価\n本項では，3.1.3 項で設定した評価項目をセンサの姿勢推定によって評価する方法を述\nべる．表3.1 に各評価項目について，対象となるセンサと判定のタイミングを示す．\n評価項目1「バックスイング」および評価項目2「フォロースルー」については，蹴り\n足に装着したセンサの姿勢推定結果を基に，バックスイング時およびフォロースルー時\nの角度を回帰的に求め，これらの角度をもとに評価を行う．一方で評価項目3「軸足の傾\nき」および評価項目4「上半身の傾き」については，蹴り足センサが認識した各ポイント\n（インパクトやフォロースルー）における，軸足および胸部のセンサの姿勢推定から姿勢\n状態を確認し，それぞれの良し悪しを分類的に評価する．具体的な判定方法は，評価項目\n3「軸足の傾き」はインパクト時に0 °以下の場合は「良」，0 °より上の場合は「悪」と\n判定し，評価項目4「上半身の傾き」はフォロースルー時に0 °以上の場合は「良」，0 °\nより未満の場合は「悪」と判定する．\n31\n表3.1: 評価項目の判定タイミングと使用センサ\n評価項目\n判定タイミング\n使用センサ\nバックスイング\nバックスイング時\n",
            "判定タイミングと使用センサ\n評価項目\n判定タイミング\n使用センサ\nバックスイング\nバックスイング時\n蹴り足\nフォロースルー\nフォロースルー時\n蹴り足\n軸足の傾き\nインパクト時\n軸足\n上半身の傾き\nフォロースルー時\n胸部\n3.4\n機械学習による動作評価手法\n3.4.1\n機械学習による動作評価手法の概要\n本研究では，3.3 節で紹介した姿勢推定による評価手法の比較検証として，機械学習を\n用いた評価手法を提案する．先行研究では，動作の分類や熟練度の判別手法として機械学\n習が広く活用されており，その結果，多様な動作パターンを学習し，高精度な識別が可能\nであることが示されている．これを踏まえ，本研究では機械学習手法をシュート動作の評\n価に応用できるかを検証する．\n図3.9 に機械学習による動作評価手法の概要図を示す．まず計測したIMU センサデータ\nからシュート動作をセグメントし，機械学習に利用する特徴量を抽出する．特徴量の抽出\nに際しては，統計データを抽出した上で，主成分分析（PCA）を用いて次元削減を実施す\nる．最後に機械学習による分類によってシュートフォームの良し悪しを判別をすることで\n動",
            "元削減を実施す\nる．最後に機械学習による分類によってシュートフォームの良し悪しを判別をすることで\n動作を評価する．\n図3.9: 機械学習による動作評価手法の概要図\n32\n3.4.2\nセグメンテーション手法\n計測した時系列データには，助走を行う前やキックを行った後などの評価範囲外の不要\nなデータが含まれる．そのため，時系列データからキックを行った部分のみを抜き出す必\n要がある．そこで時系列データからキックイベントを検出し，セグメントすることで抽出\nする．\n本研究ではセグメンテーション手法としてインパクトを基準にセグメントを実施する．\nインパクトは蹴り足とボールが接触する瞬間の動作を指す．この動作の特徴として，蹴り\n足はインパクトにかけて加速し，ボールに接触した後は急激に減速する．この加速と減速\nの特性は加速度データにも反映され，特徴的なピークとして現れると考えられる．本研究\nでは適切な前処理によって加速度データからインパクトを検出する．インパクト検出の流\nれを図3.10 に示す．\n図3.10: インパクト検出フロー\n33\nインパクト検出のための前処理\n最初に加速度データから重力加速度成分",
            "0: インパクト検出フロー\n33\nインパクト検出のための前処理\n最初に加速度データから重力加速度成分を取り除き，キック動作に起因する加速度成分\nのみを抽出する．本研究の計測システムのセンサデータは不等間隔であるため，まず線形\n補間を用いて100Hz の等間隔データにリサンプリングする．その後，高速フーリエ変換\n（FFT）を適用し，0.5Hz 以下の低周波成分を削除することで重力加速度成分を除去した．\n次に，3 軸加速度データを統合し，運動の方向に依存しない単純な運動の強度を抽出す\nる．これは3 軸加速度データのノルムを計算する．ノルムは式（3.5）によって算出する．\nnorm =\n√\nx2 + y2 + z2\n(3.5)\n次に，移動平均フィルタを用いてノルムデータを平滑化し，ノイズを除去する．この処\n理によって加速度データの特徴的なピークを明確化する．本研究では移動平均フィルタの\nウィンドウサイズを10 に設定した．平滑化したデータは式（3.6）によって算出する．\nSt = 1\nk\nk\n∑\ni=1\nnorm(t −i)\n(3.6)\nセグメンテーション\n最後に平滑化したノルムデータを基に",
            "∑\ni=1\nnorm(t −i)\n(3.6)\nセグメンテーション\n最後に平滑化したノルムデータを基に，インパクトをノルムデータの最大値として検出\nする．検出したインパクトを基準とし，インパクト前1.5 秒，インパクト後0.5 秒の範囲\nをセグメントすることで抽出する．この時間範囲は，映像データをもとに算出し，シュー\nト動作の前後の動きを十分に含むように設定した．動作の始まりから終わりまでを適切に\nカバーすることで，シュート動作の特徴を十分に捉えられるようにした．\n3.4.3\n特徴量の抽出\nセグメント化されたデータを基に，機械学習の入力データとして適切な特徴量を抽出す\nる．統計的な特徴量として，3 軸加速度および3 軸角速度の各軸から最大値，最小値，標\n準偏差，平均値，中央値，範囲（最大値-最小値），尖度，歪度の8 種類を算出する．数\n値解析ソフトウェアであるMATLAB[42] を用いて，合計48 個の特徴量を抽出したデータ\nセットを作成した．\n抽出した特徴量の次元が高い場合，機械学習モデルに対して，過学習を引き起こす可能\n性がある．特徴量の数が増えるとモデルの複雑性が増し，学習データ",
            "デルに対して，過学習を引き起こす可能\n性がある．特徴量の数が増えるとモデルの複雑性が増し，学習データへの適合度が過剰に\n高くなり，新しいデータに対する分類精度が低下するリスクが生じる．そこで，本研究で\nは主成分分析（PCA）を用いた次元削減を行い，データの分散を保持しつつ，不要な特徴\n量を削減することで，モデルの汎化性能向上を図る．具体的には，累積寄与率が95%を\n保持しつつ，主成分を選択することで，情報の損失を抑えながら，次元圧縮を行う．\n3.4.4\n機械学習手法によるシュートフォーム評価\n本研究では，シュートフォームを評価するために，回帰モデルと分類モデルを構築し，\n比較検証を実施する．評価項目1「バックスイング」と評価項目2「フォロースルー」に\n34\nついては具体的な角度を推定するため，回帰モデル構築し，評価を行う．本研究では，線\n形回帰（Liner Regression），ランダムフォレスト回帰（Random Forest Regression），サ\nポートベクター回帰（SVR，Support Vector Regression），k 近傍回帰（k-Nearest Neighb",
            "Support Vector Regression），k 近傍回帰（k-Nearest Neighbors\nRegression, k-NNR）の4 種類を用いて比較検証を実施する．評価項目3「軸足の傾き」，\n評価項目4「上半身の傾き」については，フォームの良し悪しを判定するため，分類モデ\nルを構築することで評価を行う．本研究では，ランダムフォレスト（Random Forest），サ\nポートベクターマシン（SVM，Support Vector Machine），k 近傍法（k-Nearest Neighbors,\nk-NN），ナイーブベイズ（Naive Bayes）の5 種類の分類器を用いて比較検証を実施する．\n35\n第4章\n提案手法の検証実験\n4.1\nデータ収集実験\n本節は，第3 章で提案したシュートフォームの評価手法の検証するために実施したデー\nタ収集実験とその結果について説明する．\n実験担当者は，臨床研究に携わる人のe ラーニングサイト「ICR 臨床研究入門」にて，\n「研究倫理と被験者保護」および「人を対象とする医学系研究に関する倫理指針」を履修\nしている．また，本実験は，青山学",
            "験者保護」および「人を対象とする医学系研究に関する倫理指針」を履修\nしている．また，本実験は，青山学院大学理工学部ライフサイエンス委員会の「人に係る\n研究」に関する審査・承認を受け実施され（承認番号H20-S10-2），被験者は実験説明を\n受け，実験に対する同意書による同意をもって，実験に参加頂いている．\n4.1.1\n実験目的\n本実験の目的は，第3 章で提案したシュートフォームの評価手法を検証するためのデー\nタを収集することである．現役のサッカー選手のシュート動作を対象にデータを取得し，\n収集したデータを基に評価精度を検証することで提案手法の有効性を評価する．\n4.1.2\n被験者\n本実験は，青山学院大学男子サッカー部に所属する現役選手18 名を被験者として実施し\nた．被験者は平均身長171.5 ± 11.5 cm，平均体重63.0 ± 12 kg，全員がサッカー歴10 年以\n上の経験を有している．また，被験者の利き足は右利きが15 名，左利きが3 名であった．\n4.1.3\n実験方法\n本実験はサッカー部が日常的に利用している人工芝グラウンドで実施した．計測には3.2\n節で述べた計測システ",
            "験はサッカー部が日常的に利用している人工芝グラウンドで実施した．計測には3.2\n節で述べた計測システムで動作を計測するとともに，カメラを被験者の後方および被験者\nの利き足側に設置することで，シュート動作全体を撮影する．この撮影データを基に正解\nデータとしてラベリングを実施し，提案手法の精度を検証する．\n被験者にはゴールに対して正面の位置を初期位置として，静止した状態のボールに対し\nてシュート動作を開始してもらった．計測システムの操作は実験担当者が行い，各被験\n者に対して5 回ずつ繰り返して計測した．計測中にセンサとシステムの切断が確認され\nた場合は，追加で計測を実施した．また，被験者には特別な指示を与えず，自然な動作で\nシュートを蹴るように求めた．本研究の実験環境を図4.1 に示す．\n36\n図4.1: 実験の概要図\n4.1.4\nデータ収集実験の結果\n本実験の結果として，途中で通信が切断してしまったものも含めて，合計で102 回の計\n測を実施した．計測データを確認した結果，一部のデータにおいて，図4.2 に示すように\n途切れているデータが確認された．このようなデータは検証に使用できないた",
            "いて，図4.2 に示すように\n途切れているデータが確認された．このようなデータは検証に使用できないため除外対象\nとした．各センサで有効と判断されたデータ数を表4.1 に示す．\n胸部および左足に装着したセンサデータは比較的安定した計測が可能であった．一方で，\n右足のセンサデータは通信が途切れやすい傾向が見られた．この要因として，右足が蹴り\n足として大きな動作を伴うため，センサに加わる動作負荷が影響した可能性が考えられ\nる．また，センサデータを受信するスマートフォンの位置が蹴り足とは反対側となること\nが多かったため，通信距離が長くなったことも要因の1 つとなった可能性がある．\n37\n図4.2: 除外対象としたデータ例\n表4.1: 各センサで有効と判断されたデータ数\nセンサ部位\n有効データ数\n左足\n88\n胸部\n93\n右足\n93\n4.2\nラベリング方法\nデータ収集実験で取得したデータのラベル付けには，スポーツ解析を目的とした運動解\n析ソフトウェアのKinovea[43] を用いた．Kinovea は撮影した映像をインポートすること\nで，距離，角度，速度の計測，軌跡を描画する機能など運動の動作解",
            " は撮影した映像をインポートすること\nで，距離，角度，速度の計測，軌跡を描画する機能など運動の動作解析に特化した機能を\n利用することができる．図4.3 にKinovea の利用画面を示す．本研究では，設定した評価\n項目に関連する足の角度や上半身の傾きに関するラベリングを実施した．ラベリングの項\n目を表4.2 に示す．\n表4.2: ラベリングの項目\nラベリング項目\n取得データ\nバックスイング\n蹴り足の角度\nフォロースルー\n蹴り足の角度\n軸足の傾き\n軸足が前傾しているか/ していないか\n胸の姿勢\n胸部が前傾しているか/ していないか\n38\n図4.3: Kinovea（[43] から引用）\n4.3\n評価精度検証方法\n4.3.1\n姿勢推定手法の検証方法\nIMU センサを用いた姿勢推定手法の精度を検証するため，数値データを用いた誤差の\n評価と分類ラベルの一致率による評価の2 種類の方法を採用する．蹴り足の角度のように\n連続値を持つデータに対しては，推定値とラベリング結果の誤差を平均絶対誤差（MAE）\nおよび平均絶対誤差率（MAPE）を用いて算出し，推定精度を評価する．一方，軸足の傾\nきや上半身の",
            "）\nおよび平均絶対誤差率（MAPE）を用いて算出し，推定精度を評価する．一方，軸足の傾\nきや上半身の方向のようにカテゴリ分類が必要なデータに対しては，推定値とラベルの一\n致率を指標として評価を行う．バックスイングとフォロースルーの検証では，蹴り足の角\n度に関する数値データを用い，MAE およびMAPE を算出して誤差の大きさを評価する．\nインパクト時の軸足の傾き，上半身の傾き，上半身の方向の検証では，姿勢推定による分\n類結果とラベリング結果を比較し，一致率を求めることで精度を評価する．これらの手法\nを用いて，IMU センサを活用した姿勢推定の妥当性を検証する．\nIMU センサを用いた姿勢推定手法の精度を検証する方法として，回帰的な誤差評価と\n分類的な一致率評価の2 種類で検証する．バックスイングやフォロースルーの蹴り足の角\n度に関しては，推定値とラベリング結果の誤差を平均絶対誤差（MAE）および平均絶対\n誤差率（MAPE）を用いて算出し，回帰的な手法で推定精度を評価する．一方，インパク\nト時の軸足の傾きやフォロースルー時の上半身の傾きについては，姿勢推定による分類結\n果とラベリング結果",
            "ト時の軸足の傾きやフォロースルー時の上半身の傾きについては，姿勢推定による分類結\n果とラベリング結果の一致率を指標とし，分類的な手法で精度を評価する．これらの手法\nを用いて，IMU センサを活用した姿勢推定の妥当性を検証する．\n39\n4.3.2\n機械学習手法の検証方法\n本研究では，3.4 節で紹介した機械学習手法を用いて回帰モデルと分類モデルの両方を\n構築し，動作評価の精度を検証する．回帰モデルの検証は，姿勢推定手法の検証方法と同\n様に平均絶対誤差（MAE）および平均絶対誤差率（MAPE）を用いて算出し，推定精度\nを評価する．一方で分類モデルは，収集実験で得られたデータ数が限られているため，1\n人抜き交差検証（Leave-One-Subject-Out Cross-Validation, LOSO-CV) を適用し，適合率，\n再現率，F1 スコアを算出し，各モデルの性能を比較する．1 人抜き交差検証は，全被験者\nのデータから，1 人分をテストデータとして除外し，残りの被験者データを用いて学習を\n行い，学習後に除外した被験者のデータを用いて，モデルの性能を検証する手法である．\nこのプロセ",
            "学習を\n行い，学習後に除外した被験者のデータを用いて，モデルの性能を検証する手法である．\nこのプロセスを被験者の数だけ繰り返し，最終的に全ての被験者に対する各モデルの性能\nを比較する．これにより，個人差の影響を考慮しつつ，異なる被験者に対しても適用可能\nなモデルの精度を評価する．\n40\n第5章\n提案手法の検証結果と考察\n5.1\n姿勢推定による動作評価手法の結果と考察\n5.1.1\n姿勢推定による動作評価手法の結果\n評価項目1「バックスイング」および評価項目2「フォロースルー」の検証結果\nIMU センサを用いた姿勢推定による動作評価手法の精度を検証するため，評価項目1\n「バックスイング」および評価項目2「フォロースルー」は推定結果とラベリング結果の\n平均絶対誤差（MAE）および平均絶対誤差率（MAPE）を指標として検証した．検証結\n果を表5.1 に示す．\n表5.1: 評価項目1「バックスイング」および評価項目2「フォロースルー」に関する姿勢\n推定による評価精度\n評価項目\nMAE（°）\nMAPE（%）\n十分なバックスイング\n17.5\n14.0\nフォロースルーの前方への動き\n13.5\n25.2",
            "E（%）\n十分なバックスイング\n17.5\n14.0\nフォロースルーの前方への動き\n13.5\n25.2\nMAE は，推定値と正解値の絶対誤差の平均を示し，数値が小さいほど推定値が実際の\n値に近いことを意味する．一方，MAPE は誤差を正解値に対する割合で示し，相対的な誤\n差の大きさを評価する指標である．バックスイングの結果はMAE=17.5°，MAPE=14.0%，\nフォロースルーの結果はMAE=13.5 °，MAPE=25.2%であった．これにより，バックスイ\nングよりもフォロースルーの方が推定誤差は小さいものの，相対誤差（MAPE）は大きく，\n動作ごとのばらつきの影響を受けている可能性が示唆された．精度の観点では，バックス\nイングは一定の精度を保っているが，フォロースルーでは個人差や姿勢推定の誤差が相対\n的に大きくなる傾向が見られた．\n評価項目3「軸足の傾き」および評価項目4「上半身の傾き」の検証結果\n評価項目3「軸足の傾き」および評価項目4「上半身の傾き」は推定結果とラベリング\n結果の一致率を指標として検証した．検証結果を表5.2 に示す．\n表5.2: 軸足の傾きおよび上半身の評価",
            "の一致率を指標として検証した．検証結果を表5.2 に示す．\n表5.2: 軸足の傾きおよび上半身の評価精度\n評価項目\n一致率（%）\nインパクト時の軸足の傾き\n67.0\nフォロースルー時の上半身の傾き\n44.0\n41\n5.1.2\n姿勢推定による動作評価手法の考察\nバックスイングとフォロースルーの回帰的な評価には，IMU センサによる姿勢推定の結\n果をそのまま利用しているため，正確な評価には一定以上の姿勢推定精度が求められる．\nしかし，バックスイングやフォロースルーのように大きな角度変化を伴う動作では，IMU\nセンサの特性上，姿勢推定時の積分計算による累積誤差の影響を受けやすい．特に，バッ\nクスイングのMAPE が14%と比較的低い値で収まっているのに対し，フォロースルーは\n20%以上と高い誤差を示しており，フォロースルーの方が動作として激しく，姿勢推定誤\n差が大きくなっている可能性が考えられる．また，シュート動作の流れとしてフォロース\nルーはバックスイングよりも後の動作であり，順番的に累積誤差が蓄積されることで，誤\n差がより大きくなった可能性もある．この課題に対処する方法としては，現在用い",
            "差が蓄積されることで，誤\n差がより大きくなった可能性もある．この課題に対処する方法としては，現在用いている\n相補フィルタ以外のセンサフュージョン技術を導入し，姿勢推定アルゴリズムを改良する\nことで累積誤差を低減することが考えられる．また，より多くのデータを収集し，実際の\n値との誤差を統計的に分析することで，誤差の傾向を明らかにし，それを考慮した補正を\n加えることで評価システムとしての実用性を向上させることが可能である．\n軸足の傾きや上半身の傾きの分類的な評価においては，いずれも高い精度を達成するこ\nとはできなかった．精度が低下した要因としては，先述のバックスイングとフォロース\nルーと同様にIMU センサの姿勢推定の精度自体が十分でないため，評価方法として0 °以\n上を「良」，0 °未満を「悪」のように単純な閾値設定をした場合，誤った判定結果になっ\nてしまう可能性が考えられる．この課題に対する対処法として，姿勢推定の誤差を考慮し\nた閾値の設定を行うことが必要である．誤差がマイナス方向に生じてしまう場合は，閾値\nを低めに設定するなど，姿勢推定の誤差の傾向を考慮した閾値設定を導入することで，",
            "てしまう場合は，閾値\nを低めに設定するなど，姿勢推定の誤差の傾向を考慮した閾値設定を導入することで，よ\nり安定した評価が可能になると考えられる．\n5.2\n機械学習による動作評価手法の結果と考察\n5.2.1\n機械学習による動作評価手法の結果\n評価項目1：バックスイング\n表5.3 に評価項目1「バックスイング」の回帰モデルによる推定結果を示す．最も精度\nが高かったのはランダムフォレスト（MAE = 8.6 °, MAPE = 6.8%）であり，最も精度が\n低かったのは線形回帰（MAE = 11.1 °, MAPE = 9.1%）であった．\n表5.3: 評価項目1「バックスイング」の評価精度結果\nModel\nMAE（°）\nMAPE（%）\nLinear Regression\n11.1\n9.1\nRandom Forest\n8.6\n6.8\nSVR\n9.0\n7.0\nk-NN\n8.8\n7.0\n42\n評価項目3：フォロースルー\n表5.4 に「フォロースルーの前方への動き」の回帰モデルによる推定結果を示す．最も\n精度が高かったのはランダムフォレスト（MAE = 5.9 °, MAPE = 11.7%）であ",
            "最も\n精度が高かったのはランダムフォレスト（MAE = 5.9 °, MAPE = 11.7%）であり，最も精\n度が低かったのは線形回帰（MAE = 8.2 °, MAPE = 17.4%）であった．\n表5.4: 評価項目3「フォロースルー」の評価精度結果\nModel\nMAE（°）\nMAPE（%）\nLinear Regression\n8.3\n17.4\nRandom Forest\n5.9\n11.7\nSVR\n6.3\n12.4\nk-NN\n6.7\n13.1\n評価項目2：軸足の傾き\n表5.5 に「軸足の傾き」の機械学習による評価精度の結果を示す．ナイーブベイズが適\n合率81.1%，再現率81.3%，F1 スコア81.1%という最も高い精度を達成した．その他のモ\nデルも比較的高い評価精度を示したが，サポートベクターマシンはF1 スコア71.1%と他\nの手法に比べてやや低い結果となった．\n表5.5: 評価項目2「インパクト時の軸足の傾き」の評価精度結果\nModel\nPrecision[%]\nRecall[%]\nF1 score[%]\nRandom Forest\n76.7\n78.9\n76.7\nSupp",
            "l[%]\nF1 score[%]\nRandom Forest\n76.7\n78.9\n76.7\nSupport Vector Machine\n71.1\n81.8\n71.1\nk-Nearest Neighbor\n72.2\n79.5\n72.2\nNaive Bayes\n81.1\n81.3\n81.1\n評価項目4：上半身の傾き\n表5.6 に「上半身の傾き」の機械学習による評価精度の結果を示す．k 近傍法（k-Nearest\nNeighbor, k-NN）が適合率87.4%，再現率73.6%，F1 スコア77.4%という最も高い精度を\n達成した．その他のモデルも比較的高い評価精度を示したが，ナイーブベイズはF1 スコ\nア69.6% と他の手法に比べてやや低い結果となった．\n表5.6: 評価項目4「上半身の傾き」の評価精度結果\nModel\nPrecision[%]\nRecall[%]\nF1 score[%]\nRandom Forest\n83.7\n71.7\n73.3\nSupport Vector Machine\n84.1\n71.4\n74.3\nk-Nearest Neighbor\n87.4\n73.6\n77.",
            "ne\n84.1\n71.4\n74.3\nk-Nearest Neighbor\n87.4\n73.6\n77.4\nNaive Bayes\n81.5\n65.0\n69.6\n43\n5.2.2\n機械学習による動作評価手法の考察\nバックスイングおよびフォロースルーの評価精度は，どちらもランダムフォレストが\n最も精度が高く，線形回帰が最も低い精度となった．この結果は，バックスイングとフォ\nロースルーの動作が単純な線形関係で表現できないことを示している．これらの動作は複\n数の関節が連動して行われるため，線形回帰のような単純なモデルでは適切に学習するこ\nとが難しいと考えられる．一方で，ランダムフォレストのような非線形な関係を捉えられ\nるモデルは特徴量間の相互作用を考慮できるため，高い精度を示したと考えられる．\n軸足の傾きの評価精度はナイーブベイズが最も精度が高かった．ナイーブベイスの混同\n行列を図5.1 に示す．\n「軸足の傾きが適切である」と分類すべきデータ（クラス0）につい\nて，69 件中66 件を正しく分類しており，高い識別精度を持つことがわかる．しかし，\n「軸\n足の傾きが適切でない」とすべきデータ（クラス",
            "ており，高い識別精度を持つことがわかる．しかし，\n「軸\n足の傾きが適切でない」とすべきデータ（クラス1）については，16 件中14 件が誤分類さ\nれ，適切である（クラス0）と判定されてしまった．この誤分類の要因として，学習デー\nタの中でクラス1 のサンプル数が少なく，モデルがクラス0 に偏った学習をしてしまった．\n可能性が考えられる．その結果，適切でない軸足の傾きを正しき識別する精度が低下した\nと考えられる．\n図5.1: 「軸足の傾き」に対するナイーブベイズによる混同行列\n上半身の評価精度はk 近傍法が最も精度が高かった．k 近傍法の混同行列を図5.2 に示\nす．結果を確認すると，k 近傍法はクラス0（適切な上半身の傾き）について，66 件中57\n件を正しく判定している．しかし，クラス1（不適切な上半身の傾き）の識別精度は低く，\n44\n27 件のうち16 件が誤分類されており，誤判定が多数を占める結果となった．これは，ク\nラス1 のサンプル数が少なく，データサンプルに偏りがあるため，モデルがクラス0 に\n偏った学習が考えられる．\n図5.2: 「上半身の傾き」に対するk 近傍法の混同行列",
            "ルがクラス0 に\n偏った学習が考えられる．\n図5.2: 「上半身の傾き」に対するk 近傍法の混同行列\n45\n第6章\n結論と今後の展望\n6.1\n結論\n本研究では，IMU センサを用いたサッカーのシュートフォーム自動評価手法を提案し，\n姿勢推定手法と機械学習手法を比較・検証した．姿勢推定手法はシュート動作の主要フェー\nズを正確に識別し，フォームの特徴を解析することに有用である一方で，一部の姿勢推定\nに誤差が生じた．一方，機械学習手法は時系列データから適切な特徴量を抽出し，フォー\nムの良否を高精度で識別できることが確認された．これらの結果から，機械学習手法が評\n価精度の面で優れていること，姿勢推定手法が動作の分節や詳細なフォーム解析に有効で\nあることが示された．\nまた，本研究では現役のサッカー選手を対象にデータ収集を行ったが，対象者の範囲が\n限定されていたため，モデルの汎用性向上のためにはさらなるデータ収集が必要である．\nさらに，姿勢推定手法の評価精度を向上させるためには，アルゴリズムの改良やセンサの\n装着位置の最適化が求められる．\n6.2\n今後の展望\n本研究で提案したシュートフォーム評価手",
            "センサの\n装着位置の最適化が求められる．\n6.2\n今後の展望\n本研究で提案したシュートフォーム評価手法をより実用的なシステムへと発展させるた\nめには，いくつかの課題を解決する必要がある．まず，データ収集の多様化が挙げられる．\n本研究では主に現役選手を対象にデータを取得したが，より多様な選手の動作データを収\n集することで，モデルの一般化能力を向上させることが可能となる．特に，初心者やプロ\n選手を含めたデータを取得することで，技術レベルごとのフォームの違いをより詳細に分\n析できる．また，試合環境下でのデータ収集を行うことで，より実践的なフォーム評価の\n精度を検証し，実際のプレーシーンでの適用可能性を高めることが重要である．\n次に，姿勢推定手法の精度向上が求められる．本研究では，IMU センサを用いた姿勢\n推定において，相補フィルタを適用することで動作の認識を行ったが，一部の姿勢推定に\n誤差が生じる課題があった．今後は，姿勢推定アルゴリズムの改良を行い，IMU データ\nからの角度推定精度を向上させるとともに，センサの装着位置の最適化を進めることで，\n測定誤差を低減する必要がある．例えば，異な",
            "させるとともに，センサの装着位置の最適化を進めることで，\n測定誤差を低減する必要がある．例えば，異なる身体部位にセンサを装着することで，よ\nり正確な姿勢情報を取得し，動作解析の精度を向上させることが考えられる．\nさらに，機械学習手法の高度化も今後の重要な課題となる．本研究では，時系列デー\nタから特徴量を抽出し，フォーム評価モデルを構築したが，より精度の高い識別を実現\nするためには，追加の動作特徴を抽出し，学習モデルの最適化を行う必要がある．特に，\nLSTM やTransformer などの深層学習モデルを導入することで，時系列データの複雑なパ\nターンを捉え，より高精度なフォーム識別が可能となると考えられる．また，従来の閾値\n判定手法と組み合わせることで，定量的な評価と機械学習による柔軟な識別を両立させる\n46\nことも有効である．\n本研究の成果を実際のトレーニング環境で活用するためには，リアルタイムフィード\nバックシステムの開発も重要である．選手が自身のフォームを即座に確認し，修正できる\nシステムを構築することで，より効果的な技能向上が可能となる．例えば，スマートフォ\nンやタブレットを用",
            "システムを構築することで，より効果的な技能向上が可能となる．例えば，スマートフォ\nンやタブレットを用いたアプリケーションを開発し，選手にリアルタイムでフォームの\nフィードバックを提供する仕組みを導入することが考えられる．さらに，音声や振動を用\nいた直感的なフィードバック機能を追加することで，選手が瞬時にフォームの改善点を認\n識し，修正できるようになる．\n加えて，本研究で提案したフォーム評価手法をサッカーの他の動作にも応用することが\n期待される．シュート動作だけでなく，ドリブルやパス，ヘディングといった動作にも適\n用することで，総合的なスキル向上支援システムの構築が可能となる．また，コーチング\n支援機能を強化し，選手ごとの課題点や改善方法を具体的に提示できるシステムを開発す\nることで，指導者の負担軽減やトレーニングの効率化にも寄与することができる．\n本研究の成果をもとに，今後はIMU センサを活用したフォーム評価技術の発展を促進\nし，サッカー選手の技術向上を支援する実用的なシステムの構築を目指す．\n47\n謝辞\n本研究はJSPS 科研費JP22K11998 の助成を受け, 実施されました．",
            "目指す．\n47\n謝辞\n本研究はJSPS 科研費JP22K11998 の助成を受け, 実施されました．\n本研究を遂行するにあたり，青山学院大学理工学部情報テクノロジー学科ロペズ・ギヨー\nム教授に深く感謝申し上げます．先生のもとで研究に取り組むことができたからこそ，最\n後までやり遂げることができたと感じています．約4 年間に渡り，研究についてご助言い\nただき，また多くの学びの機会を与えてくださったことに，改めて御礼申し上げます．研\n究補助員の大熊ちひろ様には，研究室の環境整備やTA などの事務手続きにおいて，多大\nなサポートをしていただきました．研究に専念できる寛容を整えてくださったことに，深\nく感謝いたします．本研究の実験にご協力いただいた青山学院大学サッカー部の選手の皆\n様，監督，コーチの皆様にも厚く御礼申し上げます．お忙しい中，実験のための環境をご\n提供いただき，貴重なデータ収集にご協力いただいたことに，心より感謝申し上げます．\n最後に，これまで支えてくれた家族に，心から感謝いたします．常に温かく見守り，励\nましてくれたおかげで，ここまで研究を続けることができました．\n2025 年1",
            "．常に温かく見守り，励\nましてくれたおかげで，ここまで研究を続けることができました．\n2025 年1 月31 日\n平井龍彦\n48\n参考文献\n[1] WorldAtlas. The most popular sports in the world. https://www.worldatlas.\ncom/articles/what-are-the-most-popular-sports-in-the-world.\nhtml. (参照日2024/7/29).\n[2] 公益財団法人日本サッカー協会(JFA). 日本サッカー協会選手登録数. https://\nwww.jfa.jp/about_jfa/organization/databox/player.html. (参照日\n2024/8/1).\n[3] 公益財団法人日本サッカー協会(JFA). 日本サッカー協会指導者登録数. https:\n//www.jfa.jp/about_jfa/organization/databox/coach.html.\n(参照\n日2024/8/1).\n[4] 公益財団法人日本サッカー協会(JFA).\n指導者養成",
            "ml.\n(参照\n日2024/8/1).\n[4] 公益財団法人日本サッカー協会(JFA).\n指導者養成講習会.\nhttps://jfa.jp/\ncoach/official/license.html. (参照日2024/8/1).\n[5] イングランドサッカー協会（TheFA）.\nRatios\nof\nadults\nto\nchil-\ndren.\nhttps://www.thefa.com/-/media/thefacom-new/files/\nrules-and-regulations/safeguarding/section-5/26072024/\n55-ratios-of-adults-to-children.pdf. (参照日2024/8/1).\n[6] INSIDE\nFIFA.\nGoal-line\ntechnology.\nhttps://\ninside.fifa.com/technical/football-technology/\nfootball-technologies-and-innovations-at-the-fifa-world-cup-2022/\ngoal-line-",
            "innovations-at-the-fifa-world-cup-2022/\ngoal-line-technology. (参照日2024/8/1).\n[7] SAP. Sports team management software—sap sports one. https://www.sap.com/\nproducts/technology-platform/sports-one.html. (参照日2024/8/1).\n[8] Catapult.\nCatapult vector pro.\nhttps://www.catapult.com/solutions/\nvector-pro. (参照日2024/8/1).\n[9] Playermaker.\nPlayermaker 2.0.\nhttps://www.playermaker.com/product/\nplayermaker/. (参照日2024/8/1).\n[10] 青柳光璃, ギヨーム・ロペズ, 横窪安奈. Footbsense: 慣性計測装置を用いた自然環境下\nにおけるサッカー動作の識別. 情報処理学会シンポジウムシリーズ",
            "e: 慣性計測装置を用いた自然環境下\nにおけるサッカー動作の識別. 情報処理学会シンポジウムシリーズ(IPSJ Symposium\nSeries (CD-ROM)), 第2022 巻, pp. ROMBUNNO.8C–3. 情報処理学会, 7 2022.\n[11] Dominik Schuldhaus, Constantin Zwick, Harald K¨orger, Eva Dorschky, Robert Kirk, and\nBjoern M. Eskoﬁer. Inertial sensor-based approach for shot/pass classiﬁcation during a\nsoccer match. KDD Workshop on Large-Scale Sports Analytics, pp. 1–6, 2015.\n49\n[12] 伊藤大晃, 後藤佑介. マルチセンサを用いたサッカー選手の動作分析システムの提案. 情\n報処理学会研究報告, Vol. Vol.2016-DPS-167 No.9, Vol.2016-MBL-79 No.9, Vol.201",
            "l.2016-DPS-167 No.9, Vol.2016-MBL-79 No.9, Vol.2016-\nITS-65 No.9, , 2016.\n[13] Maike Stoeve, Dominik Schuldhaus, Axel Gamp, Constantin Zwick, and Bjoern M. Es-\nkoﬁer. From the laboratory to the ﬁeld: Imu-based shot and pass detection in football\ntraining and game scenarios using deep learning. Sensors, Vol. 21, No. 9, p. 3071, 2021.\n[14] Karin Mascher, Stefan Laller, and Manfred Wieser. Development of smart shin guards for\nsoccer performance analysis based on mems accelerometers, machine learnin",
            "ysis based on mems accelerometers, machine learning, and gnss.\nCEUR Workshop Proceedings, Vol. ICL-GNSS 2021 WiP Proceedings, , 2021.\n[15] Omar Alobaid and Lakshmish Ramaswamy. A feature-based approach for identifying\nsoccer moves using an accelerometer sensor. In Proceedings of the 13th International\nJoint Conference on Biomedical Engineering Systems and Technologies (BIOSTEC 2020)\n- Volume 5: HEALTHINF, pp. 34–44, Valletta, Malta, 2020. SCITEPRESS – Science and\nTechnology Publications, Lda.\n[1",
            "ESS – Science and\nTechnology Publications, Lda.\n[16] H M Sajjad Hossain, Md Abdullah Al Haﬁz Khan, and Nirmalya Roy. Soccermate: A\npersonal soccer attribute proﬁler using wearables. In Proceedings of the First IEEE In-\nternational Workshop on Behavioral Implications of Contextual Analytics (PerCom Work-\nshops), pp. 1–6, Kona, Hawaii, USA, 2017. IEEE.\n[17] 今井友揮, 内山彰, 馬込卓弥, 東野輝夫. サッカートラッキングデータを用いた機械\n学習に基づくプレー認識手法の提案. 情報処理学会研究報告, Vol. Vol.2018-MBL-86\nNo.47, Vol.2018-UBI-57 No.47, , 2 2018.\n[18] 紅林佑",
            "6\nNo.47, Vol.2018-UBI-57 No.47, , 2 2018.\n[18] 紅林佑亮, 清水剛士, 長谷川明生. Arduinoおよびセンサーを用いたスポーツ動作解析シ\nステムの試作. 情報処理学会研究報告(IPSJ SIG Technical Report), 第Vol.2016-IOT-34\n巻, pp. 1–6. 情報処理学会, 6 2016.\n[19] 真鍋晃大, 石井直方, 福崎千穂. 慣性センサを用いたサッカー動作の解析と評価.\n[20] Katarzyna Piechota and Edyta Majorczyk. Decision-making time and neuromuscular co-\nordination in youth and senior soccer goalkeepers. Sensors, Vol. 23, , 2023.\n[21] Gwyneth B. Ross, Brittany Dowling, Nikolaus F. Troje, Steven L. Fischer, and Ryan B.\nGraham.\nClass",
            "roje, Steven L. Fischer, and Ryan B.\nGraham.\nClassifying elite from novice athletes using simulated wearable sensor data.\nFrontiers in Bioengineering and Biotechnology, 2020.\n[22] 中村康雄, 齊藤稔, 林豊彦, 江原義弘. 熟練者・未熟練者におけるインステップキック\n動作解析. バイオメカニズム, Vol. 20, pp. 53–64, 2010.\n[23] 辻元典央, 内藤景, 川崎廉, 絹巻悟. サッカー未経験者におけるインステップキック動\n作の特徴. 福井工業大学研究紀要, Vol. 50, , 2020.\n[24] 金子和輝, 中村拓真, 矢入郁子, 平田均. Openpose を用いたサッカー熟練度の分類. 人\n工知能学会第34 回全国大会論文集, 2020.\n50\n[25] 正木直樹, 三村瑠郁, 小泉信郎, 鈴木元樹, 塩谷浩之. サッカーのパス・トラップ動作に\nおける姿勢解析のためのモーション",
            "小泉信郎, 鈴木元樹, 塩谷浩之. サッカーのパス・トラップ動作に\nおける姿勢解析のためのモーションキャプチャを用いた動作特徴量の抽出に関する\n検討. 情報処理学会第85 回全国大会, 2023.\n[26] Chun Yu, Ting-Yuan Huang, and Hsi-Pin Ma. Motion analysis of football kick based on\nan imu sensor. Sensors, 2022.\n[27] Erik Wilmes, Cornelis J. de Ruiter, Bram J.C. Bastiaansen, Jasper F.J.A. van Zon,\nRiemer J.K. Vegter, Michel S. Brink, Edwin A. Goedhart, Koen A.P.M. Lemmink, and\nGeert J.P. Savelsbergh. Inertial sensor-based motion tracking in football with movement\nintensity quantiﬁcation. S",
            " football with movement\nintensity quantiﬁcation. Sensors, Vol. 20, No. 9, p. 2527, 2020.\n[28] Khaled Takizadeh, Fazlollah Bagherzadeh, Mahmoud Sheikh, Davood Hoomenian Sharif\nAbadi, and Hadi Veisi. The application of artiﬁcial neural network and wearable inertial\nsensor in kicking skill assessment. Journal of Advanced Sport Technology, Vol. 8, No. 1,\npp. 34–45, 2023.\n[29] Ante Raa, Goran Kuvaˇci´c, Andrea De Giorgio, Maha Sellami, Luca Paolo Ardig`o,\nNicola Luigi Bragazzi, and Johnny Padulo.\nThe",
            "g`o,\nNicola Luigi Bragazzi, and Johnny Padulo.\nThe ball kicking speed: A new, efﬁcient\nperformance indicator in youth soccer. PLOS ONE, Vol. 14, No. 5, p. e0217101, 2019.\n[30] 安達凱永, 雪竹翼, 中原匡哉. 深層学習を活用したサッカーにおける個人練習の支援技\n術の開発. 情報処理学会全国大会講演論文集, Vol. 85, pp. 373–374, 2023.\n[31] Joshua Marris, Steve Barrett, Grant Abt, and Chris Towlson. Quantifying technical ac-\ntions in professional soccer using foot-mounted inertial measurement units. Science and\nMedicine in Football, 2021.\n[32] Mohammed Ikram, Mo",
            "edicine in Football, 2021.\n[32] Mohammed Ikram, Mohammad Dahman Alshehri, and Farookh Khadeer Hussain. Archi-\ntecture of an iot-based system for football supervision (iot football). Conference Paper,\n2015.\n[33] H˚akon Kvale Stensland, Vamsidhar Reddy Gaddam, Marius Tennøe, Espen Helgedagsrud,\nMikkel Næss, Henrik Kjus Alstad, Asgeir Mortensen, Ragnar Langseth, Sigurd Ljødal,\nØystein Landsverk, Carsten Griwodz, and P˚al Halvorsen. Bagadus: An integrated real-\ntime system for soccer analytics. ACM ",
            "rated real-\ntime system for soccer analytics. ACM Transactions on Multimedia Computing, Commu-\nnications, and Applications, Vol. 10, No. 1s, p. Article 14 (21 pages), 2014.\n[34] 公益財団法人日本サッカー協会(JFA). JFA キッズ（U-8/U-10）ハンドブック. 公益\n財団法人日本サッカー協会(JFA), 3 2012. JFA キッズプログラム.\n[35] G¨unal Bilek and Bet¨ul Ayg¨un. Factors associated with match result and number of goals\nscored and conceded in the english premier league.\nBitlis Eren University Journal of\nScience, Vol. 11, No. 1, pp. 227–236, 2022.\n[36] Dieg",
            "ence, Vol. 11, No. 1, pp. 227–236, 2022.\n[36] Diego Brito Souza, Roberto L´opez-Del Campo, Hugo Blanco-Pita, Ricardo Resta, and\nJuan Del Coso. A new paradigm to understand success in professional football: analysis\n51\nof match statistics in laliga for 8 complete seasons. International Journal of Performance\nAnalysis in Sport, Vol. 19, No. 4, pp. 123–135.\n[37] A. Lees, T. Asai, T. B. Andersen, H. Nunome, and T. Sterzing. The biomechanics of\nkicking in soccer: A review. Journal of Sports Sciences,",
            "g in soccer: A review. Journal of Sports Sciences, Vol. 28, No. 8, pp. 805–817,\n2010.\n[38] 田所剛之. 東大卒キックコーチが教える本当に正しいキックの蹴り方: 思い通りの\nシュートやパスを蹴られる選手になる! 日本文芸社, 東京, 4 2023. 物理学に基づく\nキック理論を解説した実践書.\n[39] Suunto. Movesense. https://movesense.com/.\n[40] Apple.\niphone15.\nhttps://www.apple.com/jp/shop/buy-iphone/\niphone-15.\n[41] google. ﬂutter. https://flutter.dev/.\n[42] MathWorks.\nMatlab.\nhttps://www.mathworks.com/products/matlab.\nhtml.\n[43] Kinovea. Kinovea - video analysis software for sports. https://w",
            "ea - video analysis software for sports. https://www.kinovea.\norg/.\n52\n質疑応答\n大原　剛三　情報テクノロジー学科　教授\nQ\n機械学習の分類精度の指標として，なぜAccuracy で評価をしたのか？評価する上\nではPrecision も重要だと思います．\nA\nご質問ありがとうございます．姿勢推定の評価精度の指標はAccuracy のみを算出\nしていたため，機械学習による評価精度に関しては他の指標は省略し，accuracy を\n掲載しました．本論文には他の評価指標の結果も掲載しております．\n浦垣　啓志郎　情報テクノロジー学科　助手\nQ\nセンサを使った姿勢推定はいくつかあると思いますが，サッカーにおける姿勢推\n定の難しさは？\nA\nご質問ありがとうございます．サッカーの動作は曲線的で急加速・急減速が多く，\nセンサのノイズが大きくなりやすいという課題があります．また，長時間の利用で\nは静止状態の姿勢推定を用いて定期的に補正するのが理想ですが，サッカーではそ\nの機会が少なく，補正が難しいと考えられます．今回は接触プレーを考慮し",
            "のが理想ですが，サッカーではそ\nの機会が少なく，補正が難しいと考えられます．今回は接触プレーを考慮していま\nせんが，試合や対人練習を想定した場合，より激しい動きによってノイズが増加す\nるため，安定した推定が難しくなる可能性があります．\nQ\nサッカーにおける姿勢推定の難しさに対する対処は？また，難しい結果になったこ\nとに対する考察は？\nA\n本研究では，ノイズ除去やセンサキャリブレーションを行い，精度の高い姿勢推定\nを目指しました．その結果，姿勢推定のグラフ形状は理想的でしたが，姿勢推定の\n具体的な値に関しては低い傾向がありました．ノイズを除去し切ることができてい\nない可能性や補正の限界による影響と考えられます．今後は，さらなる補正手法の\n改良や異なるセンサフュージョン手法による精度向上を検討する必要があります．\nQ\nIMU をサッカー選手につけると運動の邪魔になる欠点があると思います．非侵襲的\n案Vision-based なフォーム推定と提案手法とを比べた利点/欠点をもう少し強調した\n方が良いような気がしました．\nA\nカメラベースは選手の動作を妨げずに高精度な動作解析が可能ですが，設置や",
            "良いような気がしました．\nA\nカメラベースは選手の動作を妨げずに高精度な動作解析が可能ですが，設置や環境\nの制約が多く，コストも高くなるという欠点があります．一方，センサベースは安価\nで持ち運びが容易であり，環境への依存性が少なく利用できるという利点が考えら\nれます．カメラベースとセンサベースには対照的な特徴がそれぞれありますが，ア\nマチュア向けのシステム開発を目指す上で，センサベースの手法を選択しました．\n53\n"
        ]
    },
    {
        "id": "paper_16",
        "filename": "M2024_Yusaku_Arai.pdf",
        "title": "M2024_Yusaku_Arai",
        "fulltext": " \n \n \n \n \n青  山  学  院  大  学 \n \n理  工  学  研  究  科 \n \n \n \n理工学専攻    知能情報    コース \n \n \n \n \n修  士  論  文 \n \n \n \n       学 生 番 号       35623215       \n \n \n       氏     名      新井 優作       \n \n \n研究指導教員   ロペズ ギヨーム 教授     \n \nAcademic Year of 2024, Submitted on January 31st, 2025 \n \nGraduate School of Science and Engineering, Aoyama Gakuin University \n \nTitle: Development of a Cooking Support System Using the Acoustic Characteristics of \nFried Chicken \n \nStudent Name: Yusaku Arai  \nID Number: 35623215  \nDegree: Master of Engineering \nCourse: Intelligence and Information \nThesis Advisor: Professor Guillaume Lopez \n \nAbstract  \nThe recent spread of COVID-19 has increased opportunities to cook at home, and the \nnumber of novice cooks has increased. Fried foods present a significant challenge for novices \nbecause it is difficult to determine the proper frying conditions (heat, time, etc.). This research \naims to develop a cooking support system, FCGS (Fried Chicken Goal system), which analyzes \nthe cooking sound of fried chicken and judges the end of frying. \nFCGS collects frying sounds using a smartphone microphone and detects the end of frying. \nIt classifies the cooking sounds into two categories, “Middle” and “Finish,” and notifies the \nuser in real-time when frying is finished. This makes it possible for even novice cooks to take \nout fried food at the appropriate time. \nThe following three types of sound features were investigated to analyze frying sound based \non various research fields dealing with sound signal analysis.  \n● \nMel-frequency cepstral coefficients (MFCC), which are widely used in voice recognition \n● \nWavelet coefficients, which are efficient in abnormality analysis from sound or \nvibration signal \n● \nAmplitude spectrogram, which is used in music analysis and bioacoustics \nIn particular, the amplitude spectrogram can visualize frequency components that change \nwith time, making capturing changes in fried sound easy. The study also introduces a change \npoint detection method to determine the timing of the end of frying accurately.  \nVarious machine-learning classifiers (SVM, k-NN, XGBoost) were tested to discriminate \nbetween mid-frying and end-of-frying. In addition, resampling techniques were used to deal \nwith data imbalance problems. FCGS was evaluated by cross-validation using frying sound \ndata. MFCC-based classification achieved an F1 score of 57.6%, and amplitude spectrograms \nenabled change-point detection, identifying the end of frying with 90% accuracy in F1 score, \nprecision, and recall. In particular, the introduction of change-point detection significantly \nreduced the number of misjudgments during frying. \nIn this study, a cooking support system, FCGS, was developed to determine the end of frying \nby analyzing the sound of fried food cooking. Evaluation experiments demonstrated that the \nsystem could detect the end of frying accurately and effectively assist novice cooks. Future \nchallenges include improving accuracy in different environments (noisy places), optimizing \nreal-time processing, and applying machine learning methods.  \n理工学専攻修士論文要旨 \n \n \n提出年度 \n：2024 年度 \n提出日  \n：2025 年 1 月 31 日 \n専修コース \n：知能情報コース \n学生番号 \n：35623215 \n学生氏名 \n：新井 優作 \n研究指導教員 ：ロペズ ギヨーム 教授 \n \n（論文題目） \n唐揚げの音響特性を利用した調理支援システムの開発 \n \n（内容の要旨） \n近年，新型コロナウイルス感染症の拡大により，自宅で料理をする機会が増加し，料理初心者の増\n加が確認されている．特に揚げ物は，適切な加熱状態を見極めることが難しく，料理初心者にとって\n大きな課題となっている．また，加熱不十分な鶏肉は食中毒のリスクを伴うため，安全な調理が求め\nられる．本研究では，唐揚げの調理音を分析し，揚げ終わりを判定する調理支援システム「FCGs \n(Fried Chicken Goal system)」を開発することを目的とする． \n調理支援に関する研究として，音響センシングを活用した調理状態の認識が進められている．例え\nば，沸騰音や調理環境音を分析することで，調理プロセスの段階を特定する研究がある．また，食材\nの音響的特徴を利用し，成熟度や品質を判断する研究も存在する．本研究では，これらの知見を基に，\n唐揚げの調理音を用いた調理支援システムを構築する．FCGs は，スマートフォンのマイクを用いて唐\n揚げの調理音を収集し，機械学習によって揚げ終わりを検出するシステムである．理音を「揚げ途中\n（Middle）」と「揚げ終わり（Finish）」の2 つに分類し，リアルタイムで揚げ終わりをユーザーに通\n知する．これにより，料理初心者でも適切なタイミングで唐揚げを取り出すことが可能となる． \n調理音の特徴量として，音波信号の解析が使われている様々な分野を参考に，次の３つを検討した． \n● \n音声認識分野に用いられているメル周波数ケプストラム係数（MFCC） \n● \n音波・振動の異常検知分野に用いられているウェーブレット係数 \n● \n音楽分析や生物音響学に用いられている振幅スペクトログラム \n特に，振幅スペクトログラムは，時間とともに変化する周波数成分を視覚化でき，揚げ音の変化を\n捉えやすいことや，変化点検出手法を導入し，揚げ終わりのタイミングを高精度に判定することが期\n待できる． \n識別手法として，複数の機械学習分類器（SVM，k-NN，XGBoost など）を用いて揚げ途中と揚げ\n終わりの判別を行う．さらに，リサンプリング手法を活用し，データの不均衡問題に対応する．また，\n変化点検出アルゴリズムを用いることで，調理中の音の変化を解析し，適切なタイミングで揚げ終わ\nりを判定する．FCGs の評価は，調理音データを用いた1 データ抜き交差検証によって行われた．\nMFCC を用いた分類では，F1 スコアが57.6%を達成し，振幅スペクトログラムを基にした変化点検出\nでは，揚げ終わりの検出精度がF1 スコア，適合率，再現率の3 指標において90%を達成した．特に，\n変化点検出を導入することで，揚げ途中での誤判定を大幅に削減できた． \n本研究では，唐揚げの調理音を分析し，揚げ終わりを判定する調理支援システムFCGsを開発した．\n評価実験の結果，本システムは高い精度で揚げ終わりを検出可能であり，料理初心者の調理を支援す\nる効果が期待される．今後の課題として，異なる環境（騒音がある場所）での精度向上，リアルタイ\nム処理の最適化，さらなる機械学習手法の適用が挙げられる．また，スマートスピーカとの連携やマ\nルチモーダル解析（画像＋音）を活用することで，より高度な調理支援システムの開発が可能となる． \n \n \n青山学院大学大学院理工学研究科 \n唐揚げの音響特性を利用した\n調理支援システムの開発\n新井優作\n2025/01/31\n目次\n第1 章\n序論\n3\n1.1\n研究背景. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n3\n1.1.1\n調理支援システムの需要. . . . . . . . . . . . . . . . . . . . . . . .\n3\n1.1.2\nセンシング技術を利用した調理支援. . . . . . . . . . . . . . . . . .\n4\n1.1.3\n揚げ物の揚がり具合判断. . . . . . . . . . . . . . . . . . . . . . . .\n5\n1.1.4\n加熱不十分な鶏肉調理の危険性. . . . . . . . . . . . . . . . . . . .\n6\n1.1.5\n音の検出・認知を行う既存製品. . . . . . . . . . . . . . . . . . . .\n6\n1.2\n研究目的. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n7\n1.3\n本論文の構成. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n8\n第2 章\n調理支援および音響的特徴を利用した関連研究\n9\n2.1\n音響センシングによる調理支援に関する研究. . . . . . . . . . . . . . . . .\n9\n2.2\n食材の音響的特徴を利用した状態認識に関する研究. . . . . . . . . . . . .\n11\n2.3\n異常音検出に関する関連研究\n. . . . . . . . . . . . . . . . . . . . . . . . .\n13\n2.4\n画像認識による調理支援および食材の状態認識に関する研究. . . . . . . .\n15\n第3 章\nFCGs: 料理初心者に向けた唐揚げ調理支援システム\n17\n3.1\nFCGs の提案\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n17\n3.1.1\n唐揚げの調理状態の定義. . . . . . . . . . . . . . . . . . . . . . . .\n17\n3.1.2\nFCGs のシステム構成\n. . . . . . . . . . . . . . . . . . . . . . . . .\n17\n第4 章\n調理音の特徴抽出手法および識別手法\n19\n4.1\n調理音および特徴量の解析手法\n. . . . . . . . . . . . . . . . . . . . . . . .\n19\n4.1.1\nスペクトログラム解析. . . . . . . . . . . . . . . . . . . . . . . . .\n19\n4.1.2\n主成分分析\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n20\n4.1.3\nt 分布型確率的近傍埋め込み法. . . . . . . . . . . . . . . . . . . . .\n20\n4.2\n調理音から抽出される音響特徴量. . . . . . . . . . . . . . . . . . . . . . .\n21\n4.2.1\n振幅スペクトログラム. . . . . . . . . . . . . . . . . . . . . . . . .\n21\n4.2.2\nMFCC . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n21\n4.2.3\nウェーブレット変換\n. . . . . . . . . . . . . . . . . . . . . . . . . .\n23\n4.3\n調理段階の識別手法\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n24\n4.3.1\n機械学習分類手法. . . . . . . . . . . . . . . . . . . . . . . . . . . .\n24\n4.3.2\nリサンプリングによる不均等データ処理手法. . . . . . . . . . . . .\n27\n4.3.3\n調理音の変化点検出手法. . . . . . . . . . . . . . . . . . . . . . . .\n29\n4.3.4\n調理音に含まれる雑音の処理\n. . . . . . . . . . . . . . . . . . . . .\n30\n4.4\n各識別手法の評価方法および評価指標\n. . . . . . . . . . . . . . . . . . . .\n31\n1\n4.4.1\n一グループ抜き交差検証による評価方法. . . . . . . . . . . . . . .\n31\n4.4.2\n評価指標. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n31\n第5 章\n調理音識別手法およびFCGs の開発\n33\n5.1\n調理音データのラベリング. . . . . . . . . . . . . . . . . . . . . . . . . . .\n33\n5.2\n機械学習モデルによる唐揚げの調理音データ分類精度の評価. . . . . . . .\n33\n5.2.1\nMFCC 特徴量を使用した分類精度の評価. . . . . . . . . . . . . . .\n34\n5.2.2\nPCA およびt-SNE によるMFCC 特徴量解析. . . . . . . . . . . . .\n37\n5.2.3\nリサンプリングバランスの調整による分類モデルの再評価\n. . . . .\n38\n5.2.4\n振幅スペクトログラムに基づく再ラベリング. . . . . . . . . . . . .\n39\n5.2.5\n4 クラスにおけるMFCC 特徴量による分類精度の評価\n. . . . . . .\n39\n5.2.6\nウェーブレット変換による特徴量抽出を利用した分類精度の評価\n.\n42\n5.3\n変化点検出による唐揚げの揚げ終わり検出精度の評価. . . . . . . . . . . .\n42\n5.4\n変化点検出を利用した揚げ終わり判定システムの実装. . . . . . . . . . . .\n46\n第6 章\n結論\n52\n6.1\n本研究のまとめ. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n52\n6.2\n今後の展望\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n52\n謝辞\n54\n参考文献\n55\n付録A 本研究に関する論文と発表実績\n62\n付録B 唐揚げの一般的なレシピまとめ\n63\n付録C MFCC 特徴量を使用したその他の分類精度の評価\n64\nC.1\nアンダーサンプリングにCluster Centroid を使用した際の分類精度一覧. .\n64\nC.2\nアンダーサンプリングにCondensed Nearest Neighbour を使用した際の分\n類精度一覧\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n66\nC.3\nアンダーサンプリングにNearMiss-1 を使用した際の分類精度一覧. . . . .\n67\nC.4\nアンダーサンプリングにNearMiss-2 を使用した際の分類精度一覧. . . . .\n68\nC.5\nアンダーサンプリングにOne-Sided Selection を使用した際の分類精度一覧\n69\n2\n第1章\n序論\n本章では序論として，本研究における背景および研究目的，本論文の構成について述\nべる．\n1.1\n研究背景\n1.1.1\n調理支援システムの需要\n料理初心者の増加\n新型コロナウイルス感染症の拡大以前は，フードデリバリーサービスが普及したことも\nあり，外食・中食の利用頻度が増加の一途を辿っていた[1][2]．反対に，家庭で料理をす\nる機会は減少していた．しかし，新型コロナウイルス感染症の拡大により，在宅時間が増\nえると共に，料理をする機会も増加した．\n2021 年に実施された農林水産省による「食育に関する意識調査」では，図1.1 で示され\nているように「自宅で食事を食べる回数」・「自宅で料理を作る回数」が増えたと回答した\n割合がそれぞれ35.5%，26.5%となった．特に若い世代（20～39 歳）において，\n「自宅で料\n理を作る回数」が増えたと回答した割合は39.5%にまで上った[3]．2020 年の消費者動向\n調査においても，コロナ禍での調理時間・回数が増えたと回答した割合は全体で32.9%と\nなった[4]．\nこの傾向は海外でも見られる．スペイン・クロアチア・ニュージーランドでそれぞれ実\n施された調査では，新型コロナウイルス感染症の流行によるロックダウン中に調理頻度が\n増加したものの割合は約4～5 割という結果が報告されている[5][6][7]．\nこのように，新型コロナウイルス感染症が拡大した結果，料理をする機会が増加してい\nる．これに伴い，普段料理をする機会がなかった人々が料理をする機会を得たため，料理\n初心者が増加していると考えられる．\n調理技術による料理の壁\n料理初心者の大きな壁として，レシピ表現の曖昧さおよび調理技術の不足が挙げられる．\nレシピ表現の曖昧さに関しては調味料の量をあらわす「少々」および「適量」，火加減\nにおける食材の色・状態変化の見極めが壁となっている．ハウス食品株式会社が男女500\n人ずつの計1000 人を対象に実施した調査によると「レシピの独特な表現に戸惑ったこと\nがある」と回答した人は約6 割である．そのうち，コロナ禍で料理を始めた人は約8 割に\n上る[8]．\n調理技術においては食材を適切な大きさに切るといった基本的な技術から，魚の三枚お\nろしをはじめとした多様な包丁さばきなどが料理初心者にとって習得に時間のかかる技術\nであると考えられる．平島らの調査によると，半月切りや輪切りという基本的な包丁の技\n3\n図1.1: 新型コロナウイルス感染症による食生活の変化（[3] より引用）\n術において，普段調理をほとんどしない235 人のうち，それぞれ，18.7%と8.9%の人がで\nきないと回答している[9]．\nよって，料理初心者がすぐに習得することが困難である技術および調理における判断を\n支援するシステムが必要であると考えられる．\n1.1.2\nセンシング技術を利用した調理支援\n料理初心者を支援するための技術として，センシング技術が挙げられる．近年，IoT\n（Internet of Things）技術の普及によりスマートフォンおよびタブレットだけなく，日常\nのあらゆるものにセンサが搭載されている．調理器具およびキッチン用品もその例外では\nない．調理器具およびキッチン用品とセンシング技術やIoT 技術を導入したスマートキッ\nチン家電は，料理初心者の未熟な技術および判断を支援し，調理の負担を軽減する．Kido\nらの研究では，調味料の容器にモーションセンサ，LED ライトを用いることで調味料追加\n4\nの支援システムを提案した[10]．加藤らの研究では，包丁の柄先に加速度センサを用いる\nレシピ動画の自動同期システムSynCook を提案した[11]．また，2021 年にはHestan Cue\nという調理器具，IH ヒーター，ビデオガイド付きレシピを組み合わせたスマート調理家電\nが発売された[12]．図1.2 のように調理器具，IH ヒーター，スマートデバイスがBluetooth\nで連動し，調理器具に組み込まれている温度センサにより最適な温度をリアルタイムで検\n知，加熱温度をアプリを介してIH ヒーターに指示する．さらに調理器具に食材を入れる\nタイミングおよびひっくり返すタイミング，取り出すタイミングなどを通知する．\nこのように料理をする際に利用するものとセンシング技術の融合により，日々の料理が\n可制御，可視化されていることがわかる．\n図1.2: スマート調理家電「Hestan Cue」のシステム概要（[12] より引用）\n1.1.3\n揚げ物の揚がり具合判断\n揚げ物は食品に小麦粉・溶き卵・パン粉・片栗粉などをコーティングし，高温の油で揚\nげることで表面の水分を蒸発させサクサクの食感を実現している．周りの衣および食品\nのサイズ，揚げる時間によって揚げ物の食感も変わる[13]．そのため衣は色が付き十分揚\nがっているように見えるが中身に火が通っていない場合がある．このように，表面だけで\n判断することが難しい揚げ物は，料理初心者にとっては困難なレシピの1 つであると考え\nられる．\nそこで本研究では揚げ物に着目する．揚げ物を揚げる際，衣の水分損失が指数的に減少\nすることから，揚げ物の揚がり具合による水分と油の振動が音響的変化にあらわれると想\n定される[14]．よって，揚げ物を揚げている時間に対する音響変化を利用した，揚がり具\n合の判定が可能であると考えられる．\n5\n1.1.4\n加熱不十分な鶏肉調理の危険性\n揚げ物料理の中でも，加熱不足で食中毒となる危険性が高い食材は鶏肉である．生の鶏\n肉はサルモネラやカンピロバクター等の食中毒菌の感染源となる[15][16]．特に，カンピ\nロバクター食中毒はノロウイルスと並んで食中毒事件数が高い値となっている．厚生労働\n省が実施した調査では，令和5 年においてカンピロバクター食中毒が発生した件数が211\n件に上っていることを報告している[17]．結果，日本では各機関が予防のために注意喚起\nしている[17][18][19]．食中毒を防ぐための十分な加熱は，鶏肉の中心温度が75◦C 以上で\n1 分間以上とされている．\nしかしSolveig らの調査によると，家庭での鶏肉調理の大半が内部温度を測定せずに調\n理されており，病原体の完全な無害化を達成できていない場合が多いことがわかった[20]．\nよって本研究では，加熱不十分な状態を調理完了と誤判定しない安全な調理支援システ\nムを構築する．\n1.1.5\n音の検出・認知を行う既存製品\n今日では，様々なスマートデバイスが普及したことにより，音を利用する技術が日常生\n活に馴染んでいる．本項では，既に一般に普及している音を利用した技術を紹介する．\n音声センサによる音検知通知\nGoogle およびApple はスマートデバイスが周囲の物音を聞き取り通知してくれる機能\nを提供している[21][22]．本機能は聴覚の障害がある人およびイヤホン・耳栓を装着して\nいるとき，物音に気付きにくい状況下でも，指定の音を検知すると図1.3 のようにスマー\nトデバイスへ直接通知をしたり，端末の振動およびカメラ撮影用ライトを点滅させたりし\nて通知をしてくれる．このようにスマートデバイスに内蔵されている音声センサのみで音\nの検知が可能になっている．\nまた，スマートフォンの内臓マイクロフォンなどの音響的センサは身近な機械に組み込\nむことが容易であり，料理中に水がかかることおよびセンサの設置が不自由であるといっ\nた課題が解消される．\nスマートスピーカの普及\nApple が自社のスマートフォンに搭載した「Siri」およびAmazon が発売した「Amazon\nEcho」などを皮切りにスマートスピーカの市場は成長を続けている．野村総合研究所の\n「IT ナビゲーター2021 年度版」[23] によると2020 年のスマートスピーカ世帯普及率は\n11.2%（583 万世帯）だったが，2021 年には13.5%（691 万世帯）と増加している（図1.4）．\nさらに2026 年には30.8%（1544 世帯）にまで上ることが見込まれている．\nこのような現状から，本研究では音を利用した料理支援に着目する．\n6\n図1.3: Android 端末の音検知通知の様子（[21] より引用）\n1.2\n研究目的\n前節で述べたように，新型コロナウイルス感染症拡大の影響から現代社会の料理に対す\nる向き合い方に変化が生じており，料理初心者に対する料理支援の必要性が増加してい\nる．また，揚げ物料理に対する料理初心者の壁として，火加減の調整および中身まで火が\n通っているかの判断などの難しさが存在する．音の技術に関しては，既に身近にある様々\nな製品にその技術が組み込まれているため馴染みのある技術だと言える．以上の点から本\n論文では身近な端末であるスマートフォンに内臓されているマイクロフォンから音響信号\nを取得し，揚げ物の中でも特に中身が十分加熱されているかわかりづらく，加熱不十分に\nよる食中毒の危険性を持つ鶏肉料理の一つである唐揚げを対象とする．そして，唐揚げの\n揚げ終わりを判別する調理支援システムの開発を目的とする．\nそこで本研究では次の2 つを目標とする．\n1.\n唐揚げの調理状態において，揚げ終わりとなる前の状態で調理完了と誤判定しない安\n全な音判定システムの構築．\n2.\nスマートフォン上で唐揚げの揚げ終わりをリアルタイムに判別する，容易に利用可能\nなアプリケーションの開発．\n調理音から振幅の平均を算出し，変化点検出を実施した結果，揚げ終わりの検出はF1\nスコア，適合率，再現率の3 種類の指標で90%の精度を達成した．また，変化点検出アル\n7\n図1.4: 日本におけるスマートスピーカの保有世帯数・普及率予測（[23] より引用）\nゴリズムを実装した，リアルタイムで唐揚げの調理完了タイミングを判定するスマート\nフォンアプリケーションFCGs を開発した．\n1.3\n本論文の構成\n本論文の構成を以下に示す．\n第1 章: 序論\n本論文の研究背景，研究目的および論文の構成について述べる．\n第2 章: 調理支援および音響特徴を利用した関連研究\n本研究に関連する，調理支援に関する研究および音響特徴を利用した研究について\n述べる．\n第3 章: FCGs: 料理初心者に向けた唐揚げ調理支援システム\n唐揚げの調理支援システムの提案について述べる．\n第4 章: 調理音の特徴抽出手法および識別手法\n本研究で検討した唐揚げの調理音から得られる音響特徴量および調理完了の識別手\n法について述べる．\n第5 章: 調理音識別手法およびFCGs の開発\n各識別手法の評価および調理支援システムの評価について述べる．また，提案手法\nの開発について述べる．\n第6 章: 結論\n本論文の結論と今後の展望について述べる．\n8\n第2章\n調理支援および音響的特徴を利用した関連\n研究\n本章では本研究を進めるにあたっての関連した研究についてまとめる．\n2.1\n音響センシングによる調理支援に関する研究\n調理中の動作および食材を音で認識することで，調理支援が可能である．そのため，調\n理活動認識および食材の状態認識に関する研究が実施されている．\nTabacchi らは，調理プロセスの段階を音響および振動データに基づいて分類する新しい\n統計的パターン認識手法を提案した[24]．本研究では，水の沸騰という単純なケースを対\n象とし，調理段階の識別精度を向上させる最適化モジュールを導入した．\n沸騰段階のデータは，鍋に水を1.5 L 入れ，室温から最大加熱力で加熱することで収録\nされた．記録には，AKG SE300B カーディオイドマイク（44.1 kHz）とPCB 加速度計\n（352C33，44.1 kHz）が使用され，合計28 回の実験が実施された．また，録音環境は静か\nな部屋で統一された．特徴量としてMFCC（Mel-Frequency Cepstral Coeﬃcient）が使用\nされ，加熱，核沸騰，遷移沸騰，膜沸騰の4 つの段階が識別された．各録音は100 ms ご\nとに分割され，Parzen Classiﬁer を用いて分類が行われた．音響データ単独，振動データ\n単独，および両者の組み合わせの3 種類の特徴セットが試験された．\n最適化モジュールでは，分類結果に移動平均フィルタを適用し，閾値を超える確率が1\n秒以上続く場合にクラスが確定される仕組みが導入された．この結果，加熱および膜沸騰\n段階では最適化後に100%の識別精度が達成された．一方，核沸騰および遷移沸騰段階で\nは，最適化前の識別精度は約98%であったが，最適化により誤分類が減少した．\n今後の課題として，振動データのラベル付けが音響信号に基づいて実施されたことによ\nる精度低下が指摘されている．振動データの独自のラベリング手法の導入や，温度センサ\nや圧力センサなど他のデータと統合したマルチモーダル処理が求められる．\n宮澤らは，調理環境音を用いた行動認識においてレシピ情報を時系列的に考慮し，音響\n識別器の中間特徴量を導入することで認識精度の向上を図った[25]．従来の手法では「切\nる」「焼く」といった調理行動のみを対象としていたが，本研究では「水の音」や「ビニー\nル袋の擦れる音」などの環境音も認識対象に加えることで，行動識別の精度がさらに向上\nすることが示された．\n焼きそばの調理を対象とし，音響データはiPhone 8 で録音された6 つの調理環境音を\n使用した．録音された音声データは，サンプリング周波数16 kHz で記録された．特徴量\nとしてMFCC と，音響識別器の中間層から抽出した特徴量が使用された．音響識別器に\nはEnvNet-v2 を改良したモデルが採用され，ボトルネック層の出力を新たな特徴量とし\nて利用することで，調理行動の識別精度向上が図られた．\n9\n調理行動の識別にはHMM（Hidden Markov Model）が使用され，モデルの出力確率分\n布はGMM（Gaussian mixture models）で推定された．実験では，MFCC の窓幅を16 ms，\n160 ms，1600 ms の3 条件で設定し，HMM の混合数1・2 の条件で識別精度が評価され\nた．評価指標としてF 値が用いられ，cut（切る）・grill（焼く）の調理行動に加えothers\n（その他）が対象となった．HMM ネットワークは図2.1 のようになる．\n図2.1: レシピ情報を加味したHMM ネットワーク（[25] より引用）\n結果として，MFCC と比較して音響識別器の中間特徴量を導入した方が「焼く」行動の\n識別精度が向上した．特に，中間特徴量の次元を100 に設定した場合，F 値が最も高くな\nり，音響識別器を用いる有効性が示された．一方，\n「切る」行動に関しては中間特徴量の\n導入による精度向上は確認されなかったものの，全体的な識別精度は向上した．さらに，\n「その他」クラスを「水の音」「ビニール袋の音」などに細分化することで，他クラスとの\n誤認識が減少し，識別性能が向上することが確認された．\n今後の課題として，GMM の混合数の増加が必ずしも識別精度向上に寄与しないことが\n指摘された．特に「切る」音と環境音（others）が類似している場合，誤分類の原因とな\nる可能性がある．環境音クラスをさらに細分化することで，識別精度を高める必要があ\nる．また，実験はオフラインで実施されたが，オンラインのリアルタイム認識システムへ\nの応用が求められる．\n陳らは，音響解析を用いて唐揚げの揚がり具合を判定する手法を提案した[26]．本研究\nでは，スマートフォンの内蔵マイクを活用して調理中の音響データを取得し，機械学習を\n用いて唐揚げの調理状態を分類することを目的とした．従来の調理支援システムは，調理\n器具にセンサを取り付ける必要があったが，本手法では外部機器を必要とせず，より簡便\nに導入可能なシステムが設計された．\n唐揚げの調理音を対象とし，データはiPhone 11 を使用して静かなキッチン環境で録音\nされた．サンプリング周波数は44.1 kHz で，調理油の温度はクックサーモ5495B を使用\nして監視された．表2.1 の通り，温度（150◦C，170◦C，200◦C），個数（5 個，7 個，10 個），\n調理油の使用回数（1 回目，2 回目）の条件を変えて10 回分のデータが収集された．調理\n音は「揚げはじめ」「変化1」「変化2」「変化3」「揚げ上がり」の5 つのラベルに分類さ\nれ，音響データにはMFCC が特徴量として使用された．\n機械学習には，自動機械学習ツール「TPOT」を使用した．TPOT は遺伝的プログラミ\nングにより最適なモデルを自動探索し，ハイパーパラメータの調整を実施する．本研究\nでは，5 分割交差検証を用いて複数のモデルを試行した結果，XGB（eXtreme Gradient\nBoosting）が最も高い精度を達成した．\n実験の結果は表2.2 の通り，全体のF1 スコアは97.14%，揚げ上がり段階のF1 スコア\nは85.71%に達した．揚げはじめや変化段階は95%以上の精度で分類されたが，揚げ上が\n10\n表2.1: 計測10 回分の唐揚げの揚げ方（[26] を基に作成）\n温度[◦C]\n個数[個]\n油使用回数[回]\n動画1\n170\n7\n1\n動画2\n170\n7\n2\n動画3\n170\n10\n1\n動画4\n170\n10\n2\n動画5\n170\n5\n1\n動画6\n170\n5\n2\n動画7\n150\n7\n1\n動画8\n150\n7\n2\n動画9\n200\n7\n1\n動画10\n200\n7\n2\nり段階の精度は他のクラスよりも低かった．\n表2.2: 各クラスにおいての評価結果（[26] より引用）\n評価尺度\nその他\n揚げはじめ\n変化1\n変化2\n変化3\n揚げ上がり\n平均\n加重平均\nRecall\n98.53%\n95.71%\n98.66%\n95.96%\n98.58%\n83.33%\n95.13%\n97.15%\nSpeciﬁcity\n99.79%\n99.63%\n98.14%\n99.52%\n99.40%\n99.80%\n99.38%\n99.15%\nPrecision\n97.10%\n98.67%\n95.45%\n98.17%\n97.66%\n88.24%\n95.88%\n97.17%\nAccuracy\n98.53%\n95.71%\n98.66%\n95.96%\n98.58%\n83.33%\n95.13%\n97.15%\nF1-score\n97.81%\n97.17%\n97.03%\n97.05%\n98.12%\n85.71%\n95.48%\n97.14%\n揚げ上がり段階の精度が低下した要因として，データ数の不足が挙げられる．特に高温\nや低温，量が多い状態では音響特性が異なり，単純な閾値設定では分類が困難であった．\nしかし，TPOT による機械学習モデルの最適化により，温度や個数の条件が異なっても\n一定の精度が維持された．\n本研究は，音響解析と機械学習を組み合わせて調理支援を行う新たなアプローチを提案\nしており，外部センサを必要とせず，スマートフォンだけで調理状態を判定できる点が特\n徴である．今後は，より多くの調理データを収集し，揚げ上がり段階の精度向上を目指す\nとともに，リアルタイムでの揚がり具合判定システムの構築が求められる．\n2.2\n食材の音響的特徴を利用した状態認識に関する研究\n食材の状態を正確に把握することは，食品の品質管理および食材の美味しさの認識に有\n効である．そのため，非破壊的な食材の状態認識および食感の分類に関する研究が実施さ\nれている．\nCaladcad らは，音響信号に基づいてココナッツの成熟度を判定する手法を提案した[27]．\n本研究では，ココナッツを叩くことで得られる音響データを取得し，機械学習を活用して\n成熟度を分類することを目的としている．従来の成熟度判定は農家が音を頼りに行う主観\n的な方法であったが，本手法では音響データを解析することで，より客観的で高精度な分\n類を目指している．\n11\nココナッツのタッピング音は，専用のタッピングチャンバを用いて収録された．サンプ\nリング周波数は44.1 kHz で，吸音材を用いたチャンバ内でノイズを抑えながら録音され\nた．収録された音響データは，高速フーリエ変換（Fast Fourier Transform，FFT）を施\nし，周波数領域の特徴量を抽出した．サンプル数は129 個（未成熟8 個，成熟36 個，過\n成熟85 個）で，それぞれ3 回ずつタッピングされ，合計387 のデータが得られた．\n機械学習モデルとして，人工ニューラルネットワーク（Artiﬁcial Neural Network，ANN），\nサポートベクターマシン（Support Vector Machine，SVM），ランダムフォレストの3 種\n類が用いられた．データは70%を訓練用，30%をテスト用として分割し，10 分割交差検\n証によりモデルの評価が実施された．\n実験の結果は表2.3 の通りである．ランダムフォレストが最も高い精度を達成し，訓練\n精度は90.98%，テスト精度は83.48%に達した．一方，ANN は訓練精度79.32%，テスト\n精度81.74%で安定した結果を示し，SVM はやや精度が低かった．特に過成熟の分類精度\nは高かったが，未成熟と成熟の識別はやや難しく，データの不均衡が影響したと考えら\nれる．\n表2.3: 3 種類の機械学習分類器の性能比較（[27] より引用）\nModel\nClassiﬁcation Accuracy [%]\nF- Score [%]\nTrain\nTest\nTrain\nTest\nArtiﬁcial Neural Network\n79.32\n81.74\n77.46\n79.27\nRandom Forest\n90.98\n83.48\n91.41\n81.35\nSupport Vector Machine\n88.35\n80.00\n88.79\n76.67\n原因として，未成熟のサンプル数が少ないことが分類精度の低下を引き起こしている可\n能性が指摘された．今後は，サンプル数の増加やデータ拡張を実施し，未成熟クラスの精\n度向上を図る必要がある．また，深層学習モデルの導入による分類精度向上や，リアルタ\nイム判定が可能なシステムの構築が求められる．\nZhao らは，芯にかびを持つ不健全なリンゴを非破壊で検出するために，振動音響信号\nの多領域特徴を用いた深層学習と浅層学習を組み合わせたハイブリッドモデルを提案した\n[28]．本研究は，健康な果実，軽度のかび芯（不健全），重度のかび芯（病果）の3 クラ\nス分類を目指し，果実内部の初期異常を検出する方法を開発している．\nかび芯はリンゴの内部障害であり，初期段階では外観上の異常がなく，食品安全上のリ\nスクが見過ごされやすい．本研究では，リンゴの赤道帯部分に電圧刺激を加え，誘発さ\nれた振動音響信号を圧電センサを用いて収集した．振動音響信号は時間領域，周波数領\n域，時間-周波数領域の2 次元画像に変換され，多領域特徴の抽出に利用された．ResNet50\nで深層特徴を得た後，SVM およびExtreme Learning Machine（ELM）の浅層学習モデ\nルで分類するハイブリッド構造を採用し，特徴選択と分類器の最適化には粒子群最適化\n（Particle Swarm Optimization，PSO）アルゴリズムが用いられた．\nリンゴ1200 個を対象とした実験では，時間-周波数領域の特徴が特に効果的であり，提\n案モデル（IResNet50-PSO-ELM）は全体で96.7%の分類精度を達成した．健康な果実，不\n健康な果実，病果の分類精度はそれぞれ100%，94.1%，96.2%であり，不健康な果実の一\n部が健康な果実または病果と誤分類される課題が残ったものの，F1 スコアは全クラスで\n12\n95%以上を記録した．\n本研究は，果実内部の初期障害を高精度で非破壊検出する可能性を示しており，振動音\n響データを利用した食品品質管理の有用性を提案している．\nLopez らは，食品のサクサク感を音響信号に基づいて分類する手法を提案した[29]．本\n研究では，Autonomous Sensory Meridian Response（ASMR）動画から音声データを収\n集し，フライドチキン，ポテトチップス，トーストのサクサク感を深層ニューラルネット\nワーク（Deep Neural Network，DNN）で分類することを目的としている．従来の官能評\n価や機械的測定と異なり，音響データを用いることで，非侵襲的かつ迅速に食品の食感を\n評価することが可能となる．\n本研究では，YouTube のASMR 動画584 本からフライドチキン，ポテトチップス，トー\nストの咀嚼音を収集した．音声データは1 秒ごとにトリミングされ，サンプリング周波数\nを22,050 Hz に統一して保存された．収集した音声から，MFCC および離散フーリエ変換\n（Discrete Fourier Transform，DFT）スペクトルが特徴量として抽出された．また，テス\nトデータとして音響防音ボックス内で機械的に圧縮して収録されたフレッシュトースト，\nASMR 動画から収集されたミルクに浸したトーストの音響データを用意した．\n分類モデルには，MFCC を用いた多層パーセプトロン（Multi-layer Perceptron，MLP）\nと，DFT スペクトルを入力とするResNet（残差ネットワーク）が使用された．MLP は\n512，256，3 のニューロンを持つ3 層の全結合ネットワークで構成され，ResNet は複数の\n残差ブロックからなる深層学習モデルである．\n結果，MLP モデルは学習データで95%，テストデータで100%の精度を達成した．一\n方，ResNet モデルは学習データで85%，データ拡張後には97%の精度を示したが，テス\nトデータでは16%と低い精度にとどまった．特に，MLP モデルはフレッシュトーストと\nミルクに浸したトーストの音響データも高精度で分類し，外部データに対する汎化性能が\n示された．\n本研究は，食品のサクサク感を音響信号から分類する新たな手法を提示し，食品業界に\nおける品質管理や製品開発に貢献する知見を提供している．今後は，さらなるデータセッ\nトの拡充やリアルタイムでの分類システム構築が求められる．\n本研究においても，唐揚げのフライ調理音に最適な特徴量および分類器を利用すること\nで，揚げ終わりの特徴を捉え，正確な識別が可能であると考える．\n2.3\n異常音検出に関する関連研究\n異常音検出は，注意を向けないと気づくことが困難な変化を認識可能にする．そのため，\nわずかな音の変化を捉えるための研究が実施されている．\nXiao らは，ガスパイプラインの漏れを音響信号に基づいて検出する手法を提案した[30]．\n本研究では，ウェーブレット変換とSVM を組み合わせた漏れ検出および深刻度分類シス\nテムを開発し，パイプラインの安全性を向上させる技術について検討している．特に，漏\nれ音の特性を利用し，高精度かつ迅速に漏れの規模の識別が可能であることが示されてい\nる．音響センサによって収集された漏れ音はウェーブレット変換によって特徴抽出が行わ\nれ，ノイズ除去後にSVM で分類される．\n本システムの開発には，30 m および3 m のパイプラインが使用され，直径1 mm，3\n13\nmm，5 mm の漏れ穴を設けた実験が実施された．結果として，漏れの有無は99.4%の精度\nで検出され，漏れの深刻度は95.6%の精度で分類された．特に，標準偏差，ウェーブレッ\nト平均周波数，および絶対平均が漏れの深刻度分類において重要な役割を果たした．\nMalviya らは，呼吸音を用いてCOVID-19 および他の呼吸器疾患を検出するシステムを\n提案した[31]．本研究では，自己符号化器と長短期記憶ネットワーク（Long Short-Term\nMemory，LSTM）を組み合わせ，音響データから疾患を高精度に分類する手法を開発し\nている．\n呼吸器疾患の診断において，咳や呼吸音は重要なバイオマーカーとなる．音響データを\n解析することで，COVID-19 や肺炎，慢性閉塞性肺疾患（Chronic Obstructive Pulmonary\nDisease，COPD）などを検出できる可能性が示されている．特に自己符号化器は健康な\n音声データを学習し，異常がある場合に高い再構築誤差を示すことで疾患の存在を検出\nする役割を果たす．LSTM はその後の分類フェーズで音声データの時間的特徴を学習し，\n疾患の種類を判別する．\n本システムは，Kaggle やPﬁzer Digital Medicine Challenge から収集した呼吸音データ\nを使用し，515 件の音声データで構成されたデータセットで訓練・検証が実施された．デー\nタセットには，COVID-19 患者185 名，健康な人150 名，およびその他の呼吸器疾患（肺\n炎，COPD，上気道感染症など）を持つ患者180 名が含まれている．音声データは22,050\nHz でリサンプリングされ，短時間フーリエ変換（Short-Time Fourier Transform，STFT）\nによって特徴が抽出された．\nモデルは，LSTM が200 エポック，自己符号化器が100 エポックで学習され，損失関\n数として平均二乗誤差が使用された．表2.4 の通り，分類精度は平均97.5%に達し，特に\nCOVID-19 の検出においては曲線下面積1.0 を達成し，感度1.0，特異度0.979，F1 スコ\nア0.984 という非常に高い精度が得られた．他の呼吸器疾患の分類精度も平均96%以上で\nあり，COVID-19 と他の疾患の正確な識別が可能であることが示された．\n表2.4: 呼吸器疾患のマルチクラス分類の性能評価指標（[31] より引用）\nClass\nAccuracy\nPrecision\nSensitivity\nSpeciﬁcity\nF1-Score\nPneumonia\n0.944\n0.563\n0.818\n0.953\n0.667\nURTI\n0.981\n0.75\n0.857\n0.987\n0.80\nBronchiolitis\n0.994\n1.00\n0.75\n1.00\n0.857\nCOVID-19\n0.987\n0.968\n1.00\n0.979\n0.984\nCOPD\n0.944\n0.981\n0.867\n0.990\n0.920\nHealthy\n1.00\n1.00\n1.00\n1.00\n1.00\n本研究では，唐揚げの調理音から揚げ終わり音を検出するシステムを提案する．唐揚げ\nの揚げ終わり音は，人間の耳で聞き取れる変化ではあるが，注意を向けないと気づくこと\nが難しい．しかし，唐揚げ調理音を時系列データとして捉え，揚げ終わりの際に発生する\n音を異常音および変化点として捉えることが可能であるならば，本研究においても異常音\n検出は有効であると考えられる．\n14\n2.4\n画像認識による調理支援および食材の状態認識に関する研究\n音だけでなく，カメラを利用した状態認識による調理支援に関する研究も実施されて\nいる．\nLin らは，人工知能（Artiﬁcial Intelligence，AI）技術を用いて食品の調理状態を自動で\n判定するシステムを開発した[32]．本研究では，機械ビジョンと画像処理技術を組み合わ\nせ，食品の色の変化を解析することで「未調理」「調理済み」「過調理」の各状態を識別す\nることを目的としている．\n食品の調理状態をリアルタイムで監視するため，システムはRGB 画像をHSV 色空間\nに変換し，画像セグメンテーションを実施することで食品と背景を分離している．色相，\n彩度，明度の変化を利用して食品の調理成熟度や調理ムラを判断し，油の光沢やソースの\n吸収状態も解析する．画像処理アルゴリズムは，特定の色差や分布を用いて，調理工程を\n終了するか部分的に攪拌するかを判断する．\n研究では，約120 種類の食品データセットを用いて，調理成熟度や油の光沢，ソース吸\n収といったパラメータを定義し，AI アルゴリズムで解析した．実験結果では，誤認率を\n3%未満に抑え，各画像の解析時間を0.2 秒以下に短縮することに成功した．また，キャベ\nツ，レタス，エリンギの3 種類の食品において，調理ムラや過調理箇所を特定し，自動攪\n拌を実行するロボットアームが実装された．\nこのシステムは，調理状態をより正確に判断できる食品調理の自動化を実現する可能性\nを示しており，将来的にはさらに多くの食品種に対応することで，食品調理の質を向上さ\nせることが期待されている．\nChao らは，バゲットの外観品質を自動評価するために，画像処理技術を活用した新し\nい評価システムを提案した[33]．本研究は，サイズ，平行度，色の3 つの指標を基に，従\n来の主観的な手作業評価を置き換える客観的で定量的な評価手法を開発している．\n食品業界では，食品の品質評価において外観が重要な指標となる．しかし，手作業によ\nる評価は主観的であり，評価者の熟練度に依存しやすく，時間がかかるという問題がある．\n本研究では，バゲットの画像を撮影し，画像処理技術を用いて自動的にバゲットの外観品\n質評価を行うシステムを構築した．まず，撮影画像内のベーキングトレーを基準に画像の\n視点を補正し，その後，バゲットの外観を評価する．\nバゲット124 本を対象とした実験では，サイズ評価において平均絶対誤差が0.6 mm と\n高精度であった．A・B・C の三段階による平行度と色評価では，専門家の評価との一致\n率がそれぞれ96%および94%となり，提案手法の有効性が確認された．図2.2 の左側に平\n行度，右側に色評価の示す．図2.2 より，評価アルゴリズムと専門家の評価との間に高い\n整合性があることがわかる．不一致となった要素を分析すると，評価アルゴリズムの評価\nがより正確であり，主観的なバイアスを減らすことに役立つことがわかった．また，改良\n版k-means クラスタリングを用いたベーキングトレーの抽出精度は99.21% に達し，従来\n手法を上回る性能を示した．\n本研究は，画像処理を活用した食品品質評価の自動化の可能性を示し，手作業評価の課\n題を克服する新たなアプローチを提案している．今後は，深層学習技術を活用したバゲッ\nトの切り込みの評価や，より大規模なデータセットの収集により，さらなる精度向上が期\n待される．\nArman らは，ポテトチップスの揚げ工程をリアルタイムで最適化するスマートフライン\n15\n図2.2: 平行度および色評価の混同行列（[33] より引用）\nグシステムを提案した[34]．油吸収およびアクリルアミド生成は，健康リスクおよび品質\nのばらつきにつながる重要な課題である．従来の揚げ工程では，ポテトの化学的特性の個\n体差が考慮されず，一律の温度・時間で調理されていた．そこで，本研究ではコンピュー\nタビジョン，ハイパースペクトル画像，機械学習，デジタルツイン技術を統合したリアル\nタイム制御システムを開発することにより，リアルタイムでポテトの状態をモニタリング\nし，揚げ条件を動的に調整する．\nポテトを対象とした実験では，アクリルアミド生成が最大66%削減，油吸収量は16%\n低減された．また，色・食感の均一性が向上し，専門家の評価との一致率が高いことが確\n認された．リアルタイムモニタリングの精度については，色の予測精度R2 = 0.96，食感\n（硬さ）の予測精度R2 = 0.91，油含有量の予測精度R2 = 0.98 と高い性能を示した．\n本研究は，食品加工の自動化と品質管理の高度化を実現する新たなアプローチを示して\nいる．今後は，デジタルツイン技術を活用したさらなる最適化や，大規模データの収集に\nより，より高度なスマートフライングシステムの開発が期待される．\nこのように，同じ食材において，画像分析を利用して微細な差異を検知し，分類・識別\nすることが可能である．本論文では，音のみを利用して，唐揚げの状態認識および調理支\n援を検討している．調理環境にカメラを設置することおよび，レンズを曇らせたり，汚し\nたりしないように注意しながら調理することは，料理初心者にとっては困難であると考え\nたためである．しかし，今後スマートグラスといった料理中でも，容易に利用可能なデバ\nイスを利用して，画像と音のセンシングによるマルチモーダルシステムとして，調理支援\nの精度向上が実現可能であると考える．\n16\n第3章\nFCGs:料理初心者に向けた唐揚げ調理支\n援システム\n本章では，料理初心者が唐揚げの不完全な調理を防ぐために，揚げ終わりを通知する料\n理支援システムFCGs を提案する．第1 章で述べたように，音センシングは，他のセンサ\nに比べ設置の不自由がなく簡単に利用可能であり，現代では広く利用されている技術であ\nる．よって，スマートフォンのマイクロフォンから得られる調理音から，揚げ終わりを判\n定する．FCGs は「Fried Chicken Goal system」の頭文字をとった造語である．\n3.1\nFCGs の提案\n本節では唐揚げの揚げ終わり検出手法を提案する．唐揚げの調理音から，揚げ終わりを\n検出するために，機械学習および変化点検出による精度検証を実施する．その後，最も精\n度の良い手法を利用して，スマートフォンアプリケーションとして実装する．精度検証の\n結果は第5 章で述べる．\n3.1.1\n唐揚げの調理状態の定義\n本研究では，唐揚げの「揚げ終わり（Finish）」を衣にきつね色がしっかり付き，気泡\nが細かく完全に浮いている状態とし，それ以前の状態を総じて「揚げ途中（Middle）」と\n定義する．\n3.1.2\nFCGs のシステム構成\n本論文では，唐揚げの揚げ終わりを判別するアプリケーションの開発を目標としている\nため，アプリケーションのユーザビリティを考慮しないシンプルな構成とした．唐揚げの\nフライ調理を開始すると同時に，調理開始ボタンを押下し，揚げ終わりのフィードバック\nを確認した段階で調理終了ボタンを押下する．揚げ途中から揚げ終わりへの変化は，アプ\nリケーションの画面および通知音によってフィードバックする．画面によるフィードバッ\nクは図3.1 の通りである．画面上部には調理の経過時間を示すタイマーを設置している．\n17\n図3.1: FCGs の画面フィードバックの様子（左図：揚げ途中，右図：揚げ終わり）\n18\n第4章\n調理音の特徴抽出手法および識別手法\n本章では本研究で使用した解析手法，特徴量，機械学習手法および変化点検出手法につ\nいて述べる．また，解析はすべてプログラミング言語のPython を使用している．解析に\n利用したデータの詳細は表4.1 の通りである．調理音1 から調理音4 は唐揚げの調理音以\n外の雑音（水が流れる音，キッチンタイマーの音，人の話し声等）が含まれたデータであ\nる．調理音5 から調理音10 は陳らが収集したデータを使用しており，静かな環境下で得\nられたデータである[26]．これらのデータを利用して解析および手法の検討を実施する．\n表4.1: 本研究で利用した唐揚げの調理音データ一覧\n時間[s]\n温度[◦C]\n個数[個]\n油使用回数[回]\n雑音の有無\n調理音1\n269\n180\n7\n1\n有\n調理音2\n280\n180\n7\n2\n有\n調理音3\n258\n180\n7\n1\n有\n調理音4\n279\n180\n7\n2\n有\n調理音5\n247\n170\n7\n1\n無\n調理音6\n300\n170\n7\n2\n無\n調理音7\n313\n170\n10\n1\n無\n調理音8\n361\n170\n10\n2\n無\n調理音9\n300\n170\n5\n1\n無\n調理音10\n271\n170\n5\n2\n無\n唐揚げの一般的な調理時間および調理油の温度を調査したところ，平均4 分程度で170◦C\nから180◦C の調理油で調理していることがわかっている（表B.1）．よって，表4.1 のデー\nタも一般的な調理データであると考えられる．\n4.1\n調理音および特徴量の解析手法\n本節では，調理音の解析に利用した振幅スペクトログラムおよび特徴量の解析に利用し\nた手法を述べる．\n4.1.1\nスペクトログラム解析\n本研究では，調理音データの解析に4.2.1 項で後述する，振幅スペクトログラムを用い\nる．図4.1 に示すように，振幅スペクトログラムを可視化することで，視覚的に解析する\nことを可能にする．\nこの振幅スペクトログラムを用いることで，音響的な特徴の時間変化を詳細に確認でき，\n特定のイベントが発生する瞬間を視覚的に捉えることが可能となる．そのため，5.2.4 項\n19\n図4.1: 調理音3 における振幅スペクトログラムの可視化\nでは，振幅スペクトログラムを基に調理音の変化点を特定し，ラベリングを実施した．特\nに，クラスの変化が明確に反映される周波数帯域の傾向を分析し，それをラベル付けの指\n標として活用した．\n4.1.2\n主成分分析\n主成分分析（Principal component analysis, PCA）は，多次元データの情報を可能な限\nり損なわずに低次元に圧縮する手法である[35]．PCA はデータの分散が最大となる方向\nを見つけ，その方向を基にデータを新しい座標軸へ変換することで次元を削減する．\n高次元の特徴量空間において，データの分布やクラス間の関係を直感的に理解すること\nは困難である．PCA を用いることで，データの主要な変動方向を抽出し，低次元空間上\nに可視化する．\n本研究では，PCA 利用して3 次元に削減された特徴量の分布を可視化する．これによ\nり，データのクラスタリング傾向や分離性を評価する．\n4.1.3\nt 分布型確率的近傍埋め込み法\nt 分布型確率的近傍埋め込み法（t-distributed stochastic neighbor embedding, t-SNE）\nは，高次元データを低次元空間（通常は2 次元または3 次元）に埋め込むための非線形次\n元削減手法である[36]．特に，データの局所的な構造を保持することに優れており，クラ\nスタリングや特徴量のパターンを視覚的に分析するために用いられる．高次元空間におけ\n20\nるデータ点間の近傍関係を，低次元空間上で可能な限り保持するように変換する．そのた\nめに，データ点間の類似度を確率分布として定義し，それを低次元空間に最適化する．\n本研究ではPCA と同様に，t-SNE を用いて特徴量の分布を可視化し，データのクラス\nタリング傾向や類似性を評価する．\n4.2\n調理音から抽出される音響特徴量\n本節では，各種識別手法で使用する音響特徴量の算出方法を述べる．\n4.2.1\n振幅スペクトログラム\n振幅スペクトログラムは，調理音データに対してSTFT[37] により得られる．フーリエ\n変換は，時間領域の信号を周波数領域に変換し，信号の周波数成分を解析するための基本\n的な手法である[38]．また，任意の周期信号を複数の正弦波または余弦波に分解可能であ\nることを示している．信号x(t) のフーリエ変換は式4.1 で定義される．\nX(f) =\n∫∞\n−∞x(t)e−j2πft dt\n(4.1)\nここで，X(f)は周波数f における信号のフーリエ変換，x(t)は時間領域での信号，e−j2πft\nはフーリエ変換の基底関数，t は時間変数，f は周波数定数である．\nまた，STFT は信号を短い時間区間ごとに区切ってフーリエ変換を適用する．これによ\nり時間的な周波数変化の解析が可能となる．STFT は以下の式4.2 で定義される．\nX(t, f) =\n∫∞\n−∞x(τ)h(τ −t)e−j2πfτdτ\n(4.2)\nここで，X(t, f) は時刻t における周波数f のSTFT 結果，x(τ) は時間領域の入力信号，\nh(τ −t) は窓関数，e−j2πfτ はフーリエ変換の基底関数である．振幅スペクトログラムは式\n4.2 の絶対値を取ることで求められるため，式4.3 となる．\nS(t, f) = |X(t, f)|\n(4.3)\n振幅スペクトログラムを求めることで，特定の時間帯で強く現れる周波数成分を特定可\n能である．図4.2 は調理音3 の音波形とその波形にSTFT を適用した結果である．\n図4.2 のSTFT を適用した結果から，0 Hz から2,500 Hz の周波数帯の成分が大きいこ\nとがわかる．このようにして得られた振幅スペクトログラムの各時間に対して，すべての\n周波数の振幅の平均を計算した値を変化点検出に利用した．\n4.2.2\nMFCC\nMFCC は低周波成分の解像度は高く，高周波成分は低いという人間の聴覚の周波数認識\n特性を反映した特徴量である[39]．音声認識および楽器の識別，調理支援など幅広い分野\nで利用されている．MFCC の計算手順は以下の通りである．まず，式4.4 により窓関数を\n適用した音声フレーム信号x(n) に対し，DFT を適用して周波数領域のスペクトルを取得\nする．\n21\n図4.2: 調理音3 における音波形（上）からSTFT により得られた平均振幅スペクトルの\nプロット（下）\nX(f) =\nN−1\n∑\nn=0\nx(n)e−j2πfn/N\n(4.4)\nここで，N はフレームの長さである．式4.4 の二乗を取ることで，各短時間区間のパワー\nスペクトルP(f) を求める（式4.5）．\nP(f) = |X(f)|2\n(4.5)\n次に人間の聴覚特性を考慮するため，メル周波数軸上で等間隔に並んだ三角窓のバンド\nパスフィルタで構成されるメルフィルタバンクを適用する．メル周波数とは，1,000 Hz の\n単一の周波数で構成された音を1,000 mel の音高として，人間の音高知覚を考慮した尺度\n（メル尺度）でスケーリングした周波数である[40]．メル尺度は式4.6 で表され，周波数f\nHz をメル周波数M mel とするM(f) としてスケーリングされる．\nM(f) = 2595 log10\n(\n1 + f\n700\n)\n(4.6)\n式4.6 を適用して，メル周波数にスケーリングされたパワースペクトルP(M) をメルフィ\n22\nルタバンクと畳み込む．臨界帯域パワースペクトルのサンプルをθ(Mk)(k = 1, . . . , K) と\nして式4.7 で得る．\nθ(Mk) =\n∑\nM\nP(M −Mk)ψ(M)\n(4.7)\nここで，Mk はメルフィルタの中心周波数，ψ(M) は臨界帯域のマスキング曲線である．\n計算された臨界帯域パワースペクトルθ(Mk) に対して，式4.8 による対数変換を適用する．\nX(k) = ln(θ(Mk)),\nk = 1, . . . , K\n(4.8)\n最後に離散コサイン変換（Discrete Cosine Transform，DCT）を適用してMFCC を取\n得する（式4.9）．\nMFCC(d) =\nK\n∑\nk=1\nXk cos\n[\nd(k −0.5) π\nK\n]\n,\nd = 1, . . . , D\n(4.9)\n本研究では唐揚げを揚げる際に生じる調理音の変化を利用しており，その変化は人間の\n耳で十分感じ取れる音の変化である．そのため本研究では機械学習による揚げ終わり判定\nモデルを構築する際に，MFCC を音響特徴量として検討している．また，MFCC は，20\n次元，DFT の窓サイズ1,024 で取得する．\n4.2.3\nウェーブレット変換\nウェーブレット変換は，信号を異なるスケール（周波数）で分解することで，時間-周\n波数解析を可能にする信号処理手法である[41][42]．ウェーブレット変換は，基底関数で\nあるマザーウェーブレットを異なるスケールと時間シフトを用いて変形しながら，信号を\n解析する．マザーウェーブレットは，スケールパラメータa と時間シフトパラメータb に\nよって次の式4.10 のように定義される．\nψa,b(t) =\n1\n√aψ\n(t −b\na\n)\n(4.10)\nウェーブレット変換には，大きく分けて連続ウェーブレット変換（Continuous Wavelet\nTransform: CWT）と離散ウェーブレット変換（Discrete Wavelet Transform，DWT）の\n2 種類が存在する．本研究では，計算コストが低く，信号の階層的分解が可能なDWT を\n用いる．\nDWTは，信号を異なる周波数帯域に分解し，階層的に特徴を抽出する手法である．DWT\nは式4.11 で得られる．\nW(j, k) =\nN−1\n∑\nn=0\nx(n)ψj,k(n)\n(4.11)\nここで，x(n) は入力信号，N は信号の長さである．DWT の特徴の一つは，多重解像度\n解析によって信号を段階的に分解できることである．各分解レベルで，入力信号s(t) は式\n4.12 のように表される．\n23\ns(t) = An +\nn\n∑\ni=1\nDi\n(4.12)\nここで，An はレベルn の低周波成分（近似係数），Di は各段階の高周波成分（詳細係\n数）である．図4.3 は，多重解像度解析の概念を示している．入力信号s が分解され，レ\nベル1 の近似係数A1 と詳細係数D1 が得られる．レベル1 の近似係数を分解するとレベ\nル2 の近似係数と詳細係数が得られる．このように近似係数の分解を任意のレベルまで繰\nり返すことが可能である．この処理は，入力信号および近似係数に対してローパスフィル\nタおよびハイパスフィルタを適用することと等しい[43]．\n図4.3: DWT による多重解像度解析の概念図\n本研究では，機械学習による揚げ終わり判定モデルの構築の際に，レベル10 までの近\n似係数および詳細係数を取得し，これらの係数から統計的特徴量を算出している．算出す\nる統計的特徴量は表4.2 にまとめた通りである．\nこれらの特徴を利用してウェーブレット変換を検討する．また，本研究ではDaubechies\n基底を使用してウェーブレット変換を実施する[44]．\n4.3\n調理段階の識別手法\n4.3.1\n機械学習分類手法\n唐揚げの調理音から揚げ終わりを検出する手法として機械学習を検討する．本研究では\n教師あり学習を使用し，前節で述べた音響特徴量を検討する．機械学習はPython の機械\n学習ライブラリである「sckit-learn」を用いて実装する[45]．sckit-learn は，データの前処\n理および多種多様な機械学習手法の取り扱いが可能なライブラリである．なお，XGBoost\nは「xgboost」ライブラリを用いて実装する[46]．本項では，機械学習の際に検討する分\n類器を示す．\n24\n表4.2: ウェーブレット変換から算出する統計的特徴量一覧\n特徴量名\n説明\n近似係数の平均値\n低周波成分の平均的なエネルギーを表す．揚げ物の音\nの全体的なエネルギーの変化を捉える．\n詳細係数の平均値（レベルn）\nレベルn の詳細係数の平均．高周波成分の傾向を示\nし，油のはじける音の変化を測定．\n標準偏差\nレベルn の詳細係数の散らばり具合を示す．音の変\n動の大きさを定量化．\n最大値\nレベルn の詳細係数の最大値．揚げ物のピーク音を\n捉える．\n最小値\nレベルn の詳細係数の最小値．音の静かな瞬間を捉\nえる．\n尖度\nエネルギー分布の鋭さを示す．音の分布が尖っている\nかどうかを評価．\n歪度\n分布の左右対称性を評価し，特定の方向に偏った音の\n傾向を分析．\nシャノンエントロピー\nエネルギーの不確実性を測る指標．音のランダム性や\n複雑さを評価．\n分散\nデータのばらつきを表し，音の変動の大きさを定量化\nする．\n平均絶対値\n各詳細係数の絶対値の平均を計算し，音の振幅の平均\n的な大きさを示す．\nサポートベクターマシン\nSVM は，統計的学習理論に基づく機械学習手法の一つである[47]．異なるクラスのデー\nタを分離する最適な超平面を求めることを目的とし，クラス間のマージンを最大化するこ\nとによって分類する．データが線形分離できない場合には，カーネル関数を利用すること\nで高次元空間へ写像し，線形分離可能な空間で分類する．この手法をカーネルトリックと\n呼ぶ[48]．本研究では，以下に示す4 種類のカーネルを検討する．\n1. Linear カーネル（SV Mlinear）\n特徴空間への変換をせずにそのまま線形分類するカーネル．このカーネルを用いた\n場合，通常の線形分類器と類似した振る舞いをするが，マージン最大化の特性によ\nりロバストな分類が可能となる．\n2. Polynominal カーネル（SV Mpoly）\n非線形の特徴空間を利用するためのカーネル．データを高次元の多項式空間にマッ\nピングすることで，線形分離が困難なデータに対しても，非線形な分離境界を構築\nし，適切な分類を可能にする．\n3. Radial Basis Function カーネル（SV Mrbf）\nデータを無限次元の特徴空間へ非線形変換するカーネル．線形分離が困難なデータ\nにも適用可能であり，局所的な影響を考慮し，データの分布に応じた柔軟な分類が\n可能である．\n25\n4. Sigmoid カーネル（SV Msigmoid）\nニューラルネットワークの活性化関数であるシグモイド関数に基づいたカーネル[49]．\nニューラルネットワークの隠れ層に相当する特徴変換を実施する．\nガウシアンナイーブベイズ\nガウシアンナイーブベイズ（Gauusian Naive Bayes，GNB）は単純な確率論的アルゴ\nリズムであり，ベイズの定理を用いたナイーブベイズアルゴリズムの1 種である[50][51]．\nGNB は，各クラスごとに特徴量が独立したガウス分布に従うと仮定し，事後確立を求め\nることで分類する．この仮定に基づき，学習データから各クラスごとの平均と分散を推定\nし，新しいデータに対するクラスの事後確率を計算する．\nk 近傍法\nk 近傍法（k-Nearest Neighbors，kNN）は，距離に基づく非パラメトリックな分類アル\nゴリズムである[52]．この手法は，未知のデータ点に対して訓練データ内の最も近いk 個\nのデータ点（近傍）を参照し，多数決に基づいて分類する．分類手順は以下の通りである．\n1. 新しいデータ点が与えられたとき，訓練データに含まれるすべてのデータ点との距\n離を計算する．\n2. 距離が近い上位k 個のデータ点を選択する．\n3. 選択したデータ点のクラスを多数決で決定し，最も多く含まれるクラスを新しいデー\nタのクラスとして割り当てる．\nランダムフォレスト\nランダムフォレストは，決定木を基にしたアンサンブル学習の一手法である[53]．この\n手法は複数の決定木を構築し，それらの予測を統合することで，単一の決定木に比べて過\n学習を抑え，頑健な分類を実現する．\nXGBoost\nXGB は，勾配ブースティング（Gradient Boosting）を基盤とした機械学習手法であり，\n従来の勾配ブースティング決定木の改良版として開発された[54][55]．複数の決定木を逐\n次的に学習し，予測誤差を最小化することでモデルを最適化するブースティング手法で\nある．各ステップで新しい決定木を作成し，既存のモデルが予測しきれなかった誤差（残\n差）を補正するように学習を進める．\n26\nロジスティック回帰\nロジスティック回帰は，線形分類モデルであり，特に二値分類問題に適している[56]．こ\nの手法は，線形回帰を拡張し，出力を確率として解釈できるようにすることで，分類タス\nクに適用可能としている．ロジスティック回帰では，線形回帰と同様に入力特徴量の線形\n結合を用いて決定境界を定めるが，出力が0 または1 のクラスラベルに適合するよう，シ\nグモイド関数を用いて変換する．シグモイド関数は，入力値を0 から1 の範囲にマッピン\nグする非線形関数であり，出力を確率として解釈することが可能となる．\n4.3.2\nリサンプリングによる不均等データ処理手法\n本研究で扱う調理音データのクラスには大きな偏りがあったため，少数クラスに対して\nはオーバーサンプリング，多数クラスに対してはアンダーサンプリングを適用する．これ\nらのリサンプリングはPython のライブラリである「imbalanced-learn」を用いて実装す\nる[57]．imbalanced-learn は，scikit-learn に依存しており，不均等なクラスを持つ分類を\n扱うためのツールを提供する．本項では，機械学習の際に検討するリサンプリング手法を\n示す．\nオーバーサンプリング手法\n本研究で検討する3 種類のオーバーサンプリング手法を示す．\n1. ADASYN\nADASYN（Adaptive Synthetic Sampling）は，少数クラスに対して適応的に合成デー\nタを生成することにより，データの分布をより均衡に近づける[58]．合成データの生\n成は，少数クラス内の各データ点の近傍におけるデータ密度を考慮し，不均衡度が\n高い領域でより多くのサンプルを生成するように設計されている．\n2. SMOTE\nSMOTE（Synthetic Minority Over-sampling Technique）は，単純なデータのコピー\nではなく，少数クラスのデータ間で線形補間を実行し，新しいサンプルを生成する\n[59]．この手法により，データの分布をより自然に拡張し，学習モデルの汎化性能を\n向上させることが可能となる．本研究では，SMOTE を拡張したBorderline SMOTE\nおよびSVMSMOTE を検討する．\n• Borderline SMOTE\nBorderline SMOTE（BSMOTE）は，クラスの決定境界付近のマイノリティク\nラスのデータ点に重点を置いて合成データを生成することで，分類性能の向上\nを図る[60]．分類器の学習において，クラスの境界付近のデータは分類が特に難\nしく，誤分類のリスクが高いため，これらのデータを強化することで，モデルの\n分類性能を向上が見込まれる．\n• SVMSMOTE\nSVMSMOTE（Support Vector Machine Synthetic Minority Over-sampling Tech-\nnique）は，SMOTE と同様に少数クラスのデータ間で合成サンプルを生成する\n27\nが，その際にSVM を用いて，分類の境界付近にあるデータ点を選択し，重点的\nにサンプリングする[61]．この手法により，モデルが学習する際の決定境界を\nより適切に調整でき，分類性能の向上が期待される．SVMSMOTE はSVM 同\n様，4.3.1 節で述べたカーネルを選択できるため，同様に4 種類のカーネルを検\n討する．\nアンダーサンプリング手法\n本研究で検討する5 種類のアンダーサンプリング手法を示す．\n1. Cluster Centroids\nClusterCentroids（CC）は，多数クラスのデータをクラスタリングし，各クラスタの\n重心を代表点としてサンプリングすることで，データのバランスを調整する手法で\nある[62]．この手法は，データの情報をなるべく保持しつつ，多数クラスのデータサ\nイズを削減することを目的としている．\n2. Condensed Nearest Neighbour\nCondensed Nearest Neighbour（CNN）は，分類に必要なデータ点を保持しつつ，冗\n長なデータ点を削除する[63]．少数クラスのデータをそのまま保持し，多数クラスの\nデータからランダムに1 つのデータ点を選択し，初期プロトタイプセットS を作成\nする．残りの多数クラスのデータを，S を用いて1-NN 分類を実施する．もし誤分類\nされた多数クラスのデータ点が存在すれば，それをS に追加する．すべての多数ク\nラスのデータ点が正しく分類されるまで，このプロセスを繰り返すことにより，分\n類の決定境界を形成するために必要なデータ点のみを保持し，不必要なデータ点の\n削除が可能となる．\n3. Near Miss\nNearMiss は，多数クラスのデータ点を削減する際に，少数クラスとの近傍関係を考\n慮することで，適切なデータ削減を実現する[64]．NearMisss にはバージョン1 から\n3 の3 種類存在し，それぞれ異なる基準で多数クラスのデータを削減する．\n• NearMiss-1（NM1）\n各多数クラスのデータ点について，少数クラスのデータ点までの距離を計算す\nる．次に，少数クラスのk 個の最近傍データ点との距離の平均を求める．距離\nの平均が最も小さい多数クラスのデータ点を保持し，それ以外のデータを削除\nする．\n• NearMiss-2（NM2）\n各多数クラスのデータ点について，少数クラスのデータ点までの距離を計算す\nる．次に，少数クラスのk 個の最近傍データ点との距離の平均を求める．距離\nの平均が最も大きい多数クラスのデータ点を保持し，それ以外のデータを削除\nする．\n• NearMiss-3（NM3）\n各少数クラスのデータ点に対して，多数クラスのデータ点との距離を計算する．\n28\n最も近いN 個の多数クラスのデータ点のみを保持し，それ以外の多数クラスの\nデータを削除する．\n本研究では，3 種類のバージョンのNearMiss を検討する．\n4. Neighbourhood Cleaning Rule\nNeighbourhood Cleaning Rule（NCR）は，データセット内のノイズや誤分類の可能\n性が高いデータを削除することで，分類モデルの精度を向上させる手法である[65]．\nNCR の手順は，まず，各データに対してkNN を適用し，近傍データ点のクラス分布\nを分析する．特定のデータ点が，近傍の多数派クラスと異なるクラスである場合，そ\nのデータ点は「ノイズ」または「誤分類される可能性が高いデータ」とみなされる．\n次に，近傍の多数クラスのデータ点に囲まれた少数クラスのデータは保持し，近傍の\nデータ点と一致しない多数クラスのデータ点を削除する．最後に，決定境界を維持\nするため，近傍の多数クラスのデータと一致しない少数クラスのデータを削除する．\n5. One-Sided Selection\nOne-Sided Selection（OSS）は，多数クラスの冗長なデータを削減しつつ，少数クラ\nスの重要なデータを保持する手法である[66]．これは，CNN とTomek Links という\n2 つのアプローチを組み合わせることで実現されている．Tomek Links は，異なるク\nラスに属する2 つのデータ点が互いに最近傍である場合，それらのデータ点がクラ\nスの境界付近に位置することを示す[67]．OSS では，Tomek Links のペアのうち，多\n数クラスのデータ点を削除する．これにより，決定境界の近くにある多数クラスの\nデータ点を削減する．その後，CNN を適用し，多数クラスのデータセットを縮小す\nる．このプロセスにより，ノイズや冗長なデータを削減しながら，分類の決定境界\nを明確化することが可能となる．\n本研究では，本項で述べたオーバーサンプリング手法およびアンダーサンプリング手法\nを組み合わせて，不均等データ処理を実施する．\n4.3.3\n調理音の変化点検出手法\n変化点検出は，時系列データにおいて統計的な性質が変化する点を特定する技術である．\n本研究では，唐揚げの揚げ終わりの音を変化点として捉え，調理過程における音響特徴の\n変化を解析することで，適切な揚げ時間の検出が可能であるかを検討する．変化点検出は\nPython のライブラリである「ruptures」を用いて実装する[68]．ruptures は，非定常信号\nの分析とセグメンテーションのためのメソッドが取り扱い可能なライブラリである．\n本研究では，変化点検出手法の一つであるWindow アルゴリズムを利用する[69]．この\n手法は，データの局所的な変化を捉えやすく，リアルタイムの変化点検出に適している．\nWindow アルゴリズムは，データストリームに沿ってスライドする2 つのウィンドウを用\nいて，それぞれのウィンドウ内の信号の統計的特性を比較し，差異を計測することで変化\n点を検出する．与えられたコスト関数c に対して，区間a, b における信号y の差異を測る\n指標d は式4.13 で定義される．\nd(ya.t, yt.b) = c(ya.b) −c(ya.t) −c(yt.b),\n(a < t < b)\n(4.13)\n29\n本研究では，マハラノビス距離をコスト関数として利用する．マハラノビス距離は，デー\nタの共分散構造を考慮した距離計量を計算する．マハラノビス型の距離を使用したコスト\n関数cM は式4.14 のように定義される．\ncM(ya.b) =\nb\n∑\nt=a+1\n∥yt −¯ya.b∥M 2\n(4.14)\nここで，¯ya.b は部分信号ya.b の平均値である．マハラノビス距離は，通常のユークリッ\nド距離よりも特徴を適切に捉えることが可能である．\n変化点検出では，コスト関数を最小化することで変化点を決定する．その際，式4.15 で\n与えられるペナルティ項を加えた目的関数を最小化する．\nTotalCost =\nk\n∑\ni=0\ncM(yti,ti+1) + λ · k\n(4.15)\nここで，cM(yti,ti+1) は各セグメントti, ti+1 間におけるコスト関数，k は検出された変化\n点の数，λ はペナルティの重みである．ペナルティが大きいほど，変化点の数が減少し，\n小さいほど変化点が増加する．よって，適切なペナルティを設定する必要がある．\n本研究では，前述した機械学習手法に加え，本変化点検出手法の精度を比較し，最も精\n度の良い手法をアプリケーションに実装する．\n4.3.4\n調理音に含まれる雑音の処理\n調理音には，お皿がぶつかる音やタイマーの音など突発的な雑音が含まれており，目\n立っている．そこで本研究では，メディアンフィルタを使用する[70]．メディアンフィル\nタは，突発的な大きなノイズの除去に有効である．メディアンフィルタの例を図4.4 に示\nす．データの集合を降順に並べ，中心の位置の値（中央値）を出力する．これにより，突\n発的な値を除去しつつ，トレンドの変化を合理的に維持することができる．\n図4.4: メディアンフィルタの仕組み\nメディアンフィルタは，変化点検出を実施する際に，振幅の平均に対して適用する．\n30\n4.4\n各識別手法の評価方法および評価指標\n本節では，本研究で使用する評価方法および評価指標の4 種類について述べる．\n4.4.1\n一グループ抜き交差検証による評価方法\nまず評価方法について，本研究では唐揚げのフライ調理音10 種類に対して，一グルー\nプ抜き交差検証（Leave-One-Group-Out Cross-Validation, LOGO-CV）を実施する[71]．\nLOGO-CV は，データを予め定義したグループ単位で分割し，各グループを順番にテス\nトデータとして取り除く手法である．本研究におけるLOGO-CV を図4.5 に示す．本研究\nの場合は，データは調理音ごとに分けられているため，各調理音を一つのグループと見な\nし，グループごとに交差検証を実施する．\n図4.5: 本研究における一グループ抜き交差検証\n4.4.2\n評価指標\n性能評価には，適合率，再現率，F1 スコア，および正解率を使用する．機械学習モデル\nの性能評価においては，揚げ途中と揚げ終わりの2 クラス分類におけるモデルの予測結果\nを，実際のクラスと比較したものを混同行列として表す．混同行列の構造を表4.3 に示す．\n表4.3: 混同行列の構造\n実際のクラス0（Negative）\n実際のクラス1（Positive）\n予測クラス0（Negative）\nTN（True Negative）\nFN（False Negative）\n予測クラス1（Positive）\nFP（False Positive）\nTP（True Positive）\n本研究においては，クラス0 が揚げ途中，クラス1 が揚げ終わりを意味する．各要素の\n意味は以下の通りである．\n31\nTN（True Negative，真陰性）\n実際のクラスが揚げ途中（Negative）であり，モデルが正しく揚げ途中と予測した数．\nTP（True Positive，真陽性）\n実際のクラスが揚げ終わり（Positive）であり，モデルが正しく揚げ終わりと予測し\nた数．\nFP（False Positive，偽陽性）\n実際のクラスが揚げ途中（Negative）であるにもかかわらず，モデルが誤って揚げ終\nわりと予測した数．\nFN（False Negative，偽陰性）\n実際のクラスが揚げ終わり（Positive）であるにもかかわらず，モデルが誤って揚げ\n途中と予測した数．\n次に，各評価指標について述べる．適合率は，モデルが揚げ終わり（Positive）と予測\nしたデータのうち，実際に揚げ終わりであったデータの割合を示す．数式は以下の通りで\nある：\nPrecision =\nTP\nTP + FP\n(4.16)\n適合率が高いほど，揚げ終わりと予測したデータの中に誤って揚げ途中が分類される割\n合が少ないことを意味する．本研究では，安全な揚げ終わり判定に重点を置いているた\nめ，適合率を重視する．\n再現率は，実際に揚げ終わり（Positive）であるデータのうち，モデルが正しく揚げ終\nわりと予測した割合を示す．数式は以下の通りである：\nRecall =\nTP\nTP + FN\n(4.17)\n再現率が高いほど，実際に揚げ終わりであるデータを取りこぼさずに予測できているこ\nとを意味する．\nF1 スコアは，適合率と再現率の調和平均であり，バランスの取れた評価指標である．数\n式は以下の通りである：\nF1 = 2 × Precision × Recall\nPrecision + Recall\n(4.18)\nF1 スコアは，適合率と再現率のバランスが重要な場合に用いられる．\n正解率は，全予測のうち正しく分類された割合を示す．数式は以下の通りである：\nAccuracy =\nTP + TN\nTP + TN + FP + FN\n(4.19)\n正解率は全体的なモデルの性能を示すが，クラスの分布が不均衡な場合には注意が必要\nである．\n32\n第5章\n調理音識別手法およびFCGsの開発\n本章では第4 章で述べた解析手法を利用した唐揚げの揚げ終わり分類および検出の精度\n評価について述べる．また，最も精度の良い手法を利用して，リアルタイムで揚げ終わり\nを識別するスマートフォンアプリケーションを開発する．\n5.1\n調理音データのラベリング\n調理音データのラベリングは，音声解析ソフトELANを使用した[72]．本研究では，3.1.1\n項で述べた通り，ラベルの種類を「揚げ途中」と「揚げ終わり」の2 クラスとした．ラベ\nルの基準は実際の音，衣の色の変化，油の気泡の変化，ELAN による波形解析を利用して\n決定した．\n各調理音に対するクラスごとのデータ時間は5.1 のようになっている．\n表5.1: ラベル付けしたデータのラベル時間\n調理時間[s]\n揚げ途中[s]\n揚げ終わり[s]\n調理音1\n269\n243\n26\n調理音2\n280\n240\n40\n調理音3\n258\n224\n34\n調理音4\n279\n253\n26\n調理音5\n247\n236\n11\n調理音6\n300\n290\n10\n調理音7\n313\n302\n10\n調理音8\n361\n340\n21\n調理音9\n300\n285\n15\n調理音10\n271\n259\n12\n揚げ途中から揚げ終わりへの変化の様子は図5.1 のようになっている．揚げ終わりに近\nづくにつれて衣の色がきつね色になり，気泡も細かくなっていることがわかる．\n5.2\n機械学習モデルによる唐揚げの調理音データ分類精度の評価\n本節では，第4 章で述べた手法を利用して，唐揚げの調理音から揚げ途中および揚げ終\nわりの分類が可能な機械学習モデルを検討する．表5.1 の通り，揚げ途中と揚げ終わりク\nラスのデータバランスは不均等である．よって，オーバーサンプリングおよびアンダー\nサンプリングの両手法を適用し，データセットを均等にする．また，分類モデルは1 調\n理音抜き交差検証を実施し，F1 スコア，適合率，再現率，正解率の4 種類の指標で評価\nする．使用する調理音は10 種類であるため，各指標において，10 回分の平均値および標\n33\n図5.1: 揚げ途中から揚げ終わりへの変化の様子\n準偏差を算出して，分類精度として評価する．分類は9 種類の分類器を使用して実施し，\nアンダーサンプリング手法7 種，オーバーサンプリング手法6 種，分類器9 種の378 通り\nをMFCC，ウェーブレット変換から得られる特徴をそれぞれ音響特徴量として利用し検\n証する．\n機械学習の際，窓幅は1 秒，シフト幅は0.25 秒としており，各調理音のサンプリング周\n波数は44.1 kHz である．真値ラベルは，フレームの半分以上が揚げ終わりのラベル時間\nを含む場合は「揚げ終わり」，そうでない場合は「揚げ途中」とラベル付けされた．\n5.2.1\nMFCC 特徴量を使用した分類精度の評価\n本項では，調理音からMFCC を特徴量として抽出した場合の分類精度を評価する．ま\nず，両クラスの割合を5:5 にした場合における，最も高い精度を含むNCR との組み合わせ\nの分類精度を以下に示す．リサンプリングの順序は，アンダーサンプリングを適用した後，\nオーバーサンプリングを適用している．表5.2 はオーバーサンプリングにBSMOTE を適用\nした各分類器による分類精度である．リサンプリング適用前のクラスのサンプル数の比は\nMiddle: Finish = 10, 608: 870 であり，適用後の比は，Middle: Finish = 10, 449: 10, 449\nとなった．\n表5.2: NCR+BSMOTE を適用したMFCC 特徴量の分類精度\n分類器\nF1 スコア\n適合率\n再現率\n正解率\nロジスティック回帰\n0.521 ± 0.345\n0.551 ± 0.312\n0.591 ± 0.424\n0.622 ± 0.150\nランダムフォレスト\n0.105 ± 0.196\n0.847 ± 0.312\n0.071 ± 0.141\n0.527 ± 0.062\nGNB\n0.488 ± 0.424\n0.606 ± 0.356\n0.597 ± 0.512\n0.646 ± 0.179\nkNN\n0.207 ± 0.308\n0.456 ± 0.435\n0.207 ± 0.353\n0.523 ± 0.123\nSV Mlinear\n0.510 ± 0.351\n0.524 ± 0.319\n0.584 ± 0.433\n0.614 ± 0.157\nSV Mpoly\n0.520 ± 0.379\n0.690 ± 0.293\n0.619 ± 0.476\n0.634 ± 0.172\nSV Mrbf\n0.539 ± 0.355\n0.625 ± 0.268\n0.646 ± 0.461\n0.640 ± 0.151\nSV Msigmoid\n0.468 ± 0.410\n0.619 ± 0.373\n0.563 ± 0.497\n0.587 ± 0.224\nXGB\n0.178 ± 0.267\n0.568 ± 0.431\n0.151 ± 0.242\n0.539 ± 0.065\nF1 スコアと適合率がともに6 割を超えているモデルは見受けられなかった．また，5 割\nを超えているモデルにおいても，標準偏差に注目すると安定性が低いことわかる．表5.3\n34\nはオーバーサンプリングにSV MSMOTElinear を適用した各分類器による分類精度であ\nる．リサンプリング後のサンプル比はMiddle: Finish = 10, 449: 8, 898 となった．\n表5.3: NCR+SV MSMOTElinear を適用したMFCC 特徴量の分類精度\n分類器\nF1 スコア\n適合率\n再現率\n正解率\nロジスティック回帰\n0.506 ± 0.294\n0.596 ± 0.264\n0.588 ± 0.419\n0.636 ± 0.129\nランダムフォレスト\n0.059 ± 0.122\n0.701 ± 0.382\n0.037 ± 0.081\n0.557 ± 0.074\nGNB\n0.394 ± 0.411\n0.623 ± 0.358\n0.506 ± 0.520\n0.614 ± 0.181\nkNN\n0.157 ± 0.253\n0.411 ± 0.398\n0.158 ± 0.314\n0.536 ± 0.098\nSVMlinear\n0.549 ± 0.265\n0.591 ± 0.250\n0.643 ± 0.386\n0.645 ± 0.107\nSVMpoly\n0.576 ± 0.324\n0.729 ± 0.193\n0.701 ± 0.417\n0.678 ± 0.130\nSVMrbf\n0.546 ± 0.352\n0.617 ± 0.270\n0.699 ± 0.463\n0.668 ± 0.138\nSVMsigmoid\n0.383 ± 0.381\n0.541 ± 0.371\n0.515 ± 0.512\n0.542 ± 0.225\nXGB\n0.071 ± 0.110\n0.446 ± 0.421\n0.058 ± 0.106\n0.527 ± 0.081\nBSMOTE と同様に，F1 スコアと適合率がともに6 割を超えているモデルはなかった．\nしかし，SV Mpoly はF1 スコアが57.6% ± 32.4%ではあるが，適合率が7 割を超えて安定\nしていることがわかる．表5.4 はオーバーサンプリングにSV MSMOTEpoly を適用した\n各分類器による分類精度である．クラスのサンプル数はMiddle: Finish = 10, 449: 10, 449\nである．\n表5.4: NCR+SV MSMOTEpoly を適用したMFCC 特徴量の分類精度\n分類器\nF1 スコア\n適合率\n再現率\n正解率\nロジスティック回帰\n0.574 ± 0.304\n0.614 ± 0.259\n0.639 ± 0.396\n0.649 ± 0.135\nランダムフォレスト\n0.138 ± 0.227\n0.729 ± 0.401\n0.100 ± 0.166\n0.531 ± 0.064\nGNB\n0.486 ± 0.405\n0.649 ± 0.302\n0.591 ± 0.498\n0.634 ± 0.170\nkNN\n0.218 ± 0.317\n0.460 ± 0.435\n0.226 ± 0.370\n0.516 ± 0.136\nSV Mlinear\n0.559 ± 0.311\n0.588 ± 0.264\n0.626 ± 0.398\n0.634 ± 0.142\nSV Mpoly\n0.535 ± 0.363\n0.705 ± 0.261\n0.629 ± 0.459\n0.637 ± 0.166\nSV Mrbf\n0.574 ± 0.341\n0.645 ± 0.270\n0.691 ± 0.441\n0.656 ± 0.136\nSV Msigmoid\n0.455 ± 0.401\n0.614 ± 0.369\n0.549 ± 0.497\n0.576 ± 0.219\nXGB\n0.252 ± 0.297\n0.462 ± 0.414\n0.217 ± 0.277\n0.560 ± 0.086\nNCR+SV MSMOTEpoly を適用すると，NCR+SV MSMOTElinear 同様，SV Mpoly 分\n類器のF1 スコアが5 割以上かつ適合率7 割以上のモデルであることがわかる．表5.5 は\nオーバーサンプリングにSV MSMOTErbf を適用した各分類器による分類精度である．ク\nラスのサンプル数はMiddle: Finish = 10, 449: 10, 449 である．\n結果，rbfカーネルを使用したSVMSMOTEは，polyカーネルを使用しているSVMSMOTE\nと同様の精度が得られたことがわかる．表5.6はオーバーサンプリングにSVMSMOTEsigmoid\nを適用した各分類器による分類精度である．クラスのサンプル数はMiddle: Finish =\n10, 449: 10, 449 である．\n表5.6 の通り，sigmoid カーネルを使用したSVMSMOTE も，他のカーネルを使用した\nSVMSMOTE と同様の結果となった．表5.7 はオーバーサンプリングにADASYN を適用し\n35\n表5.5: NCR+SV MSMOTErbf を適用したMFCC 特徴量の分類精度\n分類器\nF1 スコア\n適合率\n再現率\n正解率\nロジスティック回帰\n0.570 ± 0.298\n0.613 ± 0.260\n0.632 ± 0.391\n0.644 ± 0.130\nランダムフォレスト\n0.146 ± 0.246\n0.725 ± 0.401\n0.112 ± 0.196\n0.536 ± 0.072\nGNB\n0.487 ± 0.403\n0.653 ± 0.298\n0.591 ± 0.497\n0.633 ± 0.171\nkNN\n0.219 ± 0.320\n0.457 ± 0.433\n0.228 ± 0.375\n0.516 ± 0.140\nSV Mlinear\n0.558 ± 0.309\n0.586 ± 0.265\n0.627 ± 0.396\n0.631 ± 0.141\nSV Mpoly\n0.528 ± 0.363\n0.702 ± 0.264\n0.621 ± 0.460\n0.633 ± 0.164\nSV Mrbf\n0.568 ± 0.343\n0.642 ± 0.268\n0.684 ± 0.442\n0.652 ± 0.134\nSV Msigmoid\n0.456 ± 0.400\n0.614 ± 0.370\n0.549 ± 0.496\n0.576 ± 0.219\nXGB\n0.217 ± 0.267\n0.457 ± 0.382\n0.177 ± 0.234\n0.544 ± 0.081\n表5.6: NCR+SV MSMOTEsigmoid を適用したMFCC 特徴量の分類精度\n分類器\nF1 スコア\n適合率\n再現率\n正解率\nロジスティック回帰\n0.561 ± 0.299\n0.609 ± 0.261\n0.622 ± 0.390\n0.638 ± 0.128\nランダムフォレスト\n0.144 ± 0.240\n0.681 ± 0.390\n0.110 ± 0.195\n0.532 ± 0.071\nGNB\n0.491 ± 0.399\n0.665 ± 0.293\n0.593 ± 0.495\n0.634 ± 0.171\nkNN\n0.219 ± 0.321\n0.457 ± 0.433\n0.228 ± 0.375\n0.516 ± 0.140\nSV Mlinear\n0.550 ± 0.309\n0.583 ± 0.266\n0.616 ± 0.396\n0.626 ± 0.140\nSV Mpoly\n0.527 ± 0.364\n0.701 ± 0.266\n0.620 ± 0.461\n0.632 ± 0.165\nSV Mrbf\n0.568 ± 0.343\n0.642 ± 0.268\n0.685 ± 0.442\n0.653 ± 0.135\nSV Msigmoid\n0.456 ± 0.400\n0.614 ± 0.370\n0.549 ± 0.496\n0.577 ± 0.219\nXGB\n0.217 ± 0.287\n0.486 ± 0.440\n0.186 ± 0.256\n0.546 ± 0.075\nた各分類器による分類精度である．クラスのサンプル数はMiddle: Finish = 10, 449: 10, 428\nである．\n結果として，NCR に対しては，どのオーバーサンプリング手法を組み合わせても，同\nじような結果が得られた．その中でも僅差でNCR+SV MSMOTElinear の組み合わせに\nおける，SV Mpoly 分類器を使用した際の分類精度が，最も良い結果となった．しかし，全\n体としてF1 スコアと適合率が8 割以上の分類精度となるモデルは構築できなかった．\n原因として，以下の3 点が考えられる．\n1 つは，オーバーサンプリング，特にSMOTE やADASYN は，少数クラスのデータを\n合成するが，既存のデータポイントを補完しているだけであり，新しい情報を追加するわ\nけではない．そのため，訓練データに過度に適合し，汎化性能が低下した可能性がある．\n2 つ目として，NCR+SV MSMOTElinear の組み合わせにおいて，元のデータセットの\nクラス比である10, 608: 870 から10, 449: 8, 898 にリサンプリングしたように，本来のデー\nタ分布と大きく異なるデータで学習した．これにより，クラスの決定境界が不安定になっ\nた可能性が考えられる．\n3 つ目として，F1 スコアのばらつきが大きいことからも，特徴量が十分にクラスを分離\nできていない可能性が考えられる．\nよって，PCA およびt-SNE による特徴の可視化を実施し，クラス間の分離が適切であ\n36\n表5.7: NCR+ADASYN を適用したMFCC 特徴量の分類精度\n分類器\nF1 スコア\n適合率\n再現率\n正解率\nロジスティック回帰\n0.553 ± 0.320\n0.609 ± 0.270\n0.618 ± 0.418\n0.645 ± 0.139\nランダムフォレスト\n0.119 ± 0.217\n0.839 ± 0.311\n0.085 ± 0.165\n0.533 ± 0.066\nGNB\n0.475 ± 0.415\n0.614 ± 0.367\n0.572 ± 0.498\n0.634 ± 0.174\nkNN\n0.193 ± 0.309\n0.418 ± 0.405\n0.203 ± 0.363\n0.509 ± 0.131\nSV Mlinear\n0.532 ± 0.303\n0.572 ± 0.271\n0.594 ± 0.402\n0.615 ± 0.136\nSV Mpoly\n0.531 ± 0.377\n0.691 ± 0.295\n0.632 ± 0.469\n0.639 ± 0.169\nSV Mrbf\n0.570 ± 0.341\n0.643 ± 0.269\n0.684 ± 0.441\n0.655 ± 0.137\nSV Msigmoid\n0.446 ± 0.399\n0.611 ± 0.368\n0.538 ± 0.500\n0.573 ± 0.216\nXGB\n0.083 ± 0.129\n0.604 ± 0.434\n0.053 ± 0.082\n0.493 ± 0.059\nるかを確認する．\n5.2.2\nPCA およびt-SNE によるMFCC 特徴量解析\n前項で最も分類精度の良い分類器を含んでいた，NCR+SV MSMOTElinear のリサンプ\nリング手法前後を解析し，リサンプリングの影響およびMFCC のクラス分離能力を確認\nする．\n図5.2 はPCA の結果である．左図がリサンプリング適用前で，右図はリサンプリング\n適用後である．青色が揚げ途中で，赤色は揚げ終わりを示している．\nリンサプリング前は，揚げ途中が圧倒的に多く，揚げ途中は少数点在していることがわ\nかる．また，揚げ途中は3 つほどの異なるクラスタに分かれており，データ構造に一定の\nパターンがあるように見える．揚げ終わりは，揚げ途中のデータの間に少しずつ散らばっ\nており，明確なクラスタを形成していないことがわかる．このことから，揚げ終わりは明\n確な特徴を持たない，もしくは揚げ途中の中に埋もれており，単純な決定境界による分類\nが困難であると考えられる．また，揚げ途中がいくつかのクラスタを形成していることか\nら，揚げ途中内部に異なるサブクラスがあると推測される．\nこれに対して，リサンプリング後は，揚げ終わりのデータは増加したが，データの分布\nは大きく変化しておらず，揚げ途中のデータ構造もリサンプリング前と大きな変化が見ら\nれないことがわかる．このことから，揚げ途中と揚げ終わりの分離が改善されておらず，\n揚げ終わりのデータ数が単に増加しただけとなっている可能性が考えられる．\n次に，t-SNE による解析結果を図5.3 に示す．左図がリサンプリング適用前で，右図は\nリサンプリング適用後である．\nリサンプリング前は，揚げ途中が圧倒的に多く，揚げ終わりはデータの端や一部にまと\nまって分布していることがわかる．また，揚げ終わりは明確なクラスタを形成せず，揚げ\n途中のデータの間に散らばっている．\nこれに対して，リサンプリング後は揚げ終わりのデータが大幅に増加し，データの形は\n曲線状になっており，不自然な分布が見られる．\n原因として，揚げ終わりのサンプルを人工的に増やしたことにより，歪んだデータ構造\nになった可能性が高い．この曲線状になった分布が，モデルの学習に悪影響を及ぼしてい\n37\n図5.2: PCA によるMFCC 解析結果（NCR+SV MSMOTElinear 適用前後）\nる可能性が考えられる．特に，オーバーサンプリングにより，データバランスを5:5 にし\nたため，決定境界付近でデータが過剰合成されていると考えられる．\n図5.3: t-SNE によるMFCC 解析結果（NCR+SV MSMOTElinear 適用前後）\n以上の結果より，クラスのデータバランスを調整する必要があると考える．そのため，\nリサンプリングのバランスを5:5 ではなく，6:4 のように調整して，再度モデルの性能を評\n価する．また，揚げ途中クラスの細分化を実施し，データバランスの不均等を緩和する．\n5.2.3\nリサンプリングバランスの調整による分類モデルの再評価\n本項では，データバランスを6:4 となるようにリサンプリングを適用し，機械学習モデ\nルを検証する．ここで，アンダーサンプリング手法の内，リサンプリングの割合を指定で\n38\nきないアルゴリズムであるCNN，NCR，OSS は検討対象外とした．\n5.2.4\n振幅スペクトログラムに基づく再ラベリング\n揚げ途中クラスを細分化し，データセットの不均等を緩和するために，再度ラベリング\nを実施する．ラベリングは主に，振幅の強度に基づいて実施し，振幅の強度は調理音の振\n幅スペクトログラムを可視化することで視覚的に捉える．ラベリング後は，実際の調理音，\n調理時に撮影されていた動画を確認して，各ラベルの整合性が取れているか確認する．\nラベリングの結果，各調理音は4 クラスに分けられた．図5.4 は，調理音3 におけるラ\nベリング結果である．白線はクラスが切り替わる瞬間を示している．\n図5.4: 調理音3 における振幅スペクトログラムに基づくラベリング結果\nこのようにして，各調理音の振幅スペクトログラムを解析し，再度ラベリングした結果\nを表5.8 に示す．\n結果，2 クラスでラベリングしていた時よりも，揚げ途中が細分化されたため，データ\nセットの不均等な状態が緩和された．本研究では揚げ終わりの識別に重点を置いているた\nめ，ラベル3 と揚げ終わりであるラベル4（揚げ終わり）の二値分類による性能評価を実\n施する．\n5.2.5\n4 クラスにおけるMFCC 特徴量による分類精度の評価\n前項でのラベリング結果を基に，MFCC 特徴量を利用して，分類精度の評価を実施す\nる．MFCC を抽出した際のデータバランスは，クラス1: クラス2: クラス3: 揚げ終わり=\n39\n表5.8: 振幅スペクトログラムに基づくラベリング結果一覧\nラベル1 [s]\nラベル2 [s]\nラベル3 [s]\nラベル4（Finish）[s]\n調理音1\n0 - 45\n45 - 123\n123 - 214\n214 - 269\n調理音2\n0 - 50\n50 - 129\n129 - 238\n238 - 280\n調理音3\n0 - 32\n32 - 129\n129 - 218\n218 - 258\n調理音4\n0 - 43\n43 - 147\n147 - 225\n225 - 278\n調理音5\n0 - 60\n60 - 120\n120 - 176\n176 - 246\n調理音6\n0 - 75\n75 - 174\n174 - 208\n208 - 300\n調理音7\n0 - 34\n34 - 136\n136 - 195\n195 - 313\n調理音8\n0 - 28\n28 - 100\n100 - 215\n215 - 361\n調理音9\n0 - 43\n43 - 106\n106 - 157\n157 - 300\n調理音10\n0 - 63\n63 - 98\n98 - 185\n185 - 270\n1, 812: 3, 156: 3, 076: 3, 434 となった．このうち，クラス3 および揚げ終わりクラスの2 ク\nラスによる分類を実施する．\nまず，図5.5 に再度ラベリングされた結果を基にしたPCA 結果を示す．左図は4 クラス\nすべてのPCA 結果をプロットしており，右図は分類対象とするクラス3 および揚げ終わ\nりをプロットした結果である．\n4 クラスの結果より，クラス1 およびクラス2 は明確なクラスタを形成している部分が\nあるが，クラス3 および揚げ終わりとの境界は曖昧である．右図より，クラス3 と揚げ終\nわりは重なる領域が多いことがわかる．また，クラスタ間に明確な境界がない．\n図5.5: 4 クラスラベルにおけるMFCC のPCA 結果（左図:4 クラス，右図:2 クラス）\n次に，t-SNE による分析を図5.6 に示す．左図より，クラス1 およびクラス2 は比較的\n分離している．また右図より，クラス3 および揚げ終わりは，大部分が重なっており，完\n全に分離されていない．いくつかのクラスタは形成されているが，明確な境界が見られな\nいことがわかる．\n40\n図5.6: 4 クラスラベルにおけるMFCC のt-SNE 結果（左図:4 クラス，右図:2 クラス）\nPCA およびt-SNE の解析結果より，クラス3 および揚げ終わりは，特徴空間において\n極めて似た振る舞いをしている可能性がある．また，現在の特徴セットのみでは，揚げ途\n中と揚げ終わりを十分に区別できないと考えられる．\n表5.9 に，クラス3 および揚げ終わりによる二値分類の結果を示す．リサンプリングを適\n用した際の最も良い分類精度は，F1 スコアが57.6% ± 32.4%，適合率が72.9% ± 19.3%\nであった．この精度と比較すると，全体的に適合率は向上しているが，F1 スコアはどの\n分類器も上回っていない．\n表5.9: MFCC を利用した分類器ごとのクラス3 および揚げ終わりの分類精度\n分類器\nF1 スコア\n適合率\n再現率\n正解率\nロジスティック回帰\n0.496 ± 0.316\n0.649 ± 0.282\n0.620 ± 0.440\n0.587 ± 0.117\nランダムフォレスト\n0.509 ± 0.318\n0.740 ± 0.238\n0.598 ± 0.409\n0.600 ± 0.146\nGNB\n0.471 ± 0.413\n0.799 ± 0.203\n0.588 ± 0.507\n0.662 ± 0.116\nkNN\n0.409 ± 0.294\n0.668 ± 0.250\n0.455 ± 0.388\n0.520 ± 0.194\nSV Mlinear\n0.494 ± 0.308\n0.648 ± 0.282\n0.617 ± 0.437\n0.584 ± 0.110\nSV Mpoly\n0.456 ± 0.390\n0.790 ± 0.217\n0.549 ± 0.481\n0.609 ± 0.181\nSV Mrbf\n0.489 ± 0.371\n0.796 ± 0.221\n0.581 ± 0.469\n0.620 ± 0.161\nSV Msigmoid\n0.463 ± 0.378\n0.784 ± 0.283\n0.562 ± 0.456\n0.563 ± 0.261\nXGB\n0.426 ± 0.279\n0.638 ± 0.285\n0.455 ± 0.372\n0.540 ± 0.146\n以上の結果より，クラス3 および揚げ終わりは，特徴空間において極めて似た振る舞い\nをしている可能性が高く，現在の特徴セットのみでは，揚げ終わりを十分に分類すること\nができないことがわかった．\n41\n5.2.6\nウェーブレット変換による特徴量抽出を利用した分類精度の評価\n次に，ウェーブレット変換を利用した音響特徴量の抽出を検討する．図5.7 はPCA 結\n果であり，左図は4 クラス，右図はクラス3 および揚げ終わりをプロットしている．左図\nより，各クラスは全体的に密集しており，分離していないことがわかる．また，右図より\n揚げ終わりはクラス3 よりも広域に分布しており，一部の揚げ終わりデータは外側に散ら\nばっていることがわかる．このことから，揚げ終わりとクラス3 は異なる特徴を持つ可能\n性がある．しかし，両クラスともに混在している領域があるため，完全な分離は困難であ\nると推測される．\n図5.7: 4 クラスラベルにおけるウェーブレット変換から得られる特徴量のPCA 結果\n（左図:4 クラス，右図:2 クラス）\n図5.8 はt-SNE による解析結果である．左図の4 クラス描画結果から，PCA よりもクラ\nス間のまとまりが明確になっていることがわかる．また，右図のクラス3 および揚げ終わ\nりのプロットより，t-SNE の結果でも両クラスは混在しており，明確な境界がないことが\nわかる．\n以上の解析結果より，クラス3 と揚げ終わりの間には明確な境界が存在しない可能性が\n高く，ウェーブレット変換から算出した特徴量では，クラスの識別に有効でないと考えら\nれる．\n表5.10 に，クラス3 および揚げ終わりによる二値分類の結果を示す．表5.9 の結果と比\n較しても，特筆して精度の差が開いている分類器は存在しない．\n以上の結果より，本研究でウェーブレット変換から算出した特徴量では，クラス3 およ\nび揚げ終わりの分類が困難であることがわかった．\n5.3\n変化点検出による唐揚げの揚げ終わり検出精度の評価\n変化点検出における精度評価は，揚げ途中から揚げ終わりへの変化点（真の変化点）に\n対する検出精度を評価するために，適合率，再現率，F1 スコアを使用する．ここで適合\n42\n図5.8: 4 クラスラベルにおけるウェーブレット変換から得られる特徴量のt-SNE 結果\n（左図:4 クラス，右図:2 クラス）\n率は，検出した変化点のうち，どれだけが真の変化点であったかを表す．再現率は，真の\n変化点がどれだけ正しく検出されたかを表す．真の変化点の検出有無は，許容範囲を設定\nして，その範囲内に検出点が収まっていた場合，検出されたこととする．許容範囲は，真\nの変化点±10 秒と設定する．この値は，1.1.4 で述べた通り，食中毒を防ぐための十分な\n加熱は，鶏肉の中心の温度が75◦C 以上で1 分間以上とされており，前節で再定義した揚\nげ終わりラベルの時間はすべて調理開始から1 分以上経過していることから，危険ではな\nい範囲であることがわかる．また，変化点検出には，時間ごとの振幅の平均を特徴として\n利用した．調理音1 から調理音4 は雑音が含まれているため，振幅の平均に対してメディ\nアンフィルタを適用する．\n解析の結果，最も揚げ終わりの変化点を捉えることが可能なパラメータは，ウィンドウ\n幅30，ペナルティ6.5 であった．以下に，このパラメータを設定した変化点検出による各\n調理音の検出結果を示す．\n図5.9 は調理音1，図5.10 は調理音2 の変化点検出結果である．調理音1 の真の変化点\nは214 秒であり，それに最も近い変化点は214.601 秒で検出されているため，正確に変化\n点を捉えている．調理音2 の真の変化点は238 秒，それに最も近い変化点は259.383 秒で\nあった．調理音2 に対しては正確に変化点を捉えられなかったことがわかる．\n図5.11 は調理音3，図5.12 は調理音4 の変化点検出結果である．調理音3 の真の変化点\nは218 秒であり，検出された変化点は219.413 秒であった．また，調理音4 は真の変化点\nが225 秒，検出された変化点は226.778 秒であった．どちらの変化点検出のおいても，真\nの変化点と2 秒以内の誤差であり，他の変化点も検出されていない．\n図5.13 は調理音5，図5.14 は調理音6 の変化点検出結果である．調理音5 の真の変化点\nは176 秒であり，それに最も近い変化点は176.851 秒であった．また，調理音6 は真の変\n化点が208 秒，それに最も近い変化点は206.891 秒であった．どちらも誤差が2 秒以内に\n収まっているが，他の変化点も検出されている．\n43\n表5.10: ウェーブレット変換を利用した分類器ごとのクラス3 および揚げ終わりの分類精\n度\n分類器\nF1 スコア\n適合率\n再現率\n正解率\nロジスティック回帰\n0.550 ± 0.256\n0.668 ± 0.251\n0.583 ± 0.347\n0.611 ± 0.168\nランダムフォレスト\n0.419 ± 0.339\n0.493 ± 0.371\n0.464 ± 0.419\n0.542 ± 0.203\nGNB\n0.447 ± 0.359\n0.779 ± 0.266\n0.445 ± 0.412\n0.607 ± 0.217\nkNN\n0.439 ± 0.246\n0.574 ± 0.325\n0.525 ± 0.345\n0.445 ± 0.212\nSV Clinear\n0.529 ± 0.250\n0.664 ± 0.256\n0.554 ± 0.347\n0.591 ± 0.167\nSV Cpoly\n0.226 ± 0.337\n0.734 ± 0.350\n0.300 ± 0.460\n0.503 ± 0.184\nSV Crbf\n0.349 ± 0.315\n0.674 ± 0.330\n0.415 ± 0.425\n0.493 ± 0.201\nSV Csigmoid\n0.449 ± 0.207\n0.643 ± 0.263\n0.502 ± 0.316\n0.487 ± 0.159\nXGB\n0.430 ± 0.339\n0.510 ± 0.373\n0.485 ± 0.436\n0.541 ± 0.214\n図5.9: 調理音1 の変化点検出結果\n図5.15 は調理音7，図5.16 は調理音8 の変化点検出結果である．調理音7 の真の変化点\nは195 秒であり，それに最も近い変化点は192.168 秒であった．また，調理音8 は真の変\n化点が215 秒，それに最も近い変化点は212.159 秒であった．どちらも誤差が4 秒以内に\n収まっているが，調理音5，6 と同様に他の変化点も検出されている．\n図5.17 は調理音9，図5.18 は調理音10 の変化点検出結果である．調理音9 の真の変化\n点は157 秒であり，それに最も近い変化点は157.208 秒であった．また，調理音10 は真の\n変化点は185 秒，それに最も近い変化点は181.882 秒であった．調理音9 については，誤\n差がほとんどないことがわかる．調理音10 は誤差が4 秒以内に収まっている．また，両\n結果ともに他の変化点も検出されている．\n調理音1 から10 までの変化点検出の評価一覧および，真の変化点と検出された最も近\nい変化点を表5.11 に示す．調理音2 以外は，真の変化点を正しく検出していることがわ\nかる．また，各調理音の変化点検出結果の図より，150 秒以降に初めて検出された変化点\n44\n図5.10: 調理音2 の変化点検出結果\nが真の変化点であることがわかる．150 秒以降と限定することで，調理音2 以外は真の変\n化点が正確に検出可能であり，誤検出も調理音2 以外は存在しない．つまり，この制約に\nより，揚げ終わりの検出精度は3 種類すべての指標において90%となり，適合率が90%で\nあることから，誤検出の可能性は10%となる．\nこれに対して，機械学習手法はモデルの精度が安定していない．よって，本研究におい\nては，機械学習手法よりも変化点検出の方が，揚げ終わり識別に対して精度が高いと言え\nる．このことから，変化点検出を利用した唐揚げの調理音識別が可能であると考え，FCGs\nには変化点検出アルゴリズムを実装する．\n表5.11: 各調理音の変化点および精度一覧\nF1 スコア\n適合率\n再現率\n真の変化点[s]\n検出された変化点[s]\n調理音1\n0.500\n0.333\n1.000\n214\n214.601\n調理音2\n0.000\n0.000\n0.000\n238\n259.383\n調理音3\n1.000\n1.000\n1.000\n218\n219.413\n調理音4\n1.000\n1.000\n1.000\n225\n226.778\n調理音5\n0.400\n0.250\n1.000\n176\n176.851\n調理音6\n0.667\n0.500\n1.000\n208\n206.891\n調理音7\n0.500\n0.333\n1.000\n195\n192.168\n調理音8\n0.500\n0.333\n1.000\n215\n212.159\n調理音9\n0.333\n0.200\n1.000\n157\n157.208\n調理音10\n0.500\n0.333\n1.000\n185\n181.882\n45\n図5.11: 調理音3 の変化点検出結果\n5.4\n変化点検出を利用した揚げ終わり判定システムの実装\n前節までの結果より，揚げ終わり識別手法として変化点検出を利用する．スマートフォ\nンアプリケーションの実装は，Android Studio を使用した[73]．また，変化点検出のアル\nゴリズムはChaquopy を利用して実装した[74]．Chaquopy はAndroid アプリにPython\nコンポーネントを組み込み可能とするSDK である．\n録音を開始してから，揚げ終わりを判定するまでのシステムフローチャートを図5.19 に\n示す．\n変化点検出は録音を開始してから165 秒後から開始する．これは，150 秒地点が変化点\n検出のウィンドウの中心となるようにするためである．変化点検出に利用するデータ量は\n30 秒分であり，165 秒経過した段階で特徴量を算出する．特徴量は振幅スペクトログラム\nを算出するため，STFT 適用後，振幅スペクトルを求める．その後，メディアンフィルタ\nで雑音を低減し，時間ごとのエネルギーを算出する．そのエネルギーを基に変化点を検出\nする．検出された場合は，図3.1 のような画面によるフィードバックを実施する．これに\nより，アプリケーション利用者は，唐揚げが揚がったタイミングを認知する．\n46\n図5.12: 調理音4 の変化点検出結果\n図5.13: 調理音5 の変化点検出結果\n47\n図5.14: 調理音6 の変化点検出結果\n図5.15: 調理音7 の変化点検出結果\n48\n図5.16: 調理音8 の変化点検出結果\n図5.17: 調理音9 の変化点検出結果\n49\n図5.18: 調理音10 の変化点検出結果\n50\n図5.19: FCGs のシステムフローチャート\n51\n第6章\n結論\n本章では，本研究のまとめおよび今後の展望について述べる．\n6.1\n本研究のまとめ\n本研究では，唐揚げの揚げ終わりの見極めが料理初心者にとって課題となっていること\nに対して，料理中でも容易に利用可能なスマートフォン向け調理支援システムFCGs を開\n発した．\nまた，揚げ終わりとなる前の状態で調理完了と誤判定しない安全な判定システムを構築\nするために，機械学習および変化点検出手法を検討した．機械学習手法においては，リサン\nプリング手法を組み合わせて，分類精度の向上を図った．また音響特徴量として，MFCC，\nウェーブレット変換を検討した．変化点検出手法はWindow ベースのアルゴリズムを検討\nした結果，機械学習手法よりも高い精度で，揚げ終わりの検出が可能であることが判明し\nた．よって，FCGs には，変化点検出による揚げ終わり検出を実装し，調理支援システム\nを開発した．\n本研究の目標に対する結果としては以下の通りである．\n1.\n唐揚げの調理状態において，揚げ終わりとなる前の状態で調理完了と誤判定しない\n安全な音判定システムの構築を目指した．結果，変化点検出手法を利用することで，\n揚げ終わりの検出における再現率が90%を達成した．また，調理開始から150 秒以\n降の変化点を揚げ終わりの変化点として検出することで，F1 スコア，適合率，再現\n率の3 種類の指標において90%の精度を達成し，誤検出は10%となった．\n2.\nスマートフォン上で唐揚げの揚げ終わりをリアルタイムに判別する，容易に利用可\n能なアプリケーションの開発を目指した．結果，変化点検出アルゴリズムを利用し\nて，スマートフォンのマイクロフォンからリアルタイムにデータを取得し，唐揚げ\nの揚げ終わりを判定するアプリケーションを開発した．\n6.2\n今後の展望\n今後の展望として，揚げ終わり識別手法の精度向上が挙げられる．本研究で検討した機\n械学習手法は，調理音データの時系列情報を考慮していなかったため，LSTM といった時\n系列を考慮した機械学習モデルを利用することで，分類精度の向上が可能であると考える\n[75]．本研究でもLSTM を検証したが，時系列データが不足していたため，十分な結果を\n得ることができずに断念した．よって，データセットの拡充を実施して，より頑健な揚げ\n終わり判定システムの構築を検討したい．\nまた，調理油の温度および調理環境の違いにも対応可能なアルゴリズムおよび分類モデ\nルの構築を目指す．料理初心者は，油の温度を正確に測定することが困難であると考えら\n52\nれる．よって，油の温度がある程度，異なっていても問題なく調理可能な手法を検討する\n必要があると考える．調理環境においても，騒音の種類や使用する調理器具の違いなどに\nより，音響が異なってくるため，調理環境の違いにも対応可能な手法が必要である．\n本研究では，唐揚げの調理が完了したタイミングを検出する調理支援にとどまっている．\nそのため，検出されたタイミングが最も美味しい状態であるかは判別できていない．し\nかし，クリスピー度に関する研究は，これまで数多く実施されている[76][77][78][79]．ク\nリスピー度は唐揚げの食感として表現される感覚である．よって，美味しさに対する最適\nなタイミングを検知し，美味しい唐揚げを調理する支援システムに拡張可能であると考\nえる．\n精度向上の手法として，画像分析も利用可能である．スマートグラスのようなマイクロ\nフォンおよびカメラを搭載したデバイス利用することで，マルチモーダルシステムによ\nる精度向上が期待される．また，フィードバックをスマートグラス上に表示可能であるた\nめ，ユーザビリティの高い調理支援システムの開発が可能であると考える．\nまた，本研究の最終的な目標として，揚げ物料理すべてに対応可能な調理支援システム\nを開発を考えている．そのため，唐揚げだけでなく，天ぷら，コロッケ，豚カツ，白身魚\nのフライなどのレシピに対しても，研究を実施したいと考えている．その結果，料理初\n心者の料理へのハードルを下げ，自炊を習慣付けるモチベーションにつながることを期待\nする．\n53\n謝辞\n本研究を進めるにあたって，学部4 年から3 年間，ご指導いただいた青山学院大学理工\n学部情報テクノロジー学科Guillaume Lopez 教授に深く感謝申し上げます．研究方針，研\n究における課題，就職活動に至るまでご指導いただいたこと，特に，毎週の研究会で，毎\n度的確なご助言をいただいたこと，心から感謝しております．加えて，私の力不足により，\n機械学習の分類精度が中々良くならず，学会発表や論文誌への投稿が叶わなかったこと，\nお詫び申し上げます．\nまた，大学関連の事務手続きおよび研究室の整備等，お心遣いいただいた研究補助員の\n大熊ちひろ様にも深く感謝申し上げます．\nさらに，副査として，残り時間で実現可能な識別手法について的確なご助言をいただき\nました青山学院大学理工学部情報テクノロジー学科大原剛三教授に深く感謝申し上げます．\nそして，研究生活において日々研究の助言をいただいたウェアラブル環境情報システム\n研究室の同期の皆様，並びに学部4 年時にデータ収集にご協力いただいただけでなく，大\n学生活を支えてくださった母にも深く感謝申し上げます．\n2025 年1 月31 日\n新井優作\n54\n参考文献\n[1] 日本政策金庫公庫. 飲食店のテイクアウト・デリバリーサービス等に関する消費者調査\n結果. https://www.jfc.go.jp/n/findings/pdf/seikatsu20_1215a.pdf, 12 2020.\n(最終参照日：2024/12/31).\n[2] 日本政策金庫公庫. 中食と外食に関する消費者動向調査結果. https://www.jfc.go.\njp/n/findings/pdf/topics_180913a.pdf, 9 2018. (最終参照日：2024/12/31).\n[3] 農林水産省. 新型コロナウイルス感染症の拡大による食生活の変化. https://www.\nmaff.go.jp/j/syokuiku/ishiki/r03/zuhyou/z9-1.html, 3 2021.\n(最終参照日：\n2024/12/31).\n[4] 日本政策金庫公庫.\n食の志向等に関する調査結果.\nhttps://www.jfc.go.jp/n/\nfindings/pdf/topics_200805a.pdf, 7 2020. (最終参照日：2024/12/31).\n[5] Celia Rodr´ıguez-P´erez, Esther Molina-Montes, Vito Verardo, Reyes Artacho, Bel´en\nGarc´ıa-Villanova, Eduardo Jes´us Guerra-Hern´andez, and Mar´ıa Dolores Ru´ız-L´opez.\nChanges in dietary behaviours during the covid-19 outbreak conﬁnement in the span-\nish covidiet study. Nutrients, Vol. 12, No. 6, p. 1730, 2020.\n[6] Danijela Pfeifer, Josip Reˇsetar, Jasenka Gajdoˇs Kljusuri´c, Ines Panjkota Krbavˇci´c,\nDarija Vraneˇsi´c Bender, Celia Rodr´ıguez-P´erez, Mar´ıa Dolores Ru´ız-L´opez, and Zvon-\nimir ˇSatali´c. Cooking at home and adherence to the mediterranean diet during the\ncovid-19 conﬁnement: the experience from the croatian covidiet study. Frontiers in\nnutrition, Vol. 8, p. 617721, 2021.\n[7] Sarah Gerritsen, Victoria Egli, Rajshri Roy, Jill Haszard, Charlotte De Backer, Lau-\nranna Teunissen, Isabelle Cuykx, Paulien Decorte, Sara Pabian Pabian, Kathleen\nVan Royen, et al. Seven weeks of home-cooked meals: Changes to new zealanders ’\ngrocery shopping, cooking and eating during the covid-19 lockdown. Journal of the\nRoyal Society of New Zealand, Vol. 51, No. sup1, pp. S4–S22, 2021.\n[8] ハウス食品株式会社. さっと・・・レシピの独特表現「レシピ語」に料理初心者の約8割が\n戸惑っていることが判明！https://housefoods.jp/company/news/pdf/20210517_\nrelease_v2.pdf, 5 2021. (最終参照日：2025/1/2).\n[9] 平島円, 磯部由香, 堀光代. 学生の「切り方」に対する認知度と自信度の変化. 日本\n調理科学会誌, Vol. 54, No. 5, pp. 234–243, 2021.\n[10] Yuta Kido, Teruhiro Mizumoto, Hirohiko Suwa, Yutaka Arakawa, and Keiichi Ya-\nsumoto. A cooking support system for seasoning with smart cruet. In International\nConference on Human-Computer Interaction, pp. 369–382. Springer, 2019.\n55\n[11] 加藤岳大,\n横窪安奈,\nロペズギヨーム.\nSyncook: 動画メタデータと加速度セ\nンサを用いたレシピ動画進行度自動同期システム.\nhttps://www.wiss.org/\nWISS2020Proceedings/data/N-15.pdf, 2020. (最終参照日：2025/1/2).\n[12] 株式会社Felicidad. Hestan cue へスタンキュー公式サイト. https://hestancue.jp/.\n(最終参照日：2025/1/2).\n[13] KY Voong, AB Norton, TB Mills, and IT Norton. Characterisation of deep-fried\nbatter and breaded coatings. Food Structure, Vol. 16, pp. 43–49, 2018.\n[14] Franco Pedreschi, Pamela Hern´andez, Clara Figueroa, and Pedro Moyano. Modeling\nwater loss during frying of potato slices. International journal of food properties,\nVol. 8, No. 2, pp. 289–299, 2005.\n[15] 国立感染症研究所.\nサルモネラ感染症とは.\nhttps://www.niid.go.jp/niid/ja/\nkansennohanashi/409-salmonella.html. (最終参照日：2024/12/11).\n[16] 国立感染症研究所. カンピロバクター感染症とは. https://www.niid.go.jp/niid/\nja/kansennohanashi/385-campylobacter-intro.html. (最終参照日：2024/12/11).\n[17] 厚生労働省.\nカンピロバクター食中毒予防について（q&a）.\nhttps:\n//www.mhlw.go.jp/stf/seisakunitsuite/bunya/kenkou_iryou/shokuhin/\nsyokuchu/campylobacterqa.html. (最終参照日：2024/12/11).\n[18] 食品安全委員会.\nカンピロバクターによる食中毒にご注意ください.\nhttps:\n//www.fsc.go.jp/sonota/e1_campylo_chudoku_20160205.html.\n(最終参照日：\n2024/12/11).\n[19] 農林水産省. 鶏料理を楽しむために～カンピロバクターによる食中毒にご注意を！！\n～. https://www.kurashikagaku.co.jp/report/detail.php?id=133. (最終参照\n日：2024/12/11).\n[20] Solveig Langsrud, Oddvin Sørheim, Silje Elisabeth Skuland, Val´erie Lengard Almli,\nMerete Rus˚as Jensen, Magnhild Seim Grøvlen, Øydis Ueland, and Trond Møretrø.\nCooking chicken at home: Common or recommended approaches to judge doneness\nmay not assure suﬃcient inactivation of pathogens. PLoS One, Vol. 15, No. 4, p.\ne0230928, 2020.\n[21] engadget. New android feature alerts you to smoke alarms and other ’critical’ sounds.\nhttps://www.engadget.com/android-sound-notification-alerts-170045534.\nhtml, 10 2020. (最終参照日：2025/1/2).\n[22] Apple Inc. iphone でサウンドを認識する-apple サポート(日本). https://support.\napple.com/ja-jp/guide/iphone/iphf2dc33312/ios. (最終参照日：2025/1/2).\n[23] 株式会社野村総合研究所. 第301 回nri メディアフォーラム「it ナビゲーター2021\n年度版」. https://www.nri.com/-/media/Corporate/jp/Files/PDF/knowledge/\nreport/cc/mediaforum/2020/forum301.pdf, 12 2020. (最終参照日：2025/1/2).\n56\n[24] M Tabacchi, C Asensio, I Pav´on, M Recuero, J Mir, and MC Artal. A statistical\npattern recognition approach for the classiﬁcation of cooking stages. the boiling water\ncase. Applied acoustics, Vol. 74, No. 8, pp. 1022–1032, 2013.\n[25] 宮澤要二, 齋藤大輔, 峯松信明ほか. レシピ情報に基づく調理行動認識における音響\n識別器の中間特徴量利用に関する検討. 研究報告音楽情報科学(MUS), Vol. 2020,\nNo. 31, pp. 1–6, 2020.\n[26] 陳維, 塚田紘也, 横窪安奈ほか. 音解析による唐揚げの揚がり具合判定手法. マルチ\nメディア, 分散, 協調とモバイルシンポジウム2022 論文集, Vol. 2022, pp. 265–270,\n2022.\n[27] June Anne Caladcad, Shiela Cabahug, Mary Rose Catamco, Paul Elyson Villaceran,\nLeizel Cosgafa, Karl Norbert Cabizares, Marfe Hermosilla, et al. Determining philip-\npine coconut maturity level using machine learning algorithms based on acoustic\nsignal. Computers and electronics in agriculture, Vol. 172, p. 105327, 2020.\n[28] Kang Zhao, He Li, Zhihua Zha, Mingcan Zhai, and Jie Wu. Detection of sub-healthy\napples with moldy core using deep-shallow learning for vibro-acoustic multi-domain\nfeatures. Measurement: Food, Vol. 8, p. 100068, 2022.\n[29] Rafael Z Lopes and Gustavo C Dacanal. Classiﬁcation of crispness of food materials\nby deep neural networks. Journal of Texture Studies, Vol. 54, No. 6, pp. 845–859,\n2023.\n[30] Rui Xiao, Qunfang Hu, and Jie Li. Leak detection of gas pipelines using acoustic\nsignals based on wavelet transform and support vector machine. Measurement, Vol.\n146, pp. 479–489, 2019.\n[31] Anjali Malviya, Rahul Dixit, Anupam Shukla, and Nagendra Kushwaha. A novel\napproach to detection of covid-19 and other respiratory diseases using autoencoder\nand lstm. SN Computer Science, Vol. 6, No. 1, pp. 1–11, 2025.\n[32] Chern-Sheng Lin, Yu-Ching Pan, Yu-Xin Kuo, Ching-Kun Chen, and Chuen-Lin\nTien. A study of automatic judgment of food color and cooking conditions with\nartiﬁcial intelligence technology. Processes, Vol. 9, No. 7, p. 1128, 2021.\n[33] Chao Dong, Luelue Huang, Cheng Xiong, Mengkun Li, and Jiamei Tang. Evalua-\ntion of quality of baguette bread using image analysis technique. Journal of Food\nComposition and Analysis, p. 107222, 2025.\n[34] Arman Areﬁ, Oliver Hensel, and Barbara Sturm. Intelligent potato frying: time to say\ngoodbye to the“ good old ”processing strategies. Thermal Science and Engineering\nProgress, Vol. 34, p. 101389, 2022.\n[35] Herv´e Abdi and Lynne J Williams. Principal component analysis. Wiley interdisci-\nplinary reviews: computational statistics, Vol. 2, No. 4, pp. 433–459, 2010.\n57\n[36] Laurens Van der Maaten and Geoﬀrey Hinton. Visualizing data using t-sne. Journal\nof machine learning research, Vol. 9, No. 11, 2008.\n[37] Leon Cohen. Time-frequency analysis, Vol. 778. Prentice Hall PTR New Jersey, 1995.\n[38] Ian Naismith Sneddon. Fourier transforms. Courier Corporation, 1995.\n[39] Fang Zheng, Guoliang Zhang, and Zhanjiang Song. Comparison of diﬀerent imple-\nmentations of mfcc. Journal of Computer science and Technology, Vol. 16, No. 6, pp.\n582–589, 2001.\n[40] Stanley Smith Stevens, John Volkmann, and Edwin Broomell Newman. A scale for\nthe measurement of the psychological magnitude pitch. The journal of the acoustical\nsociety of america, Vol. 8, No. 3, pp. 185–190, 1937.\n[41] Ingrid Daubechies. Ten lectures on wavelets. Society for industrial and applied math-\nematics, 1992.\n[42] Ki-Bok Kim, David K Hsu, and Daniel J Barnard. Estimation of porosity content of\ncomposite materials by applying discrete wavelet transform to ultrasonic backscat-\ntered signal. NDT & E International, Vol. 56, pp. 10–16, 2013.\n[43] Gilbert Strang. Wavelets and Filter Banks. Wellesley-Cambridge Press, 1996.\n[44] Ingrid Daubechies and Bruce J Bates. Ten lectures on wavelets, 1993.\n[45] scikit learn. scikit-learn. https://scikit-learn.org/stable/index.html. (最終\n参照日：2025/1/21).\n[46] xgboost developers. Xgboost documentation. https://xgboost.readthedocs.io/\nen/stable/. (最終参照日：2025/1/22).\n[47] Vladimir Vapnik. The nature of statistical learning theory. Springer science & business\nmedia, 2013.\n[48] Mariette Awad, Rahul Khanna, Mariette Awad, and Rahul Khanna. Support vector\nmachines for classiﬁcation.\nEﬃcient learning machines: Theories, concepts, and\napplications for engineers and system designers, pp. 39–66, 2015.\n[49] Jun Han and Claudio Moraga. The inﬂuence of the sigmoid function parameters on\nthe speed of backpropagation learning. In International workshop on artiﬁcial neural\nnetworks, pp. 195–201. Springer, 1995.\n[50] Christopher M Bishop and Nasser M Nasrabadi. Pattern recognition and machine\nlearning, Vol. 4. Springer, 2006.\n[51] Thomas Bayes. Lii. an essay towards solving a problem in the doctrine of chances. by\nthe late rev. mr. bayes, frs communicated by mr. price, in a letter to john canton, amfr\ns. Philosophical transactions of the Royal Society of London, No. 53, pp. 370–418,\n1763.\n58\n[52] Thomas Cover and Peter Hart. Nearest neighbor pattern classiﬁcation. IEEE trans-\nactions on information theory, Vol. 13, No. 1, pp. 21–27, 1967.\n[53] Tin Kam Ho. The random subspace method for constructing decision forests. IEEE\ntransactions on pattern analysis and machine intelligence, Vol. 20, No. 8, pp. 832–844,\n1998.\n[54] Tianqi Chen and Carlos Guestrin. Xgboost: A scalable tree boosting system. In\nProceedings of the 22nd acm sigkdd international conference on knowledge discovery\nand data mining, pp. 785–794, 2016.\n[55] Trevor Hastie, Robert Tibshirani, Jerome Friedman, Trevor Hastie, Robert Tibshi-\nrani, and Jerome Friedman. Boosting and additive trees. The elements of statistical\nlearning: data mining, inference, and prediction, pp. 337–387, 2009.\n[56] David W Hosmer Jr, Stanley Lemeshow, and Rodney X Sturdivant. Applied logistic\nregression. John Wiley & Sons, 2013.\n[57] The imbalanced-learn developers.\nimbalanced-learn documentation.\nhttps://\nimbalanced-learn.org/stable/. (最終参照日：2025/1/21).\n[58] Haibo He, Yang Bai, Edwardo A Garcia, and Shutao Li. Adasyn: Adaptive synthetic\nsampling approach for imbalanced learning. In 2008 IEEE international joint con-\nference on neural networks (IEEE world congress on computational intelligence), pp.\n1322–1328. Ieee, 2008.\n[59] Nitesh V Chawla, Kevin W Bowyer, Lawrence O Hall, and W Philip Kegelmeyer.\nSmote: synthetic minority over-sampling technique. Journal of artiﬁcial intelligence\nresearch, Vol. 16, pp. 321–357, 2002.\n[60] Hui Han, Wen-Yuan Wang, and Bing-Huan Mao. Borderline-smote: a new over-\nsampling method in imbalanced data sets learning. In International conference on\nintelligent computing, pp. 878–887. Springer, 2005.\n[61] Hien M Nguyen, Eric W Cooper, and Katsuari Kamei. Borderline over-sampling for\nimbalanced data classiﬁcation. International Journal of Knowledge Engineering and\nSoft Data Paradigms, Vol. 3, No. 1, pp. 4–21, 2011.\n[62] Wei-Chao Lin, Chih-Fong Tsai, Ya-Han Hu, and Jing-Shang Jhang. Clustering-based\nundersampling in class-imbalanced data. Information Sciences, Vol. 409, pp. 17–26,\n2017.\n[63] Peter Hart. The condensed nearest neighbor rule (corresp.). IEEE transactions on\ninformation theory, Vol. 14, No. 3, pp. 515–516, 1968.\n[64] Inderjeet Mani and I Zhang. knn approach to unbalanced data distributions: a case\nstudy involving information extraction. In Proceedings of workshop on learning from\nimbalanced datasets, Vol. 126, pp. 1–7. ICML, 2003.\n59\n[65] Jorma Laurikkala. Improving identiﬁcation of diﬃcult small classes by balancing\nclass distribution. In Artiﬁcial Intelligence in Medicine: 8th Conference on Artiﬁcial\nIntelligence in Medicine in Europe, AIME 2001 Cascais, Portugal, July 1–4, 2001,\nProceedings 8, pp. 63–66. Springer, 2001.\n[66] Miroslav Kubat, Stan Matwin, et al. Addressing the curse of imbalanced training\nsets: one-sided selection. In Icml, Vol. 97, p. 179. Citeseer, 1997.\n[67] Tomek Ivan. Two modiﬁcations of cnn. IEEE transactions on Systems, Man and\nCommunications, SMC, Vol. 6, pp. 769–772, 1976.\n[68] ruptures.\nWelcome\nto\nruptures.\nhttps://centre-borelli.github.io/\nruptures-docs/. (最終参照日：2025/1/22).\n[69] Charles Truong, Laurent Oudre, and Nicolas Vayatis.\nSelective review of oﬄine\nchange point detection methods. Signal Processing, Vol. 167, p. 107299, 2020.\n[70] Ioannis Pitas and Anastasios N Venetsanopoulos. Nonlinear digital ﬁlters: principles\nand applications, Vol. 84. Springer Science & Business Media, 2013.\n[71] Daniel Berrar, et al. Cross-validation., 2019.\n[72] Elan — the language archive. https://archive.mpi.nl/tla/elan. (最終参照日：\n2025/1/19).\n[73] Google LLC.\nAndroid studio.\nhttps://developer.android.com/studio?hl=ja.\n(最終参照日：2025/1/23).\n[74] Chaquo Ltd. Chaquopy python sdk for android. https://chaquo.com/chaquopy/.\n(最終参照日：2025/1/23).\n[75] S Hochreiter. Long short-term memory. Neural Computation MIT-Press, 1997.\n[76] Liara S Dias-Faceto, Ana Salvador, and Ana C Conti-Silva. Acoustic settings combi-\nnation as a sensory crispness indicator of dry crispy food. Journal of texture studies,\nVol. 51, No. 2, pp. 232–241, 2020.\n[77] Tˆeko Gouyo, Christian Mestres, Isabelle Maraval, B´en´edicte Fontez, C´eline Hoﬂeit-\nner, and Philippe Bohuon.\nAssessment of acoustic-mechanical measurements for\ntexture of french fries: Comparison of deep-fat frying and air frying. Food Research\nInternational, Vol. 131, p. 108947, 2020.\n[78] Jacob Tizhe Liberty, Md Haﬁzur Rahman Bhuiyan, and Michael Ngadi. Assessing\ntextural changes of breaded deep-fat fried chicken nuggets during post-frying holdings\nunder infrared heat-lamp using acoustic-mechanical techniques. International Journal\nof Food Science and Technology, Vol. 59, No. 11, pp. 8596–8605, 2024.\n[79] Jacob Tizhe Liberty, Md Haﬁzur Rahman Bhuiyan, and Michael Ngadi. Unravelling\nthe nexus between structure, texture, and acoustic traits of fried chicken nuggets.\n60\nInternational Journal of Food Science and Technology, Vol. 59, No. 11, pp. 8571–\n8582, 2024.\n61\n付録A\n本研究に関する論文と発表実績\n1. 新井優作, ロペズギヨーム: 唐揚げの音響特性による揚げ終わり判定, マルチメディ\nア, 分散, 協調とモバイル(DICOMO2023) シンポジウム論文集, pp.137-142(2023)\n62\n付録B\n唐揚げの一般的なレシピまとめ\nインターネット上に掲載されている10 種類の唐揚げレシピを調査した結果を表B.1 に\nまとめる．空欄となっている箇所はレシピに明記されていなかった情報である．\n表B.1: 唐揚げレシピの調理条件まとめ\n温度[◦C]\n鶏もも肉の量[g]\n1 つ当たりの大きさ\n調理時間[分]\n油の種類\nレシピ1\n180\n300\n-\n4\n-\nレシピ2\n160\n250\n-\n4–5\nサラダ油\nレシピ3\n160–170\n300–400\n3–4 cm\n4–6\n-\nレシピ4\n170\n350\n4–5 cm\n6\n-\nレシピ5\n170\n300\n-\n3–4\nサラダ油\nレシピ6\n170\n100\n小さめの一口大\n3–4\n-\nレシピ7\n170–180\n800\n-\n3\nサラダ油\nレシピ8\n170\n250\n3–4 cm 四方\n4–6\nサラダ油\nレシピ9\n170\n300\n3–4 cm 程度\n4–5\nサラダ油\nレシピ10\n160–170\n300\n一口大\n4–5\n-\n補足として，レシピ2 は160◦C で3 分から4 分調理した後，強火で1 分程度揚げる．レ\nシピ3 は3 分から4 分調理した後，4 分から5 分休める．その後，高温の油で1 分から2\n分揚げる．レシピ4 は3 分フライ調理後，2 分裏返して調理，最後に強火で1 分調理する．\nレシピ5 の調理油は鍋の底から3 cm 程度まで入れて調理する．レシピ7 は2 分程度揚げ\nた後，余熱で4 分程度おき，再度200◦C で約1 分揚げる．レシピ8 は，まず2 分から3 分\n程度調理する．鶏肉の下部に揚げ色がついたら裏返し，さらに2 分3 分揚げる．レシピ\n9 の調理油は鍋の底から2 cm 程度まで入れる．レシピ10 では，4 分から5 分揚げた後，\n180◦C でカラッと揚げる．\n表B.1 より，調理時間は平均4 分程度，調理油は基本的にサラダ油が使用されており，\n160◦C から180◦C の温度で調理されることが一般的であることが判明した．\n63\n付録C\nMFCC特徴量を使用したその他の分類\n精度の評価\nC.1\nアンダーサンプリングにCluster Centroid を使用した際の分類精\n度一覧\n表C.1 はアンダーサンプリングにCC，オーバーサンプリングにBSMOTE を適用した\n各分類器による分類精度である．クラスのサンプル数はMiddle: Finish = 1, 740: 1, 441\nとなった．\n表C.1: CC+BSMOTE を適用したMFCC 特徴量の分類精度\n分類器\nF1 スコア\n適合率\n再現率\n正解率\nロジスティック回帰\n0.420 ± 0.304\n0.480 ± 0.294\n0.520 ± 0.451\n0.619 ± 0.104\nランダムフォレスト\n0.133 ± 0.190\n0.759 ± 0.340\n0.092 ± 0.135\n0.585 ± 0.078\nGNB\n0.375 ± 0.363\n0.580 ± 0.334\n0.487 ± 0.481\n0.609 ± 0.150\nkNN\n0.194 ± 0.280\n0.381 ± 0.361\n0.221 ± 0.369\n0.551 ± 0.118\nSV Mlinear\n0.482 ± 0.266\n0.616 ± 0.211\n0.618 ± 0.425\n0.608 ± 0.110\nSV Mpoly\n0.393 ± 0.319\n0.762 ± 0.264\n0.514 ± 0.483\n0.611 ± 0.117\nSV Mrbf\n0.377 ± 0.345\n0.757 ± 0.271\n0.518 ± 0.503\n0.603 ± 0.136\nSV Msigmoid\n0.256 ± 0.332\n0.196 ± 0.254\n0.383 ± 0.495\n0.490 ± 0.178\nXGB\n0.272 ± 0.308\n0.631 ± 0.344\n0.293 ± 0.386\n0.608 ± 0.112\n表C.2 はアンダーサンプリングにCC，オーバーサンプリングにSV MSMOTElinear\nを適用した各分類器による分類精度である．クラスのサンプル数はMiddle: Finish =\n1, 740: 1, 516 となった．\n表C.2: CC+SV MSMOTElinear を適用したMFCC 特徴量の分類精度\n分類器\nF1 スコア\n適合率\n再現率\n正解率\nロジスティック回帰\n0.420 ± 0.304\n0.480 ± 0.294\n0.520 ± 0.451\n0.619 ± 0.104\nランダムフォレスト\n0.137 ± 0.260\n0.745 ± 0.362\n0.119 ± 0.264\n0.600 ± 0.105\nGNB\n0.375 ± 0.363\n0.580 ± 0.334\n0.487 ± 0.481\n0.609 ± 0.150\nkNN\n0.194 ± 0.280\n0.381 ± 0.361\n0.221 ± 0.369\n0.551 ± 0.118\nSV Mlinear\n0.482 ± 0.266\n0.616 ± 0.211\n0.618 ± 0.425\n0.608 ± 0.110\nSV Mpoly\n0.393 ± 0.319\n0.762 ± 0.264\n0.514 ± 0.483\n0.611 ± 0.117\nSV Mrbf\n0.377 ± 0.345\n0.757 ± 0.271\n0.518 ± 0.503\n0.603 ± 0.136\nSV Msigmoid\n0.256 ± 0.332\n0.196 ± 0.254\n0.383 ± 0.495\n0.490 ± 0.178\nXGB\n0.272 ± 0.308\n0.631 ± 0.344\n0.293 ± 0.386\n0.608 ± 0.112\n64\n表C.3はアンダーサンプリングにCC，オーバーサンプリングにSV MSMOTEpoly を適用\nした各分類器による分類精度である．クラスのサンプル数はMiddle: Finish = 1, 740: 1, 575\nとなった．\n表C.3: CC+SV MSMOTEpoly を適用したMFCC 特徴量の分類精度\n分類器\nF1 スコア\n適合率\n再現率\n正解率\nロジスティック回帰\n0.470 ± 0.307\n0.517 ± 0.300\n0.551 ± 0.432\n0.615 ± 0.091\nランダムフォレスト\n0.231 ± 0.311\n0.774 ± 0.318\n0.230 ± 0.349\n0.579 ± 0.077\nGNB\n0.449 ± 0.342\n0.718 ± 0.252\n0.562 ± 0.473\n0.602 ± 0.134\nkNN\n0.203 ± 0.290\n0.407 ± 0.367\n0.222 ± 0.368\n0.522 ± 0.115\nSV Mlinear\n0.511 ± 0.278\n0.553 ± 0.265\n0.588 ± 0.402\n0.618 ± 0.106\nSV Mpoly\n0.526 ± 0.335\n0.764 ± 0.208\n0.637 ± 0.457\n0.656 ± 0.125\nSV Mrbf\n0.581 ± 0.318\n0.719 ± 0.207\n0.728 ± 0.418\n0.655 ± 0.131\nSV Msigmoid\n0.285 ± 0.346\n0.230 ± 0.268\n0.401 ± 0.499\n0.472 ± 0.164\nXGB\n0.334 ± 0.287\n0.635 ± 0.306\n0.301 ± 0.302\n0.598 ± 0.103\n表C.4はアンダーサンプリングにCC，オーバーサンプリングにSV MSMOTErbf を適用\nした各分類器による分類精度である．クラスのサンプル数はMiddle: Finish = 1, 740: 1, 575\nとなった．\n表C.4: CC+SV MSMOTErbf を適用したMFCC 特徴量の分類精度\n分類器\nF1 スコア\n適合率\n再現率\n正解率\nロジスティック回帰\n0.455 ± 0.305\n0.511 ± 0.296\n0.537 ± 0.438\n0.602 ± 0.091\nランダムフォレスト\n0.231 ± 0.323\n0.802 ± 0.310\n0.206 ± 0.321\n0.591 ± 0.119\nGNB\n0.447 ± 0.343\n0.717 ± 0.255\n0.560 ± 0.475\n0.601 ± 0.134\nkNN\n0.208 ± 0.295\n0.408 ± 0.369\n0.227 ± 0.372\n0.524 ± 0.119\nSV Mlinear\n0.523 ± 0.262\n0.559 ± 0.239\n0.617 ± 0.388\n0.610 ± 0.096\nSV Mpoly\n0.527 ± 0.331\n0.763 ± 0.212\n0.637 ± 0.453\n0.653 ± 0.124\nSV Mrbf\n0.573 ± 0.317\n0.717 ± 0.208\n0.721 ± 0.423\n0.650 ± 0.128\nSV Msigmoid\n0.283 ± 0.344\n0.229 ± 0.266\n0.397 ± 0.494\n0.470 ± 0.164\nXGB\n0.364 ± 0.283\n0.654 ± 0.299\n0.330 ± 0.301\n0.606 ± 0.099\n表C.5 はアンダーサンプリングにCC，オーバーサンプリングにSV MSMOTEsigmoid\nを適用した各分類器による分類精度である．クラスのサンプル数はMiddle: Finish =\n1, 740: 1, 575 となった．\n表C.6 はアンダーサンプリングにCC，オーバーサンプリングにADASYN を適用した\n各分類器による分類精度である．クラスのサンプル数はMiddle: Finish = 1, 740: 1, 724\nとなった．\n65\n表C.5: CC+SV MSMOTEsigmoid を適用したMFCC 特徴量の分類精度\n分類器\nF1 スコア\n適合率\n再現率\n正解率\nロジスティック回帰\n0.453 ± 0.299\n0.518 ± 0.287\n0.533 ± 0.437\n0.596 ± 0.091\nランダムフォレスト\n0.208 ± 0.289\n0.772 ± 0.312\n0.189 ± 0.289\n0.565 ± 0.096\nGNB\n0.444 ± 0.343\n0.717 ± 0.255\n0.556 ± 0.477\n0.600 ± 0.135\nkNN\n0.210 ± 0.295\n0.412 ± 0.372\n0.228 ± 0.372\n0.524 ± 0.119\nSV Mlinear\n0.511 ± 0.263\n0.561 ± 0.235\n0.611 ± 0.407\n0.608 ± 0.084\nSV Mpoly\n0.528 ± 0.329\n0.764 ± 0.212\n0.636 ± 0.450\n0.654 ± 0.124\nSV Mrbf\n0.574 ± 0.317\n0.716 ± 0.208\n0.723 ± 0.421\n0.651 ± 0.126\nSV Msigmoid\n0.282 ± 0.343\n0.229 ± 0.266\n0.395 ± 0.492\n0.469 ± 0.164\nXGB\n0.368 ± 0.268\n0.734 ± 0.222\n0.356 ± 0.330\n0.592 ± 0.089\n表C.6: CC+ADASYN を適用したMFCC 特徴量の分類精度\n分類器\nF1 スコア\n適合率\n再現率\n正解率\nロジスティック回帰\n0.453 ± 0.299\n0.518 ± 0.287\n0.533 ± 0.437\n0.596 ± 0.091\nランダムフォレスト\n0.178 ± 0.304\n0.821 ± 0.315\n0.166 ± 0.313\n0.582 ± 0.094\nGNB\n0.444 ± 0.343\n0.717 ± 0.255\n0.556 ± 0.477\n0.600 ± 0.135\nkNN\n0.210 ± 0.295\n0.412 ± 0.372\n0.228 ± 0.372\n0.524 ± 0.119\nSV Mlinear\n0.511 ± 0.263\n0.561 ± 0.235\n0.611 ± 0.407\n0.608 ± 0.084\nSV Mpoly\n0.528 ± 0.329\n0.764 ± 0.212\n0.636 ± 0.450\n0.654 ± 0.124\nSV Mrbf\n0.574 ± 0.317\n0.716 ± 0.208\n0.723 ± 0.421\n0.651 ± 0.126\nSV Msigmoid\n0.282 ± 0.343\n0.229 ± 0.266\n0.395 ± 0.492\n0.469 ± 0.164\nXGB\n0.368 ± 0.268\n0.734 ± 0.222\n0.356 ± 0.330\n0.592 ± 0.089\nC.2\nアンダーサンプリングにCondensed Nearest Neighbour を使用\nした際の分類精度一覧\n表C.7 はアンダーサンプリングにCNN，オーバーサンプリングにBSMOTE を適用し\nた各分類器による分類精度である．クラスのサンプル数はMiddle: Finish = 870: 870 と\nなった．\n表C.8 はアンダーサンプリングにCNN，オーバーサンプリングにSV MSMOTElinear\nを適用した各分類器による分類精度である．クラスのサンプル数はMiddle: Finish =\n870: 870 となった．\n表C.9はアンダーサンプリングにCNN，オーバーサンプリングにSV MSMOTEpoly を適\n用した各分類器による分類精度である．クラスのサンプル数はMiddle: Finish = 870: 870\nとなった．\n表C.10はアンダーサンプリングにCNN，オーバーサンプリングにSV MSMOTErbf を適\n用した各分類器による分類精度である．クラスのサンプル数はMiddle: Finish = 870: 870\nとなった．\n表C.11 はアンダーサンプリングにCNN，オーバーサンプリングにSV MSMOTEsigmoid\nを適用した各分類器による分類精度である．クラスのサンプル数はMiddle: Finish =\n66\n表C.7: CNN+BSMOTE を適用したMFCC 特徴量の分類精度\n分類器\nF1 スコア\n適合率\n再現率\n正解率\nロジスティック回帰\n0.456 ± 0.295\n0.628 ± 0.209\n0.588 ± 0.456\n0.541 ± 0.045\nランダムフォレスト\n0.327 ± 0.294\n0.602 ± 0.319\n0.383 ± 0.382\n0.497 ± 0.064\nGNB\n0.421 ± 0.324\n0.666 ± 0.232\n0.579 ± 0.478\n0.520 ± 0.049\nkNN\n0.208 ± 0.329\n0.520 ± 0.428\n0.241 ± 0.404\n0.514 ± 0.148\nSV Mlinear\n0.459 ± 0.278\n0.577 ± 0.195\n0.586 ± 0.445\n0.535 ± 0.039\nSV Mpoly\n0.432 ± 0.320\n0.557 ± 0.284\n0.590 ± 0.471\n0.513 ± 0.052\nSV Mrbf\n0.484 ± 0.316\n0.591 ± 0.240\n0.676 ± 0.462\n0.528 ± 0.052\nSV Msigmoid\n0.450 ± 0.315\n0.341 ± 0.273\n0.664 ± 0.471\n0.479 ± 0.046\nXGB\n0.289 ± 0.271\n0.548 ± 0.296\n0.330 ± 0.373\n0.485 ± 0.053\n表C.8: CNN+SV MSMOTElinear を適用したMFCC 特徴量の分類精度\n分類器\nF1 スコア\n適合率\n再現率\n正解率\nロジスティック回帰\n0.442 ± 0.309\n0.636 ± 0.210\n0.569 ± 0.468\n0.537 ± 0.060\nランダムフォレスト\n0.239 ± 0.272\n0.521 ± 0.343\n0.246 ± 0.329\n0.497 ± 0.076\nGNB\n0.389 ± 0.333\n0.709 ± 0.243\n0.495 ± 0.467\n0.531 ± 0.068\nkNN\n0.201 ± 0.309\n0.421 ± 0.414\n0.244 ± 0.412\n0.485 ± 0.111\nSV Mlinear\n0.456 ± 0.279\n0.656 ± 0.205\n0.569 ± 0.454\n0.541 ± 0.053\nSV Mpoly\n0.458 ± 0.326\n0.590 ± 0.281\n0.616 ± 0.472\n0.535 ± 0.049\nSV Mrbf\n0.545 ± 0.269\n0.619 ± 0.202\n0.722 ± 0.414\n0.546 ± 0.084\nSV Msigmoid\n0.343 ± 0.362\n0.272 ± 0.290\n0.475 ± 0.506\n0.507 ± 0.069\nXGB\n0.359 ± 0.305\n0.593 ± 0.281\n0.400 ± 0.399\n0.538 ± 0.071\n870: 870 となった．\nC.3\nアンダーサンプリングにNearMiss-1 を使用した際の分類精度一覧\n表C.12 はアンダーサンプリングにNM1，オーバーサンプリングにBSMOTE を適用し\nた各分類器による分類精度である．クラスのサンプル数はMiddle: Finish = 1, 740: 1, 740\nとなった．\n表C.13 はアンダーサンプリングにNM1，オーバーサンプリングにSV MSMOTElinear\nを適用した各分類器による分類精度である．クラスのサンプル数はMiddle: Finish =\n1, 740: 1, 740 となった．\n表C.14 はアンダーサンプリングにNM1，オーバーサンプリングにSV MSMOTEpoly\nを適用した各分類器による分類精度である．クラスのサンプル数はMiddle: Finish =\n1, 740: 1, 740 となった．\n表C.15 はアンダーサンプリングにNM1，オーバーサンプリングにSV MSMOTErbf\nを適用した各分類器による分類精度である．クラスのサンプル数はMiddle: Finish =\n1, 740: 1, 740 となった．\n表C.16 はアンダーサンプリングにNM1，オーバーサンプリングにSV MSMOTEsigmoid\n67\n表C.9: CNN+SV MSMOTEpoly を適用したMFCC 特徴量の分類精度\n分類器\nF1 スコア\n適合率\n再現率\n正解率\nロジスティック回帰\n0.448 ± 0.318\n0.635 ± 0.160\n0.576 ± 0.474\n0.556 ± 0.070\nランダムフォレスト\n0.273 ± 0.259\n0.545 ± 0.349\n0.266 ± 0.311\n0.520 ± 0.068\nGNB\n0.434 ± 0.331\n0.658 ± 0.249\n0.578 ± 0.478\n0.540 ± 0.076\nkNN\n0.199 ± 0.322\n0.508 ± 0.427\n0.237 ± 0.406\n0.499 ± 0.151\nSV Mlinear\n0.443 ± 0.295\n0.636 ± 0.157\n0.563 ± 0.469\n0.548 ± 0.049\nSV Mpoly\n0.517 ± 0.293\n0.637 ± 0.200\n0.681 ± 0.426\n0.552 ± 0.079\nSV Mrbf\n0.557 ± 0.289\n0.640 ± 0.197\n0.766 ± 0.407\n0.561 ± 0.071\nSV Msigmoid\n0.313 ± 0.336\n0.260 ± 0.278\n0.415 ± 0.464\n0.493 ± 0.067\nXGB\n0.322 ± 0.277\n0.475 ± 0.308\n0.334 ± 0.317\n0.507 ± 0.072\n表C.10: CNN+SV MSMOTErbf を適用したMFCC 特徴量の分類精度\n分類器\nF1 スコア\n適合率\n再現率\n正解率\nロジスティック回帰\n0.448 ± 0.318\n0.635 ± 0.160\n0.576 ± 0.474\n0.556 ± 0.070\nランダムフォレスト\n0.288 ± 0.270\n0.589 ± 0.328\n0.296 ± 0.309\n0.500 ± 0.076\nGNB\n0.434 ± 0.331\n0.658 ± 0.249\n0.578 ± 0.478\n0.540 ± 0.076\nkNN\n0.199 ± 0.322\n0.508 ± 0.427\n0.237 ± 0.406\n0.499 ± 0.151\nSV Mlinear\n0.443 ± 0.295\n0.636 ± 0.157\n0.563 ± 0.469\n0.548 ± 0.049\nSV Mpoly\n0.517 ± 0.293\n0.637 ± 0.200\n0.681 ± 0.426\n0.552 ± 0.079\nSV Mrbf\n0.557 ± 0.289\n0.640 ± 0.197\n0.766 ± 0.407\n0.561 ± 0.071\nSV Msigmoid\n0.313 ± 0.336\n0.260 ± 0.278\n0.415 ± 0.464\n0.493 ± 0.067\nXGB\n0.322 ± 0.277\n0.475 ± 0.308\n0.334 ± 0.317\n0.507 ± 0.072\nを適用した各分類器による分類精度である．クラスのサンプル数はMiddle: Finish =\n1, 740: 1, 740 となった．\n表C.17 はアンダーサンプリングにNM1，オーバーサンプリングにADASYN を適用し\nた各分類器による分類精度である．クラスのサンプル数はMiddle: Finish = 1, 740: 1, 726\nとなった．\nC.4\nアンダーサンプリングにNearMiss-2 を使用した際の分類精度一覧\n表C.18 はアンダーサンプリングにNM2，オーバーサンプリングにBSMOTE を適用し\nた各分類器による分類精度である．クラスのサンプル数はMiddle: Finish = 1, 740: 1, 740\nとなった．\n表C.19 はアンダーサンプリングにNM2，オーバーサンプリングにSV MSMOTElinear\nを適用した各分類器による分類精度である．クラスのサンプル数はMiddle: Finish =\n1, 740: 1, 740 となった．\n表C.20 はアンダーサンプリングにNM2，オーバーサンプリングにSV MSMOTEpoly\nを適用した各分類器による分類精度である．クラスのサンプル数はMiddle: Finish =\n1, 740: 1, 740 となった．\n68\n表C.11: CNN+SV MSMOTEsigmoid を適用したMFCC 特徴量の分類精度\n分類器\nF1 スコア\n適合率\n再現率\n正解率\nロジスティック回帰\n0.448 ± 0.318\n0.635 ± 0.160\n0.576 ± 0.474\n0.556 ± 0.070\nランダムフォレスト\n0.300 ± 0.277\n0.500 ± 0.340\n0.308 ± 0.316\n0.509 ± 0.075\nGNB\n0.434 ± 0.331\n0.658 ± 0.249\n0.578 ± 0.478\n0.540 ± 0.076\nkNN\n0.199 ± 0.322\n0.508 ± 0.427\n0.237 ± 0.406\n0.499 ± 0.151\nSV Mlinear\n0.443 ± 0.295\n0.636 ± 0.157\n0.563 ± 0.469\n0.548 ± 0.049\nSV Mpoly\n0.517 ± 0.293\n0.637 ± 0.200\n0.681 ± 0.426\n0.552 ± 0.079\nSV Mrbf\n0.557 ± 0.289\n0.640 ± 0.197\n0.766 ± 0.407\n0.561 ± 0.071\nSV Msigmoid\n0.313 ± 0.336\n0.260 ± 0.278\n0.415 ± 0.464\n0.493 ± 0.067\nXGB\n0.322 ± 0.277\n0.475 ± 0.308\n0.334 ± 0.317\n0.507 ± 0.072\n表C.12: NM1+BSMOTE を適用したMFCC 特徴量の分類精度\n分類器\nF1 スコア\n適合率\n再現率\n正解率\nロジスティック回帰\n0.401 ± 0.299\n0.642 ± 0.201\n0.530 ± 0.468\n0.513 ± 0.015\nランダムフォレスト\n0.163 ± 0.218\n0.554 ± 0.363\n0.164 ± 0.290\n0.484 ± 0.052\nGNB\n0.410 ± 0.355\n0.722 ± 0.242\n0.572 ± 0.499\n0.535 ± 0.063\nkNN\n0.272 ± 0.314\n0.690 ± 0.345\n0.343 ± 0.430\n0.503 ± 0.089\nSV Mlinear\n0.447 ± 0.283\n0.658 ± 0.199\n0.574 ± 0.455\n0.532 ± 0.042\nSV Mpoly\n0.464 ± 0.320\n0.576 ± 0.284\n0.631 ± 0.461\n0.530 ± 0.067\nSV Mrbf\n0.474 ± 0.297\n0.574 ± 0.252\n0.671 ± 0.455\n0.487 ± 0.088\nSV Msigmoid\n0.590 ± 0.212\n0.558 ± 0.157\n0.847 ± 0.329\n0.513 ± 0.042\nXGB\n0.277 ± 0.225\n0.553 ± 0.309\n0.262 ± 0.295\n0.491 ± 0.075\n表C.21 はアンダーサンプリングにNM2，オーバーサンプリングにSV MSMOTErbf\nを適用した各分類器による分類精度である．クラスのサンプル数はMiddle: Finish =\n1, 740: 1, 740 となった．\n表C.22 はアンダーサンプリングにNM2，オーバーサンプリングにSV MSMOTEsigmoid\nを適用した各分類器による分類精度である．クラスのサンプル数はMiddle: Finish =\n1, 740: 1, 740 となった．\n表C.23 はアンダーサンプリングにNM2，オーバーサンプリングにADASYN を適用し\nた各分類器による分類精度である．クラスのサンプル数はMiddle: Finish = 1, 740: 1, 725\nとなった．\nC.5\nアンダーサンプリングにOne-Sided Selection を使用した際の分\n類精度一覧\n表C.24 はアンダーサンプリングにOSS，オーバーサンプリングにBSMOTE を適用し\nた各分類器による分類精度である．クラスのサンプル数はMiddle: Finish = 6, 470: 6, 470\nとなった．\n表C.25 はアンダーサンプリングにOSS，オーバーサンプリングにSV MSMOTElinear\n69\n表C.13: NM1+SV MSMOTElinear を適用したMFCC 特徴量の分類精度\n分類器\nF1 スコア\n適合率\n再現率\n正解率\nロジスティック回帰\n0.401 ± 0.291\n0.616 ± 0.161\n0.518 ± 0.461\n0.517 ± 0.029\nランダムフォレスト\n0.282 ± 0.235\n0.642 ± 0.259\n0.281 ± 0.294\n0.491 ± 0.044\nGNB\n0.435 ± 0.329\n0.568 ± 0.283\n0.610 ± 0.494\n0.523 ± 0.059\nkNN\n0.257 ± 0.303\n0.688 ± 0.343\n0.320 ± 0.415\n0.495 ± 0.080\nSV Mlinear\n0.425 ± 0.277\n0.597 ± 0.157\n0.539 ± 0.453\n0.524 ± 0.043\nSV Mpoly\n0.450 ± 0.329\n0.678 ± 0.235\n0.598 ± 0.470\n0.540 ± 0.095\nSV Mrbf\n0.453 ± 0.314\n0.555 ± 0.283\n0.644 ± 0.476\n0.497 ± 0.054\nSV Msigmoid\n0.277 ± 0.335\n0.666 ± 0.334\n0.405 ± 0.509\n0.470 ± 0.098\nXGB\n0.329 ± 0.240\n0.536 ± 0.278\n0.355 ± 0.332\n0.467 ± 0.070\n表C.14: NM1+SV MSMOTEpoly を適用したMFCC 特徴量の分類精度\n分類器\nF1 スコア\n適合率\n再現率\n正解率\nロジスティック回帰\n0.426 ± 0.283\n0.642 ± 0.172\n0.552 ± 0.458\n0.522 ± 0.024\nランダムフォレスト\n0.274 ± 0.272\n0.722 ± 0.247\n0.301 ± 0.362\n0.508 ± 0.024\nGNB\n0.419 ± 0.343\n0.595 ± 0.291\n0.593 ± 0.501\n0.527 ± 0.057\nkNN\n0.266 ± 0.312\n0.585 ± 0.390\n0.337 ± 0.428\n0.497 ± 0.099\nSV Mlinear\n0.448 ± 0.265\n0.640 ± 0.167\n0.564 ± 0.443\n0.530 ± 0.031\nSV Mpoly\n0.454 ± 0.318\n0.566 ± 0.283\n0.627 ± 0.467\n0.522 ± 0.052\nSV Mrbf\n0.473 ± 0.293\n0.579 ± 0.240\n0.668 ± 0.454\n0.492 ± 0.055\nSV Msigmoid\n0.281 ± 0.334\n0.672 ± 0.334\n0.407 ± 0.508\n0.470 ± 0.103\nXGB\n0.346 ± 0.285\n0.586 ± 0.263\n0.390 ± 0.407\n0.499 ± 0.130\nを適用した各分類器による分類精度である．クラスのサンプル数はMiddle: Finish =\n6, 470: 5, 889 となった．\n表C.26 はアンダーサンプリングにOSS，オーバーサンプリングにSV MSMOTEpoly\nを適用した各分類器による分類精度である．クラスのサンプル数はMiddle: Finish =\n6, 470: 6, 470 となった．\n表C.27 はアンダーサンプリングにOSS，オーバーサンプリングにSV MSMOTErbf\nを適用した各分類器による分類精度である．クラスのサンプル数はMiddle: Finish =\n6, 470: 6, 470 となった．\n表C.28 はアンダーサンプリングにOSS，オーバーサンプリングにSV MSMOTEsigmoid\nを適用した各分類器による分類精度である．クラスのサンプル数はMiddle: Finish =\n6, 470: 6, 470 となった．\n表C.29 はアンダーサンプリングにNM2，オーバーサンプリングにADASYN を適用し\nた各分類器による分類精度である．クラスのサンプル数はMiddle: Finish = 6, 470: 6, 499\nとなった．\n70\n表C.15: NM1+SV MSMOTErbf を適用したMFCC 特徴量の分類精度\n分類器\nF1 スコア\n適合率\n再現率\n正解率\nロジスティック回帰\n0.425 ± 0.279\n0.644 ± 0.176\n0.552 ± 0.460\n0.521 ± 0.021\nランダムフォレスト\n0.364 ± 0.241\n0.651 ± 0.248\n0.398 ± 0.337\n0.500 ± 0.049\nGNB\n0.421 ± 0.340\n0.599 ± 0.294\n0.592 ± 0.498\n0.528 ± 0.058\nkNN\n0.267 ± 0.313\n0.586 ± 0.390\n0.338 ± 0.430\n0.497 ± 0.101\nSV Mlinear\n0.450 ± 0.267\n0.647 ± 0.172\n0.575 ± 0.456\n0.531 ± 0.032\nSV Mpoly\n0.446 ± 0.323\n0.558 ± 0.284\n0.630 ± 0.485\n0.517 ± 0.049\nSV Mrbf\n0.450 ± 0.309\n0.556 ± 0.275\n0.645 ± 0.475\n0.491 ± 0.035\nSV Msigmoid\n0.281 ± 0.333\n0.672 ± 0.334\n0.406 ± 0.507\n0.469 ± 0.103\nXGB\n0.361 ± 0.295\n0.555 ± 0.309\n0.393 ± 0.393\n0.508 ± 0.142\n表C.16: NM1+SV MSMOTEsigmoid を適用したMFCC 特徴量の分類精度\n分類器\nF1 スコア\n適合率\n再現率\n正解率\nロジスティック回帰\n0.424 ± 0.281\n0.643 ± 0.175\n0.551 ± 0.462\n0.520 ± 0.020\nランダムフォレスト\n0.290 ± 0.240\n0.619 ± 0.237\n0.300 ± 0.338\n0.496 ± 0.073\nGNB\n0.423 ± 0.338\n0.601 ± 0.296\n0.594 ± 0.497\n0.528 ± 0.058\nkNN\n0.267 ± 0.314\n0.586 ± 0.390\n0.339 ± 0.431\n0.498 ± 0.101\nSV Mlinear\n0.443 ± 0.267\n0.644 ± 0.170\n0.567 ± 0.457\n0.528 ± 0.028\nSV Mpoly\n0.442 ± 0.324\n0.556 ± 0.284\n0.626 ± 0.489\n0.515 ± 0.046\nSV Mrbf\n0.441 ± 0.312\n0.552 ± 0.274\n0.634 ± 0.482\n0.490 ± 0.027\nSV Msigmoid\n0.281 ± 0.333\n0.672 ± 0.334\n0.406 ± 0.507\n0.469 ± 0.103\nXGB\n0.392 ± 0.265\n0.612 ± 0.237\n0.410 ± 0.359\n0.531 ± 0.111\n表C.17: NM1+ADASYN を適用したMFCC 特徴量の分類精度\n分類器\nF1 スコア\n適合率\n再現率\n正解率\nロジスティック回帰\n0.401 ± 0.294\n0.653 ± 0.204\n0.527 ± 0.470\n0.517 ± 0.019\nランダムフォレスト\n0.223 ± 0.217\n0.589 ± 0.274\n0.206 ± 0.280\n0.488 ± 0.085\nGNB\n0.419 ± 0.345\n0.603 ± 0.289\n0.572 ± 0.491\n0.539 ± 0.066\nkNN\n0.266 ± 0.314\n0.585 ± 0.386\n0.339 ± 0.431\n0.498 ± 0.091\nSV Mlinear\n0.437 ± 0.289\n0.654 ± 0.199\n0.563 ± 0.464\n0.532 ± 0.046\nSV Mpoly\n0.448 ± 0.321\n0.559 ± 0.283\n0.629 ± 0.485\n0.521 ± 0.039\nSV Mrbf\n0.454 ± 0.311\n0.555 ± 0.283\n0.646 ± 0.474\n0.500 ± 0.038\nSV Msigmoid\n0.578 ± 0.218\n0.549 ± 0.161\n0.833 ± 0.344\n0.503 ± 0.044\nXGB\n0.268 ± 0.256\n0.518 ± 0.327\n0.297 ± 0.343\n0.466 ± 0.068\n71\n表C.18: NM2+BSMOTE を適用したMFCC 特徴量の分類精度\n分類器\nF1 スコア\n適合率\n再現率\n正解率\nロジスティック回帰\n0.385 ± 0.287\n0.607 ± 0.217\n0.494 ± 0.456\n0.504 ± 0.027\nランダムフォレスト\n0.138 ± 0.217\n0.576 ± 0.384\n0.124 ± 0.243\n0.512 ± 0.039\nGNB\n0.439 ± 0.377\n0.676 ± 0.293\n0.577 ± 0.493\n0.562 ± 0.142\nkNN\n0.242 ± 0.281\n0.473 ± 0.359\n0.272 ± 0.369\n0.478 ± 0.098\nSV Mlinear\n0.445 ± 0.271\n0.644 ± 0.201\n0.551 ± 0.426\n0.528 ± 0.051\nSV Mpoly\n0.499 ± 0.269\n0.616 ± 0.209\n0.664 ± 0.395\n0.512 ± 0.059\nSV Mrbf\n0.524 ± 0.280\n0.608 ± 0.207\n0.752 ± 0.423\n0.513 ± 0.017\nSV Msigmoid\n0.589 ± 0.215\n0.557 ± 0.158\n0.844 ± 0.331\n0.514 ± 0.045\nXGB\n0.197 ± 0.249\n0.510 ± 0.382\n0.217 ± 0.342\n0.488 ± 0.039\n表C.19: NM2+SV MSMOTElinear を適用したMFCC 特徴量の分類精度\n分類器\nF1 スコア\n適合率\n再現率\n正解率\nロジスティック回帰\n0.384 ± 0.279\n0.606 ± 0.215\n0.486 ± 0.452\n0.505 ± 0.019\nランダムフォレスト\n0.168 ± 0.205\n0.695 ± 0.274\n0.149 ± 0.253\n0.505 ± 0.031\nGNB\n0.456 ± 0.357\n0.581 ± 0.310\n0.609 ± 0.487\n0.549 ± 0.147\nkNN\n0.216 ± 0.257\n0.553 ± 0.354\n0.236 ± 0.337\n0.459 ± 0.093\nSV Mlinear\n0.426 ± 0.259\n0.637 ± 0.203\n0.520 ± 0.425\n0.518 ± 0.029\nSV Mpoly\n0.442 ± 0.285\n0.575 ± 0.245\n0.588 ± 0.441\n0.483 ± 0.099\nSV Mrbf\n0.520 ± 0.280\n0.605 ± 0.208\n0.746 ± 0.427\n0.511 ± 0.021\nSV Msigmoid\n0.583 ± 0.217\n0.551 ± 0.160\n0.837 ± 0.339\n0.507 ± 0.042\nXGB\n0.321 ± 0.283\n0.544 ± 0.318\n0.371 ± 0.408\n0.491 ± 0.087\n表C.20: NM2+SV MSMOTEpoly を適用したMFCC 特徴量の分類精度\n分類器\nF1 スコア\n適合率\n再現率\n正解率\nロジスティック回帰\n0.395 ± 0.279\n0.617 ± 0.215\n0.503 ± 0.450\n0.507 ± 0.026\nランダムフォレスト\n0.213 ± 0.220\n0.620 ± 0.327\n0.184 ± 0.243\n0.510 ± 0.060\nGNB\n0.459 ± 0.351\n0.694 ± 0.251\n0.598 ± 0.471\n0.552 ± 0.145\nkNN\n0.256 ± 0.287\n0.472 ± 0.360\n0.296 ± 0.380\n0.468 ± 0.103\nSV Mlinear\n0.433 ± 0.260\n0.638 ± 0.200\n0.534 ± 0.426\n0.519 ± 0.029\nSV Mpoly\n0.466 ± 0.290\n0.591 ± 0.243\n0.617 ± 0.433\n0.498 ± 0.107\nSV Mrbf\n0.523 ± 0.280\n0.607 ± 0.207\n0.751 ± 0.423\n0.511 ± 0.013\nSV Msigmoid\n0.513 ± 0.282\n0.600 ± 0.214\n0.731 ± 0.425\n0.506 ± 0.046\nXGB\n0.371 ± 0.301\n0.468 ± 0.303\n0.420 ± 0.418\n0.536 ± 0.105\n72\n表C.21: NM2+SV MSMOTErbf を適用したMFCC 特徴量の分類精度\n分類器\nF1 スコア\n適合率\n再現率\n正解率\nロジスティック回帰\n0.399 ± 0.279\n0.623 ± 0.213\n0.507 ± 0.450\n0.510 ± 0.018\nランダムフォレスト\n0.137 ± 0.211\n0.615 ± 0.379\n0.137 ± 0.278\n0.496 ± 0.033\nGNB\n0.464 ± 0.351\n0.697 ± 0.248\n0.604 ± 0.470\n0.554 ± 0.147\nkNN\n0.258 ± 0.288\n0.473 ± 0.359\n0.298 ± 0.382\n0.469 ± 0.105\nSV Mlinear\n0.436 ± 0.259\n0.646 ± 0.199\n0.535 ± 0.426\n0.523 ± 0.027\nSV Mpoly\n0.443 ± 0.307\n0.574 ± 0.266\n0.593 ± 0.458\n0.498 ± 0.096\nSV Mrbf\n0.507 ± 0.282\n0.597 ± 0.214\n0.728 ± 0.434\n0.501 ± 0.024\nSV Msigmoid\n0.578 ± 0.220\n0.549 ± 0.163\n0.828 ± 0.344\n0.505 ± 0.047\nXGB\n0.328 ± 0.266\n0.550 ± 0.317\n0.353 ± 0.375\n0.508 ± 0.069\n表C.22: NM2+SV MSMOTEsigmoid を適用したMFCC 特徴量の分類精度\n分類器\nF1 スコア\n適合率\n再現率\n正解率\nロジスティック回帰\n0.397 ± 0.280\n0.623 ± 0.211\n0.504 ± 0.450\n0.510 ± 0.018\nランダムフォレスト\n0.138 ± 0.175\n0.581 ± 0.329\n0.110 ± 0.165\n0.492 ± 0.028\nGNB\n0.468 ± 0.350\n0.697 ± 0.248\n0.610 ± 0.465\n0.554 ± 0.148\nkNN\n0.259 ± 0.290\n0.473 ± 0.360\n0.300 ± 0.385\n0.470 ± 0.106\nSV Mlinear\n0.432 ± 0.259\n0.644 ± 0.198\n0.531 ± 0.426\n0.522 ± 0.024\nSV Mpoly\n0.430 ± 0.318\n0.561 ± 0.284\n0.582 ± 0.471\n0.501 ± 0.083\nSV Mrbf\n0.492 ± 0.282\n0.588 ± 0.220\n0.706 ± 0.437\n0.491 ± 0.039\nSV Msigmoid\n0.578 ± 0.220\n0.549 ± 0.163\n0.828 ± 0.344\n0.505 ± 0.047\nXGB\n0.332 ± 0.255\n0.469 ± 0.308\n0.359 ± 0.371\n0.508 ± 0.052\n表C.23: NM2+ASASYN を適用したMFCC 特徴量の分類精度\n分類器\nF1 スコア\n適合率\n再現率\n正解率\nロジスティック回帰\n0.372 ± 0.284\n0.602 ± 0.221\n0.475 ± 0.459\n0.501 ± 0.036\nランダムフォレスト\n0.122 ± 0.214\n0.683 ± 0.366\n0.117 ± 0.251\n0.504 ± 0.040\nGNB\n0.451 ± 0.360\n0.592 ± 0.318\n0.580 ± 0.473\n0.556 ± 0.149\nkNN\n0.249 ± 0.282\n0.472 ± 0.352\n0.284 ± 0.377\n0.470 ± 0.111\nSV Mlinear\n0.409 ± 0.274\n0.632 ± 0.208\n0.507 ± 0.442\n0.516 ± 0.041\nSV Mpoly\n0.432 ± 0.313\n0.561 ± 0.284\n0.582 ± 0.464\n0.500 ± 0.075\nSV Mrbf\n0.517 ± 0.283\n0.605 ± 0.209\n0.739 ± 0.432\n0.514 ± 0.025\nSV Msigmoid\n0.579 ± 0.222\n0.550 ± 0.164\n0.831 ± 0.347\n0.508 ± 0.056\nXGB\n0.180 ± 0.251\n0.660 ± 0.300\n0.198 ± 0.333\n0.492 ± 0.032\n73\n表C.24: OSS+BSMOTE を適用したMFCC 特徴量の分類精度\n分類器\nF1 スコア\n適合率\n再現率\n正解率\nロジスティック回帰\n0.546 ± 0.284\n0.678 ± 0.232\n0.600 ± 0.388\n0.625 ± 0.103\nランダムフォレスト\n0.041 ± 0.067\n0.762 ± 0.362\n0.025 ± 0.041\n0.496 ± 0.024\nGNB\n0.392 ± 0.403\n0.674 ± 0.342\n0.462 ± 0.487\n0.601 ± 0.143\nkNN\n0.183 ± 0.312\n0.511 ± 0.438\n0.205 ± 0.382\n0.495 ± 0.147\nSV Mlinear\n0.551 ± 0.299\n0.560 ± 0.294\n0.618 ± 0.393\n0.625 ± 0.119\nSV Mpoly\n0.397 ± 0.358\n0.675 ± 0.205\n0.480 ± 0.476\n0.575 ± 0.117\nSV Mrbf\n0.504 ± 0.331\n0.695 ± 0.182\n0.627 ± 0.462\n0.603 ± 0.109\nSV Msigmoid\n0.430 ± 0.385\n0.672 ± 0.309\n0.538 ± 0.499\n0.593 ± 0.141\nXGB\n0.151 ± 0.242\n0.699 ± 0.366\n0.138 ± 0.255\n0.506 ± 0.081\n表C.25: OSS+SV MSMOTElinear を適用したMFCC 特徴量の分類精度\n分類器\nF1 スコア\n適合率\n再現率\n正解率\nロジスティック回帰\n0.525 ± 0.222\n0.593 ± 0.256\n0.581 ± 0.360\n0.600 ± 0.089\nランダムフォレスト\n0.051 ± 0.089\n0.722 ± 0.394\n0.033 ± 0.057\n0.502 ± 0.071\nGNB\n0.324 ± 0.377\n0.606 ± 0.391\n0.409 ± 0.489\n0.558 ± 0.153\nkNN\n0.174 ± 0.299\n0.493 ± 0.418\n0.190 ± 0.359\n0.504 ± 0.124\nSV Mlinear\n0.575 ± 0.234\n0.601 ± 0.259\n0.646 ± 0.333\n0.624 ± 0.111\nSV Mpoly\n0.384 ± 0.328\n0.656 ± 0.225\n0.480 ± 0.467\n0.555 ± 0.113\nSV Mrbf\n0.503 ± 0.298\n0.670 ± 0.205\n0.639 ± 0.431\n0.582 ± 0.101\nSV Msigmoid\n0.394 ± 0.378\n0.641 ± 0.330\n0.520 ± 0.509\n0.569 ± 0.158\nXGB\n0.176 ± 0.191\n0.568 ± 0.400\n0.141 ± 0.153\n0.504 ± 0.055\n表C.26: OSS+SV MSMOTEpoly を適用したMFCC 特徴量の分類精度\n分類器\nF1 スコア\n適合率\n再現率\n正解率\nロジスティック回帰\n0.573 ± 0.266\n0.622 ± 0.252\n0.629 ± 0.375\n0.641 ± 0.101\nランダムフォレスト\n0.073 ± 0.123\n0.627 ± 0.432\n0.052 ± 0.086\n0.480 ± 0.054\nGNB\n0.383 ± 0.399\n0.603 ± 0.338\n0.469 ± 0.494\n0.584 ± 0.139\nkNN\n0.207 ± 0.312\n0.529 ± 0.426\n0.232 ± 0.386\n0.493 ± 0.142\nSV Mlinear\n0.586 ± 0.260\n0.606 ± 0.255\n0.647 ± 0.366\n0.641 ± 0.106\nSV Mpoly\n0.492 ± 0.333\n0.733 ± 0.177\n0.586 ± 0.449\n0.610 ± 0.098\nSV Mrbf\n0.553 ± 0.311\n0.706 ± 0.181\n0.692 ± 0.431\n0.615 ± 0.093\nSV Msigmoid\n0.424 ± 0.384\n0.667 ± 0.310\n0.533 ± 0.502\n0.589 ± 0.140\nXGB\n0.169 ± 0.243\n0.695 ± 0.360\n0.164 ± 0.267\n0.499 ± 0.074\n74\n表C.27: OSS+SV MSMOTErbf を適用したMFCC 特徴量の分類精度\n分類器\nF1 スコア\n適合率\n再現率\n正解率\nロジスティック回帰\n0.569 ± 0.266\n0.623 ± 0.252\n0.626 ± 0.379\n0.639 ± 0.100\nランダムフォレスト\n0.083 ± 0.135\n0.740 ± 0.369\n0.061 ± 0.098\n0.488 ± 0.042\nGNB\n0.387 ± 0.400\n0.609 ± 0.329\n0.474 ± 0.496\n0.585 ± 0.143\nkNN\n0.208 ± 0.312\n0.528 ± 0.426\n0.234 ± 0.388\n0.493 ± 0.142\nSV Mlinear\n0.578 ± 0.263\n0.604 ± 0.255\n0.640 ± 0.372\n0.638 ± 0.105\nSV Mpoly\n0.493 ± 0.333\n0.736 ± 0.182\n0.588 ± 0.450\n0.609 ± 0.099\nSV Mrbf\n0.553 ± 0.312\n0.706 ± 0.181\n0.694 ± 0.432\n0.615 ± 0.093\nSV Msigmoid\n0.425 ± 0.383\n0.668 ± 0.310\n0.534 ± 0.501\n0.590 ± 0.140\nXGB\n0.234 ± 0.279\n0.579 ± 0.374\n0.232 ± 0.308\n0.519 ± 0.080\n表C.28: OSS+SV MSMOTEsigmoid を適用したMFCC 特徴量の分類精度\n分類器\nF1 スコア\n適合率\n再現率\n正解率\nロジスティック回帰\n0.568 ± 0.265\n0.623 ± 0.252\n0.624 ± 0.379\n0.639 ± 0.099\nランダムフォレスト\n0.067 ± 0.113\n0.723 ± 0.389\n0.047 ± 0.078\n0.480 ± 0.055\nGNB\n0.389 ± 0.400\n0.619 ± 0.325\n0.475 ± 0.496\n0.586 ± 0.145\nkNN\n0.209 ± 0.313\n0.528 ± 0.426\n0.234 ± 0.389\n0.493 ± 0.142\nSV Mlinear\n0.576 ± 0.263\n0.604 ± 0.255\n0.637 ± 0.372\n0.637 ± 0.105\nSV Mpoly\n0.492 ± 0.334\n0.736 ± 0.182\n0.587 ± 0.450\n0.609 ± 0.100\nSV Mrbf\n0.553 ± 0.312\n0.707 ± 0.181\n0.693 ± 0.433\n0.616 ± 0.094\nSV Msigmoid\n0.425 ± 0.383\n0.667 ± 0.310\n0.534 ± 0.501\n0.590 ± 0.140\nXGB\n0.217 ± 0.252\n0.564 ± 0.373\n0.205 ± 0.263\n0.507 ± 0.061\n表C.29: OSS+ADASYN を適用したMFCC 特徴量の分類精度\n分類器\nF1 スコア\n適合率\n再現率\n正解率\nロジスティック回帰\n0.547 ± 0.249\n0.611 ± 0.252\n0.593 ± 0.379\n0.622 ± 0.088\nランダムフォレスト\n0.058 ± 0.101\n0.733 ± 0.380\n0.038 ± 0.065\n0.490 ± 0.031\nGNB\n0.403 ± 0.403\n0.680 ± 0.324\n0.481 ± 0.493\n0.597 ± 0.158\nkNN\n0.192 ± 0.307\n0.498 ± 0.401\n0.216 ± 0.377\n0.489 ± 0.135\nSV Mlinear\n0.549 ± 0.251\n0.593 ± 0.256\n0.603 ± 0.378\n0.616 ± 0.094\nSV Mpoly\n0.451 ± 0.338\n0.711 ± 0.180\n0.545 ± 0.476\n0.592 ± 0.105\nSV Mrbf\n0.544 ± 0.307\n0.699 ± 0.178\n0.677 ± 0.434\n0.610 ± 0.093\nSV Msigmoid\n0.422 ± 0.383\n0.666 ± 0.310\n0.532 ± 0.502\n0.587 ± 0.141\nXGB\n0.108 ± 0.165\n0.477 ± 0.433\n0.085 ± 0.140\n0.477 ± 0.078\n75\n質疑応答\n浦垣啓志郎情報テクノロジー学科助手\nQ\n近年の研究では，CNN などを利用した方が結果が出ることがわかっているにも関\nわらず，SVM などの古典的な分類器を利用しているのはなぜですか．\nA\nご質問ありがとうございます．本研究で取得したデータセットの問題があったため\nです．10 種類の調理音データを取得しましたが，時系列データとしては，10 種類の\nデータではデータ量として少ないため，CNN やRNN などは検討できませんでした．\n実際に，LSTM を考慮いたしましたが，モデルの学習途中で過学習となっているこ\nとがすぐにわかり，断念しております．\n浦垣啓志郎情報テクノロジー学科助手\nQ\n解いている問題が非常に面白いです．ヒューリスティックアルゴリズムだと唐揚げ\n粉の材質とかにも敏感なので，対策に関する考察があると良いと思いました．\nA\n貴重なご意見ありがとうございます．本研究で利用した調理データには，パン粉で\n調理したものと唐揚げ粉を利用したものの2 種類ございました．両者の特徴は多少\n異なりましたが，どちらも変化点検出を利用して揚げ終わりを捉えられておりまし\nた．今後，他の材料を使用した際の特徴の違いも考慮したシステムを構築していき\nたいと考えております．\n大原剛三情報テクノロジー学科教授\nQ\n変化点検出において，実際の検出されたタイミングと真値ラベルとの誤差は，何秒\n程度ありますか．\nA\nご質問ありがとうございます．10 種類の内，変化点を検出できたのは9 種類であ\nり，それらの真値ラベルと検出された変化点の差は，平均1.54 秒でした．150 秒以\n降に初めて検出された点という制限を設けることで，適合率も90%となっているた\nめ，安全な調理支援が可能であると考えています．\n76\nD¨urst Martin 情報テクノロジー学科教授\nQ\nCan your system be used to cook other things? (I wouldn ’t want to eat fried\nchicken every day.) How much time would the tuning for a diﬀerent dish take, and\nwhat kinds of dishes would be suited?\nA\nご質問ありがとうございます．現状のシステムでは，他の料理への適用は困難であ\nると考えております．唐揚げのフライ調理の音響特徴に対して有効な変化点検出と\nなっているため，他の料理に適用するためには，本研究のフロート同様に適切な特\n徴を調査し，精度検証を実施する必要があります．しかし，揚げ物については解析\nの結果，類似した音響特徴であると判明すれば，簡単に適用可能であると考えられ\nます．またシステムの拡張性を考慮すると，機械学習による分類ができた方が良い\nため，別の料理にチューニングする場合も，大量のデータセットを取得する必要が\nあり，その分の時間が必要であると考えています．別の適した料理としては，とん\nかつや天ぷらなど，フライ調理により衣がつく料理は，適していると考えられます．\nD¨urst Martin 情報テクノロジー学科教授\nQ\nDoes the best timing for ending frying change depending on the type of coating of\nthe fried chicken (e.g. mostly just spies vs. thick breading)?\nA\nご質問ありがとうございます．本研究で利用したデータセットにおいても，パン粉\nを利用したものと，唐揚げ粉を利用した調理手法があり，その違いによる最適なタ\nイミングは大きな違いがないことがわかっています．ただ極端なレシピにおいては，\n同様の特徴変化が捉えられない可能性があるため，最適なタイミングは変わる可能\n性があります．また，本研究では料理初心者向けのシステムであるため，そのよう\nな極端なカスタマイズは考慮しておりません．今後，個人の好みに合わせた最適な\n揚げ終わり検出が可能になるようシステムを拡張する場合，そのような極端なレシ\nピも考慮する必要があるため，今後，検討したいと思います．\nD¨urst Martin 情報テクノロジー学科教授\nQ\nWhat ’s the (average) overall cooking time for fried chicken?\nA\nご質問ありがとうございます．インターネット上に掲載されている10 種類のレシ\nピを調査したところ，調理時間は平均4 分程度となっており，本研究のデータセッ\nトにおいても，調理時間は4 分程度となっております．\n77\nD¨urst Martin 情報テクノロジー学科教授\nQ\nWere you able to successfully use your system to fry delicious fried chicken?\nA\nご質問ありがとうございます．本研究では，システムを利用してリアルタイムの性\n能評価を実施しておりません．また，本研究ではフライ調理が完了したかどうかを\n判定しており，美味しさについては考慮しておりません．今後，システムの評価を\n実施していきたいと考えております．また，ただ揚げ終わりかどうかを判定するだ\nけでなく，美味しく揚げられているかも判定できるようにシステムを拡張していき\nたいと考えております．\n78\n",
        "chunks": [
            "M2024_Yusaku_Arai. M2024_Yusaku_Arai. M2024_Yusaku_Arai",
            " \n \n \n \n \n青  山  学  院  大  学 \n \n理  工  学  研  究  科 \n \n \n \n理工学専攻    知能情報    コース \n \n \n \n \n修  士  論  文 \n \n \n \n       学 生 番 号       35623215       \n \n \n       氏     名      新井 優作       \n \n \n研究指導教員   ロペズ ギヨーム 教授     \n \nAcademic Year of 2024, Submitted on January 31st, 2025 \n \nGraduate School of Science and Engineering, Aoyama Gakuin University \n \nTitle: Development of a Cooking Support System Using the Acoustic Characteristics of \nFried Chicken \n \nStudent Name: Yusaku Arai  \nID Number: 35623215  \nDegree: M",
            "ame: Yusaku Arai  \nID Number: 35623215  \nDegree: Master of Engineering \nCourse: Intelligence and Information \nThesis Advisor: Professor Guillaume Lopez \n \nAbstract  \nThe recent spread of COVID-19 has increased opportunities to cook at home, and the \nnumber of novice cooks has increased. Fried foods present a significant challenge for novices \nbecause it is difficult to determine the proper frying conditions (heat, time, etc.). This research \naims to develop a cooking support system, FCGS (Fried ",
            " to develop a cooking support system, FCGS (Fried Chicken Goal system), which analyzes \nthe cooking sound of fried chicken and judges the end of frying. \nFCGS collects frying sounds using a smartphone microphone and detects the end of frying. \nIt classifies the cooking sounds into two categories, “Middle” and “Finish,” and notifies the \nuser in real-time when frying is finished. This makes it possible for even novice cooks to take \nout fried food at the appropriate time. \nThe following three typ",
            " at the appropriate time. \nThe following three types of sound features were investigated to analyze frying sound based \non various research fields dealing with sound signal analysis.  \n● \nMel-frequency cepstral coefficients (MFCC), which are widely used in voice recognition \n● \nWavelet coefficients, which are efficient in abnormality analysis from sound or \nvibration signal \n● \nAmplitude spectrogram, which is used in music analysis and bioacoustics \nIn particular, the amplitude spectrogram can v",
            "cs \nIn particular, the amplitude spectrogram can visualize frequency components that change \nwith time, making capturing changes in fried sound easy. The study also introduces a change \npoint detection method to determine the timing of the end of frying accurately.  \nVarious machine-learning classifiers (SVM, k-NN, XGBoost) were tested to discriminate \nbetween mid-frying and end-of-frying. In addition, resampling techniques were used to deal \nwith data imbalance problems. FCGS was evaluated by c",
            "h data imbalance problems. FCGS was evaluated by cross-validation using frying sound \ndata. MFCC-based classification achieved an F1 score of 57.6%, and amplitude spectrograms \nenabled change-point detection, identifying the end of frying with 90% accuracy in F1 score, \nprecision, and recall. In particular, the introduction of change-point detection significantly \nreduced the number of misjudgments during frying. \nIn this study, a cooking support system, FCGS, was developed to determine the end ",
            " system, FCGS, was developed to determine the end of frying \nby analyzing the sound of fried food cooking. Evaluation experiments demonstrated that the \nsystem could detect the end of frying accurately and effectively assist novice cooks. Future \nchallenges include improving accuracy in different environments (noisy places), optimizing \nreal-time processing, and applying machine learning methods.  \n理工学専攻修士論文要旨 \n \n \n提出年度 \n：2024 年度 \n提出日  \n：2025 年 1 月 31 日 \n専修コース \n：知能情報コース \n学生番号 \n：35623215 \n学生氏名 \n：",
            " 月 31 日 \n専修コース \n：知能情報コース \n学生番号 \n：35623215 \n学生氏名 \n：新井 優作 \n研究指導教員 ：ロペズ ギヨーム 教授 \n \n（論文題目） \n唐揚げの音響特性を利用した調理支援システムの開発 \n \n（内容の要旨） \n近年，新型コロナウイルス感染症の拡大により，自宅で料理をする機会が増加し，料理初心者の増\n加が確認されている．特に揚げ物は，適切な加熱状態を見極めることが難しく，料理初心者にとって\n大きな課題となっている．また，加熱不十分な鶏肉は食中毒のリスクを伴うため，安全な調理が求め\nられる．本研究では，唐揚げの調理音を分析し，揚げ終わりを判定する調理支援システム「FCGs \n(Fried Chicken Goal system)」を開発することを目的とする． \n調理支援に関する研究として，音響センシングを活用した調理状態の認識が進められている．例え\nば，沸騰音や調理環境音を分析することで，調理プロセスの段階を特定する研究がある．また，食材\nの音響的特徴を利用し，成熟度や品質を判断する研究も存在する．本研究では，これらの知見を基に，\n唐揚げの調理音を用",
            "を利用し，成熟度や品質を判断する研究も存在する．本研究では，これらの知見を基に，\n唐揚げの調理音を用いた調理支援システムを構築する．FCGs は，スマートフォンのマイクを用いて唐\n揚げの調理音を収集し，機械学習によって揚げ終わりを検出するシステムである．理音を「揚げ途中\n（Middle）」と「揚げ終わり（Finish）」の2 つに分類し，リアルタイムで揚げ終わりをユーザーに通\n知する．これにより，料理初心者でも適切なタイミングで唐揚げを取り出すことが可能となる． \n調理音の特徴量として，音波信号の解析が使われている様々な分野を参考に，次の３つを検討した． \n● \n音声認識分野に用いられているメル周波数ケプストラム係数（MFCC） \n● \n音波・振動の異常検知分野に用いられているウェーブレット係数 \n● \n音楽分析や生物音響学に用いられている振幅スペクトログラム \n特に，振幅スペクトログラムは，時間とともに変化する周波数成分を視覚化でき，揚げ音の変化を\n捉えやすいことや，変化点検出手法を導入し，揚げ終わりのタイミングを高精度に判定することが期\n待できる． \n識別手法として，複数の機械学習",
            "入し，揚げ終わりのタイミングを高精度に判定することが期\n待できる． \n識別手法として，複数の機械学習分類器（SVM，k-NN，XGBoost など）を用いて揚げ途中と揚げ\n終わりの判別を行う．さらに，リサンプリング手法を活用し，データの不均衡問題に対応する．また，\n変化点検出アルゴリズムを用いることで，調理中の音の変化を解析し，適切なタイミングで揚げ終わ\nりを判定する．FCGs の評価は，調理音データを用いた1 データ抜き交差検証によって行われた．\nMFCC を用いた分類では，F1 スコアが57.6%を達成し，振幅スペクトログラムを基にした変化点検出\nでは，揚げ終わりの検出精度がF1 スコア，適合率，再現率の3 指標において90%を達成した．特に，\n変化点検出を導入することで，揚げ途中での誤判定を大幅に削減できた． \n本研究では，唐揚げの調理音を分析し，揚げ終わりを判定する調理支援システムFCGsを開発した．\n評価実験の結果，本システムは高い精度で揚げ終わりを検出可能であり，料理初心者の調理を支援す\nる効果が期待される．今後の課題として，異なる環境（騒音がある場所）での精度向上，リアル",
            "調理を支援す\nる効果が期待される．今後の課題として，異なる環境（騒音がある場所）での精度向上，リアルタイ\nム処理の最適化，さらなる機械学習手法の適用が挙げられる．また，スマートスピーカとの連携やマ\nルチモーダル解析（画像＋音）を活用することで，より高度な調理支援システムの開発が可能となる． \n \n \n青山学院大学大学院理工学研究科 \n唐揚げの音響特性を利用した\n調理支援システムの開発\n新井優作\n2025/01/31\n目次\n第1 章\n序論\n3\n1.1\n研究背景. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n3\n1.1.1\n調理支援システムの需要. . . . . . . . . . . . . . . . . . . . . . . .\n3\n1.1.2\nセンシング技術を利用した調理支援. . . . . . . . . . . . . . . . . .\n4\n1.1.3\n揚げ物の揚がり具合判断. . . . . . . . . . . . . . . . . . . . . . . .\n5",
            "断. . . . . . . . . . . . . . . . . . . . . . . .\n5\n1.1.4\n加熱不十分な鶏肉調理の危険性. . . . . . . . . . . . . . . . . . . .\n6\n1.1.5\n音の検出・認知を行う既存製品. . . . . . . . . . . . . . . . . . . .\n6\n1.2\n研究目的. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n7\n1.3\n本論文の構成. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n8\n第2 章\n調理支援および音響的特徴を利用した関連研究\n9\n2.1\n音響センシングによる調理支援に関する研究. . . . . . . . . . . . . . . . .\n9\n2.2\n食材の音響的特徴を利用した状態認識に関する研究. . . . . . . . . . . . .\n11\n2.3\n異常音検出に関する関連研",
            "関する研究. . . . . . . . . . . . .\n11\n2.3\n異常音検出に関する関連研究\n. . . . . . . . . . . . . . . . . . . . . . . . .\n13\n2.4\n画像認識による調理支援および食材の状態認識に関する研究. . . . . . . .\n15\n第3 章\nFCGs: 料理初心者に向けた唐揚げ調理支援システム\n17\n3.1\nFCGs の提案\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n17\n3.1.1\n唐揚げの調理状態の定義. . . . . . . . . . . . . . . . . . . . . . . .\n17\n3.1.2\nFCGs のシステム構成\n. . . . . . . . . . . . . . . . . . . . . . . . .\n17\n第4 章\n調理音の特徴抽出手法および識別手法\n19\n4.1\n調理音および特徴量の解析手法\n. . . . . . . . . . . . . . . . . . . . .",
            "特徴量の解析手法\n. . . . . . . . . . . . . . . . . . . . . . . .\n19\n4.1.1\nスペクトログラム解析. . . . . . . . . . . . . . . . . . . . . . . . .\n19\n4.1.2\n主成分分析\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n20\n4.1.3\nt 分布型確率的近傍埋め込み法. . . . . . . . . . . . . . . . . . . . .\n20\n4.2\n調理音から抽出される音響特徴量. . . . . . . . . . . . . . . . . . . . . . .\n21\n4.2.1\n振幅スペクトログラム. . . . . . . . . . . . . . . . . . . . . . . . .\n21\n4.2.2\nMFCC . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n21\n4.2.3\nウェー",
            ". . . . . . . . . . . . . . . . . . .\n21\n4.2.3\nウェーブレット変換\n. . . . . . . . . . . . . . . . . . . . . . . . . .\n23\n4.3\n調理段階の識別手法\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n24\n4.3.1\n機械学習分類手法. . . . . . . . . . . . . . . . . . . . . . . . . . . .\n24\n4.3.2\nリサンプリングによる不均等データ処理手法. . . . . . . . . . . . .\n27\n4.3.3\n調理音の変化点検出手法. . . . . . . . . . . . . . . . . . . . . . . .\n29\n4.3.4\n調理音に含まれる雑音の処理\n. . . . . . . . . . . . . . . . . . . . .\n30\n4.4\n各識別手法の評価方法および評価指標\n. . . . . . . . . . . . . . ",
            "4.4\n各識別手法の評価方法および評価指標\n. . . . . . . . . . . . . . . . . . . .\n31\n1\n4.4.1\n一グループ抜き交差検証による評価方法. . . . . . . . . . . . . . .\n31\n4.4.2\n評価指標. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n31\n第5 章\n調理音識別手法およびFCGs の開発\n33\n5.1\n調理音データのラベリング. . . . . . . . . . . . . . . . . . . . . . . . . . .\n33\n5.2\n機械学習モデルによる唐揚げの調理音データ分類精度の評価. . . . . . . .\n33\n5.2.1\nMFCC 特徴量を使用した分類精度の評価. . . . . . . . . . . . . . .\n34\n5.2.2\nPCA およびt-SNE によるMFCC 特徴量解析. . . . . . . . . . . . .\n37\n5.2.3\nリサンプリングバランスの調整による分類モデ",
            ". . . . . . . . . .\n37\n5.2.3\nリサンプリングバランスの調整による分類モデルの再評価\n. . . . .\n38\n5.2.4\n振幅スペクトログラムに基づく再ラベリング. . . . . . . . . . . . .\n39\n5.2.5\n4 クラスにおけるMFCC 特徴量による分類精度の評価\n. . . . . . .\n39\n5.2.6\nウェーブレット変換による特徴量抽出を利用した分類精度の評価\n.\n42\n5.3\n変化点検出による唐揚げの揚げ終わり検出精度の評価. . . . . . . . . . . .\n42\n5.4\n変化点検出を利用した揚げ終わり判定システムの実装. . . . . . . . . . . .\n46\n第6 章\n結論\n52\n6.1\n本研究のまとめ. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n52\n6.2\n今後の展望\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n52\n",
            " . . . . . . . . . . . . . . . . . . . . . . .\n52\n謝辞\n54\n参考文献\n55\n付録A 本研究に関する論文と発表実績\n62\n付録B 唐揚げの一般的なレシピまとめ\n63\n付録C MFCC 特徴量を使用したその他の分類精度の評価\n64\nC.1\nアンダーサンプリングにCluster Centroid を使用した際の分類精度一覧. .\n64\nC.2\nアンダーサンプリングにCondensed Nearest Neighbour を使用した際の分\n類精度一覧\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n66\nC.3\nアンダーサンプリングにNearMiss-1 を使用した際の分類精度一覧. . . . .\n67\nC.4\nアンダーサンプリングにNearMiss-2 を使用した際の分類精度一覧. . . . .\n68\nC.5\nアンダーサンプリングにOne-Sided Selection を使用した際の分類精度一覧\n69\n2\n第1章\n序論\n本章では序論として，本研",
            "d Selection を使用した際の分類精度一覧\n69\n2\n第1章\n序論\n本章では序論として，本研究における背景および研究目的，本論文の構成について述\nべる．\n1.1\n研究背景\n1.1.1\n調理支援システムの需要\n料理初心者の増加\n新型コロナウイルス感染症の拡大以前は，フードデリバリーサービスが普及したことも\nあり，外食・中食の利用頻度が増加の一途を辿っていた[1][2]．反対に，家庭で料理をす\nる機会は減少していた．しかし，新型コロナウイルス感染症の拡大により，在宅時間が増\nえると共に，料理をする機会も増加した．\n2021 年に実施された農林水産省による「食育に関する意識調査」では，図1.1 で示され\nているように「自宅で食事を食べる回数」・「自宅で料理を作る回数」が増えたと回答した\n割合がそれぞれ35.5%，26.5%となった．特に若い世代（20～39 歳）において，\n「自宅で料\n理を作る回数」が増えたと回答した割合は39.5%にまで上った[3]．2020 年の消費者動向\n調査においても，コロナ禍での調理時間・回数が増えたと回答した割合は全体で32.9%と\nなった[4]．\nこの傾",
            "いても，コロナ禍での調理時間・回数が増えたと回答した割合は全体で32.9%と\nなった[4]．\nこの傾向は海外でも見られる．スペイン・クロアチア・ニュージーランドでそれぞれ実\n施された調査では，新型コロナウイルス感染症の流行によるロックダウン中に調理頻度が\n増加したものの割合は約4～5 割という結果が報告されている[5][6][7]．\nこのように，新型コロナウイルス感染症が拡大した結果，料理をする機会が増加してい\nる．これに伴い，普段料理をする機会がなかった人々が料理をする機会を得たため，料理\n初心者が増加していると考えられる．\n調理技術による料理の壁\n料理初心者の大きな壁として，レシピ表現の曖昧さおよび調理技術の不足が挙げられる．\nレシピ表現の曖昧さに関しては調味料の量をあらわす「少々」および「適量」，火加減\nにおける食材の色・状態変化の見極めが壁となっている．ハウス食品株式会社が男女500\n人ずつの計1000 人を対象に実施した調査によると「レシピの独特な表現に戸惑ったこと\nがある」と回答した人は約6 割である．そのうち，コロナ禍で料理を始めた人は約8 割に\n上る[8]．\n調理技術に",
            "回答した人は約6 割である．そのうち，コロナ禍で料理を始めた人は約8 割に\n上る[8]．\n調理技術においては食材を適切な大きさに切るといった基本的な技術から，魚の三枚お\nろしをはじめとした多様な包丁さばきなどが料理初心者にとって習得に時間のかかる技術\nであると考えられる．平島らの調査によると，半月切りや輪切りという基本的な包丁の技\n3\n図1.1: 新型コロナウイルス感染症による食生活の変化（[3] より引用）\n術において，普段調理をほとんどしない235 人のうち，それぞれ，18.7%と8.9%の人がで\nきないと回答している[9]．\nよって，料理初心者がすぐに習得することが困難である技術および調理における判断を\n支援するシステムが必要であると考えられる．\n1.1.2\nセンシング技術を利用した調理支援\n料理初心者を支援するための技術として，センシング技術が挙げられる．近年，IoT\n（Internet of Things）技術の普及によりスマートフォンおよびタブレットだけなく，日常\nのあらゆるものにセンサが搭載されている．調理器具およびキッチン用品もその例外では\nない．調理器具およびキッチン",
            "ものにセンサが搭載されている．調理器具およびキッチン用品もその例外では\nない．調理器具およびキッチン用品とセンシング技術やIoT 技術を導入したスマートキッ\nチン家電は，料理初心者の未熟な技術および判断を支援し，調理の負担を軽減する．Kido\nらの研究では，調味料の容器にモーションセンサ，LED ライトを用いることで調味料追加\n4\nの支援システムを提案した[10]．加藤らの研究では，包丁の柄先に加速度センサを用いる\nレシピ動画の自動同期システムSynCook を提案した[11]．また，2021 年にはHestan Cue\nという調理器具，IH ヒーター，ビデオガイド付きレシピを組み合わせたスマート調理家電\nが発売された[12]．図1.2 のように調理器具，IH ヒーター，スマートデバイスがBluetooth\nで連動し，調理器具に組み込まれている温度センサにより最適な温度をリアルタイムで検\n知，加熱温度をアプリを介してIH ヒーターに指示する．さらに調理器具に食材を入れる\nタイミングおよびひっくり返すタイミング，取り出すタイミングなどを通知する．\nこのように料理をする際に利用するものとセ",
            "ひっくり返すタイミング，取り出すタイミングなどを通知する．\nこのように料理をする際に利用するものとセンシング技術の融合により，日々の料理が\n可制御，可視化されていることがわかる．\n図1.2: スマート調理家電「Hestan Cue」のシステム概要（[12] より引用）\n1.1.3\n揚げ物の揚がり具合判断\n揚げ物は食品に小麦粉・溶き卵・パン粉・片栗粉などをコーティングし，高温の油で揚\nげることで表面の水分を蒸発させサクサクの食感を実現している．周りの衣および食品\nのサイズ，揚げる時間によって揚げ物の食感も変わる[13]．そのため衣は色が付き十分揚\nがっているように見えるが中身に火が通っていない場合がある．このように，表面だけで\n判断することが難しい揚げ物は，料理初心者にとっては困難なレシピの1 つであると考え\nられる．\nそこで本研究では揚げ物に着目する．揚げ物を揚げる際，衣の水分損失が指数的に減少\nすることから，揚げ物の揚がり具合による水分と油の振動が音響的変化にあらわれると想\n定される[14]．よって，揚げ物を揚げている時間に対する音響変化を利用した，揚がり具\n合の判定が可能であると考",
            "14]．よって，揚げ物を揚げている時間に対する音響変化を利用した，揚がり具\n合の判定が可能であると考えられる．\n5\n1.1.4\n加熱不十分な鶏肉調理の危険性\n揚げ物料理の中でも，加熱不足で食中毒となる危険性が高い食材は鶏肉である．生の鶏\n肉はサルモネラやカンピロバクター等の食中毒菌の感染源となる[15][16]．特に，カンピ\nロバクター食中毒はノロウイルスと並んで食中毒事件数が高い値となっている．厚生労働\n省が実施した調査では，令和5 年においてカンピロバクター食中毒が発生した件数が211\n件に上っていることを報告している[17]．結果，日本では各機関が予防のために注意喚起\nしている[17][18][19]．食中毒を防ぐための十分な加熱は，鶏肉の中心温度が75◦C 以上で\n1 分間以上とされている．\nしかしSolveig らの調査によると，家庭での鶏肉調理の大半が内部温度を測定せずに調\n理されており，病原体の完全な無害化を達成できていない場合が多いことがわかった[20]．\nよって本研究では，加熱不十分な状態を調理完了と誤判定しない安全な調理支援システ\nムを構築する．\n1.1.5\n音の検",
            "は，加熱不十分な状態を調理完了と誤判定しない安全な調理支援システ\nムを構築する．\n1.1.5\n音の検出・認知を行う既存製品\n今日では，様々なスマートデバイスが普及したことにより，音を利用する技術が日常生\n活に馴染んでいる．本項では，既に一般に普及している音を利用した技術を紹介する．\n音声センサによる音検知通知\nGoogle およびApple はスマートデバイスが周囲の物音を聞き取り通知してくれる機能\nを提供している[21][22]．本機能は聴覚の障害がある人およびイヤホン・耳栓を装着して\nいるとき，物音に気付きにくい状況下でも，指定の音を検知すると図1.3 のようにスマー\nトデバイスへ直接通知をしたり，端末の振動およびカメラ撮影用ライトを点滅させたりし\nて通知をしてくれる．このようにスマートデバイスに内蔵されている音声センサのみで音\nの検知が可能になっている．\nまた，スマートフォンの内臓マイクロフォンなどの音響的センサは身近な機械に組み込\nむことが容易であり，料理中に水がかかることおよびセンサの設置が不自由であるといっ\nた課題が解消される．\nスマートスピーカの普及\nApple が自社の",
            "センサの設置が不自由であるといっ\nた課題が解消される．\nスマートスピーカの普及\nApple が自社のスマートフォンに搭載した「Siri」およびAmazon が発売した「Amazon\nEcho」などを皮切りにスマートスピーカの市場は成長を続けている．野村総合研究所の\n「IT ナビゲーター2021 年度版」[23] によると2020 年のスマートスピーカ世帯普及率は\n11.2%（583 万世帯）だったが，2021 年には13.5%（691 万世帯）と増加している（図1.4）．\nさらに2026 年には30.8%（1544 世帯）にまで上ることが見込まれている．\nこのような現状から，本研究では音を利用した料理支援に着目する．\n6\n図1.3: Android 端末の音検知通知の様子（[21] より引用）\n1.2\n研究目的\n前節で述べたように，新型コロナウイルス感染症拡大の影響から現代社会の料理に対す\nる向き合い方に変化が生じており，料理初心者に対する料理支援の必要性が増加してい\nる．また，揚げ物料理に対する料理初心者の壁として，火加減の調整および中身まで火が\n通っているかの判断などの難しさが存在",
            "理に対する料理初心者の壁として，火加減の調整および中身まで火が\n通っているかの判断などの難しさが存在する．音の技術に関しては，既に身近にある様々\nな製品にその技術が組み込まれているため馴染みのある技術だと言える．以上の点から本\n論文では身近な端末であるスマートフォンに内臓されているマイクロフォンから音響信号\nを取得し，揚げ物の中でも特に中身が十分加熱されているかわかりづらく，加熱不十分に\nよる食中毒の危険性を持つ鶏肉料理の一つである唐揚げを対象とする．そして，唐揚げの\n揚げ終わりを判別する調理支援システムの開発を目的とする．\nそこで本研究では次の2 つを目標とする．\n1.\n唐揚げの調理状態において，揚げ終わりとなる前の状態で調理完了と誤判定しない安\n全な音判定システムの構築．\n2.\nスマートフォン上で唐揚げの揚げ終わりをリアルタイムに判別する，容易に利用可能\nなアプリケーションの開発．\n調理音から振幅の平均を算出し，変化点検出を実施した結果，揚げ終わりの検出はF1\nスコア，適合率，再現率の3 種類の指標で90%の精度を達成した．また，変化点検出アル\n7\n図1.4: 日本におけるスマート",
            "の3 種類の指標で90%の精度を達成した．また，変化点検出アル\n7\n図1.4: 日本におけるスマートスピーカの保有世帯数・普及率予測（[23] より引用）\nゴリズムを実装した，リアルタイムで唐揚げの調理完了タイミングを判定するスマート\nフォンアプリケーションFCGs を開発した．\n1.3\n本論文の構成\n本論文の構成を以下に示す．\n第1 章: 序論\n本論文の研究背景，研究目的および論文の構成について述べる．\n第2 章: 調理支援および音響特徴を利用した関連研究\n本研究に関連する，調理支援に関する研究および音響特徴を利用した研究について\n述べる．\n第3 章: FCGs: 料理初心者に向けた唐揚げ調理支援システム\n唐揚げの調理支援システムの提案について述べる．\n第4 章: 調理音の特徴抽出手法および識別手法\n本研究で検討した唐揚げの調理音から得られる音響特徴量および調理完了の識別手\n法について述べる．\n第5 章: 調理音識別手法およびFCGs の開発\n各識別手法の評価および調理支援システムの評価について述べる．また，提案手法\nの開発について述べる．\n第6 章: 結論\n本論文の結論と今後の展望",
            "価について述べる．また，提案手法\nの開発について述べる．\n第6 章: 結論\n本論文の結論と今後の展望について述べる．\n8\n第2章\n調理支援および音響的特徴を利用した関連\n研究\n本章では本研究を進めるにあたっての関連した研究についてまとめる．\n2.1\n音響センシングによる調理支援に関する研究\n調理中の動作および食材を音で認識することで，調理支援が可能である．そのため，調\n理活動認識および食材の状態認識に関する研究が実施されている．\nTabacchi らは，調理プロセスの段階を音響および振動データに基づいて分類する新しい\n統計的パターン認識手法を提案した[24]．本研究では，水の沸騰という単純なケースを対\n象とし，調理段階の識別精度を向上させる最適化モジュールを導入した．\n沸騰段階のデータは，鍋に水を1.5 L 入れ，室温から最大加熱力で加熱することで収録\nされた．記録には，AKG SE300B カーディオイドマイク（44.1 kHz）とPCB 加速度計\n（352C33，44.1 kHz）が使用され，合計28 回の実験が実施された．また，録音環境は静か\nな部屋で統一された．特徴量としてMF",
            "使用され，合計28 回の実験が実施された．また，録音環境は静か\nな部屋で統一された．特徴量としてMFCC（Mel-Frequency Cepstral Coeﬃcient）が使用\nされ，加熱，核沸騰，遷移沸騰，膜沸騰の4 つの段階が識別された．各録音は100 ms ご\nとに分割され，Parzen Classiﬁer を用いて分類が行われた．音響データ単独，振動データ\n単独，および両者の組み合わせの3 種類の特徴セットが試験された．\n最適化モジュールでは，分類結果に移動平均フィルタを適用し，閾値を超える確率が1\n秒以上続く場合にクラスが確定される仕組みが導入された．この結果，加熱および膜沸騰\n段階では最適化後に100%の識別精度が達成された．一方，核沸騰および遷移沸騰段階で\nは，最適化前の識別精度は約98%であったが，最適化により誤分類が減少した．\n今後の課題として，振動データのラベル付けが音響信号に基づいて実施されたことによ\nる精度低下が指摘されている．振動データの独自のラベリング手法の導入や，温度センサ\nや圧力センサなど他のデータと統合したマルチモーダル処理が求められる．\n宮澤らは，",
            "導入や，温度センサ\nや圧力センサなど他のデータと統合したマルチモーダル処理が求められる．\n宮澤らは，調理環境音を用いた行動認識においてレシピ情報を時系列的に考慮し，音響\n識別器の中間特徴量を導入することで認識精度の向上を図った[25]．従来の手法では「切\nる」「焼く」といった調理行動のみを対象としていたが，本研究では「水の音」や「ビニー\nル袋の擦れる音」などの環境音も認識対象に加えることで，行動識別の精度がさらに向上\nすることが示された．\n焼きそばの調理を対象とし，音響データはiPhone 8 で録音された6 つの調理環境音を\n使用した．録音された音声データは，サンプリング周波数16 kHz で記録された．特徴量\nとしてMFCC と，音響識別器の中間層から抽出した特徴量が使用された．音響識別器に\nはEnvNet-v2 を改良したモデルが採用され，ボトルネック層の出力を新たな特徴量とし\nて利用することで，調理行動の識別精度向上が図られた．\n9\n調理行動の識別にはHMM（Hidden Markov Model）が使用され，モデルの出力確率分\n布はGMM（Gaussian mixture m",
            "kov Model）が使用され，モデルの出力確率分\n布はGMM（Gaussian mixture models）で推定された．実験では，MFCC の窓幅を16 ms，\n160 ms，1600 ms の3 条件で設定し，HMM の混合数1・2 の条件で識別精度が評価され\nた．評価指標としてF 値が用いられ，cut（切る）・grill（焼く）の調理行動に加えothers\n（その他）が対象となった．HMM ネットワークは図2.1 のようになる．\n図2.1: レシピ情報を加味したHMM ネットワーク（[25] より引用）\n結果として，MFCC と比較して音響識別器の中間特徴量を導入した方が「焼く」行動の\n識別精度が向上した．特に，中間特徴量の次元を100 に設定した場合，F 値が最も高くな\nり，音響識別器を用いる有効性が示された．一方，\n「切る」行動に関しては中間特徴量の\n導入による精度向上は確認されなかったものの，全体的な識別精度は向上した．さらに，\n「その他」クラスを「水の音」「ビニール袋の音」などに細分化することで，他クラスとの\n誤認識が減少し，識別性能が向上することが確認された．\n今後",
            "音」などに細分化することで，他クラスとの\n誤認識が減少し，識別性能が向上することが確認された．\n今後の課題として，GMM の混合数の増加が必ずしも識別精度向上に寄与しないことが\n指摘された．特に「切る」音と環境音（others）が類似している場合，誤分類の原因とな\nる可能性がある．環境音クラスをさらに細分化することで，識別精度を高める必要があ\nる．また，実験はオフラインで実施されたが，オンラインのリアルタイム認識システムへ\nの応用が求められる．\n陳らは，音響解析を用いて唐揚げの揚がり具合を判定する手法を提案した[26]．本研究\nでは，スマートフォンの内蔵マイクを活用して調理中の音響データを取得し，機械学習を\n用いて唐揚げの調理状態を分類することを目的とした．従来の調理支援システムは，調理\n器具にセンサを取り付ける必要があったが，本手法では外部機器を必要とせず，より簡便\nに導入可能なシステムが設計された．\n唐揚げの調理音を対象とし，データはiPhone 11 を使用して静かなキッチン環境で録音\nされた．サンプリング周波数は44.1 kHz で，調理油の温度はクックサーモ5495B を使用",
            "録音\nされた．サンプリング周波数は44.1 kHz で，調理油の温度はクックサーモ5495B を使用\nして監視された．表2.1 の通り，温度（150◦C，170◦C，200◦C），個数（5 個，7 個，10 個），\n調理油の使用回数（1 回目，2 回目）の条件を変えて10 回分のデータが収集された．調理\n音は「揚げはじめ」「変化1」「変化2」「変化3」「揚げ上がり」の5 つのラベルに分類さ\nれ，音響データにはMFCC が特徴量として使用された．\n機械学習には，自動機械学習ツール「TPOT」を使用した．TPOT は遺伝的プログラミ\nングにより最適なモデルを自動探索し，ハイパーパラメータの調整を実施する．本研究\nでは，5 分割交差検証を用いて複数のモデルを試行した結果，XGB（eXtreme Gradient\nBoosting）が最も高い精度を達成した．\n実験の結果は表2.2 の通り，全体のF1 スコアは97.14%，揚げ上がり段階のF1 スコア\nは85.71%に達した．揚げはじめや変化段階は95%以上の精度で分類されたが，揚げ上が\n10\n表2.1: 計測10 回分の唐揚げの揚げ方（[26",
            "は95%以上の精度で分類されたが，揚げ上が\n10\n表2.1: 計測10 回分の唐揚げの揚げ方（[26] を基に作成）\n温度[◦C]\n個数[個]\n油使用回数[回]\n動画1\n170\n7\n1\n動画2\n170\n7\n2\n動画3\n170\n10\n1\n動画4\n170\n10\n2\n動画5\n170\n5\n1\n動画6\n170\n5\n2\n動画7\n150\n7\n1\n動画8\n150\n7\n2\n動画9\n200\n7\n1\n動画10\n200\n7\n2\nり段階の精度は他のクラスよりも低かった．\n表2.2: 各クラスにおいての評価結果（[26] より引用）\n評価尺度\nその他\n揚げはじめ\n変化1\n変化2\n変化3\n揚げ上がり\n平均\n加重平均\nRecall\n98.53%\n95.71%\n98.66%\n95.96%\n98.58%\n83.33%\n95.13%\n97.15%\nSpeciﬁcity\n99.79%\n99.63%\n98.14%\n99.52%\n99.40%\n99.80%\n99.38%\n99.15%\nPrecision\n97.10%\n98.67%\n95.45%\n98.17%\n97.66%\n88.24%\n95.88%\n97.17%\nAccurac",
            "\n95.45%\n98.17%\n97.66%\n88.24%\n95.88%\n97.17%\nAccuracy\n98.53%\n95.71%\n98.66%\n95.96%\n98.58%\n83.33%\n95.13%\n97.15%\nF1-score\n97.81%\n97.17%\n97.03%\n97.05%\n98.12%\n85.71%\n95.48%\n97.14%\n揚げ上がり段階の精度が低下した要因として，データ数の不足が挙げられる．特に高温\nや低温，量が多い状態では音響特性が異なり，単純な閾値設定では分類が困難であった．\nしかし，TPOT による機械学習モデルの最適化により，温度や個数の条件が異なっても\n一定の精度が維持された．\n本研究は，音響解析と機械学習を組み合わせて調理支援を行う新たなアプローチを提案\nしており，外部センサを必要とせず，スマートフォンだけで調理状態を判定できる点が特\n徴である．今後は，より多くの調理データを収集し，揚げ上がり段階の精度向上を目指す\nとともに，リアルタイムでの揚がり具合判定システムの構築が求められる．\n2.2\n食材の音響的特徴を利用した状態認識に関する研究\n食材の状態を",
            "定システムの構築が求められる．\n2.2\n食材の音響的特徴を利用した状態認識に関する研究\n食材の状態を正確に把握することは，食品の品質管理および食材の美味しさの認識に有\n効である．そのため，非破壊的な食材の状態認識および食感の分類に関する研究が実施さ\nれている．\nCaladcad らは，音響信号に基づいてココナッツの成熟度を判定する手法を提案した[27]．\n本研究では，ココナッツを叩くことで得られる音響データを取得し，機械学習を活用して\n成熟度を分類することを目的としている．従来の成熟度判定は農家が音を頼りに行う主観\n的な方法であったが，本手法では音響データを解析することで，より客観的で高精度な分\n類を目指している．\n11\nココナッツのタッピング音は，専用のタッピングチャンバを用いて収録された．サンプ\nリング周波数は44.1 kHz で，吸音材を用いたチャンバ内でノイズを抑えながら録音され\nた．収録された音響データは，高速フーリエ変換（Fast Fourier Transform，FFT）を施\nし，周波数領域の特徴量を抽出した．サンプル数は129 個（未成熟8 個，成熟36 個，過\n成熟",
            "を施\nし，周波数領域の特徴量を抽出した．サンプル数は129 個（未成熟8 個，成熟36 個，過\n成熟85 個）で，それぞれ3 回ずつタッピングされ，合計387 のデータが得られた．\n機械学習モデルとして，人工ニューラルネットワーク（Artiﬁcial Neural Network，ANN），\nサポートベクターマシン（Support Vector Machine，SVM），ランダムフォレストの3 種\n類が用いられた．データは70%を訓練用，30%をテスト用として分割し，10 分割交差検\n証によりモデルの評価が実施された．\n実験の結果は表2.3 の通りである．ランダムフォレストが最も高い精度を達成し，訓練\n精度は90.98%，テスト精度は83.48%に達した．一方，ANN は訓練精度79.32%，テスト\n精度81.74%で安定した結果を示し，SVM はやや精度が低かった．特に過成熟の分類精度\nは高かったが，未成熟と成熟の識別はやや難しく，データの不均衡が影響したと考えら\nれる．\n表2.3: 3 種類の機械学習分類器の性能比較（[27] より引用）\nModel\nClassiﬁcation A",
            "3 種類の機械学習分類器の性能比較（[27] より引用）\nModel\nClassiﬁcation Accuracy [%]\nF- Score [%]\nTrain\nTest\nTrain\nTest\nArtiﬁcial Neural Network\n79.32\n81.74\n77.46\n79.27\nRandom Forest\n90.98\n83.48\n91.41\n81.35\nSupport Vector Machine\n88.35\n80.00\n88.79\n76.67\n原因として，未成熟のサンプル数が少ないことが分類精度の低下を引き起こしている可\n能性が指摘された．今後は，サンプル数の増加やデータ拡張を実施し，未成熟クラスの精\n度向上を図る必要がある．また，深層学習モデルの導入による分類精度向上や，リアルタ\nイム判定が可能なシステムの構築が求められる．\nZhao らは，芯にかびを持つ不健全なリンゴを非破壊で検出するために，振動音響信号\nの多領域特徴を用いた深層学習と浅層学習を組み合わせたハイブリッドモデルを提案した\n[28]．本研究は，健康な果実，軽度のかび芯（不健全），重度のかび芯（病果）の3 ",
            "モデルを提案した\n[28]．本研究は，健康な果実，軽度のかび芯（不健全），重度のかび芯（病果）の3 クラ\nス分類を目指し，果実内部の初期異常を検出する方法を開発している．\nかび芯はリンゴの内部障害であり，初期段階では外観上の異常がなく，食品安全上のリ\nスクが見過ごされやすい．本研究では，リンゴの赤道帯部分に電圧刺激を加え，誘発さ\nれた振動音響信号を圧電センサを用いて収集した．振動音響信号は時間領域，周波数領\n域，時間-周波数領域の2 次元画像に変換され，多領域特徴の抽出に利用された．ResNet50\nで深層特徴を得た後，SVM およびExtreme Learning Machine（ELM）の浅層学習モデ\nルで分類するハイブリッド構造を採用し，特徴選択と分類器の最適化には粒子群最適化\n（Particle Swarm Optimization，PSO）アルゴリズムが用いられた．\nリンゴ1200 個を対象とした実験では，時間-周波数領域の特徴が特に効果的であり，提\n案モデル（IResNet50-PSO-ELM）は全体で96.7%の分類精度を達成した．健康な果実，不\n健康な果実，病果の分類精",
            "0-PSO-ELM）は全体で96.7%の分類精度を達成した．健康な果実，不\n健康な果実，病果の分類精度はそれぞれ100%，94.1%，96.2%であり，不健康な果実の一\n部が健康な果実または病果と誤分類される課題が残ったものの，F1 スコアは全クラスで\n12\n95%以上を記録した．\n本研究は，果実内部の初期障害を高精度で非破壊検出する可能性を示しており，振動音\n響データを利用した食品品質管理の有用性を提案している．\nLopez らは，食品のサクサク感を音響信号に基づいて分類する手法を提案した[29]．本\n研究では，Autonomous Sensory Meridian Response（ASMR）動画から音声データを収\n集し，フライドチキン，ポテトチップス，トーストのサクサク感を深層ニューラルネット\nワーク（Deep Neural Network，DNN）で分類することを目的としている．従来の官能評\n価や機械的測定と異なり，音響データを用いることで，非侵襲的かつ迅速に食品の食感を\n評価することが可能となる．\n本研究では，YouTube のASMR 動画584 本からフライドチキン，ポテ",
            "ることが可能となる．\n本研究では，YouTube のASMR 動画584 本からフライドチキン，ポテトチップス，トー\nストの咀嚼音を収集した．音声データは1 秒ごとにトリミングされ，サンプリング周波数\nを22,050 Hz に統一して保存された．収集した音声から，MFCC および離散フーリエ変換\n（Discrete Fourier Transform，DFT）スペクトルが特徴量として抽出された．また，テス\nトデータとして音響防音ボックス内で機械的に圧縮して収録されたフレッシュトースト，\nASMR 動画から収集されたミルクに浸したトーストの音響データを用意した．\n分類モデルには，MFCC を用いた多層パーセプトロン（Multi-layer Perceptron，MLP）\nと，DFT スペクトルを入力とするResNet（残差ネットワーク）が使用された．MLP は\n512，256，3 のニューロンを持つ3 層の全結合ネットワークで構成され，ResNet は複数の\n残差ブロックからなる深層学習モデルである．\n結果，MLP モデルは学習データで95%，テストデータで100%の精度を達成した．一\n",
            "デルである．\n結果，MLP モデルは学習データで95%，テストデータで100%の精度を達成した．一\n方，ResNet モデルは学習データで85%，データ拡張後には97%の精度を示したが，テス\nトデータでは16%と低い精度にとどまった．特に，MLP モデルはフレッシュトーストと\nミルクに浸したトーストの音響データも高精度で分類し，外部データに対する汎化性能が\n示された．\n本研究は，食品のサクサク感を音響信号から分類する新たな手法を提示し，食品業界に\nおける品質管理や製品開発に貢献する知見を提供している．今後は，さらなるデータセッ\nトの拡充やリアルタイムでの分類システム構築が求められる．\n本研究においても，唐揚げのフライ調理音に最適な特徴量および分類器を利用すること\nで，揚げ終わりの特徴を捉え，正確な識別が可能であると考える．\n2.3\n異常音検出に関する関連研究\n異常音検出は，注意を向けないと気づくことが困難な変化を認識可能にする．そのため，\nわずかな音の変化を捉えるための研究が実施されている．\nXiao らは，ガスパイプラインの漏れを音響信号に基づいて検出する手法を提案した[30]．\n本",
            "る．\nXiao らは，ガスパイプラインの漏れを音響信号に基づいて検出する手法を提案した[30]．\n本研究では，ウェーブレット変換とSVM を組み合わせた漏れ検出および深刻度分類シス\nテムを開発し，パイプラインの安全性を向上させる技術について検討している．特に，漏\nれ音の特性を利用し，高精度かつ迅速に漏れの規模の識別が可能であることが示されてい\nる．音響センサによって収集された漏れ音はウェーブレット変換によって特徴抽出が行わ\nれ，ノイズ除去後にSVM で分類される．\n本システムの開発には，30 m および3 m のパイプラインが使用され，直径1 mm，3\n13\nmm，5 mm の漏れ穴を設けた実験が実施された．結果として，漏れの有無は99.4%の精度\nで検出され，漏れの深刻度は95.6%の精度で分類された．特に，標準偏差，ウェーブレッ\nト平均周波数，および絶対平均が漏れの深刻度分類において重要な役割を果たした．\nMalviya らは，呼吸音を用いてCOVID-19 および他の呼吸器疾患を検出するシステムを\n提案した[31]．本研究では，自己符号化器と長短期記憶ネットワーク（Long Sh",
            "出するシステムを\n提案した[31]．本研究では，自己符号化器と長短期記憶ネットワーク（Long Short-Term\nMemory，LSTM）を組み合わせ，音響データから疾患を高精度に分類する手法を開発し\nている．\n呼吸器疾患の診断において，咳や呼吸音は重要なバイオマーカーとなる．音響データを\n解析することで，COVID-19 や肺炎，慢性閉塞性肺疾患（Chronic Obstructive Pulmonary\nDisease，COPD）などを検出できる可能性が示されている．特に自己符号化器は健康な\n音声データを学習し，異常がある場合に高い再構築誤差を示すことで疾患の存在を検出\nする役割を果たす．LSTM はその後の分類フェーズで音声データの時間的特徴を学習し，\n疾患の種類を判別する．\n本システムは，Kaggle やPﬁzer Digital Medicine Challenge から収集した呼吸音データ\nを使用し，515 件の音声データで構成されたデータセットで訓練・検証が実施された．デー\nタセットには，COVID-19 患者185 名，健康な人150 名，およびその他の呼吸器疾患（",
            "デー\nタセットには，COVID-19 患者185 名，健康な人150 名，およびその他の呼吸器疾患（肺\n炎，COPD，上気道感染症など）を持つ患者180 名が含まれている．音声データは22,050\nHz でリサンプリングされ，短時間フーリエ変換（Short-Time Fourier Transform，STFT）\nによって特徴が抽出された．\nモデルは，LSTM が200 エポック，自己符号化器が100 エポックで学習され，損失関\n数として平均二乗誤差が使用された．表2.4 の通り，分類精度は平均97.5%に達し，特に\nCOVID-19 の検出においては曲線下面積1.0 を達成し，感度1.0，特異度0.979，F1 スコ\nア0.984 という非常に高い精度が得られた．他の呼吸器疾患の分類精度も平均96%以上で\nあり，COVID-19 と他の疾患の正確な識別が可能であることが示された．\n表2.4: 呼吸器疾患のマルチクラス分類の性能評価指標（[31] より引用）\nClass\nAccuracy\nPrecision\nSensitivity\nSpeciﬁcity\nF1-Score\nPneumon",
            "\nPrecision\nSensitivity\nSpeciﬁcity\nF1-Score\nPneumonia\n0.944\n0.563\n0.818\n0.953\n0.667\nURTI\n0.981\n0.75\n0.857\n0.987\n0.80\nBronchiolitis\n0.994\n1.00\n0.75\n1.00\n0.857\nCOVID-19\n0.987\n0.968\n1.00\n0.979\n0.984\nCOPD\n0.944\n0.981\n0.867\n0.990\n0.920\nHealthy\n1.00\n1.00\n1.00\n1.00\n1.00\n本研究では，唐揚げの調理音から揚げ終わり音を検出するシステムを提案する．唐揚げ\nの揚げ終わり音は，人間の耳で聞き取れる変化ではあるが，注意を向けないと気づくこと\nが難しい．しかし，唐揚げ調理音を時系列データとして捉え，揚げ終わりの際に発生する\n音を異常音および変化点として捉えることが可能であるならば，本研究においても異常音\n検出は有効であると考えられる．\n14\n2.4\n画像認識による調理支援および食材の状態認識に関する研究\n音だけでなく，カメラを利用した状態認識による調",
            "像認識による調理支援および食材の状態認識に関する研究\n音だけでなく，カメラを利用した状態認識による調理支援に関する研究も実施されて\nいる．\nLin らは，人工知能（Artiﬁcial Intelligence，AI）技術を用いて食品の調理状態を自動で\n判定するシステムを開発した[32]．本研究では，機械ビジョンと画像処理技術を組み合わ\nせ，食品の色の変化を解析することで「未調理」「調理済み」「過調理」の各状態を識別す\nることを目的としている．\n食品の調理状態をリアルタイムで監視するため，システムはRGB 画像をHSV 色空間\nに変換し，画像セグメンテーションを実施することで食品と背景を分離している．色相，\n彩度，明度の変化を利用して食品の調理成熟度や調理ムラを判断し，油の光沢やソースの\n吸収状態も解析する．画像処理アルゴリズムは，特定の色差や分布を用いて，調理工程を\n終了するか部分的に攪拌するかを判断する．\n研究では，約120 種類の食品データセットを用いて，調理成熟度や油の光沢，ソース吸\n収といったパラメータを定義し，AI アルゴリズムで解析した．実験結果では，誤認率を\n3%未満に抑",
            "吸\n収といったパラメータを定義し，AI アルゴリズムで解析した．実験結果では，誤認率を\n3%未満に抑え，各画像の解析時間を0.2 秒以下に短縮することに成功した．また，キャベ\nツ，レタス，エリンギの3 種類の食品において，調理ムラや過調理箇所を特定し，自動攪\n拌を実行するロボットアームが実装された．\nこのシステムは，調理状態をより正確に判断できる食品調理の自動化を実現する可能性\nを示しており，将来的にはさらに多くの食品種に対応することで，食品調理の質を向上さ\nせることが期待されている．\nChao らは，バゲットの外観品質を自動評価するために，画像処理技術を活用した新し\nい評価システムを提案した[33]．本研究は，サイズ，平行度，色の3 つの指標を基に，従\n来の主観的な手作業評価を置き換える客観的で定量的な評価手法を開発している．\n食品業界では，食品の品質評価において外観が重要な指標となる．しかし，手作業によ\nる評価は主観的であり，評価者の熟練度に依存しやすく，時間がかかるという問題がある．\n本研究では，バゲットの画像を撮影し，画像処理技術を用いて自動的にバゲットの外観品\n質評価を行うシ",
            "．\n本研究では，バゲットの画像を撮影し，画像処理技術を用いて自動的にバゲットの外観品\n質評価を行うシステムを構築した．まず，撮影画像内のベーキングトレーを基準に画像の\n視点を補正し，その後，バゲットの外観を評価する．\nバゲット124 本を対象とした実験では，サイズ評価において平均絶対誤差が0.6 mm と\n高精度であった．A・B・C の三段階による平行度と色評価では，専門家の評価との一致\n率がそれぞれ96%および94%となり，提案手法の有効性が確認された．図2.2 の左側に平\n行度，右側に色評価の示す．図2.2 より，評価アルゴリズムと専門家の評価との間に高い\n整合性があることがわかる．不一致となった要素を分析すると，評価アルゴリズムの評価\nがより正確であり，主観的なバイアスを減らすことに役立つことがわかった．また，改良\n版k-means クラスタリングを用いたベーキングトレーの抽出精度は99.21% に達し，従来\n手法を上回る性能を示した．\n本研究は，画像処理を活用した食品品質評価の自動化の可能性を示し，手作業評価の課\n題を克服する新たなアプローチを提案している．今後は，深層学習技術",
            "動化の可能性を示し，手作業評価の課\n題を克服する新たなアプローチを提案している．今後は，深層学習技術を活用したバゲッ\nトの切り込みの評価や，より大規模なデータセットの収集により，さらなる精度向上が期\n待される．\nArman らは，ポテトチップスの揚げ工程をリアルタイムで最適化するスマートフライン\n15\n図2.2: 平行度および色評価の混同行列（[33] より引用）\nグシステムを提案した[34]．油吸収およびアクリルアミド生成は，健康リスクおよび品質\nのばらつきにつながる重要な課題である．従来の揚げ工程では，ポテトの化学的特性の個\n体差が考慮されず，一律の温度・時間で調理されていた．そこで，本研究ではコンピュー\nタビジョン，ハイパースペクトル画像，機械学習，デジタルツイン技術を統合したリアル\nタイム制御システムを開発することにより，リアルタイムでポテトの状態をモニタリング\nし，揚げ条件を動的に調整する．\nポテトを対象とした実験では，アクリルアミド生成が最大66%削減，油吸収量は16%\n低減された．また，色・食感の均一性が向上し，専門家の評価との一致率が高いことが確\n認された．リアルタイム",
            "された．また，色・食感の均一性が向上し，専門家の評価との一致率が高いことが確\n認された．リアルタイムモニタリングの精度については，色の予測精度R2 = 0.96，食感\n（硬さ）の予測精度R2 = 0.91，油含有量の予測精度R2 = 0.98 と高い性能を示した．\n本研究は，食品加工の自動化と品質管理の高度化を実現する新たなアプローチを示して\nいる．今後は，デジタルツイン技術を活用したさらなる最適化や，大規模データの収集に\nより，より高度なスマートフライングシステムの開発が期待される．\nこのように，同じ食材において，画像分析を利用して微細な差異を検知し，分類・識別\nすることが可能である．本論文では，音のみを利用して，唐揚げの状態認識および調理支\n援を検討している．調理環境にカメラを設置することおよび，レンズを曇らせたり，汚し\nたりしないように注意しながら調理することは，料理初心者にとっては困難であると考え\nたためである．しかし，今後スマートグラスといった料理中でも，容易に利用可能なデバ\nイスを利用して，画像と音のセンシングによるマルチモーダルシステムとして，調理支援\nの精度向上が実現可",
            "イスを利用して，画像と音のセンシングによるマルチモーダルシステムとして，調理支援\nの精度向上が実現可能であると考える．\n16\n第3章\nFCGs:料理初心者に向けた唐揚げ調理支\n援システム\n本章では，料理初心者が唐揚げの不完全な調理を防ぐために，揚げ終わりを通知する料\n理支援システムFCGs を提案する．第1 章で述べたように，音センシングは，他のセンサ\nに比べ設置の不自由がなく簡単に利用可能であり，現代では広く利用されている技術であ\nる．よって，スマートフォンのマイクロフォンから得られる調理音から，揚げ終わりを判\n定する．FCGs は「Fried Chicken Goal system」の頭文字をとった造語である．\n3.1\nFCGs の提案\n本節では唐揚げの揚げ終わり検出手法を提案する．唐揚げの調理音から，揚げ終わりを\n検出するために，機械学習および変化点検出による精度検証を実施する．その後，最も精\n度の良い手法を利用して，スマートフォンアプリケーションとして実装する．精度検証の\n結果は第5 章で述べる．\n3.1.1\n唐揚げの調理状態の定義\n本研究では，唐揚げの「揚げ終わり（Finis",
            "第5 章で述べる．\n3.1.1\n唐揚げの調理状態の定義\n本研究では，唐揚げの「揚げ終わり（Finish）」を衣にきつね色がしっかり付き，気泡\nが細かく完全に浮いている状態とし，それ以前の状態を総じて「揚げ途中（Middle）」と\n定義する．\n3.1.2\nFCGs のシステム構成\n本論文では，唐揚げの揚げ終わりを判別するアプリケーションの開発を目標としている\nため，アプリケーションのユーザビリティを考慮しないシンプルな構成とした．唐揚げの\nフライ調理を開始すると同時に，調理開始ボタンを押下し，揚げ終わりのフィードバック\nを確認した段階で調理終了ボタンを押下する．揚げ途中から揚げ終わりへの変化は，アプ\nリケーションの画面および通知音によってフィードバックする．画面によるフィードバッ\nクは図3.1 の通りである．画面上部には調理の経過時間を示すタイマーを設置している．\n17\n図3.1: FCGs の画面フィードバックの様子（左図：揚げ途中，右図：揚げ終わり）\n18\n第4章\n調理音の特徴抽出手法および識別手法\n本章では本研究で使用した解析手法，特徴量，機械学習手法および変化点検出手法につ\nいて",
            "および識別手法\n本章では本研究で使用した解析手法，特徴量，機械学習手法および変化点検出手法につ\nいて述べる．また，解析はすべてプログラミング言語のPython を使用している．解析に\n利用したデータの詳細は表4.1 の通りである．調理音1 から調理音4 は唐揚げの調理音以\n外の雑音（水が流れる音，キッチンタイマーの音，人の話し声等）が含まれたデータであ\nる．調理音5 から調理音10 は陳らが収集したデータを使用しており，静かな環境下で得\nられたデータである[26]．これらのデータを利用して解析および手法の検討を実施する．\n表4.1: 本研究で利用した唐揚げの調理音データ一覧\n時間[s]\n温度[◦C]\n個数[個]\n油使用回数[回]\n雑音の有無\n調理音1\n269\n180\n7\n1\n有\n調理音2\n280\n180\n7\n2\n有\n調理音3\n258\n180\n7\n1\n有\n調理音4\n279\n180\n7\n2\n有\n調理音5\n247\n170\n7\n1\n無\n調理音6\n300\n170\n7\n2\n無\n調理音7\n313\n170\n10\n1\n無\n調理音8\n361\n170\n10\n2\n無\n調理音9\n300\n170\n5\n1\n無\n調理",
            "0\n10\n1\n無\n調理音8\n361\n170\n10\n2\n無\n調理音9\n300\n170\n5\n1\n無\n調理音10\n271\n170\n5\n2\n無\n唐揚げの一般的な調理時間および調理油の温度を調査したところ，平均4 分程度で170◦C\nから180◦C の調理油で調理していることがわかっている（表B.1）．よって，表4.1 のデー\nタも一般的な調理データであると考えられる．\n4.1\n調理音および特徴量の解析手法\n本節では，調理音の解析に利用した振幅スペクトログラムおよび特徴量の解析に利用し\nた手法を述べる．\n4.1.1\nスペクトログラム解析\n本研究では，調理音データの解析に4.2.1 項で後述する，振幅スペクトログラムを用い\nる．図4.1 に示すように，振幅スペクトログラムを可視化することで，視覚的に解析する\nことを可能にする．\nこの振幅スペクトログラムを用いることで，音響的な特徴の時間変化を詳細に確認でき，\n特定のイベントが発生する瞬間を視覚的に捉えることが可能となる．そのため，5.2.4 項\n19\n図4.1: 調理音3 における振幅スペクトログラムの可視化\nでは，振幅スペクトログラムを基に調理音",
            "\n図4.1: 調理音3 における振幅スペクトログラムの可視化\nでは，振幅スペクトログラムを基に調理音の変化点を特定し，ラベリングを実施した．特\nに，クラスの変化が明確に反映される周波数帯域の傾向を分析し，それをラベル付けの指\n標として活用した．\n4.1.2\n主成分分析\n主成分分析（Principal component analysis, PCA）は，多次元データの情報を可能な限\nり損なわずに低次元に圧縮する手法である[35]．PCA はデータの分散が最大となる方向\nを見つけ，その方向を基にデータを新しい座標軸へ変換することで次元を削減する．\n高次元の特徴量空間において，データの分布やクラス間の関係を直感的に理解すること\nは困難である．PCA を用いることで，データの主要な変動方向を抽出し，低次元空間上\nに可視化する．\n本研究では，PCA 利用して3 次元に削減された特徴量の分布を可視化する．これによ\nり，データのクラスタリング傾向や分離性を評価する．\n4.1.3\nt 分布型確率的近傍埋め込み法\nt 分布型確率的近傍埋め込み法（t-distributed stochastic neig",
            "め込み法\nt 分布型確率的近傍埋め込み法（t-distributed stochastic neighbor embedding, t-SNE）\nは，高次元データを低次元空間（通常は2 次元または3 次元）に埋め込むための非線形次\n元削減手法である[36]．特に，データの局所的な構造を保持することに優れており，クラ\nスタリングや特徴量のパターンを視覚的に分析するために用いられる．高次元空間におけ\n20\nるデータ点間の近傍関係を，低次元空間上で可能な限り保持するように変換する．そのた\nめに，データ点間の類似度を確率分布として定義し，それを低次元空間に最適化する．\n本研究ではPCA と同様に，t-SNE を用いて特徴量の分布を可視化し，データのクラス\nタリング傾向や類似性を評価する．\n4.2\n調理音から抽出される音響特徴量\n本節では，各種識別手法で使用する音響特徴量の算出方法を述べる．\n4.2.1\n振幅スペクトログラム\n振幅スペクトログラムは，調理音データに対してSTFT[37] により得られる．フーリエ\n変換は，時間領域の信号を周波数領域に変換し，信号の周波数成分を解析するための基本\n的",
            "れる．フーリエ\n変換は，時間領域の信号を周波数領域に変換し，信号の周波数成分を解析するための基本\n的な手法である[38]．また，任意の周期信号を複数の正弦波または余弦波に分解可能であ\nることを示している．信号x(t) のフーリエ変換は式4.1 で定義される．\nX(f) =\n∫∞\n−∞x(t)e−j2πft dt\n(4.1)\nここで，X(f)は周波数f における信号のフーリエ変換，x(t)は時間領域での信号，e−j2πft\nはフーリエ変換の基底関数，t は時間変数，f は周波数定数である．\nまた，STFT は信号を短い時間区間ごとに区切ってフーリエ変換を適用する．これによ\nり時間的な周波数変化の解析が可能となる．STFT は以下の式4.2 で定義される．\nX(t, f) =\n∫∞\n−∞x(τ)h(τ −t)e−j2πfτdτ\n(4.2)\nここで，X(t, f) は時刻t における周波数f のSTFT 結果，x(τ) は時間領域の入力信号，\nh(τ −t) は窓関数，e−j2πfτ はフーリエ変換の基底関数である．振幅スペクトログラムは式\n4.2 の絶対値を取ることで求められるため，式4.",
            "エ変換の基底関数である．振幅スペクトログラムは式\n4.2 の絶対値を取ることで求められるため，式4.3 となる．\nS(t, f) = |X(t, f)|\n(4.3)\n振幅スペクトログラムを求めることで，特定の時間帯で強く現れる周波数成分を特定可\n能である．図4.2 は調理音3 の音波形とその波形にSTFT を適用した結果である．\n図4.2 のSTFT を適用した結果から，0 Hz から2,500 Hz の周波数帯の成分が大きいこ\nとがわかる．このようにして得られた振幅スペクトログラムの各時間に対して，すべての\n周波数の振幅の平均を計算した値を変化点検出に利用した．\n4.2.2\nMFCC\nMFCC は低周波成分の解像度は高く，高周波成分は低いという人間の聴覚の周波数認識\n特性を反映した特徴量である[39]．音声認識および楽器の識別，調理支援など幅広い分野\nで利用されている．MFCC の計算手順は以下の通りである．まず，式4.4 により窓関数を\n適用した音声フレーム信号x(n) に対し，DFT を適用して周波数領域のスペクトルを取得\nする．\n21\n図4.2: 調理音3 における音波形（上）",
            "T を適用して周波数領域のスペクトルを取得\nする．\n21\n図4.2: 調理音3 における音波形（上）からSTFT により得られた平均振幅スペクトルの\nプロット（下）\nX(f) =\nN−1\n∑\nn=0\nx(n)e−j2πfn/N\n(4.4)\nここで，N はフレームの長さである．式4.4 の二乗を取ることで，各短時間区間のパワー\nスペクトルP(f) を求める（式4.5）．\nP(f) = |X(f)|2\n(4.5)\n次に人間の聴覚特性を考慮するため，メル周波数軸上で等間隔に並んだ三角窓のバンド\nパスフィルタで構成されるメルフィルタバンクを適用する．メル周波数とは，1,000 Hz の\n単一の周波数で構成された音を1,000 mel の音高として，人間の音高知覚を考慮した尺度\n（メル尺度）でスケーリングした周波数である[40]．メル尺度は式4.6 で表され，周波数f\nHz をメル周波数M mel とするM(f) としてスケーリングされる．\nM(f) = 2595 log10\n(\n1 + f\n700\n)\n(4.6)\n式4.6 を適用して，メル周波数にスケーリングされたパワースペクトルP(M) を",
            "0\n)\n(4.6)\n式4.6 を適用して，メル周波数にスケーリングされたパワースペクトルP(M) をメルフィ\n22\nルタバンクと畳み込む．臨界帯域パワースペクトルのサンプルをθ(Mk)(k = 1, . . . , K) と\nして式4.7 で得る．\nθ(Mk) =\n∑\nM\nP(M −Mk)ψ(M)\n(4.7)\nここで，Mk はメルフィルタの中心周波数，ψ(M) は臨界帯域のマスキング曲線である．\n計算された臨界帯域パワースペクトルθ(Mk) に対して，式4.8 による対数変換を適用する．\nX(k) = ln(θ(Mk)),\nk = 1, . . . , K\n(4.8)\n最後に離散コサイン変換（Discrete Cosine Transform，DCT）を適用してMFCC を取\n得する（式4.9）．\nMFCC(d) =\nK\n∑\nk=1\nXk cos\n[\nd(k −0.5) π\nK\n]\n,\nd = 1, . . . , D\n(4.9)\n本研究では唐揚げを揚げる際に生じる調理音の変化を利用しており，その変化は人間の\n耳で十分感じ取れる音の変化である．そのため本研究では機械学習による揚げ終わり",
            "おり，その変化は人間の\n耳で十分感じ取れる音の変化である．そのため本研究では機械学習による揚げ終わり判定\nモデルを構築する際に，MFCC を音響特徴量として検討している．また，MFCC は，20\n次元，DFT の窓サイズ1,024 で取得する．\n4.2.3\nウェーブレット変換\nウェーブレット変換は，信号を異なるスケール（周波数）で分解することで，時間-周\n波数解析を可能にする信号処理手法である[41][42]．ウェーブレット変換は，基底関数で\nあるマザーウェーブレットを異なるスケールと時間シフトを用いて変形しながら，信号を\n解析する．マザーウェーブレットは，スケールパラメータa と時間シフトパラメータb に\nよって次の式4.10 のように定義される．\nψa,b(t) =\n1\n√aψ\n(t −b\na\n)\n(4.10)\nウェーブレット変換には，大きく分けて連続ウェーブレット変換（Continuous Wavelet\nTransform: CWT）と離散ウェーブレット変換（Discrete Wavelet Transform，DWT）の\n2 種類が存在する．本研究では，計算コストが低く，信号",
            "avelet Transform，DWT）の\n2 種類が存在する．本研究では，計算コストが低く，信号の階層的分解が可能なDWT を\n用いる．\nDWTは，信号を異なる周波数帯域に分解し，階層的に特徴を抽出する手法である．DWT\nは式4.11 で得られる．\nW(j, k) =\nN−1\n∑\nn=0\nx(n)ψj,k(n)\n(4.11)\nここで，x(n) は入力信号，N は信号の長さである．DWT の特徴の一つは，多重解像度\n解析によって信号を段階的に分解できることである．各分解レベルで，入力信号s(t) は式\n4.12 のように表される．\n23\ns(t) = An +\nn\n∑\ni=1\nDi\n(4.12)\nここで，An はレベルn の低周波成分（近似係数），Di は各段階の高周波成分（詳細係\n数）である．図4.3 は，多重解像度解析の概念を示している．入力信号s が分解され，レ\nベル1 の近似係数A1 と詳細係数D1 が得られる．レベル1 の近似係数を分解するとレベ\nル2 の近似係数と詳細係数が得られる．このように近似係数の分解を任意のレベルまで繰\nり返すことが可能である．この処理は，入力信号",
            "得られる．このように近似係数の分解を任意のレベルまで繰\nり返すことが可能である．この処理は，入力信号および近似係数に対してローパスフィル\nタおよびハイパスフィルタを適用することと等しい[43]．\n図4.3: DWT による多重解像度解析の概念図\n本研究では，機械学習による揚げ終わり判定モデルの構築の際に，レベル10 までの近\n似係数および詳細係数を取得し，これらの係数から統計的特徴量を算出している．算出す\nる統計的特徴量は表4.2 にまとめた通りである．\nこれらの特徴を利用してウェーブレット変換を検討する．また，本研究ではDaubechies\n基底を使用してウェーブレット変換を実施する[44]．\n4.3\n調理段階の識別手法\n4.3.1\n機械学習分類手法\n唐揚げの調理音から揚げ終わりを検出する手法として機械学習を検討する．本研究では\n教師あり学習を使用し，前節で述べた音響特徴量を検討する．機械学習はPython の機械\n学習ライブラリである「sckit-learn」を用いて実装する[45]．sckit-learn は，データの前処\n理および多種多様な機械学習手法の取り扱いが可能なライブラ",
            "．sckit-learn は，データの前処\n理および多種多様な機械学習手法の取り扱いが可能なライブラリである．なお，XGBoost\nは「xgboost」ライブラリを用いて実装する[46]．本項では，機械学習の際に検討する分\n類器を示す．\n24\n表4.2: ウェーブレット変換から算出する統計的特徴量一覧\n特徴量名\n説明\n近似係数の平均値\n低周波成分の平均的なエネルギーを表す．揚げ物の音\nの全体的なエネルギーの変化を捉える．\n詳細係数の平均値（レベルn）\nレベルn の詳細係数の平均．高周波成分の傾向を示\nし，油のはじける音の変化を測定．\n標準偏差\nレベルn の詳細係数の散らばり具合を示す．音の変\n動の大きさを定量化．\n最大値\nレベルn の詳細係数の最大値．揚げ物のピーク音を\n捉える．\n最小値\nレベルn の詳細係数の最小値．音の静かな瞬間を捉\nえる．\n尖度\nエネルギー分布の鋭さを示す．音の分布が尖っている\nかどうかを評価．\n歪度\n分布の左右対称性を評価し，特定の方向に偏った音の\n傾向を分析．\nシャノンエントロピー\nエネルギーの不確実性を測る指標．音のランダム性や\n複雑さを評価．\n分散\nデータ",
            "シャノンエントロピー\nエネルギーの不確実性を測る指標．音のランダム性や\n複雑さを評価．\n分散\nデータのばらつきを表し，音の変動の大きさを定量化\nする．\n平均絶対値\n各詳細係数の絶対値の平均を計算し，音の振幅の平均\n的な大きさを示す．\nサポートベクターマシン\nSVM は，統計的学習理論に基づく機械学習手法の一つである[47]．異なるクラスのデー\nタを分離する最適な超平面を求めることを目的とし，クラス間のマージンを最大化するこ\nとによって分類する．データが線形分離できない場合には，カーネル関数を利用すること\nで高次元空間へ写像し，線形分離可能な空間で分類する．この手法をカーネルトリックと\n呼ぶ[48]．本研究では，以下に示す4 種類のカーネルを検討する．\n1. Linear カーネル（SV Mlinear）\n特徴空間への変換をせずにそのまま線形分類するカーネル．このカーネルを用いた\n場合，通常の線形分類器と類似した振る舞いをするが，マージン最大化の特性によ\nりロバストな分類が可能となる．\n2. Polynominal カーネル（SV Mpoly）\n非線形の特徴空間を利用するためのカーネル．",
            ". Polynominal カーネル（SV Mpoly）\n非線形の特徴空間を利用するためのカーネル．データを高次元の多項式空間にマッ\nピングすることで，線形分離が困難なデータに対しても，非線形な分離境界を構築\nし，適切な分類を可能にする．\n3. Radial Basis Function カーネル（SV Mrbf）\nデータを無限次元の特徴空間へ非線形変換するカーネル．線形分離が困難なデータ\nにも適用可能であり，局所的な影響を考慮し，データの分布に応じた柔軟な分類が\n可能である．\n25\n4. Sigmoid カーネル（SV Msigmoid）\nニューラルネットワークの活性化関数であるシグモイド関数に基づいたカーネル[49]．\nニューラルネットワークの隠れ層に相当する特徴変換を実施する．\nガウシアンナイーブベイズ\nガウシアンナイーブベイズ（Gauusian Naive Bayes，GNB）は単純な確率論的アルゴ\nリズムであり，ベイズの定理を用いたナイーブベイズアルゴリズムの1 種である[50][51]．\nGNB は，各クラスごとに特徴量が独立したガウス分布に従うと仮定し，事後確立を求め\nる",
            "][51]．\nGNB は，各クラスごとに特徴量が独立したガウス分布に従うと仮定し，事後確立を求め\nることで分類する．この仮定に基づき，学習データから各クラスごとの平均と分散を推定\nし，新しいデータに対するクラスの事後確率を計算する．\nk 近傍法\nk 近傍法（k-Nearest Neighbors，kNN）は，距離に基づく非パラメトリックな分類アル\nゴリズムである[52]．この手法は，未知のデータ点に対して訓練データ内の最も近いk 個\nのデータ点（近傍）を参照し，多数決に基づいて分類する．分類手順は以下の通りである．\n1. 新しいデータ点が与えられたとき，訓練データに含まれるすべてのデータ点との距\n離を計算する．\n2. 距離が近い上位k 個のデータ点を選択する．\n3. 選択したデータ点のクラスを多数決で決定し，最も多く含まれるクラスを新しいデー\nタのクラスとして割り当てる．\nランダムフォレスト\nランダムフォレストは，決定木を基にしたアンサンブル学習の一手法である[53]．この\n手法は複数の決定木を構築し，それらの予測を統合することで，単一の決定木に比べて過\n学習を抑え，頑健な分類を実現す",
            "決定木を構築し，それらの予測を統合することで，単一の決定木に比べて過\n学習を抑え，頑健な分類を実現する．\nXGBoost\nXGB は，勾配ブースティング（Gradient Boosting）を基盤とした機械学習手法であり，\n従来の勾配ブースティング決定木の改良版として開発された[54][55]．複数の決定木を逐\n次的に学習し，予測誤差を最小化することでモデルを最適化するブースティング手法で\nある．各ステップで新しい決定木を作成し，既存のモデルが予測しきれなかった誤差（残\n差）を補正するように学習を進める．\n26\nロジスティック回帰\nロジスティック回帰は，線形分類モデルであり，特に二値分類問題に適している[56]．こ\nの手法は，線形回帰を拡張し，出力を確率として解釈できるようにすることで，分類タス\nクに適用可能としている．ロジスティック回帰では，線形回帰と同様に入力特徴量の線形\n結合を用いて決定境界を定めるが，出力が0 または1 のクラスラベルに適合するよう，シ\nグモイド関数を用いて変換する．シグモイド関数は，入力値を0 から1 の範囲にマッピン\nグする非線形関数であり，出力を確率として",
            "る．シグモイド関数は，入力値を0 から1 の範囲にマッピン\nグする非線形関数であり，出力を確率として解釈することが可能となる．\n4.3.2\nリサンプリングによる不均等データ処理手法\n本研究で扱う調理音データのクラスには大きな偏りがあったため，少数クラスに対して\nはオーバーサンプリング，多数クラスに対してはアンダーサンプリングを適用する．これ\nらのリサンプリングはPython のライブラリである「imbalanced-learn」を用いて実装す\nる[57]．imbalanced-learn は，scikit-learn に依存しており，不均等なクラスを持つ分類を\n扱うためのツールを提供する．本項では，機械学習の際に検討するリサンプリング手法を\n示す．\nオーバーサンプリング手法\n本研究で検討する3 種類のオーバーサンプリング手法を示す．\n1. ADASYN\nADASYN（Adaptive Synthetic Sampling）は，少数クラスに対して適応的に合成デー\nタを生成することにより，データの分布をより均衡に近づける[58]．合成データの生\n成は，少数クラス内の各データ点の近傍における",
            "ータの分布をより均衡に近づける[58]．合成データの生\n成は，少数クラス内の各データ点の近傍におけるデータ密度を考慮し，不均衡度が\n高い領域でより多くのサンプルを生成するように設計されている．\n2. SMOTE\nSMOTE（Synthetic Minority Over-sampling Technique）は，単純なデータのコピー\nではなく，少数クラスのデータ間で線形補間を実行し，新しいサンプルを生成する\n[59]．この手法により，データの分布をより自然に拡張し，学習モデルの汎化性能を\n向上させることが可能となる．本研究では，SMOTE を拡張したBorderline SMOTE\nおよびSVMSMOTE を検討する．\n• Borderline SMOTE\nBorderline SMOTE（BSMOTE）は，クラスの決定境界付近のマイノリティク\nラスのデータ点に重点を置いて合成データを生成することで，分類性能の向上\nを図る[60]．分類器の学習において，クラスの境界付近のデータは分類が特に難\nしく，誤分類のリスクが高いため，これらのデータを強化することで，モデルの\n分類性能を向上が見込",
            "に難\nしく，誤分類のリスクが高いため，これらのデータを強化することで，モデルの\n分類性能を向上が見込まれる．\n• SVMSMOTE\nSVMSMOTE（Support Vector Machine Synthetic Minority Over-sampling Tech-\nnique）は，SMOTE と同様に少数クラスのデータ間で合成サンプルを生成する\n27\nが，その際にSVM を用いて，分類の境界付近にあるデータ点を選択し，重点的\nにサンプリングする[61]．この手法により，モデルが学習する際の決定境界を\nより適切に調整でき，分類性能の向上が期待される．SVMSMOTE はSVM 同\n様，4.3.1 節で述べたカーネルを選択できるため，同様に4 種類のカーネルを検\n討する．\nアンダーサンプリング手法\n本研究で検討する5 種類のアンダーサンプリング手法を示す．\n1. Cluster Centroids\nClusterCentroids（CC）は，多数クラスのデータをクラスタリングし，各クラスタの\n重心を代表点としてサンプリングすることで，データのバランスを調整する手法で\nある[62]．",
            "ラスタの\n重心を代表点としてサンプリングすることで，データのバランスを調整する手法で\nある[62]．この手法は，データの情報をなるべく保持しつつ，多数クラスのデータサ\nイズを削減することを目的としている．\n2. Condensed Nearest Neighbour\nCondensed Nearest Neighbour（CNN）は，分類に必要なデータ点を保持しつつ，冗\n長なデータ点を削除する[63]．少数クラスのデータをそのまま保持し，多数クラスの\nデータからランダムに1 つのデータ点を選択し，初期プロトタイプセットS を作成\nする．残りの多数クラスのデータを，S を用いて1-NN 分類を実施する．もし誤分類\nされた多数クラスのデータ点が存在すれば，それをS に追加する．すべての多数ク\nラスのデータ点が正しく分類されるまで，このプロセスを繰り返すことにより，分\n類の決定境界を形成するために必要なデータ点のみを保持し，不必要なデータ点の\n削除が可能となる．\n3. Near Miss\nNearMiss は，多数クラスのデータ点を削減する際に，少数クラスとの近傍関係を考\n慮することで，適切",
            "arMiss は，多数クラスのデータ点を削減する際に，少数クラスとの近傍関係を考\n慮することで，適切なデータ削減を実現する[64]．NearMisss にはバージョン1 から\n3 の3 種類存在し，それぞれ異なる基準で多数クラスのデータを削減する．\n• NearMiss-1（NM1）\n各多数クラスのデータ点について，少数クラスのデータ点までの距離を計算す\nる．次に，少数クラスのk 個の最近傍データ点との距離の平均を求める．距離\nの平均が最も小さい多数クラスのデータ点を保持し，それ以外のデータを削除\nする．\n• NearMiss-2（NM2）\n各多数クラスのデータ点について，少数クラスのデータ点までの距離を計算す\nる．次に，少数クラスのk 個の最近傍データ点との距離の平均を求める．距離\nの平均が最も大きい多数クラスのデータ点を保持し，それ以外のデータを削除\nする．\n• NearMiss-3（NM3）\n各少数クラスのデータ点に対して，多数クラスのデータ点との距離を計算する．\n28\n最も近いN 個の多数クラスのデータ点のみを保持し，それ以外の多数クラスの\nデータを削除する．\n本研究では，3 ",
            " 個の多数クラスのデータ点のみを保持し，それ以外の多数クラスの\nデータを削除する．\n本研究では，3 種類のバージョンのNearMiss を検討する．\n4. Neighbourhood Cleaning Rule\nNeighbourhood Cleaning Rule（NCR）は，データセット内のノイズや誤分類の可能\n性が高いデータを削除することで，分類モデルの精度を向上させる手法である[65]．\nNCR の手順は，まず，各データに対してkNN を適用し，近傍データ点のクラス分布\nを分析する．特定のデータ点が，近傍の多数派クラスと異なるクラスである場合，そ\nのデータ点は「ノイズ」または「誤分類される可能性が高いデータ」とみなされる．\n次に，近傍の多数クラスのデータ点に囲まれた少数クラスのデータは保持し，近傍の\nデータ点と一致しない多数クラスのデータ点を削除する．最後に，決定境界を維持\nするため，近傍の多数クラスのデータと一致しない少数クラスのデータを削除する．\n5. One-Sided Selection\nOne-Sided Selection（OSS）は，多数クラスの冗長なデータを削減",
            "election\nOne-Sided Selection（OSS）は，多数クラスの冗長なデータを削減しつつ，少数クラ\nスの重要なデータを保持する手法である[66]．これは，CNN とTomek Links という\n2 つのアプローチを組み合わせることで実現されている．Tomek Links は，異なるク\nラスに属する2 つのデータ点が互いに最近傍である場合，それらのデータ点がクラ\nスの境界付近に位置することを示す[67]．OSS では，Tomek Links のペアのうち，多\n数クラスのデータ点を削除する．これにより，決定境界の近くにある多数クラスの\nデータ点を削減する．その後，CNN を適用し，多数クラスのデータセットを縮小す\nる．このプロセスにより，ノイズや冗長なデータを削減しながら，分類の決定境界\nを明確化することが可能となる．\n本研究では，本項で述べたオーバーサンプリング手法およびアンダーサンプリング手法\nを組み合わせて，不均等データ処理を実施する．\n4.3.3\n調理音の変化点検出手法\n変化点検出は，時系列データにおいて統計的な性質が変化する点を特定する技術である．\n本研究では",
            "出手法\n変化点検出は，時系列データにおいて統計的な性質が変化する点を特定する技術である．\n本研究では，唐揚げの揚げ終わりの音を変化点として捉え，調理過程における音響特徴の\n変化を解析することで，適切な揚げ時間の検出が可能であるかを検討する．変化点検出は\nPython のライブラリである「ruptures」を用いて実装する[68]．ruptures は，非定常信号\nの分析とセグメンテーションのためのメソッドが取り扱い可能なライブラリである．\n本研究では，変化点検出手法の一つであるWindow アルゴリズムを利用する[69]．この\n手法は，データの局所的な変化を捉えやすく，リアルタイムの変化点検出に適している．\nWindow アルゴリズムは，データストリームに沿ってスライドする2 つのウィンドウを用\nいて，それぞれのウィンドウ内の信号の統計的特性を比較し，差異を計測することで変化\n点を検出する．与えられたコスト関数c に対して，区間a, b における信号y の差異を測る\n指標d は式4.13 で定義される．\nd(ya.t, yt.b) = c(ya.b) −c(ya.t) −c(yt.b)",
            " で定義される．\nd(ya.t, yt.b) = c(ya.b) −c(ya.t) −c(yt.b),\n(a < t < b)\n(4.13)\n29\n本研究では，マハラノビス距離をコスト関数として利用する．マハラノビス距離は，デー\nタの共分散構造を考慮した距離計量を計算する．マハラノビス型の距離を使用したコスト\n関数cM は式4.14 のように定義される．\ncM(ya.b) =\nb\n∑\nt=a+1\n∥yt −¯ya.b∥M 2\n(4.14)\nここで，¯ya.b は部分信号ya.b の平均値である．マハラノビス距離は，通常のユークリッ\nド距離よりも特徴を適切に捉えることが可能である．\n変化点検出では，コスト関数を最小化することで変化点を決定する．その際，式4.15 で\n与えられるペナルティ項を加えた目的関数を最小化する．\nTotalCost =\nk\n∑\ni=0\ncM(yti,ti+1) + λ · k\n(4.15)\nここで，cM(yti,ti+1) は各セグメントti, ti+1 間におけるコスト関数，k は検出された変化\n点の数，λ はペナルティの重みである．ペナルティが大きいほど，変化",
            "コスト関数，k は検出された変化\n点の数，λ はペナルティの重みである．ペナルティが大きいほど，変化点の数が減少し，\n小さいほど変化点が増加する．よって，適切なペナルティを設定する必要がある．\n本研究では，前述した機械学習手法に加え，本変化点検出手法の精度を比較し，最も精\n度の良い手法をアプリケーションに実装する．\n4.3.4\n調理音に含まれる雑音の処理\n調理音には，お皿がぶつかる音やタイマーの音など突発的な雑音が含まれており，目\n立っている．そこで本研究では，メディアンフィルタを使用する[70]．メディアンフィル\nタは，突発的な大きなノイズの除去に有効である．メディアンフィルタの例を図4.4 に示\nす．データの集合を降順に並べ，中心の位置の値（中央値）を出力する．これにより，突\n発的な値を除去しつつ，トレンドの変化を合理的に維持することができる．\n図4.4: メディアンフィルタの仕組み\nメディアンフィルタは，変化点検出を実施する際に，振幅の平均に対して適用する．\n30\n4.4\n各識別手法の評価方法および評価指標\n本節では，本研究で使用する評価方法および評価指標の4 種類について述べる",
            "法の評価方法および評価指標\n本節では，本研究で使用する評価方法および評価指標の4 種類について述べる．\n4.4.1\n一グループ抜き交差検証による評価方法\nまず評価方法について，本研究では唐揚げのフライ調理音10 種類に対して，一グルー\nプ抜き交差検証（Leave-One-Group-Out Cross-Validation, LOGO-CV）を実施する[71]．\nLOGO-CV は，データを予め定義したグループ単位で分割し，各グループを順番にテス\nトデータとして取り除く手法である．本研究におけるLOGO-CV を図4.5 に示す．本研究\nの場合は，データは調理音ごとに分けられているため，各調理音を一つのグループと見な\nし，グループごとに交差検証を実施する．\n図4.5: 本研究における一グループ抜き交差検証\n4.4.2\n評価指標\n性能評価には，適合率，再現率，F1 スコア，および正解率を使用する．機械学習モデル\nの性能評価においては，揚げ途中と揚げ終わりの2 クラス分類におけるモデルの予測結果\nを，実際のクラスと比較したものを混同行列として表す．混同行列の構造を表4.3 に示す．\n表4.",
            "結果\nを，実際のクラスと比較したものを混同行列として表す．混同行列の構造を表4.3 に示す．\n表4.3: 混同行列の構造\n実際のクラス0（Negative）\n実際のクラス1（Positive）\n予測クラス0（Negative）\nTN（True Negative）\nFN（False Negative）\n予測クラス1（Positive）\nFP（False Positive）\nTP（True Positive）\n本研究においては，クラス0 が揚げ途中，クラス1 が揚げ終わりを意味する．各要素の\n意味は以下の通りである．\n31\nTN（True Negative，真陰性）\n実際のクラスが揚げ途中（Negative）であり，モデルが正しく揚げ途中と予測した数．\nTP（True Positive，真陽性）\n実際のクラスが揚げ終わり（Positive）であり，モデルが正しく揚げ終わりと予測し\nた数．\nFP（False Positive，偽陽性）\n実際のクラスが揚げ途中（Negative）であるにもかかわらず，モデルが誤って揚げ終\nわりと予測した数．\nFN（False Negative，偽陰性）\n実際の",
            "らず，モデルが誤って揚げ終\nわりと予測した数．\nFN（False Negative，偽陰性）\n実際のクラスが揚げ終わり（Positive）であるにもかかわらず，モデルが誤って揚げ\n途中と予測した数．\n次に，各評価指標について述べる．適合率は，モデルが揚げ終わり（Positive）と予測\nしたデータのうち，実際に揚げ終わりであったデータの割合を示す．数式は以下の通りで\nある：\nPrecision =\nTP\nTP + FP\n(4.16)\n適合率が高いほど，揚げ終わりと予測したデータの中に誤って揚げ途中が分類される割\n合が少ないことを意味する．本研究では，安全な揚げ終わり判定に重点を置いているた\nめ，適合率を重視する．\n再現率は，実際に揚げ終わり（Positive）であるデータのうち，モデルが正しく揚げ終\nわりと予測した割合を示す．数式は以下の通りである：\nRecall =\nTP\nTP + FN\n(4.17)\n再現率が高いほど，実際に揚げ終わりであるデータを取りこぼさずに予測できているこ\nとを意味する．\nF1 スコアは，適合率と再現率の調和平均であり，バランスの取れた評価指標である．数\n式は",
            "意味する．\nF1 スコアは，適合率と再現率の調和平均であり，バランスの取れた評価指標である．数\n式は以下の通りである：\nF1 = 2 × Precision × Recall\nPrecision + Recall\n(4.18)\nF1 スコアは，適合率と再現率のバランスが重要な場合に用いられる．\n正解率は，全予測のうち正しく分類された割合を示す．数式は以下の通りである：\nAccuracy =\nTP + TN\nTP + TN + FP + FN\n(4.19)\n正解率は全体的なモデルの性能を示すが，クラスの分布が不均衡な場合には注意が必要\nである．\n32\n第5章\n調理音識別手法およびFCGsの開発\n本章では第4 章で述べた解析手法を利用した唐揚げの揚げ終わり分類および検出の精度\n評価について述べる．また，最も精度の良い手法を利用して，リアルタイムで揚げ終わり\nを識別するスマートフォンアプリケーションを開発する．\n5.1\n調理音データのラベリング\n調理音データのラベリングは，音声解析ソフトELANを使用した[72]．本研究では，3.1.1\n項で述べた通り，ラベルの種類を「揚げ途中」と「揚げ終わ",
            "Nを使用した[72]．本研究では，3.1.1\n項で述べた通り，ラベルの種類を「揚げ途中」と「揚げ終わり」の2 クラスとした．ラベ\nルの基準は実際の音，衣の色の変化，油の気泡の変化，ELAN による波形解析を利用して\n決定した．\n各調理音に対するクラスごとのデータ時間は5.1 のようになっている．\n表5.1: ラベル付けしたデータのラベル時間\n調理時間[s]\n揚げ途中[s]\n揚げ終わり[s]\n調理音1\n269\n243\n26\n調理音2\n280\n240\n40\n調理音3\n258\n224\n34\n調理音4\n279\n253\n26\n調理音5\n247\n236\n11\n調理音6\n300\n290\n10\n調理音7\n313\n302\n10\n調理音8\n361\n340\n21\n調理音9\n300\n285\n15\n調理音10\n271\n259\n12\n揚げ途中から揚げ終わりへの変化の様子は図5.1 のようになっている．揚げ終わりに近\nづくにつれて衣の色がきつね色になり，気泡も細かくなっていることがわかる．\n5.2\n機械学習モデルによる唐揚げの調理音データ分類精度の評価\n本節では，第4 章で述べた手法を利用して，唐揚げの調理音から揚",
            "る唐揚げの調理音データ分類精度の評価\n本節では，第4 章で述べた手法を利用して，唐揚げの調理音から揚げ途中および揚げ終\nわりの分類が可能な機械学習モデルを検討する．表5.1 の通り，揚げ途中と揚げ終わりク\nラスのデータバランスは不均等である．よって，オーバーサンプリングおよびアンダー\nサンプリングの両手法を適用し，データセットを均等にする．また，分類モデルは1 調\n理音抜き交差検証を実施し，F1 スコア，適合率，再現率，正解率の4 種類の指標で評価\nする．使用する調理音は10 種類であるため，各指標において，10 回分の平均値および標\n33\n図5.1: 揚げ途中から揚げ終わりへの変化の様子\n準偏差を算出して，分類精度として評価する．分類は9 種類の分類器を使用して実施し，\nアンダーサンプリング手法7 種，オーバーサンプリング手法6 種，分類器9 種の378 通り\nをMFCC，ウェーブレット変換から得られる特徴をそれぞれ音響特徴量として利用し検\n証する．\n機械学習の際，窓幅は1 秒，シフト幅は0.25 秒としており，各調理音のサンプリング周\n波数は44.1 kHz である．真値ラベルは，",
            "幅は0.25 秒としており，各調理音のサンプリング周\n波数は44.1 kHz である．真値ラベルは，フレームの半分以上が揚げ終わりのラベル時間\nを含む場合は「揚げ終わり」，そうでない場合は「揚げ途中」とラベル付けされた．\n5.2.1\nMFCC 特徴量を使用した分類精度の評価\n本項では，調理音からMFCC を特徴量として抽出した場合の分類精度を評価する．ま\nず，両クラスの割合を5:5 にした場合における，最も高い精度を含むNCR との組み合わせ\nの分類精度を以下に示す．リサンプリングの順序は，アンダーサンプリングを適用した後，\nオーバーサンプリングを適用している．表5.2 はオーバーサンプリングにBSMOTE を適用\nした各分類器による分類精度である．リサンプリング適用前のクラスのサンプル数の比は\nMiddle: Finish = 10, 608: 870 であり，適用後の比は，Middle: Finish = 10, 449: 10, 449\nとなった．\n表5.2: NCR+BSMOTE を適用したMFCC 特徴量の分類精度\n分類器\nF1 スコア\n適合率\n再現率\n正解率\nロジスティック",
            " を適用したMFCC 特徴量の分類精度\n分類器\nF1 スコア\n適合率\n再現率\n正解率\nロジスティック回帰\n0.521 ± 0.345\n0.551 ± 0.312\n0.591 ± 0.424\n0.622 ± 0.150\nランダムフォレスト\n0.105 ± 0.196\n0.847 ± 0.312\n0.071 ± 0.141\n0.527 ± 0.062\nGNB\n0.488 ± 0.424\n0.606 ± 0.356\n0.597 ± 0.512\n0.646 ± 0.179\nkNN\n0.207 ± 0.308\n0.456 ± 0.435\n0.207 ± 0.353\n0.523 ± 0.123\nSV Mlinear\n0.510 ± 0.351\n0.524 ± 0.319\n0.584 ± 0.433\n0.614 ± 0.157\nSV Mpoly\n0.520 ± 0.379\n0.690 ± 0.293\n0.619 ± 0.476\n0.634 ± 0.172\nSV Mrbf\n0.539 ± 0.355\n0.625 ± 0.268\n0.646 ± 0.461\n0.640 ± 0.151\nSV Msigmo",
            ".625 ± 0.268\n0.646 ± 0.461\n0.640 ± 0.151\nSV Msigmoid\n0.468 ± 0.410\n0.619 ± 0.373\n0.563 ± 0.497\n0.587 ± 0.224\nXGB\n0.178 ± 0.267\n0.568 ± 0.431\n0.151 ± 0.242\n0.539 ± 0.065\nF1 スコアと適合率がともに6 割を超えているモデルは見受けられなかった．また，5 割\nを超えているモデルにおいても，標準偏差に注目すると安定性が低いことわかる．表5.3\n34\nはオーバーサンプリングにSV MSMOTElinear を適用した各分類器による分類精度であ\nる．リサンプリング後のサンプル比はMiddle: Finish = 10, 449: 8, 898 となった．\n表5.3: NCR+SV MSMOTElinear を適用したMFCC 特徴量の分類精度\n分類器\nF1 スコア\n適合率\n再現率\n正解率\nロジスティック回帰\n0.506 ± 0.294\n0.596 ± 0.264\n0.588 ± 0.419\n0.636 ± 0.129\nランダムフ",
            "94\n0.596 ± 0.264\n0.588 ± 0.419\n0.636 ± 0.129\nランダムフォレスト\n0.059 ± 0.122\n0.701 ± 0.382\n0.037 ± 0.081\n0.557 ± 0.074\nGNB\n0.394 ± 0.411\n0.623 ± 0.358\n0.506 ± 0.520\n0.614 ± 0.181\nkNN\n0.157 ± 0.253\n0.411 ± 0.398\n0.158 ± 0.314\n0.536 ± 0.098\nSVMlinear\n0.549 ± 0.265\n0.591 ± 0.250\n0.643 ± 0.386\n0.645 ± 0.107\nSVMpoly\n0.576 ± 0.324\n0.729 ± 0.193\n0.701 ± 0.417\n0.678 ± 0.130\nSVMrbf\n0.546 ± 0.352\n0.617 ± 0.270\n0.699 ± 0.463\n0.668 ± 0.138\nSVMsigmoid\n0.383 ± 0.381\n0.541 ± 0.371\n0.515 ± 0.512\n0.542 ± 0.225\nXGB\n0.071",
            ".541 ± 0.371\n0.515 ± 0.512\n0.542 ± 0.225\nXGB\n0.071 ± 0.110\n0.446 ± 0.421\n0.058 ± 0.106\n0.527 ± 0.081\nBSMOTE と同様に，F1 スコアと適合率がともに6 割を超えているモデルはなかった．\nしかし，SV Mpoly はF1 スコアが57.6% ± 32.4%ではあるが，適合率が7 割を超えて安定\nしていることがわかる．表5.4 はオーバーサンプリングにSV MSMOTEpoly を適用した\n各分類器による分類精度である．クラスのサンプル数はMiddle: Finish = 10, 449: 10, 449\nである．\n表5.4: NCR+SV MSMOTEpoly を適用したMFCC 特徴量の分類精度\n分類器\nF1 スコア\n適合率\n再現率\n正解率\nロジスティック回帰\n0.574 ± 0.304\n0.614 ± 0.259\n0.639 ± 0.396\n0.649 ± 0.135\nランダムフォレスト\n0.138 ± 0.227\n0.729 ± 0.401\n0.100 ± 0.166\n0.53",
            "レスト\n0.138 ± 0.227\n0.729 ± 0.401\n0.100 ± 0.166\n0.531 ± 0.064\nGNB\n0.486 ± 0.405\n0.649 ± 0.302\n0.591 ± 0.498\n0.634 ± 0.170\nkNN\n0.218 ± 0.317\n0.460 ± 0.435\n0.226 ± 0.370\n0.516 ± 0.136\nSV Mlinear\n0.559 ± 0.311\n0.588 ± 0.264\n0.626 ± 0.398\n0.634 ± 0.142\nSV Mpoly\n0.535 ± 0.363\n0.705 ± 0.261\n0.629 ± 0.459\n0.637 ± 0.166\nSV Mrbf\n0.574 ± 0.341\n0.645 ± 0.270\n0.691 ± 0.441\n0.656 ± 0.136\nSV Msigmoid\n0.455 ± 0.401\n0.614 ± 0.369\n0.549 ± 0.497\n0.576 ± 0.219\nXGB\n0.252 ± 0.297\n0.462 ± 0.414\n0.217 ± 0.277\n0.560 ± 0.",
            "252 ± 0.297\n0.462 ± 0.414\n0.217 ± 0.277\n0.560 ± 0.086\nNCR+SV MSMOTEpoly を適用すると，NCR+SV MSMOTElinear 同様，SV Mpoly 分\n類器のF1 スコアが5 割以上かつ適合率7 割以上のモデルであることがわかる．表5.5 は\nオーバーサンプリングにSV MSMOTErbf を適用した各分類器による分類精度である．ク\nラスのサンプル数はMiddle: Finish = 10, 449: 10, 449 である．\n結果，rbfカーネルを使用したSVMSMOTEは，polyカーネルを使用しているSVMSMOTE\nと同様の精度が得られたことがわかる．表5.6はオーバーサンプリングにSVMSMOTEsigmoid\nを適用した各分類器による分類精度である．クラスのサンプル数はMiddle: Finish =\n10, 449: 10, 449 である．\n表5.6 の通り，sigmoid カーネルを使用したSVMSMOTE も，他のカーネルを使用した\nSVMSMOTE と同様の結果となった．表5.7 はオーバー",
            "SMOTE も，他のカーネルを使用した\nSVMSMOTE と同様の結果となった．表5.7 はオーバーサンプリングにADASYN を適用し\n35\n表5.5: NCR+SV MSMOTErbf を適用したMFCC 特徴量の分類精度\n分類器\nF1 スコア\n適合率\n再現率\n正解率\nロジスティック回帰\n0.570 ± 0.298\n0.613 ± 0.260\n0.632 ± 0.391\n0.644 ± 0.130\nランダムフォレスト\n0.146 ± 0.246\n0.725 ± 0.401\n0.112 ± 0.196\n0.536 ± 0.072\nGNB\n0.487 ± 0.403\n0.653 ± 0.298\n0.591 ± 0.497\n0.633 ± 0.171\nkNN\n0.219 ± 0.320\n0.457 ± 0.433\n0.228 ± 0.375\n0.516 ± 0.140\nSV Mlinear\n0.558 ± 0.309\n0.586 ± 0.265\n0.627 ± 0.396\n0.631 ± 0.141\nSV Mpoly\n0.528 ± 0.363\n0.702 ± 0.264\n0.621 ±",
            "0.141\nSV Mpoly\n0.528 ± 0.363\n0.702 ± 0.264\n0.621 ± 0.460\n0.633 ± 0.164\nSV Mrbf\n0.568 ± 0.343\n0.642 ± 0.268\n0.684 ± 0.442\n0.652 ± 0.134\nSV Msigmoid\n0.456 ± 0.400\n0.614 ± 0.370\n0.549 ± 0.496\n0.576 ± 0.219\nXGB\n0.217 ± 0.267\n0.457 ± 0.382\n0.177 ± 0.234\n0.544 ± 0.081\n表5.6: NCR+SV MSMOTEsigmoid を適用したMFCC 特徴量の分類精度\n分類器\nF1 スコア\n適合率\n再現率\n正解率\nロジスティック回帰\n0.561 ± 0.299\n0.609 ± 0.261\n0.622 ± 0.390\n0.638 ± 0.128\nランダムフォレスト\n0.144 ± 0.240\n0.681 ± 0.390\n0.110 ± 0.195\n0.532 ± 0.071\nGNB\n0.491 ± 0.399\n0.665 ± 0.293\n0.59",
            "0.532 ± 0.071\nGNB\n0.491 ± 0.399\n0.665 ± 0.293\n0.593 ± 0.495\n0.634 ± 0.171\nkNN\n0.219 ± 0.321\n0.457 ± 0.433\n0.228 ± 0.375\n0.516 ± 0.140\nSV Mlinear\n0.550 ± 0.309\n0.583 ± 0.266\n0.616 ± 0.396\n0.626 ± 0.140\nSV Mpoly\n0.527 ± 0.364\n0.701 ± 0.266\n0.620 ± 0.461\n0.632 ± 0.165\nSV Mrbf\n0.568 ± 0.343\n0.642 ± 0.268\n0.685 ± 0.442\n0.653 ± 0.135\nSV Msigmoid\n0.456 ± 0.400\n0.614 ± 0.370\n0.549 ± 0.496\n0.577 ± 0.219\nXGB\n0.217 ± 0.287\n0.486 ± 0.440\n0.186 ± 0.256\n0.546 ± 0.075\nた各分類器による分類精度である．クラスのサンプル数はMiddle: Finish =",
            "± 0.075\nた各分類器による分類精度である．クラスのサンプル数はMiddle: Finish = 10, 449: 10, 428\nである．\n結果として，NCR に対しては，どのオーバーサンプリング手法を組み合わせても，同\nじような結果が得られた．その中でも僅差でNCR+SV MSMOTElinear の組み合わせに\nおける，SV Mpoly 分類器を使用した際の分類精度が，最も良い結果となった．しかし，全\n体としてF1 スコアと適合率が8 割以上の分類精度となるモデルは構築できなかった．\n原因として，以下の3 点が考えられる．\n1 つは，オーバーサンプリング，特にSMOTE やADASYN は，少数クラスのデータを\n合成するが，既存のデータポイントを補完しているだけであり，新しい情報を追加するわ\nけではない．そのため，訓練データに過度に適合し，汎化性能が低下した可能性がある．\n2 つ目として，NCR+SV MSMOTElinear の組み合わせにおいて，元のデータセットの\nクラス比である10, 608: 870 から10, 449: 8, 898 にリサンプリングしたように，本来",
            "である10, 608: 870 から10, 449: 8, 898 にリサンプリングしたように，本来のデー\nタ分布と大きく異なるデータで学習した．これにより，クラスの決定境界が不安定になっ\nた可能性が考えられる．\n3 つ目として，F1 スコアのばらつきが大きいことからも，特徴量が十分にクラスを分離\nできていない可能性が考えられる．\nよって，PCA およびt-SNE による特徴の可視化を実施し，クラス間の分離が適切であ\n36\n表5.7: NCR+ADASYN を適用したMFCC 特徴量の分類精度\n分類器\nF1 スコア\n適合率\n再現率\n正解率\nロジスティック回帰\n0.553 ± 0.320\n0.609 ± 0.270\n0.618 ± 0.418\n0.645 ± 0.139\nランダムフォレスト\n0.119 ± 0.217\n0.839 ± 0.311\n0.085 ± 0.165\n0.533 ± 0.066\nGNB\n0.475 ± 0.415\n0.614 ± 0.367\n0.572 ± 0.498\n0.634 ± 0.174\nkNN\n0.193 ± 0.309\n0.418 ± 0.405\n0.2",
            "\n0.634 ± 0.174\nkNN\n0.193 ± 0.309\n0.418 ± 0.405\n0.203 ± 0.363\n0.509 ± 0.131\nSV Mlinear\n0.532 ± 0.303\n0.572 ± 0.271\n0.594 ± 0.402\n0.615 ± 0.136\nSV Mpoly\n0.531 ± 0.377\n0.691 ± 0.295\n0.632 ± 0.469\n0.639 ± 0.169\nSV Mrbf\n0.570 ± 0.341\n0.643 ± 0.269\n0.684 ± 0.441\n0.655 ± 0.137\nSV Msigmoid\n0.446 ± 0.399\n0.611 ± 0.368\n0.538 ± 0.500\n0.573 ± 0.216\nXGB\n0.083 ± 0.129\n0.604 ± 0.434\n0.053 ± 0.082\n0.493 ± 0.059\nるかを確認する．\n5.2.2\nPCA およびt-SNE によるMFCC 特徴量解析\n前項で最も分類精度の良い分類器を含んでいた，NCR+SV MSMOTElinear のリサンプ\nリング手法前後を解析し",
            "の良い分類器を含んでいた，NCR+SV MSMOTElinear のリサンプ\nリング手法前後を解析し，リサンプリングの影響およびMFCC のクラス分離能力を確認\nする．\n図5.2 はPCA の結果である．左図がリサンプリング適用前で，右図はリサンプリング\n適用後である．青色が揚げ途中で，赤色は揚げ終わりを示している．\nリンサプリング前は，揚げ途中が圧倒的に多く，揚げ途中は少数点在していることがわ\nかる．また，揚げ途中は3 つほどの異なるクラスタに分かれており，データ構造に一定の\nパターンがあるように見える．揚げ終わりは，揚げ途中のデータの間に少しずつ散らばっ\nており，明確なクラスタを形成していないことがわかる．このことから，揚げ終わりは明\n確な特徴を持たない，もしくは揚げ途中の中に埋もれており，単純な決定境界による分類\nが困難であると考えられる．また，揚げ途中がいくつかのクラスタを形成していることか\nら，揚げ途中内部に異なるサブクラスがあると推測される．\nこれに対して，リサンプリング後は，揚げ終わりのデータは増加したが，データの分布\nは大きく変化しておらず，揚げ途中のデータ構造もリサン",
            "，揚げ終わりのデータは増加したが，データの分布\nは大きく変化しておらず，揚げ途中のデータ構造もリサンプリング前と大きな変化が見ら\nれないことがわかる．このことから，揚げ途中と揚げ終わりの分離が改善されておらず，\n揚げ終わりのデータ数が単に増加しただけとなっている可能性が考えられる．\n次に，t-SNE による解析結果を図5.3 に示す．左図がリサンプリング適用前で，右図は\nリサンプリング適用後である．\nリサンプリング前は，揚げ途中が圧倒的に多く，揚げ終わりはデータの端や一部にまと\nまって分布していることがわかる．また，揚げ終わりは明確なクラスタを形成せず，揚げ\n途中のデータの間に散らばっている．\nこれに対して，リサンプリング後は揚げ終わりのデータが大幅に増加し，データの形は\n曲線状になっており，不自然な分布が見られる．\n原因として，揚げ終わりのサンプルを人工的に増やしたことにより，歪んだデータ構造\nになった可能性が高い．この曲線状になった分布が，モデルの学習に悪影響を及ぼしてい\n37\n図5.2: PCA によるMFCC 解析結果（NCR+SV MSMOTElinear 適用前後）\nる可能",
            ".2: PCA によるMFCC 解析結果（NCR+SV MSMOTElinear 適用前後）\nる可能性が考えられる．特に，オーバーサンプリングにより，データバランスを5:5 にし\nたため，決定境界付近でデータが過剰合成されていると考えられる．\n図5.3: t-SNE によるMFCC 解析結果（NCR+SV MSMOTElinear 適用前後）\n以上の結果より，クラスのデータバランスを調整する必要があると考える．そのため，\nリサンプリングのバランスを5:5 ではなく，6:4 のように調整して，再度モデルの性能を評\n価する．また，揚げ途中クラスの細分化を実施し，データバランスの不均等を緩和する．\n5.2.3\nリサンプリングバランスの調整による分類モデルの再評価\n本項では，データバランスを6:4 となるようにリサンプリングを適用し，機械学習モデ\nルを検証する．ここで，アンダーサンプリング手法の内，リサンプリングの割合を指定で\n38\nきないアルゴリズムであるCNN，NCR，OSS は検討対象外とした．\n5.2.4\n振幅スペクトログラムに基づく再ラベリング\n揚げ途中クラスを細分化し，データセット",
            "した．\n5.2.4\n振幅スペクトログラムに基づく再ラベリング\n揚げ途中クラスを細分化し，データセットの不均等を緩和するために，再度ラベリング\nを実施する．ラベリングは主に，振幅の強度に基づいて実施し，振幅の強度は調理音の振\n幅スペクトログラムを可視化することで視覚的に捉える．ラベリング後は，実際の調理音，\n調理時に撮影されていた動画を確認して，各ラベルの整合性が取れているか確認する．\nラベリングの結果，各調理音は4 クラスに分けられた．図5.4 は，調理音3 におけるラ\nベリング結果である．白線はクラスが切り替わる瞬間を示している．\n図5.4: 調理音3 における振幅スペクトログラムに基づくラベリング結果\nこのようにして，各調理音の振幅スペクトログラムを解析し，再度ラベリングした結果\nを表5.8 に示す．\n結果，2 クラスでラベリングしていた時よりも，揚げ途中が細分化されたため，データ\nセットの不均等な状態が緩和された．本研究では揚げ終わりの識別に重点を置いているた\nめ，ラベル3 と揚げ終わりであるラベル4（揚げ終わり）の二値分類による性能評価を実\n施する．\n5.2.5\n4 クラスにお",
            "終わりであるラベル4（揚げ終わり）の二値分類による性能評価を実\n施する．\n5.2.5\n4 クラスにおけるMFCC 特徴量による分類精度の評価\n前項でのラベリング結果を基に，MFCC 特徴量を利用して，分類精度の評価を実施す\nる．MFCC を抽出した際のデータバランスは，クラス1: クラス2: クラス3: 揚げ終わり=\n39\n表5.8: 振幅スペクトログラムに基づくラベリング結果一覧\nラベル1 [s]\nラベル2 [s]\nラベル3 [s]\nラベル4（Finish）[s]\n調理音1\n0 - 45\n45 - 123\n123 - 214\n214 - 269\n調理音2\n0 - 50\n50 - 129\n129 - 238\n238 - 280\n調理音3\n0 - 32\n32 - 129\n129 - 218\n218 - 258\n調理音4\n0 - 43\n43 - 147\n147 - 225\n225 - 278\n調理音5\n0 - 60\n60 - 120\n120 - 176\n176 - 246\n調理音6\n0 - 75\n75 - 174\n174 - 208\n208 - 300\n調理音7\n0 - 34\n34 - 1",
            "75\n75 - 174\n174 - 208\n208 - 300\n調理音7\n0 - 34\n34 - 136\n136 - 195\n195 - 313\n調理音8\n0 - 28\n28 - 100\n100 - 215\n215 - 361\n調理音9\n0 - 43\n43 - 106\n106 - 157\n157 - 300\n調理音10\n0 - 63\n63 - 98\n98 - 185\n185 - 270\n1, 812: 3, 156: 3, 076: 3, 434 となった．このうち，クラス3 および揚げ終わりクラスの2 ク\nラスによる分類を実施する．\nまず，図5.5 に再度ラベリングされた結果を基にしたPCA 結果を示す．左図は4 クラス\nすべてのPCA 結果をプロットしており，右図は分類対象とするクラス3 および揚げ終わ\nりをプロットした結果である．\n4 クラスの結果より，クラス1 およびクラス2 は明確なクラスタを形成している部分が\nあるが，クラス3 および揚げ終わりとの境界は曖昧である．右図より，クラス3 と揚げ終\nわりは重なる領域が多いことがわかる．また，クラスタ間に明確な境界がない．\n図5.",
            "クラス3 と揚げ終\nわりは重なる領域が多いことがわかる．また，クラスタ間に明確な境界がない．\n図5.5: 4 クラスラベルにおけるMFCC のPCA 結果（左図:4 クラス，右図:2 クラス）\n次に，t-SNE による分析を図5.6 に示す．左図より，クラス1 およびクラス2 は比較的\n分離している．また右図より，クラス3 および揚げ終わりは，大部分が重なっており，完\n全に分離されていない．いくつかのクラスタは形成されているが，明確な境界が見られな\nいことがわかる．\n40\n図5.6: 4 クラスラベルにおけるMFCC のt-SNE 結果（左図:4 クラス，右図:2 クラス）\nPCA およびt-SNE の解析結果より，クラス3 および揚げ終わりは，特徴空間において\n極めて似た振る舞いをしている可能性がある．また，現在の特徴セットのみでは，揚げ途\n中と揚げ終わりを十分に区別できないと考えられる．\n表5.9 に，クラス3 および揚げ終わりによる二値分類の結果を示す．リサンプリングを適\n用した際の最も良い分類精度は，F1 スコアが57.6% ± 32.4%，適合率が72.9% ± 19.3%\n",
            "の最も良い分類精度は，F1 スコアが57.6% ± 32.4%，適合率が72.9% ± 19.3%\nであった．この精度と比較すると，全体的に適合率は向上しているが，F1 スコアはどの\n分類器も上回っていない．\n表5.9: MFCC を利用した分類器ごとのクラス3 および揚げ終わりの分類精度\n分類器\nF1 スコア\n適合率\n再現率\n正解率\nロジスティック回帰\n0.496 ± 0.316\n0.649 ± 0.282\n0.620 ± 0.440\n0.587 ± 0.117\nランダムフォレスト\n0.509 ± 0.318\n0.740 ± 0.238\n0.598 ± 0.409\n0.600 ± 0.146\nGNB\n0.471 ± 0.413\n0.799 ± 0.203\n0.588 ± 0.507\n0.662 ± 0.116\nkNN\n0.409 ± 0.294\n0.668 ± 0.250\n0.455 ± 0.388\n0.520 ± 0.194\nSV Mlinear\n0.494 ± 0.308\n0.648 ± 0.282\n0.617 ± 0.437\n0.584 ± 0.110\nSV Mpoly\n0.4",
            "8 ± 0.282\n0.617 ± 0.437\n0.584 ± 0.110\nSV Mpoly\n0.456 ± 0.390\n0.790 ± 0.217\n0.549 ± 0.481\n0.609 ± 0.181\nSV Mrbf\n0.489 ± 0.371\n0.796 ± 0.221\n0.581 ± 0.469\n0.620 ± 0.161\nSV Msigmoid\n0.463 ± 0.378\n0.784 ± 0.283\n0.562 ± 0.456\n0.563 ± 0.261\nXGB\n0.426 ± 0.279\n0.638 ± 0.285\n0.455 ± 0.372\n0.540 ± 0.146\n以上の結果より，クラス3 および揚げ終わりは，特徴空間において極めて似た振る舞い\nをしている可能性が高く，現在の特徴セットのみでは，揚げ終わりを十分に分類すること\nができないことがわかった．\n41\n5.2.6\nウェーブレット変換による特徴量抽出を利用した分類精度の評価\n次に，ウェーブレット変換を利用した音響特徴量の抽出を検討する．図5.7 はPCA 結\n果であり，左図は4 クラス，右図はクラス3 および揚げ",
            "徴量の抽出を検討する．図5.7 はPCA 結\n果であり，左図は4 クラス，右図はクラス3 および揚げ終わりをプロットしている．左図\nより，各クラスは全体的に密集しており，分離していないことがわかる．また，右図より\n揚げ終わりはクラス3 よりも広域に分布しており，一部の揚げ終わりデータは外側に散ら\nばっていることがわかる．このことから，揚げ終わりとクラス3 は異なる特徴を持つ可能\n性がある．しかし，両クラスともに混在している領域があるため，完全な分離は困難であ\nると推測される．\n図5.7: 4 クラスラベルにおけるウェーブレット変換から得られる特徴量のPCA 結果\n（左図:4 クラス，右図:2 クラス）\n図5.8 はt-SNE による解析結果である．左図の4 クラス描画結果から，PCA よりもクラ\nス間のまとまりが明確になっていることがわかる．また，右図のクラス3 および揚げ終わ\nりのプロットより，t-SNE の結果でも両クラスは混在しており，明確な境界がないことが\nわかる．\n以上の解析結果より，クラス3 と揚げ終わりの間には明確な境界が存在しない可能性が\n高く，ウェーブレット変換から算",
            "果より，クラス3 と揚げ終わりの間には明確な境界が存在しない可能性が\n高く，ウェーブレット変換から算出した特徴量では，クラスの識別に有効でないと考えら\nれる．\n表5.10 に，クラス3 および揚げ終わりによる二値分類の結果を示す．表5.9 の結果と比\n較しても，特筆して精度の差が開いている分類器は存在しない．\n以上の結果より，本研究でウェーブレット変換から算出した特徴量では，クラス3 およ\nび揚げ終わりの分類が困難であることがわかった．\n5.3\n変化点検出による唐揚げの揚げ終わり検出精度の評価\n変化点検出における精度評価は，揚げ途中から揚げ終わりへの変化点（真の変化点）に\n対する検出精度を評価するために，適合率，再現率，F1 スコアを使用する．ここで適合\n42\n図5.8: 4 クラスラベルにおけるウェーブレット変換から得られる特徴量のt-SNE 結果\n（左図:4 クラス，右図:2 クラス）\n率は，検出した変化点のうち，どれだけが真の変化点であったかを表す．再現率は，真の\n変化点がどれだけ正しく検出されたかを表す．真の変化点の検出有無は，許容範囲を設定\nして，その範囲内に検出点が収まって",
            "正しく検出されたかを表す．真の変化点の検出有無は，許容範囲を設定\nして，その範囲内に検出点が収まっていた場合，検出されたこととする．許容範囲は，真\nの変化点±10 秒と設定する．この値は，1.1.4 で述べた通り，食中毒を防ぐための十分な\n加熱は，鶏肉の中心の温度が75◦C 以上で1 分間以上とされており，前節で再定義した揚\nげ終わりラベルの時間はすべて調理開始から1 分以上経過していることから，危険ではな\nい範囲であることがわかる．また，変化点検出には，時間ごとの振幅の平均を特徴として\n利用した．調理音1 から調理音4 は雑音が含まれているため，振幅の平均に対してメディ\nアンフィルタを適用する．\n解析の結果，最も揚げ終わりの変化点を捉えることが可能なパラメータは，ウィンドウ\n幅30，ペナルティ6.5 であった．以下に，このパラメータを設定した変化点検出による各\n調理音の検出結果を示す．\n図5.9 は調理音1，図5.10 は調理音2 の変化点検出結果である．調理音1 の真の変化点\nは214 秒であり，それに最も近い変化点は214.601 秒で検出されているため，正確に変化\n点を捉えてい",
            "4 秒であり，それに最も近い変化点は214.601 秒で検出されているため，正確に変化\n点を捉えている．調理音2 の真の変化点は238 秒，それに最も近い変化点は259.383 秒で\nあった．調理音2 に対しては正確に変化点を捉えられなかったことがわかる．\n図5.11 は調理音3，図5.12 は調理音4 の変化点検出結果である．調理音3 の真の変化点\nは218 秒であり，検出された変化点は219.413 秒であった．また，調理音4 は真の変化点\nが225 秒，検出された変化点は226.778 秒であった．どちらの変化点検出のおいても，真\nの変化点と2 秒以内の誤差であり，他の変化点も検出されていない．\n図5.13 は調理音5，図5.14 は調理音6 の変化点検出結果である．調理音5 の真の変化点\nは176 秒であり，それに最も近い変化点は176.851 秒であった．また，調理音6 は真の変\n化点が208 秒，それに最も近い変化点は206.891 秒であった．どちらも誤差が2 秒以内に\n収まっているが，他の変化点も検出されている．\n43\n表5.10: ウェーブレット変換を利用した分類器ご",
            "まっているが，他の変化点も検出されている．\n43\n表5.10: ウェーブレット変換を利用した分類器ごとのクラス3 および揚げ終わりの分類精\n度\n分類器\nF1 スコア\n適合率\n再現率\n正解率\nロジスティック回帰\n0.550 ± 0.256\n0.668 ± 0.251\n0.583 ± 0.347\n0.611 ± 0.168\nランダムフォレスト\n0.419 ± 0.339\n0.493 ± 0.371\n0.464 ± 0.419\n0.542 ± 0.203\nGNB\n0.447 ± 0.359\n0.779 ± 0.266\n0.445 ± 0.412\n0.607 ± 0.217\nkNN\n0.439 ± 0.246\n0.574 ± 0.325\n0.525 ± 0.345\n0.445 ± 0.212\nSV Clinear\n0.529 ± 0.250\n0.664 ± 0.256\n0.554 ± 0.347\n0.591 ± 0.167\nSV Cpoly\n0.226 ± 0.337\n0.734 ± 0.350\n0.300 ± 0.460\n0.503 ± 0.184\nSV Crbf\n0.349 ± 0.315",
            "\n0.300 ± 0.460\n0.503 ± 0.184\nSV Crbf\n0.349 ± 0.315\n0.674 ± 0.330\n0.415 ± 0.425\n0.493 ± 0.201\nSV Csigmoid\n0.449 ± 0.207\n0.643 ± 0.263\n0.502 ± 0.316\n0.487 ± 0.159\nXGB\n0.430 ± 0.339\n0.510 ± 0.373\n0.485 ± 0.436\n0.541 ± 0.214\n図5.9: 調理音1 の変化点検出結果\n図5.15 は調理音7，図5.16 は調理音8 の変化点検出結果である．調理音7 の真の変化点\nは195 秒であり，それに最も近い変化点は192.168 秒であった．また，調理音8 は真の変\n化点が215 秒，それに最も近い変化点は212.159 秒であった．どちらも誤差が4 秒以内に\n収まっているが，調理音5，6 と同様に他の変化点も検出されている．\n図5.17 は調理音9，図5.18 は調理音10 の変化点検出結果である．調理音9 の真の変化\n点は157 秒であり，それに最も近い変化点は157.208 秒であ",
            "結果である．調理音9 の真の変化\n点は157 秒であり，それに最も近い変化点は157.208 秒であった．また，調理音10 は真の\n変化点は185 秒，それに最も近い変化点は181.882 秒であった．調理音9 については，誤\n差がほとんどないことがわかる．調理音10 は誤差が4 秒以内に収まっている．また，両\n結果ともに他の変化点も検出されている．\n調理音1 から10 までの変化点検出の評価一覧および，真の変化点と検出された最も近\nい変化点を表5.11 に示す．調理音2 以外は，真の変化点を正しく検出していることがわ\nかる．また，各調理音の変化点検出結果の図より，150 秒以降に初めて検出された変化点\n44\n図5.10: 調理音2 の変化点検出結果\nが真の変化点であることがわかる．150 秒以降と限定することで，調理音2 以外は真の変\n化点が正確に検出可能であり，誤検出も調理音2 以外は存在しない．つまり，この制約に\nより，揚げ終わりの検出精度は3 種類すべての指標において90%となり，適合率が90%で\nあることから，誤検出の可能性は10%となる．\nこれに対して，機械学習手法はモデル",
            "，適合率が90%で\nあることから，誤検出の可能性は10%となる．\nこれに対して，機械学習手法はモデルの精度が安定していない．よって，本研究におい\nては，機械学習手法よりも変化点検出の方が，揚げ終わり識別に対して精度が高いと言え\nる．このことから，変化点検出を利用した唐揚げの調理音識別が可能であると考え，FCGs\nには変化点検出アルゴリズムを実装する．\n表5.11: 各調理音の変化点および精度一覧\nF1 スコア\n適合率\n再現率\n真の変化点[s]\n検出された変化点[s]\n調理音1\n0.500\n0.333\n1.000\n214\n214.601\n調理音2\n0.000\n0.000\n0.000\n238\n259.383\n調理音3\n1.000\n1.000\n1.000\n218\n219.413\n調理音4\n1.000\n1.000\n1.000\n225\n226.778\n調理音5\n0.400\n0.250\n1.000\n176\n176.851\n調理音6\n0.667\n0.500\n1.000\n208\n206.891\n調理音7\n0.500\n0.333\n1.000\n195\n192.168\n調理音8\n0.500\n0.333\n1.",
            "\n0.500\n0.333\n1.000\n195\n192.168\n調理音8\n0.500\n0.333\n1.000\n215\n212.159\n調理音9\n0.333\n0.200\n1.000\n157\n157.208\n調理音10\n0.500\n0.333\n1.000\n185\n181.882\n45\n図5.11: 調理音3 の変化点検出結果\n5.4\n変化点検出を利用した揚げ終わり判定システムの実装\n前節までの結果より，揚げ終わり識別手法として変化点検出を利用する．スマートフォ\nンアプリケーションの実装は，Android Studio を使用した[73]．また，変化点検出のアル\nゴリズムはChaquopy を利用して実装した[74]．Chaquopy はAndroid アプリにPython\nコンポーネントを組み込み可能とするSDK である．\n録音を開始してから，揚げ終わりを判定するまでのシステムフローチャートを図5.19 に\n示す．\n変化点検出は録音を開始してから165 秒後から開始する．これは，150 秒地点が変化点\n検出のウィンドウの中心となるようにするためである．変化点検出に利用するデータ量は\n30 秒",
            "が変化点\n検出のウィンドウの中心となるようにするためである．変化点検出に利用するデータ量は\n30 秒分であり，165 秒経過した段階で特徴量を算出する．特徴量は振幅スペクトログラム\nを算出するため，STFT 適用後，振幅スペクトルを求める．その後，メディアンフィルタ\nで雑音を低減し，時間ごとのエネルギーを算出する．そのエネルギーを基に変化点を検出\nする．検出された場合は，図3.1 のような画面によるフィードバックを実施する．これに\nより，アプリケーション利用者は，唐揚げが揚がったタイミングを認知する．\n46\n図5.12: 調理音4 の変化点検出結果\n図5.13: 調理音5 の変化点検出結果\n47\n図5.14: 調理音6 の変化点検出結果\n図5.15: 調理音7 の変化点検出結果\n48\n図5.16: 調理音8 の変化点検出結果\n図5.17: 調理音9 の変化点検出結果\n49\n図5.18: 調理音10 の変化点検出結果\n50\n図5.19: FCGs のシステムフローチャート\n51\n第6章\n結論\n本章では，本研究のまとめおよび今後の展望について述べる．\n6.1\n本研究のまとめ\n本研究では，唐",
            "論\n本章では，本研究のまとめおよび今後の展望について述べる．\n6.1\n本研究のまとめ\n本研究では，唐揚げの揚げ終わりの見極めが料理初心者にとって課題となっていること\nに対して，料理中でも容易に利用可能なスマートフォン向け調理支援システムFCGs を開\n発した．\nまた，揚げ終わりとなる前の状態で調理完了と誤判定しない安全な判定システムを構築\nするために，機械学習および変化点検出手法を検討した．機械学習手法においては，リサン\nプリング手法を組み合わせて，分類精度の向上を図った．また音響特徴量として，MFCC，\nウェーブレット変換を検討した．変化点検出手法はWindow ベースのアルゴリズムを検討\nした結果，機械学習手法よりも高い精度で，揚げ終わりの検出が可能であることが判明し\nた．よって，FCGs には，変化点検出による揚げ終わり検出を実装し，調理支援システム\nを開発した．\n本研究の目標に対する結果としては以下の通りである．\n1.\n唐揚げの調理状態において，揚げ終わりとなる前の状態で調理完了と誤判定しない\n安全な音判定システムの構築を目指した．結果，変化点検出手法を利用することで，\n揚げ終",
            "と誤判定しない\n安全な音判定システムの構築を目指した．結果，変化点検出手法を利用することで，\n揚げ終わりの検出における再現率が90%を達成した．また，調理開始から150 秒以\n降の変化点を揚げ終わりの変化点として検出することで，F1 スコア，適合率，再現\n率の3 種類の指標において90%の精度を達成し，誤検出は10%となった．\n2.\nスマートフォン上で唐揚げの揚げ終わりをリアルタイムに判別する，容易に利用可\n能なアプリケーションの開発を目指した．結果，変化点検出アルゴリズムを利用し\nて，スマートフォンのマイクロフォンからリアルタイムにデータを取得し，唐揚げ\nの揚げ終わりを判定するアプリケーションを開発した．\n6.2\n今後の展望\n今後の展望として，揚げ終わり識別手法の精度向上が挙げられる．本研究で検討した機\n械学習手法は，調理音データの時系列情報を考慮していなかったため，LSTM といった時\n系列を考慮した機械学習モデルを利用することで，分類精度の向上が可能であると考える\n[75]．本研究でもLSTM を検証したが，時系列データが不足していたため，十分な結果を\n得ることができずに断念した",
            "でもLSTM を検証したが，時系列データが不足していたため，十分な結果を\n得ることができずに断念した．よって，データセットの拡充を実施して，より頑健な揚げ\n終わり判定システムの構築を検討したい．\nまた，調理油の温度および調理環境の違いにも対応可能なアルゴリズムおよび分類モデ\nルの構築を目指す．料理初心者は，油の温度を正確に測定することが困難であると考えら\n52\nれる．よって，油の温度がある程度，異なっていても問題なく調理可能な手法を検討する\n必要があると考える．調理環境においても，騒音の種類や使用する調理器具の違いなどに\nより，音響が異なってくるため，調理環境の違いにも対応可能な手法が必要である．\n本研究では，唐揚げの調理が完了したタイミングを検出する調理支援にとどまっている．\nそのため，検出されたタイミングが最も美味しい状態であるかは判別できていない．し\nかし，クリスピー度に関する研究は，これまで数多く実施されている[76][77][78][79]．ク\nリスピー度は唐揚げの食感として表現される感覚である．よって，美味しさに対する最適\nなタイミングを検知し，美味しい唐揚げを調理する支援",
            "現される感覚である．よって，美味しさに対する最適\nなタイミングを検知し，美味しい唐揚げを調理する支援システムに拡張可能であると考\nえる．\n精度向上の手法として，画像分析も利用可能である．スマートグラスのようなマイクロ\nフォンおよびカメラを搭載したデバイス利用することで，マルチモーダルシステムによ\nる精度向上が期待される．また，フィードバックをスマートグラス上に表示可能であるた\nめ，ユーザビリティの高い調理支援システムの開発が可能であると考える．\nまた，本研究の最終的な目標として，揚げ物料理すべてに対応可能な調理支援システム\nを開発を考えている．そのため，唐揚げだけでなく，天ぷら，コロッケ，豚カツ，白身魚\nのフライなどのレシピに対しても，研究を実施したいと考えている．その結果，料理初\n心者の料理へのハードルを下げ，自炊を習慣付けるモチベーションにつながることを期待\nする．\n53\n謝辞\n本研究を進めるにあたって，学部4 年から3 年間，ご指導いただいた青山学院大学理工\n学部情報テクノロジー学科Guillaume Lopez 教授に深く感謝申し上げます．研究方針，研\n究における課題，就職活動",
            "科Guillaume Lopez 教授に深く感謝申し上げます．研究方針，研\n究における課題，就職活動に至るまでご指導いただいたこと，特に，毎週の研究会で，毎\n度的確なご助言をいただいたこと，心から感謝しております．加えて，私の力不足により，\n機械学習の分類精度が中々良くならず，学会発表や論文誌への投稿が叶わなかったこと，\nお詫び申し上げます．\nまた，大学関連の事務手続きおよび研究室の整備等，お心遣いいただいた研究補助員の\n大熊ちひろ様にも深く感謝申し上げます．\nさらに，副査として，残り時間で実現可能な識別手法について的確なご助言をいただき\nました青山学院大学理工学部情報テクノロジー学科大原剛三教授に深く感謝申し上げます．\nそして，研究生活において日々研究の助言をいただいたウェアラブル環境情報システム\n研究室の同期の皆様，並びに学部4 年時にデータ収集にご協力いただいただけでなく，大\n学生活を支えてくださった母にも深く感謝申し上げます．\n2025 年1 月31 日\n新井優作\n54\n参考文献\n[1] 日本政策金庫公庫. 飲食店のテイクアウト・デリバリーサービス等に関する消費者調査\n結果. ",
            "\n[1] 日本政策金庫公庫. 飲食店のテイクアウト・デリバリーサービス等に関する消費者調査\n結果. https://www.jfc.go.jp/n/findings/pdf/seikatsu20_1215a.pdf, 12 2020.\n(最終参照日：2024/12/31).\n[2] 日本政策金庫公庫. 中食と外食に関する消費者動向調査結果. https://www.jfc.go.\njp/n/findings/pdf/topics_180913a.pdf, 9 2018. (最終参照日：2024/12/31).\n[3] 農林水産省. 新型コロナウイルス感染症の拡大による食生活の変化. https://www.\nmaff.go.jp/j/syokuiku/ishiki/r03/zuhyou/z9-1.html, 3 2021.\n(最終参照日：\n2024/12/31).\n[4] 日本政策金庫公庫.\n食の志向等に関する調査結果.\nhttps://www.jfc.go.jp/n/\nfindings/pdf/topics_200805a.pdf, 7 2020. (最終参照日：2024/12/31",
            "/pdf/topics_200805a.pdf, 7 2020. (最終参照日：2024/12/31).\n[5] Celia Rodr´ıguez-P´erez, Esther Molina-Montes, Vito Verardo, Reyes Artacho, Bel´en\nGarc´ıa-Villanova, Eduardo Jes´us Guerra-Hern´andez, and Mar´ıa Dolores Ru´ız-L´opez.\nChanges in dietary behaviours during the covid-19 outbreak conﬁnement in the span-\nish covidiet study. Nutrients, Vol. 12, No. 6, p. 1730, 2020.\n[6] Danijela Pfeifer, Josip Reˇsetar, Jasenka Gajdoˇs Kljusuri´c, Ines Panjkota Krbavˇci´c,\nDarija Vraneˇsi´c Bender, Celia Rodr´",
            " Krbavˇci´c,\nDarija Vraneˇsi´c Bender, Celia Rodr´ıguez-P´erez, Mar´ıa Dolores Ru´ız-L´opez, and Zvon-\nimir ˇSatali´c. Cooking at home and adherence to the mediterranean diet during the\ncovid-19 conﬁnement: the experience from the croatian covidiet study. Frontiers in\nnutrition, Vol. 8, p. 617721, 2021.\n[7] Sarah Gerritsen, Victoria Egli, Rajshri Roy, Jill Haszard, Charlotte De Backer, Lau-\nranna Teunissen, Isabelle Cuykx, Paulien Decorte, Sara Pabian Pabian, Kathleen\nVan Royen, et al. Seven wee",
            "abian Pabian, Kathleen\nVan Royen, et al. Seven weeks of home-cooked meals: Changes to new zealanders ’\ngrocery shopping, cooking and eating during the covid-19 lockdown. Journal of the\nRoyal Society of New Zealand, Vol. 51, No. sup1, pp. S4–S22, 2021.\n[8] ハウス食品株式会社. さっと・・・レシピの独特表現「レシピ語」に料理初心者の約8割が\n戸惑っていることが判明！https://housefoods.jp/company/news/pdf/20210517_\nrelease_v2.pdf, 5 2021. (最終参照日：2025/1/2).\n[9] 平島円, 磯部由香, 堀光代. 学生の「切り方」に対する認知度と自信度の変化. 日本\n調理科学会誌, Vol. 54, No. 5, pp. 234–243, 2021.\n[10] Yut",
            "理科学会誌, Vol. 54, No. 5, pp. 234–243, 2021.\n[10] Yuta Kido, Teruhiro Mizumoto, Hirohiko Suwa, Yutaka Arakawa, and Keiichi Ya-\nsumoto. A cooking support system for seasoning with smart cruet. In International\nConference on Human-Computer Interaction, pp. 369–382. Springer, 2019.\n55\n[11] 加藤岳大,\n横窪安奈,\nロペズギヨーム.\nSyncook: 動画メタデータと加速度セ\nンサを用いたレシピ動画進行度自動同期システム.\nhttps://www.wiss.org/\nWISS2020Proceedings/data/N-15.pdf, 2020. (最終参照日：2025/1/2).\n[12] 株式会社Felicidad. Hestan cue へスタンキュー公式サイト. https://hestancue.jp/.",
            "d. Hestan cue へスタンキュー公式サイト. https://hestancue.jp/.\n(最終参照日：2025/1/2).\n[13] KY Voong, AB Norton, TB Mills, and IT Norton. Characterisation of deep-fried\nbatter and breaded coatings. Food Structure, Vol. 16, pp. 43–49, 2018.\n[14] Franco Pedreschi, Pamela Hern´andez, Clara Figueroa, and Pedro Moyano. Modeling\nwater loss during frying of potato slices. International journal of food properties,\nVol. 8, No. 2, pp. 289–299, 2005.\n[15] 国立感染症研究所.\nサルモネラ感染症とは.\nhttps://www.niid.go.jp/niid/ja/\nkansennohanashi",
            "は.\nhttps://www.niid.go.jp/niid/ja/\nkansennohanashi/409-salmonella.html. (最終参照日：2024/12/11).\n[16] 国立感染症研究所. カンピロバクター感染症とは. https://www.niid.go.jp/niid/\nja/kansennohanashi/385-campylobacter-intro.html. (最終参照日：2024/12/11).\n[17] 厚生労働省.\nカンピロバクター食中毒予防について（q&a）.\nhttps:\n//www.mhlw.go.jp/stf/seisakunitsuite/bunya/kenkou_iryou/shokuhin/\nsyokuchu/campylobacterqa.html. (最終参照日：2024/12/11).\n[18] 食品安全委員会.\nカンピロバクターによる食中毒にご注意ください.\nhttps:\n//www.fsc.go.jp/sonota/e1_campylo_chudoku_20160205.html.\n(最終参照日：\n2024/12/11",
            "_campylo_chudoku_20160205.html.\n(最終参照日：\n2024/12/11).\n[19] 農林水産省. 鶏料理を楽しむために～カンピロバクターによる食中毒にご注意を！！\n～. https://www.kurashikagaku.co.jp/report/detail.php?id=133. (最終参照\n日：2024/12/11).\n[20] Solveig Langsrud, Oddvin Sørheim, Silje Elisabeth Skuland, Val´erie Lengard Almli,\nMerete Rus˚as Jensen, Magnhild Seim Grøvlen, Øydis Ueland, and Trond Møretrø.\nCooking chicken at home: Common or recommended approaches to judge doneness\nmay not assure suﬃcient inactivation of pathogens. PLoS One, Vol. 15, No. 4, p",
            "tivation of pathogens. PLoS One, Vol. 15, No. 4, p.\ne0230928, 2020.\n[21] engadget. New android feature alerts you to smoke alarms and other ’critical’ sounds.\nhttps://www.engadget.com/android-sound-notification-alerts-170045534.\nhtml, 10 2020. (最終参照日：2025/1/2).\n[22] Apple Inc. iphone でサウンドを認識する-apple サポート(日本). https://support.\napple.com/ja-jp/guide/iphone/iphf2dc33312/ios. (最終参照日：2025/1/2).\n[23] 株式会社野村総合研究所. 第301 回nri メディアフォーラム「it ナビゲーター2021\n年度版」. https://www.nri.com/-/media/Corporate/jp/Files/P",
            ". https://www.nri.com/-/media/Corporate/jp/Files/PDF/knowledge/\nreport/cc/mediaforum/2020/forum301.pdf, 12 2020. (最終参照日：2025/1/2).\n56\n[24] M Tabacchi, C Asensio, I Pav´on, M Recuero, J Mir, and MC Artal. A statistical\npattern recognition approach for the classiﬁcation of cooking stages. the boiling water\ncase. Applied acoustics, Vol. 74, No. 8, pp. 1022–1032, 2013.\n[25] 宮澤要二, 齋藤大輔, 峯松信明ほか. レシピ情報に基づく調理行動認識における音響\n識別器の中間特徴量利用に関する検討. 研究報告音楽情報科学(MUS), Vol. 2020,\nNo. 31, pp. 1–6, 2020.\n[26] 陳維, 塚田紘也, ",
            " Vol. 2020,\nNo. 31, pp. 1–6, 2020.\n[26] 陳維, 塚田紘也, 横窪安奈ほか. 音解析による唐揚げの揚がり具合判定手法. マルチ\nメディア, 分散, 協調とモバイルシンポジウム2022 論文集, Vol. 2022, pp. 265–270,\n2022.\n[27] June Anne Caladcad, Shiela Cabahug, Mary Rose Catamco, Paul Elyson Villaceran,\nLeizel Cosgafa, Karl Norbert Cabizares, Marfe Hermosilla, et al. Determining philip-\npine coconut maturity level using machine learning algorithms based on acoustic\nsignal. Computers and electronics in agriculture, Vol. 172, p. 105327, 2020.\n[28] Kang Zhao, He Li, Zhihu",
            "172, p. 105327, 2020.\n[28] Kang Zhao, He Li, Zhihua Zha, Mingcan Zhai, and Jie Wu. Detection of sub-healthy\napples with moldy core using deep-shallow learning for vibro-acoustic multi-domain\nfeatures. Measurement: Food, Vol. 8, p. 100068, 2022.\n[29] Rafael Z Lopes and Gustavo C Dacanal. Classiﬁcation of crispness of food materials\nby deep neural networks. Journal of Texture Studies, Vol. 54, No. 6, pp. 845–859,\n2023.\n[30] Rui Xiao, Qunfang Hu, and Jie Li. Leak detection of gas pipelines using ac",
            "d Jie Li. Leak detection of gas pipelines using acoustic\nsignals based on wavelet transform and support vector machine. Measurement, Vol.\n146, pp. 479–489, 2019.\n[31] Anjali Malviya, Rahul Dixit, Anupam Shukla, and Nagendra Kushwaha. A novel\napproach to detection of covid-19 and other respiratory diseases using autoencoder\nand lstm. SN Computer Science, Vol. 6, No. 1, pp. 1–11, 2025.\n[32] Chern-Sheng Lin, Yu-Ching Pan, Yu-Xin Kuo, Ching-Kun Chen, and Chuen-Lin\nTien. A study of automatic judgment",
            " and Chuen-Lin\nTien. A study of automatic judgment of food color and cooking conditions with\nartiﬁcial intelligence technology. Processes, Vol. 9, No. 7, p. 1128, 2021.\n[33] Chao Dong, Luelue Huang, Cheng Xiong, Mengkun Li, and Jiamei Tang. Evalua-\ntion of quality of baguette bread using image analysis technique. Journal of Food\nComposition and Analysis, p. 107222, 2025.\n[34] Arman Areﬁ, Oliver Hensel, and Barbara Sturm. Intelligent potato frying: time to say\ngoodbye to the“ good old ”processing",
            ": time to say\ngoodbye to the“ good old ”processing strategies. Thermal Science and Engineering\nProgress, Vol. 34, p. 101389, 2022.\n[35] Herv´e Abdi and Lynne J Williams. Principal component analysis. Wiley interdisci-\nplinary reviews: computational statistics, Vol. 2, No. 4, pp. 433–459, 2010.\n57\n[36] Laurens Van der Maaten and Geoﬀrey Hinton. Visualizing data using t-sne. Journal\nof machine learning research, Vol. 9, No. 11, 2008.\n[37] Leon Cohen. Time-frequency analysis, Vol. 778. Prentice Hal",
            "n. Time-frequency analysis, Vol. 778. Prentice Hall PTR New Jersey, 1995.\n[38] Ian Naismith Sneddon. Fourier transforms. Courier Corporation, 1995.\n[39] Fang Zheng, Guoliang Zhang, and Zhanjiang Song. Comparison of diﬀerent imple-\nmentations of mfcc. Journal of Computer science and Technology, Vol. 16, No. 6, pp.\n582–589, 2001.\n[40] Stanley Smith Stevens, John Volkmann, and Edwin Broomell Newman. A scale for\nthe measurement of the psychological magnitude pitch. The journal of the acoustical\nsoci",
            "agnitude pitch. The journal of the acoustical\nsociety of america, Vol. 8, No. 3, pp. 185–190, 1937.\n[41] Ingrid Daubechies. Ten lectures on wavelets. Society for industrial and applied math-\nematics, 1992.\n[42] Ki-Bok Kim, David K Hsu, and Daniel J Barnard. Estimation of porosity content of\ncomposite materials by applying discrete wavelet transform to ultrasonic backscat-\ntered signal. NDT & E International, Vol. 56, pp. 10–16, 2013.\n[43] Gilbert Strang. Wavelets and Filter Banks. Wellesley-Camb",
            " Strang. Wavelets and Filter Banks. Wellesley-Cambridge Press, 1996.\n[44] Ingrid Daubechies and Bruce J Bates. Ten lectures on wavelets, 1993.\n[45] scikit learn. scikit-learn. https://scikit-learn.org/stable/index.html. (最終\n参照日：2025/1/21).\n[46] xgboost developers. Xgboost documentation. https://xgboost.readthedocs.io/\nen/stable/. (最終参照日：2025/1/22).\n[47] Vladimir Vapnik. The nature of statistical learning theory. Springer science & business\nmedia, 2013.\n[48] Mariette Awad, Rahul Khanna, Mariette ",
            " 2013.\n[48] Mariette Awad, Rahul Khanna, Mariette Awad, and Rahul Khanna. Support vector\nmachines for classiﬁcation.\nEﬃcient learning machines: Theories, concepts, and\napplications for engineers and system designers, pp. 39–66, 2015.\n[49] Jun Han and Claudio Moraga. The inﬂuence of the sigmoid function parameters on\nthe speed of backpropagation learning. In International workshop on artiﬁcial neural\nnetworks, pp. 195–201. Springer, 1995.\n[50] Christopher M Bishop and Nasser M Nasrabadi. Pattern ",
            "istopher M Bishop and Nasser M Nasrabadi. Pattern recognition and machine\nlearning, Vol. 4. Springer, 2006.\n[51] Thomas Bayes. Lii. an essay towards solving a problem in the doctrine of chances. by\nthe late rev. mr. bayes, frs communicated by mr. price, in a letter to john canton, amfr\ns. Philosophical transactions of the Royal Society of London, No. 53, pp. 370–418,\n1763.\n58\n[52] Thomas Cover and Peter Hart. Nearest neighbor pattern classiﬁcation. IEEE trans-\nactions on information theory, Vol.",
            "n. IEEE trans-\nactions on information theory, Vol. 13, No. 1, pp. 21–27, 1967.\n[53] Tin Kam Ho. The random subspace method for constructing decision forests. IEEE\ntransactions on pattern analysis and machine intelligence, Vol. 20, No. 8, pp. 832–844,\n1998.\n[54] Tianqi Chen and Carlos Guestrin. Xgboost: A scalable tree boosting system. In\nProceedings of the 22nd acm sigkdd international conference on knowledge discovery\nand data mining, pp. 785–794, 2016.\n[55] Trevor Hastie, Robert Tibshirani, Je",
            "4, 2016.\n[55] Trevor Hastie, Robert Tibshirani, Jerome Friedman, Trevor Hastie, Robert Tibshi-\nrani, and Jerome Friedman. Boosting and additive trees. The elements of statistical\nlearning: data mining, inference, and prediction, pp. 337–387, 2009.\n[56] David W Hosmer Jr, Stanley Lemeshow, and Rodney X Sturdivant. Applied logistic\nregression. John Wiley & Sons, 2013.\n[57] The imbalanced-learn developers.\nimbalanced-learn documentation.\nhttps://\nimbalanced-learn.org/stable/. (最終参照日：2025/1/21).\n[58",
            "balanced-learn.org/stable/. (最終参照日：2025/1/21).\n[58] Haibo He, Yang Bai, Edwardo A Garcia, and Shutao Li. Adasyn: Adaptive synthetic\nsampling approach for imbalanced learning. In 2008 IEEE international joint con-\nference on neural networks (IEEE world congress on computational intelligence), pp.\n1322–1328. Ieee, 2008.\n[59] Nitesh V Chawla, Kevin W Bowyer, Lawrence O Hall, and W Philip Kegelmeyer.\nSmote: synthetic minority over-sampling technique. Journal of artiﬁcial intelligence\nresearch, Vol. ",
            " Journal of artiﬁcial intelligence\nresearch, Vol. 16, pp. 321–357, 2002.\n[60] Hui Han, Wen-Yuan Wang, and Bing-Huan Mao. Borderline-smote: a new over-\nsampling method in imbalanced data sets learning. In International conference on\nintelligent computing, pp. 878–887. Springer, 2005.\n[61] Hien M Nguyen, Eric W Cooper, and Katsuari Kamei. Borderline over-sampling for\nimbalanced data classiﬁcation. International Journal of Knowledge Engineering and\nSoft Data Paradigms, Vol. 3, No. 1, pp. 4–21, 2011",
            "Soft Data Paradigms, Vol. 3, No. 1, pp. 4–21, 2011.\n[62] Wei-Chao Lin, Chih-Fong Tsai, Ya-Han Hu, and Jing-Shang Jhang. Clustering-based\nundersampling in class-imbalanced data. Information Sciences, Vol. 409, pp. 17–26,\n2017.\n[63] Peter Hart. The condensed nearest neighbor rule (corresp.). IEEE transactions on\ninformation theory, Vol. 14, No. 3, pp. 515–516, 1968.\n[64] Inderjeet Mani and I Zhang. knn approach to unbalanced data distributions: a case\nstudy involving information extraction. In Pro",
            "ase\nstudy involving information extraction. In Proceedings of workshop on learning from\nimbalanced datasets, Vol. 126, pp. 1–7. ICML, 2003.\n59\n[65] Jorma Laurikkala. Improving identiﬁcation of diﬃcult small classes by balancing\nclass distribution. In Artiﬁcial Intelligence in Medicine: 8th Conference on Artiﬁcial\nIntelligence in Medicine in Europe, AIME 2001 Cascais, Portugal, July 1–4, 2001,\nProceedings 8, pp. 63–66. Springer, 2001.\n[66] Miroslav Kubat, Stan Matwin, et al. Addressing the curse ",
            "v Kubat, Stan Matwin, et al. Addressing the curse of imbalanced training\nsets: one-sided selection. In Icml, Vol. 97, p. 179. Citeseer, 1997.\n[67] Tomek Ivan. Two modiﬁcations of cnn. IEEE transactions on Systems, Man and\nCommunications, SMC, Vol. 6, pp. 769–772, 1976.\n[68] ruptures.\nWelcome\nto\nruptures.\nhttps://centre-borelli.github.io/\nruptures-docs/. (最終参照日：2025/1/22).\n[69] Charles Truong, Laurent Oudre, and Nicolas Vayatis.\nSelective review of oﬄine\nchange point detection methods. Signal Pro",
            "f oﬄine\nchange point detection methods. Signal Processing, Vol. 167, p. 107299, 2020.\n[70] Ioannis Pitas and Anastasios N Venetsanopoulos. Nonlinear digital ﬁlters: principles\nand applications, Vol. 84. Springer Science & Business Media, 2013.\n[71] Daniel Berrar, et al. Cross-validation., 2019.\n[72] Elan — the language archive. https://archive.mpi.nl/tla/elan. (最終参照日：\n2025/1/19).\n[73] Google LLC.\nAndroid studio.\nhttps://developer.android.com/studio?hl=ja.\n(最終参照日：2025/1/23).\n[74] Chaquo Ltd. Chaq",
            "io?hl=ja.\n(最終参照日：2025/1/23).\n[74] Chaquo Ltd. Chaquopy python sdk for android. https://chaquo.com/chaquopy/.\n(最終参照日：2025/1/23).\n[75] S Hochreiter. Long short-term memory. Neural Computation MIT-Press, 1997.\n[76] Liara S Dias-Faceto, Ana Salvador, and Ana C Conti-Silva. Acoustic settings combi-\nnation as a sensory crispness indicator of dry crispy food. Journal of texture studies,\nVol. 51, No. 2, pp. 232–241, 2020.\n[77] Tˆeko Gouyo, Christian Mestres, Isabelle Maraval, B´en´edicte Fontez, C´eline",
            "res, Isabelle Maraval, B´en´edicte Fontez, C´eline Hoﬂeit-\nner, and Philippe Bohuon.\nAssessment of acoustic-mechanical measurements for\ntexture of french fries: Comparison of deep-fat frying and air frying. Food Research\nInternational, Vol. 131, p. 108947, 2020.\n[78] Jacob Tizhe Liberty, Md Haﬁzur Rahman Bhuiyan, and Michael Ngadi. Assessing\ntextural changes of breaded deep-fat fried chicken nuggets during post-frying holdings\nunder infrared heat-lamp using acoustic-mechanical techniques. Intern",
            "-lamp using acoustic-mechanical techniques. International Journal\nof Food Science and Technology, Vol. 59, No. 11, pp. 8596–8605, 2024.\n[79] Jacob Tizhe Liberty, Md Haﬁzur Rahman Bhuiyan, and Michael Ngadi. Unravelling\nthe nexus between structure, texture, and acoustic traits of fried chicken nuggets.\n60\nInternational Journal of Food Science and Technology, Vol. 59, No. 11, pp. 8571–\n8582, 2024.\n61\n付録A\n本研究に関する論文と発表実績\n1. 新井優作, ロペズギヨーム: 唐揚げの音響特性による揚げ終わり判定, マルチメディ\nア, 分散, 協調とモバイル(DICOMO2023) シンポジウム論",
            "揚げ終わり判定, マルチメディ\nア, 分散, 協調とモバイル(DICOMO2023) シンポジウム論文集, pp.137-142(2023)\n62\n付録B\n唐揚げの一般的なレシピまとめ\nインターネット上に掲載されている10 種類の唐揚げレシピを調査した結果を表B.1 に\nまとめる．空欄となっている箇所はレシピに明記されていなかった情報である．\n表B.1: 唐揚げレシピの調理条件まとめ\n温度[◦C]\n鶏もも肉の量[g]\n1 つ当たりの大きさ\n調理時間[分]\n油の種類\nレシピ1\n180\n300\n-\n4\n-\nレシピ2\n160\n250\n-\n4–5\nサラダ油\nレシピ3\n160–170\n300–400\n3–4 cm\n4–6\n-\nレシピ4\n170\n350\n4–5 cm\n6\n-\nレシピ5\n170\n300\n-\n3–4\nサラダ油\nレシピ6\n170\n100\n小さめの一口大\n3–4\n-\nレシピ7\n170–180\n800\n-\n3\nサラダ油\nレシピ8\n170\n250\n3–4 cm 四方\n4–6\nサラダ油\nレシピ9\n170\n300\n3–4 cm 程度\n4–5\nサラダ油\nレシピ10\n160–170\n300\n一口大\n4",
            "170\n300\n3–4 cm 程度\n4–5\nサラダ油\nレシピ10\n160–170\n300\n一口大\n4–5\n-\n補足として，レシピ2 は160◦C で3 分から4 分調理した後，強火で1 分程度揚げる．レ\nシピ3 は3 分から4 分調理した後，4 分から5 分休める．その後，高温の油で1 分から2\n分揚げる．レシピ4 は3 分フライ調理後，2 分裏返して調理，最後に強火で1 分調理する．\nレシピ5 の調理油は鍋の底から3 cm 程度まで入れて調理する．レシピ7 は2 分程度揚げ\nた後，余熱で4 分程度おき，再度200◦C で約1 分揚げる．レシピ8 は，まず2 分から3 分\n程度調理する．鶏肉の下部に揚げ色がついたら裏返し，さらに2 分3 分揚げる．レシピ\n9 の調理油は鍋の底から2 cm 程度まで入れる．レシピ10 では，4 分から5 分揚げた後，\n180◦C でカラッと揚げる．\n表B.1 より，調理時間は平均4 分程度，調理油は基本的にサラダ油が使用されており，\n160◦C から180◦C の温度で調理されることが一般的であることが判明した．\n63\n付録C\nMFCC特徴量を使用したそ",
            "◦C の温度で調理されることが一般的であることが判明した．\n63\n付録C\nMFCC特徴量を使用したその他の分類\n精度の評価\nC.1\nアンダーサンプリングにCluster Centroid を使用した際の分類精\n度一覧\n表C.1 はアンダーサンプリングにCC，オーバーサンプリングにBSMOTE を適用した\n各分類器による分類精度である．クラスのサンプル数はMiddle: Finish = 1, 740: 1, 441\nとなった．\n表C.1: CC+BSMOTE を適用したMFCC 特徴量の分類精度\n分類器\nF1 スコア\n適合率\n再現率\n正解率\nロジスティック回帰\n0.420 ± 0.304\n0.480 ± 0.294\n0.520 ± 0.451\n0.619 ± 0.104\nランダムフォレスト\n0.133 ± 0.190\n0.759 ± 0.340\n0.092 ± 0.135\n0.585 ± 0.078\nGNB\n0.375 ± 0.363\n0.580 ± 0.334\n0.487 ± 0.481\n0.609 ± 0.150\nkNN\n0.194 ± 0.280\n0.381 ± 0.361\n0.",
            "1\n0.609 ± 0.150\nkNN\n0.194 ± 0.280\n0.381 ± 0.361\n0.221 ± 0.369\n0.551 ± 0.118\nSV Mlinear\n0.482 ± 0.266\n0.616 ± 0.211\n0.618 ± 0.425\n0.608 ± 0.110\nSV Mpoly\n0.393 ± 0.319\n0.762 ± 0.264\n0.514 ± 0.483\n0.611 ± 0.117\nSV Mrbf\n0.377 ± 0.345\n0.757 ± 0.271\n0.518 ± 0.503\n0.603 ± 0.136\nSV Msigmoid\n0.256 ± 0.332\n0.196 ± 0.254\n0.383 ± 0.495\n0.490 ± 0.178\nXGB\n0.272 ± 0.308\n0.631 ± 0.344\n0.293 ± 0.386\n0.608 ± 0.112\n表C.2 はアンダーサンプリングにCC，オーバーサンプリングにSV MSMOTElinear\nを適用した各分類器による分類精度である．クラスのサンプル数はMiddle: Finish =\n1, 740",
            "した各分類器による分類精度である．クラスのサンプル数はMiddle: Finish =\n1, 740: 1, 516 となった．\n表C.2: CC+SV MSMOTElinear を適用したMFCC 特徴量の分類精度\n分類器\nF1 スコア\n適合率\n再現率\n正解率\nロジスティック回帰\n0.420 ± 0.304\n0.480 ± 0.294\n0.520 ± 0.451\n0.619 ± 0.104\nランダムフォレスト\n0.137 ± 0.260\n0.745 ± 0.362\n0.119 ± 0.264\n0.600 ± 0.105\nGNB\n0.375 ± 0.363\n0.580 ± 0.334\n0.487 ± 0.481\n0.609 ± 0.150\nkNN\n0.194 ± 0.280\n0.381 ± 0.361\n0.221 ± 0.369\n0.551 ± 0.118\nSV Mlinear\n0.482 ± 0.266\n0.616 ± 0.211\n0.618 ± 0.425\n0.608 ± 0.110\nSV Mpoly\n0.393 ± 0.319\n0.762 ± 0.264\n0.514 ± 0.48",
            "\nSV Mpoly\n0.393 ± 0.319\n0.762 ± 0.264\n0.514 ± 0.483\n0.611 ± 0.117\nSV Mrbf\n0.377 ± 0.345\n0.757 ± 0.271\n0.518 ± 0.503\n0.603 ± 0.136\nSV Msigmoid\n0.256 ± 0.332\n0.196 ± 0.254\n0.383 ± 0.495\n0.490 ± 0.178\nXGB\n0.272 ± 0.308\n0.631 ± 0.344\n0.293 ± 0.386\n0.608 ± 0.112\n64\n表C.3はアンダーサンプリングにCC，オーバーサンプリングにSV MSMOTEpoly を適用\nした各分類器による分類精度である．クラスのサンプル数はMiddle: Finish = 1, 740: 1, 575\nとなった．\n表C.3: CC+SV MSMOTEpoly を適用したMFCC 特徴量の分類精度\n分類器\nF1 スコア\n適合率\n再現率\n正解率\nロジスティック回帰\n0.470 ± 0.307\n0.517 ± 0.300\n0.551 ± 0.432\n0.615 ± 0",
            ".470 ± 0.307\n0.517 ± 0.300\n0.551 ± 0.432\n0.615 ± 0.091\nランダムフォレスト\n0.231 ± 0.311\n0.774 ± 0.318\n0.230 ± 0.349\n0.579 ± 0.077\nGNB\n0.449 ± 0.342\n0.718 ± 0.252\n0.562 ± 0.473\n0.602 ± 0.134\nkNN\n0.203 ± 0.290\n0.407 ± 0.367\n0.222 ± 0.368\n0.522 ± 0.115\nSV Mlinear\n0.511 ± 0.278\n0.553 ± 0.265\n0.588 ± 0.402\n0.618 ± 0.106\nSV Mpoly\n0.526 ± 0.335\n0.764 ± 0.208\n0.637 ± 0.457\n0.656 ± 0.125\nSV Mrbf\n0.581 ± 0.318\n0.719 ± 0.207\n0.728 ± 0.418\n0.655 ± 0.131\nSV Msigmoid\n0.285 ± 0.346\n0.230 ± 0.268\n0.401 ± 0.499\n0.472 ± 0",
            ".285 ± 0.346\n0.230 ± 0.268\n0.401 ± 0.499\n0.472 ± 0.164\nXGB\n0.334 ± 0.287\n0.635 ± 0.306\n0.301 ± 0.302\n0.598 ± 0.103\n表C.4はアンダーサンプリングにCC，オーバーサンプリングにSV MSMOTErbf を適用\nした各分類器による分類精度である．クラスのサンプル数はMiddle: Finish = 1, 740: 1, 575\nとなった．\n表C.4: CC+SV MSMOTErbf を適用したMFCC 特徴量の分類精度\n分類器\nF1 スコア\n適合率\n再現率\n正解率\nロジスティック回帰\n0.455 ± 0.305\n0.511 ± 0.296\n0.537 ± 0.438\n0.602 ± 0.091\nランダムフォレスト\n0.231 ± 0.323\n0.802 ± 0.310\n0.206 ± 0.321\n0.591 ± 0.119\nGNB\n0.447 ± 0.343\n0.717 ± 0.255\n0.560 ± 0.475\n0.601 ± 0.134\nkNN\n0.208 ± 0.295",
            ".255\n0.560 ± 0.475\n0.601 ± 0.134\nkNN\n0.208 ± 0.295\n0.408 ± 0.369\n0.227 ± 0.372\n0.524 ± 0.119\nSV Mlinear\n0.523 ± 0.262\n0.559 ± 0.239\n0.617 ± 0.388\n0.610 ± 0.096\nSV Mpoly\n0.527 ± 0.331\n0.763 ± 0.212\n0.637 ± 0.453\n0.653 ± 0.124\nSV Mrbf\n0.573 ± 0.317\n0.717 ± 0.208\n0.721 ± 0.423\n0.650 ± 0.128\nSV Msigmoid\n0.283 ± 0.344\n0.229 ± 0.266\n0.397 ± 0.494\n0.470 ± 0.164\nXGB\n0.364 ± 0.283\n0.654 ± 0.299\n0.330 ± 0.301\n0.606 ± 0.099\n表C.5 はアンダーサンプリングにCC，オーバーサンプリングにSV MSMOTEsigmoid\nを適用した各分類器による分類精度である．クラスのサンプル数はMiddl",
            " MSMOTEsigmoid\nを適用した各分類器による分類精度である．クラスのサンプル数はMiddle: Finish =\n1, 740: 1, 575 となった．\n表C.6 はアンダーサンプリングにCC，オーバーサンプリングにADASYN を適用した\n各分類器による分類精度である．クラスのサンプル数はMiddle: Finish = 1, 740: 1, 724\nとなった．\n65\n表C.5: CC+SV MSMOTEsigmoid を適用したMFCC 特徴量の分類精度\n分類器\nF1 スコア\n適合率\n再現率\n正解率\nロジスティック回帰\n0.453 ± 0.299\n0.518 ± 0.287\n0.533 ± 0.437\n0.596 ± 0.091\nランダムフォレスト\n0.208 ± 0.289\n0.772 ± 0.312\n0.189 ± 0.289\n0.565 ± 0.096\nGNB\n0.444 ± 0.343\n0.717 ± 0.255\n0.556 ± 0.477\n0.600 ± 0.135\nkNN\n0.210 ± 0.295\n0.412 ± 0.372\n0.228 ± 0.372\n0",
            "35\nkNN\n0.210 ± 0.295\n0.412 ± 0.372\n0.228 ± 0.372\n0.524 ± 0.119\nSV Mlinear\n0.511 ± 0.263\n0.561 ± 0.235\n0.611 ± 0.407\n0.608 ± 0.084\nSV Mpoly\n0.528 ± 0.329\n0.764 ± 0.212\n0.636 ± 0.450\n0.654 ± 0.124\nSV Mrbf\n0.574 ± 0.317\n0.716 ± 0.208\n0.723 ± 0.421\n0.651 ± 0.126\nSV Msigmoid\n0.282 ± 0.343\n0.229 ± 0.266\n0.395 ± 0.492\n0.469 ± 0.164\nXGB\n0.368 ± 0.268\n0.734 ± 0.222\n0.356 ± 0.330\n0.592 ± 0.089\n表C.6: CC+ADASYN を適用したMFCC 特徴量の分類精度\n分類器\nF1 スコア\n適合率\n再現率\n正解率\nロジスティック回帰\n0.453 ± 0.299\n0.518 ± 0.287\n0.533 ± 0.437\n0.5",
            "ック回帰\n0.453 ± 0.299\n0.518 ± 0.287\n0.533 ± 0.437\n0.596 ± 0.091\nランダムフォレスト\n0.178 ± 0.304\n0.821 ± 0.315\n0.166 ± 0.313\n0.582 ± 0.094\nGNB\n0.444 ± 0.343\n0.717 ± 0.255\n0.556 ± 0.477\n0.600 ± 0.135\nkNN\n0.210 ± 0.295\n0.412 ± 0.372\n0.228 ± 0.372\n0.524 ± 0.119\nSV Mlinear\n0.511 ± 0.263\n0.561 ± 0.235\n0.611 ± 0.407\n0.608 ± 0.084\nSV Mpoly\n0.528 ± 0.329\n0.764 ± 0.212\n0.636 ± 0.450\n0.654 ± 0.124\nSV Mrbf\n0.574 ± 0.317\n0.716 ± 0.208\n0.723 ± 0.421\n0.651 ± 0.126\nSV Msigmoid\n0.282 ± 0.343\n0.229 ± 0.266\n0.395 ± 0.492\n0.4",
            "moid\n0.282 ± 0.343\n0.229 ± 0.266\n0.395 ± 0.492\n0.469 ± 0.164\nXGB\n0.368 ± 0.268\n0.734 ± 0.222\n0.356 ± 0.330\n0.592 ± 0.089\nC.2\nアンダーサンプリングにCondensed Nearest Neighbour を使用\nした際の分類精度一覧\n表C.7 はアンダーサンプリングにCNN，オーバーサンプリングにBSMOTE を適用し\nた各分類器による分類精度である．クラスのサンプル数はMiddle: Finish = 870: 870 と\nなった．\n表C.8 はアンダーサンプリングにCNN，オーバーサンプリングにSV MSMOTElinear\nを適用した各分類器による分類精度である．クラスのサンプル数はMiddle: Finish =\n870: 870 となった．\n表C.9はアンダーサンプリングにCNN，オーバーサンプリングにSV MSMOTEpoly を適\n用した各分類器による分類精度である．クラスのサンプル数はMiddle: Finish = 870: 870\nとなった．\n",
            "分類精度である．クラスのサンプル数はMiddle: Finish = 870: 870\nとなった．\n表C.10はアンダーサンプリングにCNN，オーバーサンプリングにSV MSMOTErbf を適\n用した各分類器による分類精度である．クラスのサンプル数はMiddle: Finish = 870: 870\nとなった．\n表C.11 はアンダーサンプリングにCNN，オーバーサンプリングにSV MSMOTEsigmoid\nを適用した各分類器による分類精度である．クラスのサンプル数はMiddle: Finish =\n66\n表C.7: CNN+BSMOTE を適用したMFCC 特徴量の分類精度\n分類器\nF1 スコア\n適合率\n再現率\n正解率\nロジスティック回帰\n0.456 ± 0.295\n0.628 ± 0.209\n0.588 ± 0.456\n0.541 ± 0.045\nランダムフォレスト\n0.327 ± 0.294\n0.602 ± 0.319\n0.383 ± 0.382\n0.497 ± 0.064\nGNB\n0.421 ± 0.324\n0.666 ± 0.232\n0.579 ± 0.478\n0.520",
            "NB\n0.421 ± 0.324\n0.666 ± 0.232\n0.579 ± 0.478\n0.520 ± 0.049\nkNN\n0.208 ± 0.329\n0.520 ± 0.428\n0.241 ± 0.404\n0.514 ± 0.148\nSV Mlinear\n0.459 ± 0.278\n0.577 ± 0.195\n0.586 ± 0.445\n0.535 ± 0.039\nSV Mpoly\n0.432 ± 0.320\n0.557 ± 0.284\n0.590 ± 0.471\n0.513 ± 0.052\nSV Mrbf\n0.484 ± 0.316\n0.591 ± 0.240\n0.676 ± 0.462\n0.528 ± 0.052\nSV Msigmoid\n0.450 ± 0.315\n0.341 ± 0.273\n0.664 ± 0.471\n0.479 ± 0.046\nXGB\n0.289 ± 0.271\n0.548 ± 0.296\n0.330 ± 0.373\n0.485 ± 0.053\n表C.8: CNN+SV MSMOTElinear を適用したMFCC 特徴量の分類精度\n分類器\nF1 スコア\n適",
            "NN+SV MSMOTElinear を適用したMFCC 特徴量の分類精度\n分類器\nF1 スコア\n適合率\n再現率\n正解率\nロジスティック回帰\n0.442 ± 0.309\n0.636 ± 0.210\n0.569 ± 0.468\n0.537 ± 0.060\nランダムフォレスト\n0.239 ± 0.272\n0.521 ± 0.343\n0.246 ± 0.329\n0.497 ± 0.076\nGNB\n0.389 ± 0.333\n0.709 ± 0.243\n0.495 ± 0.467\n0.531 ± 0.068\nkNN\n0.201 ± 0.309\n0.421 ± 0.414\n0.244 ± 0.412\n0.485 ± 0.111\nSV Mlinear\n0.456 ± 0.279\n0.656 ± 0.205\n0.569 ± 0.454\n0.541 ± 0.053\nSV Mpoly\n0.458 ± 0.326\n0.590 ± 0.281\n0.616 ± 0.472\n0.535 ± 0.049\nSV Mrbf\n0.545 ± 0.269\n0.619 ± 0.202\n0.722 ± 0.414\n0.546",
            "bf\n0.545 ± 0.269\n0.619 ± 0.202\n0.722 ± 0.414\n0.546 ± 0.084\nSV Msigmoid\n0.343 ± 0.362\n0.272 ± 0.290\n0.475 ± 0.506\n0.507 ± 0.069\nXGB\n0.359 ± 0.305\n0.593 ± 0.281\n0.400 ± 0.399\n0.538 ± 0.071\n870: 870 となった．\nC.3\nアンダーサンプリングにNearMiss-1 を使用した際の分類精度一覧\n表C.12 はアンダーサンプリングにNM1，オーバーサンプリングにBSMOTE を適用し\nた各分類器による分類精度である．クラスのサンプル数はMiddle: Finish = 1, 740: 1, 740\nとなった．\n表C.13 はアンダーサンプリングにNM1，オーバーサンプリングにSV MSMOTElinear\nを適用した各分類器による分類精度である．クラスのサンプル数はMiddle: Finish =\n1, 740: 1, 740 となった．\n表C.14 はアンダーサンプリングにNM1，オーバーサンプリング",
            "740: 1, 740 となった．\n表C.14 はアンダーサンプリングにNM1，オーバーサンプリングにSV MSMOTEpoly\nを適用した各分類器による分類精度である．クラスのサンプル数はMiddle: Finish =\n1, 740: 1, 740 となった．\n表C.15 はアンダーサンプリングにNM1，オーバーサンプリングにSV MSMOTErbf\nを適用した各分類器による分類精度である．クラスのサンプル数はMiddle: Finish =\n1, 740: 1, 740 となった．\n表C.16 はアンダーサンプリングにNM1，オーバーサンプリングにSV MSMOTEsigmoid\n67\n表C.9: CNN+SV MSMOTEpoly を適用したMFCC 特徴量の分類精度\n分類器\nF1 スコア\n適合率\n再現率\n正解率\nロジスティック回帰\n0.448 ± 0.318\n0.635 ± 0.160\n0.576 ± 0.474\n0.556 ± 0.070\nランダムフォレスト\n0.273 ± 0.259\n0.545 ± 0.349\n0.266 ± 0.311\n0.520 ± 0.068\nGN",
            "0.259\n0.545 ± 0.349\n0.266 ± 0.311\n0.520 ± 0.068\nGNB\n0.434 ± 0.331\n0.658 ± 0.249\n0.578 ± 0.478\n0.540 ± 0.076\nkNN\n0.199 ± 0.322\n0.508 ± 0.427\n0.237 ± 0.406\n0.499 ± 0.151\nSV Mlinear\n0.443 ± 0.295\n0.636 ± 0.157\n0.563 ± 0.469\n0.548 ± 0.049\nSV Mpoly\n0.517 ± 0.293\n0.637 ± 0.200\n0.681 ± 0.426\n0.552 ± 0.079\nSV Mrbf\n0.557 ± 0.289\n0.640 ± 0.197\n0.766 ± 0.407\n0.561 ± 0.071\nSV Msigmoid\n0.313 ± 0.336\n0.260 ± 0.278\n0.415 ± 0.464\n0.493 ± 0.067\nXGB\n0.322 ± 0.277\n0.475 ± 0.308\n0.334 ± 0.317\n0.507 ± 0.072\n表C.10: C",
            "0.475 ± 0.308\n0.334 ± 0.317\n0.507 ± 0.072\n表C.10: CNN+SV MSMOTErbf を適用したMFCC 特徴量の分類精度\n分類器\nF1 スコア\n適合率\n再現率\n正解率\nロジスティック回帰\n0.448 ± 0.318\n0.635 ± 0.160\n0.576 ± 0.474\n0.556 ± 0.070\nランダムフォレスト\n0.288 ± 0.270\n0.589 ± 0.328\n0.296 ± 0.309\n0.500 ± 0.076\nGNB\n0.434 ± 0.331\n0.658 ± 0.249\n0.578 ± 0.478\n0.540 ± 0.076\nkNN\n0.199 ± 0.322\n0.508 ± 0.427\n0.237 ± 0.406\n0.499 ± 0.151\nSV Mlinear\n0.443 ± 0.295\n0.636 ± 0.157\n0.563 ± 0.469\n0.548 ± 0.049\nSV Mpoly\n0.517 ± 0.293\n0.637 ± 0.200\n0.681 ± 0.426\n0.552 ± 0.079\nSV Mrbf\n",
            "0.637 ± 0.200\n0.681 ± 0.426\n0.552 ± 0.079\nSV Mrbf\n0.557 ± 0.289\n0.640 ± 0.197\n0.766 ± 0.407\n0.561 ± 0.071\nSV Msigmoid\n0.313 ± 0.336\n0.260 ± 0.278\n0.415 ± 0.464\n0.493 ± 0.067\nXGB\n0.322 ± 0.277\n0.475 ± 0.308\n0.334 ± 0.317\n0.507 ± 0.072\nを適用した各分類器による分類精度である．クラスのサンプル数はMiddle: Finish =\n1, 740: 1, 740 となった．\n表C.17 はアンダーサンプリングにNM1，オーバーサンプリングにADASYN を適用し\nた各分類器による分類精度である．クラスのサンプル数はMiddle: Finish = 1, 740: 1, 726\nとなった．\nC.4\nアンダーサンプリングにNearMiss-2 を使用した際の分類精度一覧\n表C.18 はアンダーサンプリングにNM2，オーバーサンプリングにBSMOTE を適用し\nた各分類",
            "\n表C.18 はアンダーサンプリングにNM2，オーバーサンプリングにBSMOTE を適用し\nた各分類器による分類精度である．クラスのサンプル数はMiddle: Finish = 1, 740: 1, 740\nとなった．\n表C.19 はアンダーサンプリングにNM2，オーバーサンプリングにSV MSMOTElinear\nを適用した各分類器による分類精度である．クラスのサンプル数はMiddle: Finish =\n1, 740: 1, 740 となった．\n表C.20 はアンダーサンプリングにNM2，オーバーサンプリングにSV MSMOTEpoly\nを適用した各分類器による分類精度である．クラスのサンプル数はMiddle: Finish =\n1, 740: 1, 740 となった．\n68\n表C.11: CNN+SV MSMOTEsigmoid を適用したMFCC 特徴量の分類精度\n分類器\nF1 スコア\n適合率\n再現率\n正解率\nロジスティック回帰\n0.448 ± 0.318\n0.635 ± 0.160\n0.576 ± 0.474\n0.556 ± 0.070\nランダムフォレスト\n0.300 ± 0",
            "60\n0.576 ± 0.474\n0.556 ± 0.070\nランダムフォレスト\n0.300 ± 0.277\n0.500 ± 0.340\n0.308 ± 0.316\n0.509 ± 0.075\nGNB\n0.434 ± 0.331\n0.658 ± 0.249\n0.578 ± 0.478\n0.540 ± 0.076\nkNN\n0.199 ± 0.322\n0.508 ± 0.427\n0.237 ± 0.406\n0.499 ± 0.151\nSV Mlinear\n0.443 ± 0.295\n0.636 ± 0.157\n0.563 ± 0.469\n0.548 ± 0.049\nSV Mpoly\n0.517 ± 0.293\n0.637 ± 0.200\n0.681 ± 0.426\n0.552 ± 0.079\nSV Mrbf\n0.557 ± 0.289\n0.640 ± 0.197\n0.766 ± 0.407\n0.561 ± 0.071\nSV Msigmoid\n0.313 ± 0.336\n0.260 ± 0.278\n0.415 ± 0.464\n0.493 ± 0.067\nXGB\n0.322 ± 0.277\n0",
            "78\n0.415 ± 0.464\n0.493 ± 0.067\nXGB\n0.322 ± 0.277\n0.475 ± 0.308\n0.334 ± 0.317\n0.507 ± 0.072\n表C.12: NM1+BSMOTE を適用したMFCC 特徴量の分類精度\n分類器\nF1 スコア\n適合率\n再現率\n正解率\nロジスティック回帰\n0.401 ± 0.299\n0.642 ± 0.201\n0.530 ± 0.468\n0.513 ± 0.015\nランダムフォレスト\n0.163 ± 0.218\n0.554 ± 0.363\n0.164 ± 0.290\n0.484 ± 0.052\nGNB\n0.410 ± 0.355\n0.722 ± 0.242\n0.572 ± 0.499\n0.535 ± 0.063\nkNN\n0.272 ± 0.314\n0.690 ± 0.345\n0.343 ± 0.430\n0.503 ± 0.089\nSV Mlinear\n0.447 ± 0.283\n0.658 ± 0.199\n0.574 ± 0.455\n0.532 ± 0.042\nSV Mpoly\n0.464 ± 0.320\n0.576 ±",
            "0.455\n0.532 ± 0.042\nSV Mpoly\n0.464 ± 0.320\n0.576 ± 0.284\n0.631 ± 0.461\n0.530 ± 0.067\nSV Mrbf\n0.474 ± 0.297\n0.574 ± 0.252\n0.671 ± 0.455\n0.487 ± 0.088\nSV Msigmoid\n0.590 ± 0.212\n0.558 ± 0.157\n0.847 ± 0.329\n0.513 ± 0.042\nXGB\n0.277 ± 0.225\n0.553 ± 0.309\n0.262 ± 0.295\n0.491 ± 0.075\n表C.21 はアンダーサンプリングにNM2，オーバーサンプリングにSV MSMOTErbf\nを適用した各分類器による分類精度である．クラスのサンプル数はMiddle: Finish =\n1, 740: 1, 740 となった．\n表C.22 はアンダーサンプリングにNM2，オーバーサンプリングにSV MSMOTEsigmoid\nを適用した各分類器による分類精度である．クラスのサンプル数はMiddle: Finish =\n1, 740: 1, 7",
            "による分類精度である．クラスのサンプル数はMiddle: Finish =\n1, 740: 1, 740 となった．\n表C.23 はアンダーサンプリングにNM2，オーバーサンプリングにADASYN を適用し\nた各分類器による分類精度である．クラスのサンプル数はMiddle: Finish = 1, 740: 1, 725\nとなった．\nC.5\nアンダーサンプリングにOne-Sided Selection を使用した際の分\n類精度一覧\n表C.24 はアンダーサンプリングにOSS，オーバーサンプリングにBSMOTE を適用し\nた各分類器による分類精度である．クラスのサンプル数はMiddle: Finish = 6, 470: 6, 470\nとなった．\n表C.25 はアンダーサンプリングにOSS，オーバーサンプリングにSV MSMOTElinear\n69\n表C.13: NM1+SV MSMOTElinear を適用したMFCC 特徴量の分類精度\n分類器\nF1 スコア\n適合率\n再現率\n正解率\nロジスティック回帰\n0.401 ± 0.291\n0.616 ± 0.161\n0.518 ± 0.461\n",
            "スティック回帰\n0.401 ± 0.291\n0.616 ± 0.161\n0.518 ± 0.461\n0.517 ± 0.029\nランダムフォレスト\n0.282 ± 0.235\n0.642 ± 0.259\n0.281 ± 0.294\n0.491 ± 0.044\nGNB\n0.435 ± 0.329\n0.568 ± 0.283\n0.610 ± 0.494\n0.523 ± 0.059\nkNN\n0.257 ± 0.303\n0.688 ± 0.343\n0.320 ± 0.415\n0.495 ± 0.080\nSV Mlinear\n0.425 ± 0.277\n0.597 ± 0.157\n0.539 ± 0.453\n0.524 ± 0.043\nSV Mpoly\n0.450 ± 0.329\n0.678 ± 0.235\n0.598 ± 0.470\n0.540 ± 0.095\nSV Mrbf\n0.453 ± 0.314\n0.555 ± 0.283\n0.644 ± 0.476\n0.497 ± 0.054\nSV Msigmoid\n0.277 ± 0.335\n0.666 ± 0.334\n0.405 ± 0.509\n",
            "sigmoid\n0.277 ± 0.335\n0.666 ± 0.334\n0.405 ± 0.509\n0.470 ± 0.098\nXGB\n0.329 ± 0.240\n0.536 ± 0.278\n0.355 ± 0.332\n0.467 ± 0.070\n表C.14: NM1+SV MSMOTEpoly を適用したMFCC 特徴量の分類精度\n分類器\nF1 スコア\n適合率\n再現率\n正解率\nロジスティック回帰\n0.426 ± 0.283\n0.642 ± 0.172\n0.552 ± 0.458\n0.522 ± 0.024\nランダムフォレスト\n0.274 ± 0.272\n0.722 ± 0.247\n0.301 ± 0.362\n0.508 ± 0.024\nGNB\n0.419 ± 0.343\n0.595 ± 0.291\n0.593 ± 0.501\n0.527 ± 0.057\nkNN\n0.266 ± 0.312\n0.585 ± 0.390\n0.337 ± 0.428\n0.497 ± 0.099\nSV Mlinear\n0.448 ± 0.265\n0.640 ± 0.167\n0.564 ± 0.443\n0.53",
            "ear\n0.448 ± 0.265\n0.640 ± 0.167\n0.564 ± 0.443\n0.530 ± 0.031\nSV Mpoly\n0.454 ± 0.318\n0.566 ± 0.283\n0.627 ± 0.467\n0.522 ± 0.052\nSV Mrbf\n0.473 ± 0.293\n0.579 ± 0.240\n0.668 ± 0.454\n0.492 ± 0.055\nSV Msigmoid\n0.281 ± 0.334\n0.672 ± 0.334\n0.407 ± 0.508\n0.470 ± 0.103\nXGB\n0.346 ± 0.285\n0.586 ± 0.263\n0.390 ± 0.407\n0.499 ± 0.130\nを適用した各分類器による分類精度である．クラスのサンプル数はMiddle: Finish =\n6, 470: 5, 889 となった．\n表C.26 はアンダーサンプリングにOSS，オーバーサンプリングにSV MSMOTEpoly\nを適用した各分類器による分類精度である．クラスのサンプル数はMiddle: Finish =\n6, 470: 6, 470 となった．\n",
            "る．クラスのサンプル数はMiddle: Finish =\n6, 470: 6, 470 となった．\n表C.27 はアンダーサンプリングにOSS，オーバーサンプリングにSV MSMOTErbf\nを適用した各分類器による分類精度である．クラスのサンプル数はMiddle: Finish =\n6, 470: 6, 470 となった．\n表C.28 はアンダーサンプリングにOSS，オーバーサンプリングにSV MSMOTEsigmoid\nを適用した各分類器による分類精度である．クラスのサンプル数はMiddle: Finish =\n6, 470: 6, 470 となった．\n表C.29 はアンダーサンプリングにNM2，オーバーサンプリングにADASYN を適用し\nた各分類器による分類精度である．クラスのサンプル数はMiddle: Finish = 6, 470: 6, 499\nとなった．\n70\n表C.15: NM1+SV MSMOTErbf を適用したMFCC 特徴量の分類精度\n分類器\nF1 スコア\n適合率\n再現率\n正解率\nロジスティック回帰\n0.425 ± 0.279\n0.644 ± 0.176\n0.",
            "率\n再現率\n正解率\nロジスティック回帰\n0.425 ± 0.279\n0.644 ± 0.176\n0.552 ± 0.460\n0.521 ± 0.021\nランダムフォレスト\n0.364 ± 0.241\n0.651 ± 0.248\n0.398 ± 0.337\n0.500 ± 0.049\nGNB\n0.421 ± 0.340\n0.599 ± 0.294\n0.592 ± 0.498\n0.528 ± 0.058\nkNN\n0.267 ± 0.313\n0.586 ± 0.390\n0.338 ± 0.430\n0.497 ± 0.101\nSV Mlinear\n0.450 ± 0.267\n0.647 ± 0.172\n0.575 ± 0.456\n0.531 ± 0.032\nSV Mpoly\n0.446 ± 0.323\n0.558 ± 0.284\n0.630 ± 0.485\n0.517 ± 0.049\nSV Mrbf\n0.450 ± 0.309\n0.556 ± 0.275\n0.645 ± 0.475\n0.491 ± 0.035\nSV Msigmoid\n0.281 ± 0.333\n0.672 ± 0.334\n0.",
            "± 0.035\nSV Msigmoid\n0.281 ± 0.333\n0.672 ± 0.334\n0.406 ± 0.507\n0.469 ± 0.103\nXGB\n0.361 ± 0.295\n0.555 ± 0.309\n0.393 ± 0.393\n0.508 ± 0.142\n表C.16: NM1+SV MSMOTEsigmoid を適用したMFCC 特徴量の分類精度\n分類器\nF1 スコア\n適合率\n再現率\n正解率\nロジスティック回帰\n0.424 ± 0.281\n0.643 ± 0.175\n0.551 ± 0.462\n0.520 ± 0.020\nランダムフォレスト\n0.290 ± 0.240\n0.619 ± 0.237\n0.300 ± 0.338\n0.496 ± 0.073\nGNB\n0.423 ± 0.338\n0.601 ± 0.296\n0.594 ± 0.497\n0.528 ± 0.058\nkNN\n0.267 ± 0.314\n0.586 ± 0.390\n0.339 ± 0.431\n0.498 ± 0.101\nSV Mlinear\n0.443 ± 0.267\n0.644 ± 0.170\n0.5",
            "± 0.101\nSV Mlinear\n0.443 ± 0.267\n0.644 ± 0.170\n0.567 ± 0.457\n0.528 ± 0.028\nSV Mpoly\n0.442 ± 0.324\n0.556 ± 0.284\n0.626 ± 0.489\n0.515 ± 0.046\nSV Mrbf\n0.441 ± 0.312\n0.552 ± 0.274\n0.634 ± 0.482\n0.490 ± 0.027\nSV Msigmoid\n0.281 ± 0.333\n0.672 ± 0.334\n0.406 ± 0.507\n0.469 ± 0.103\nXGB\n0.392 ± 0.265\n0.612 ± 0.237\n0.410 ± 0.359\n0.531 ± 0.111\n表C.17: NM1+ADASYN を適用したMFCC 特徴量の分類精度\n分類器\nF1 スコア\n適合率\n再現率\n正解率\nロジスティック回帰\n0.401 ± 0.294\n0.653 ± 0.204\n0.527 ± 0.470\n0.517 ± 0.019\nランダムフォレスト\n0.223 ± 0.217\n0.589 ± 0.274\n0.20",
            "± 0.019\nランダムフォレスト\n0.223 ± 0.217\n0.589 ± 0.274\n0.206 ± 0.280\n0.488 ± 0.085\nGNB\n0.419 ± 0.345\n0.603 ± 0.289\n0.572 ± 0.491\n0.539 ± 0.066\nkNN\n0.266 ± 0.314\n0.585 ± 0.386\n0.339 ± 0.431\n0.498 ± 0.091\nSV Mlinear\n0.437 ± 0.289\n0.654 ± 0.199\n0.563 ± 0.464\n0.532 ± 0.046\nSV Mpoly\n0.448 ± 0.321\n0.559 ± 0.283\n0.629 ± 0.485\n0.521 ± 0.039\nSV Mrbf\n0.454 ± 0.311\n0.555 ± 0.283\n0.646 ± 0.474\n0.500 ± 0.038\nSV Msigmoid\n0.578 ± 0.218\n0.549 ± 0.161\n0.833 ± 0.344\n0.503 ± 0.044\nXGB\n0.268 ± 0.256\n0.518 ± 0.327\n0.297 ± 0.",
            "± 0.044\nXGB\n0.268 ± 0.256\n0.518 ± 0.327\n0.297 ± 0.343\n0.466 ± 0.068\n71\n表C.18: NM2+BSMOTE を適用したMFCC 特徴量の分類精度\n分類器\nF1 スコア\n適合率\n再現率\n正解率\nロジスティック回帰\n0.385 ± 0.287\n0.607 ± 0.217\n0.494 ± 0.456\n0.504 ± 0.027\nランダムフォレスト\n0.138 ± 0.217\n0.576 ± 0.384\n0.124 ± 0.243\n0.512 ± 0.039\nGNB\n0.439 ± 0.377\n0.676 ± 0.293\n0.577 ± 0.493\n0.562 ± 0.142\nkNN\n0.242 ± 0.281\n0.473 ± 0.359\n0.272 ± 0.369\n0.478 ± 0.098\nSV Mlinear\n0.445 ± 0.271\n0.644 ± 0.201\n0.551 ± 0.426\n0.528 ± 0.051\nSV Mpoly\n0.499 ± 0.269\n0.616 ± 0.209\n0.664 ± 0.395",
            "SV Mpoly\n0.499 ± 0.269\n0.616 ± 0.209\n0.664 ± 0.395\n0.512 ± 0.059\nSV Mrbf\n0.524 ± 0.280\n0.608 ± 0.207\n0.752 ± 0.423\n0.513 ± 0.017\nSV Msigmoid\n0.589 ± 0.215\n0.557 ± 0.158\n0.844 ± 0.331\n0.514 ± 0.045\nXGB\n0.197 ± 0.249\n0.510 ± 0.382\n0.217 ± 0.342\n0.488 ± 0.039\n表C.19: NM2+SV MSMOTElinear を適用したMFCC 特徴量の分類精度\n分類器\nF1 スコア\n適合率\n再現率\n正解率\nロジスティック回帰\n0.384 ± 0.279\n0.606 ± 0.215\n0.486 ± 0.452\n0.505 ± 0.019\nランダムフォレスト\n0.168 ± 0.205\n0.695 ± 0.274\n0.149 ± 0.253\n0.505 ± 0.031\nGNB\n0.456 ± 0.357\n0.581 ± 0.310\n0.609 ± 0.",
            "± 0.031\nGNB\n0.456 ± 0.357\n0.581 ± 0.310\n0.609 ± 0.487\n0.549 ± 0.147\nkNN\n0.216 ± 0.257\n0.553 ± 0.354\n0.236 ± 0.337\n0.459 ± 0.093\nSV Mlinear\n0.426 ± 0.259\n0.637 ± 0.203\n0.520 ± 0.425\n0.518 ± 0.029\nSV Mpoly\n0.442 ± 0.285\n0.575 ± 0.245\n0.588 ± 0.441\n0.483 ± 0.099\nSV Mrbf\n0.520 ± 0.280\n0.605 ± 0.208\n0.746 ± 0.427\n0.511 ± 0.021\nSV Msigmoid\n0.583 ± 0.217\n0.551 ± 0.160\n0.837 ± 0.339\n0.507 ± 0.042\nXGB\n0.321 ± 0.283\n0.544 ± 0.318\n0.371 ± 0.408\n0.491 ± 0.087\n表C.20: NM2+SV MSMOTEpoly を適用したMFCC 特徴量の分類精度\n分類器\n",
            "7\n表C.20: NM2+SV MSMOTEpoly を適用したMFCC 特徴量の分類精度\n分類器\nF1 スコア\n適合率\n再現率\n正解率\nロジスティック回帰\n0.395 ± 0.279\n0.617 ± 0.215\n0.503 ± 0.450\n0.507 ± 0.026\nランダムフォレスト\n0.213 ± 0.220\n0.620 ± 0.327\n0.184 ± 0.243\n0.510 ± 0.060\nGNB\n0.459 ± 0.351\n0.694 ± 0.251\n0.598 ± 0.471\n0.552 ± 0.145\nkNN\n0.256 ± 0.287\n0.472 ± 0.360\n0.296 ± 0.380\n0.468 ± 0.103\nSV Mlinear\n0.433 ± 0.260\n0.638 ± 0.200\n0.534 ± 0.426\n0.519 ± 0.029\nSV Mpoly\n0.466 ± 0.290\n0.591 ± 0.243\n0.617 ± 0.433\n0.498 ± 0.107\nSV Mrbf\n0.523 ± 0.280\n0.607 ± 0.207\n0.751 ± 0.4",
            "07\nSV Mrbf\n0.523 ± 0.280\n0.607 ± 0.207\n0.751 ± 0.423\n0.511 ± 0.013\nSV Msigmoid\n0.513 ± 0.282\n0.600 ± 0.214\n0.731 ± 0.425\n0.506 ± 0.046\nXGB\n0.371 ± 0.301\n0.468 ± 0.303\n0.420 ± 0.418\n0.536 ± 0.105\n72\n表C.21: NM2+SV MSMOTErbf を適用したMFCC 特徴量の分類精度\n分類器\nF1 スコア\n適合率\n再現率\n正解率\nロジスティック回帰\n0.399 ± 0.279\n0.623 ± 0.213\n0.507 ± 0.450\n0.510 ± 0.018\nランダムフォレスト\n0.137 ± 0.211\n0.615 ± 0.379\n0.137 ± 0.278\n0.496 ± 0.033\nGNB\n0.464 ± 0.351\n0.697 ± 0.248\n0.604 ± 0.470\n0.554 ± 0.147\nkNN\n0.258 ± 0.288\n0.473 ± 0.359\n0.298 ± 0.38",
            "0.147\nkNN\n0.258 ± 0.288\n0.473 ± 0.359\n0.298 ± 0.382\n0.469 ± 0.105\nSV Mlinear\n0.436 ± 0.259\n0.646 ± 0.199\n0.535 ± 0.426\n0.523 ± 0.027\nSV Mpoly\n0.443 ± 0.307\n0.574 ± 0.266\n0.593 ± 0.458\n0.498 ± 0.096\nSV Mrbf\n0.507 ± 0.282\n0.597 ± 0.214\n0.728 ± 0.434\n0.501 ± 0.024\nSV Msigmoid\n0.578 ± 0.220\n0.549 ± 0.163\n0.828 ± 0.344\n0.505 ± 0.047\nXGB\n0.328 ± 0.266\n0.550 ± 0.317\n0.353 ± 0.375\n0.508 ± 0.069\n表C.22: NM2+SV MSMOTEsigmoid を適用したMFCC 特徴量の分類精度\n分類器\nF1 スコア\n適合率\n再現率\n正解率\nロジスティック回帰\n0.397 ± 0.280\n0.623 ± 0.211\n0.",
            "率\n再現率\n正解率\nロジスティック回帰\n0.397 ± 0.280\n0.623 ± 0.211\n0.504 ± 0.450\n0.510 ± 0.018\nランダムフォレスト\n0.138 ± 0.175\n0.581 ± 0.329\n0.110 ± 0.165\n0.492 ± 0.028\nGNB\n0.468 ± 0.350\n0.697 ± 0.248\n0.610 ± 0.465\n0.554 ± 0.148\nkNN\n0.259 ± 0.290\n0.473 ± 0.360\n0.300 ± 0.385\n0.470 ± 0.106\nSV Mlinear\n0.432 ± 0.259\n0.644 ± 0.198\n0.531 ± 0.426\n0.522 ± 0.024\nSV Mpoly\n0.430 ± 0.318\n0.561 ± 0.284\n0.582 ± 0.471\n0.501 ± 0.083\nSV Mrbf\n0.492 ± 0.282\n0.588 ± 0.220\n0.706 ± 0.437\n0.491 ± 0.039\nSV Msigmoid\n0.578 ± 0.220\n0.549 ± 0.163\n0.",
            "± 0.039\nSV Msigmoid\n0.578 ± 0.220\n0.549 ± 0.163\n0.828 ± 0.344\n0.505 ± 0.047\nXGB\n0.332 ± 0.255\n0.469 ± 0.308\n0.359 ± 0.371\n0.508 ± 0.052\n表C.23: NM2+ASASYN を適用したMFCC 特徴量の分類精度\n分類器\nF1 スコア\n適合率\n再現率\n正解率\nロジスティック回帰\n0.372 ± 0.284\n0.602 ± 0.221\n0.475 ± 0.459\n0.501 ± 0.036\nランダムフォレスト\n0.122 ± 0.214\n0.683 ± 0.366\n0.117 ± 0.251\n0.504 ± 0.040\nGNB\n0.451 ± 0.360\n0.592 ± 0.318\n0.580 ± 0.473\n0.556 ± 0.149\nkNN\n0.249 ± 0.282\n0.472 ± 0.352\n0.284 ± 0.377\n0.470 ± 0.111\nSV Mlinear\n0.409 ± 0.274\n0.632 ± 0.208\n0.507 ± 0.442",
            " Mlinear\n0.409 ± 0.274\n0.632 ± 0.208\n0.507 ± 0.442\n0.516 ± 0.041\nSV Mpoly\n0.432 ± 0.313\n0.561 ± 0.284\n0.582 ± 0.464\n0.500 ± 0.075\nSV Mrbf\n0.517 ± 0.283\n0.605 ± 0.209\n0.739 ± 0.432\n0.514 ± 0.025\nSV Msigmoid\n0.579 ± 0.222\n0.550 ± 0.164\n0.831 ± 0.347\n0.508 ± 0.056\nXGB\n0.180 ± 0.251\n0.660 ± 0.300\n0.198 ± 0.333\n0.492 ± 0.032\n73\n表C.24: OSS+BSMOTE を適用したMFCC 特徴量の分類精度\n分類器\nF1 スコア\n適合率\n再現率\n正解率\nロジスティック回帰\n0.546 ± 0.284\n0.678 ± 0.232\n0.600 ± 0.388\n0.625 ± 0.103\nランダムフォレスト\n0.041 ± 0.067\n0.762 ± 0.362\n0.025 ± 0.0",
            "\nランダムフォレスト\n0.041 ± 0.067\n0.762 ± 0.362\n0.025 ± 0.041\n0.496 ± 0.024\nGNB\n0.392 ± 0.403\n0.674 ± 0.342\n0.462 ± 0.487\n0.601 ± 0.143\nkNN\n0.183 ± 0.312\n0.511 ± 0.438\n0.205 ± 0.382\n0.495 ± 0.147\nSV Mlinear\n0.551 ± 0.299\n0.560 ± 0.294\n0.618 ± 0.393\n0.625 ± 0.119\nSV Mpoly\n0.397 ± 0.358\n0.675 ± 0.205\n0.480 ± 0.476\n0.575 ± 0.117\nSV Mrbf\n0.504 ± 0.331\n0.695 ± 0.182\n0.627 ± 0.462\n0.603 ± 0.109\nSV Msigmoid\n0.430 ± 0.385\n0.672 ± 0.309\n0.538 ± 0.499\n0.593 ± 0.141\nXGB\n0.151 ± 0.242\n0.699 ± 0.366\n0.138 ± 0.255\n0.5",
            "\nXGB\n0.151 ± 0.242\n0.699 ± 0.366\n0.138 ± 0.255\n0.506 ± 0.081\n表C.25: OSS+SV MSMOTElinear を適用したMFCC 特徴量の分類精度\n分類器\nF1 スコア\n適合率\n再現率\n正解率\nロジスティック回帰\n0.525 ± 0.222\n0.593 ± 0.256\n0.581 ± 0.360\n0.600 ± 0.089\nランダムフォレスト\n0.051 ± 0.089\n0.722 ± 0.394\n0.033 ± 0.057\n0.502 ± 0.071\nGNB\n0.324 ± 0.377\n0.606 ± 0.391\n0.409 ± 0.489\n0.558 ± 0.153\nkNN\n0.174 ± 0.299\n0.493 ± 0.418\n0.190 ± 0.359\n0.504 ± 0.124\nSV Mlinear\n0.575 ± 0.234\n0.601 ± 0.259\n0.646 ± 0.333\n0.624 ± 0.111\nSV Mpoly\n0.384 ± 0.328\n0.656 ± 0.225\n0.480 ± 0.467\n",
            "V Mpoly\n0.384 ± 0.328\n0.656 ± 0.225\n0.480 ± 0.467\n0.555 ± 0.113\nSV Mrbf\n0.503 ± 0.298\n0.670 ± 0.205\n0.639 ± 0.431\n0.582 ± 0.101\nSV Msigmoid\n0.394 ± 0.378\n0.641 ± 0.330\n0.520 ± 0.509\n0.569 ± 0.158\nXGB\n0.176 ± 0.191\n0.568 ± 0.400\n0.141 ± 0.153\n0.504 ± 0.055\n表C.26: OSS+SV MSMOTEpoly を適用したMFCC 特徴量の分類精度\n分類器\nF1 スコア\n適合率\n再現率\n正解率\nロジスティック回帰\n0.573 ± 0.266\n0.622 ± 0.252\n0.629 ± 0.375\n0.641 ± 0.101\nランダムフォレスト\n0.073 ± 0.123\n0.627 ± 0.432\n0.052 ± 0.086\n0.480 ± 0.054\nGNB\n0.383 ± 0.399\n0.603 ± 0.338\n0.469 ± 0.494",
            ".054\nGNB\n0.383 ± 0.399\n0.603 ± 0.338\n0.469 ± 0.494\n0.584 ± 0.139\nkNN\n0.207 ± 0.312\n0.529 ± 0.426\n0.232 ± 0.386\n0.493 ± 0.142\nSV Mlinear\n0.586 ± 0.260\n0.606 ± 0.255\n0.647 ± 0.366\n0.641 ± 0.106\nSV Mpoly\n0.492 ± 0.333\n0.733 ± 0.177\n0.586 ± 0.449\n0.610 ± 0.098\nSV Mrbf\n0.553 ± 0.311\n0.706 ± 0.181\n0.692 ± 0.431\n0.615 ± 0.093\nSV Msigmoid\n0.424 ± 0.384\n0.667 ± 0.310\n0.533 ± 0.502\n0.589 ± 0.140\nXGB\n0.169 ± 0.243\n0.695 ± 0.360\n0.164 ± 0.267\n0.499 ± 0.074\n74\n表C.27: OSS+SV MSMOTErbf を適用したMFCC 特徴量の分類精度\n分類器\nF",
            "4\n表C.27: OSS+SV MSMOTErbf を適用したMFCC 特徴量の分類精度\n分類器\nF1 スコア\n適合率\n再現率\n正解率\nロジスティック回帰\n0.569 ± 0.266\n0.623 ± 0.252\n0.626 ± 0.379\n0.639 ± 0.100\nランダムフォレスト\n0.083 ± 0.135\n0.740 ± 0.369\n0.061 ± 0.098\n0.488 ± 0.042\nGNB\n0.387 ± 0.400\n0.609 ± 0.329\n0.474 ± 0.496\n0.585 ± 0.143\nkNN\n0.208 ± 0.312\n0.528 ± 0.426\n0.234 ± 0.388\n0.493 ± 0.142\nSV Mlinear\n0.578 ± 0.263\n0.604 ± 0.255\n0.640 ± 0.372\n0.638 ± 0.105\nSV Mpoly\n0.493 ± 0.333\n0.736 ± 0.182\n0.588 ± 0.450\n0.609 ± 0.099\nSV Mrbf\n0.553 ± 0.312\n0.706 ± 0.181\n0.694 ± 0.43",
            "9\nSV Mrbf\n0.553 ± 0.312\n0.706 ± 0.181\n0.694 ± 0.432\n0.615 ± 0.093\nSV Msigmoid\n0.425 ± 0.383\n0.668 ± 0.310\n0.534 ± 0.501\n0.590 ± 0.140\nXGB\n0.234 ± 0.279\n0.579 ± 0.374\n0.232 ± 0.308\n0.519 ± 0.080\n表C.28: OSS+SV MSMOTEsigmoid を適用したMFCC 特徴量の分類精度\n分類器\nF1 スコア\n適合率\n再現率\n正解率\nロジスティック回帰\n0.568 ± 0.265\n0.623 ± 0.252\n0.624 ± 0.379\n0.639 ± 0.099\nランダムフォレスト\n0.067 ± 0.113\n0.723 ± 0.389\n0.047 ± 0.078\n0.480 ± 0.055\nGNB\n0.389 ± 0.400\n0.619 ± 0.325\n0.475 ± 0.496\n0.586 ± 0.145\nkNN\n0.209 ± 0.313\n0.528 ± 0.426\n0.234 ± 0.38",
            "0.145\nkNN\n0.209 ± 0.313\n0.528 ± 0.426\n0.234 ± 0.389\n0.493 ± 0.142\nSV Mlinear\n0.576 ± 0.263\n0.604 ± 0.255\n0.637 ± 0.372\n0.637 ± 0.105\nSV Mpoly\n0.492 ± 0.334\n0.736 ± 0.182\n0.587 ± 0.450\n0.609 ± 0.100\nSV Mrbf\n0.553 ± 0.312\n0.707 ± 0.181\n0.693 ± 0.433\n0.616 ± 0.094\nSV Msigmoid\n0.425 ± 0.383\n0.667 ± 0.310\n0.534 ± 0.501\n0.590 ± 0.140\nXGB\n0.217 ± 0.252\n0.564 ± 0.373\n0.205 ± 0.263\n0.507 ± 0.061\n表C.29: OSS+ADASYN を適用したMFCC 特徴量の分類精度\n分類器\nF1 スコア\n適合率\n再現率\n正解率\nロジスティック回帰\n0.547 ± 0.249\n0.611 ± 0.252\n0.593 ± 0.37",
            "ロジスティック回帰\n0.547 ± 0.249\n0.611 ± 0.252\n0.593 ± 0.379\n0.622 ± 0.088\nランダムフォレスト\n0.058 ± 0.101\n0.733 ± 0.380\n0.038 ± 0.065\n0.490 ± 0.031\nGNB\n0.403 ± 0.403\n0.680 ± 0.324\n0.481 ± 0.493\n0.597 ± 0.158\nkNN\n0.192 ± 0.307\n0.498 ± 0.401\n0.216 ± 0.377\n0.489 ± 0.135\nSV Mlinear\n0.549 ± 0.251\n0.593 ± 0.256\n0.603 ± 0.378\n0.616 ± 0.094\nSV Mpoly\n0.451 ± 0.338\n0.711 ± 0.180\n0.545 ± 0.476\n0.592 ± 0.105\nSV Mrbf\n0.544 ± 0.307\n0.699 ± 0.178\n0.677 ± 0.434\n0.610 ± 0.093\nSV Msigmoid\n0.422 ± 0.383\n0.666 ± 0.310\n0.532 ± 0.50",
            " Msigmoid\n0.422 ± 0.383\n0.666 ± 0.310\n0.532 ± 0.502\n0.587 ± 0.141\nXGB\n0.108 ± 0.165\n0.477 ± 0.433\n0.085 ± 0.140\n0.477 ± 0.078\n75\n質疑応答\n浦垣啓志郎情報テクノロジー学科助手\nQ\n近年の研究では，CNN などを利用した方が結果が出ることがわかっているにも関\nわらず，SVM などの古典的な分類器を利用しているのはなぜですか．\nA\nご質問ありがとうございます．本研究で取得したデータセットの問題があったため\nです．10 種類の調理音データを取得しましたが，時系列データとしては，10 種類の\nデータではデータ量として少ないため，CNN やRNN などは検討できませんでした．\n実際に，LSTM を考慮いたしましたが，モデルの学習途中で過学習となっているこ\nとがすぐにわかり，断念しております．\n浦垣啓志郎情報テクノロジー学科助手\nQ\n解いている問題が非常に面白いです．ヒューリスティックアルゴリズムだと唐揚げ\n粉の材質とかにも敏感なので，対策に関する考察があると良いと思いま",
            "リスティックアルゴリズムだと唐揚げ\n粉の材質とかにも敏感なので，対策に関する考察があると良いと思いました．\nA\n貴重なご意見ありがとうございます．本研究で利用した調理データには，パン粉で\n調理したものと唐揚げ粉を利用したものの2 種類ございました．両者の特徴は多少\n異なりましたが，どちらも変化点検出を利用して揚げ終わりを捉えられておりまし\nた．今後，他の材料を使用した際の特徴の違いも考慮したシステムを構築していき\nたいと考えております．\n大原剛三情報テクノロジー学科教授\nQ\n変化点検出において，実際の検出されたタイミングと真値ラベルとの誤差は，何秒\n程度ありますか．\nA\nご質問ありがとうございます．10 種類の内，変化点を検出できたのは9 種類であ\nり，それらの真値ラベルと検出された変化点の差は，平均1.54 秒でした．150 秒以\n降に初めて検出された点という制限を設けることで，適合率も90%となっているた\nめ，安全な調理支援が可能であると考えています．\n76\nD¨urst Martin 情報テクノロジー学科教授\nQ\nCan your system be used to cook o",
            "n 情報テクノロジー学科教授\nQ\nCan your system be used to cook other things? (I wouldn ’t want to eat fried\nchicken every day.) How much time would the tuning for a diﬀerent dish take, and\nwhat kinds of dishes would be suited?\nA\nご質問ありがとうございます．現状のシステムでは，他の料理への適用は困難であ\nると考えております．唐揚げのフライ調理の音響特徴に対して有効な変化点検出と\nなっているため，他の料理に適用するためには，本研究のフロート同様に適切な特\n徴を調査し，精度検証を実施する必要があります．しかし，揚げ物については解析\nの結果，類似した音響特徴であると判明すれば，簡単に適用可能であると考えられ\nます．またシステムの拡張性を考慮すると，機械学習による分類ができた方が良い\nため，別の料理にチューニングする場合も，大量のデータセットを取得する必要が\nあり，その分の時間が必要であると考えて",
            "にチューニングする場合も，大量のデータセットを取得する必要が\nあり，その分の時間が必要であると考えています．別の適した料理としては，とん\nかつや天ぷらなど，フライ調理により衣がつく料理は，適していると考えられます．\nD¨urst Martin 情報テクノロジー学科教授\nQ\nDoes the best timing for ending frying change depending on the type of coating of\nthe fried chicken (e.g. mostly just spies vs. thick breading)?\nA\nご質問ありがとうございます．本研究で利用したデータセットにおいても，パン粉\nを利用したものと，唐揚げ粉を利用した調理手法があり，その違いによる最適なタ\nイミングは大きな違いがないことがわかっています．ただ極端なレシピにおいては，\n同様の特徴変化が捉えられない可能性があるため，最適なタイミングは変わる可能\n性があります．また，本研究では料理初心者向けのシステムであるため，そのよう\nな極端なカスタマイズは考慮しておりません．今後，個",
            "では料理初心者向けのシステムであるため，そのよう\nな極端なカスタマイズは考慮しておりません．今後，個人の好みに合わせた最適な\n揚げ終わり検出が可能になるようシステムを拡張する場合，そのような極端なレシ\nピも考慮する必要があるため，今後，検討したいと思います．\nD¨urst Martin 情報テクノロジー学科教授\nQ\nWhat ’s the (average) overall cooking time for fried chicken?\nA\nご質問ありがとうございます．インターネット上に掲載されている10 種類のレシ\nピを調査したところ，調理時間は平均4 分程度となっており，本研究のデータセッ\nトにおいても，調理時間は4 分程度となっております．\n77\nD¨urst Martin 情報テクノロジー学科教授\nQ\nWere you able to successfully use your system to fry delicious fried chicken?\nA\nご質問ありがとうございます．本研究では，システムを利用してリアルタイムの性\n能評価を実施しておりません．また，本研究では",
            "います．本研究では，システムを利用してリアルタイムの性\n能評価を実施しておりません．また，本研究ではフライ調理が完了したかどうかを\n判定しており，美味しさについては考慮しておりません．今後，システムの評価を\n実施していきたいと考えております．また，ただ揚げ終わりかどうかを判定するだ\nけでなく，美味しく揚げられているかも判定できるようにシステムを拡張していき\nたいと考えております．\n78\n"
        ]
    }
]